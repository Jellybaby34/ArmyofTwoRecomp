#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_82A5DC58"))) PPC_WEAK_FUNC(sub_82A5DC58);
PPC_FUNC_IMPL(__imp__sub_82A5DC58) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c4
	ctx.lr = 0x82A5DC60;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lis r3,-17477
	ctx.r3.s64 = -1145372672;
	// ori r3,r3,48059
	ctx.r3.u64 = ctx.r3.u64 | 48059;
	// lwz r31,0(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82a5cf58
	ctx.lr = 0x82A5DC78;
	sub_82A5CF58(ctx, base);
	// lis r29,256
	ctx.r29.s64 = 16777216;
	// b 0x82a5dc98
	goto loc_82A5DC98;
loc_82A5DC80:
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// slw r11,r29,r11
	ctx.r11.u64 = ctx.r11.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r11.u8 & 0x3F));
	// and. r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 & ctx.r10.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a5dca4
	if (!ctx.cr0.eq) goto loc_82A5DCA4;
	// db16cyc 
loc_82A5DC98:
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a5dc80
	if (!ctx.cr6.eq) goto loc_82A5DC80;
loc_82A5DCA4:
	// li r28,0
	ctx.r28.s64 = 0;
	// li r27,1
	ctx.r27.s64 = 1;
loc_82A5DCAC:
	// mfmsr r10
	ctx.r10.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r31
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r31.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// cmpw cr6,r11,r28
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r28.s32, ctx.xer);
	// bne cr6,0x82a5dcd0
	if (!ctx.cr6.eq) goto loc_82A5DCD0;
	// stwcx. r27,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r27.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82a5dcac
	if (!ctx.cr0.eq) goto loc_82A5DCAC;
	// b 0x82a5dcd8
	goto loc_82A5DCD8;
loc_82A5DCD0:
	// stwcx. r11,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
loc_82A5DCD8:
	// mr r11,r11
	ctx.r11.u64 = ctx.r11.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a5dcac
	if (!ctx.cr6.eq) goto loc_82A5DCAC;
	// lwsync 
	// lwz r11,60(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 60);
	// lwz r10,56(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	// lis r3,-17477
	ctx.r3.s64 = -1145372672;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82a5dd14
	if (!ctx.cr6.eq) goto loc_82A5DD14;
	// ori r3,r3,48060
	ctx.r3.u64 = ctx.r3.u64 | 48060;
	// bl 0x82a5cf58
	ctx.lr = 0x82A5DD04;
	sub_82A5CF58(ctx, base);
	// lwsync 
	// stw r28,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r28.u32);
loc_82A5DD0C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c514
	__restgprlr_27(ctx, base);
	return;
loc_82A5DD14:
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// ori r3,r3,48061
	ctx.r3.u64 = ctx.r3.u64 | 48061;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r11.u32);
	// lwz r11,60(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 60);
	// clrlwi r10,r11,30
	ctx.r10.u64 = ctx.r11.u32 & 0x3;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r10,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r30.u32);
	// stw r11,60(r30)
	PPC_STORE_U32(ctx.r30.u32 + 60, ctx.r11.u32);
	// bl 0x82a5cf58
	ctx.lr = 0x82A5DD44;
	sub_82A5CF58(ctx, base);
	// lwz r3,60(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// bl 0x82a5cf58
	ctx.lr = 0x82A5DD4C;
	sub_82A5CF58(ctx, base);
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// bl 0x82a5cf58
	ctx.lr = 0x82A5DD54;
	sub_82A5CF58(ctx, base);
	// lwz r11,56(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	// lwz r10,60(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 60);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// clrlwi r3,r11,30
	ctx.r3.u64 = ctx.r11.u32 & 0x3;
	// bl 0x82a5cf58
	ctx.lr = 0x82A5DD68;
	sub_82A5CF58(ctx, base);
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// ble cr6,0x82a5dd7c
	if (!ctx.cr6.gt) goto loc_82A5DD7C;
	// lwz r5,36(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// b 0x82a5dda8
	goto loc_82A5DDA8;
loc_82A5DD7C:
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// lwz r5,72(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// stw r28,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r28.u32);
	// cmplwi r5,0
	ctx.cr0.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// slw r11,r29,r11
	ctx.r11.u64 = ctx.r11.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r11.u8 & 0x3F));
	// stw r11,56(r31)
	PPC_STORE_U32(ctx.r31.u32 + 56, ctx.r11.u32);
	// beq 0x82a5dda0
	if (ctx.cr0.eq) goto loc_82A5DDA0;
	// stw r28,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r28.u32);
	// b 0x82a5dda8
	goto loc_82A5DDA8;
loc_82A5DDA0:
	// addi r5,r4,4
	ctx.r5.s64 = ctx.r4.s64 + 4;
	// stw r4,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r4.u32);
loc_82A5DDA8:
	// lis r29,-16384
	ctx.r29.s64 = -1073741824;
loc_82A5DDAC:
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// cmplw cr6,r6,r11
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82a5ddd4
	if (!ctx.cr6.lt) goto loc_82A5DDD4;
	// addi r11,r6,1
	ctx.r11.s64 = ctx.r6.s64 + 1;
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r5,32(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// stw r11,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r11.u32);
	// lwsync 
	// b 0x82a5de24
	goto loc_82A5DE24;
loc_82A5DDD4:
	// lwz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// rlwinm. r10,r11,0,0,0
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x80000000;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82a5de40
	if (!ctx.cr0.eq) goto loc_82A5DE40;
	// lwz r9,360(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 360);
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// lwz r8,356(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 356);
	// rlwinm r10,r11,16,17,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 16) & 0x7FFF;
	// and. r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 & ctx.r8.u64;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne 0x82a5de00
	if (!ctx.cr0.eq) goto loc_82A5DE00;
	// add r5,r10,r5
	ctx.r5.u64 = ctx.r10.u64 + ctx.r5.u64;
	// b 0x82a5ddac
	goto loc_82A5DDAC;
loc_82A5DE00:
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// add r10,r10,r5
	ctx.r10.u64 = ctx.r10.u64 + ctx.r5.u64;
	// stw r27,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r27.u32);
	// stw r5,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r5.u32);
	// stw r11,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r11.u32);
	// stw r10,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r10.u32);
	// lwsync 
	// li r6,0
	ctx.r6.s64 = 0;
loc_82A5DE24:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r28,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r28.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A5DE38;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r5,36(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// b 0x82a5ddac
	goto loc_82A5DDAC;
loc_82A5DE40:
	// lis r10,-29440
	ctx.r10.s64 = -1929379840;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82a5de5c
	if (!ctx.cr6.eq) goto loc_82A5DE5C;
	// lwz r11,4(r5)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// addi r5,r5,8
	ctx.r5.s64 = ctx.r5.s64 + 8;
	// stw r11,360(r31)
	PPC_STORE_U32(ctx.r31.u32 + 360, ctx.r11.u32);
	// b 0x82a5ddac
	goto loc_82A5DDAC;
loc_82A5DE5C:
	// lis r10,-29696
	ctx.r10.s64 = -1946157056;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82a5de80
	if (!ctx.cr6.eq) goto loc_82A5DE80;
	// lwz r11,4(r5)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// lwz r11,8(r5)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// addi r5,r5,12
	ctx.r5.s64 = ctx.r5.s64 + 12;
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// b 0x82a5ddac
	goto loc_82A5DDAC;
loc_82A5DE80:
	// rlwinm r10,r11,0,0,1
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xC0000000;
	// cmplw cr6,r10,r29
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r29.u32, ctx.xer);
	// bne cr6,0x82a5deb4
	if (!ctx.cr6.eq) goto loc_82A5DEB4;
	// cmplw cr6,r11,r29
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r29.u32, ctx.xer);
	// bne cr6,0x82a5deac
	if (!ctx.cr6.eq) goto loc_82A5DEAC;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a5db30
	ctx.lr = 0x82A5DEA0;
	sub_82A5DB30(ctx, base);
	// mr. r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// bne 0x82a5ddac
	if (!ctx.cr0.eq) goto loc_82A5DDAC;
	// b 0x82a5dd0c
	goto loc_82A5DD0C;
loc_82A5DEAC:
	// addi r5,r11,4
	ctx.r5.s64 = ctx.r11.s64 + 4;
	// b 0x82a5ddac
	goto loc_82A5DDAC;
loc_82A5DEB4:
	// lis r3,-12288
	ctx.r3.s64 = -805306368;
	// bl 0x82a5cf58
	ctx.lr = 0x82A5DEBC;
	sub_82A5CF58(ctx, base);
	// lwz r11,100(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// stw r27,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r27.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r10,60(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// stw r11,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r11.u32);
	// beq cr6,0x82a5df3c
	if (ctx.cr6.eq) goto loc_82A5DF3C;
	// stw r5,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r5.u32);
	// lwsync 
	// stw r28,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r28.u32);
	// b 0x82a5deec
	goto loc_82A5DEEC;
loc_82A5DEE8:
	// db16cyc 
loc_82A5DEEC:
	// lwz r11,96(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a5dee8
	if (!ctx.cr6.eq) goto loc_82A5DEE8;
loc_82A5DEF8:
	// mfmsr r10
	ctx.r10.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r31
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r31.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// cmpw cr6,r11,r28
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r28.s32, ctx.xer);
	// bne cr6,0x82a5df1c
	if (!ctx.cr6.eq) goto loc_82A5DF1C;
	// stwcx. r27,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r27.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82a5def8
	if (!ctx.cr0.eq) goto loc_82A5DEF8;
	// b 0x82a5df24
	goto loc_82A5DF24;
loc_82A5DF1C:
	// stwcx. r11,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
loc_82A5DF24:
	// mr r11,r11
	ctx.r11.u64 = ctx.r11.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a5def8
	if (!ctx.cr6.eq) goto loc_82A5DEF8;
	// lwsync 
	// lwz r5,36(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// b 0x82a5df50
	goto loc_82A5DF50;
loc_82A5DF3C:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// bl 0x82a5d808
	ctx.lr = 0x82A5DF48;
	sub_82A5D808(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// stw r28,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r28.u32);
loc_82A5DF50:
	// lwz r11,100(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// lis r3,-12288
	ctx.r3.s64 = -805306368;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// ori r3,r3,1
	ctx.r3.u64 = ctx.r3.u64 | 1;
	// stw r11,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r11.u32);
	// bl 0x82a5cf58
	ctx.lr = 0x82A5DF68;
	sub_82A5CF58(ctx, base);
	// b 0x82a5ddac
	goto loc_82A5DDAC;
}

__attribute__((alias("__imp__sub_82A5DF70"))) PPC_WEAK_FUNC(sub_82A5DF70);
PPC_FUNC_IMPL(__imp__sub_82A5DF70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b8
	ctx.lr = 0x82A5DF78;
	__savegprlr_24(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// li r3,-2
	ctx.r3.s64 = -2;
	// lwz r4,4(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// bl 0x82a3abd0
	ctx.lr = 0x82A5DF8C;
	sub_82A3ABD0(ctx, base);
	// lis r24,-32256
	ctx.r24.s64 = -2113929216;
loc_82A5DF90:
	// lis r11,-5
	ctx.r11.s64 = -327680;
	// lwz r25,0(r26)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// addi r27,r1,80
	ctx.r27.s64 = ctx.r1.s64 + 80;
	// ori r11,r11,27680
	ctx.r11.u64 = ctx.r11.u64 | 27680;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lwz r11,4(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// lwz r10,376(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 376);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a5dfb8
	if (ctx.cr6.eq) goto loc_82A5DFB8;
	// li r27,0
	ctx.r27.s64 = 0;
loc_82A5DFB8:
	// lwz r11,60(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 60);
	// lwz r10,56(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 56);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82a5e0bc
	if (!ctx.cr6.eq) goto loc_82A5E0BC;
	// addi r31,r25,44
	ctx.r31.s64 = ctx.r25.s64 + 44;
loc_82A5DFCC:
	// mfmsr r10
	ctx.r10.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r31
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r31.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stwcx. r11,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82a5dfcc
	if (!ctx.cr0.eq) goto loc_82A5DFCC;
	// addi r28,r26,32
	ctx.r28.s64 = ctx.r26.s64 + 32;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,3
	ctx.r4.s64 = 3;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8308b2b4
	ctx.lr = 0x82A5E004;
	__imp__KeWaitForSingleObject(ctx, base);
loc_82A5E004:
	// mfmsr r10
	ctx.r10.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r31
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r31.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stwcx. r11,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82a5e004
	if (!ctx.cr0.eq) goto loc_82A5E004;
	// b 0x82a5e0b4
	goto loc_82A5E0B4;
loc_82A5E024:
	// lwz r11,2016(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 2016);
	// lwz r30,0(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r29,r30,14944
	ctx.r29.s64 = ctx.r30.s64 + 14944;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8308acb4
	ctx.lr = 0x82A5E038;
	__imp__RtlEnterCriticalSection(ctx, base);
	// lbz r11,10942(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 10942);
	// rlwinm. r11,r11,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a5e05c
	if (ctx.cr0.eq) goto loc_82A5E05C;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82a567f0
	ctx.lr = 0x82A5E04C;
	sub_82A567F0(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r30,14844
	ctx.r4.s64 = ctx.r30.s64 + 14844;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82a567f8
	ctx.lr = 0x82A5E05C;
	sub_82A567F8(ctx, base);
loc_82A5E05C:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8308acc4
	ctx.lr = 0x82A5E064;
	__imp__RtlLeaveCriticalSection(ctx, base);
loc_82A5E064:
	// mfmsr r10
	ctx.r10.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r31
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r31.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stwcx. r11,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82a5e064
	if (!ctx.cr0.eq) goto loc_82A5E064;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,3
	ctx.r4.s64 = 3;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8308b2b4
	ctx.lr = 0x82A5E098;
	__imp__KeWaitForSingleObject(ctx, base);
loc_82A5E098:
	// mfmsr r10
	ctx.r10.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r31
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r31.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stwcx. r11,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82a5e098
	if (!ctx.cr0.eq) goto loc_82A5E098;
loc_82A5E0B4:
	// cmplwi cr6,r3,258
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 258, ctx.xer);
	// beq cr6,0x82a5e024
	if (ctx.cr6.eq) goto loc_82A5E024;
loc_82A5E0BC:
	// addi r3,r26,32
	ctx.r3.s64 = ctx.r26.s64 + 32;
	// bl 0x8308b2a4
	ctx.lr = 0x82A5E0C4;
	__imp__KeResetEvent(ctx, base);
	// lwz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a5e0dc
	if (ctx.cr6.eq) goto loc_82A5E0DC;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82a5dc58
	ctx.lr = 0x82A5E0D8;
	sub_82A5DC58(ctx, base);
	// b 0x82a5df90
	goto loc_82A5DF90;
loc_82A5E0DC:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82d5c508
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A5E0E8"))) PPC_WEAK_FUNC(sub_82A5E0E8);
PPC_FUNC_IMPL(__imp__sub_82A5E0E8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lbz r10,268(r13)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r13.u32 + 268);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mulli r10,r10,80
	ctx.r10.s64 = ctx.r10.s64 * 80;
	// lwz r11,2016(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2016);
	// lis r3,-21846
	ctx.r3.s64 = -1431699456;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// ori r3,r3,43690
	ctx.r3.u64 = ctx.r3.u64 | 43690;
	// addi r31,r11,11324
	ctx.r31.s64 = ctx.r11.s64 + 11324;
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// clrlwi r11,r11,30
	ctx.r11.u64 = ctx.r11.u32 & 0x3;
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r5,r11,r31
	PPC_STORE_U32(ctx.r11.u32 + ctx.r31.u32, ctx.r5.u32);
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,56(r31)
	PPC_STORE_U32(ctx.r31.u32 + 56, ctx.r11.u32);
	// bl 0x82a5cf58
	ctx.lr = 0x82A5E144;
	sub_82A5CF58(ctx, base);
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// bl 0x82a5cf58
	ctx.lr = 0x82A5E14C;
	sub_82A5CF58(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// addi r3,r31,32
	ctx.r3.s64 = ctx.r31.s64 + 32;
	// bl 0x8308b2c4
	ctx.lr = 0x82A5E15C;
	__imp__KeSetEvent(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A5E170"))) PPC_WEAK_FUNC(sub_82A5E170);
PPC_FUNC_IMPL(__imp__sub_82A5E170) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82a50d68
	ctx.lr = 0x82A5E18C;
	sub_82A50D68(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a4f968
	ctx.lr = 0x82A5E194;
	sub_82A4F968(ctx, base);
	// lwz r11,13244(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13244);
	// lwz r8,13240(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13240);
	// addi r30,r31,13368
	ctx.r30.s64 = ctx.r31.s64 + 13368;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r31,13388
	ctx.r10.s64 = ctx.r31.s64 + 13388;
	// li r9,5
	ctx.r9.s64 = 5;
	// stw r8,13232(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13232, ctx.r8.u32);
	// stw r11,13236(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13236, ctx.r11.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_82A5E1BC:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x82a5e1bc
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82A5E1BC;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82a50bc0
	ctx.lr = 0x82A5E1DC;
	sub_82A50BC0(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r31,13248
	ctx.r3.s64 = ctx.r31.s64 + 13248;
	// bl 0x82a50bc0
	ctx.lr = 0x82A5E1E8;
	sub_82A50BC0(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r31,13348
	ctx.r3.s64 = ctx.r31.s64 + 13348;
	// bl 0x82a50bc0
	ctx.lr = 0x82A5E1F4;
	sub_82A50BC0(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r31,13268
	ctx.r3.s64 = ctx.r31.s64 + 13268;
	// bl 0x82a50bc0
	ctx.lr = 0x82A5E200;
	sub_82A50BC0(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r31,13288
	ctx.r3.s64 = ctx.r31.s64 + 13288;
	// bl 0x82a50bc0
	ctx.lr = 0x82A5E20C;
	sub_82A50BC0(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r31,13308
	ctx.r3.s64 = ctx.r31.s64 + 13308;
	// bl 0x82a50bc0
	ctx.lr = 0x82A5E218;
	sub_82A50BC0(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r31,13328
	ctx.r3.s64 = ctx.r31.s64 + 13328;
	// bl 0x82a50bc0
	ctx.lr = 0x82A5E224;
	sub_82A50BC0(ctx, base);
	// lwz r3,8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// addi r10,r3,252
	ctx.r10.s64 = ctx.r3.s64 + 252;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a5e240
	if (!ctx.cr6.gt) goto loc_82A5E240;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82a50968
	ctx.lr = 0x82A5E240;
	sub_82A50968(ctx, base);
loc_82A5E240:
	// lis r11,-32768
	ctx.r11.s64 = -2147483648;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// lwz r11,13188(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13188);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r11.u32);
	// lwz r11,12748(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12748);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r11.u32);
	// lwz r11,12748(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12748);
	// lwz r8,12992(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12992);
	// lwz r7,12996(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12996);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x82a5e2c0
	if (!ctx.cr6.gt) goto loc_82A5E2C0;
	// addi r10,r3,16
	ctx.r10.s64 = ctx.r3.s64 + 16;
	// addi r11,r31,12756
	ctx.r11.s64 = ctx.r31.s64 + 12756;
loc_82A5E278:
	// lwz r6,-4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// subf r6,r8,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r8.s64;
	// stw r6,-4(r10)
	PPC_STORE_U32(ctx.r10.u32 + -4, ctx.r6.u32);
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// subf r6,r7,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r7.s64;
	// stw r6,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r6.u32);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// subf r6,r8,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r8.s64;
	// stw r6,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r6.u32);
	// lwz r6,8(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// subf r6,r7,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r7.s64;
	// stw r6,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r6.u32);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lwz r6,12748(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12748);
	// cmplw cr6,r9,r6
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, ctx.xer);
	// blt cr6,0x82a5e278
	if (ctx.cr6.lt) goto loc_82A5E278;
loc_82A5E2C0:
	// addi r11,r3,252
	ctx.r11.s64 = ctx.r3.s64 + 252;
	// stw r11,13376(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13376, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A5E2E0"))) PPC_WEAK_FUNC(sub_82A5E2E0);
PPC_FUNC_IMPL(__imp__sub_82A5E2E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82A5E2E8;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// lbz r11,10941(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10941);
	// rlwinm. r11,r11,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a5e30c
	if (!ctx.cr0.eq) goto loc_82A5E30C;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// bl 0x82a50388
	ctx.lr = 0x82A5E30C;
	sub_82A50388(ctx, base);
loc_82A5E30C:
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,100
	ctx.r4.s64 = 100;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a500b8
	ctx.lr = 0x82A5E31C;
	sub_82A500B8(ctx, base);
	// li r26,0
	ctx.r26.s64 = 0;
	// mr. r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq 0x82a5e374
	if (ctx.cr0.eq) goto loc_82A5E374;
	// lwz r11,13368(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13368);
	// addi r4,r29,-4
	ctx.r4.s64 = ctx.r29.s64 + -4;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82a5e340
	if (!ctx.cr0.eq) goto loc_82A5E340;
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// b 0x82a5e358
	goto loc_82A5E358;
loc_82A5E340:
	// rlwinm r9,r11,12,20,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 12) & 0xFFF;
	// clrlwi r10,r11,3
	ctx.r10.u64 = ctx.r11.u32 & 0x1FFFFFFF;
	// addi r11,r9,512
	ctx.r11.s64 = ctx.r9.s64 + 512;
	// rlwinm r11,r11,0,19,19
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addis r7,r11,-16384
	ctx.r7.s64 = ctx.r11.s64 + -1073741824;
loc_82A5E358:
	// lis r11,-32090
	ctx.r11.s64 = -2103050240;
	// ori r5,r30,1
	ctx.r5.u64 = ctx.r30.u64 | 1;
	// addi r6,r11,-7960
	ctx.r6.s64 = ctx.r11.s64 + -7960;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a507d0
	ctx.lr = 0x82A5E36C;
	sub_82A507D0(ctx, base);
	// addi r28,r3,4
	ctx.r28.s64 = ctx.r3.s64 + 4;
	// b 0x82a5e378
	goto loc_82A5E378;
loc_82A5E374:
	// lwz r28,84(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82A5E378:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,32
	ctx.r4.s64 = 32;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a500b8
	ctx.lr = 0x82A5E388;
	sub_82A500B8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// bne 0x82a5e398
	if (!ctx.cr0.eq) goto loc_82A5E398;
	// lwz r30,84(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82A5E398:
	// lbz r11,10941(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10941);
	// stw r26,13232(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13232, ctx.r26.u32);
	// stw r26,13236(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13236, ctx.r26.u32);
	// rlwinm. r27,r11,27,31,31
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// beq 0x82a5e3c4
	if (ctx.cr0.eq) goto loc_82A5E3C4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a4f9a0
	ctx.lr = 0x82A5E3B4;
	sub_82A4F9A0(ctx, base);
	// lbz r11,10941(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10941);
	// andi. r11,r11,223
	ctx.r11.u64 = ctx.r11.u64 & 223;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stb r11,10941(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10941, ctx.r11.u8);
	// b 0x82a5e46c
	goto loc_82A5E46C;
loc_82A5E3C4:
	// addi r3,r31,13368
	ctx.r3.s64 = ctx.r31.s64 + 13368;
	// bl 0x82a4fd98
	ctx.lr = 0x82A5E3CC;
	sub_82A4FD98(ctx, base);
	// addi r3,r31,13248
	ctx.r3.s64 = ctx.r31.s64 + 13248;
	// bl 0x82a4fd98
	ctx.lr = 0x82A5E3D4;
	sub_82A4FD98(ctx, base);
	// addi r3,r31,13348
	ctx.r3.s64 = ctx.r31.s64 + 13348;
	// bl 0x82a4fd98
	ctx.lr = 0x82A5E3DC;
	sub_82A4FD98(ctx, base);
	// addi r3,r31,13268
	ctx.r3.s64 = ctx.r31.s64 + 13268;
	// bl 0x82a4fd98
	ctx.lr = 0x82A5E3E4;
	sub_82A4FD98(ctx, base);
	// addi r3,r31,13288
	ctx.r3.s64 = ctx.r31.s64 + 13288;
	// bl 0x82a4fd98
	ctx.lr = 0x82A5E3EC;
	sub_82A4FD98(ctx, base);
	// addi r3,r31,13308
	ctx.r3.s64 = ctx.r31.s64 + 13308;
	// bl 0x82a4fd98
	ctx.lr = 0x82A5E3F4;
	sub_82A4FD98(ctx, base);
	// addi r3,r31,13328
	ctx.r3.s64 = ctx.r31.s64 + 13328;
	// bl 0x82a4fd98
	ctx.lr = 0x82A5E3FC;
	sub_82A4FD98(ctx, base);
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82a5e424
	if (ctx.cr6.eq) goto loc_82A5E424;
	// addi r8,r31,13388
	ctx.r8.s64 = ctx.r31.s64 + 13388;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50630
	ctx.lr = 0x82A5E420;
	sub_82A50630(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
loc_82A5E424:
	// lwz r11,21532(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21532);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a5e43c
	if (!ctx.cr6.eq) goto loc_82A5E43C;
	// lbz r11,10941(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10941);
	// rlwinm. r11,r11,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a5e46c
	if (!ctx.cr0.eq) goto loc_82A5E46C;
loc_82A5E43C:
	// rlwinm r11,r29,12,20,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 12) & 0xFFF;
	// subf r9,r29,r28
	ctx.r9.s64 = ctx.r28.s64 - ctx.r29.s64;
	// addi r11,r11,512
	ctx.r11.s64 = ctx.r11.s64 + 512;
	// clrlwi r10,r29,3
	ctx.r10.u64 = ctx.r29.u32 & 0x1FFFFFFF;
	// rlwinm r11,r11,0,19,19
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000;
	// addi r8,r31,13388
	ctx.r8.s64 = ctx.r31.s64 + 13388;
	// li r7,1
	ctx.r7.s64 = 1;
	// srawi r6,r9,2
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r6.s64 = ctx.r9.s32 >> 2;
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50630
	ctx.lr = 0x82A5E46C;
	sub_82A50630(ctx, base);
loc_82A5E46C:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A5E478"))) PPC_WEAK_FUNC(sub_82A5E478);
PPC_FUNC_IMPL(__imp__sub_82A5E478) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b8
	ctx.lr = 0x82A5E480;
	__savegprlr_24(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r11,22300(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 22300);
	// rlwinm. r11,r11,0,23,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x100;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a5e5e8
	if (!ctx.cr0.eq) goto loc_82A5E5E8;
	// lis r4,-19072
	ctx.r4.s64 = -1249902592;
	// li r3,200
	ctx.r3.s64 = 200;
	// bl 0x8247f370
	ctx.lr = 0x82A5E4A0;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,11804(r30)
	PPC_STORE_U32(ctx.r30.u32 + 11804, ctx.r3.u32);
	// bne 0x82a5e4b4
	if (!ctx.cr0.eq) goto loc_82A5E4B4;
loc_82A5E4AC:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82a5e5ec
	goto loc_82A5E5EC;
loc_82A5E4B4:
	// li r27,0
	ctx.r27.s64 = 0;
	// lwz r11,22300(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 22300);
	// lis r24,256
	ctx.r24.s64 = 16777216;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// stw r27,11012(r30)
	PPC_STORE_U32(ctx.r30.u32 + 11012, ctx.r27.u32);
loc_82A5E4CC:
	// slw r8,r24,r10
	ctx.r8.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r24.u32 << (ctx.r10.u8 & 0x3F));
	// and. r8,r8,r11
	ctx.r8.u64 = ctx.r8.u64 & ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a5e4dc
	if (ctx.cr0.eq) goto loc_82A5E4DC;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
loc_82A5E4DC:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi cr6,r10,6
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 6, ctx.xer);
	// blt cr6,0x82a5e4cc
	if (ctx.cr6.lt) goto loc_82A5E4CC;
	// lwz r10,14896(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 14896);
	// lis r7,-16384
	ctx.r7.s64 = -1073741824;
	// lwz r8,14900(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 14900);
	// rlwinm. r11,r11,0,5,5
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// li r26,-1
	ctx.r26.s64 = -1;
	// stw r9,10984(r30)
	PPC_STORE_U32(ctx.r30.u32 + 10984, ctx.r9.u32);
	// stw r27,10988(r30)
	PPC_STORE_U32(ctx.r30.u32 + 10988, ctx.r27.u32);
	// stw r10,10948(r30)
	PPC_STORE_U32(ctx.r30.u32 + 10948, ctx.r10.u32);
	// stw r7,11028(r30)
	PPC_STORE_U32(ctx.r30.u32 + 11028, ctx.r7.u32);
	// stw r8,10956(r30)
	PPC_STORE_U32(ctx.r30.u32 + 10956, ctx.r8.u32);
	// beq 0x82a5e51c
	if (ctx.cr0.eq) goto loc_82A5E51C;
	// li r26,2
	ctx.r26.s64 = 2;
	// stw r26,11320(r30)
	PPC_STORE_U32(ctx.r30.u32 + 11320, ctx.r26.u32);
loc_82A5E51C:
	// mr r29,r27
	ctx.r29.u64 = ctx.r27.u64;
	// lis r28,32512
	ctx.r28.s64 = 2130706432;
	// addi r31,r30,11364
	ctx.r31.s64 = ctx.r30.s64 + 11364;
	// lis r25,-32256
	ctx.r25.s64 = -2113929216;
loc_82A5E52C:
	// lwz r11,22300(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 22300);
	// slw r10,r24,r29
	ctx.r10.u64 = ctx.r29.u8 & 0x20 ? 0 : (ctx.r24.u32 << (ctx.r29.u8 & 0x3F));
	// and. r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a5e5cc
	if (ctx.cr0.eq) goto loc_82A5E5CC;
	// cmpwi cr6,r26,0
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// bge cr6,0x82a5e54c
	if (!ctx.cr6.lt) goto loc_82A5E54C;
	// mr r26,r29
	ctx.r26.u64 = ctx.r29.u64;
	// stw r29,11320(r30)
	PPC_STORE_U32(ctx.r30.u32 + 11320, ctx.r29.u32);
loc_82A5E54C:
	// addi r11,r30,10944
	ctx.r11.s64 = ctx.r30.s64 + 10944;
	// stw r29,-36(r31)
	PPC_STORE_U32(ctx.r31.u32 + -36, ctx.r29.u32);
	// addis r10,r28,16640
	ctx.r10.s64 = ctx.r28.s64 + 1090519040;
	// stw r28,-12(r31)
	PPC_STORE_U32(ctx.r31.u32 + -12, ctx.r28.u32);
	// addi r6,r31,-40
	ctx.r6.s64 = ctx.r31.s64 + -40;
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// addi r8,r31,12
	ctx.r8.s64 = ctx.r31.s64 + 12;
	// stw r11,-40(r31)
	PPC_STORE_U32(ctx.r31.u32 + -40, ctx.r11.u32);
	// lis r11,-32090
	ctx.r11.s64 = -2103050240;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r5,r11,-8336
	ctx.r5.s64 = ctx.r11.s64 + -8336;
	// stw r10,-16(r31)
	PPC_STORE_U32(ctx.r31.u32 + -16, ctx.r10.u32);
	// lis r4,1
	ctx.r4.s64 = 65536;
	// li r3,0
	ctx.r3.s64 = 0;
	// stb r27,-8(r31)
	PPC_STORE_U8(ctx.r31.u32 + -8, ctx.r27.u8);
	// stw r27,-4(r31)
	PPC_STORE_U32(ctx.r31.u32 + -4, ctx.r27.u32);
	// stw r31,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r31.u32);
	// stw r31,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r31.u32);
	// bl 0x82a3ad58
	ctx.lr = 0x82A5E598;
	sub_82A3AD58(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r3.u32);
	// beq 0x82a5e4ac
	if (ctx.cr0.eq) goto loc_82A5E4AC;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r4,2344(r25)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r25.u32 + 2344);
	// bl 0x8308ae44
	ctx.lr = 0x82A5E5B0;
	__imp__ObReferenceObjectByHandle(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a5e5cc
	if (ctx.cr0.lt) goto loc_82A5E5CC;
	// li r4,17
	ctx.r4.s64 = 17;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x8308ae34
	ctx.lr = 0x82A5E5C4;
	__imp__KeSetBasePriorityThread(ctx, base);
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x8308ae24
	ctx.lr = 0x82A5E5CC;
	__imp__ObDereferenceObject(ctx, base);
loc_82A5E5CC:
	// lis r11,32512
	ctx.r11.s64 = 2130706432;
	// addi r28,r28,128
	ctx.r28.s64 = ctx.r28.s64 + 128;
	// ori r11,r11,768
	ctx.r11.u64 = ctx.r11.u64 | 768;
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r31,r31,80
	ctx.r31.s64 = ctx.r31.s64 + 80;
	// cmplw cr6,r28,r11
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a5e52c
	if (ctx.cr6.lt) goto loc_82A5E52C;
loc_82A5E5E8:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82A5E5EC:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82d5c508
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A5E5F8"))) PPC_WEAK_FUNC(sub_82A5E5F8);
PPC_FUNC_IMPL(__imp__sub_82A5E5F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A5E600;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// lis r4,-20096
	ctx.r4.s64 = -1317011456;
	// lwz r3,11804(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11804);
	// stw r28,10948(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10948, ctx.r28.u32);
	// bl 0x8247f398
	ctx.lr = 0x82A5E61C;
	sub_8247F398(ctx, base);
	// addi r30,r31,11356
	ctx.r30.s64 = ctx.r31.s64 + 11356;
	// li r29,6
	ctx.r29.s64 = 6;
loc_82A5E624:
	// lwz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a5e640
	if (ctx.cr6.eq) goto loc_82A5E640;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8308b2c4
	ctx.lr = 0x82A5E640;
	__imp__KeSetEvent(ctx, base);
loc_82A5E640:
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r30,r30,80
	ctx.r30.s64 = ctx.r30.s64 + 80;
	// bne 0x82a5e624
	if (!ctx.cr0.eq) goto loc_82A5E624;
	// addi r30,r31,11372
	ctx.r30.s64 = ctx.r31.s64 + 11372;
	// li r29,6
	ctx.r29.s64 = 6;
loc_82A5E654:
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a5e670
	if (ctx.cr0.eq) goto loc_82A5E670;
	// li r4,-1
	ctx.r4.s64 = -1;
	// bl 0x82a3a980
	ctx.lr = 0x82A5E668;
	sub_82A3A980(ctx, base);
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82a3a2c0
	ctx.lr = 0x82A5E670;
	sub_82A3A2C0(ctx, base);
loc_82A5E670:
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r30,r30,80
	ctx.r30.s64 = ctx.r30.s64 + 80;
	// bne 0x82a5e654
	if (!ctx.cr0.eq) goto loc_82A5E654;
	// stw r28,10984(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10984, ctx.r28.u32);
	// stw r28,10988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10988, ctx.r28.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A5E690"))) PPC_WEAK_FUNC(sub_82A5E690);
PPC_FUNC_IMPL(__imp__sub_82A5E690) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4bc
	ctx.lr = 0x82A5E698;
	__savegprlr_25(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// lwz r3,48(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a5e6c0
	if (!ctx.cr6.gt) goto loc_82A5E6C0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50d68
	ctx.lr = 0x82A5E6C0;
	sub_82A50D68(ctx, base);
loc_82A5E6C0:
	// li r11,8712
	ctx.r11.s64 = 8712;
	// li r10,6
	ctx.r10.s64 = 6;
	// lis r9,1
	ctx.r9.s64 = 65536;
	// lis r8,2
	ctx.r8.s64 = 131072;
	// ori r9,r9,8192
	ctx.r9.u64 = ctx.r9.u64 | 8192;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// li r7,0
	ctx.r7.s64 = 0;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// stwu r9,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r3.u32 = ea;
	// stwu r8,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r3.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// lwz r10,148(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 148);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// bgt cr6,0x82a5e728
	if (ctx.cr6.gt) goto loc_82A5E728;
	// lwz r10,28(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 28);
	// rlwinm r9,r28,5,0,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 5) & 0xFFFFFFE0;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// li r9,8997
	ctx.r9.s64 = 8997;
	// rlwinm r8,r10,12,20,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0xFFF;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// clrlwi r9,r10,3
	ctx.r9.u64 = ctx.r10.u32 & 0x1FFFFFFF;
	// addi r10,r8,512
	ctx.r10.s64 = ctx.r8.s64 + 512;
	// rlwinm r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// b 0x82a5e7ec
	goto loc_82A5E7EC;
loc_82A5E728:
	// lis r9,-16384
	ctx.r9.s64 = -1073741824;
	// li r8,0
	ctx.r8.s64 = 0;
	// ori r25,r9,24832
	ctx.r25.u64 = ctx.r9.u64 | 24832;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// lis r9,-16384
	ctx.r9.s64 = -1073741824;
	// ori r30,r9,24576
	ctx.r30.u64 = ctx.r9.u64 | 24576;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// beq cr6,0x82a5e7d8
	if (ctx.cr6.eq) goto loc_82A5E7D8;
	// rlwinm r27,r28,5,0,26
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 5) & 0xFFFFFFE0;
	// li r28,0
	ctx.r28.s64 = 0;
	// addi r29,r29,28
	ctx.r29.s64 = ctx.r29.s64 + 28;
	// mr r26,r10
	ctx.r26.u64 = ctx.r10.u64;
loc_82A5E760:
	// li r8,3
	ctx.r8.s64 = 3;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// lis r7,-16383
	ctx.r7.s64 = -1073676288;
	// add r10,r27,r10
	ctx.r10.u64 = ctx.r27.u64 + ctx.r10.u64;
	// ori r7,r7,11521
	ctx.r7.u64 = ctx.r7.u64 | 11521;
	// lis r6,4
	ctx.r6.s64 = 262144;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// clrlwi r9,r10,3
	ctx.r9.u64 = ctx.r10.u32 & 0x1FFFFFFF;
	// ori r6,r6,805
	ctx.r6.u64 = ctx.r6.u64 | 805;
	// slw r5,r8,r28
	ctx.r5.u64 = ctx.r28.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r28.u8 & 0x3F));
	// rlwinm r8,r10,12,20,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0xFFF;
	// addi r10,r8,512
	ctx.r10.s64 = ctx.r8.s64 + 512;
	// stwu r5,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	ctx.r11.u32 = ea;
	// rlwinm r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// stwu r6,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r11.u32 = ea;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// ble cr6,0x82a5e7c8
	if (!ctx.cr6.gt) goto loc_82A5E7C8;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50d68
	ctx.lr = 0x82A5E7C4;
	sub_82A50D68(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82A5E7C8:
	// addic. r26,r26,-1
	ctx.xer.ca = ctx.r26.u32 > 0;
	ctx.r26.s64 = ctx.r26.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// addi r28,r28,2
	ctx.r28.s64 = ctx.r28.s64 + 2;
	// bne 0x82a5e760
	if (!ctx.cr0.eq) goto loc_82A5E760;
loc_82A5E7D8:
	// stwu r30,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r30.u32);
	ctx.r11.u32 = ea;
	// lwz r10,12708(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12708);
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r25,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r25.u32);
	ctx.r11.u32 = ea;
	// lwz r10,12712(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12712);
loc_82A5E7EC:
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lis r10,-16384
	ctx.r10.s64 = -1073741824;
	// li r9,21
	ctx.r9.s64 = 21;
	// ori r10,r10,23296
	ctx.r10.u64 = ctx.r10.u64 | 23296;
	// li r12,1
	ctx.r12.s64 = 1;
	// rldicr r12,r12,57,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 57) & 0xFFFFFFFFFFFFFFFF;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r11,r11,8
	ctx.r11.u64 = ctx.r11.u64 | 8;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// or r11,r11,r12
	ctx.r11.u64 = ctx.r11.u64 | ctx.r12.u64;
	// li r12,1
	ctx.r12.s64 = 1;
	// rldicr r12,r12,56,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// or r11,r11,r12
	ctx.r11.u64 = ctx.r11.u64 | ctx.r12.u64;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82d5c50c
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A5E840"))) PPC_WEAK_FUNC(sub_82A5E840);
PPC_FUNC_IMPL(__imp__sub_82A5E840) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A5E848;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r11,-1
	ctx.r11.s64 = -1;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// clrldi r30,r11,32
	ctx.r30.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// addi r11,r31,1152
	ctx.r11.s64 = ctx.r31.s64 + 1152;
	// li r10,26
	ctx.r10.s64 = 26;
	// std r30,11824(r31)
	PPC_STORE_U64(ctx.r31.u32 + 11824, ctx.r30.u64);
loc_82A5E864:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// rlwinm r9,r9,0,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFC;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// bne 0x82a5e864
	if (!ctx.cr0.eq) goto loc_82A5E864;
	// addi r11,r31,1776
	ctx.r11.s64 = ctx.r31.s64 + 1776;
	// li r10,18
	ctx.r10.s64 = 18;
loc_82A5E884:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// li r8,1
	ctx.r8.s64 = 1;
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// rlwimi r9,r8,0,30,31
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r8.u32, 0) & 0x3) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFFC);
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// bne 0x82a5e884
	if (!ctx.cr0.eq) goto loc_82A5E884;
	// lis r7,8192
	ctx.r7.s64 = 536870912;
	// lwz r11,10564(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10564);
	// lis r6,15
	ctx.r6.s64 = 983040;
	// lwz r8,10568(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10568);
	// ori r7,r7,8192
	ctx.r7.u64 = ctx.r7.u64 | 8192;
	// lis r5,15
	ctx.r5.s64 = 983040;
	// li r9,8
	ctx.r9.s64 = 8;
	// ori r6,r6,61440
	ctx.r6.u64 = ctx.r6.u64 | 61440;
	// ori r5,r5,61696
	ctx.r5.u64 = ctx.r5.u64 | 61696;
	// stw r7,10428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10428, ctx.r7.u32);
	// oris r7,r11,8
	ctx.r7.u64 = ctx.r11.u64 | 524288;
	// lis r11,255
	ctx.r11.s64 = 16711680;
	// stw r9,10604(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10604, ctx.r9.u32);
	// li r10,14
	ctx.r10.s64 = 14;
	// stw r6,10708(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10708, ctx.r6.u32);
	// li r9,4
	ctx.r9.s64 = 4;
	// stw r5,10712(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10712, ctx.r5.u32);
	// ori r6,r11,65535
	ctx.r6.u64 = ctx.r11.u64 | 65535;
	// li r4,16
	ctx.r4.s64 = 16;
	// stw r7,10564(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10564, ctx.r7.u32);
	// oris r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 65536;
	// li r5,2
	ctx.r5.s64 = 2;
	// stw r10,10628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10628, ctx.r10.u32);
	// li r11,-1
	ctx.r11.s64 = -1;
	// stw r9,10580(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10580, ctx.r9.u32);
	// stw r9,10688(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10688, ctx.r9.u32);
	// stw r10,10768(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10768, ctx.r10.u32);
	// stw r4,10772(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10772, ctx.r4.u32);
	// stw r8,10568(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10568, ctx.r8.u32);
	// stw r6,10444(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10444, ctx.r6.u32);
	// stw r5,10824(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10824, ctx.r5.u32);
	// std r11,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r11.u64);
	// std r11,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r11.u64);
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// std r11,24(r31)
	PPC_STORE_U64(ctx.r31.u32 + 24, ctx.r11.u64);
	// std r11,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r11.u64);
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lwz r9,56(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// stw r10,10916(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10916, ctx.r10.u32);
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// ble cr6,0x82a5e950
	if (!ctx.cr6.gt) goto loc_82A5E950;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50d68
	ctx.lr = 0x82A5E94C;
	sub_82A50D68(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82A5E950:
	// li r9,3329
	ctx.r9.s64 = 3329;
	// lis r8,1024
	ctx.r8.s64 = 67108864;
	// lis r10,-16382
	ctx.r10.s64 = -1073610752;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// ori r10,r10,8448
	ctx.r10.u64 = ctx.r10.u64 | 8448;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// li r9,129
	ctx.r9.s64 = 129;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// mr r4,r10
	ctx.r4.u64 = ctx.r10.u64;
	// lis r10,-31980
	ctx.r10.s64 = -2095841280;
	// li r5,130
	ctx.r5.s64 = 130;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// li r3,3650
	ctx.r3.s64 = 3650;
	// li r29,8032
	ctx.r29.s64 = 8032;
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// li r9,15
	ctx.r9.s64 = 15;
	// stwu r6,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r11.u32 = ea;
	// lwz r10,21868(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 21868);
	// oris r10,r10,32769
	ctx.r10.u64 = ctx.r10.u64 | 2147549184;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lis r10,-31980
	ctx.r10.s64 = -2095841280;
	// stwu r4,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r4.u32);
	ctx.r11.u32 = ea;
	// stwu r5,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	ctx.r11.u32 = ea;
	// stwu r30,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r30.u32);
	ctx.r11.u32 = ea;
	// lwz r10,21872(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 21872);
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r3,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r3.u32);
	ctx.r11.u32 = ea;
	// stwu r29,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r29.u32);
	ctx.r11.u32 = ea;
	// lwz r10,22300(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 22300);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// li r10,3205
	ctx.r10.s64 = 3205;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// bne 0x82a5e9dc
	if (!ctx.cr0.eq) goto loc_82A5E9DC;
	// li r9,3
	ctx.r9.s64 = 3;
loc_82A5E9DC:
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// li r10,1404
	ctx.r10.s64 = 1404;
	// lis r9,2989
	ctx.r9.s64 = 195887104;
	// li r8,1403
	ctx.r8.s64 = 1403;
	// ori r9,r9,61453
	ctx.r9.u64 = ctx.r9.u64 | 61453;
	// li r7,0
	ctx.r7.s64 = 0;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A5EA10"))) PPC_WEAK_FUNC(sub_82A5EA10);
PPC_FUNC_IMPL(__imp__sub_82A5EA10) {
	PPC_FUNC_PROLOGUE();
	// lhz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r4.u32 + 0);
	// lhz r9,2(r4)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r4.u32 + 2);
	// rlwinm r10,r11,26,6,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3FFFFFF;
	// rlwinm r11,r9,26,6,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 26) & 0x3FFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// clrlwi r9,r11,16
	ctx.r9.u64 = ctx.r11.u32 & 0xFFFF;
	// cmplwi cr6,r9,1023
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 1023, ctx.xer);
	// ble cr6,0x82a5ea34
	if (!ctx.cr6.gt) goto loc_82A5EA34;
	// li r11,1023
	ctx.r11.s64 = 1023;
loc_82A5EA34:
	// rlwinm r10,r10,1,15,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1FFFE;
	// rlwinm r11,r11,1,15,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0x1FFFE;
	// lhzx r9,r10,r5
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r10.u32 + ctx.r5.u32);
	// rotlwi r9,r9,6
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 6);
	// sth r9,0(r3)
	PPC_STORE_U16(ctx.r3.u32 + 0, ctx.r9.u16);
	// lhzx r11,r11,r5
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + ctx.r5.u32);
	// lhzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r10.u32 + ctx.r5.u32);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// sth r11,2(r3)
	PPC_STORE_U16(ctx.r3.u32 + 2, ctx.r11.u16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A5EA60"))) PPC_WEAK_FUNC(sub_82A5EA60);
PPC_FUNC_IMPL(__imp__sub_82A5EA60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beq cr6,0x82a5eabc
	if (ctx.cr6.eq) goto loc_82A5EABC;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfd f0,16640(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16640);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// bgt cr6,0x82a5ea90
	if (ctx.cr6.gt) goto loc_82A5EA90;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f0,16636(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16636);
	ctx.f0.f64 = double(temp.f32);
	// b 0x82a5ead4
	goto loc_82A5EAD4;
loc_82A5EA90:
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f0,16632(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16632);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// fadds f13,f1,f0
	ctx.f13.f64 = double(float(ctx.f1.f64 + ctx.f0.f64));
	// lfd f2,16624(r11)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16624);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f0,16616(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16616);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// bl 0x82d5bbd0
	ctx.lr = 0x82A5EAB4;
	sub_82D5BBD0(ctx, base);
	// frsp f1,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64));
	// b 0x82a5eb00
	goto loc_82A5EB00;
loc_82A5EABC:
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfd f0,16608(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16608);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// bgt cr6,0x82a5eadc
	if (ctx.cr6.gt) goto loc_82A5EADC;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f0,16600(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16600);
	ctx.f0.f64 = double(temp.f32);
loc_82A5EAD4:
	// fmuls f1,f1,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// b 0x82a5eb00
	goto loc_82A5EB00;
loc_82A5EADC:
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfd f2,16592(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16592);
	// bl 0x82d5bbd0
	ctx.lr = 0x82A5EAE8;
	sub_82D5BBD0(ctx, base);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// frsp f12,f1
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f1.f64));
	// lfs f0,16584(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16584);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f13,16632(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16632);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64));
loc_82A5EB00:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A5EB10"))) PPC_WEAK_FUNC(sub_82A5EB10);
PPC_FUNC_IMPL(__imp__sub_82A5EB10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beq cr6,0x82a5eb6c
	if (ctx.cr6.eq) goto loc_82A5EB6C;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfd f0,16704(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16704);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// bge cr6,0x82a5eb40
	if (!ctx.cr6.lt) goto loc_82A5EB40;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f0,16700(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16700);
	ctx.f0.f64 = double(temp.f32);
	// b 0x82a5eb84
	goto loc_82A5EB84;
loc_82A5EB40:
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f0,16696(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16696);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// fadds f13,f1,f0
	ctx.f13.f64 = double(float(ctx.f1.f64 + ctx.f0.f64));
	// lfd f2,16688(r11)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16688);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f0,16680(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16680);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// bl 0x82d5bbd0
	ctx.lr = 0x82A5EB64;
	sub_82D5BBD0(ctx, base);
	// frsp f1,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64));
	// b 0x82a5ebb0
	goto loc_82A5EBB0;
loc_82A5EB6C:
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfd f0,16672(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16672);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// bge cr6,0x82a5eb8c
	if (!ctx.cr6.lt) goto loc_82A5EB8C;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f0,16664(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16664);
	ctx.f0.f64 = double(temp.f32);
loc_82A5EB84:
	// fmuls f1,f1,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// b 0x82a5ebb0
	goto loc_82A5EBB0;
loc_82A5EB8C:
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfd f2,16656(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16656);
	// bl 0x82d5bbd0
	ctx.lr = 0x82A5EB98;
	sub_82D5BBD0(ctx, base);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// frsp f12,f1
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f1.f64));
	// lfs f0,16648(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16648);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f13,16696(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16696);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64));
loc_82A5EBB0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A5EBC0"))) PPC_WEAK_FUNC(sub_82A5EBC0);
PPC_FUNC_IMPL(__imp__sub_82A5EBC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A5EBC8;
	__savegprlr_28(ctx, base);
	// addi r12,r1,-40
	ctx.r12.s64 = ctx.r1.s64 + -40;
	// bl 0x82d5c578
	ctx.lr = 0x82A5EBD0;
	__savefpr_28(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// cntlzw r11,r30
	ctx.r11.u64 = ctx.r30.u32 == 0 ? 32 : __builtin_clz(ctx.r30.u32);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// xori r31,r11,1
	ctx.r31.u64 = ctx.r11.u64 ^ 1;
	// bl 0x8308b2d4
	ctx.lr = 0x82A5EBF0;
	__imp__VdGetCurrentDisplayGamma(ctx, base);
	// lis r10,-31988
	ctx.r10.s64 = -2096365568;
	// lfs f2,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f2.f64 = double(temp.f32);
	// lis r9,-31980
	ctx.r9.s64 = -2095841280;
	// rlwinm r11,r31,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,-30464
	ctx.r10.s64 = ctx.r10.s64 + -30464;
	// addi r9,r9,21888
	ctx.r9.s64 = ctx.r9.s64 + 21888;
	// rlwinm r8,r31,11,0,20
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 11) & 0xFFFFF800;
	// add r28,r8,r9
	ctx.r28.u64 = ctx.r8.u64 + ctx.r9.u64;
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// lis r9,-31980
	ctx.r9.s64 = -2095841280;
	// addi r9,r9,21880
	ctx.r9.s64 = ctx.r9.s64 + 21880;
	// bne cr6,0x82a5ec34
	if (!ctx.cr6.eq) goto loc_82A5EC34;
	// lfsx f0,r11,r9
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r9.u32);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f2
	ctx.cr6.compare(ctx.f0.f64, ctx.f2.f64);
	// beq cr6,0x82a5ed38
	if (ctx.cr6.eq) goto loc_82A5ED38;
loc_82A5EC34:
	// stfsx f2,r11,r9
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r9.u32, temp.u32);
	// stwx r8,r11,r10
	PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, ctx.r8.u32);
	// lis r7,-32253
	ctx.r7.s64 = -2113732608;
	// lis r9,-32240
	ctx.r9.s64 = -2112880640;
	// lis r10,-32230
	ctx.r10.s64 = -2112225280;
	// lis r11,-32244
	ctx.r11.s64 = -2113142784;
	// li r31,0
	ctx.r31.s64 = 0;
	// lfd f29,-4344(r7)
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r7.u32 + -4344);
	// mr r29,r28
	ctx.r29.u64 = ctx.r28.u64;
	// lfd f30,16712(r9)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r9.u32 + 16712);
	// lfs f31,21344(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 21344);
	ctx.f31.f64 = double(temp.f32);
	// lfs f28,22540(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 22540);
	ctx.f28.f64 = double(temp.f32);
	// b 0x82a5ec70
	goto loc_82A5EC70;
loc_82A5EC68:
	// lfs f2,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f2.f64 = double(temp.f32);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82A5EC70:
	// extsw r11,r31
	ctx.r11.s64 = ctx.r31.s32;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r11.u64);
	// lfd f0,96(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fmuls f1,f0,f28
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// bne cr6,0x82a5eca0
	if (!ctx.cr6.eq) goto loc_82A5ECA0;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82a5ea60
	ctx.lr = 0x82A5EC98;
	sub_82A5EA60(ctx, base);
	// lfs f2,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f2.f64 = double(temp.f32);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82A5ECA0:
	// cmplwi cr6,r8,1
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 1, ctx.xer);
	// beq cr6,0x82a5ecdc
	if (ctx.cr6.eq) goto loc_82A5ECDC;
	// cmplwi cr6,r8,2
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 2, ctx.xer);
	// beq cr6,0x82a5ecd0
	if (ctx.cr6.eq) goto loc_82A5ECD0;
	// cmplwi cr6,r8,3
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 3, ctx.xer);
	// bne cr6,0x82a5ecd0
	if (!ctx.cr6.eq) goto loc_82A5ECD0;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82a5ecc4
	if (!ctx.cr6.eq) goto loc_82A5ECC4;
	// fdivs f2,f31,f2
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = double(float(ctx.f31.f64 / ctx.f2.f64));
loc_82A5ECC4:
	// bl 0x82d5bbd0
	ctx.lr = 0x82A5ECC8;
	sub_82D5BBD0(ctx, base);
	// frsp f1,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64));
	// b 0x82a5ece4
	goto loc_82A5ECE4;
loc_82A5ECD0:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82a5eb10
	ctx.lr = 0x82A5ECD8;
	sub_82A5EB10(ctx, base);
	// b 0x82a5ece4
	goto loc_82A5ECE4;
loc_82A5ECDC:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82a5ea60
	ctx.lr = 0x82A5ECE4;
	sub_82A5EA60(ctx, base);
loc_82A5ECE4:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq cr6,0x82a5ecf4
	if (ctx.cr6.eq) goto loc_82A5ECF4;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82a5ea60
	ctx.lr = 0x82A5ECF4;
	sub_82A5EA60(ctx, base);
loc_82A5ECF4:
	// fmadd f0,f1,f30,f29
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f1.f64 * ctx.f30.f64 + ctx.f29.f64;
	// addi r11,r1,88
	ctx.r11.s64 = ctx.r1.s64 + 88;
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge cr6,0x82a5ed18
	if (!ctx.cr6.lt) goto loc_82A5ED18;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82a5ed24
	goto loc_82A5ED24;
loc_82A5ED18:
	// cmpwi cr6,r11,1023
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1023, ctx.xer);
	// ble cr6,0x82a5ed24
	if (!ctx.cr6.gt) goto loc_82A5ED24;
	// li r11,1023
	ctx.r11.s64 = 1023;
loc_82A5ED24:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// sth r11,0(r29)
	PPC_STORE_U16(ctx.r29.u32 + 0, ctx.r11.u16);
	// addi r29,r29,2
	ctx.r29.s64 = ctx.r29.s64 + 2;
	// cmpwi cr6,r31,1024
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 1024, ctx.xer);
	// blt cr6,0x82a5ec68
	if (ctx.cr6.lt) goto loc_82A5EC68;
loc_82A5ED38:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// addi r12,r1,-40
	ctx.r12.s64 = ctx.r1.s64 + -40;
	// bl 0x82d5c5c4
	ctx.lr = 0x82A5ED48;
	__restfpr_28(ctx, base);
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A5ED50"))) PPC_WEAK_FUNC(sub_82A5ED50);
PPC_FUNC_IMPL(__imp__sub_82A5ED50) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82a5ebc0
	ctx.lr = 0x82A5ED74;
	sub_82A5EBC0(ctx, base);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// addi r11,r31,512
	ctx.r11.s64 = ctx.r31.s64 + 512;
	// subf r8,r31,r30
	ctx.r8.s64 = ctx.r30.s64 - ctx.r31.s64;
	// li r9,256
	ctx.r9.s64 = 256;
loc_82A5ED84:
	// lhz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r10.u32 + 0);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// rlwinm r7,r7,27,5,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFE;
	// lhzx r7,r7,r3
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r7.u32 + ctx.r3.u32);
	// rotlwi r7,r7,6
	ctx.r7.u64 = __builtin_rotateleft32(ctx.r7.u32, 6);
	// sth r7,-512(r11)
	PPC_STORE_U16(ctx.r11.u32 + -512, ctx.r7.u16);
	// lhzx r7,r8,r11
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r8.u32 + ctx.r11.u32);
	// rlwinm r7,r7,27,5,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFE;
	// lhzx r7,r7,r3
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r7.u32 + ctx.r3.u32);
	// rotlwi r7,r7,6
	ctx.r7.u64 = __builtin_rotateleft32(ctx.r7.u32, 6);
	// sth r7,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r7.u16);
	// lhz r7,1024(r10)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r10.u32 + 1024);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// rlwinm r7,r7,27,5,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFE;
	// lhzx r7,r7,r3
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r7.u32 + ctx.r3.u32);
	// rotlwi r7,r7,6
	ctx.r7.u64 = __builtin_rotateleft32(ctx.r7.u32, 6);
	// sth r7,512(r11)
	PPC_STORE_U16(ctx.r11.u32 + 512, ctx.r7.u16);
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// bne 0x82a5ed84
	if (!ctx.cr0.eq) goto loc_82A5ED84;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A5EDE8"))) PPC_WEAK_FUNC(sub_82A5EDE8);
PPC_FUNC_IMPL(__imp__sub_82A5EDE8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82a5ebc0
	ctx.lr = 0x82A5EE0C;
	sub_82A5EBC0(ctx, base);
	// addi r8,r31,512
	ctx.r8.s64 = ctx.r31.s64 + 512;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// subf r31,r31,r30
	ctx.r31.s64 = ctx.r30.s64 - ctx.r31.s64;
	// li r6,128
	ctx.r6.s64 = 128;
loc_82A5EE20:
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// addi r3,r8,-512
	ctx.r3.s64 = ctx.r8.s64 + -512;
	// bl 0x82a5ea10
	ctx.lr = 0x82A5EE2C;
	sub_82A5EA10(ctx, base);
	// add r4,r31,r8
	ctx.r4.u64 = ctx.r31.u64 + ctx.r8.u64;
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// bl 0x82a5ea10
	ctx.lr = 0x82A5EE38;
	sub_82A5EA10(ctx, base);
	// addi r4,r7,1024
	ctx.r4.s64 = ctx.r7.s64 + 1024;
	// addi r3,r8,512
	ctx.r3.s64 = ctx.r8.s64 + 512;
	// bl 0x82a5ea10
	ctx.lr = 0x82A5EE44;
	sub_82A5EA10(ctx, base);
	// addic. r6,r6,-1
	ctx.xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r6.s32, 0, ctx.xer);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x82a5ee20
	if (!ctx.cr0.eq) goto loc_82A5EE20;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A5EE70"))) PPC_WEAK_FUNC(sub_82A5EE70);
PPC_FUNC_IMPL(__imp__sub_82A5EE70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// li r4,2309
	ctx.r4.s64 = 2309;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// bl 0x82a50f88
	ctx.lr = 0x82A5EE94;
	sub_82A50F88(ctx, base);
	// lis r11,1
	ctx.r11.s64 = 65536;
	// li r10,0
	ctx.r10.s64 = 0;
	// ori r8,r11,6433
	ctx.r8.u64 = ctx.r11.u64 | 6433;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,6439
	ctx.r6.s64 = 6439;
	// li r5,7
	ctx.r5.s64 = 7;
	// li r9,0
	ctx.r9.s64 = 0;
	// stwu r8,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r3.u32 = ea;
	// addi r11,r31,1024
	ctx.r11.s64 = ctx.r31.s64 + 1024;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// stwu r7,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r3.u32 = ea;
	// stwu r6,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r3.u32 = ea;
	// stwu r5,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	ctx.r3.u32 = ea;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
loc_82A5EECC:
	// lhz r8,-1024(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + -1024);
	// li r6,6437
	ctx.r6.s64 = 6437;
	// lhz r7,-512(r11)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r11.u32 + -512);
	// lis r4,-16379
	ctx.r4.s64 = -1073414144;
	// lhz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// li r3,6434
	ctx.r3.s64 = 6434;
	// rlwimi r7,r8,10,6,15
	ctx.r7.u64 = (__builtin_rotateleft32(ctx.r8.u32, 10) & 0x3FF0000) | (ctx.r7.u64 & 0xFFFFFFFFFC00FFFF);
	// rlwinm r8,r5,26,6,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 26) & 0x3FFFFFF;
	// rlwinm r7,r7,4,2,21
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0x3FFFFC00;
	// stwu r6,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r10.u32 = ea;
	// ori r4,r4,17664
	ctx.r4.u64 = ctx.r4.u64 | 17664;
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// li r7,7
	ctx.r7.s64 = 7;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// stwu r8,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r10.u32 = ea;
	// cmplwi cr6,r9,256
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 256, ctx.xer);
	// stwu r4,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r4.u32);
	ctx.r10.u32 = ea;
	// stwu r7,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r10.u32 = ea;
	// stwu r6,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r10.u32 = ea;
	// stwu r8,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r10.u32 = ea;
	// stwu r5,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	ctx.r10.u32 = ea;
	// stwu r3,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r3.u32);
	ctx.r10.u32 = ea;
	// stwu r9,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r10.u32 = ea;
	// blt cr6,0x82a5eecc
	if (ctx.cr6.lt) goto loc_82A5EECC;
	// stw r10,48(r30)
	PPC_STORE_U32(ctx.r30.u32 + 48, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A5EF50"))) PPC_WEAK_FUNC(sub_82A5EF50);
PPC_FUNC_IMPL(__imp__sub_82A5EF50) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A5EF58;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// li r4,1413
	ctx.r4.s64 = 1413;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// bl 0x82a50f88
	ctx.lr = 0x82A5EF6C;
	sub_82A50F88(ctx, base);
	// lis r11,1
	ctx.r11.s64 = 65536;
	// li r10,1
	ctx.r10.s64 = 1;
	// ori r8,r11,6433
	ctx.r8.u64 = ctx.r11.u64 | 6433;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,6439
	ctx.r6.s64 = 6439;
	// li r5,7
	ctx.r5.s64 = 7;
	// li r9,0
	ctx.r9.s64 = 0;
	// stwu r8,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r3.u32 = ea;
	// addi r11,r31,514
	ctx.r11.s64 = ctx.r31.s64 + 514;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// stwu r7,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r3.u32 = ea;
	// stwu r6,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r3.u32 = ea;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// stwu r5,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	ctx.r10.u32 = ea;
loc_82A5EFA4:
	// lis r8,2
	ctx.r8.s64 = 131072;
	// lis r7,-16379
	ctx.r7.s64 = -1073414144;
	// ori r8,r8,39204
	ctx.r8.u64 = ctx.r8.u64 | 39204;
	// ori r7,r7,17664
	ctx.r7.u64 = ctx.r7.u64 | 17664;
	// li r6,7
	ctx.r6.s64 = 7;
	// li r5,6436
	ctx.r5.s64 = 6436;
	// li r4,0
	ctx.r4.s64 = 0;
	// stwu r8,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r10.u32 = ea;
	// li r3,-1
	ctx.r3.s64 = -1;
	// lhz r8,-512(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + -512);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lhz r31,-514(r11)
	ctx.r31.u64 = PPC_LOAD_U16(ctx.r11.u32 + -514);
	// rotlwi r8,r8,16
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 16);
	// cmplwi cr6,r9,128
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 128, ctx.xer);
	// or r8,r8,r31
	ctx.r8.u64 = ctx.r8.u64 | ctx.r31.u64;
	// li r31,6434
	ctx.r31.s64 = 6434;
	// stwu r8,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r10.u32 = ea;
	// lhz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// lhz r29,-2(r11)
	ctx.r29.u64 = PPC_LOAD_U16(ctx.r11.u32 + -2);
	// rotlwi r8,r8,16
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 16);
	// or r8,r8,r29
	ctx.r8.u64 = ctx.r8.u64 | ctx.r29.u64;
	// stwu r8,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r10.u32 = ea;
	// lhz r8,512(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + 512);
	// lhz r29,510(r11)
	ctx.r29.u64 = PPC_LOAD_U16(ctx.r11.u32 + 510);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// rotlwi r8,r8,16
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 16);
	// or r8,r8,r29
	ctx.r8.u64 = ctx.r8.u64 | ctx.r29.u64;
	// stwu r8,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r10.u32 = ea;
	// stwu r7,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r10.u32 = ea;
	// stwu r6,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r10.u32 = ea;
	// stwu r5,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	ctx.r10.u32 = ea;
	// stwu r4,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r4.u32);
	ctx.r10.u32 = ea;
	// stwu r3,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r3.u32);
	ctx.r10.u32 = ea;
	// stwu r31,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r31.u32);
	ctx.r10.u32 = ea;
	// stwu r9,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r10.u32 = ea;
	// blt cr6,0x82a5efa4
	if (ctx.cr6.lt) goto loc_82A5EFA4;
	// stw r10,48(r30)
	PPC_STORE_U32(ctx.r30.u32 + 48, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A5F040"))) PPC_WEAK_FUNC(sub_82A5F040);
PPC_FUNC_IMPL(__imp__sub_82A5F040) {
	PPC_FUNC_PROLOGUE();
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r3,1024
	ctx.r11.s64 = ctx.r3.s64 + 1024;
loc_82A5F048:
	// li r9,255
	ctx.r9.s64 = 255;
	// lis r8,3
	ctx.r8.s64 = 196608;
	// divwu r9,r10,r9
	ctx.r9.u32 = ctx.r10.u32 / ctx.r9.u32;
	// ori r8,r8,65280
	ctx.r8.u64 = ctx.r8.u64 | 65280;
	// rlwinm r9,r9,6,10,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 6) & 0x3FFFC0;
	// addi r10,r10,1023
	ctx.r10.s64 = ctx.r10.s64 + 1023;
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// sth r9,-1024(r11)
	PPC_STORE_U16(ctx.r11.u32 + -1024, ctx.r9.u16);
	// sth r9,-512(r11)
	PPC_STORE_U16(ctx.r11.u32 + -512, ctx.r9.u16);
	// sth r9,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r9.u16);
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// blt cr6,0x82a5f048
	if (ctx.cr6.lt) goto loc_82A5F048;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x82a5ed50
	sub_82A5ED50(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A5F090"))) PPC_WEAK_FUNC(sub_82A5F090);
PPC_FUNC_IMPL(__imp__sub_82A5F090) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A5F098"))) PPC_WEAK_FUNC(sub_82A5F098);
PPC_FUNC_IMPL(__imp__sub_82A5F098) {
	PPC_FUNC_PROLOGUE();
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r11,r3,512
	ctx.r11.s64 = ctx.r3.s64 + 512;
	// li r7,127
	ctx.r7.s64 = 127;
loc_82A5F0A4:
	// divwu r10,r9,r7
	ctx.r10.u32 = ctx.r9.u32 / ctx.r7.u32;
	// addis r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 65536;
	// lis r8,127
	ctx.r8.s64 = 8323072;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// ori r6,r8,65408
	ctx.r6.u64 = ctx.r8.u64 | 65408;
	// clrlwi r10,r10,16
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
	// divwu r8,r9,r7
	ctx.r8.u32 = ctx.r9.u32 / ctx.r7.u32;
	// cmplw cr6,r9,r6
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, ctx.xer);
	// subf r8,r10,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r10.s64;
	// clrlwi r8,r8,16
	ctx.r8.u64 = ctx.r8.u32 & 0xFFFF;
	// sth r10,-512(r11)
	PPC_STORE_U16(ctx.r11.u32 + -512, ctx.r10.u16);
	// sth r10,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r10.u16);
	// sth r10,512(r11)
	PPC_STORE_U16(ctx.r11.u32 + 512, ctx.r10.u16);
	// sth r8,-510(r11)
	PPC_STORE_U16(ctx.r11.u32 + -510, ctx.r8.u16);
	// sth r8,2(r11)
	PPC_STORE_U16(ctx.r11.u32 + 2, ctx.r8.u16);
	// sth r8,514(r11)
	PPC_STORE_U16(ctx.r11.u32 + 514, ctx.r8.u16);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// blt cr6,0x82a5f0a4
	if (ctx.cr6.lt) goto loc_82A5F0A4;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x82a5ede8
	sub_82A5EDE8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A5F100"))) PPC_WEAK_FUNC(sub_82A5F100);
PPC_FUNC_IMPL(__imp__sub_82A5F100) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A5F108"))) PPC_WEAK_FUNC(sub_82A5F108);
PPC_FUNC_IMPL(__imp__sub_82A5F108) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4ac
	ctx.lr = 0x82A5F110;
	__savegprlr_21(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r7,16(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r8,r11,8040
	ctx.r8.s64 = ctx.r11.s64 + 8040;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// clrlwi r31,r10,26
	ctx.r31.u64 = ctx.r10.u32 & 0x3F;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r23,r8,1
	ctx.r23.s64 = ctx.r8.s64 + 1;
	// lwz r9,20(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r8,r7,26,28,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 26) & 0xF;
	// rlwinm r7,r31,1,0,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r27,r8,1
	ctx.r27.s64 = ctx.r8.s64 + 1;
	// rlwinm r8,r11,10,23,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 10) & 0x1FF;
	// rlwinm r25,r11,1,31,31
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0x1;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// lbzx r11,r7,r23
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + ctx.r23.u32);
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// rlwinm r22,r10,13,0,18
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 13) & 0xFFFFE000;
	// mullw r11,r11,r8
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r8.s32);
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// addi r5,r1,132
	ctx.r5.s64 = ctx.r1.s64 + 132;
	// addi r4,r1,136
	ctx.r4.s64 = ctx.r1.s64 + 136;
	// rlwinm r26,r9,23,30,31
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 23) & 0x3;
	// rlwinm r24,r9,21,31,31
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 21) & 0x1;
	// rlwinm r23,r10,1,31,31
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	// srawi r22,r22,26
	ctx.xer.ca = (ctx.r22.s32 < 0) & ((ctx.r22.u32 & 0x3FFFFFF) != 0);
	ctx.r22.s64 = ctx.r22.s32 >> 26;
	// rlwinm r21,r11,2,3,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0x1FFFFFFC;
	// bl 0x82a457b0
	ctx.lr = 0x82A5F188;
	sub_82A457B0(ctx, base);
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
	// lwz r5,128(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// lwz r4,132(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// lwz r3,136(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// stw r28,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r28.u32);
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r29.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// stw r21,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r21.u32);
	// stw r22,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r22.u32);
	// stw r23,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r23.u32);
	// bl 0x82a459a0
	ctx.lr = 0x82A5F1C4;
	sub_82A459A0(ctx, base);
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82d5c4fc
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A5F1D0"))) PPC_WEAK_FUNC(sub_82A5F1D0);
PPC_FUNC_IMPL(__imp__sub_82A5F1D0) {
	PPC_FUNC_PROLOGUE();
	// lbz r11,10943(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 10943);
	// ori r11,r11,4
	ctx.r11.u64 = ctx.r11.u64 | 4;
	// stb r11,10943(r3)
	PPC_STORE_U8(ctx.r3.u32 + 10943, ctx.r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A5F1E0"))) PPC_WEAK_FUNC(sub_82A5F1E0);
PPC_FUNC_IMPL(__imp__sub_82A5F1E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.f31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,32767
	ctx.r11.s64 = 2147418112;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// ori r11,r11,65535
	ctx.r11.u64 = ctx.r11.u64 | 65535;
	// cmpldi cr6,r31,0
	ctx.cr6.compare<uint64_t>(ctx.r31.u64, 0, ctx.xer);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// bne cr6,0x82a5f214
	if (!ctx.cr6.eq) goto loc_82A5F214;
	// lfs f1,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// b 0x82a5f234
	goto loc_82A5F234;
loc_82A5F214:
	// bl 0x82d62600
	ctx.lr = 0x82A5F218;
	sub_82D62600(ctx, base);
	// lis r11,-32247
	ctx.r11.s64 = -2113339392;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lfd f0,16912(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16912);
	// fmul f31,f1,f0
	ctx.f31.f64 = ctx.f1.f64 * ctx.f0.f64;
	// bl 0x82d62600
	ctx.lr = 0x82A5F22C;
	sub_82D62600(ctx, base);
	// fdiv f0,f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f31.f64 / ctx.f1.f64;
	// frsp f1,f0
	ctx.f1.f64 = double(float(ctx.f0.f64));
loc_82A5F234:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// lfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A5F250"))) PPC_WEAK_FUNC(sub_82A5F250);
PPC_FUNC_IMPL(__imp__sub_82A5F250) {
	PPC_FUNC_PROLOGUE();
	// cmpdi cr6,r3,0
	ctx.cr6.compare<int64_t>(ctx.r3.s64, 0, ctx.xer);
	// bge cr6,0x82a5f260
	if (!ctx.cr6.lt) goto loc_82A5F260;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82A5F260:
	// cmpdi cr6,r4,0
	ctx.cr6.compare<int64_t>(ctx.r4.s64, 0, ctx.xer);
	// bne cr6,0x82a5f274
	if (!ctx.cr6.eq) goto loc_82A5F274;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,65535
	ctx.r3.u64 = ctx.r3.u64 | 65535;
	// blr 
	return;
loc_82A5F274:
	// cmpd cr6,r3,r4
	ctx.cr6.compare<int64_t>(ctx.r3.s64, ctx.r4.s64, ctx.xer);
	// blt cr6,0x82a5f288
	if (ctx.cr6.lt) goto loc_82A5F288;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,65534
	ctx.r3.u64 = ctx.r3.u64 | 65534;
	// blr 
	return;
loc_82A5F288:
	// lis r11,0
	ctx.r11.s64 = 0;
	// tdllei r4,0
	// ori r11,r11,65534
	ctx.r11.u64 = ctx.r11.u64 | 65534;
	// mulld r10,r3,r11
	ctx.r10.s64 = ctx.r3.s64 * ctx.r11.s64;
	// rotldi r11,r10,1
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u64, 1);
	// divd r10,r10,r4
	ctx.r10.s64 = ctx.r10.s64 / ctx.r4.s64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r3,r10,0
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// andc r11,r4,r11
	ctx.r11.u64 = ctx.r4.u64 & ~ctx.r11.u64;
	// tdlgei r11,-1
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A5F2B8"))) PPC_WEAK_FUNC(sub_82A5F2B8);
PPC_FUNC_IMPL(__imp__sub_82A5F2B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82a5f2e0
	if (!ctx.cr6.eq) goto loc_82A5F2E0;
	// lis r3,-32038
	ctx.r3.s64 = -2099642368;
	// ori r3,r3,23
	ctx.r3.u64 = ctx.r3.u64 | 23;
	// b 0x82a5f34c
	goto loc_82A5F34C;
loc_82A5F2E0:
	// lbz r11,4(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 4);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,107
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 107, ctx.xer);
	// bgt cr6,0x82a5f328
	if (ctx.cr6.gt) goto loc_82A5F328;
	// beq cr6,0x82a5f318
	if (ctx.cr6.eq) goto loc_82A5F318;
	// cmpwi cr6,r11,97
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 97, ctx.xer);
	// beq cr6,0x82a5f318
	if (ctx.cr6.eq) goto loc_82A5F318;
	// cmpwi cr6,r11,98
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 98, ctx.xer);
	// ble cr6,0x82a5f348
	if (!ctx.cr6.gt) goto loc_82A5F348;
	// cmpwi cr6,r11,100
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 100, ctx.xer);
	// ble cr6,0x82a5f318
	if (!ctx.cr6.gt) goto loc_82A5F318;
	// addi r11,r11,-102
	ctx.r11.s64 = ctx.r11.s64 + -102;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// bgt cr6,0x82a5f348
	if (ctx.cr6.gt) goto loc_82A5F348;
loc_82A5F318:
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r4,r11,16720
	ctx.r4.s64 = ctx.r11.s64 + 16720;
	// bl 0x8308b1d4
	ctx.lr = 0x82A5F324;
	__imp__sprintf(ctx, base);
	// b 0x82a5f348
	goto loc_82A5F348;
loc_82A5F328:
	// cmpwi cr6,r11,109
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 109, ctx.xer);
	// beq cr6,0x82a5f33c
	if (ctx.cr6.eq) goto loc_82A5F33C;
	// cmpwi cr6,r11,116
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 116, ctx.xer);
	// bne cr6,0x82a5f348
	if (!ctx.cr6.eq) goto loc_82A5F348;
	// b 0x82a5f318
	goto loc_82A5F318;
loc_82A5F33C:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x82a62728
	ctx.lr = 0x82A5F348;
	sub_82A62728(ctx, base);
loc_82A5F348:
	// lis r3,730
	ctx.r3.s64 = 47841280;
loc_82A5F34C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A5F360"))) PPC_WEAK_FUNC(sub_82A5F360);
PPC_FUNC_IMPL(__imp__sub_82A5F360) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r11,16560(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16560);
	// lwz r10,21664(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 21664);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82a5f390
	if (!ctx.cr6.eq) goto loc_82A5F390;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82a5f3b0
	goto loc_82A5F3B0;
loc_82A5F390:
	// lwz r11,21652(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 21652);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82a5f3c8
	if (ctx.cr6.eq) goto loc_82A5F3C8;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a5f3ac
	if (!ctx.cr6.eq) goto loc_82A5F3AC;
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,21652(r30)
	PPC_STORE_U32(ctx.r30.u32 + 21652, ctx.r11.u32);
loc_82A5F3AC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A5F3B0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82A5F3C8:
	// lwz r11,21656(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 21656);
	// lwz r10,21660(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 21660);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a5f3ac
	if (ctx.cr6.eq) goto loc_82A5F3AC;
	// addi r11,r11,5408
	ctx.r11.s64 = ctx.r11.s64 + 5408;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r30
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// bl 0x82a43f68
	ctx.lr = 0x82A5F3E8;
	sub_82A43F68(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a5f3ac
	if (!ctx.cr0.eq) goto loc_82A5F3AC;
	// lis r11,-31980
	ctx.r11.s64 = -2095841280;
	// li r5,480
	ctx.r5.s64 = 480;
	// addi r31,r11,26068
	ctx.r31.s64 = ctx.r11.s64 + 26068;
	// addi r3,r31,4
	ctx.r3.s64 = ctx.r31.s64 + 4;
	// addi r4,r31,484
	ctx.r4.s64 = ctx.r31.s64 + 484;
	// bl 0x82d5c630
	ctx.lr = 0x82A5F408;
	sub_82D5C630(ctx, base);
	// lwz r11,21656(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 21656);
	// addi r4,r31,484
	ctx.r4.s64 = ctx.r31.s64 + 484;
	// addi r11,r11,5408
	ctx.r11.s64 = ctx.r11.s64 + 5408;
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwzx r3,r10,r30
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r30.u32);
	// stw r11,-4(r31)
	PPC_STORE_U32(ctx.r31.u32 + -4, ctx.r11.u32);
	// bl 0x82a456a8
	ctx.lr = 0x82A5F430;
	sub_82A456A8(ctx, base);
	// lwz r11,21656(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 21656);
	// lwz r10,21648(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 21648);
	// rlwinm r9,r11,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// bne cr6,0x82a5f460
	if (!ctx.cr6.eq) goto loc_82A5F460;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82a5f464
	goto loc_82A5F464;
loc_82A5F460:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
loc_82A5F464:
	// lwz r10,16560(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16560);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,21656(r30)
	PPC_STORE_U32(ctx.r30.u32 + 21656, ctx.r11.u32);
	// stw r10,21664(r30)
	PPC_STORE_U32(ctx.r30.u32 + 21664, ctx.r10.u32);
	// b 0x82a5f3b0
	goto loc_82A5F3B0;
}

__attribute__((alias("__imp__sub_82A5F478"))) PPC_WEAK_FUNC(sub_82A5F478);
PPC_FUNC_IMPL(__imp__sub_82A5F478) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mftb r8
	ctx.r8.u64 = __rdtsc();
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r10,8
	ctx.r10.s64 = 8;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82A5F4A0:
	// std r7,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r7.u64);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// bdnz 0x82a5f4a0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82A5F4A0;
	// lwz r6,21572(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21572);
	// sradi r7,r8,32
	ctx.xer.ca = (ctx.r8.s64 < 0) & ((ctx.r8.u64 & 0xFFFFFFFF) != 0);
	ctx.r7.s64 = ctx.r8.s64 >> 32;
	// stw r8,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r8.u32);
	// lfs f0,21588(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 21588);
	ctx.f0.f64 = double(temp.f32);
	// lwz r8,21668(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21668);
	// stfs f0,112(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lwz r11,21616(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21616);
	// lfs f0,21584(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 21584);
	ctx.f0.f64 = double(temp.f32);
	// lwz r10,10896(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10896);
	// stfs f0,116(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stw r6,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r6.u32);
	// addi r5,r11,-1
	ctx.r5.s64 = ctx.r11.s64 + -1;
	// lwz r6,16560(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16560);
	// stw r8,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r8.u32);
	// lwz r8,136(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// stw r7,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r7.u32);
	// lwz r7,21612(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21612);
	// stw r6,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r6.u32);
	// lwz r6,21608(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21608);
	// stw r7,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r7.u32);
	// clrlwi r7,r11,29
	ctx.r7.u64 = ctx.r11.u32 & 0x7;
	// stw r6,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r6.u32);
	// ori r6,r8,65535
	ctx.r6.u64 = ctx.r8.u64 | 65535;
	// addi r8,r11,1
	ctx.r8.s64 = ctx.r11.s64 + 1;
	// addi r7,r7,16
	ctx.r7.s64 = ctx.r7.s64 + 16;
	// clrlwi r8,r8,29
	ctx.r8.u64 = ctx.r8.u32 & 0x7;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r4,r8,16
	ctx.r4.s64 = ctx.r8.s64 + 16;
	// stw r6,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r6.u32);
	// clrlwi r8,r5,29
	ctx.r8.u64 = ctx.r5.u32 & 0x7;
	// rlwinm r5,r4,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r8,16
	ctx.r8.s64 = ctx.r8.s64 + 16;
	// lwbrx r7,r7,r10
	ctx.r7.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32));
	// rlwinm r4,r8,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwbrx r8,r5,r10
	ctx.r8.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r5.u32 + ctx.r10.u32));
	// cmpldi cr6,r8,0
	ctx.cr6.compare<uint64_t>(ctx.r8.u64, 0, ctx.xer);
	// lwbrx r5,r4,r10
	ctx.r5.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r4.u32 + ctx.r10.u32));
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// mr r7,r5
	ctx.r7.u64 = ctx.r5.u64;
	// beq cr6,0x82a5f598
	if (ctx.cr6.eq) goto loc_82A5F598;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// stw r11,21616(r9)
	PPC_STORE_U32(ctx.r9.u32 + 21616, ctx.r11.u32);
	// beq cr6,0x82a5f598
	if (ctx.cr6.eq) goto loc_82A5F598;
	// cmpldi cr6,r7,0
	ctx.cr6.compare<uint64_t>(ctx.r7.u64, 0, ctx.xer);
	// beq cr6,0x82a5f598
	if (ctx.cr6.eq) goto loc_82A5F598;
	// li r11,1
	ctx.r11.s64 = 1;
	// cmpld cr6,r10,r7
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, ctx.r7.u64, ctx.xer);
	// rldicr r11,r11,32,63
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// bgt cr6,0x82a5f578
	if (ctx.cr6.gt) goto loc_82A5F578;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
loc_82A5F578:
	// cmpld cr6,r8,r10
	ctx.cr6.compare<uint64_t>(ctx.r8.u64, ctx.r10.u64, ctx.xer);
	// bgt cr6,0x82a5f584
	if (ctx.cr6.gt) goto loc_82A5F584;
	// add r8,r8,r11
	ctx.r8.u64 = ctx.r8.u64 + ctx.r11.u64;
loc_82A5F584:
	// subf r4,r7,r8
	ctx.r4.s64 = ctx.r8.s64 - ctx.r7.s64;
	// subf r3,r10,r8
	ctx.r3.s64 = ctx.r8.s64 - ctx.r10.s64;
	// bl 0x82a5f250
	ctx.lr = 0x82A5F590;
	sub_82A5F250(ctx, base);
	// rlwimi r3,r6,0,0,15
	ctx.r3.u64 = (__builtin_rotateleft32(ctx.r6.u32, 0) & 0xFFFF0000) | (ctx.r3.u64 & 0xFFFFFFFF0000FFFF);
	// stw r3,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r3.u32);
loc_82A5F598:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82a5f360
	ctx.lr = 0x82A5F5A0;
	sub_82A5F360(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a5f878
	if (ctx.cr0.eq) goto loc_82A5F878;
	// lis r11,-31980
	ctx.r11.s64 = -2095841280;
	// addi r9,r11,26068
	ctx.r9.s64 = ctx.r11.s64 + 26068;
	// ld r11,4(r9)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r9.u32 + 4);
	// ld r10,484(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 484);
	// subf r7,r11,r10
	ctx.r7.s64 = ctx.r10.s64 - ctx.r11.s64;
	// lwz r11,0(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// ld r10,492(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 492);
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// ld r11,12(r9)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r9.u32 + 12);
	// subf r8,r11,r10
	ctx.r8.s64 = ctx.r10.s64 - ctx.r11.s64;
	// ld r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// subf r3,r11,r8
	ctx.r3.s64 = ctx.r8.s64 - ctx.r11.s64;
	// bl 0x82a5f250
	ctx.lr = 0x82A5F5E8;
	sub_82A5F250(ctx, base);
	// lwz r10,136(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// rlwimi r10,r11,16,0,15
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r10.u64 & 0xFFFFFFFF0000FFFF);
	// stw r10,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r10.u32);
	// bl 0x82a5f250
	ctx.lr = 0x82A5F600;
	sub_82A5F250(ctx, base);
	// ld r11,124(r9)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r9.u32 + 124);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// ld r10,604(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 604);
	// ld r6,132(r9)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r9.u32 + 132);
	// ld r5,612(r9)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r9.u32 + 612);
	// subf r4,r11,r10
	ctx.r4.s64 = ctx.r10.s64 - ctx.r11.s64;
	// subf r3,r6,r5
	ctx.r3.s64 = ctx.r5.s64 - ctx.r6.s64;
	// bl 0x82a5f250
	ctx.lr = 0x82A5F620;
	sub_82A5F250(ctx, base);
	// ld r31,620(r9)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r9.u32 + 620);
	// rlwimi r8,r3,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r3.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// subf r11,r31,r4
	ctx.r11.s64 = ctx.r4.s64 - ctx.r31.s64;
	// subf r11,r5,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r5.s64;
	// ld r5,140(r9)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r9.u32 + 140);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// stw r8,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r8.u32);
	// add r3,r11,r6
	ctx.r3.u64 = ctx.r11.u64 + ctx.r6.u64;
	// bl 0x82a5f250
	ctx.lr = 0x82A5F644;
	sub_82A5F250(ctx, base);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// subf r3,r5,r31
	ctx.r3.s64 = ctx.r31.s64 - ctx.r5.s64;
	// bl 0x82a5f250
	ctx.lr = 0x82A5F650;
	sub_82A5F250(ctx, base);
	// ld r11,444(r9)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r9.u32 + 444);
	// ld r10,924(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 924);
	// rlwimi r8,r3,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r3.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// ld r11,436(r9)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r9.u32 + 436);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// ld r11,916(r9)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r9.u32 + 916);
	// stw r8,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r8.u32);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lis r10,0
	ctx.r10.s64 = 0;
	// cmpdi cr6,r11,0
	ctx.cr6.compare<int64_t>(ctx.r11.s64, 0, ctx.xer);
	// ori r4,r10,65535
	ctx.r4.u64 = ctx.r10.u64 | 65535;
	// lis r10,0
	ctx.r10.s64 = 0;
	// ori r5,r10,43689
	ctx.r5.u64 = ctx.r10.u64 | 43689;
	// bge cr6,0x82a5f694
	if (!ctx.cr6.lt) goto loc_82A5F694;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82a5f6c4
	goto loc_82A5F6C4;
loc_82A5F694:
	// cmpdi cr6,r7,0
	ctx.cr6.compare<int64_t>(ctx.r7.s64, 0, ctx.xer);
	// bne cr6,0x82a5f6a4
	if (!ctx.cr6.eq) goto loc_82A5F6A4;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// b 0x82a5f6c4
	goto loc_82A5F6C4;
loc_82A5F6A4:
	// mulld r10,r11,r5
	ctx.r10.s64 = ctx.r11.s64 * ctx.r5.s64;
	// rotldi r11,r10,1
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u64, 1);
	// divd r10,r10,r7
	ctx.r10.s64 = ctx.r10.s64 / ctx.r7.s64;
	// addi r8,r11,-1
	ctx.r8.s64 = ctx.r11.s64 + -1;
	// rotlwi r11,r10,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// andc r10,r7,r8
	ctx.r10.u64 = ctx.r7.u64 & ~ctx.r8.u64;
	// tdllei r7,0
	// tdlgei r10,-1
loc_82A5F6C4:
	// ld r8,932(r9)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r9.u32 + 932);
	// ld r10,452(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 452);
	// subf r10,r10,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r10.s64;
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// rlwimi r11,r8,0,0,15
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r8.u32, 0) & 0xFFFF0000) | (ctx.r11.u64 & 0xFFFFFFFF0000FFFF);
	// cmpdi cr6,r10,0
	ctx.cr6.compare<int64_t>(ctx.r10.s64, 0, ctx.xer);
	// bge cr6,0x82a5f6e8
	if (!ctx.cr6.lt) goto loc_82A5F6E8;
	// li r8,0
	ctx.r8.s64 = 0;
	// b 0x82a5f718
	goto loc_82A5F718;
loc_82A5F6E8:
	// cmpdi cr6,r7,0
	ctx.cr6.compare<int64_t>(ctx.r7.s64, 0, ctx.xer);
	// bne cr6,0x82a5f6f8
	if (!ctx.cr6.eq) goto loc_82A5F6F8;
	// mr r8,r4
	ctx.r8.u64 = ctx.r4.u64;
	// b 0x82a5f718
	goto loc_82A5F718;
loc_82A5F6F8:
	// mulld r8,r10,r5
	ctx.r8.s64 = ctx.r10.s64 * ctx.r5.s64;
	// rotldi r10,r8,1
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u64, 1);
	// divd r8,r8,r7
	ctx.r8.s64 = ctx.r8.s64 / ctx.r7.s64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// tdllei r7,0
	// andc r10,r7,r10
	ctx.r10.u64 = ctx.r7.u64 & ~ctx.r10.u64;
	// rotlwi r8,r8,0
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 0);
	// tdlgei r10,-1
loc_82A5F718:
	// ld r10,236(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 236);
	// rlwimi r11,r8,16,0,15
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r8.u32, 16) & 0xFFFF0000) | (ctx.r11.u64 & 0xFFFFFFFF0000FFFF);
	// ld r6,716(r9)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r9.u32 + 716);
	// subf r10,r10,r6
	ctx.r10.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r11,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r11.u32);
	// cmpdi cr6,r10,0
	ctx.cr6.compare<int64_t>(ctx.r10.s64, 0, ctx.xer);
	// bge cr6,0x82a5f73c
	if (!ctx.cr6.lt) goto loc_82A5F73C;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82a5f76c
	goto loc_82A5F76C;
loc_82A5F73C:
	// cmpdi cr6,r7,0
	ctx.cr6.compare<int64_t>(ctx.r7.s64, 0, ctx.xer);
	// bne cr6,0x82a5f74c
	if (!ctx.cr6.eq) goto loc_82A5F74C;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// b 0x82a5f76c
	goto loc_82A5F76C;
loc_82A5F74C:
	// mulld r10,r10,r5
	ctx.r10.s64 = ctx.r10.s64 * ctx.r5.s64;
	// rotldi r11,r10,1
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u64, 1);
	// divd r10,r10,r7
	ctx.r10.s64 = ctx.r10.s64 / ctx.r7.s64;
	// addi r8,r11,-1
	ctx.r8.s64 = ctx.r11.s64 + -1;
	// rotlwi r11,r10,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// andc r10,r7,r8
	ctx.r10.u64 = ctx.r7.u64 & ~ctx.r8.u64;
	// tdllei r7,0
	// tdlgei r10,-1
loc_82A5F76C:
	// ld r8,572(r9)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r9.u32 + 572);
	// ld r10,92(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 92);
	// subf r10,r10,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r10.s64;
	// lwz r8,152(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// rlwimi r11,r8,0,0,15
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r8.u32, 0) & 0xFFFF0000) | (ctx.r11.u64 & 0xFFFFFFFF0000FFFF);
	// cmpdi cr6,r10,0
	ctx.cr6.compare<int64_t>(ctx.r10.s64, 0, ctx.xer);
	// bge cr6,0x82a5f790
	if (!ctx.cr6.lt) goto loc_82A5F790;
	// li r8,0
	ctx.r8.s64 = 0;
	// b 0x82a5f7c0
	goto loc_82A5F7C0;
loc_82A5F790:
	// cmpdi cr6,r7,0
	ctx.cr6.compare<int64_t>(ctx.r7.s64, 0, ctx.xer);
	// bne cr6,0x82a5f7a0
	if (!ctx.cr6.eq) goto loc_82A5F7A0;
	// mr r8,r4
	ctx.r8.u64 = ctx.r4.u64;
	// b 0x82a5f7c0
	goto loc_82A5F7C0;
loc_82A5F7A0:
	// mulld r8,r10,r5
	ctx.r8.s64 = ctx.r10.s64 * ctx.r5.s64;
	// rotldi r10,r8,1
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u64, 1);
	// divd r8,r8,r7
	ctx.r8.s64 = ctx.r8.s64 / ctx.r7.s64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// tdllei r7,0
	// andc r10,r7,r10
	ctx.r10.u64 = ctx.r7.u64 & ~ctx.r10.u64;
	// rotlwi r8,r8,0
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 0);
	// tdlgei r10,-1
loc_82A5F7C0:
	// ld r10,460(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 460);
	// rlwimi r11,r8,16,0,15
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r8.u32, 16) & 0xFFFF0000) | (ctx.r11.u64 & 0xFFFFFFFF0000FFFF);
	// ld r6,940(r9)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r9.u32 + 940);
	// subf r10,r10,r6
	ctx.r10.s64 = ctx.r6.s64 - ctx.r10.s64;
	// rldicr r10,r10,1,62
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u64, 1) & 0xFFFFFFFFFFFFFFFE;
	// stw r11,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r11.u32);
	// cmpdi cr6,r10,0
	ctx.cr6.compare<int64_t>(ctx.r10.s64, 0, ctx.xer);
	// bge cr6,0x82a5f7e8
	if (!ctx.cr6.lt) goto loc_82A5F7E8;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82a5f818
	goto loc_82A5F818;
loc_82A5F7E8:
	// cmpdi cr6,r7,0
	ctx.cr6.compare<int64_t>(ctx.r7.s64, 0, ctx.xer);
	// bne cr6,0x82a5f7f8
	if (!ctx.cr6.eq) goto loc_82A5F7F8;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// b 0x82a5f818
	goto loc_82A5F818;
loc_82A5F7F8:
	// mulld r10,r10,r5
	ctx.r10.s64 = ctx.r10.s64 * ctx.r5.s64;
	// rotldi r11,r10,1
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u64, 1);
	// divd r10,r10,r7
	ctx.r10.s64 = ctx.r10.s64 / ctx.r7.s64;
	// addi r8,r11,-1
	ctx.r8.s64 = ctx.r11.s64 + -1;
	// rotlwi r11,r10,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// andc r10,r7,r8
	ctx.r10.u64 = ctx.r7.u64 & ~ctx.r8.u64;
	// tdllei r7,0
	// tdlgei r10,-1
loc_82A5F818:
	// ld r10,468(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 468);
	// ld r9,948(r9)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r9.u32 + 948);
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// lwz r9,156(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// rldicr r10,r10,1,62
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u64, 1) & 0xFFFFFFFFFFFFFFFE;
	// rlwimi r11,r9,0,0,15
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0xFFFF0000) | (ctx.r11.u64 & 0xFFFFFFFF0000FFFF);
	// cmpdi cr6,r10,0
	ctx.cr6.compare<int64_t>(ctx.r10.s64, 0, ctx.xer);
	// bge cr6,0x82a5f840
	if (!ctx.cr6.lt) goto loc_82A5F840;
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x82a5f870
	goto loc_82A5F870;
loc_82A5F840:
	// cmpdi cr6,r7,0
	ctx.cr6.compare<int64_t>(ctx.r7.s64, 0, ctx.xer);
	// bne cr6,0x82a5f850
	if (!ctx.cr6.eq) goto loc_82A5F850;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// b 0x82a5f870
	goto loc_82A5F870;
loc_82A5F850:
	// mulld r9,r10,r5
	ctx.r9.s64 = ctx.r10.s64 * ctx.r5.s64;
	// rotldi r10,r9,1
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u64, 1);
	// divd r9,r9,r7
	ctx.r9.s64 = ctx.r9.s64 / ctx.r7.s64;
	// addi r8,r10,-1
	ctx.r8.s64 = ctx.r10.s64 + -1;
	// rotlwi r10,r9,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// andc r9,r7,r8
	ctx.r9.u64 = ctx.r7.u64 & ~ctx.r8.u64;
	// tdllei r7,0
	// tdlgei r9,-1
loc_82A5F870:
	// rlwimi r11,r10,16,0,15
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r11.u64 & 0xFFFFFFFF0000FFFF);
	// b 0x82a5f898
	goto loc_82A5F898;
loc_82A5F878:
	// lwz r11,136(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// oris r11,r11,65535
	ctx.r11.u64 = ctx.r11.u64 | 4294901760;
	// stw r11,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r11.u32);
	// li r11,-1
	ctx.r11.s64 = -1;
	// stw r11,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r11.u32);
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r11.u32);
	// stw r11,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r11.u32);
	// stw r11,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r11.u32);
loc_82A5F898:
	// lis r3,17459
	ctx.r3.s64 = 1144193024;
	// stw r11,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r11.u32);
	// li r5,64
	ctx.r5.s64 = 64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// ori r3,r3,25703
	ctx.r3.u64 = ctx.r3.u64 | 25703;
	// bl 0x82e99780
	ctx.lr = 0x82A5F8B0;
	sub_82E99780(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A5F8C8"))) PPC_WEAK_FUNC(sub_82A5F8C8);
PPC_FUNC_IMPL(__imp__sub_82A5F8C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stfd f30,-40(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -40, ctx.f30.u64);
	// stfd f31,-32(r1)
	PPC_STORE_U64(ctx.r1.u32 + -32, ctx.f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,32767
	ctx.r11.s64 = 2147418112;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// ori r11,r11,65535
	ctx.r11.u64 = ctx.r11.u64 | 65535;
	// cmplwi cr6,r31,18
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 18, ctx.xer);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// bgt cr6,0x82a5fd6c
	if (ctx.cr6.gt) goto loc_82A5FD6C;
	// lis r12,-32240
	ctx.r12.s64 = -2112880640;
	// addi r12,r12,16728
	ctx.r12.s64 = ctx.r12.s64 + 16728;
	// rlwinm r0,r31,1,0,30
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U16(ctx.r12.u32 + ctx.r0.u32);
	// lis r12,-32090
	ctx.r12.s64 = -2103050240;
	// addi r12,r12,-1756
	ctx.r12.s64 = ctx.r12.s64 + -1756;
	// add r12,r12,r0
	ctx.r12.u64 = ctx.r12.u64 + ctx.r0.u64;
	// mtctr r12
	ctx.ctr.u64 = ctx.r12.u64;
	// nop 
	// bctr 
	switch (ctx.r31.u64) {
	case 0:
		goto loc_82A5F924;
	case 1:
		goto loc_82A5F944;
	case 2:
		goto loc_82A5F970;
	case 3:
		goto loc_82A5F988;
	case 4:
		goto loc_82A5F9EC;
	case 5:
		goto loc_82A5FA08;
	case 6:
		goto loc_82A5FA48;
	case 7:
		goto loc_82A5FAEC;
	case 8:
		goto loc_82A5FB68;
	case 9:
		goto loc_82A5FBB8;
	case 10:
		goto loc_82A5FC18;
	case 11:
		goto loc_82A5FC4C;
	case 12:
		goto loc_82A5FC90;
	case 13:
		goto loc_82A5FCC0;
	case 14:
		goto loc_82A5FCEC;
	case 15:
		goto loc_82A5FD18;
	case 16:
		goto loc_82A5FD4C;
	case 17:
		goto loc_82A5FADC;
	case 18:
		goto loc_82A5FAEC;
	default:
		__builtin_unreachable();
	}
loc_82A5F924:
	// lwz r11,21572(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21572);
	// lfs f0,21588(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 21588);
	ctx.f0.f64 = double(temp.f32);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// b 0x82a5fd70
	goto loc_82A5FD70;
loc_82A5F944:
	// lwz r11,21572(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21572);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a5fd6c
	if (ctx.cr0.eq) goto loc_82A5FD6C;
	// clrldi r11,r11,32
	ctx.r11.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// lfs f0,21584(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 21584);
	ctx.f0.f64 = double(temp.f32);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fdivs f1,f0,f13
	ctx.f1.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// b 0x82a5fd70
	goto loc_82A5FD70;
loc_82A5F970:
	// lwz r11,16560(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16560);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
loc_82A5F97C:
	// fcfid f0,f0
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(ctx.f0.f64));
	// b 0x82a5fd70
	goto loc_82A5FD70;
loc_82A5F988:
	// lwz r11,21608(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21608);
	// lwz r10,21572(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21572);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
loc_82A5F9A0:
	// fcfid f13,f13
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(ctx.f13.s64);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fdivs f13,f0,f13
	ctx.f13.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
loc_82A5F9B4:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f0,-28040(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28040);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f12,21348(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21348);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f13,f12
	ctx.cr6.compare(ctx.f13.f64, ctx.f12.f64);
	// bge cr6,0x82a5f9d8
	if (!ctx.cr6.lt) goto loc_82A5F9D8;
	// fmr f0,f12
	ctx.f0.f64 = ctx.f12.f64;
	// b 0x82a5f9e4
	goto loc_82A5F9E4;
loc_82A5F9D8:
	// fcmpu cr6,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bgt cr6,0x82a5f9e4
	if (ctx.cr6.gt) goto loc_82A5F9E4;
	// fmr f0,f13
	ctx.f0.f64 = ctx.f13.f64;
loc_82A5F9E4:
	// fmr f1,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f0.f64;
	// b 0x82a5fd70
	goto loc_82A5FD70;
loc_82A5F9EC:
	// lwz r11,21612(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21612);
	// lwz r10,21572(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21572);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// b 0x82a5f9a0
	goto loc_82A5F9A0;
loc_82A5FA08:
	// lwz r11,21572(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21572);
	// lwz r10,21612(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21612);
	// lwz r9,21608(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21608);
	// subf r10,r10,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r10.s64;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fdivs f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 / ctx.f0.f64));
	// b 0x82a5f9b4
	goto loc_82A5F9B4;
loc_82A5FA48:
	// lwz r11,21616(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21616);
	// lwz r10,10896(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 10896);
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// addi r7,r11,-1
	ctx.r7.s64 = ctx.r11.s64 + -1;
	// clrlwi r9,r9,29
	ctx.r9.u64 = ctx.r9.u32 & 0x7;
	// clrlwi r8,r11,29
	ctx.r8.u64 = ctx.r11.u32 & 0x7;
	// addi r6,r9,16
	ctx.r6.s64 = ctx.r9.s64 + 16;
	// clrlwi r9,r7,29
	ctx.r9.u64 = ctx.r7.u32 & 0x7;
	// addi r8,r8,16
	ctx.r8.s64 = ctx.r8.s64 + 16;
	// addi r9,r9,16
	ctx.r9.s64 = ctx.r9.s64 + 16;
	// rlwinm r7,r6,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwbrx r31,r7,r10
	ctx.r31.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32));
	// lwbrx r8,r8,r10
	ctx.r8.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32));
	// lwbrx r30,r9,r10
	ctx.r30.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32));
	// cmpldi cr6,r31,0
	ctx.cr6.compare<uint64_t>(ctx.r31.u64, 0, ctx.xer);
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// beq cr6,0x82a5fd6c
	if (ctx.cr6.eq) goto loc_82A5FD6C;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// stw r11,21616(r3)
	PPC_STORE_U32(ctx.r3.u32 + 21616, ctx.r11.u32);
	// beq cr6,0x82a5fd6c
	if (ctx.cr6.eq) goto loc_82A5FD6C;
	// cmpldi cr6,r30,0
	ctx.cr6.compare<uint64_t>(ctx.r30.u64, 0, ctx.xer);
	// beq cr6,0x82a5fd6c
	if (ctx.cr6.eq) goto loc_82A5FD6C;
	// li r11,1
	ctx.r11.s64 = 1;
	// cmpld cr6,r10,r30
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, ctx.r30.u64, ctx.xer);
	// rldicr r11,r11,32,63
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// bgt cr6,0x82a5fac0
	if (ctx.cr6.gt) goto loc_82A5FAC0;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
loc_82A5FAC0:
	// cmpld cr6,r31,r10
	ctx.cr6.compare<uint64_t>(ctx.r31.u64, ctx.r10.u64, ctx.xer);
	// bgt cr6,0x82a5facc
	if (ctx.cr6.gt) goto loc_82A5FACC;
	// add r31,r31,r11
	ctx.r31.u64 = ctx.r31.u64 + ctx.r11.u64;
loc_82A5FACC:
	// subf r3,r10,r31
	ctx.r3.s64 = ctx.r31.s64 - ctx.r10.s64;
	// bl 0x82d62600
	ctx.lr = 0x82A5FAD4;
	sub_82D62600(ctx, base);
	// subf r3,r30,r31
	ctx.r3.s64 = ctx.r31.s64 - ctx.r30.s64;
	// b 0x82a5fba4
	goto loc_82A5FBA4;
loc_82A5FADC:
	// lwz r11,21668(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21668);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// b 0x82a5f97c
	goto loc_82A5F97C;
loc_82A5FAEC:
	// bl 0x82a5f360
	ctx.lr = 0x82A5FAF0;
	sub_82A5F360(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a5fd6c
	if (ctx.cr0.eq) goto loc_82A5FD6C;
	// lis r11,-31980
	ctx.r11.s64 = -2095841280;
	// cmpwi cr6,r31,7
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 7, ctx.xer);
	// addi r11,r11,26068
	ctx.r11.s64 = ctx.r11.s64 + 26068;
	// ld r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 4);
	// ld r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 484);
	// subf r30,r10,r9
	ctx.r30.s64 = ctx.r9.s64 - ctx.r10.s64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// ld r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 12);
	// ld r11,492(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 492);
	// subf r3,r10,r11
	ctx.r3.s64 = ctx.r11.s64 - ctx.r10.s64;
	// bne cr6,0x82a5fb38
	if (!ctx.cr6.eq) goto loc_82A5FB38;
	// ld r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// subf r3,r11,r3
	ctx.r3.s64 = ctx.r3.s64 - ctx.r11.s64;
loc_82A5FB38:
	// cmpldi cr6,r3,0
	ctx.cr6.compare<uint64_t>(ctx.r3.u64, 0, ctx.xer);
	// beq cr6,0x82a5fd6c
	if (ctx.cr6.eq) goto loc_82A5FD6C;
	// bl 0x82d62600
	ctx.lr = 0x82A5FB44;
	sub_82D62600(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = ctx.f1.f64;
	// bl 0x82d62600
	ctx.lr = 0x82A5FB50;
	sub_82D62600(ctx, base);
	// fdiv f0,f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f31.f64 / ctx.f1.f64;
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// frsp f13,f0
	ctx.f13.f64 = double(float(ctx.f0.f64));
	// lfs f0,21344(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21344);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// b 0x82a5f9b4
	goto loc_82A5F9B4;
loc_82A5FB68:
	// bl 0x82a5f360
	ctx.lr = 0x82A5FB6C;
	sub_82A5F360(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a5fd6c
	if (ctx.cr0.eq) goto loc_82A5FD6C;
	// lis r11,-31980
	ctx.r11.s64 = -2095841280;
	// addi r11,r11,26068
	ctx.r11.s64 = ctx.r11.s64 + 26068;
	// ld r10,124(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 124);
	// ld r9,604(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 604);
	// subf r31,r10,r9
	ctx.r31.s64 = ctx.r9.s64 - ctx.r10.s64;
	// cmpldi cr6,r31,0
	ctx.cr6.compare<uint64_t>(ctx.r31.u64, 0, ctx.xer);
	// beq cr6,0x82a5fd6c
	if (ctx.cr6.eq) goto loc_82A5FD6C;
	// ld r10,132(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 132);
	// ld r11,612(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 612);
loc_82A5FB98:
	// subf r3,r10,r11
	ctx.r3.s64 = ctx.r11.s64 - ctx.r10.s64;
	// bl 0x82d62600
	ctx.lr = 0x82A5FBA0;
	sub_82D62600(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82A5FBA4:
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = ctx.f1.f64;
	// bl 0x82d62600
	ctx.lr = 0x82A5FBAC;
	sub_82D62600(ctx, base);
	// fdiv f0,f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f31.f64 / ctx.f1.f64;
loc_82A5FBB0:
	// frsp f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f0.f64));
	// b 0x82a5f9b4
	goto loc_82A5F9B4;
loc_82A5FBB8:
	// bl 0x82a5f360
	ctx.lr = 0x82A5FBBC;
	sub_82A5F360(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a5fd6c
	if (ctx.cr0.eq) goto loc_82A5FD6C;
	// lis r11,-31980
	ctx.r11.s64 = -2095841280;
	// addi r31,r11,26068
	ctx.r31.s64 = ctx.r11.s64 + 26068;
	// ld r11,124(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 124);
	// ld r10,604(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 604);
	// subf r3,r11,r10
	ctx.r3.s64 = ctx.r10.s64 - ctx.r11.s64;
	// cmpldi cr6,r3,0
	ctx.cr6.compare<uint64_t>(ctx.r3.u64, 0, ctx.xer);
	// beq cr6,0x82a5fd6c
	if (ctx.cr6.eq) goto loc_82A5FD6C;
	// bl 0x82d62600
	ctx.lr = 0x82A5FBE4;
	sub_82D62600(ctx, base);
	// ld r11,132(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 132);
	// ld r10,612(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 612);
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = ctx.f1.f64;
	// subf r3,r11,r10
	ctx.r3.s64 = ctx.r10.s64 - ctx.r11.s64;
	// bl 0x82d62600
	ctx.lr = 0x82A5FBF8;
	sub_82D62600(ctx, base);
	// ld r11,140(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 140);
	// ld r10,620(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 620);
	// fsub f30,f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = ctx.f31.f64 - ctx.f1.f64;
	// subf r3,r11,r10
	ctx.r3.s64 = ctx.r10.s64 - ctx.r11.s64;
	// bl 0x82d62600
	ctx.lr = 0x82A5FC0C;
	sub_82D62600(ctx, base);
	// fsub f0,f30,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f30.f64 - ctx.f1.f64;
	// fdiv f0,f0,f31
	ctx.f0.f64 = ctx.f0.f64 / ctx.f31.f64;
	// b 0x82a5fbb0
	goto loc_82A5FBB0;
loc_82A5FC18:
	// bl 0x82a5f360
	ctx.lr = 0x82A5FC1C;
	sub_82A5F360(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a5fd6c
	if (ctx.cr0.eq) goto loc_82A5FD6C;
	// lis r11,-31980
	ctx.r11.s64 = -2095841280;
	// addi r11,r11,26068
	ctx.r11.s64 = ctx.r11.s64 + 26068;
	// ld r10,124(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 124);
	// ld r9,604(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 604);
	// subf r31,r10,r9
	ctx.r31.s64 = ctx.r9.s64 - ctx.r10.s64;
	// cmpldi cr6,r31,0
	ctx.cr6.compare<uint64_t>(ctx.r31.u64, 0, ctx.xer);
	// beq cr6,0x82a5fd6c
	if (ctx.cr6.eq) goto loc_82A5FD6C;
	// ld r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 140);
	// ld r11,620(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 620);
	// b 0x82a5fb98
	goto loc_82A5FB98;
loc_82A5FC4C:
	// bl 0x82a5f360
	ctx.lr = 0x82A5FC50;
	sub_82A5F360(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a5fd6c
	if (ctx.cr0.eq) goto loc_82A5FD6C;
	// lis r11,-31980
	ctx.r11.s64 = -2095841280;
	// addi r11,r11,26068
	ctx.r11.s64 = ctx.r11.s64 + 26068;
	// ld r10,444(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 444);
	// ld r9,924(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 924);
	// subf r8,r10,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r10.s64;
	// ld r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 4);
	// ld r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 484);
	// subf r4,r10,r9
	ctx.r4.s64 = ctx.r9.s64 - ctx.r10.s64;
	// ld r10,436(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 436);
	// ld r11,916(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 916);
	// subf r10,r10,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r10.s64;
	// add r3,r10,r11
	ctx.r3.u64 = ctx.r10.u64 + ctx.r11.u64;
loc_82A5FC88:
	// bl 0x82a5f1e0
	ctx.lr = 0x82A5FC8C;
	sub_82A5F1E0(ctx, base);
	// b 0x82a5fd70
	goto loc_82A5FD70;
loc_82A5FC90:
	// bl 0x82a5f360
	ctx.lr = 0x82A5FC94;
	sub_82A5F360(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a5fd6c
	if (ctx.cr0.eq) goto loc_82A5FD6C;
	// lis r11,-31980
	ctx.r11.s64 = -2095841280;
	// addi r11,r11,26068
	ctx.r11.s64 = ctx.r11.s64 + 26068;
	// ld r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 4);
	// ld r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 484);
	// subf r4,r10,r9
	ctx.r4.s64 = ctx.r9.s64 - ctx.r10.s64;
	// ld r10,452(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 452);
	// ld r11,932(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 932);
loc_82A5FCB8:
	// subf r3,r10,r11
	ctx.r3.s64 = ctx.r11.s64 - ctx.r10.s64;
	// b 0x82a5fc88
	goto loc_82A5FC88;
loc_82A5FCC0:
	// bl 0x82a5f360
	ctx.lr = 0x82A5FCC4;
	sub_82A5F360(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a5fd6c
	if (ctx.cr0.eq) goto loc_82A5FD6C;
	// lis r11,-31980
	ctx.r11.s64 = -2095841280;
	// addi r11,r11,26068
	ctx.r11.s64 = ctx.r11.s64 + 26068;
	// ld r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 4);
	// ld r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 484);
	// subf r4,r10,r9
	ctx.r4.s64 = ctx.r9.s64 - ctx.r10.s64;
	// ld r10,236(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 236);
	// ld r11,716(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 716);
	// b 0x82a5fcb8
	goto loc_82A5FCB8;
loc_82A5FCEC:
	// bl 0x82a5f360
	ctx.lr = 0x82A5FCF0;
	sub_82A5F360(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a5fd6c
	if (ctx.cr0.eq) goto loc_82A5FD6C;
	// lis r11,-31980
	ctx.r11.s64 = -2095841280;
	// addi r11,r11,26068
	ctx.r11.s64 = ctx.r11.s64 + 26068;
	// ld r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 4);
	// ld r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 484);
	// subf r4,r10,r9
	ctx.r4.s64 = ctx.r9.s64 - ctx.r10.s64;
	// ld r10,92(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 92);
	// ld r11,572(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 572);
	// b 0x82a5fcb8
	goto loc_82A5FCB8;
loc_82A5FD18:
	// bl 0x82a5f360
	ctx.lr = 0x82A5FD1C;
	sub_82A5F360(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a5fd6c
	if (ctx.cr0.eq) goto loc_82A5FD6C;
	// lis r11,-31980
	ctx.r11.s64 = -2095841280;
	// addi r11,r11,26068
	ctx.r11.s64 = ctx.r11.s64 + 26068;
	// ld r10,460(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 460);
	// ld r9,940(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 940);
loc_82A5FD34:
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// ld r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 4);
	// ld r11,484(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 484);
	// rldicr r3,r9,1,62
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r9.u64, 1) & 0xFFFFFFFFFFFFFFFE;
	// subf r4,r10,r11
	ctx.r4.s64 = ctx.r11.s64 - ctx.r10.s64;
	// b 0x82a5fc88
	goto loc_82A5FC88;
loc_82A5FD4C:
	// bl 0x82a5f360
	ctx.lr = 0x82A5FD50;
	sub_82A5F360(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a5fd6c
	if (ctx.cr0.eq) goto loc_82A5FD6C;
	// lis r11,-31980
	ctx.r11.s64 = -2095841280;
	// addi r11,r11,26068
	ctx.r11.s64 = ctx.r11.s64 + 26068;
	// ld r10,468(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 468);
	// ld r9,948(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 948);
	// b 0x82a5fd34
	goto loc_82A5FD34;
loc_82A5FD6C:
	// lfs f1,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
loc_82A5FD70:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// lfd f30,-40(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// lfd f31,-32(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A5FD90"))) PPC_WEAK_FUNC(sub_82A5FD90);
PPC_FUNC_IMPL(__imp__sub_82A5FD90) {
	PPC_FUNC_PROLOGUE();
	// b 0x82a50ff0
	sub_82A50FF0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A5FD98"))) PPC_WEAK_FUNC(sub_82A5FD98);
PPC_FUNC_IMPL(__imp__sub_82A5FD98) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82e99810
	ctx.lr = 0x82A5FDB4;
	sub_82E99810(ctx, base);
	// rlwinm. r11,r3,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a5fdc4
	if (ctx.cr0.eq) goto loc_82A5FDC4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a5f478
	ctx.lr = 0x82A5FDC4;
	sub_82A5F478(ctx, base);
loc_82A5FDC4:
	// li r5,40
	ctx.r5.s64 = 40;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82d5cb60
	ctx.lr = 0x82A5FDD4;
	sub_82D5CB60(ctx, base);
	// lis r11,-32090
	ctx.r11.s64 = -2103050240;
	// lbz r10,10943(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10943);
	// lis r30,-32256
	ctx.r30.s64 = -2113929216;
	// lwz r9,16560(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16560);
	// addi r11,r11,-624
	ctx.r11.s64 = ctx.r11.s64 + -624;
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// li r9,6534
	ctx.r9.s64 = 6534;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r11.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r10,10943(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10943, ctx.r10.u8);
	// lwz r10,2332(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2332);
	// stw r3,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r3.u32);
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a5fe3c
	if (ctx.cr0.eq) goto loc_82A5FE3C;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,82
	ctx.r3.s64 = 82;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A5FE38;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r10,2332(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2332);
loc_82A5FE3C:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82a5fe94
	if (!ctx.cr6.eq) goto loc_82A5FE94;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2020(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2020);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82a5fe74
	if (ctx.cr6.eq) goto loc_82A5FE74;
	// rotlwi r11,r9,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a5fe94
	if (ctx.cr0.eq) goto loc_82A5FE94;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a5fe94
	if (ctx.cr0.eq) goto loc_82A5FE94;
	// b 0x82a5fe84
	goto loc_82A5FE84;
loc_82A5FE74:
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a5fe94
	if (ctx.cr0.eq) goto loc_82A5FE94;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
loc_82A5FE84:
	// lwz r4,16560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16560);
	// li r3,46
	ctx.r3.s64 = 46;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A5FE94;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A5FE94:
	// lbz r11,10943(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10943);
	// andi. r11,r11,253
	ctx.r11.u64 = ctx.r11.u64 & 253;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stb r11,10943(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10943, ctx.r11.u8);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A5FEB8"))) PPC_WEAK_FUNC(sub_82A5FEB8);
PPC_FUNC_IMPL(__imp__sub_82A5FEB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A5FEC0;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2016(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2016);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a60070
	if (ctx.cr6.eq) goto loc_82A60070;
	// rotlwi r31,r10,0
	ctx.r31.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a60070
	if (ctx.cr6.eq) goto loc_82A60070;
	// ld r11,10880(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 10880);
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82a60070
	if (ctx.cr6.eq) goto loc_82A60070;
	// cmplwi cr6,r3,34
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 34, ctx.xer);
	// bgt cr6,0x82a5ff94
	if (ctx.cr6.gt) goto loc_82A5FF94;
	// beq cr6,0x82a5ff8c
	if (ctx.cr6.eq) goto loc_82A5FF8C;
	// cmplwi cr6,r3,1
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 1, ctx.xer);
	// blt cr6,0x82a5ff7c
	if (ctx.cr6.lt) goto loc_82A5FF7C;
	// beq cr6,0x82a5ff7c
	if (ctx.cr6.eq) goto loc_82A5FF7C;
	// cmplwi cr6,r3,16
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 16, ctx.xer);
	// beq cr6,0x82a5ff50
	if (ctx.cr6.eq) goto loc_82A5FF50;
	// cmplwi cr6,r3,17
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 17, ctx.xer);
	// bne cr6,0x82a60070
	if (!ctx.cr6.eq) goto loc_82A60070;
	// li r9,1
	ctx.r9.s64 = 1;
	// lis r11,-31980
	ctx.r11.s64 = -2095841280;
	// cmplwi cr6,r4,6
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 6, ctx.xer);
	// lwz r10,27072(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 27072);
	// slw r8,r9,r4
	ctx.r8.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r4.u8 & 0x3F));
	// or r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 | ctx.r10.u64;
	// stw r10,27072(r11)
	PPC_STORE_U32(ctx.r11.u32 + 27072, ctx.r10.u32);
	// bne cr6,0x82a60070
	if (!ctx.cr6.eq) goto loc_82A60070;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r9,21624(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21624, ctx.r9.u32);
	// stw r11,21616(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21616, ctx.r11.u32);
	// stw r11,21620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21620, ctx.r11.u32);
	// b 0x82a60070
	goto loc_82A60070;
loc_82A5FF50:
	// li r11,1
	ctx.r11.s64 = 1;
	// cmplwi cr6,r4,6
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 6, ctx.xer);
	// slw r9,r11,r4
	ctx.r9.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r11.u32 << (ctx.r4.u8 & 0x3F));
	// lis r11,-31980
	ctx.r11.s64 = -2095841280;
	// lwz r10,27072(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 27072);
	// andc r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r9.u64;
	// stw r10,27072(r11)
	PPC_STORE_U32(ctx.r11.u32 + 27072, ctx.r10.u32);
	// bne cr6,0x82a60070
	if (!ctx.cr6.eq) goto loc_82A60070;
	// li r11,0
	ctx.r11.s64 = 0;
loc_82A5FF74:
	// stw r11,21624(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21624, ctx.r11.u32);
	// b 0x82a60070
	goto loc_82A60070;
loc_82A5FF7C:
	// li r11,0
	ctx.r11.s64 = 0;
	// lis r10,-31980
	ctx.r10.s64 = -2095841280;
	// stw r11,27072(r10)
	PPC_STORE_U32(ctx.r10.u32 + 27072, ctx.r11.u32);
	// b 0x82a5ff74
	goto loc_82A5FF74;
loc_82A5FF8C:
	// stw r4,21676(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21676, ctx.r4.u32);
	// b 0x82a60070
	goto loc_82A60070;
loc_82A5FF94:
	// cmplwi cr6,r3,224
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 224, ctx.xer);
	// beq cr6,0x82a60038
	if (ctx.cr6.eq) goto loc_82A60038;
	// cmplwi cr6,r3,225
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 225, ctx.xer);
	// beq cr6,0x82a60038
	if (ctx.cr6.eq) goto loc_82A60038;
	// cmplwi cr6,r3,226
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 226, ctx.xer);
	// beq cr6,0x82a60038
	if (ctx.cr6.eq) goto loc_82A60038;
	// cmplwi cr6,r3,255
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 255, ctx.xer);
	// bne cr6,0x82a60070
	if (!ctx.cr6.eq) goto loc_82A60070;
	// lis r28,-31980
	ctx.r28.s64 = -2095841280;
	// lwz r11,27072(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 27072);
	// clrlwi. r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a5fff4
	if (ctx.cr0.eq) goto loc_82A5FFF4;
	// lwz r11,21572(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21572);
	// lfs f0,21588(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 21588);
	ctx.f0.f64 = double(temp.f32);
	// lis r3,2
	ctx.r3.s64 = 131072;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f0,-18864(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18864);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// bl 0x82e99718
	ctx.lr = 0x82A5FFF4;
	sub_82E99718(ctx, base);
loc_82A5FFF4:
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// li r29,17
	ctx.r29.s64 = 17;
	// addi r11,r11,-30448
	ctx.r11.s64 = ctx.r11.s64 + -30448;
	// addi r30,r11,8
	ctx.r30.s64 = ctx.r11.s64 + 8;
loc_82A60004:
	// lwz r11,-8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + -8);
	// lwz r10,27072(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 27072);
	// and. r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 & ctx.r10.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a60028
	if (ctx.cr0.eq) goto loc_82A60028;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82a5f8c8
	ctx.lr = 0x82A60020;
	sub_82A5F8C8(ctx, base);
	// lwz r3,-4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + -4);
	// bl 0x82e99718
	ctx.lr = 0x82A60028;
	sub_82E99718(ctx, base);
loc_82A60028:
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r30,r30,12
	ctx.r30.s64 = ctx.r30.s64 + 12;
	// bne 0x82a60004
	if (!ctx.cr0.eq) goto loc_82A60004;
	// b 0x82a60070
	goto loc_82A60070;
loc_82A60038:
	// lwz r11,21532(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21532);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a60070
	if (ctx.cr6.eq) goto loc_82A60070;
	// bl 0x82a3a970
	ctx.lr = 0x82A60048;
	sub_82A3A970(ctx, base);
	// lwz r11,10888(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10888);
	// cmplw cr6,r11,r3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r3.u32, ctx.xer);
	// bne cr6,0x82a60070
	if (!ctx.cr6.eq) goto loc_82A60070;
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// lwz r3,48(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a6006c
	if (!ctx.cr6.gt) goto loc_82A6006C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50d68
	ctx.lr = 0x82A6006C;
	sub_82A50D68(ctx, base);
loc_82A6006C:
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
loc_82A60070:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A60078"))) PPC_WEAK_FUNC(sub_82A60078);
PPC_FUNC_IMPL(__imp__sub_82A60078) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lis r31,-32256
	ctx.r31.s64 = -2113929216;
	// lwz r11,2020(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2020);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a600c4
	if (ctx.cr6.eq) goto loc_82A600C4;
	// rotlwi r11,r10,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a600ec
	if (ctx.cr0.eq) goto loc_82A600EC;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a600ec
	if (ctx.cr0.eq) goto loc_82A600EC;
	// b 0x82a600d8
	goto loc_82A600D8;
loc_82A600C4:
	// lwz r11,2332(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a600ec
	if (ctx.cr0.eq) goto loc_82A600EC;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
loc_82A600D8:
	// lis r10,-32090
	ctx.r10.s64 = -2103050240;
	// li r3,28
	ctx.r3.s64 = 28;
	// addi r4,r10,-3400
	ctx.r4.s64 = ctx.r10.s64 + -3400;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A600EC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A600EC:
	// lis r11,-32090
	ctx.r11.s64 = -2103050240;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r30.u32);
	// addi r11,r11,-3632
	ctx.r11.s64 = ctx.r11.s64 + -3632;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,2332(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a60120
	if (ctx.cr0.eq) goto loc_82A60120;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,66
	ctx.r3.s64 = 66;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A60120;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A60120:
	// lwz r11,2332(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a60148
	if (ctx.cr0.eq) goto loc_82A60148;
	// lis r10,-32090
	ctx.r10.s64 = -2103050240;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// li r3,89
	ctx.r3.s64 = 89;
	// addi r4,r10,-328
	ctx.r4.s64 = ctx.r10.s64 + -328;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A60148;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A60148:
	// li r11,0
	ctx.r11.s64 = 0;
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r11,21616(r30)
	PPC_STORE_U32(ctx.r30.u32 + 21616, ctx.r11.u32);
	// stw r11,21620(r30)
	PPC_STORE_U32(ctx.r30.u32 + 21620, ctx.r11.u32);
	// stw r10,21624(r30)
	PPC_STORE_U32(ctx.r30.u32 + 21624, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A60178"))) PPC_WEAK_FUNC(sub_82A60178);
PPC_FUNC_IMPL(__imp__sub_82A60178) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32256
	ctx.r31.s64 = -2113929216;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r11,2332(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2332);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq 0x82a601bc
	if (ctx.cr0.eq) goto loc_82A601BC;
	// lwz r11,24(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,28
	ctx.r3.s64 = 28;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A601B8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,2332(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2332);
loc_82A601BC:
	// lis r10,-32090
	ctx.r10.s64 = -2103050240;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r30.u32);
	// addi r10,r10,-3632
	ctx.r10.s64 = ctx.r10.s64 + -3632;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq 0x82a601f0
	if (ctx.cr0.eq) goto loc_82A601F0;
	// lwz r11,24(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,65
	ctx.r3.s64 = 65;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A601EC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,2332(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2332);
loc_82A601F0:
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a60214
	if (ctx.cr0.eq) goto loc_82A60214;
	// lis r10,-32090
	ctx.r10.s64 = -2103050240;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// li r3,90
	ctx.r3.s64 = 90;
	// addi r4,r10,-328
	ctx.r4.s64 = ctx.r10.s64 + -328;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A60214;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A60214:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A60230"))) PPC_WEAK_FUNC(sub_82A60230);
PPC_FUNC_IMPL(__imp__sub_82A60230) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a60264
	if (!ctx.cr6.gt) goto loc_82A60264;
	// bl 0x82a50d68
	ctx.lr = 0x82A60260;
	sub_82A50D68(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82A60264:
	// lis r10,-16382
	ctx.r10.s64 = -1073610752;
	// ori r9,r10,22528
	ctx.r9.u64 = ctx.r10.u64 | 22528;
	// lis r10,-32768
	ctx.r10.s64 = -2147483648;
	// ori r8,r10,3
	ctx.r8.u64 = ctx.r10.u64 | 3;
	// rlwinm r10,r30,12,20,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 12) & 0xFFF;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// clrlwi r9,r30,3
	ctx.r9.u64 = ctx.r30.u32 & 0x1FFFFFFF;
	// addi r10,r10,512
	ctx.r10.s64 = ctx.r10.s64 + 512;
	// rlwinm r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// lis r9,-8531
	ctx.r9.s64 = -559087616;
	// ori r9,r9,48879
	ctx.r9.u64 = ctx.r9.u64 | 48879;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A602C0"))) PPC_WEAK_FUNC(sub_82A602C0);
PPC_FUNC_IMPL(__imp__sub_82A602C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r4,70
	ctx.r4.s64 = 70;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82a50f88
	ctx.lr = 0x82A602DC;
	sub_82A50F88(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a602e8
	if (ctx.cr0.eq) goto loc_82A602E8;
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
loc_82A602E8:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A60300"))) PPC_WEAK_FUNC(sub_82A60300);
PPC_FUNC_IMPL(__imp__sub_82A60300) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,21652(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21652);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// bne cr6,0x82a603c4
	if (!ctx.cr6.eq) goto loc_82A603C4;
	// lwz r11,21660(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21660);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// bne cr6,0x82a60338
	if (!ctx.cr6.eq) goto loc_82A60338;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82a6033c
	goto loc_82A6033C;
loc_82A60338:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
loc_82A6033C:
	// lwz r10,21656(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21656);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a603c4
	if (ctx.cr6.eq) goto loc_82A603C4;
	// rlwinm r30,r11,1,0,30
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// bne cr6,0x82a60358
	if (!ctx.cr6.eq) goto loc_82A60358;
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
loc_82A60358:
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a60374
	if (!ctx.cr6.gt) goto loc_82A60374;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50d68
	ctx.lr = 0x82A60370;
	sub_82A50D68(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82A60374:
	// lis r10,-16382
	ctx.r10.s64 = -1073610752;
	// lis r9,-32768
	ctx.r9.s64 = -2147483648;
	// ori r10,r10,22528
	ctx.r10.u64 = ctx.r10.u64 | 22528;
	// ori r8,r9,3
	ctx.r8.u64 = ctx.r9.u64 | 3;
	// rlwinm r9,r30,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-8531
	ctx.r7.s64 = -559087616;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// ori r7,r7,48879
	ctx.r7.u64 = ctx.r7.u64 | 48879;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// lwz r10,21648(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21648);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r8,r10,12,20,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0xFFF;
	// clrlwi r9,r10,3
	ctx.r9.u64 = ctx.r10.u32 & 0x1FFFFFFF;
	// addi r10,r8,512
	ctx.r10.s64 = ctx.r8.s64 + 512;
	// rlwinm r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
loc_82A603C4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A603E0"))) PPC_WEAK_FUNC(sub_82A603E0);
PPC_FUNC_IMPL(__imp__sub_82A603E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A603E8;
	__savegprlr_28(ctx, base);
	// stwu r1,-384(r1)
	ea = -384 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// lwz r9,16720(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16720);
	// rlwinm. r11,r9,0,21,21
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x400;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a605b0
	if (ctx.cr0.eq) goto loc_82A605B0;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2332(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a6041c
	if (ctx.cr0.eq) goto loc_82A6041C;
	// lwz r11,32(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// b 0x82a60420
	goto loc_82A60420;
loc_82A6041C:
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
loc_82A60420:
	// lwz r11,16(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A6042C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r3,16724(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16724, ctx.r3.u32);
loc_82A60430:
	// stw r28,16720(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16720, ctx.r28.u32);
loc_82A60434:
	// lwz r11,21580(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21580);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// lwz r11,21576(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21576);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// mftb r11
	ctx.r11.u64 = __rdtsc();
	// ld r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// cmpdi cr6,r10,0
	ctx.cr6.compare<int64_t>(ctx.r10.s64, 0, ctx.xer);
	// beq cr6,0x82a60468
	if (ctx.cr6.eq) goto loc_82A60468;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// stw r11,21572(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21572, ctx.r11.u32);
loc_82A60468:
	// ld r9,21592(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 21592);
	// ld r7,21600(r31)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r31.u32 + 21600);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,21652(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21652);
	// std r28,21592(r31)
	PPC_STORE_U64(ctx.r31.u32 + 21592, ctx.r28.u64);
	// stw r9,21608(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21608, ctx.r9.u32);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// stw r10,21580(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21580, ctx.r10.u32);
	// stw r8,21576(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21576, ctx.r8.u32);
	// stw r7,21612(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21612, ctx.r7.u32);
	// std r28,21600(r31)
	PPC_STORE_U64(ctx.r31.u32 + 21600, ctx.r28.u64);
	// bne cr6,0x82a60614
	if (!ctx.cr6.eq) goto loc_82A60614;
	// li r5,240
	ctx.r5.s64 = 240;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82d5cb60
	ctx.lr = 0x82A604AC;
	sub_82D5CB60(ctx, base);
	// lbz r11,10942(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10942);
	// stw r28,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r28.u32);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = ctx.r11.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
	// li r11,8
	ctx.r11.s64 = 8;
	// stw r11,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r11.u32);
	// li r11,13
	ctx.r11.s64 = 13;
	// stw r11,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r11.u32);
	// li r11,37
	ctx.r11.s64 = 37;
	// stw r11,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r11.u32);
	// li r11,19
	ctx.r11.s64 = 19;
	// stw r11,312(r1)
	PPC_STORE_U32(ctx.r1.u32 + 312, ctx.r11.u32);
	// stw r11,316(r1)
	PPC_STORE_U32(ctx.r1.u32 + 316, ctx.r11.u32);
	// li r11,6
	ctx.r11.s64 = 6;
	// stw r11,320(r1)
	PPC_STORE_U32(ctx.r1.u32 + 320, ctx.r11.u32);
	// li r11,25
	ctx.r11.s64 = 25;
	// stw r11,324(r1)
	PPC_STORE_U32(ctx.r1.u32 + 324, ctx.r11.u32);
	// li r11,26
	ctx.r11.s64 = 26;
	// stw r11,328(r1)
	PPC_STORE_U32(ctx.r1.u32 + 328, ctx.r11.u32);
	// li r11,200
	ctx.r11.s64 = 200;
	// stw r11,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r11.u32);
	// li r11,30
	ctx.r11.s64 = 30;
	// stw r11,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r11.u32);
	// bne 0x82a6051c
	if (!ctx.cr0.eq) goto loc_82A6051C;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a437e0
	ctx.lr = 0x82A6051C;
	sub_82A437E0(ctx, base);
loc_82A6051C:
	// lwz r11,21628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21628);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a60538
	if (!ctx.cr6.eq) goto loc_82A60538;
	// lis r4,-23680
	ctx.r4.s64 = -1551892480;
	// li r3,1952
	ctx.r3.s64 = 1952;
	// bl 0x8247f370
	ctx.lr = 0x82A60534;
	sub_8247F370(ctx, base);
	// stw r3,21628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21628, ctx.r3.u32);
loc_82A60538:
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
	// addi r29,r31,21632
	ctx.r29.s64 = ctx.r31.s64 + 21632;
loc_82A60540:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a60564
	if (!ctx.cr6.eq) goto loc_82A60564;
	// lwz r11,21628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21628);
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// add r5,r11,r30
	ctx.r5.u64 = ctx.r11.u64 + ctx.r30.u64;
	// bl 0x82a438c8
	ctx.lr = 0x82A60560;
	sub_82A438C8(ctx, base);
	// stw r3,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r3.u32);
loc_82A60564:
	// addi r30,r30,480
	ctx.r30.s64 = ctx.r30.s64 + 480;
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// cmpwi cr6,r30,1920
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 1920, ctx.xer);
	// blt cr6,0x82a60540
	if (ctx.cr6.lt) goto loc_82A60540;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a43960
	ctx.lr = 0x82A60584;
	sub_82A43960(ctx, base);
	// lwz r11,21648(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21648);
	// stw r28,21656(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21656, ctx.r28.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r28,21660(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21660, ctx.r28.u32);
	// bne cr6,0x82a605a4
	if (!ctx.cr6.eq) goto loc_82A605A4;
	// lwz r11,21628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21628);
	// addi r11,r11,1920
	ctx.r11.s64 = ctx.r11.s64 + 1920;
	// stw r11,21648(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21648, ctx.r11.u32);
loc_82A605A4:
	// li r11,2
	ctx.r11.s64 = 2;
	// stw r11,21652(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21652, ctx.r11.u32);
	// b 0x82a60670
	goto loc_82A60670;
loc_82A605B0:
	// rlwinm. r11,r9,0,23,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x100;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a60434
	if (ctx.cr0.eq) goto loc_82A60434;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2332(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a605d4
	if (ctx.cr0.eq) goto loc_82A605D4;
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// b 0x82a605d8
	goto loc_82A605D8;
loc_82A605D4:
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
loc_82A605D8:
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// rlwinm r4,r9,20,4,11
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 20) & 0xFF00000;
	// addi r3,r11,16768
	ctx.r3.s64 = ctx.r11.s64 + 16768;
	// lwz r11,12(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A605F0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// stw r3,16724(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16724, ctx.r3.u32);
	// blt 0x82a60430
	if (ctx.cr0.lt) goto loc_82A60430;
	// lwz r11,16720(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16720);
	// li r10,1
	ctx.r10.s64 = 1;
	// rlwimi r11,r10,10,23,23
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 10) & 0x100) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFEFF);
	// rlwimi r11,r10,10,21,21
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 10) & 0x400) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFBFF);
	// stw r11,16720(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16720, ctx.r11.u32);
	// b 0x82a60434
	goto loc_82A60434;
loc_82A60614:
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// bne cr6,0x82a60670
	if (!ctx.cr6.eq) goto loc_82A60670;
	// lbz r11,10942(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10942);
	// clrlwi. r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a60634
	if (!ctx.cr0.eq) goto loc_82A60634;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a437e0
	ctx.lr = 0x82A60634;
	sub_82A437E0(ctx, base);
loc_82A60634:
	// lwz r11,21660(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21660);
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82a60648
	if (ctx.cr6.eq) goto loc_82A60648;
	// addi r30,r11,1
	ctx.r30.s64 = ctx.r11.s64 + 1;
loc_82A60648:
	// lwz r11,21656(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21656);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82a60670
	if (ctx.cr6.eq) goto loc_82A60670;
	// addi r11,r30,5408
	ctx.r11.s64 = ctx.r30.s64 + 5408;
	// li r5,0
	ctx.r5.s64 = 0;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwzx r4,r11,r31
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r31.u32);
	// bl 0x82a44070
	ctx.lr = 0x82A6066C;
	sub_82A44070(ctx, base);
	// stw r30,21660(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21660, ctx.r30.u32);
loc_82A60670:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a5fd98
	ctx.lr = 0x82A60678;
	sub_82A5FD98(ctx, base);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2020(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2020);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a606a4
	if (ctx.cr0.eq) goto loc_82A606A4;
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a606a4
	if (ctx.cr0.eq) goto loc_82A606A4;
	// li r3,0
	ctx.r3.s64 = 0;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A606A4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A606A4:
	// addi r1,r1,384
	ctx.r1.s64 = ctx.r1.s64 + 384;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A606B0"))) PPC_WEAK_FUNC(sub_82A606B0);
PPC_FUNC_IMPL(__imp__sub_82A606B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r5,255
	ctx.r5.s64 = 255;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,81
	ctx.r3.s64 = ctx.r1.s64 + 81;
	// stb r11,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r11.u8);
	// bl 0x82d5cb60
	ctx.lr = 0x82A606DC;
	sub_82D5CB60(ctx, base);
	// li r5,256
	ctx.r5.s64 = 256;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82d5e188
	ctx.lr = 0x82A606EC;
	sub_82D5E188(ctx, base);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2332(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a60718
	if (ctx.cr0.eq) goto loc_82A60718;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,84
	ctx.r3.s64 = 84;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A60714;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82a6071c
	goto loc_82A6071C;
loc_82A60718:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A6071C:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82a6072c
	if (ctx.cr6.eq) goto loc_82A6072C;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82a60734
	goto loc_82A60734;
loc_82A6072C:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_82A60734:
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A60748"))) PPC_WEAK_FUNC(sub_82A60748);
PPC_FUNC_IMPL(__imp__sub_82A60748) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82A60750;
	__savegprlr_26(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// stw r8,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r8.u32);
	// stw r7,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r7.u32);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82a607bc
	if (!ctx.cr6.eq) goto loc_82A607BC;
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a607bc
	if (!ctx.cr6.eq) goto loc_82A607BC;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82a607bc
	if (!ctx.cr6.eq) goto loc_82A607BC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a607bc
	if (!ctx.cr6.eq) goto loc_82A607BC;
	// stw r4,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r4.u32);
	// stw r5,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r5.u32);
loc_82A607BC:
	// lwz r8,88(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// subf r10,r10,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r10.s64;
	// lwz r8,92(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// subf r29,r9,r8
	ctx.r29.s64 = ctx.r8.s64 - ctx.r9.s64;
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
	// bne 0x82a607e0
	if (!ctx.cr0.eq) goto loc_82A607E0;
	// lwz r27,21540(r26)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r26.u32 + 21540);
loc_82A607E0:
	// lwz r30,20(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplwi r30,0
	ctx.cr0.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne 0x82a60828
	if (!ctx.cr0.eq) goto loc_82A60828;
	// lwz r11,13588(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 13588);
	// mullw r9,r27,r29
	ctx.r9.s64 = int64_t(ctx.r27.s32) * int64_t(ctx.r29.s32);
	// divwu r30,r9,r10
	ctx.r30.u32 = ctx.r9.u32 / ctx.r10.u32;
	// twllei r10,0
	// clrlwi. r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a60824
	if (!ctx.cr0.eq) goto loc_82A60824;
	// bl 0x8308b2e4
	ctx.lr = 0x82A60808;
	__imp__VdQueryVideoFlags(ctx, base);
	// clrlwi. r11,r3,31
	ctx.r11.u64 = ctx.r3.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a60824
	if (!ctx.cr0.eq) goto loc_82A60824;
	// cmplw cr6,r30,r29
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r29.u32, ctx.xer);
	// bgt cr6,0x82a60824
	if (ctx.cr6.gt) goto loc_82A60824;
	// lwz r11,21544(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 21544);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a60828
	if (!ctx.cr6.gt) goto loc_82A60828;
loc_82A60824:
	// lwz r30,21544(r26)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r26.u32 + 21544);
loc_82A60828:
	// li r5,56
	ctx.r5.s64 = 56;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82d5c630
	ctx.lr = 0x82A60838;
	sub_82D5C630(ctx, base);
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// stw r27,16(r28)
	PPC_STORE_U32(ctx.r28.u32 + 16, ctx.r27.u32);
	// stw r30,20(r28)
	PPC_STORE_U32(ctx.r28.u32 + 20, ctx.r30.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r10,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r10.u32);
	// stw r9,4(r28)
	PPC_STORE_U32(ctx.r28.u32 + 4, ctx.r9.u32);
	// stw r8,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r8.u32);
	// stw r11,12(r28)
	PPC_STORE_U32(ctx.r28.u32 + 12, ctx.r11.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A60870"))) PPC_WEAK_FUNC(sub_82A60870);
PPC_FUNC_IMPL(__imp__sub_82A60870) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r11.u32);
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// stw r11,4(r5)
	PPC_STORE_U32(ctx.r5.u32 + 4, ctx.r11.u32);
	// lwz r11,8(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// stw r11,8(r5)
	PPC_STORE_U32(ctx.r5.u32 + 8, ctx.r11.u32);
	// lwz r11,12(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// stw r11,12(r5)
	PPC_STORE_U32(ctx.r5.u32 + 12, ctx.r11.u32);
	// lwz r11,16(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// stw r11,16(r5)
	PPC_STORE_U32(ctx.r5.u32 + 16, ctx.r11.u32);
	// lwz r11,20(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// stw r11,20(r5)
	PPC_STORE_U32(ctx.r5.u32 + 20, ctx.r11.u32);
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r10,24(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82a608bc
	if (!ctx.cr6.eq) goto loc_82A608BC;
	// stw r11,24(r5)
	PPC_STORE_U32(ctx.r5.u32 + 24, ctx.r11.u32);
	// stw r11,40(r5)
	PPC_STORE_U32(ctx.r5.u32 + 40, ctx.r11.u32);
	// b 0x82a608c8
	goto loc_82A608C8;
loc_82A608BC:
	// li r10,3
	ctx.r10.s64 = 3;
	// stw r10,24(r5)
	PPC_STORE_U32(ctx.r5.u32 + 24, ctx.r10.u32);
	// stw r10,40(r5)
	PPC_STORE_U32(ctx.r5.u32 + 40, ctx.r10.u32);
loc_82A608C8:
	// stw r11,28(r5)
	PPC_STORE_U32(ctx.r5.u32 + 28, ctx.r11.u32);
	// stw r11,32(r5)
	PPC_STORE_U32(ctx.r5.u32 + 32, ctx.r11.u32);
	// stw r11,36(r5)
	PPC_STORE_U32(ctx.r5.u32 + 36, ctx.r11.u32);
	// stw r11,44(r5)
	PPC_STORE_U32(ctx.r5.u32 + 44, ctx.r11.u32);
	// stw r11,48(r5)
	PPC_STORE_U32(ctx.r5.u32 + 48, ctx.r11.u32);
	// stw r11,52(r5)
	PPC_STORE_U32(ctx.r5.u32 + 52, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A608E8"))) PPC_WEAK_FUNC(sub_82A608E8);
PPC_FUNC_IMPL(__imp__sub_82A608E8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A608F0;
	__savegprlr_29(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82a60748
	ctx.lr = 0x82A60908;
	sub_82A60748(ctx, base);
	// lwz r11,21540(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21540);
	// addi r3,r1,152
	ctx.r3.s64 = ctx.r1.s64 + 152;
	// lwz r10,21544(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21544);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r5,56
	ctx.r5.s64 = 56;
	// sth r30,144(r1)
	PPC_STORE_U16(ctx.r1.u32 + 144, ctx.r30.u16);
	// sth r29,146(r1)
	PPC_STORE_U16(ctx.r1.u32 + 146, ctx.r29.u16);
	// sth r11,148(r1)
	PPC_STORE_U16(ctx.r1.u32 + 148, ctx.r11.u16);
	// sth r10,150(r1)
	PPC_STORE_U16(ctx.r1.u32 + 150, ctx.r10.u16);
	// bl 0x82d5c630
	ctx.lr = 0x82A60930;
	sub_82D5C630(ctx, base);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x8308b2f4
	ctx.lr = 0x82A6093C;
	__imp__VdCallGraphicsNotificationRoutines(ctx, base);
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A60948"))) PPC_WEAK_FUNC(sub_82A60948);
PPC_FUNC_IMPL(__imp__sub_82A60948) {
	PPC_FUNC_PROLOGUE();
	// vrfim v11,v1
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v11.f32, _mm_round_ps(_mm_load_ps(ctx.v1.f32), _MM_FROUND_TO_NEG_INF | _MM_FROUND_NO_EXC));
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r11,r11,16816
	ctx.r11.s64 = ctx.r11.s64 + 16816;
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// vspltw v12,v0,0
	_mm_store_si128((__m128i*)ctx.v12.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// vspltw v10,v0,1
	_mm_store_si128((__m128i*)ctx.v10.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xAA));
	// addi r11,r11,16800
	ctx.r11.s64 = ctx.r11.s64 + 16800;
	// vspltw v7,v0,2
	_mm_store_si128((__m128i*)ctx.v7.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x55));
	// vspltw v5,v0,3
	_mm_store_si128((__m128i*)ctx.v5.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x0));
	// vsubfp v0,v1,v11
	_mm_store_ps(ctx.v0.f32, _mm_sub_ps(_mm_load_ps(ctx.v1.f32), _mm_load_ps(ctx.v11.f32)));
	// vexptefp v11,v11
	ctx.v11.f32[0] = exp2f(ctx.v11.f32[0]);
	ctx.v11.f32[1] = exp2f(ctx.v11.f32[1]);
	ctx.v11.f32[2] = exp2f(ctx.v11.f32[2]);
	ctx.v11.f32[3] = exp2f(ctx.v11.f32[3]);
	// lvx128 v13,r0,r11
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v8,v13,1
	_mm_store_si128((__m128i*)ctx.v8.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xAA));
	// vspltw v9,v13,0
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// vspltw v6,v13,2
	_mm_store_si128((__m128i*)ctx.v6.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0x55));
	// vspltw v4,v13,3
	_mm_store_si128((__m128i*)ctx.v4.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0x0));
	// vmaddfp v10,v0,v10,v12
	_mm_store_ps(ctx.v10.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v10.f32)), _mm_load_ps(ctx.v12.f32)));
	// vmulfp128 v13,v0,v0
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32)));
	// vmaddfp v9,v0,v8,v9
	_mm_store_ps(ctx.v9.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v8.f32)), _mm_load_ps(ctx.v9.f32)));
	// vmulfp128 v0,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v10,v13,v7,v10
	_mm_store_ps(ctx.v10.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v7.f32)), _mm_load_ps(ctx.v10.f32)));
	// vmaddfp v9,v13,v6,v9
	_mm_store_ps(ctx.v9.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v6.f32)), _mm_load_ps(ctx.v9.f32)));
	// vmulfp128 v13,v13,v13
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v10,v0,v5,v10
	_mm_store_ps(ctx.v10.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v5.f32)), _mm_load_ps(ctx.v10.f32)));
	// vmaddfp v0,v0,v4,v9
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v4.f32)), _mm_load_ps(ctx.v9.f32)));
	// vmaddfp v0,v13,v0,v10
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v10.f32)));
	// vor v13,v0,v0
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// vor v10,v0,v0
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// vrefp v0,v0
	_mm_store_ps(ctx.v0.f32, _mm_div_ps(_mm_set1_ps(1), _mm_load_ps(ctx.v0.f32)));
	// vnmsubfp v13,v13,v0,v12
	_mm_store_ps(ctx.v13.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v12.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vor v8,v0,v0
	_mm_store_si128((__m128i*)ctx.v8.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// vmaddfp v0,v0,v13,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)), _mm_load_ps(ctx.v0.f32)));
	// vnmsubfp v13,v10,v0,v12
	_mm_store_ps(ctx.v13.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v12.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vcmpeqfp v12,v0,v0
	_mm_store_ps(ctx.v12.f32, _mm_cmpeq_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32)));
	// vmaddfp v0,v0,v13,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)), _mm_load_ps(ctx.v0.f32)));
	// vsel v0,v8,v0,v12
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v8.u8)), _mm_and_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v0.u8))));
	// vmulfp128 v1,v11,v0
	_mm_store_ps(ctx.v1.f32, _mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v0.f32)));
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A609E8"))) PPC_WEAK_FUNC(sub_82A609E8);
PPC_FUNC_IMPL(__imp__sub_82A609E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,292
	ctx.r11.s64 = 19136512;
	// stfs f1,-48(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -48, temp.u32);
	// addi r9,r1,-48
	ctx.r9.s64 = ctx.r1.s64 + -48;
	// ori r10,r11,16237
	ctx.r10.u64 = ctx.r11.u64 | 16237;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f0,-18888(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18888);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f13,21344(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21344);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// stfs f13,-32(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -32, temp.u32);
	// addi r11,r11,5712
	ctx.r11.s64 = ctx.r11.s64 + 5712;
	// lvx128 v12,r0,r11
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// addi r11,r11,5728
	ctx.r11.s64 = ctx.r11.s64 + 5728;
	// lvx128 v11,r0,r11
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// addi r11,r11,5696
	ctx.r11.s64 = ctx.r11.s64 + 5696;
	// lvx128 v10,r0,r11
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lwz r11,-48(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -48);
	// rlwimi r11,r10,30,1,31
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 30) & 0x7FFFFFFF) | (ctx.r11.u64 & 0xFFFFFFFF80000000);
	// stw r11,-48(r1)
	PPC_STORE_U32(ctx.r1.u32 + -48, ctx.r11.u32);
	// lfs f13,-48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -48);
	ctx.f13.f64 = double(temp.f32);
	// fadds f12,f13,f1
	ctx.f12.f64 = double(float(ctx.f13.f64 + ctx.f1.f64));
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f13,16864(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16864);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fctiwz f13,f13
	ctx.f13.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f13.f64));
	// stfiwx f13,0,r9
	PPC_STORE_U32(ctx.r9.u32, ctx.f13.u32);
	// lwa r11,-48(r1)
	ctx.r11.s64 = int32_t(PPC_LOAD_U32(ctx.r1.u32 + -48));
	// std r11,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.r11.u64);
	// lfd f13,-48(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fnmsubs f0,f13,f0,f1
	ctx.f0.f64 = double(float(-(ctx.f13.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// stfs f0,-28(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -28, temp.u32);
	// fmuls f13,f0,f0
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// stfs f13,-24(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -24, temp.u32);
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f0,-20(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -20, temp.u32);
	// addi r11,r1,-32
	ctx.r11.s64 = ctx.r1.s64 + -32;
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,-16
	ctx.r11.s64 = ctx.r1.s64 + -16;
	// vspltw v13,v0,1
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xAA));
	// vmulfp128 v0,v0,v0
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32)));
	// vmulfp128 v0,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// vspltw v9,v0,3
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x0));
	// vmsum4fp128 v10,v0,v10
	_mm_store_ps(ctx.v10.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v10.f32), 0xFF));
	// vmulfp128 v13,v9,v13
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v9.f32), _mm_load_ps(ctx.v13.f32)));
	// stvx128 v10,r0,r11
	_mm_store_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v10.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,-32
	ctx.r11.s64 = ctx.r1.s64 + -32;
	// vmulfp128 v0,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// vmulfp128 v13,v0,v13
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// vmsum4fp128 v0,v0,v12
	_mm_store_ps(ctx.v0.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v12.f32), 0xFF));
	// vmsum4fp128 v13,v13,v11
	_mm_store_ps(ctx.v13.f32, _mm_dp_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v11.f32), 0xFF));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,-48
	ctx.r11.s64 = ctx.r1.s64 + -48;
	// lfs f0,-32(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -32);
	ctx.f0.f64 = double(temp.f32);
	// stvx128 v13,r0,r11
	_mm_store_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lfs f13,-48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -48);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// lfs f13,-16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	ctx.f13.f64 = double(temp.f32);
	// fadds f1,f0,f13
	ctx.f1.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A60AE8"))) PPC_WEAK_FUNC(sub_82A60AE8);
PPC_FUNC_IMPL(__imp__sub_82A60AE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	PPCVRegister vTemp{};
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// stfs f1,20(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// addi r10,r1,-32
	ctx.r10.s64 = ctx.r1.s64 + -32;
	// stfs f2,28(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// addi r9,r1,-28
	ctx.r9.s64 = ctx.r1.s64 + -28;
	// vspltisw v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_set1_epi32(int(0x0)));
	// addi r8,r1,20
	ctx.r8.s64 = ctx.r1.s64 + 20;
	// vspltisw v11,-1
	_mm_store_si128((__m128i*)ctx.v11.u32, _mm_set1_epi32(int(0xFFFFFFFF)));
	// addi r7,r1,-20
	ctx.r7.s64 = ctx.r1.s64 + -20;
	// vspltisw v4,-9
	_mm_store_si128((__m128i*)ctx.v4.u32, _mm_set1_epi32(int(0xFFFFFFF7)));
	// lfs f0,21348(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21348);
	ctx.f0.f64 = double(temp.f32);
	// addi r11,r1,-24
	ctx.r11.s64 = ctx.r1.s64 + -24;
	// stfs f0,-32(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -32, temp.u32);
	// stfs f0,-28(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -28, temp.u32);
	// vslw v3,v11,v11
	ctx.v3.u32[0] = ctx.v11.u32[0] << (ctx.v11.u8[0] & 0x1F);
	ctx.v3.u32[1] = ctx.v11.u32[1] << (ctx.v11.u8[4] & 0x1F);
	ctx.v3.u32[2] = ctx.v11.u32[2] << (ctx.v11.u8[8] & 0x1F);
	ctx.v3.u32[3] = ctx.v11.u32[3] << (ctx.v11.u8[12] & 0x1F);
	// lvlx v0,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r10,r1,-20
	ctx.r10.s64 = ctx.r1.s64 + -20;
	// lvlx v12,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r9,r1,28
	ctx.r9.s64 = ctx.r1.s64 + 28;
	// stfs f0,-24(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -24, temp.u32);
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v10,0,r11
	temp.u32 = ctx.r11.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r11,r1,-24
	ctx.r11.s64 = ctx.r1.s64 + -24;
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v0,v10,4,3
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v10.f32), 57), 4));
	// stfs f0,-20(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -20, temp.u32);
	// lvlx v10,0,r7
	temp.u32 = ctx.r7.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,-20(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -20, temp.u32);
	// stfs f0,-24(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -24, temp.u32);
	// lvlx v9,0,r11
	temp.u32 = ctx.r11.u32;
	_mm_store_si128((__m128i*)ctx.v9.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// lvlx v8,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v8.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lvlx v7,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v7.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v8,v10,4,3
	_mm_store_ps(ctx.v8.f32, _mm_blend_ps(_mm_load_ps(ctx.v8.f32), _mm_permute_ps(_mm_load_ps(ctx.v10.f32), 57), 4));
	// vrlimi128 v7,v9,4,3
	_mm_store_ps(ctx.v7.f32, _mm_blend_ps(_mm_load_ps(ctx.v7.f32), _mm_permute_ps(_mm_load_ps(ctx.v9.f32), 57), 4));
	// addi r11,r11,16848
	ctx.r11.s64 = ctx.r11.s64 + 16848;
	// vor v12,v8,v8
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_load_si128((__m128i*)ctx.v8.u8));
	// vor v10,v7,v7
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_load_si128((__m128i*)ctx.v7.u8));
	// vor v8,v0,v0
	_mm_store_si128((__m128i*)ctx.v8.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// lvx128 v9,r0,r11
	_mm_store_si128((__m128i*)ctx.v9.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v7,v9,0
	_mm_store_si128((__m128i*)ctx.v7.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), 0xFF));
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// vspltw v5,v9,1
	_mm_store_si128((__m128i*)ctx.v5.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), 0xAA));
	// vrlimi128 v10,v12,3,2
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// vupkd3d128 v12,v13,4
	temp.f32 = 3.0f;
	temp.s32 += ctx.v13.s16[1];
	vTemp.f32[3] = temp.f32;
	temp.f32 = 3.0f;
	temp.s32 += ctx.v13.s16[0];
	vTemp.f32[2] = temp.f32;
	vTemp.f32[1] = 0.0f;
	vTemp.f32[0] = 1.0f;
	ctx.v12 = vTemp;
	// addi r11,r11,16832
	ctx.r11.s64 = ctx.r11.s64 + 16832;
	// vspltw v29,v9,2
	_mm_store_si128((__m128i*)ctx.v29.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), 0x55));
	// vspltw v6,v12,3
	_mm_store_si128((__m128i*)ctx.v6.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v12.u32), 0x0));
	// vandc v12,v8,v3
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v3.u8), _mm_load_si128((__m128i*)ctx.v8.u8)));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vslw v10,v11,v4
	ctx.v10.u32[0] = ctx.v11.u32[0] << (ctx.v4.u8[0] & 0x1F);
	ctx.v10.u32[1] = ctx.v11.u32[1] << (ctx.v4.u8[4] & 0x1F);
	ctx.v10.u32[2] = ctx.v11.u32[2] << (ctx.v4.u8[8] & 0x1F);
	ctx.v10.u32[3] = ctx.v11.u32[3] << (ctx.v4.u8[12] & 0x1F);
	// vlogefp v2,v12
	ctx.fpscr.enableFlushModeUnconditional();
	ctx.v2.f32[0] = log2f(ctx.v12.f32[0]);
	ctx.v2.f32[1] = log2f(ctx.v12.f32[1]);
	ctx.v2.f32[2] = log2f(ctx.v12.f32[2]);
	ctx.v2.f32[3] = log2f(ctx.v12.f32[3]);
	// vsel v10,v12,v6,v10
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_or_si128(_mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v10.u8), _mm_load_si128((__m128i*)ctx.v12.u8)), _mm_and_si128(_mm_load_si128((__m128i*)ctx.v10.u8), _mm_load_si128((__m128i*)ctx.v6.u8))));
	// vsubfp v12,v10,v6
	_mm_store_ps(ctx.v12.f32, _mm_sub_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v6.f32)));
	// vrfim v10,v2
	_mm_store_ps(ctx.v10.f32, _mm_round_ps(_mm_load_ps(ctx.v2.f32), _MM_FROUND_TO_NEG_INF | _MM_FROUND_NO_EXC));
	// vmaddfp v5,v12,v5,v7
	_mm_store_ps(ctx.v5.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v5.f32)), _mm_load_ps(ctx.v7.f32)));
	// lvx128 v7,r0,r11
	_mm_store_si128((__m128i*)ctx.v7.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// vspltw v30,v7,1
	_mm_store_si128((__m128i*)ctx.v30.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), 0xAA));
	// vspltw v31,v7,0
	_mm_store_si128((__m128i*)ctx.v31.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), 0xFF));
	// addi r11,r11,16816
	ctx.r11.s64 = ctx.r11.s64 + 16816;
	// vspltw v28,v7,2
	_mm_store_si128((__m128i*)ctx.v28.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), 0x55));
	// vspltw v27,v7,3
	_mm_store_si128((__m128i*)ctx.v27.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), 0x0));
	// vmulfp128 v1,v10,v0
	_mm_store_ps(ctx.v1.f32, _mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v0.f32)));
	// vmulfp128 v10,v12,v12
	_mm_store_ps(ctx.v10.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v12.f32)));
	// vmaddfp v31,v12,v30,v31
	_mm_store_ps(ctx.v31.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v30.f32)), _mm_load_ps(ctx.v31.f32)));
	// vmaddfp v30,v10,v29,v5
	_mm_store_ps(ctx.v30.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v29.f32)), _mm_load_ps(ctx.v5.f32)));
	// vspltw v29,v9,3
	_mm_store_si128((__m128i*)ctx.v29.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), 0x0));
	// lvx128 v9,r0,r11
	_mm_store_si128((__m128i*)ctx.v9.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// vmulfp128 v2,v12,v10
	_mm_store_ps(ctx.v2.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v10.f32)));
	// vspltw v5,v9,0
	_mm_store_si128((__m128i*)ctx.v5.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), 0xFF));
	// addi r11,r11,16800
	ctx.r11.s64 = ctx.r11.s64 + 16800;
	// vmulfp128 v26,v10,v10
	_mm_store_ps(ctx.v26.f32, _mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v10.f32)));
	// vmaddfp v10,v10,v28,v31
	_mm_store_ps(ctx.v10.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v28.f32)), _mm_load_ps(ctx.v31.f32)));
	// vspltw v25,v9,1
	_mm_store_si128((__m128i*)ctx.v25.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), 0xAA));
	// vmulfp128 v12,v12,v0
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v0.f32)));
	// lvx128 v7,r0,r11
	_mm_store_si128((__m128i*)ctx.v7.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v31,v7,0
	_mm_store_si128((__m128i*)ctx.v31.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), 0xFF));
	// vspltw v28,v7,1
	_mm_store_si128((__m128i*)ctx.v28.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), 0xAA));
	// vmaddfp v10,v2,v27,v10
	_mm_store_ps(ctx.v10.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v2.f32), _mm_load_ps(ctx.v27.f32)), _mm_load_ps(ctx.v10.f32)));
	// vspltw v24,v7,2
	_mm_store_si128((__m128i*)ctx.v24.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), 0x55));
	// vmaddfp v30,v2,v29,v30
	_mm_store_ps(ctx.v30.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v2.f32), _mm_load_ps(ctx.v29.f32)), _mm_load_ps(ctx.v30.f32)));
	// vspltw v29,v9,2
	_mm_store_si128((__m128i*)ctx.v29.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), 0x55));
	// vspltw v9,v9,3
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), 0x0));
	// vand v3,v8,v3
	_mm_store_si128((__m128i*)ctx.v3.u8, _mm_and_si128(_mm_load_si128((__m128i*)ctx.v8.u8), _mm_load_si128((__m128i*)ctx.v3.u8)));
	// vspltw v7,v7,3
	_mm_store_si128((__m128i*)ctx.v7.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), 0x0));
	// vslw v4,v11,v4
	ctx.v4.u32[0] = ctx.v11.u32[0] << (ctx.v4.u8[0] & 0x1F);
	ctx.v4.u32[1] = ctx.v11.u32[1] << (ctx.v4.u8[4] & 0x1F);
	ctx.v4.u32[2] = ctx.v11.u32[2] << (ctx.v4.u8[8] & 0x1F);
	ctx.v4.u32[3] = ctx.v11.u32[3] << (ctx.v4.u8[12] & 0x1F);
	// addi r11,r1,-16
	ctx.r11.s64 = ctx.r1.s64 + -16;
	// vmaddfp v10,v26,v10,v30
	_mm_store_ps(ctx.v10.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v26.f32), _mm_load_ps(ctx.v10.f32)), _mm_load_ps(ctx.v30.f32)));
	// vcmpgtfp v30,v13,v0
	_mm_store_ps(ctx.v30.f32, _mm_cmpgt_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)));
	// vmaddfp v12,v12,v10,v1
	_mm_store_ps(ctx.v12.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v10.f32)), _mm_load_ps(ctx.v1.f32)));
	// vrfim v10,v12
	_mm_store_ps(ctx.v10.f32, _mm_round_ps(_mm_load_ps(ctx.v12.f32), _MM_FROUND_TO_NEG_INF | _MM_FROUND_NO_EXC));
	// vsubfp v12,v12,v10
	_mm_store_ps(ctx.v12.f32, _mm_sub_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v10.f32)));
	// vexptefp v2,v10
	ctx.v2.f32[0] = exp2f(ctx.v10.f32[0]);
	ctx.v2.f32[1] = exp2f(ctx.v10.f32[1]);
	ctx.v2.f32[2] = exp2f(ctx.v10.f32[2]);
	ctx.v2.f32[3] = exp2f(ctx.v10.f32[3]);
	// vmulfp128 v10,v12,v12
	_mm_store_ps(ctx.v10.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v12.f32)));
	// vmaddfp v1,v12,v25,v5
	_mm_store_ps(ctx.v1.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v25.f32)), _mm_load_ps(ctx.v5.f32)));
	// vmaddfp v31,v12,v28,v31
	_mm_store_ps(ctx.v31.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v28.f32)), _mm_load_ps(ctx.v31.f32)));
	// vmulfp128 v12,v12,v10
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v10.f32)));
	// vmaddfp v1,v10,v29,v1
	_mm_store_ps(ctx.v1.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v29.f32)), _mm_load_ps(ctx.v1.f32)));
	// vmaddfp v31,v10,v24,v31
	_mm_store_ps(ctx.v31.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v24.f32)), _mm_load_ps(ctx.v31.f32)));
	// vmulfp128 v10,v10,v10
	_mm_store_ps(ctx.v10.f32, _mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v10.f32)));
	// vmaddfp v9,v12,v9,v1
	_mm_store_ps(ctx.v9.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v9.f32)), _mm_load_ps(ctx.v1.f32)));
	// vmaddfp v12,v12,v7,v31
	_mm_store_ps(ctx.v12.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v7.f32)), _mm_load_ps(ctx.v31.f32)));
	// vctsxs v1,v0,0
	_mm_store_si128((__m128i*)ctx.v1.s32, _mm_vctsxs(_mm_load_ps(ctx.v0.f32)));
	// vcmpeqfp v7,v0,v13
	_mm_store_ps(ctx.v7.f32, _mm_cmpeq_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v12,v10,v12,v9
	_mm_store_ps(ctx.v12.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v12.f32)), _mm_load_ps(ctx.v9.f32)));
	// vspltisw v10,1
	_mm_store_si128((__m128i*)ctx.v10.u32, _mm_set1_epi32(int(0x1)));
	// vrfiz v9,v0
	_mm_store_ps(ctx.v9.f32, _mm_round_ps(_mm_load_ps(ctx.v0.f32), _MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC));
	// vand v1,v1,v10
	_mm_store_si128((__m128i*)ctx.v1.u8, _mm_and_si128(_mm_load_si128((__m128i*)ctx.v1.u8), _mm_load_si128((__m128i*)ctx.v10.u8)));
	// vsrw v10,v4,v10
	ctx.v10.u32[0] = ctx.v4.u32[0] >> (ctx.v10.u8[0] & 0x1F);
	ctx.v10.u32[1] = ctx.v4.u32[1] >> (ctx.v10.u8[4] & 0x1F);
	ctx.v10.u32[2] = ctx.v4.u32[2] >> (ctx.v10.u8[8] & 0x1F);
	ctx.v10.u32[3] = ctx.v4.u32[3] >> (ctx.v10.u8[12] & 0x1F);
	// vslw v11,v1,v11
	ctx.v11.u32[0] = ctx.v1.u32[0] << (ctx.v11.u8[0] & 0x1F);
	ctx.v11.u32[1] = ctx.v1.u32[1] << (ctx.v11.u8[4] & 0x1F);
	ctx.v11.u32[2] = ctx.v1.u32[2] << (ctx.v11.u8[8] & 0x1F);
	ctx.v11.u32[3] = ctx.v1.u32[3] << (ctx.v11.u8[12] & 0x1F);
	// vor v29,v12,v12
	_mm_store_si128((__m128i*)ctx.v29.u8, _mm_load_si128((__m128i*)ctx.v12.u8));
	// vcmpeqfp v31,v0,v9
	_mm_store_ps(ctx.v31.f32, _mm_cmpeq_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v9.f32)));
	// vor v1,v12,v12
	_mm_store_si128((__m128i*)ctx.v1.u8, _mm_load_si128((__m128i*)ctx.v12.u8));
	// vcmpeqfp v9,v8,v13
	_mm_store_ps(ctx.v9.f32, _mm_cmpeq_ps(_mm_load_ps(ctx.v8.f32), _mm_load_ps(ctx.v13.f32)));
	// vcmpgtfp v8,v13,v8
	_mm_store_ps(ctx.v8.f32, _mm_cmpgt_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v8.f32)));
	// vrefp v0,v12
	_mm_store_ps(ctx.v0.f32, _mm_div_ps(_mm_set1_ps(1), _mm_load_ps(ctx.v12.f32)));
	// vand v12,v3,v11
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_and_si128(_mm_load_si128((__m128i*)ctx.v3.u8), _mm_load_si128((__m128i*)ctx.v11.u8)));
	// vor v13,v13,v12
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)ctx.v12.u8)));
	// vandc v11,v8,v31
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v31.u8), _mm_load_si128((__m128i*)ctx.v8.u8)));
	// vandc v8,v9,v30
	_mm_store_si128((__m128i*)ctx.v8.u8, _mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v30.u8), _mm_load_si128((__m128i*)ctx.v9.u8)));
	// vor v9,v9,v7
	_mm_store_si128((__m128i*)ctx.v9.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v9.u8), _mm_load_si128((__m128i*)ctx.v7.u8)));
	// vsel v13,v10,v13,v8
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_or_si128(_mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v8.u8), _mm_load_si128((__m128i*)ctx.v10.u8)), _mm_and_si128(_mm_load_si128((__m128i*)ctx.v8.u8), _mm_load_si128((__m128i*)ctx.v13.u8))));
	// vnmsubfp v10,v29,v0,v5
	_mm_store_ps(ctx.v10.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v29.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v5.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vor v11,v11,v9
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v11.u8), _mm_load_si128((__m128i*)ctx.v9.u8)));
	// vor v9,v0,v0
	_mm_store_si128((__m128i*)ctx.v9.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// vsel v13,v13,v6,v7
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_or_si128(_mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v7.u8), _mm_load_si128((__m128i*)ctx.v13.u8)), _mm_and_si128(_mm_load_si128((__m128i*)ctx.v7.u8), _mm_load_si128((__m128i*)ctx.v6.u8))));
	// vmaddfp v0,v0,v10,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v10.f32)), _mm_load_ps(ctx.v0.f32)));
	// vnmsubfp v10,v1,v0,v5
	_mm_store_ps(ctx.v10.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v1.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v5.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vcmpeqfp v8,v0,v0
	_mm_store_ps(ctx.v8.f32, _mm_cmpeq_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32)));
	// vmaddfp v0,v0,v10,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v10.f32)), _mm_load_ps(ctx.v0.f32)));
	// vsel v0,v9,v0,v8
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v8.u8), _mm_load_si128((__m128i*)ctx.v9.u8)), _mm_and_si128(_mm_load_si128((__m128i*)ctx.v8.u8), _mm_load_si128((__m128i*)ctx.v0.u8))));
	// vmulfp128 v0,v2,v0
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v2.f32), _mm_load_ps(ctx.v0.f32)));
	// vor v0,v0,v12
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)ctx.v12.u8)));
	// vsel v0,v0,v13,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v11.u8), _mm_load_si128((__m128i*)ctx.v0.u8)), _mm_and_si128(_mm_load_si128((__m128i*)ctx.v11.u8), _mm_load_si128((__m128i*)ctx.v13.u8))));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lfs f1,-16(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A60D18"))) PPC_WEAK_FUNC(sub_82A60D18);
PPC_FUNC_IMPL(__imp__sub_82A60D18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// stfs f1,20(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// addi r10,r1,-32
	ctx.r10.s64 = ctx.r1.s64 + -32;
	// vspltisw v0,1
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_set1_epi32(int(0x1)));
	// addi r9,r1,-24
	ctx.r9.s64 = ctx.r1.s64 + -24;
	// addi r8,r1,20
	ctx.r8.s64 = ctx.r1.s64 + 20;
	// lfs f0,21348(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21348);
	ctx.f0.f64 = double(temp.f32);
	// addi r11,r1,-28
	ctx.r11.s64 = ctx.r1.s64 + -28;
	// stfs f0,-32(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -32, temp.u32);
	// vcfsx v12,v0,1
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_cvtepi32_ps(_mm_load_si128((__m128i*)ctx.v0.u32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x3F000000)))));
	// stfs f0,-28(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -28, temp.u32);
	// lvlx v13,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,-24(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -24, temp.u32);
	// lvlx v11,0,r11
	temp.u32 = ctx.r11.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r11,r1,-16
	ctx.r11.s64 = ctx.r1.s64 + -16;
	// vrlimi128 v11,v13,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 57), 4));
	// lvlx v10,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvlx v13,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v13,v10,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v10.f32), 57), 4));
	// vrlimi128 v13,v11,3,2
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 78), 3));
	// vrsqrtefp v0,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_div_ps(_mm_set1_ps(1), _mm_sqrt_ps(_mm_load_ps(ctx.v13.f32))));
	// vor v11,v13,v13
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_load_si128((__m128i*)ctx.v13.u8));
	// vmulfp128 v10,v13,v12
	_mm_store_ps(ctx.v10.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v12.f32)));
	// vmulfp128 v9,v0,v0
	_mm_store_ps(ctx.v9.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32)));
	// vcmpeqfp v8,v0,v0
	_mm_store_ps(ctx.v8.f32, _mm_cmpeq_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32)));
	// vnmsubfp v12,v10,v9,v12
	_mm_store_ps(ctx.v12.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v9.f32)), _mm_load_ps(ctx.v12.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vmaddfp v0,v0,v12,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v12.f32)), _mm_load_ps(ctx.v0.f32)));
	// vcmpeqfp v12,v12,v12
	_mm_store_ps(ctx.v12.f32, _mm_cmpeq_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v12.f32)));
	// vmulfp128 v0,v13,v0
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)));
	// vxor v13,v12,v8
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_xor_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v8.u8)));
	// vsel v0,v0,v11,v13
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)ctx.v0.u8)), _mm_and_si128(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)ctx.v11.u8))));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lfs f1,-16(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A60DA0"))) PPC_WEAK_FUNC(sub_82A60DA0);
PPC_FUNC_IMPL(__imp__sub_82A60DA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82A60DA8;
	__savegprlr_26(ctx, base);
	// stwu r1,-992(r1)
	ea = -992 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mullw. r11,r30,r29
	ctx.r11.s64 = int64_t(ctx.r30.s32) * int64_t(ctx.r29.s32);
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble 0x82a60dd0
	if (!ctx.cr0.gt) goto loc_82A60DD0;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,288
	ctx.r3.s64 = ctx.r1.s64 + 288;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82d5cab8
	ctx.lr = 0x82A60DD0;
	sub_82D5CAB8(ctx, base);
loc_82A60DD0:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82a60df8
	if (!ctx.cr6.gt) goto loc_82A60DF8;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	ctx.cr0.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq 0x82a60df8
	if (ctx.cr0.eq) goto loc_82A60DF8;
	// mtctr r30
	ctx.ctr.u64 = ctx.r30.u64;
loc_82A60DEC:
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bdnz 0x82a60dec
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82A60DEC;
loc_82A60DF8:
	// srawi r11,r30,1
	ctx.xer.ca = (ctx.r30.s32 < 0) & ((ctx.r30.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r30.s32 >> 1;
	// addi r10,r30,-1
	ctx.r10.s64 = ctx.r30.s64 + -1;
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// srawi r10,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 1;
	// li r28,0
	ctx.r28.s64 = 0;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// cmpwi cr6,r30,2
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 2, ctx.xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// stwx r28,r11,r9
	PPC_STORE_U32(ctx.r11.u32 + ctx.r9.u32, ctx.r28.u32);
	// stwx r28,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, ctx.r28.u32);
	// beq cr6,0x82a60e64
	if (ctx.cr6.eq) goto loc_82A60E64;
	// addi r11,r30,2
	ctx.r11.s64 = ctx.r30.s64 + 2;
	// addi r10,r30,-3
	ctx.r10.s64 = ctx.r30.s64 + -3;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// srawi r10,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 1;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r3,r11,r9
	PPC_STORE_U32(ctx.r11.u32 + ctx.r9.u32, ctx.r3.u32);
	// stwx r3,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, ctx.r3.u32);
loc_82A60E64:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82a60e94
	if (!ctx.cr6.gt) goto loc_82A60E94;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
loc_82A60E74:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r9,-1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, -1, ctx.xer);
	// bne cr6,0x82a60e88
	if (!ctx.cr6.eq) goto loc_82A60E88;
	// li r9,2
	ctx.r9.s64 = 2;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
loc_82A60E88:
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a60e74
	if (!ctx.cr0.eq) goto loc_82A60E74;
loc_82A60E94:
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// ble cr6,0x82a611f0
	if (!ctx.cr6.gt) goto loc_82A611F0;
	// addi r11,r1,288
	ctx.r11.s64 = ctx.r1.s64 + 288;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// subf r4,r31,r11
	ctx.r4.s64 = ctx.r11.s64 - ctx.r31.s64;
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// lfs f12,-18864(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -18864);
	ctx.f12.f64 = double(temp.f32);
	// mr r31,r29
	ctx.r31.u64 = ctx.r29.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// lfd f10,-4344(r10)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r10.u32 + -4344);
	// lfs f11,21348(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21348);
	ctx.f11.f64 = double(temp.f32);
loc_82A60EC8:
	// li r7,512
	ctx.r7.s64 = 512;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82a60f94
	if (!ctx.cr6.gt) goto loc_82A60F94;
	// addi r9,r1,240
	ctx.r9.s64 = ctx.r1.s64 + 240;
	// rlwinm r8,r29,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r4,r5
	ctx.r10.u64 = ctx.r4.u64 + ctx.r5.u64;
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
loc_82A60EE4:
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stfs f0,0(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82a60ee4
	if (!ctx.cr0.eq) goto loc_82A60EE4;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
loc_82A60F04:
	// addi r10,r1,240
	ctx.r10.s64 = ctx.r1.s64 + 240;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// lfsx f0,r11,r10
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// fcmpu cr6,f0,f11
	ctx.cr6.compare(ctx.f0.f64, ctx.f11.f64);
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// addi r27,r10,7
	ctx.r27.s64 = ctx.r10.s64 + 7;
	// slw r27,r3,r27
	ctx.r27.u64 = ctx.r27.u8 & 0x20 ? 0 : (ctx.r3.u32 << (ctx.r27.u8 & 0x3F));
	// extsw r27,r27
	ctx.r27.s64 = ctx.r27.s32;
	// ble cr6,0x82a60f48
	if (!ctx.cr6.gt) goto loc_82A60F48;
	// std r27,176(r1)
	PPC_STORE_U64(ctx.r1.u32 + 176, ctx.r27.u64);
	// lfd f13,176(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fadd f0,f0,f10
	ctx.f0.f64 = ctx.f0.f64 + ctx.f10.f64;
	// b 0x82a60f60
	goto loc_82A60F60;
loc_82A60F48:
	// std r27,152(r1)
	PPC_STORE_U64(ctx.r1.u32 + 152, ctx.r27.u64);
	// lfd f13,152(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 152);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fsub f0,f0,f10
	ctx.f0.f64 = ctx.f0.f64 - ctx.f10.f64;
loc_82A60F60:
	// fctiwz f0,f0
	ctx.fpscr.disableFlushMode();
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r8
	PPC_STORE_U32(ctx.r8.u32, ctx.f0.u32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subfic r8,r10,2
	ctx.xer.ca = ctx.r10.u32 <= 2;
	ctx.r8.s64 = 2 - ctx.r10.s64;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r27,r1,192
	ctx.r27.s64 = ctx.r1.s64 + 192;
	// stwx r10,r11,r27
	PPC_STORE_U32(ctx.r11.u32 + ctx.r27.u32, ctx.r10.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// slw r10,r10,r8
	ctx.r10.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r8.u8 & 0x3F));
	// subf r7,r10,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r10.s64;
	// bne 0x82a60f04
	if (!ctx.cr0.eq) goto loc_82A60F04;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// ble cr6,0x82a61084
	if (!ctx.cr6.gt) goto loc_82A61084;
loc_82A60F94:
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// fmr f13,f12
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = ctx.f12.f64;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82a61058
	if (!ctx.cr6.gt) goto loc_82A61058;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
loc_82A60FAC:
	// addi r10,r1,240
	ctx.r10.s64 = ctx.r1.s64 + 240;
	// lfsx f0,r11,r10
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	ctx.f0.f64 = double(temp.f32);
	// fabs f9,f0
	ctx.f9.u64 = ctx.f0.u64 & ~0x8000000000000000;
	// fcmpu cr6,f9,f11
	ctx.cr6.compare(ctx.f9.f64, ctx.f11.f64);
	// ble cr6,0x82a61010
	if (!ctx.cr6.gt) goto loc_82A61010;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// addi r27,r1,192
	ctx.r27.s64 = ctx.r1.s64 + 192;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// addi r10,r10,7
	ctx.r10.s64 = ctx.r10.s64 + 7;
	// lwax r27,r11,r27
	ctx.r27.s64 = int32_t(PPC_LOAD_U32(ctx.r11.u32 + ctx.r27.u32));
	// slw r10,r3,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r3.u32 << (ctx.r10.u8 & 0x3F));
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r27,168(r1)
	PPC_STORE_U64(ctx.r1.u32 + 168, ctx.r27.u64);
	// std r10,160(r1)
	PPC_STORE_U64(ctx.r1.u32 + 160, ctx.r10.u64);
	// lfd f9,168(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 168);
	// fcfid f9,f9
	ctx.f9.f64 = double(ctx.f9.s64);
	// lfd f8,160(r1)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 160);
	// fcfid f8,f8
	ctx.f8.f64 = double(ctx.f8.s64);
	// frsp f9,f9
	ctx.f9.f64 = double(float(ctx.f9.f64));
	// frsp f8,f8
	ctx.f8.f64 = double(float(ctx.f8.f64));
	// fmuls f0,f8,f0
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fsubs f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f0.f64));
	// fdivs f0,f9,f0
	ctx.f0.f64 = double(float(ctx.f9.f64 / ctx.f0.f64));
	// fabs f0,f0
	ctx.f0.u64 = ctx.f0.u64 & ~0x8000000000000000;
	// b 0x82a61014
	goto loc_82A61014;
loc_82A61010:
	// fmr f0,f12
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f12.f64;
loc_82A61014:
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r10,255
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 255, ctx.xer);
	// bge cr6,0x82a61048
	if (!ctx.cr6.lt) goto loc_82A61048;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// sraw r10,r6,r10
	temp.u32 = ctx.r10.u32 & 0x3F;
	if (temp.u32 > 0x1F) temp.u32 = 0x1F;
	ctx.xer.ca = (ctx.r6.s32 < 0) & (((ctx.r6.s32 >> temp.u32) << temp.u32) != ctx.r6.s32);
	ctx.r10.s64 = ctx.r6.s32 >> temp.u32;
	// cmpw cr6,r7,r10
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82a61048
	if (ctx.cr6.lt) goto loc_82A61048;
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x82a61048
	if (!ctx.cr6.lt) goto loc_82A61048;
	// fmr f13,f0
	ctx.f13.f64 = ctx.f0.f64;
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
loc_82A61048:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// cmpw cr6,r9,r30
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r30.s32, ctx.xer);
	// blt cr6,0x82a60fac
	if (ctx.cr6.lt) goto loc_82A60FAC;
loc_82A61058:
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r9.u32);
	// sraw r9,r6,r9
	temp.u32 = ctx.r9.u32 & 0x3F;
	if (temp.u32 > 0x1F) temp.u32 = 0x1F;
	ctx.xer.ca = (ctx.r6.s32 < 0) & (((ctx.r6.s32 >> temp.u32) << temp.u32) != ctx.r6.s32);
	ctx.r9.s64 = ctx.r6.s32 >> temp.u32;
	// subf. r7,r9,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r9.s64;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r11,r10
	PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// bgt 0x82a60f94
	if (ctx.cr0.gt) goto loc_82A60F94;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
loc_82A61084:
	// bge cr6,0x82a611a0
	if (!ctx.cr6.lt) goto loc_82A611A0;
loc_82A61088:
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// fmr f13,f12
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = ctx.f12.f64;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82a61178
	if (!ctx.cr6.gt) goto loc_82A61178;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
loc_82A610A0:
	// addi r10,r1,240
	ctx.r10.s64 = ctx.r1.s64 + 240;
	// lfsx f0,r11,r10
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	ctx.f0.f64 = double(temp.f32);
	// fabs f9,f0
	ctx.f9.u64 = ctx.f0.u64 & ~0x8000000000000000;
	// fcmpu cr6,f9,f11
	ctx.cr6.compare(ctx.f9.f64, ctx.f11.f64);
	// ble cr6,0x82a6110c
	if (!ctx.cr6.gt) goto loc_82A6110C;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// addi r27,r1,192
	ctx.r27.s64 = ctx.r1.s64 + 192;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// addi r26,r10,7
	ctx.r26.s64 = ctx.r10.s64 + 7;
	// lwzx r10,r11,r27
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r27.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r10,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r10.u64);
	// slw r10,r3,r26
	ctx.r10.u64 = ctx.r26.u8 & 0x20 ? 0 : (ctx.r3.u32 << (ctx.r26.u8 & 0x3F));
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r10,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r10.u64);
	// lfd f9,136(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
	// fcfid f9,f9
	ctx.f9.f64 = double(ctx.f9.s64);
	// frsp f9,f9
	ctx.f9.f64 = double(float(ctx.f9.f64));
	// lfd f8,144(r1)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fcfid f8,f8
	ctx.f8.f64 = double(ctx.f8.s64);
	// frsp f8,f8
	ctx.f8.f64 = double(float(ctx.f8.f64));
	// fmuls f0,f8,f0
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fsubs f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f0.f64));
	// fdivs f0,f9,f0
	ctx.f0.f64 = double(float(ctx.f9.f64 / ctx.f0.f64));
	// fabs f0,f0
	ctx.f0.u64 = ctx.f0.u64 & ~0x8000000000000000;
	// b 0x82a61110
	goto loc_82A61110;
loc_82A6110C:
	// fmr f0,f12
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f12.f64;
loc_82A61110:
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// sraw r27,r6,r10
	temp.u32 = ctx.r10.u32 & 0x3F;
	if (temp.u32 > 0x1F) temp.u32 = 0x1F;
	ctx.xer.ca = (ctx.r6.s32 < 0) & (((ctx.r6.s32 >> temp.u32) << temp.u32) != ctx.r6.s32);
	ctx.r27.s64 = ctx.r6.s32 >> temp.u32;
	// neg r27,r27
	ctx.r27.s64 = -ctx.r27.s64;
	// cmpw cr6,r7,r27
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r27.s32, ctx.xer);
	// bgt cr6,0x82a61168
	if (ctx.cr6.gt) goto loc_82A61168;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82a61144
	if (!ctx.cr6.eq) goto loc_82A61144;
	// addi r27,r1,192
	ctx.r27.s64 = ctx.r1.s64 + 192;
	// lwzx r27,r11,r27
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r27.u32);
	// cmpwi cr6,r27,0
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// bgt cr6,0x82a61158
	if (ctx.cr6.gt) goto loc_82A61158;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
loc_82A61144:
	// ble cr6,0x82a61168
	if (!ctx.cr6.gt) goto loc_82A61168;
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r10,-256
	ctx.cr6.compare<int32_t>(ctx.r10.s32, -256, ctx.xer);
	// ble cr6,0x82a61168
	if (!ctx.cr6.gt) goto loc_82A61168;
loc_82A61158:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x82a61168
	if (!ctx.cr6.lt) goto loc_82A61168;
	// fmr f13,f0
	ctx.f13.f64 = ctx.f0.f64;
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
loc_82A61168:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// cmpw cr6,r9,r30
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r30.s32, ctx.xer);
	// blt cr6,0x82a610a0
	if (ctx.cr6.lt) goto loc_82A610A0;
loc_82A61178:
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r9.u32);
	// sraw r9,r6,r9
	temp.u32 = ctx.r9.u32 & 0x3F;
	if (temp.u32 > 0x1F) temp.u32 = 0x1F;
	ctx.xer.ca = (ctx.r6.s32 < 0) & (((ctx.r6.s32 >> temp.u32) << temp.u32) != ctx.r6.s32);
	ctx.r9.s64 = ctx.r6.s32 >> temp.u32;
	// add. r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 + ctx.r7.u64;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// stwx r9,r11,r10
	PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// blt 0x82a61088
	if (ctx.cr0.lt) goto loc_82A61088;
loc_82A611A0:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82a611e4
	if (!ctx.cr6.gt) goto loc_82A611E4;
	// rlwinm r8,r29,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r9,r5
	ctx.r9.u64 = ctx.r5.u64;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
loc_82A611B8:
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r27,r1,192
	ctx.r27.s64 = ctx.r1.s64 + 192;
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lwzx r7,r11,r7
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r7.u32);
	// lwzx r27,r11,r27
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r27.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// subfic r7,r7,2
	ctx.xer.ca = ctx.r7.u32 <= 2;
	ctx.r7.s64 = 2 - ctx.r7.s64;
	// slw r7,r27,r7
	ctx.r7.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r27.u32 << (ctx.r7.u8 & 0x3F));
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// bne 0x82a611b8
	if (!ctx.cr0.eq) goto loc_82A611B8;
loc_82A611E4:
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// bne 0x82a60ec8
	if (!ctx.cr0.eq) goto loc_82A60EC8;
loc_82A611F0:
	// addi r1,r1,992
	ctx.r1.s64 = ctx.r1.s64 + 992;
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A611F8"))) PPC_WEAK_FUNC(sub_82A611F8);
PPC_FUNC_IMPL(__imp__sub_82A611F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stfd f30,-24(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.f30.u64);
	// stfd f31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fabs f30,f1
	ctx.f30.u64 = ctx.f1.u64 & ~0x8000000000000000;
	// lis r11,-32244
	ctx.r11.s64 = -2113142784;
	// stfs f30,92(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f13,31108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 31108);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f30,f13
	ctx.cr6.compare(ctx.f30.f64, ctx.f13.f64);
	// bge cr6,0x82a61288
	if (!ctx.cr6.lt) goto loc_82A61288;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f0,16928(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16928);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// fmuls f0,f1,f0
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f13,16924(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16924);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f12,16920(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16920);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// fmuls f0,f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// fmadds f12,f0,f13,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// lfs f13,16916(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16916);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// fmadds f12,f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f13,16912(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16912);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// fmadds f12,f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f13,16908(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16908);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// fmadds f12,f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f13,16904(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16904);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// fmadds f12,f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f13,21344(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21344);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// b 0x82a61358
	goto loc_82A61358;
loc_82A61288:
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// fdivs f31,f13,f30
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = double(float(ctx.f13.f64 / ctx.f30.f64));
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r9,r1,88
	ctx.r9.s64 = ctx.r1.s64 + 88;
	// addi r8,r1,92
	ctx.r8.s64 = ctx.r1.s64 + 92;
	// lfs f0,21348(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21348);
	ctx.f0.f64 = double(temp.f32);
	// addi r11,r1,84
	ctx.r11.s64 = ctx.r1.s64 + 84;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v0,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lvlx v13,0,r11
	temp.u32 = ctx.r11.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v12,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v0,v12,4,3
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// vor v1,v0,v0
	_mm_store_si128((__m128i*)ctx.v1.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// bl 0x82a60948
	ctx.lr = 0x82A612D4;
	sub_82A60948(ctx, base);
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f30.f64;
	// stvx128 v1,r0,r11
	_mm_store_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v1.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// bl 0x82a60d18
	ctx.lr = 0x82A612E4;
	sub_82A60D18(ctx, base);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f0,16900(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16900);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f13,16896(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16896);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// fmsubs f13,f31,f0,f13
	ctx.f13.f64 = double(float(ctx.f31.f64 * ctx.f0.f64 - ctx.f13.f64));
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f0.f64 = double(temp.f32);
	// fdivs f12,f0,f1
	ctx.f12.f64 = double(float(ctx.f0.f64 / ctx.f1.f64));
	// lfs f0,16892(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16892);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// fmadds f13,f13,f31,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f0.f64));
	// lfs f0,16888(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16888);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// fmsubs f13,f13,f31,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 - ctx.f0.f64));
	// lfs f0,16884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16884);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// fmadds f13,f13,f31,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f0.f64));
	// lfs f0,16880(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16880);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// fmsubs f13,f13,f31,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 - ctx.f0.f64));
	// lfs f0,16876(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16876);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// fmadds f13,f13,f31,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f0.f64));
	// lfs f0,16872(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16872);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// fmadds f13,f13,f31,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f0.f64));
	// lfs f0,16868(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16868);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f0,f13,f31,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f0.f64));
	// fmuls f1,f12,f0
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
loc_82A61358:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// lfd f30,-24(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// lfd f31,-16(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A61370"))) PPC_WEAK_FUNC(sub_82A61370);
PPC_FUNC_IMPL(__imp__sub_82A61370) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stfd f31,-16(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.f31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f0,21348(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21348);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// bne cr6,0x82a6139c
	if (!ctx.cr6.eq) goto loc_82A6139C;
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f1,21344(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21344);
	ctx.f1.f64 = double(temp.f32);
	// b 0x82a613b4
	goto loc_82A613B4;
loc_82A6139C:
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lfs f0,28792(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28792);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f31,f1,f0
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x82a609e8
	ctx.lr = 0x82A613B0;
	sub_82A609E8(ctx, base);
	// fdivs f1,f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64 / ctx.f31.f64));
loc_82A613B4:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// lfd f31,-16(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A613C8"))) PPC_WEAK_FUNC(sub_82A613C8);
PPC_FUNC_IMPL(__imp__sub_82A613C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82d5c578
	ctx.lr = 0x82A613D8;
	__savefpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = ctx.f1.f64;
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f0,21344(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21344);
	ctx.f0.f64 = double(temp.f32);
	// fabs f13,f31
	ctx.f13.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bge cr6,0x82a61440
	if (!ctx.cr6.lt) goto loc_82A61440;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fabs f1,f31
	ctx.f1.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// lfs f2,-18724(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18724);
	ctx.f2.f64 = double(temp.f32);
	// bl 0x82a60ae8
	ctx.lr = 0x82A61404;
	sub_82A60AE8(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// fmr f29,f1
	ctx.fpscr.disableFlushMode();
	ctx.f29.f64 = ctx.f1.f64;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// lfs f30,-11884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11884);
	ctx.f30.f64 = double(temp.f32);
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f2,21356(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21356);
	ctx.f2.f64 = double(temp.f32);
	// bl 0x82a60ae8
	ctx.lr = 0x82A61420;
	sub_82A60AE8(ctx, base);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lfs f0,28796(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28796);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// fmuls f0,f1,f0
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmsubs f13,f29,f30,f0
	ctx.f13.f64 = double(float(ctx.f29.f64 * ctx.f30.f64 - ctx.f0.f64));
	// lfs f0,-4324(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4324);
	ctx.f0.f64 = double(temp.f32);
loc_82A61438:
	// fadds f1,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// b 0x82a614a8
	goto loc_82A614A8;
loc_82A61440:
	// fabs f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f30,21356(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21356);
	ctx.f30.f64 = double(temp.f32);
	// fcmpu cr6,f0,f30
	ctx.cr6.compare(ctx.f0.f64, ctx.f30.f64);
	// bge cr6,0x82a614a0
	if (!ctx.cr6.lt) goto loc_82A614A0;
	// fmr f2,f30
	ctx.f2.f64 = ctx.f30.f64;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x82a60ae8
	ctx.lr = 0x82A61460;
	sub_82A60AE8(ctx, base);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// fmr f28,f1
	ctx.fpscr.disableFlushMode();
	ctx.f28.f64 = ctx.f1.f64;
	// fabs f1,f31
	ctx.f1.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// lfs f29,28796(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28796);
	ctx.f29.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f2,-18724(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18724);
	ctx.f2.f64 = double(temp.f32);
	// bl 0x82a60ae8
	ctx.lr = 0x82A6147C;
	sub_82A60AE8(ctx, base);
	// fmuls f13,f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fabs f12,f31
	ctx.f12.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// lfs f0,-5980(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -5980);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fmsubs f13,f28,f29,f13
	ctx.f13.f64 = double(float(ctx.f28.f64 * ctx.f29.f64 - ctx.f13.f64));
	// fnmsubs f13,f12,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// lfs f0,-12000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -12000);
	ctx.f0.f64 = double(temp.f32);
	// b 0x82a61438
	goto loc_82A61438;
loc_82A614A0:
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f1,21348(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21348);
	ctx.f1.f64 = double(temp.f32);
loc_82A614A8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82d5c5c4
	ctx.lr = 0x82A614B4;
	__restfpr_28(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A614C0"))) PPC_WEAK_FUNC(sub_82A614C0);
PPC_FUNC_IMPL(__imp__sub_82A614C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82d5c578
	ctx.lr = 0x82A614D0;
	__savefpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = ctx.f1.f64;
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f0,21344(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21344);
	ctx.f0.f64 = double(temp.f32);
	// fabs f13,f31
	ctx.f13.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bge cr6,0x82a61538
	if (!ctx.cr6.lt) goto loc_82A61538;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fabs f1,f31
	ctx.f1.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// lfs f2,-18724(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18724);
	ctx.f2.f64 = double(temp.f32);
	// bl 0x82a60ae8
	ctx.lr = 0x82A614FC;
	sub_82A60AE8(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// fmr f29,f1
	ctx.fpscr.disableFlushMode();
	ctx.f29.f64 = ctx.f1.f64;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// lfs f30,-11924(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11924);
	ctx.f30.f64 = double(temp.f32);
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f2,21356(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21356);
	ctx.f2.f64 = double(temp.f32);
	// bl 0x82a60ae8
	ctx.lr = 0x82A61518;
	sub_82A60AE8(ctx, base);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lfs f0,-25288(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25288);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fmuls f0,f1,f0
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmsubs f13,f29,f30,f0
	ctx.f13.f64 = double(float(ctx.f29.f64 * ctx.f30.f64 - ctx.f0.f64));
	// lfs f0,-18744(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18744);
	ctx.f0.f64 = double(temp.f32);
loc_82A61530:
	// fadds f1,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// b 0x82a615a0
	goto loc_82A615A0;
loc_82A61538:
	// fabs f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f2,21356(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21356);
	ctx.f2.f64 = double(temp.f32);
	// fcmpu cr6,f0,f2
	ctx.cr6.compare(ctx.f0.f64, ctx.f2.f64);
	// bge cr6,0x82a61598
	if (!ctx.cr6.lt) goto loc_82A61598;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x82a60ae8
	ctx.lr = 0x82A61554;
	sub_82A60AE8(ctx, base);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// fmr f28,f1
	ctx.fpscr.disableFlushMode();
	ctx.f28.f64 = ctx.f1.f64;
	// fabs f1,f31
	ctx.f1.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// lfs f29,-25288(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25288);
	ctx.f29.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f30,-18724(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18724);
	ctx.f30.f64 = double(temp.f32);
	// fmr f2,f30
	ctx.f2.f64 = ctx.f30.f64;
	// bl 0x82a60ae8
	ctx.lr = 0x82A61574;
	sub_82A60AE8(ctx, base);
	// fmuls f13,f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fabs f12,f31
	ctx.f12.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// lfs f0,-5772(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -5772);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// fmsubs f13,f28,f29,f13
	ctx.f13.f64 = double(float(ctx.f28.f64 * ctx.f29.f64 - ctx.f13.f64));
	// fnmsubs f13,f12,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// lfs f0,28796(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28796);
	ctx.f0.f64 = double(temp.f32);
	// b 0x82a61530
	goto loc_82A61530;
loc_82A61598:
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f1,21348(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21348);
	ctx.f1.f64 = double(temp.f32);
loc_82A615A0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82d5c5c4
	ctx.lr = 0x82A615AC;
	__restfpr_28(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A615B8"))) PPC_WEAK_FUNC(sub_82A615B8);
PPC_FUNC_IMPL(__imp__sub_82A615B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4bc
	ctx.lr = 0x82A615C0;
	__savegprlr_25(ctx, base);
	// addi r12,r1,-64
	ctx.r12.s64 = ctx.r1.s64 + -64;
	// bl 0x82d5c560
	ctx.lr = 0x82A615C8;
	__savefpr_22(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32230
	ctx.r10.s64 = -2112225280;
	// fmr f25,f1
	ctx.fpscr.disableFlushMode();
	ctx.f25.f64 = ctx.f1.f64;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fmr f30,f2
	ctx.f30.f64 = ctx.f2.f64;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// lfs f23,21348(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 21348);
	ctx.f23.f64 = double(temp.f32);
	// mr r28,r9
	ctx.r28.u64 = ctx.r9.u64;
	// lfs f0,-29000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29000);
	ctx.f0.f64 = double(temp.f32);
	// mullw r31,r27,r25
	ctx.r31.s64 = int64_t(ctx.r27.s32) * int64_t(ctx.r25.s32);
	// cmpwi cr6,r26,0
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// beq cr6,0x82a61608
	if (ctx.cr6.eq) goto loc_82A61608;
	// fmr f29,f23
	ctx.f29.f64 = ctx.f23.f64;
	// b 0x82a6160c
	goto loc_82A6160C;
loc_82A61608:
	// fmr f29,f0
	ctx.fpscr.disableFlushMode();
	ctx.f29.f64 = ctx.f0.f64;
loc_82A6160C:
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// cmpwi cr6,r3,1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 1, ctx.xer);
	// lfs f24,21344(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21344);
	ctx.f24.f64 = double(temp.f32);
	// beq cr6,0x82a6194c
	if (ctx.cr6.eq) goto loc_82A6194C;
	// cmpwi cr6,r3,2
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 2, ctx.xer);
	// beq cr6,0x82a618b4
	if (ctx.cr6.eq) goto loc_82A618B4;
	// cmpwi cr6,r3,3
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 3, ctx.xer);
	// beq cr6,0x82a61834
	if (ctx.cr6.eq) goto loc_82A61834;
	// cmpwi cr6,r3,4
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 4, ctx.xer);
	// beq cr6,0x82a617d0
	if (ctx.cr6.eq) goto loc_82A617D0;
	// cmpwi cr6,r3,5
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 5, ctx.xer);
	// beq cr6,0x82a61754
	if (ctx.cr6.eq) goto loc_82A61754;
	// cmpwi cr6,r3,6
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 6, ctx.xer);
	// beq cr6,0x82a616b4
	if (ctx.cr6.eq) goto loc_82A616B4;
	// cmpwi cr6,r3,7
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 7, ctx.xer);
	// bne cr6,0x82a616b4
	if (!ctx.cr6.eq) goto loc_82A616B4;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82a61674
	if (ctx.cr6.eq) goto loc_82A61674;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a61674
	if (ctx.cr0.eq) goto loc_82A61674;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
loc_82A61668:
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bdnz 0x82a61668
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82A61668;
loc_82A61674:
	// subf r11,r27,r31
	ctx.r11.s64 = ctx.r31.s64 - ctx.r27.s64;
	// add r10,r31,r27
	ctx.r10.u64 = ctx.r31.u64 + ctx.r27.u64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82a619ac
	if (!ctx.cr6.lt) goto loc_82A619AC;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf. r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// add r10,r9,r28
	ctx.r10.u64 = ctx.r9.u64 + ctx.r28.u64;
	// lis r9,16256
	ctx.r9.s64 = 1065353216;
	// beq 0x82a619ac
	if (ctx.cr0.eq) goto loc_82A619AC;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
loc_82A616A4:
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x82a616a4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82A616A4;
	// b 0x82a619ac
	goto loc_82A619AC;
loc_82A616B4:
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82a619ac
	if (ctx.cr6.eq) goto loc_82A619AC;
	// rlwinm r11,r31,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 31) & 0x7FFFFFFF;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// subf r6,r27,r11
	ctx.r6.s64 = ctx.r11.s64 - ctx.r27.s64;
	// subf r7,r11,r27
	ctx.r7.s64 = ctx.r27.s64 - ctx.r11.s64;
loc_82A616D0:
	// cmplw cr6,r10,r6
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, ctx.xer);
	// blt cr6,0x82a61700
	if (ctx.cr6.lt) goto loc_82A61700;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82a61700
	if (!ctx.cr6.lt) goto loc_82A61700;
	// add r8,r7,r10
	ctx.r8.u64 = ctx.r7.u64 + ctx.r10.u64;
	// clrldi r8,r8,32
	ctx.r8.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fadds f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f29.f64));
	// b 0x82a61734
	goto loc_82A61734;
loc_82A61700:
	// add r8,r11,r27
	ctx.r8.u64 = ctx.r11.u64 + ctx.r27.u64;
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bge cr6,0x82a6173c
	if (!ctx.cr6.lt) goto loc_82A6173C;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a6173c
	if (ctx.cr6.lt) goto loc_82A6173C;
	// subf r8,r10,r11
	ctx.r8.s64 = ctx.r11.s64 - ctx.r10.s64;
	// add r8,r8,r27
	ctx.r8.u64 = ctx.r8.u64 + ctx.r27.u64;
	// clrldi r8,r8,32
	ctx.r8.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// std r8,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r8.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fsubs f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f29.f64));
loc_82A61734:
	// stfs f0,0(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// b 0x82a61740
	goto loc_82A61740;
loc_82A6173C:
	// stfs f23,0(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
loc_82A61740:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r10,r31
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r31.u32, ctx.xer);
	// blt cr6,0x82a616d0
	if (ctx.cr6.lt) goto loc_82A616D0;
	// b 0x82a619ac
	goto loc_82A619AC;
loc_82A61754:
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82a619ac
	if (ctx.cr6.eq) goto loc_82A619AC;
	// clrldi r11,r31,32
	ctx.r11.u64 = ctx.r31.u64 & 0xFFFFFFFF;
	// fdivs f30,f24,f30
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = double(float(ctx.f24.f64 / ctx.f30.f64));
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f28,f13,f0
	ctx.f28.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
loc_82A61780:
	// clrldi r11,r29,32
	ctx.r11.u64 = ctx.r29.u64 & 0xFFFFFFFF;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fsubs f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f28.f64));
	// fadds f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f29.f64));
	// fmuls f31,f0,f25
	ctx.f31.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmuls f1,f30,f31
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// bl 0x82a61370
	ctx.lr = 0x82A617A8;
	sub_82A61370(ctx, base);
	// fmr f27,f1
	ctx.fpscr.disableFlushMode();
	ctx.f27.f64 = ctx.f1.f64;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x82a61370
	ctx.lr = 0x82A617B4;
	sub_82A61370(ctx, base);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// fmuls f0,f27,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// stfs f0,0(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplw cr6,r29,r31
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r31.u32, ctx.xer);
	// blt cr6,0x82a61780
	if (ctx.cr6.lt) goto loc_82A61780;
	// b 0x82a619ac
	goto loc_82A619AC;
loc_82A617D0:
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82a619ac
	if (ctx.cr6.eq) goto loc_82A619AC;
	// clrldi r11,r31,32
	ctx.r11.u64 = ctx.r31.u64 & 0xFFFFFFFF;
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f13,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f31,f13,f0
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
loc_82A617F8:
	// clrldi r11,r29,32
	ctx.r11.u64 = ctx.r29.u64 & 0xFFFFFFFF;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fsubs f0,f0,f31
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f31.f64));
	// fadds f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f29.f64));
	// fmuls f1,f0,f25
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// bl 0x82a613c8
	ctx.lr = 0x82A6181C;
	sub_82A613C8(ctx, base);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// stfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplw cr6,r29,r31
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r31.u32, ctx.xer);
	// blt cr6,0x82a617f8
	if (ctx.cr6.lt) goto loc_82A617F8;
	// b 0x82a619ac
	goto loc_82A619AC;
loc_82A61834:
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82a619ac
	if (ctx.cr6.eq) goto loc_82A619AC;
	// clrldi r11,r31,32
	ctx.r11.u64 = ctx.r31.u64 & 0xFFFFFFFF;
	// fdivs f31,f24,f30
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = double(float(ctx.f24.f64 / ctx.f30.f64));
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f28,21356(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21356);
	ctx.f28.f64 = double(temp.f32);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f30,f13,f0
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
loc_82A61868:
	// clrldi r11,r29,32
	ctx.r11.u64 = ctx.r29.u64 & 0xFFFFFFFF;
	// fmr f1,f28
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f28.f64;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fsubs f0,f0,f30
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f30.f64));
	// fadds f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f29.f64));
	// fmuls f0,f0,f31
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fmuls f0,f0,f25
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmuls f0,f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// fneg f2,f0
	ctx.f2.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// bl 0x82a60ae8
	ctx.lr = 0x82A6189C;
	sub_82A60AE8(ctx, base);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// stfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplw cr6,r29,r31
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r31.u32, ctx.xer);
	// blt cr6,0x82a61868
	if (ctx.cr6.lt) goto loc_82A61868;
	// b 0x82a619ac
	goto loc_82A619AC;
loc_82A618B4:
	// clrldi r11,r31,32
	ctx.r11.u64 = ctx.r31.u64 & 0xFFFFFFFF;
	// li r30,0
	ctx.r30.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f13,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f27,f13,f0
	ctx.f27.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fsubs f28,f27,f29
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// beq cr6,0x82a619ac
	if (ctx.cr6.eq) goto loc_82A619AC;
	// fdivs f26,f24,f28
	ctx.f26.f64 = double(float(ctx.f24.f64 / ctx.f28.f64));
	// mr r29,r28
	ctx.r29.u64 = ctx.r28.u64;
loc_82A618E4:
	// clrldi r11,r30,32
	ctx.r11.u64 = ctx.r30.u64 & 0xFFFFFFFF;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f31,f0
	ctx.f31.f64 = double(float(ctx.f0.f64));
	// fsubs f0,f31,f28
	ctx.f0.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// fmuls f0,f0,f26
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f26.f64));
	// fnmsubs f1,f0,f0,f24
	ctx.f1.f64 = double(float(-(ctx.f0.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// bl 0x82a60d18
	ctx.lr = 0x82A61908;
	sub_82A60D18(ctx, base);
	// fmuls f1,f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// bl 0x82a611f8
	ctx.lr = 0x82A61910;
	sub_82A611F8(ctx, base);
	// fmr f22,f1
	ctx.fpscr.disableFlushMode();
	ctx.f22.f64 = ctx.f1.f64;
	// fmr f1,f30
	ctx.f1.f64 = ctx.f30.f64;
	// bl 0x82a611f8
	ctx.lr = 0x82A6191C;
	sub_82A611F8(ctx, base);
	// fsubs f0,f31,f27
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// fdivs f31,f22,f1
	ctx.f31.f64 = double(float(ctx.f22.f64 / ctx.f1.f64));
	// fadds f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f29.f64));
	// fmuls f1,f0,f25
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// bl 0x82a61370
	ctx.lr = 0x82A61930;
	sub_82A61370(ctx, base);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// fmuls f0,f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// stfs f0,0(r29)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// cmplw cr6,r30,r31
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r31.u32, ctx.xer);
	// blt cr6,0x82a618e4
	if (ctx.cr6.lt) goto loc_82A618E4;
	// b 0x82a619ac
	goto loc_82A619AC;
loc_82A6194C:
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82a619ac
	if (ctx.cr6.eq) goto loc_82A619AC;
	// clrldi r11,r31,32
	ctx.r11.u64 = ctx.r31.u64 & 0xFFFFFFFF;
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f13,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f31,f13,f0
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
loc_82A61974:
	// clrldi r11,r29,32
	ctx.r11.u64 = ctx.r29.u64 & 0xFFFFFFFF;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fsubs f0,f0,f31
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f31.f64));
	// fadds f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f29.f64));
	// fmuls f1,f0,f25
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// bl 0x82a614c0
	ctx.lr = 0x82A61998;
	sub_82A614C0(ctx, base);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// stfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplw cr6,r29,r31
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r31.u32, ctx.xer);
	// blt cr6,0x82a61974
	if (ctx.cr6.lt) goto loc_82A61974;
loc_82A619AC:
	// cmpwi cr6,r26,0
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// beq cr6,0x82a619b8
	if (ctx.cr6.eq) goto loc_82A619B8;
	// stfs f23,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
loc_82A619B8:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a61a24
	if (ctx.cr6.eq) goto loc_82A61A24;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
loc_82A619C8:
	// fmr f0,f23
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f23.f64;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x82a61a18
	if (ctx.cr6.eq) goto loc_82A61A18;
	// rlwinm r8,r27,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
loc_82A619E0:
	// lfs f13,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// bne 0x82a619e0
	if (!ctx.cr0.eq) goto loc_82A619E0;
	// fdivs f0,f24,f0
	ctx.f0.f64 = double(float(ctx.f24.f64 / ctx.f0.f64));
	// mr r11,r9
	ctx.r11.u64 = ctx.r9.u64;
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
loc_82A61A00:
	// lfs f13,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f13,0(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// bne 0x82a61a00
	if (!ctx.cr0.eq) goto loc_82A61A00;
loc_82A61A18:
	// addic. r7,r7,-1
	ctx.xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82a619c8
	if (!ctx.cr0.eq) goto loc_82A619C8;
loc_82A61A24:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// addi r12,r1,-64
	ctx.r12.s64 = ctx.r1.s64 + -64;
	// bl 0x82d5c5ac
	ctx.lr = 0x82A61A30;
	__restfpr_22(ctx, base);
	// b 0x82d5c50c
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A61A38"))) PPC_WEAK_FUNC(sub_82A61A38);
PPC_FUNC_IMPL(__imp__sub_82A61A38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-784(r1)
	ea = -784 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r8
	ctx.r30.u64 = ctx.r8.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// bne cr6,0x82a61a74
	if (!ctx.cr6.eq) goto loc_82A61A74;
	// addi r11,r1,88
	ctx.r11.s64 = ctx.r1.s64 + 88;
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// std r10,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r10.u64);
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
loc_82A61A74:
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f0,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f9,21360(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21360);
	ctx.f9.f64 = double(temp.f32);
	// fcmpu cr6,f0,f9
	ctx.cr6.compare(ctx.f0.f64, ctx.f9.f64);
	// bge cr6,0x82a61a8c
	if (!ctx.cr6.lt) goto loc_82A61A8C;
	// fmr f0,f9
	ctx.f0.f64 = ctx.f9.f64;
loc_82A61A8C:
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f11,21344(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21344);
	ctx.f11.f64 = double(temp.f32);
	// fcmpu cr6,f0,f11
	ctx.cr6.compare(ctx.f0.f64, ctx.f11.f64);
	// ble cr6,0x82a61aa0
	if (!ctx.cr6.gt) goto loc_82A61AA0;
	// fmr f0,f11
	ctx.f0.f64 = ctx.f11.f64;
loc_82A61AA0:
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// lfs f12,16968(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16968);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// lfs f13,20396(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20396);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f13,f0,f12,f13
	ctx.f13.f64 = double(float(-(ctx.f0.f64 * ctx.f12.f64 - ctx.f13.f64)));
	// fmadds f10,f13,f0,f11
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f11.f64));
	// beq cr6,0x82a61b58
	if (ctx.cr6.eq) goto loc_82A61B58;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beq cr6,0x82a61b58
	if (ctx.cr6.eq) goto loc_82A61B58;
	// lfs f0,4(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f9
	ctx.cr6.compare(ctx.f0.f64, ctx.f9.f64);
	// bge cr6,0x82a61ad8
	if (!ctx.cr6.lt) goto loc_82A61AD8;
	// fmr f0,f9
	ctx.f0.f64 = ctx.f9.f64;
loc_82A61AD8:
	// fcmpu cr6,f0,f11
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f11.f64);
	// ble cr6,0x82a61ae4
	if (!ctx.cr6.gt) goto loc_82A61AE4;
	// fmr f0,f11
	ctx.f0.f64 = ctx.f11.f64;
loc_82A61AE4:
	// lis r11,-32248
	ctx.r11.s64 = -2113404928;
	// lfs f13,22272(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 22272);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// fmadds f12,f0,f12,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f12.f64 + ctx.f13.f64));
	// lfd f13,16960(r11)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16960);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// fcmpu cr6,f1,f13
	ctx.cr6.compare(ctx.f1.f64, ctx.f13.f64);
	// lfs f13,26980(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 26980);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f13,f12,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// ble cr6,0x82a61b1c
	if (!ctx.cr6.gt) goto loc_82A61B1C;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfd f0,16952(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16952);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// blt cr6,0x82a61b20
	if (ctx.cr6.lt) goto loc_82A61B20;
loc_82A61B1C:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82A61B20:
	// fcmpu cr6,f10,f11
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f10.f64, ctx.f11.f64);
	// bge cr6,0x82a61b2c
	if (!ctx.cr6.lt) goto loc_82A61B2C;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82A61B2C:
	// fcmpu cr6,f13,f11
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f13.f64, ctx.f11.f64);
	// bge cr6,0x82a61b38
	if (!ctx.cr6.lt) goto loc_82A61B38;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82A61B38:
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f0,21356(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21356);
	ctx.f0.f64 = double(temp.f32);
	// fdivs f0,f0,f1
	ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f1.f64));
	// fcmpu cr6,f0,f11
	ctx.cr6.compare(ctx.f0.f64, ctx.f11.f64);
	// blt cr6,0x82a61b50
	if (ctx.cr6.lt) goto loc_82A61B50;
	// fmr f0,f11
	ctx.f0.f64 = ctx.f11.f64;
loc_82A61B50:
	// fmuls f0,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// b 0x82a61b98
	goto loc_82A61B98;
loc_82A61B58:
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfd f0,16944(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16944);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// ble cr6,0x82a61b78
	if (!ctx.cr6.gt) goto loc_82A61B78;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfd f0,16936(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16936);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// blt cr6,0x82a61b7c
	if (ctx.cr6.lt) goto loc_82A61B7C;
loc_82A61B78:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82A61B7C:
	// fcmpu cr6,f10,f11
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f10.f64, ctx.f11.f64);
	// bge cr6,0x82a61b88
	if (!ctx.cr6.lt) goto loc_82A61B88;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82A61B88:
	// fdivs f0,f11,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f11.f64 / ctx.f1.f64));
	// fcmpu cr6,f0,f11
	ctx.cr6.compare(ctx.f0.f64, ctx.f11.f64);
	// blt cr6,0x82a61b98
	if (ctx.cr6.lt) goto loc_82A61B98;
	// fmr f0,f11
	ctx.f0.f64 = ctx.f11.f64;
loc_82A61B98:
	// fmuls f13,f0,f10
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// lis r11,-32244
	ctx.r11.s64 = -2113142784;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lfs f0,-16900(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -16900);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32248
	ctx.r11.s64 = -2113404928;
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f0,4(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 4, temp.u32);
	// lfs f0,24060(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24060);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,31
	ctx.r11.s64 = 2031616;
	// ori r10,r11,65535
	ctx.r10.u64 = ctx.r11.u64 | 65535;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f10,-29000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29000);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f0,f1,f0,f10
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f10.f64));
	// fctidz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r9
	PPC_STORE_U32(ctx.r9.u32, ctx.f0.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// stw r11,648(r31)
	PPC_STORE_U32(ctx.r31.u32 + 648, ctx.r11.u32);
	// ble cr6,0x82a61be8
	if (!ctx.cr6.gt) goto loc_82A61BE8;
	// stw r10,648(r31)
	PPC_STORE_U32(ctx.r31.u32 + 648, ctx.r10.u32);
loc_82A61BE8:
	// lfs f1,4(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	ctx.f1.f64 = double(temp.f32);
	// cmpwi cr6,r5,2
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 2, ctx.xer);
	// stw r30,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r30.u32);
	// bne cr6,0x82a61c34
	if (!ctx.cr6.eq) goto loc_82A61C34;
	// lfs f0,8(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f9
	ctx.cr6.compare(ctx.f0.f64, ctx.f9.f64);
	// bge cr6,0x82a61c08
	if (!ctx.cr6.lt) goto loc_82A61C08;
	// fmr f0,f9
	ctx.f0.f64 = ctx.f9.f64;
loc_82A61C08:
	// fcmpu cr6,f0,f11
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f11.f64);
	// ble cr6,0x82a61c14
	if (!ctx.cr6.gt) goto loc_82A61C14;
	// fmr f0,f11
	ctx.f0.f64 = ctx.f11.f64;
loc_82A61C14:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f13,-18724(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18724);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f12,-11764(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11764);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// fmadds f12,f0,f13,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// lfs f13,-4324(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4324);
	ctx.f13.f64 = double(temp.f32);
	// b 0x82a61cb4
	goto loc_82A61CB4;
loc_82A61C34:
	// cmpwi cr6,r5,3
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 3, ctx.xer);
	// bne cr6,0x82a61c74
	if (!ctx.cr6.eq) goto loc_82A61C74;
	// lfs f0,8(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f9
	ctx.cr6.compare(ctx.f0.f64, ctx.f9.f64);
	// bge cr6,0x82a61c4c
	if (!ctx.cr6.lt) goto loc_82A61C4C;
	// fmr f0,f9
	ctx.f0.f64 = ctx.f9.f64;
loc_82A61C4C:
	// fcmpu cr6,f0,f11
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f11.f64);
	// ble cr6,0x82a61c58
	if (!ctx.cr6.gt) goto loc_82A61C58;
	// fmr f0,f11
	ctx.f0.f64 = ctx.f11.f64;
loc_82A61C58:
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// lfs f13,-3204(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -3204);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lfs f12,29872(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29872);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f0,f13,f12
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// fmadds f2,f13,f0,f10
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f10.f64));
	// b 0x82a61cc4
	goto loc_82A61CC4;
loc_82A61C74:
	// cmpwi cr6,r5,5
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 5, ctx.xer);
	// bne cr6,0x82a61cbc
	if (!ctx.cr6.eq) goto loc_82A61CBC;
	// lfs f0,8(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f9
	ctx.cr6.compare(ctx.f0.f64, ctx.f9.f64);
	// bge cr6,0x82a61c8c
	if (!ctx.cr6.lt) goto loc_82A61C8C;
	// fmr f0,f9
	ctx.f0.f64 = ctx.f9.f64;
loc_82A61C8C:
	// fcmpu cr6,f0,f11
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f11.f64);
	// ble cr6,0x82a61c98
	if (!ctx.cr6.gt) goto loc_82A61C98;
	// fmr f0,f11
	ctx.f0.f64 = ctx.f11.f64;
loc_82A61C98:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f13,-19000(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -19000);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f12,16664(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16664);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fmadds f12,f0,f13,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// lfs f13,-11956(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11956);
	ctx.f13.f64 = double(temp.f32);
loc_82A61CB4:
	// fmadds f2,f12,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// b 0x82a61cc4
	goto loc_82A61CC4;
loc_82A61CBC:
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f2,21348(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21348);
	ctx.f2.f64 = double(temp.f32);
loc_82A61CC4:
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// li r3,7
	ctx.r3.s64 = 7;
	// bne cr6,0x82a61cd4
	if (!ctx.cr6.eq) goto loc_82A61CD4;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
loc_82A61CD4:
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82a615b8
	ctx.lr = 0x82A61CE8;
	sub_82A615B8(ctx, base);
	// li r6,16
	ctx.r6.s64 = 16;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r31,8
	ctx.r4.s64 = ctx.r31.s64 + 8;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82a60da0
	ctx.lr = 0x82A61CFC;
	sub_82A60DA0(ctx, base);
	// addi r1,r1,784
	ctx.r1.s64 = ctx.r1.s64 + 784;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A61D18"))) PPC_WEAK_FUNC(sub_82A61D18);
PPC_FUNC_IMPL(__imp__sub_82A61D18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82A61D20;
	__savegprlr_14(ctx, base);
	// stfd f30,-168(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -168, ctx.f30.u64);
	// stfd f31,-160(r1)
	PPC_STORE_U64(ctx.r1.u32 + -160, ctx.f31.u64);
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// mr r26,r7
	ctx.r26.u64 = ctx.r7.u64;
	// mr r21,r8
	ctx.r21.u64 = ctx.r8.u64;
	// mr r15,r9
	ctx.r15.u64 = ctx.r9.u64;
	// mr r14,r10
	ctx.r14.u64 = ctx.r10.u64;
	// bl 0x8308b224
	ctx.lr = 0x82A61D54;
	__imp__VdQueryVideoMode(ctx, base);
	// lwz r29,120(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// cntlzw r11,r29
	ctx.r11.u64 = ctx.r29.u32 == 0 ? 32 : __builtin_clz(ctx.r29.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 ^ 1;
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// bne cr6,0x82a61d7c
	if (!ctx.cr6.eq) goto loc_82A61D7C;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82a61d7c
	if (!ctx.cr6.eq) goto loc_82A61D7C;
	// mr r30,r21
	ctx.r30.u64 = ctx.r21.u64;
loc_82A61D7C:
	// lwz r20,420(r1)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	// rlwinm r25,r27,16,16,31
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 16) & 0xFFFF;
	// lwz r18,21548(r28)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r28.u32 + 21548);
	// rlwinm r19,r31,16,16,31
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 16) & 0xFFFF;
	// lwz r16,21544(r28)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r28.u32 + 21544);
	// clrlwi r17,r31,16
	ctx.r17.u64 = ctx.r31.u32 & 0xFFFF;
	// rlwinm r28,r30,16,16,31
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 16) & 0xFFFF;
	// clrlwi r24,r30,16
	ctx.r24.u64 = ctx.r30.u32 & 0xFFFF;
	// lwz r11,0(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	// clrlwi r27,r27,16
	ctx.r27.u64 = ctx.r27.u32 & 0xFFFF;
	// rlwinm r23,r26,16,16,31
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 16) & 0xFFFF;
	// clrlwi r22,r26,16
	ctx.r22.u64 = ctx.r26.u32 & 0xFFFF;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a61dd8
	if (!ctx.cr6.eq) goto loc_82A61DD8;
	// cmplw cr6,r28,r23
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r23.u32, ctx.xer);
	// bne cr6,0x82a61dc4
	if (!ctx.cr6.eq) goto loc_82A61DC4;
	// li r11,7
	ctx.r11.s64 = 7;
	// b 0x82a61dd4
	goto loc_82A61DD4;
loc_82A61DC4:
	// subfc r11,r23,r28
	ctx.xer.ca = ctx.r28.u32 >= ctx.r23.u32;
	ctx.r11.s64 = ctx.r28.s64 - ctx.r23.s64;
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r11,r11,5
	ctx.r11.s64 = ctx.r11.s64 + 5;
loc_82A61DD4:
	// stw r11,0(r20)
	PPC_STORE_U32(ctx.r20.u32 + 0, ctx.r11.u32);
loc_82A61DD8:
	// lwz r11,0(r15)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a61e1c
	if (!ctx.cr6.eq) goto loc_82A61E1C;
	// divwu r11,r22,r10
	ctx.r11.u32 = ctx.r22.u32 / ctx.r10.u32;
	// twllei r10,0
	// cmplw cr6,r24,r11
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82a61e08
	if (!ctx.cr6.eq) goto loc_82A61E08;
	// subfic r11,r29,0
	ctx.xer.ca = ctx.r29.u32 <= 0;
	ctx.r11.s64 = 0 - ctx.r29.s64;
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,7
	ctx.r11.s64 = ctx.r11.s64 + 7;
	// b 0x82a61e18
	goto loc_82A61E18;
loc_82A61E08:
	// subfc r11,r11,r24
	ctx.xer.ca = ctx.r24.u32 >= ctx.r11.u32;
	ctx.r11.s64 = ctx.r24.s64 - ctx.r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r11,r11,5
	ctx.r11.s64 = ctx.r11.s64 + 5;
loc_82A61E18:
	// stw r11,0(r15)
	PPC_STORE_U32(ctx.r15.u32 + 0, ctx.r11.u32);
loc_82A61E1C:
	// clrldi r9,r23,32
	ctx.r9.u64 = ctx.r23.u64 & 0xFFFFFFFF;
	// clrldi r11,r28,32
	ctx.r11.u64 = ctx.r28.u64 & 0xFFFFFFFF;
	// std r9,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r9.u64);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fdivs f30,f0,f13
	ctx.f30.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// lfs f0,-11956(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11956);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfd f13,16992(r11)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16992);
	// fcmpu cr6,f30,f0
	ctx.cr6.compare(ctx.f30.f64, ctx.f0.f64);
	// blt cr6,0x82a61e6c
	if (ctx.cr6.lt) goto loc_82A61E6C;
	// fcmpu cr6,f30,f13
	ctx.cr6.compare(ctx.f30.f64, ctx.f13.f64);
	// bgt cr6,0x82a61e6c
	if (ctx.cr6.gt) goto loc_82A61E6C;
	// fmr f30,f0
	ctx.f30.f64 = ctx.f0.f64;
loc_82A61E6C:
	// clrldi r11,r24,32
	ctx.r11.u64 = ctx.r24.u64 & 0xFFFFFFFF;
	// clrldi r9,r22,32
	ctx.r9.u64 = ctx.r22.u64 & 0xFFFFFFFF;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// std r9,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r9.u64);
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f11,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// lfd f12,88(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// lfd f10,96(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f10,f10
	ctx.f10.f64 = double(ctx.f10.s64);
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// frsp f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64));
	// fmuls f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fdivs f31,f12,f10
	ctx.f31.f64 = double(float(ctx.f12.f64 / ctx.f10.f64));
	// fcmpu cr6,f31,f0
	ctx.cr6.compare(ctx.f31.f64, ctx.f0.f64);
	// blt cr6,0x82a61ec8
	if (ctx.cr6.lt) goto loc_82A61EC8;
	// fcmpu cr6,f31,f13
	ctx.cr6.compare(ctx.f31.f64, ctx.f13.f64);
	// bgt cr6,0x82a61ec8
	if (ctx.cr6.gt) goto loc_82A61EC8;
	// fmr f31,f0
	ctx.f31.f64 = ctx.f0.f64;
	// b 0x82a61f0c
	goto loc_82A61F0C;
loc_82A61EC8:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f13,-18724(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18724);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f31,f13
	ctx.cr6.compare(ctx.f31.f64, ctx.f13.f64);
	// blt cr6,0x82a61ee8
	if (ctx.cr6.lt) goto loc_82A61EE8;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfd f0,16984(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16984);
	// fcmpu cr6,f31,f0
	ctx.cr6.compare(ctx.f31.f64, ctx.f0.f64);
	// ble cr6,0x82a61f08
	if (!ctx.cr6.gt) goto loc_82A61F08;
loc_82A61EE8:
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f13,21356(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21356);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f31,f13
	ctx.cr6.compare(ctx.f31.f64, ctx.f13.f64);
	// blt cr6,0x82a61f0c
	if (ctx.cr6.lt) goto loc_82A61F0C;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfd f0,16952(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16952);
	// fcmpu cr6,f31,f0
	ctx.cr6.compare(ctx.f31.f64, ctx.f0.f64);
	// bgt cr6,0x82a61f0c
	if (ctx.cr6.gt) goto loc_82A61F0C;
loc_82A61F08:
	// fmr f31,f13
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = ctx.f13.f64;
loc_82A61F0C:
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r9,140(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// twllei r9,0
	// lwz r11,2152(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2152);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// divwu r11,r10,r9
	ctx.r11.u32 = ctx.r10.u32 / ctx.r9.u32;
	// rlwinm r26,r11,1,0,30
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplwi cr6,r26,10
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 10, ctx.xer);
	// ble cr6,0x82a61f34
	if (!ctx.cr6.gt) goto loc_82A61F34;
	// li r26,10
	ctx.r26.s64 = 10;
loc_82A61F34:
	// li r11,7680
	ctx.r11.s64 = 7680;
	// twllei r28,0
	// divwu r11,r11,r28
	ctx.r11.u32 = ctx.r11.u32 / ctx.r28.u32;
	// addi r30,r11,-1
	ctx.r30.s64 = ctx.r11.s64 + -1;
	// li r11,6
	ctx.r11.s64 = 6;
	// cmplwi cr6,r30,6
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 6, ctx.xer);
	// bgt cr6,0x82a61f54
	if (ctx.cr6.gt) goto loc_82A61F54;
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
loc_82A61F54:
	// clrldi r9,r9,32
	ctx.r9.u64 = ctx.r9.u64 & 0xFFFFFFFF;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// std r9,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r9.u64);
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// lfd f0,96(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f12,f0
	ctx.f12.f64 = double(float(ctx.f0.f64));
	// frsp f0,f13
	ctx.f0.f64 = double(float(ctx.f13.f64));
	// fmuls f13,f12,f30
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fdivs f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// fctidz f12,f12
	ctx.f12.s64 = (ctx.f12.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&ctx.f12.f64));
	// stfiwx f12,0,r8
	PPC_STORE_U32(ctx.r8.u32, ctx.f12.u32);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82a61fac
	if (!ctx.cr6.lt) goto loc_82A61FAC;
	// cmplwi cr6,r30,6
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 6, ctx.xer);
	// ble cr6,0x82a61fc0
	if (!ctx.cr6.gt) goto loc_82A61FC0;
	// li r30,6
	ctx.r30.s64 = 6;
	// b 0x82a61fc0
	goto loc_82A61FC0;
loc_82A61FAC:
	// fdivs f0,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// fctidz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// lwz r30,80(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82A61FC0:
	// lwz r31,436(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	// li r5,1408
	ctx.r5.s64 = 1408;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d5cb60
	ctx.lr = 0x82A61FD4;
	sub_82D5CB60(ctx, base);
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r5,0(r15)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	// mr r6,r14
	ctx.r6.u64 = ctx.r14.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r30,r31,652
	ctx.r30.s64 = ctx.r31.s64 + 652;
	// bl 0x82a61a38
	ctx.lr = 0x82A61FF8;
	sub_82A61A38(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// lwz r5,0(r20)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r6,428(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f30.f64;
	// bl 0x82a61a38
	ctx.lr = 0x82A62018;
	sub_82A61A38(ctx, base);
	// addi r6,r28,3
	ctx.r6.s64 = ctx.r28.s64 + 3;
	// rlwinm r11,r21,16,16,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r21.u32 | (ctx.r21.u64 << 32), 16) & 0xFFFF;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// rlwinm r5,r6,30,2,31
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 30) & 0x3FFFFFFF;
	// lwz r8,648(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 648);
	// clrlwi r6,r21,16
	ctx.r6.u64 = ctx.r21.u32 & 0xFFFF;
	// addi r10,r11,31
	ctx.r10.s64 = ctx.r11.s64 + 31;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// li r11,0
	ctx.r11.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// rlwinm r6,r6,0,0,30
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFE;
	// subf r26,r23,r18
	ctx.r26.s64 = ctx.r18.s64 - ctx.r23.s64;
	// cntlzw r4,r29
	ctx.r4.u64 = ctx.r29.u32 == 0 ? 32 : __builtin_clz(ctx.r29.u32);
	// stw r11,1348(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1348, ctx.r11.u32);
	// subf r3,r22,r16
	ctx.r3.s64 = ctx.r16.s64 - ctx.r22.s64;
	// stw r7,1360(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1360, ctx.r7.u32);
	// addi r5,r5,-1
	ctx.r5.s64 = ctx.r5.s64 + -1;
	// lwz r7,0(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// clrlwi r22,r17,20
	ctx.r22.u64 = ctx.r17.u32 & 0xFFF;
	// stw r6,1344(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1344, ctx.r6.u32);
	// addi r6,r9,-1
	ctx.r6.s64 = ctx.r9.s64 + -1;
	// addi r23,r7,-1
	ctx.r23.s64 = ctx.r7.s64 + -1;
	// stw r11,1332(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1332, ctx.r11.u32);
	// rlwinm r7,r4,27,31,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x1;
	// stw r11,1336(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1336, ctx.r11.u32);
	// rlwimi r6,r23,8,20,23
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r23.u32, 8) & 0xF00) | (ctx.r6.u64 & 0xFFFFFFFFFFFFF0FF);
	// rlwinm r4,r28,16,4,15
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 16) & 0xFFF0000;
	// clrlwi r28,r24,20
	ctx.r28.u64 = ctx.r24.u32 & 0xFFF;
	// rlwinm r24,r19,16,4,15
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r19.u32 | (ctx.r19.u64 << 32), 16) & 0xFFF0000;
	// or r4,r4,r28
	ctx.r4.u64 = ctx.r4.u64 | ctx.r28.u64;
	// clrlwi r5,r5,22
	ctx.r5.u64 = ctx.r5.u32 & 0x3FF;
	// or r28,r24,r22
	ctx.r28.u64 = ctx.r24.u64 | ctx.r22.u64;
	// subf r3,r27,r3
	ctx.r3.s64 = ctx.r3.s64 - ctx.r27.s64;
	// subf r26,r25,r26
	ctx.r26.s64 = ctx.r26.s64 - ctx.r25.s64;
	// stw r4,1356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1356, ctx.r4.u32);
	// rlwinm r10,r10,0,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFE0;
	// stw r5,1404(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1404, ctx.r5.u32);
	// clrlwi r5,r3,20
	ctx.r5.u64 = ctx.r3.u32 & 0xFFF;
	// stw r28,1352(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1352, ctx.r28.u32);
	// clrlwi r4,r27,20
	ctx.r4.u64 = ctx.r27.u32 & 0xFFF;
	// clrlwi r3,r25,20
	ctx.r3.u64 = ctx.r25.u32 & 0xFFF;
	// clrlwi r28,r26,20
	ctx.r28.u64 = ctx.r26.u32 & 0xFFF;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// stw r10,1340(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1340, ctx.r10.u32);
	// stw r10,1320(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1320, ctx.r10.u32);
	// stw r4,1304(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1304, ctx.r4.u32);
	// andi. r6,r6,3847
	ctx.r6.u64 = ctx.r6.u64 & 3847;
	ctx.cr0.compare<int32_t>(ctx.r6.s32, 0, ctx.xer);
	// stw r5,1308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1308, ctx.r5.u32);
	// stw r3,1312(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1312, ctx.r3.u32);
	// stw r28,1316(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1316, ctx.r28.u32);
	// stw r6,1364(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1364, ctx.r6.u32);
	// lwz r10,648(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 648);
	// rlwinm r10,r10,5,6,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0x3FFFFE0;
	// stw r10,1376(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1376, ctx.r10.u32);
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// slw r7,r8,r7
	ctx.r7.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r7.u8 & 0x3F));
	// clrlwi r7,r7,6
	ctx.r7.u64 = ctx.r7.u32 & 0x3FFFFFF;
	// lfs f11,16976(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16976);
	ctx.f11.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfs f0,-28012(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28012);
	ctx.f0.f64 = double(temp.f32);
	// lis r10,256
	ctx.r10.s64 = 16777216;
	// stw r11,1372(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1372, ctx.r11.u32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stw r7,1392(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1392, ctx.r7.u32);
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// stw r10,1388(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1388, ctx.r10.u32);
	// lwz r11,648(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 648);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r11.u64);
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// lfd f13,96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// lfd f12,88(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// fmadds f12,f13,f11,f12
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 + ctx.f12.f64));
	// lfs f13,21344(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21344);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fadds f10,f12,f13
	ctx.f10.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfs f12,-29000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29000);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f10,f10,f0,f12
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f12.f64));
	// fctidz f10,f10
	ctx.f10.s64 = (ctx.f10.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&ctx.f10.f64));
	// stfiwx f10,0,r6
	PPC_STORE_U32(ctx.r6.u32, ctx.f10.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r11,r11,9,12,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 9) & 0xFFE00;
	// stw r11,1380(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1380, ctx.r11.u32);
	// beq cr6,0x82a62200
	if (ctx.cr6.eq) goto loc_82A62200;
	// clrldi r10,r8,32
	ctx.r10.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// clrldi r9,r9,32
	ctx.r9.u64 = ctx.r9.u64 & 0xFFFFFFFF;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// std r10,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r10.u64);
	// std r9,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r9.u64);
	// lfs f9,25576(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 25576);
	ctx.f9.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f8,16972(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16972);
	ctx.f8.f64 = double(temp.f32);
	// lfd f11,96(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// lfd f10,88(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// fcfid f10,f10
	ctx.f10.f64 = double(ctx.f10.s64);
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// frsp f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64));
	// fmadds f9,f11,f9,f10
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f9.f64 + ctx.f10.f64));
	// fmadds f11,f11,f8,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 + ctx.f10.f64));
	// fadds f10,f9,f13
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// fadds f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fmadds f11,f10,f0,f12
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f12.f64));
	// fmadds f0,f13,f0,f12
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f12.f64));
	// fctidz f13,f11
	ctx.f13.s64 = (ctx.f11.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&ctx.f11.f64));
	// stfiwx f13,0,r8
	PPC_STORE_U32(ctx.r8.u32, ctx.f13.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// fctidz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&ctx.f0.f64));
	// rlwinm r11,r11,9,13,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 9) & 0x7FE00;
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, ctx.f0.u32);
	// stw r11,1396(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1396, ctx.r11.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r11,r11,9,13,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 9) & 0x7FE00;
	// stw r11,1400(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1400, ctx.r11.u32);
	// b 0x82a6224c
	goto loc_82A6224C;
loc_82A62200:
	// clrldi r11,r8,32
	ctx.r11.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// clrldi r10,r9,32
	ctx.r10.u64 = ctx.r9.u64 & 0xFFFFFFFF;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r11.u64);
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// lfd f10,96(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// lfd f9,88(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f10,f10
	ctx.f10.f64 = double(ctx.f10.s64);
	// fcfid f9,f9
	ctx.f9.f64 = double(ctx.f9.s64);
	// frsp f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64));
	// frsp f9,f9
	ctx.f9.f64 = double(float(ctx.f9.f64));
	// fmadds f11,f10,f11,f9
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 + ctx.f9.f64));
	// fadds f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fmadds f0,f13,f0,f12
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f12.f64));
	// fctidz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r9
	PPC_STORE_U32(ctx.r9.u32, ctx.f0.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r11,r11,9,13,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 9) & 0x7FE00;
	// stw r11,1396(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1396, ctx.r11.u32);
loc_82A6224C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// lfd f30,-168(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -168);
	// lfd f31,-160(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A62260"))) PPC_WEAK_FUNC(sub_82A62260);
PPC_FUNC_IMPL(__imp__sub_82A62260) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82A62268;
	__savegprlr_26(ctx, base);
	// stwu r1,-2464(r1)
	ea = -2464 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r7,r1,128
	ctx.r7.s64 = ctx.r1.s64 + 128;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82a60748
	ctx.lr = 0x82A62280;
	sub_82A60748(ctx, base);
	// lwz r11,136(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lwz r6,128(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r5,132(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// subf r9,r6,r11
	ctx.r9.s64 = ctx.r11.s64 - ctx.r6.s64;
	// lwz r11,140(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// lwz r10,21548(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21548);
	// lwz r8,21540(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21540);
	// subf r3,r5,r11
	ctx.r3.s64 = ctx.r11.s64 - ctx.r5.s64;
	// lwz r11,144(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x82a622dc
	if (ctx.cr6.eq) goto loc_82A622DC;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a622c0
	if (ctx.cr6.lt) goto loc_82A622C0;
	// cmplw cr6,r11,r8
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r8.u32, ctx.xer);
	// bgt cr6,0x82a622c0
	if (ctx.cr6.gt) goto loc_82A622C0;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
loc_82A622C0:
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a622dc
	if (ctx.cr6.lt) goto loc_82A622DC;
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// bgt cr6,0x82a622dc
	if (ctx.cr6.gt) goto loc_82A622DC;
	// subf r8,r11,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r11.s64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// rlwinm r6,r8,31,1,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 31) & 0x7FFFFFFF;
loc_82A622DC:
	// subf r7,r11,r10
	ctx.r7.s64 = ctx.r10.s64 - ctx.r11.s64;
	// lwz r10,148(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// lwz r8,21544(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21544);
	// clrlwi r4,r30,16
	ctx.r4.u64 = ctx.r30.u32 & 0xFFFF;
	// rlwinm r27,r11,16,0,15
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 16) & 0xFFFF0000;
	// subf r30,r10,r8
	ctx.r30.s64 = ctx.r8.s64 - ctx.r10.s64;
	// rlwinm r8,r7,31,1,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r7,r30,31,1,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 31) & 0x7FFFFFFF;
	// clrlwi r30,r29,16
	ctx.r30.u64 = ctx.r29.u32 & 0xFFFF;
	// clrlwi r11,r9,16
	ctx.r11.u64 = ctx.r9.u32 & 0xFFFF;
	// rlwimi r30,r4,16,0,15
	ctx.r30.u64 = (__builtin_rotateleft32(ctx.r4.u32, 16) & 0xFFFF0000) | (ctx.r30.u64 & 0xFFFFFFFF0000FFFF);
	// clrlwi r4,r5,16
	ctx.r4.u64 = ctx.r5.u32 & 0xFFFF;
	// clrlwi r5,r3,16
	ctx.r5.u64 = ctx.r3.u32 & 0xFFFF;
	// clrlwi r28,r10,16
	ctx.r28.u64 = ctx.r10.u32 & 0xFFFF;
	// rlwimi r5,r11,16,0,15
	ctx.r5.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r5.u64 & 0xFFFFFFFF0000FFFF);
	// lwz r11,152(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// clrlwi r10,r6,16
	ctx.r10.u64 = ctx.r6.u32 & 0xFFFF;
	// addi r9,r1,992
	ctx.r9.s64 = ctx.r1.s64 + 992;
	// addi r6,r1,172
	ctx.r6.s64 = ctx.r1.s64 + 172;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
	// clrlwi r29,r7,16
	ctx.r29.u64 = ctx.r7.u32 & 0xFFFF;
	// lwz r11,168(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// rlwimi r4,r10,16,0,15
	ctx.r4.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r4.u64 & 0xFFFFFFFF0000FFFF);
	// stw r9,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r9.u32);
	// addi r10,r1,156
	ctx.r10.s64 = ctx.r1.s64 + 156;
	// stw r6,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r6.u32);
	// addi r9,r1,116
	ctx.r9.s64 = ctx.r1.s64 + 116;
	// stw r3,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r3.u32);
	// or r7,r28,r27
	ctx.r7.u64 = ctx.r28.u64 | ctx.r27.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
	// clrlwi r11,r8,16
	ctx.r11.u64 = ctx.r8.u32 & 0xFFFF;
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// rlwimi r29,r11,16,0,15
	ctx.r29.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r29.u64 & 0xFFFFFFFF0000FFFF);
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// bl 0x82a61d18
	ctx.lr = 0x82A62370;
	sub_82A61D18(ctx, base);
	// lis r5,-32768
	ctx.r5.s64 = -2147483648;
	// li r4,800
	ctx.r4.s64 = 800;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x8308b0a4
	ctx.lr = 0x82A62380;
	__imp__RtlFillMemoryUlong(ctx, base);
	// li r4,220
	ctx.r4.s64 = 220;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50f88
	ctx.lr = 0x82A6238C;
	sub_82A50F88(ctx, base);
	// lwz r11,128(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r10,136(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// addi r6,r1,172
	ctx.r6.s64 = ctx.r1.s64 + 172;
	// lwz r8,140(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// addi r7,r1,992
	ctx.r7.s64 = ctx.r1.s64 + 992;
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
	// lwz r10,132(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// subf r8,r10,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r10.s64;
	// clrlwi r26,r10,16
	ctx.r26.u64 = ctx.r10.u32 & 0xFFFF;
	// stw r6,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r6.u32);
	// clrlwi r10,r9,16
	ctx.r10.u64 = ctx.r9.u32 & 0xFFFF;
	// stw r7,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r7.u32);
	// li r9,200
	ctx.r9.s64 = 200;
	// clrlwi r4,r8,16
	ctx.r4.u64 = ctx.r8.u32 & 0xFFFF;
	// addi r8,r1,192
	ctx.r8.s64 = ctx.r1.s64 + 192;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwimi r26,r11,16,0,15
	ctx.r26.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r26.u64 & 0xFFFFFFFF0000FFFF);
	// stw r9,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r9.u32);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// or r6,r5,r27
	ctx.r6.u64 = ctx.r5.u64 | ctx.r27.u64;
	// rlwimi r4,r10,16,0,15
	ctx.r4.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r4.u64 & 0xFFFFFFFF0000FFFF);
	// stw r8,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r8.u32);
	// addi r9,r1,156
	ctx.r9.s64 = ctx.r1.s64 + 156;
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// lwz r8,116(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x8308b304
	ctx.lr = 0x82A62404;
	__imp__VdInitializeScalerCommandBuffer(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r3,r28,4
	ctx.r3.s64 = ctx.r28.s64 + 4;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82d5c630
	ctx.lr = 0x82A6241C;
	sub_82D5C630(ctx, base);
	// add r11,r30,r28
	ctx.r11.u64 = ctx.r30.u64 + ctx.r28.u64;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// addi r1,r1,2464
	ctx.r1.s64 = ctx.r1.s64 + 2464;
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A62430"))) PPC_WEAK_FUNC(sub_82A62430);
PPC_FUNC_IMPL(__imp__sub_82A62430) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A62438;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,14828(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14828);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a62470
	if (ctx.cr0.eq) goto loc_82A62470;
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// lwz r11,36(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// rlwinm r10,r10,2,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0x2;
	// clrlwi r9,r11,19
	ctx.r9.u64 = ctx.r11.u32 & 0x1FFF;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// rlwinm r11,r11,19,19,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 19) & 0x1FFF;
	// add r30,r9,r10
	ctx.r30.u64 = ctx.r9.u64 + ctx.r10.u64;
	// add r29,r11,r10
	ctx.r29.u64 = ctx.r11.u64 + ctx.r10.u64;
	// b 0x82a62478
	goto loc_82A62478;
loc_82A62470:
	// lwz r30,13544(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13544);
	// lwz r29,13548(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13548);
loc_82A62478:
	// addi r28,r31,13724
	ctx.r28.s64 = ctx.r31.s64 + 13724;
	// li r5,56
	ctx.r5.s64 = 56;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82d5c630
	ctx.lr = 0x82A62488;
	sub_82D5C630(ctx, base);
	// lbz r11,10942(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10942);
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// ori r11,r11,16
	ctx.r11.u64 = ctx.r11.u64 | 16;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stb r11,10942(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10942, ctx.r11.u8);
	// bl 0x82a608e8
	ctx.lr = 0x82A624A8;
	sub_82A608E8(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A624B0"))) PPC_WEAK_FUNC(sub_82A624B0);
PPC_FUNC_IMPL(__imp__sub_82A624B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// bl 0x82a60870
	ctx.lr = 0x82A624C4;
	sub_82A60870(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82a62430
	ctx.lr = 0x82A624CC;
	sub_82A62430(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A624E0"))) PPC_WEAK_FUNC(sub_82A624E0);
PPC_FUNC_IMPL(__imp__sub_82A624E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A624E8;
	__savegprlr_28(ctx, base);
	// stwu r1,-2192(r1)
	ea = -2192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// bl 0x8308b344
	ctx.lr = 0x82A624FC;
	__imp__KeEnterCriticalRegion(ctx, base);
	// lis r28,-32256
	ctx.r28.s64 = -2113929216;
	// lwz r3,2172(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2172);
	// bl 0x8308acb4
	ctx.lr = 0x82A62508;
	__imp__RtlEnterCriticalSection(ctx, base);
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq cr6,0x82a62518
	if (ctx.cr6.eq) goto loc_82A62518;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8308b334
	ctx.lr = 0x82A62518;
	__imp__VdRetrainEDRAMWorker(ctx, base);
loc_82A62518:
	// li r11,0
	ctx.r11.s64 = 0;
	// li r8,2048
	ctx.r8.s64 = 2048;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// li r5,4096
	ctx.r5.s64 = 4096;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// bl 0x8308b324
	ctx.lr = 0x82A62540;
	__imp__VdRetrainEDRAM(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a625b0
	if (ctx.cr0.eq) goto loc_82A625B0;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82a62558
	if (!ctx.cr6.eq) goto loc_82A62558;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50ff0
	ctx.lr = 0x82A62558;
	sub_82A50FF0(ctx, base);
loc_82A62558:
	// li r4,4096
	ctx.r4.s64 = 4096;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50f88
	ctx.lr = 0x82A62564;
	sub_82A50F88(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// li r8,2048
	ctx.r8.s64 = 2048;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// li r5,4096
	ctx.r5.s64 = 4096;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// bl 0x8308b324
	ctx.lr = 0x82A6258C;
	__imp__VdRetrainEDRAM(ctx, base);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r11,r11,-4
	ctx.r11.s64 = ctx.r11.s64 + -4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// bl 0x82a50ff0
	ctx.lr = 0x82A625A8;
	sub_82A50FF0(ctx, base);
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82a62558
	if (!ctx.cr6.eq) goto loc_82A62558;
loc_82A625B0:
	// lwz r3,2172(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2172);
	// bl 0x8308acc4
	ctx.lr = 0x82A625B8;
	__imp__RtlLeaveCriticalSection(ctx, base);
	// bl 0x8308b314
	ctx.lr = 0x82A625BC;
	__imp__KeLeaveCriticalRegion(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,2192
	ctx.r1.s64 = ctx.r1.s64 + 2192;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A625C8"))) PPC_WEAK_FUNC(sub_82A625C8);
PPC_FUNC_IMPL(__imp__sub_82A625C8) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-31980
	ctx.r10.s64 = -2095841280;
	// li r11,1
	ctx.r11.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r11,27343(r10)
	PPC_STORE_U8(ctx.r10.u32 + 27343, ctx.r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A625E0"))) PPC_WEAK_FUNC(sub_82A625E0);
PPC_FUNC_IMPL(__imp__sub_82A625E0) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-31980
	ctx.r10.s64 = -2095841280;
	// li r11,0
	ctx.r11.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r11,27343(r10)
	PPC_STORE_U8(ctx.r10.u32 + 27343, ctx.r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A625F8"))) PPC_WEAK_FUNC(sub_82A625F8);
PPC_FUNC_IMPL(__imp__sub_82A625F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x82d5d4f0
	ctx.lr = 0x82A62608;
	sub_82D5D4F0(ctx, base);
	// lis r11,1
	ctx.r11.s64 = 65536;
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
	// subf r11,r3,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r3.s64;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A62630"))) PPC_WEAK_FUNC(sub_82A62630);
PPC_FUNC_IMPL(__imp__sub_82A62630) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82d5d4f0
	ctx.lr = 0x82A62648;
	sub_82D5D4F0(ctx, base);
	// lis r11,2
	ctx.r11.s64 = 131072;
	// ori r11,r11,32728
	ctx.r11.u64 = ctx.r11.u64 | 32728;
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82a62664
	if (!ctx.cr6.lt) goto loc_82A62664;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d5d4f0
	ctx.lr = 0x82A62660;
	sub_82D5D4F0(ctx, base);
	// extsw r11,r3
	ctx.r11.s64 = ctx.r3.s32;
loc_82A62664:
	// lis r10,-31988
	ctx.r10.s64 = -2096365568;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,-26252(r10)
	PPC_STORE_U32(ctx.r10.u32 + -26252, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A62688"))) PPC_WEAK_FUNC(sub_82A62688);
PPC_FUNC_IMPL(__imp__sub_82A62688) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31980
	ctx.r11.s64 = -2095841280;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r31,r11,27080
	ctx.r31.s64 = ctx.r11.s64 + 27080;
	// li r5,260
	ctx.r5.s64 = 260;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d5e188
	ctx.lr = 0x82A626B0;
	sub_82D5E188(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r11,262(r31)
	PPC_STORE_U8(ctx.r31.u32 + 262, ctx.r11.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A626D0"))) PPC_WEAK_FUNC(sub_82A626D0);
PPC_FUNC_IMPL(__imp__sub_82A626D0) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-31980
	ctx.r10.s64 = -2095841280;
	// li r11,1
	ctx.r11.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r11,27341(r10)
	PPC_STORE_U8(ctx.r10.u32 + 27341, ctx.r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A626E8"))) PPC_WEAK_FUNC(sub_82A626E8);
PPC_FUNC_IMPL(__imp__sub_82A626E8) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-31980
	ctx.r10.s64 = -2095841280;
	// li r11,1
	ctx.r11.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r11,27340(r10)
	PPC_STORE_U8(ctx.r10.u32 + 27340, ctx.r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A62700"))) PPC_WEAK_FUNC(sub_82A62700);
PPC_FUNC_IMPL(__imp__sub_82A62700) {
	PPC_FUNC_PROLOGUE();
	// addi r11,r3,21700
	ctx.r11.s64 = ctx.r3.s64 + 21700;
	// li r9,-1
	ctx.r9.s64 = -1;
	// li r10,41
	ctx.r10.s64 = 41;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82A62710:
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bdnz 0x82a62710
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82A62710;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A62728"))) PPC_WEAK_FUNC(sub_82A62728);
PPC_FUNC_IMPL(__imp__sub_82A62728) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4bc
	ctx.lr = 0x82A62730;
	__savegprlr_25(ctx, base);
	// stwu r1,-688(r1)
	ea = -688 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// addi r10,r10,24640
	ctx.r10.s64 = ctx.r10.s64 + 24640;
	// addi r28,r11,6
	ctx.r28.s64 = ctx.r11.s64 + 6;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// lis r25,-32038
	ctx.r25.s64 = -2099642368;
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// li r5,54
	ctx.r5.s64 = 54;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,90
	ctx.r3.s64 = ctx.r1.s64 + 90;
	// ori r25,r25,7
	ctx.r25.u64 = ctx.r25.u64 | 7;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,4(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// lhz r11,8(r10)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 8);
	// sth r11,88(r1)
	PPC_STORE_U16(ctx.r1.u32 + 88, ctx.r11.u16);
	// bl 0x82d5cb60
	ctx.lr = 0x82A6277C;
	sub_82D5CB60(ctx, base);
	// lis r10,-32090
	ctx.r10.s64 = -2103050240;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r10,r10,9672
	ctx.r10.s64 = ctx.r10.s64 + 9672;
	// addi r11,r11,24624
	ctx.r11.s64 = ctx.r11.s64 + 24624;
	// li r5,51
	ctx.r5.s64 = 51;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,161
	ctx.r3.s64 = ctx.r1.s64 + 161;
	// stw r10,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r10.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lbz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 12);
	// stw r10,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r10.u32);
	// stb r11,160(r1)
	PPC_STORE_U8(ctx.r1.u32 + 160, ctx.r11.u8);
	// bl 0x82d5cb60
	ctx.lr = 0x82A627C0;
	sub_82D5CB60(ctx, base);
	// lis r10,-32090
	ctx.r10.s64 = -2103050240;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r10,r10,9696
	ctx.r10.s64 = ctx.r10.s64 + 9696;
	// addi r11,r11,24612
	ctx.r11.s64 = ctx.r11.s64 + 24612;
	// li r5,54
	ctx.r5.s64 = 54;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,226
	ctx.r3.s64 = ctx.r1.s64 + 226;
	// stw r10,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,216(r1)
	PPC_STORE_U32(ctx.r1.u32 + 216, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lhz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 8);
	// stw r10,220(r1)
	PPC_STORE_U32(ctx.r1.u32 + 220, ctx.r10.u32);
	// sth r11,224(r1)
	PPC_STORE_U16(ctx.r1.u32 + 224, ctx.r11.u16);
	// bl 0x82d5cb60
	ctx.lr = 0x82A627FC;
	sub_82D5CB60(ctx, base);
	// lis r10,-32090
	ctx.r10.s64 = -2103050240;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r10,r10,9720
	ctx.r10.s64 = ctx.r10.s64 + 9720;
	// addi r11,r11,24592
	ctx.r11.s64 = ctx.r11.s64 + 24592;
	// addi r9,r1,284
	ctx.r9.s64 = ctx.r1.s64 + 284;
	// stw r10,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, ctx.r10.u32);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// li r11,19
	ctx.r11.s64 = 19;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
loc_82A62820:
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stb r11,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r11.u8);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// bdnz 0x82a62820
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82A62820;
	// li r5,45
	ctx.r5.s64 = 45;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,303
	ctx.r3.s64 = ctx.r1.s64 + 303;
	// bl 0x82d5cb60
	ctx.lr = 0x82A62844;
	sub_82D5CB60(ctx, base);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lis r10,-32090
	ctx.r10.s64 = -2103050240;
	// addi r4,r11,24564
	ctx.r4.s64 = ctx.r11.s64 + 24564;
	// addi r11,r10,9776
	ctx.r11.s64 = ctx.r10.s64 + 9776;
	// addi r3,r1,352
	ctx.r3.s64 = ctx.r1.s64 + 352;
	// li r5,27
	ctx.r5.s64 = 27;
	// stw r11,348(r1)
	PPC_STORE_U32(ctx.r1.u32 + 348, ctx.r11.u32);
	// bl 0x82d5c630
	ctx.lr = 0x82A62864;
	sub_82D5C630(ctx, base);
	// li r5,37
	ctx.r5.s64 = 37;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,379
	ctx.r3.s64 = ctx.r1.s64 + 379;
	// bl 0x82d5cb60
	ctx.lr = 0x82A62874;
	sub_82D5CB60(ctx, base);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lis r10,-32090
	ctx.r10.s64 = -2103050240;
	// addi r4,r11,24536
	ctx.r4.s64 = ctx.r11.s64 + 24536;
	// addi r11,r10,9864
	ctx.r11.s64 = ctx.r10.s64 + 9864;
	// addi r3,r1,420
	ctx.r3.s64 = ctx.r1.s64 + 420;
	// li r5,25
	ctx.r5.s64 = 25;
	// stw r11,416(r1)
	PPC_STORE_U32(ctx.r1.u32 + 416, ctx.r11.u32);
	// bl 0x82d5c630
	ctx.lr = 0x82A62894;
	sub_82D5C630(ctx, base);
	// li r5,39
	ctx.r5.s64 = 39;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,445
	ctx.r3.s64 = ctx.r1.s64 + 445;
	// bl 0x82d5cb60
	ctx.lr = 0x82A628A4;
	sub_82D5CB60(ctx, base);
	// lis r10,-32090
	ctx.r10.s64 = -2103050240;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r10,r10,9960
	ctx.r10.s64 = ctx.r10.s64 + 9960;
	// addi r11,r11,24520
	ctx.r11.s64 = ctx.r11.s64 + 24520;
	// li r5,49
	ctx.r5.s64 = 49;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,503
	ctx.r3.s64 = ctx.r1.s64 + 503;
	// stw r10,484(r1)
	PPC_STORE_U32(ctx.r1.u32 + 484, ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,488(r1)
	PPC_STORE_U32(ctx.r1.u32 + 488, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,492(r1)
	PPC_STORE_U32(ctx.r1.u32 + 492, ctx.r10.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// stw r10,496(r1)
	PPC_STORE_U32(ctx.r1.u32 + 496, ctx.r10.u32);
	// lhz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 12);
	// lbz r11,14(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 14);
	// sth r10,500(r1)
	PPC_STORE_U16(ctx.r1.u32 + 500, ctx.r10.u16);
	// stb r11,502(r1)
	PPC_STORE_U8(ctx.r1.u32 + 502, ctx.r11.u8);
	// bl 0x82d5cb60
	ctx.lr = 0x82A628F0;
	sub_82D5CB60(ctx, base);
	// lis r10,-32090
	ctx.r10.s64 = -2103050240;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r10,r10,9936
	ctx.r10.s64 = ctx.r10.s64 + 9936;
	// addi r11,r11,24504
	ctx.r11.s64 = ctx.r11.s64 + 24504;
	// li r5,51
	ctx.r5.s64 = 51;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,569
	ctx.r3.s64 = ctx.r1.s64 + 569;
	// stw r10,552(r1)
	PPC_STORE_U32(ctx.r1.u32 + 552, ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,556(r1)
	PPC_STORE_U32(ctx.r1.u32 + 556, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,560(r1)
	PPC_STORE_U32(ctx.r1.u32 + 560, ctx.r10.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lbz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 12);
	// stw r10,564(r1)
	PPC_STORE_U32(ctx.r1.u32 + 564, ctx.r10.u32);
	// stb r11,568(r1)
	PPC_STORE_U8(ctx.r1.u32 + 568, ctx.r11.u8);
	// bl 0x82d5cb60
	ctx.lr = 0x82A62934;
	sub_82D5CB60(ctx, base);
	// lis r11,-32090
	ctx.r11.s64 = -2103050240;
	// li r29,0
	ctx.r29.s64 = 0;
	// addi r11,r11,9960
	ctx.r11.s64 = ctx.r11.s64 + 9960;
	// addi r31,r1,80
	ctx.r31.s64 = ctx.r1.s64 + 80;
	// stw r11,620(r1)
	PPC_STORE_U32(ctx.r1.u32 + 620, ctx.r11.u32);
loc_82A62948:
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A62950:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82a62950
	if (!ctx.cr6.eq) goto loc_82A62950;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// rotlwi r30,r11,0
	ctx.r30.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82d625b0
	ctx.lr = 0x82A6297C;
	sub_82D625B0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a629b4
	if (ctx.cr0.eq) goto loc_82A629B4;
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r31,r31,68
	ctx.r31.s64 = ctx.r31.s64 + 68;
	// cmplwi cr6,r29,8
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 8, ctx.xer);
	// blt cr6,0x82a62948
	if (ctx.cr6.lt) goto loc_82A62948;
loc_82A62994:
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r4,r11,16720
	ctx.r4.s64 = ctx.r11.s64 + 16720;
loc_82A6299C:
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82d5e188
	ctx.lr = 0x82A629A8;
	sub_82D5E188(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// addi r1,r1,688
	ctx.r1.s64 = ctx.r1.s64 + 688;
	// b 0x82d5c50c
	__restgprlr_25(ctx, base);
	return;
loc_82A629B4:
	// mulli r10,r29,68
	ctx.r10.s64 = ctx.r29.s64 * 68;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// add r11,r30,r28
	ctx.r11.u64 = ctx.r30.u64 + ctx.r28.u64;
	// addi r3,r11,1
	ctx.r3.s64 = ctx.r11.s64 + 1;
	// lwzx r11,r10,r9
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A629D0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lis r25,730
	ctx.r25.s64 = 47841280;
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a62994
	if (ctx.cr0.eq) goto loc_82A62994;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r4,r11,24496
	ctx.r4.s64 = ctx.r11.s64 + 24496;
	// b 0x82a6299c
	goto loc_82A6299C;
}

__attribute__((alias("__imp__sub_82A629E8"))) PPC_WEAK_FUNC(sub_82A629E8);
PPC_FUNC_IMPL(__imp__sub_82A629E8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c4
	ctx.lr = 0x82A629F0;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// li r8,4096
	ctx.r8.s64 = 4096;
	// li r7,-1
	ctx.r7.s64 = -1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1028
	ctx.r5.s64 = 1028;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// li r3,2
	ctx.r3.s64 = 2;
	// li r30,0
	ctx.r30.s64 = 0;
	// bl 0x8308ae94
	ctx.lr = 0x82A62A24;
	__imp__MmAllocatePhysicalMemoryEx(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne 0x82a62a58
	if (!ctx.cr0.eq) goto loc_82A62A58;
	// lis r4,-18048
	ctx.r4.s64 = -1182793728;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8247f370
	ctx.lr = 0x82A62A38;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a62a48
	if (ctx.cr0.eq) goto loc_82A62A48;
	// li r30,1
	ctx.r30.s64 = 1;
	// b 0x82a62a58
	goto loc_82A62A58;
loc_82A62A48:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82a62a58
	if (ctx.cr6.eq) goto loc_82A62A58;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// li r30,2
	ctx.r30.s64 = 2;
loc_82A62A58:
	// stw r3,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r3.u32);
	// stw r30,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r30.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c514
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A62A68"))) PPC_WEAK_FUNC(sub_82A62A68);
PPC_FUNC_IMPL(__imp__sub_82A62A68) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r31,r3,21680
	ctx.r31.s64 = ctx.r3.s64 + 21680;
	// lwz r3,592(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 592);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a62ab0
	if (ctx.cr0.eq) goto loc_82A62AB0;
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// rlwinm. r11,r11,0,4,4
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a62aa8
	if (!ctx.cr0.eq) goto loc_82A62AA8;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r3,2
	ctx.r3.s64 = 2;
	// bl 0x8308aec4
	ctx.lr = 0x82A62AA4;
	__imp__MmFreePhysicalMemory(ctx, base);
	// b 0x82a62ab0
	goto loc_82A62AB0;
loc_82A62AA8:
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// bl 0x8247f398
	ctx.lr = 0x82A62AB0;
	sub_8247F398(ctx, base);
loc_82A62AB0:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lis r30,-20096
	ctx.r30.s64 = -1317011456;
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a62aec
	if (ctx.cr0.eq) goto loc_82A62AEC;
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// srawi r11,r11,30
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3FFFFFFF) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 30;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82a62ae0
	if (ctx.cr6.lt) goto loc_82A62AE0;
	// bne cr6,0x82a62aec
	if (!ctx.cr6.eq) goto loc_82A62AEC;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A62ADC;
	sub_8247F398(ctx, base);
	// b 0x82a62aec
	goto loc_82A62AEC;
loc_82A62AE0:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r3,2
	ctx.r3.s64 = 2;
	// bl 0x8308aec4
	ctx.lr = 0x82A62AEC;
	__imp__MmFreePhysicalMemory(ctx, base);
loc_82A62AEC:
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a62b28
	if (ctx.cr0.eq) goto loc_82A62B28;
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// srawi r11,r11,30
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3FFFFFFF) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 30;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82a62b1c
	if (ctx.cr6.lt) goto loc_82A62B1C;
	// bne cr6,0x82a62b28
	if (!ctx.cr6.eq) goto loc_82A62B28;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A62B18;
	sub_8247F398(ctx, base);
	// b 0x82a62b28
	goto loc_82A62B28;
loc_82A62B1C:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r3,2
	ctx.r3.s64 = 2;
	// bl 0x8308aec4
	ctx.lr = 0x82A62B28;
	__imp__MmFreePhysicalMemory(ctx, base);
loc_82A62B28:
	// li r5,620
	ctx.r5.s64 = 620;
	// lwz r30,616(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 616);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d5cb60
	ctx.lr = 0x82A62B3C;
	sub_82D5CB60(ctx, base);
	// addi r11,r31,20
	ctx.r11.s64 = ctx.r31.s64 + 20;
	// li r9,-1
	ctx.r9.s64 = -1;
	// stw r30,616(r31)
	PPC_STORE_U32(ctx.r31.u32 + 616, ctx.r30.u32);
	// li r10,41
	ctx.r10.s64 = 41;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82A62B50:
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bdnz 0x82a62b50
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82A62B50;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A62B78"))) PPC_WEAK_FUNC(sub_82A62B78);
PPC_FUNC_IMPL(__imp__sub_82A62B78) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4a8
	ctx.lr = 0x82A62B80;
	__savegprlr_20(ctx, base);
	// stwu r1,-480(r1)
	ea = -480 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r31,r3,21680
	ctx.r31.s64 = ctx.r3.s64 + 21680;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// addi r3,r31,368
	ctx.r3.s64 = ctx.r31.s64 + 368;
	// addi r9,r31,372
	ctx.r9.s64 = ctx.r31.s64 + 372;
	// lwz r10,604(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 604);
	// clrlwi r10,r10,3
	ctx.r10.u64 = ctx.r10.u32 & 0x1FFFFFFF;
	// srawi. r8,r10,29
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1FFFFFFF) != 0);
	ctx.r8.s64 = ctx.r10.s32 >> 29;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// stw r10,604(r31)
	PPC_STORE_U32(ctx.r31.u32 + 604, ctx.r10.u32);
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// lwz r11,36(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// rlwinm r10,r10,2,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0x2;
	// clrlwi r6,r11,19
	ctx.r6.u64 = ctx.r11.u32 & 0x1FFF;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// rlwinm r7,r11,19,19,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 19) & 0x1FFF;
	// add r11,r6,r10
	ctx.r11.u64 = ctx.r6.u64 + ctx.r10.u64;
	// add r10,r7,r10
	ctx.r10.u64 = ctx.r7.u64 + ctx.r10.u64;
	// addi r7,r11,31
	ctx.r7.s64 = ctx.r11.s64 + 31;
	// addi r6,r10,31
	ctx.r6.s64 = ctx.r10.s64 + 31;
	// rlwinm r7,r7,0,16,26
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFE0;
	// rlwinm r6,r6,0,16,26
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFE0;
	// sth r11,368(r31)
	PPC_STORE_U16(ctx.r31.u32 + 368, ctx.r11.u16);
	// sth r10,370(r31)
	PPC_STORE_U16(ctx.r31.u32 + 370, ctx.r10.u16);
	// sth r7,372(r31)
	PPC_STORE_U16(ctx.r31.u32 + 372, ctx.r7.u16);
	// sth r6,374(r31)
	PPC_STORE_U16(ctx.r31.u32 + 374, ctx.r6.u16);
	// bne 0x82a62f28
	if (!ctx.cr0.eq) goto loc_82A62F28;
	// lis r11,-32244
	ctx.r11.s64 = -2113142784;
	// lhz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + 0);
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// addi r7,r1,92
	ctx.r7.s64 = ctx.r1.s64 + 92;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// lfs f0,-16900(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -16900);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// stfs f0,96(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// std r10,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r10.u64);
	// addi r8,r1,84
	ctx.r8.s64 = ctx.r1.s64 + 84;
	// addi r29,r1,88
	ctx.r29.s64 = ctx.r1.s64 + 88;
	// lfs f12,12172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12172);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// stfs f12,92(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// addi r30,r1,88
	ctx.r30.s64 = ctx.r1.s64 + 88;
	// lvlx v13,0,r7
	temp.u32 = ctx.r7.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// addi r6,r31,408
	ctx.r6.s64 = ctx.r31.s64 + 408;
	// addi r27,r1,80
	ctx.r27.s64 = ctx.r1.s64 + 80;
	// lfs f13,21344(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21344);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// stfs f13,88(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// addi r26,r1,84
	ctx.r26.s64 = ctx.r1.s64 + 84;
	// lvlx v12,0,r5
	temp.u32 = ctx.r5.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r5,r31,424
	ctx.r5.s64 = ctx.r31.s64 + 424;
	// addi r25,r1,80
	ctx.r25.s64 = ctx.r1.s64 + 80;
	// addi r24,r1,84
	ctx.r24.s64 = ctx.r1.s64 + 84;
	// lfs f11,-4480(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4480);
	ctx.f11.f64 = double(temp.f32);
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// stfs f11,84(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// addi r23,r1,80
	ctx.r23.s64 = ctx.r1.s64 + 80;
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// li r8,12
	ctx.r8.s64 = 12;
	// lfs f0,21356(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21356);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfd f0,96(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// addi r10,r11,24448
	ctx.r10.s64 = ctx.r11.s64 + 24448;
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lvlx v11,0,r7
	temp.u32 = ctx.r7.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v11,v0,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// li r11,16
	ctx.r11.s64 = 16;
	// addi r28,r10,16
	ctx.r28.s64 = ctx.r10.s64 + 16;
	// li r7,48
	ctx.r7.s64 = 48;
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fdivs f10,f13,f0
	ctx.f10.f64 = double(float(ctx.f13.f64 / ctx.f0.f64));
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v10,0,r3
	temp.u32 = ctx.r3.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// fmuls f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// vrlimi128 v10,v12,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// lvlx v0,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r29,r10,32
	ctx.r29.s64 = ctx.r10.s64 + 32;
	// stfs f10,88(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lvlx v12,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// mr r30,r10
	ctx.r30.u64 = ctx.r10.u64;
	// vrlimi128 v0,v12,4,3
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v12,v10,v10
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vor v10,v0,v0
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// vrlimi128 v12,v13,3,2
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// vrlimi128 v10,v11,3,2
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 78), 3));
	// vor v0,v12,v12
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v12.u8));
	// vor v13,v10,v10
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r6,r31,440
	ctx.r6.s64 = ctx.r31.s64 + 440;
	// lvlx v12,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvrx v0,r11,r10
	temp.u32 = ctx.r11.u32 + ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// vor v0,v12,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// stvlx v0,0,r5
	ea = ctx.r5.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r5,r11
	ea = ctx.r5.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r5,r31,472
	ctx.r5.s64 = ctx.r31.s64 + 472;
	// lvrx v0,r11,r28
	temp.u32 = ctx.r11.u32 + ctx.r28.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// li r28,32
	ctx.r28.s64 = 32;
	// lvlx v12,r10,r11
	temp.u32 = ctx.r10.u32 + ctx.r11.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r10,r31,456
	ctx.r10.s64 = ctx.r31.s64 + 456;
	// vor v0,v12,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r22,r1,84
	ctx.r22.s64 = ctx.r1.s64 + 84;
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r21,r1,80
	ctx.r21.s64 = ctx.r1.s64 + 80;
	// lvlx v12,r30,r28
	temp.u32 = ctx.r30.u32 + ctx.r28.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r20,r1,84
	ctx.r20.s64 = ctx.r1.s64 + 84;
	// lvrx v0,r11,r29
	temp.u32 = ctx.r11.u32 + ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// addi r3,r31,488
	ctx.r3.s64 = ctx.r31.s64 + 488;
	// vor v0,v12,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r30,r1,80
	ctx.r30.s64 = ctx.r1.s64 + 80;
	// addi r29,r1,84
	ctx.r29.s64 = ctx.r1.s64 + 84;
	// addi r28,r1,84
	ctx.r28.s64 = ctx.r1.s64 + 84;
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lis r10,-32230
	ctx.r10.s64 = -2112225280;
	// lfs f0,21348(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 21348);
	ctx.f0.f64 = double(temp.f32);
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r27
	temp.u32 = ctx.r27.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r27,r1,80
	ctx.r27.s64 = ctx.r1.s64 + 80;
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v12,0,r26
	temp.u32 = ctx.r26.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r26,r1,84
	ctx.r26.s64 = ctx.r1.s64 + 84;
	// lfs f10,24660(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 24660);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v11,0,r25
	temp.u32 = ctx.r25.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r25,r1,80
	ctx.r25.s64 = ctx.r1.s64 + 80;
	// lfs f10,24656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 24656);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v10,0,r24
	temp.u32 = ctx.r24.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v10,v11,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// stvlx v0,0,r5
	ea = ctx.r5.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r5,r11
	ea = ctx.r5.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lfs f10,-11956(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11956);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r23
	temp.u32 = ctx.r23.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v11,0,r21
	temp.u32 = ctx.r21.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lfs f10,-11764(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11764);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v12,0,r22
	temp.u32 = ctx.r22.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v10,0,r20
	temp.u32 = ctx.r20.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v10,v11,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// stvlx v0,0,r3
	ea = ctx.r3.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r3,r11
	ea = ctx.r3.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f10,28796(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28796);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r6
	temp.u32 = ctx.r6.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r6,r31,520
	ctx.r6.s64 = ctx.r31.s64 + 520;
	// lfs f10,-12748(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -12748);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v12,0,r5
	temp.u32 = ctx.r5.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r5,r31,536
	ctx.r5.s64 = ctx.r31.s64 + 536;
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v10,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r29,r1,80
	ctx.r29.s64 = ctx.r1.s64 + 80;
	// lfs f10,-3712(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -3712);
	ctx.f10.f64 = double(temp.f32);
	// addi r10,r31,504
	ctx.r10.s64 = ctx.r31.s64 + 504;
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v11,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r30,r1,84
	ctx.r30.s64 = ctx.r1.s64 + 84;
	// vrlimi128 v10,v11,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r24,r1,84
	ctx.r24.s64 = ctx.r1.s64 + 84;
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r3
	temp.u32 = ctx.r3.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v11,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lfs f11,-28048(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28048);
	ctx.f11.f64 = double(temp.f32);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// stfs f11,84(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v12,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lfs f13,-11880(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11880);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v10,0,r28
	temp.u32 = ctx.r28.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v10,v11,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// stvlx v13,0,r5
	ea = ctx.r5.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v13.u8[15 - i]);
	// stvrx v13,r5,r11
	ea = ctx.r5.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v13.u8[i]);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r27
	temp.u32 = ctx.r27.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,24524(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 24524);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r31,552
	ctx.r10.s64 = ctx.r31.s64 + 552;
	// lvlx v13,0,r26
	temp.u32 = ctx.r26.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v12,0,r25
	temp.u32 = ctx.r25.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvlx v11,0,r24
	temp.u32 = ctx.r24.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lhz r11,2(r9)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r9.u32 + 2);
	// lhz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + 0);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r11,r11,27,5,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFE0;
	// b 0x82a63278
	goto loc_82A63278;
loc_82A62F28:
	// cmpwi cr6,r8,1
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 1, ctx.xer);
	// bne cr6,0x82a63280
	if (!ctx.cr6.eq) goto loc_82A63280;
	// lhz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + 0);
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// lfs f0,21348(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21348);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// stfs f0,96(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// addi r30,r1,96
	ctx.r30.s64 = ctx.r1.s64 + 96;
	// std r10,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r10.u64);
	// lfd f13,104(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// lvlx v11,0,r5
	temp.u32 = ctx.r5.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r5,r31,424
	ctx.r5.s64 = ctx.r31.s64 + 424;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f11,-29000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29000);
	ctx.f11.f64 = double(temp.f32);
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// stfs f11,84(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// lvlx v13,0,r7
	temp.u32 = ctx.r7.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lis r5,-32244
	ctx.r5.s64 = -2113142784;
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r7,r1,92
	ctx.r7.s64 = ctx.r1.s64 + 92;
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// addi r8,r1,88
	ctx.r8.s64 = ctx.r1.s64 + 88;
	// lfs f10,-4480(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4480);
	ctx.f10.f64 = double(temp.f32);
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// stfs f10,92(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// addi r29,r1,80
	ctx.r29.s64 = ctx.r1.s64 + 80;
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// lfs f13,-16900(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -16900);
	ctx.f13.f64 = double(temp.f32);
	// lis r5,-32230
	ctx.r5.s64 = -2112225280;
	// lvlx v12,0,r7
	temp.u32 = ctx.r7.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// addi r6,r31,408
	ctx.r6.s64 = ctx.r31.s64 + 408;
	// addi r10,r11,-26176
	ctx.r10.s64 = ctx.r11.s64 + -26176;
	// li r11,16
	ctx.r11.s64 = 16;
	// addi r28,r10,16
	ctx.r28.s64 = ctx.r10.s64 + 16;
	// li r8,3
	ctx.r8.s64 = 3;
	// li r7,12
	ctx.r7.s64 = 12;
	// fmuls f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,21344(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 21344);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f9,f13,f12
	ctx.f9.f64 = double(float(ctx.f13.f64 / ctx.f12.f64));
	// stfs f9,92(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fdivs f9,f13,f12
	ctx.f9.f64 = double(float(ctx.f13.f64 / ctx.f12.f64));
	// stfs f9,96(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lvlx v0,0,r3
	temp.u32 = ctx.r3.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// fmuls f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lvlx v10,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// mr r30,r10
	ctx.r30.u64 = ctx.r10.u64;
	// vrlimi128 v10,v0,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r29,r10,32
	ctx.r29.s64 = ctx.r10.s64 + 32;
	// vrlimi128 v0,v11,4,3
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v11,v10,v10
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vor v10,v0,v0
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// vrlimi128 v11,v13,3,2
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// vrlimi128 v10,v12,3,2
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vor v13,v10,v10
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r6,r31,440
	ctx.r6.s64 = ctx.r31.s64 + 440;
	// lvlx v12,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvrx v0,r11,r10
	temp.u32 = ctx.r11.u32 + ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// vor v0,v12,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// stvlx v0,0,r27
	ea = ctx.r27.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r27,r1,80
	ctx.r27.s64 = ctx.r1.s64 + 80;
	// stvrx v0,r26,r11
	ea = ctx.r26.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r26,r1,84
	ctx.r26.s64 = ctx.r1.s64 + 84;
	// lvrx v0,r11,r28
	temp.u32 = ctx.r11.u32 + ctx.r28.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// li r28,32
	ctx.r28.s64 = 32;
	// lvlx v12,r10,r11
	temp.u32 = ctx.r10.u32 + ctx.r11.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r10,r31,456
	ctx.r10.s64 = ctx.r31.s64 + 456;
	// vor v0,v12,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r25,r1,80
	ctx.r25.s64 = ctx.r1.s64 + 80;
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r24,r1,84
	ctx.r24.s64 = ctx.r1.s64 + 84;
	// lvlx v12,r30,r28
	temp.u32 = ctx.r30.u32 + ctx.r28.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r5,r31,472
	ctx.r5.s64 = ctx.r31.s64 + 472;
	// lvrx v0,r11,r29
	temp.u32 = ctx.r11.u32 + ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// addi r23,r1,80
	ctx.r23.s64 = ctx.r1.s64 + 80;
	// vor v0,v12,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// addi r22,r1,84
	ctx.r22.s64 = ctx.r1.s64 + 84;
	// addi r21,r1,80
	ctx.r21.s64 = ctx.r1.s64 + 80;
	// addi r20,r1,84
	ctx.r20.s64 = ctx.r1.s64 + 84;
	// addi r3,r31,488
	ctx.r3.s64 = ctx.r31.s64 + 488;
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// addi r30,r1,80
	ctx.r30.s64 = ctx.r1.s64 + 80;
	// lvlx v0,0,r27
	temp.u32 = ctx.r27.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r29,r1,84
	ctx.r29.s64 = ctx.r1.s64 + 84;
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// addi r28,r1,84
	ctx.r28.s64 = ctx.r1.s64 + 84;
	// lvlx v12,0,r26
	temp.u32 = ctx.r26.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r27,r1,80
	ctx.r27.s64 = ctx.r1.s64 + 80;
	// lfs f12,24660(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 24660);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v11,0,r25
	temp.u32 = ctx.r25.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lfs f12,24656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 24656);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v10,0,r24
	temp.u32 = ctx.r24.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v10,v11,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// stvlx v0,0,r5
	ea = ctx.r5.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r5,r11
	ea = ctx.r5.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lfs f12,-11956(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11956);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r23
	temp.u32 = ctx.r23.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v11,0,r21
	temp.u32 = ctx.r21.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lfs f12,-11764(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11764);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v12,0,r22
	temp.u32 = ctx.r22.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v10,0,r20
	temp.u32 = ctx.r20.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v10,v11,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// stvlx v0,0,r3
	ea = ctx.r3.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r3,r11
	ea = ctx.r3.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f12,28796(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28796);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r6
	temp.u32 = ctx.r6.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r6,r31,520
	ctx.r6.s64 = ctx.r31.s64 + 520;
	// lfs f12,-12748(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -12748);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v12,0,r5
	temp.u32 = ctx.r5.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r5,r31,536
	ctx.r5.s64 = ctx.r31.s64 + 536;
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v10,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r29,r1,80
	ctx.r29.s64 = ctx.r1.s64 + 80;
	// lfs f12,-3712(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -3712);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r31,504
	ctx.r10.s64 = ctx.r31.s64 + 504;
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v11,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r30,r1,84
	ctx.r30.s64 = ctx.r1.s64 + 84;
	// vrlimi128 v10,v11,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r26,r1,84
	ctx.r26.s64 = ctx.r1.s64 + 84;
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// addi r25,r1,80
	ctx.r25.s64 = ctx.r1.s64 + 80;
	// lvlx v0,0,r3
	temp.u32 = ctx.r3.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r24,r1,84
	ctx.r24.s64 = ctx.r1.s64 + 84;
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v11,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lfs f12,-28048(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28048);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v12,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lfs f13,-11880(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11880);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v10,0,r28
	temp.u32 = ctx.r28.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v10,v11,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// stvlx v13,0,r5
	ea = ctx.r5.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v13.u8[15 - i]);
	// stvrx v13,r5,r11
	ea = ctx.r5.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v13.u8[i]);
	// lfs f13,12172(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12172);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r27
	temp.u32 = ctx.r27.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,24524(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 24524);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r31,552
	ctx.r10.s64 = ctx.r31.s64 + 552;
	// lvlx v13,0,r26
	temp.u32 = ctx.r26.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v12,0,r25
	temp.u32 = ctx.r25.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvlx v11,0,r24
	temp.u32 = ctx.r24.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lhz r11,2(r9)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r9.u32 + 2);
	// lhz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + 0);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r11,r11,23,9,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 23) & 0x7FFFFE;
loc_82A63278:
	// stw r11,376(r31)
	PPC_STORE_U32(ctx.r31.u32 + 376, ctx.r11.u32);
	// b 0x82a635e4
	goto loc_82A635E4;
loc_82A63280:
	// cmpwi cr6,r8,2
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 2, ctx.xer);
	// bne cr6,0x82a635dc
	if (!ctx.cr6.eq) goto loc_82A635DC;
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// addi r9,r31,424
	ctx.r9.s64 = ctx.r31.s64 + 424;
	// addi r10,r11,-26080
	ctx.r10.s64 = ctx.r11.s64 + -26080;
	// li r11,16
	ctx.r11.s64 = 16;
	// mr r30,r10
	ctx.r30.u64 = ctx.r10.u64;
	// addi r29,r10,16
	ctx.r29.s64 = ctx.r10.s64 + 16;
	// addi r6,r31,440
	ctx.r6.s64 = ctx.r31.s64 + 440;
	// lvlx v13,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// mr r28,r10
	ctx.r28.u64 = ctx.r10.u64;
	// lvrx v0,r11,r10
	temp.u32 = ctx.r11.u32 + ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// addi r27,r10,32
	ctx.r27.s64 = ctx.r10.s64 + 32;
	// vor v0,v13,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// li r26,32
	ctx.r26.s64 = 32;
	// addi r10,r31,456
	ctx.r10.s64 = ctx.r31.s64 + 456;
	// addi r25,r1,80
	ctx.r25.s64 = ctx.r1.s64 + 80;
	// addi r24,r1,84
	ctx.r24.s64 = ctx.r1.s64 + 84;
	// stvlx v0,0,r9
	ea = ctx.r9.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r23,r1,80
	ctx.r23.s64 = ctx.r1.s64 + 80;
	// stvrx v0,r9,r11
	ea = ctx.r9.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r22,r1,84
	ctx.r22.s64 = ctx.r1.s64 + 84;
	// lvlx v13,r30,r11
	temp.u32 = ctx.r30.u32 + ctx.r11.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r5,r31,472
	ctx.r5.s64 = ctx.r31.s64 + 472;
	// lvrx v0,r11,r29
	temp.u32 = ctx.r11.u32 + ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// vor v0,v13,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// addi r30,r1,80
	ctx.r30.s64 = ctx.r1.s64 + 80;
	// addi r29,r1,84
	ctx.r29.s64 = ctx.r1.s64 + 84;
	// li r8,3
	ctx.r8.s64 = 3;
	// li r7,6
	ctx.r7.s64 = 6;
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// lvlx v13,r28,r26
	temp.u32 = ctx.r28.u32 + ctx.r26.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r28,r1,84
	ctx.r28.s64 = ctx.r1.s64 + 84;
	// lvrx v0,r11,r27
	temp.u32 = ctx.r11.u32 + ctx.r27.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// vor v0,v13,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lis r10,-32230
	ctx.r10.s64 = -2112225280;
	// lfs f0,21348(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 21348);
	ctx.f0.f64 = double(temp.f32);
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r25
	temp.u32 = ctx.r25.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v13,0,r24
	temp.u32 = ctx.r24.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lfs f13,24660(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 24660);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v12,0,r23
	temp.u32 = ctx.r23.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lfs f13,24656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 24656);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v11,0,r22
	temp.u32 = ctx.r22.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r5
	ea = ctx.r5.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r5,r11
	ea = ctx.r5.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lfs f13,28796(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28796);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r9,r31,504
	ctx.r9.s64 = ctx.r31.s64 + 504;
	// lfs f13,-5772(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -5772);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32230
	ctx.r10.s64 = -2112225280;
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v13,0,r6
	temp.u32 = ctx.r6.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v11,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r29,r1,80
	ctx.r29.s64 = ctx.r1.s64 + 80;
	// lfs f12,21344(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 21344);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r31,488
	ctx.r10.s64 = ctx.r31.s64 + 488;
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v12,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r30,r1,84
	ctx.r30.s64 = ctx.r1.s64 + 84;
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r27,r1,80
	ctx.r27.s64 = ctx.r1.s64 + 80;
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// addi r26,r1,84
	ctx.r26.s64 = ctx.r1.s64 + 84;
	// addi r25,r1,80
	ctx.r25.s64 = ctx.r1.s64 + 80;
	// addi r24,r1,84
	ctx.r24.s64 = ctx.r1.s64 + 84;
	// addi r6,r31,520
	ctx.r6.s64 = ctx.r31.s64 + 520;
	// lfs f12,-18724(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -18724);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r5
	temp.u32 = ctx.r5.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lfs f12,-12748(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -12748);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32230
	ctx.r10.s64 = -2112225280;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v13,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r30,r1,84
	ctx.r30.s64 = ctx.r1.s64 + 84;
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lfs f11,21356(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 21356);
	ctx.f11.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v12,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r29,r1,80
	ctx.r29.s64 = ctx.r1.s64 + 80;
	// lfs f10,-11956(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11956);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v11,0,r28
	temp.u32 = ctx.r28.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r28,r1,84
	ctx.r28.s64 = ctx.r1.s64 + 84;
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r9
	ea = ctx.r9.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r9,r11
	ea = ctx.r9.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r9,r1,84
	ctx.r9.s64 = ctx.r1.s64 + 84;
	// lfs f10,-16900(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -16900);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r27
	temp.u32 = ctx.r27.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r27,r1,80
	ctx.r27.s64 = ctx.r1.s64 + 80;
	// lfs f10,-11880(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11880);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v13,0,r26
	temp.u32 = ctx.r26.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r26,r1,84
	ctx.r26.s64 = ctx.r1.s64 + 84;
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lfs f10,24524(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 24524);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v12,0,r25
	temp.u32 = ctx.r25.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r25,r1,80
	ctx.r25.s64 = ctx.r1.s64 + 80;
	// lfs f10,12172(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12172);
	ctx.f10.f64 = double(temp.f32);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v11,0,r24
	temp.u32 = ctx.r24.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r24,r1,84
	ctx.r24.s64 = ctx.r1.s64 + 84;
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v13,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r9,r31,408
	ctx.r9.s64 = ctx.r31.s64 + 408;
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lfs f12,-29000(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29000);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v12,0,r5
	temp.u32 = ctx.r5.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lfs f12,24652(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 24652);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r31,552
	ctx.r10.s64 = ctx.r31.s64 + 552;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v11,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r30,r1,84
	ctx.r30.s64 = ctx.r1.s64 + 84;
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r6,r31,536
	ctx.r6.s64 = ctx.r31.s64 + 536;
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfs f12,-18744(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -18744);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r5
	temp.u32 = ctx.r5.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v12,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lfs f12,-17528(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -17528);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v13,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lfs f12,-11908(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11908);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v11,0,r28
	temp.u32 = ctx.r28.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r9
	ea = ctx.r9.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r9,r11
	ea = ctx.r9.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f13,8244(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8244);
	ctx.f13.f64 = double(temp.f32);
	// li r10,48
	ctx.r10.s64 = 48;
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v0,0,r27
	temp.u32 = ctx.r27.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// mr r5,r10
	ctx.r5.u64 = ctx.r10.u64;
	// lvlx v13,0,r26
	temp.u32 = ctx.r26.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v12,0,r25
	temp.u32 = ctx.r25.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvlx v11,0,r24
	temp.u32 = ctx.r24.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lhz r10,2(r3)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r3.u32 + 2);
	// lhz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 0);
	// addi r10,r10,-48
	ctx.r10.s64 = ctx.r10.s64 + -48;
	// addi r11,r11,-80
	ctx.r11.s64 = ctx.r11.s64 + -80;
	// divwu r10,r10,r9
	ctx.r10.u32 = ctx.r10.u32 / ctx.r9.u32;
	// divwu r11,r11,r5
	ctx.r11.u32 = ctx.r11.u32 / ctx.r5.u32;
	// mullw r11,r10,r11
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// rlwinm r11,r11,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// b 0x82a63278
	goto loc_82A63278;
loc_82A635DC:
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82A635E4:
	// lis r10,-31988
	ctx.r10.s64 = -2096365568;
	// lwz r11,376(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 376);
	// li r5,260
	ctx.r5.s64 = 260;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// lwz r10,-26252(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -26252);
	// rldicr r30,r10,20,63
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r10.u64, 20) & 0xFFFFFFFFFFFFFFFF;
	// mullw r10,r11,r7
	ctx.r10.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r7.s32);
	// mullw r11,r11,r8
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r8.s32);
	// stw r11,388(r31)
	PPC_STORE_U32(ctx.r31.u32 + 388, ctx.r11.u32);
	// addi r10,r10,511
	ctx.r10.s64 = ctx.r10.s64 + 511;
	// rlwinm r11,r10,23,9,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 23) & 0x7FFFFF;
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// addi r10,r10,172
	ctx.r10.s64 = ctx.r10.s64 + 172;
	// sth r11,14(r31)
	PPC_STORE_U16(ctx.r31.u32 + 14, ctx.r11.u16);
	// rlwinm r28,r10,9,0,22
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 9) & 0xFFFFFE00;
	// bl 0x82d5e188
	ctx.lr = 0x82A63628;
	sub_82D5E188(ctx, base);
	// li r27,0
	ctx.r27.s64 = 0;
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// stb r27,371(r1)
	PPC_STORE_U8(ctx.r1.u32 + 371, ctx.r27.u8);
loc_82A63638:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82a63638
	if (!ctx.cr6.eq) goto loc_82A63638;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82a63688
	if (ctx.cr6.lt) goto loc_82A63688;
loc_82A6366C:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,92
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 92, ctx.xer);
	// beq cr6,0x82a63688
	if (ctx.cr6.eq) goto loc_82A63688;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82a6366c
	if (!ctx.cr6.lt) goto loc_82A6366C;
loc_82A63688:
	// li r6,0
	ctx.r6.s64 = 0;
	// stb r27,1(r11)
	PPC_STORE_U8(ctx.r11.u32 + 1, ctx.r27.u8);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82e99840
	ctx.lr = 0x82A636A0;
	sub_82E99840(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a636d4
	if (ctx.cr0.eq) goto loc_82A636D4;
	// lis r10,640
	ctx.r10.s64 = 41943040;
	// ld r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// add r9,r30,r10
	ctx.r9.u64 = ctx.r30.u64 + ctx.r10.u64;
	// cmpld cr6,r11,r9
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, ctx.r9.u64, ctx.xer);
	// bge cr6,0x82a636d4
	if (!ctx.cr6.lt) goto loc_82A636D4;
	// cmpld cr6,r11,r10
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, ctx.r10.u64, ctx.xer);
	// ble cr6,0x82a636d0
	if (!ctx.cr6.gt) goto loc_82A636D0;
	// lis r10,-640
	ctx.r10.s64 = -41943040;
	// add r30,r11,r10
	ctx.r30.u64 = ctx.r11.u64 + ctx.r10.u64;
	// b 0x82a636d4
	goto loc_82A636D4;
loc_82A636D0:
	// mr r30,r27
	ctx.r30.u64 = ctx.r27.u64;
loc_82A636D4:
	// addi r11,r28,2048
	ctx.r11.s64 = ctx.r28.s64 + 2048;
	// clrldi r11,r11,32
	ctx.r11.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// cmpld cr6,r11,r30
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, ctx.r30.u64, ctx.xer);
	// ble cr6,0x82a636f0
	if (!ctx.cr6.gt) goto loc_82A636F0;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82a6381c
	goto loc_82A6381C;
loc_82A636F0:
	// lis r11,-17
	ctx.r11.s64 = -1114112;
	// li r9,0
	ctx.r9.s64 = 0;
	// ori r11,r11,65535
	ctx.r11.u64 = ctx.r11.u64 | 65535;
	// oris r8,r9,65520
	ctx.r8.u64 = ctx.r9.u64 | 4293918720;
	// clrldi r10,r11,32
	ctx.r10.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// lwz r11,596(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 596);
	// rotlwi r9,r30,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r30.u32, 0);
	// add r10,r30,r10
	ctx.r10.u64 = ctx.r30.u64 + ctx.r10.u64;
	// mr r29,r27
	ctx.r29.u64 = ctx.r27.u64;
	// divdu r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 / ctx.r8.u64;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// rlwimi r11,r10,14,12,17
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 14) & 0xFC000) | (ctx.r11.u64 & 0xFFFFFFFFFFF03FFF);
	// rlwinm r10,r11,18,26,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 18) & 0x3F;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r11,596(r31)
	PPC_STORE_U32(ctx.r31.u32 + 596, ctx.r11.u32);
	// rlwinm r10,r10,20,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0xFFF00000;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,384(r31)
	PPC_STORE_U32(ctx.r31.u32 + 384, ctx.r10.u32);
loc_82A63738:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82a63754
	if (ctx.cr6.eq) goto loc_82A63754;
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// srawi r11,r11,30
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3FFFFFFF) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 30;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82a63758
	if (ctx.cr6.eq) goto loc_82A63758;
loc_82A63754:
	// lwz r4,616(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 616);
loc_82A63758:
	// rlwinm r11,r29,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// add r30,r11,r31
	ctx.r30.u64 = ctx.r11.u64 + ctx.r31.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82a629e8
	ctx.lr = 0x82A63770;
	sub_82A629E8(ctx, base);
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a63814
	if (ctx.cr6.eq) goto loc_82A63814;
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// bne cr6,0x82a63794
	if (!ctx.cr6.eq) goto loc_82A63794;
	// rlwimi r11,r10,30,0,1
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 30) & 0xC0000000) | (ctx.r11.u64 & 0xFFFFFFFF3FFFFFFF);
	// b 0x82a63798
	goto loc_82A63798;
loc_82A63794:
	// rlwimi r11,r10,28,2,3
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 28) & 0x30000000) | (ctx.r11.u64 & 0xFFFFFFFFCFFFFFFF);
loc_82A63798:
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// stw r11,612(r31)
	PPC_STORE_U32(ctx.r31.u32 + 612, ctx.r11.u32);
	// cmplwi cr6,r29,2
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 2, ctx.xer);
	// blt cr6,0x82a63738
	if (ctx.cr6.lt) goto loc_82A63738;
	// li r8,4096
	ctx.r8.s64 = 4096;
	// li r7,-1
	ctx.r7.s64 = -1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,1536
	ctx.r4.s64 = 1536;
	// li r3,2
	ctx.r3.s64 = 2;
	// bl 0x8308ae94
	ctx.lr = 0x82A637C4;
	__imp__MmAllocatePhysicalMemoryEx(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,592(r31)
	PPC_STORE_U32(ctx.r31.u32 + 592, ctx.r3.u32);
	// beq 0x82a637dc
	if (ctx.cr0.eq) goto loc_82A637DC;
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// rlwinm r11,r11,0,5,3
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFF7FFFFFF;
	// b 0x82a637fc
	goto loc_82A637FC;
loc_82A637DC:
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// li r3,1536
	ctx.r3.s64 = 1536;
	// bl 0x8247f370
	ctx.lr = 0x82A637E8;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,592(r31)
	PPC_STORE_U32(ctx.r31.u32 + 592, ctx.r3.u32);
	// beq 0x82a63814
	if (ctx.cr0.eq) goto loc_82A63814;
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// oris r11,r11,2048
	ctx.r11.u64 = ctx.r11.u64 | 134217728;
loc_82A637FC:
	// stw r11,612(r31)
	PPC_STORE_U32(ctx.r31.u32 + 612, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// ori r11,r11,16
	ctx.r11.u64 = ctx.r11.u64 | 16;
	// stb r11,608(r31)
	PPC_STORE_U8(ctx.r31.u32 + 608, ctx.r11.u8);
	// b 0x82a6381c
	goto loc_82A6381C;
loc_82A63814:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
loc_82A6381C:
	// addi r1,r1,480
	ctx.r1.s64 = ctx.r1.s64 + 480;
	// b 0x82d5c4f8
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A63828"))) PPC_WEAK_FUNC(sub_82A63828);
PPC_FUNC_IMPL(__imp__sub_82A63828) {
	PPC_FUNC_PROLOGUE();
	// lwz r10,596(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 596);
	// lwz r11,380(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 380);
	// lhz r9,14(r3)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r3.u32 + 14);
	// rlwinm r8,r10,12,26,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0x3F;
	// add r11,r4,r11
	ctx.r11.u64 = ctx.r4.u64 + ctx.r11.u64;
	// rlwinm r10,r10,18,26,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x3F;
	// addi r9,r9,172
	ctx.r9.s64 = ctx.r9.s64 + 172;
	// addi r7,r10,-1
	ctx.r7.s64 = ctx.r10.s64 + -1;
	// rlwinm r9,r9,9,0,22
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 9) & 0xFFFFFE00;
	// stw r11,380(r3)
	PPC_STORE_U32(ctx.r3.u32 + 380, ctx.r11.u32);
	// cmplw cr6,r8,r7
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, ctx.xer);
	// add r10,r9,r11
	ctx.r10.u64 = ctx.r9.u64 + ctx.r11.u64;
	// bne cr6,0x82a63864
	if (!ctx.cr6.eq) goto loc_82A63864;
	// lwz r9,384(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 384);
	// b 0x82a63868
	goto loc_82A63868;
loc_82A63864:
	// lis r9,-16
	ctx.r9.s64 = -1048576;
loc_82A63868:
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a63880
	if (ctx.cr6.lt) goto loc_82A63880;
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// blelr cr6
	if (!ctx.cr6.gt) return;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82A63880:
	// addi r10,r8,46
	ctx.r10.s64 = ctx.r8.s64 + 46;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r11,r10,r3
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, ctx.r11.u32);
	// lwz r11,596(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 596);
	// rlwinm r10,r11,12,26,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 12) & 0x3F;
	// rlwinm r9,r11,18,26,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 18) & 0x3F;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// twllei r9,0
	// divwu r8,r10,r9
	ctx.r8.u32 = ctx.r10.u32 / ctx.r9.u32;
	// mullw r9,r8,r9
	ctx.r9.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r9.s32);
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// rlwimi r11,r10,20,6,11
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 20) & 0x3F00000) | (ctx.r11.u64 & 0xFFFFFFFFFC0FFFFF);
	// stw r11,596(r3)
	PPC_STORE_U32(ctx.r3.u32 + 596, ctx.r11.u32);
	// rlwinm. r10,r11,0,6,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x3F00000;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82a638d4
	if (!ctx.cr0.eq) goto loc_82A638D4;
	// lbz r11,608(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 608);
	// li r10,2048
	ctx.r10.s64 = 2048;
	// ori r11,r11,32
	ctx.r11.u64 = ctx.r11.u64 | 32;
	// stw r10,380(r3)
	PPC_STORE_U32(ctx.r3.u32 + 380, ctx.r10.u32);
	// stb r11,608(r3)
	PPC_STORE_U8(ctx.r3.u32 + 608, ctx.r11.u8);
	// blr 
	return;
loc_82A638D4:
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,380(r3)
	PPC_STORE_U32(ctx.r3.u32 + 380, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A638E0"))) PPC_WEAK_FUNC(sub_82A638E0);
PPC_FUNC_IMPL(__imp__sub_82A638E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b8
	ctx.lr = 0x82A638E8;
	__savegprlr_24(ctx, base);
	// stwu r1,-2320(r1)
	ea = -2320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// li r26,0
	ctx.r26.s64 = 0;
	// addi r31,r25,21680
	ctx.r31.s64 = ctx.r25.s64 + 21680;
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// rlwinm. r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82a63c6c
	if (ctx.cr0.eq) goto loc_82A63C6C;
	// lwz r3,364(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 364);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a63c44
	if (ctx.cr0.eq) goto loc_82A63C44;
	// rlwinm. r10,r11,0,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// li r27,-1
	ctx.r27.s64 = -1;
	// beq 0x82a63a30
	if (ctx.cr0.eq) goto loc_82A63A30;
	// rlwinm. r11,r11,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a6392c
	if (ctx.cr0.eq) goto loc_82A6392C;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// bl 0x82a3a980
	ctx.lr = 0x82A6392C;
	sub_82A3A980(ctx, base);
loc_82A6392C:
	// lwz r28,16(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r3,588(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 588);
	// bl 0x82a50928
	ctx.lr = 0x82A63938;
	sub_82A50928(ctx, base);
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// addi r29,r11,-26256
	ctx.r29.s64 = ctx.r11.s64 + -26256;
	// lis r11,-31979
	ctx.r11.s64 = -2095775744;
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// addi r11,r11,-12800
	ctx.r11.s64 = ctx.r11.s64 + -12800;
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
loc_82A63950:
	// mfmsr r9
	ctx.r9.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r10,0,r8
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(ctx.reserved.u32);
	// stwcx. r11,0,r8
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r9,1
	ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82a63950
	if (!ctx.cr0.eq) goto loc_82A63950;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// li r9,6144
	ctx.r9.s64 = 6144;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// divwu r10,r11,r9
	ctx.r10.u32 = ctx.r11.u32 / ctx.r9.u32;
	// cmplwi cr6,r10,14
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 14, ctx.xer);
	// blt cr6,0x82a63988
	if (ctx.cr6.lt) goto loc_82A63988;
	// li r10,14
	ctx.r10.s64 = 14;
loc_82A63988:
	// lwz r9,584(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 584);
	// mulli r8,r10,12
	ctx.r8.s64 = ctx.r10.s64 * 12;
	// addi r7,r9,-1
	ctx.r7.s64 = ctx.r9.s64 + -1;
	// lwz r6,380(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 380);
	// lhz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 12);
	// lis r11,-25768
	ctx.r11.s64 = -1688731648;
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// ori r24,r11,59162
	ctx.r24.u64 = ctx.r11.u64 | 59162;
	// lwz r11,596(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 596);
	// rlwinm r7,r7,2,29,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0x4;
	// rlwinm r30,r9,9,0,22
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 9) & 0xFFFFFE00;
	// rlwinm r9,r11,4,30,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0x3;
	// rlwinm r11,r11,12,26,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 12) & 0x3F;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r11,r11,5
	ctx.r11.s64 = ctx.r11.s64 + 5;
	// lwzx r4,r7,r31
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r31.u32);
	// stw r6,356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 356, ctx.r6.u32);
	// addi r7,r31,348
	ctx.r7.s64 = ctx.r31.s64 + 348;
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r26,360(r31)
	PPC_STORE_U32(ctx.r31.u32 + 360, ctx.r26.u32);
	// addi r11,r4,-4
	ctx.r11.s64 = ctx.r4.s64 + -4;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lwzx r3,r8,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r31.u32);
	// stwu r24,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r24.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r28,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r28.u32);
	ctx.r11.u32 = ea;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// bl 0x82a3a500
	ctx.lr = 0x82A639F8;
	sub_82A3A500(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a63828
	ctx.lr = 0x82A63A04;
	sub_82A63828(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r3,364(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 364);
	// bl 0x82a3a980
	ctx.lr = 0x82A63A10;
	sub_82A3A980(ctx, base);
	// lis r30,-31979
	ctx.r30.s64 = -2095775744;
	// b 0x82a63a20
	goto loc_82A63A20;
loc_82A63A18:
	// li r3,6
	ctx.r3.s64 = 6;
	// bl 0x82a3ad50
	ctx.lr = 0x82A63A20;
	sub_82A3AD50(ctx, base);
loc_82A63A20:
	// lwz r11,-12792(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + -12792);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82a63a18
	if (!ctx.cr6.eq) goto loc_82A63A18;
loc_82A63A30:
	// lwz r11,596(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 596);
	// mr r30,r26
	ctx.r30.u64 = ctx.r26.u64;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// rlwinm. r11,r11,0,12,17
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFC000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a63aac
	if (ctx.cr0.eq) goto loc_82A63AAC;
	// addi r29,r31,20
	ctx.r29.s64 = ctx.r31.s64 + 20;
loc_82A63A48:
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// rlwinm. r11,r11,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a63a78
	if (!ctx.cr0.eq) goto loc_82A63A78;
	// lwz r11,596(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 596);
	// rlwinm r11,r11,12,26,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 12) & 0x3F;
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a63a78
	if (ctx.cr6.lt) goto loc_82A63A78;
	// ble cr6,0x82a63a70
	if (!ctx.cr6.gt) goto loc_82A63A70;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// b 0x82a63a7c
	goto loc_82A63A7C;
loc_82A63A70:
	// lwz r4,380(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 380);
	// b 0x82a63a7c
	goto loc_82A63A7C;
loc_82A63A78:
	// lwz r4,164(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 164);
loc_82A63A7C:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// bl 0x82a3b1e0
	ctx.lr = 0x82A63A8C;
	sub_82A3B1E0(ctx, base);
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// bl 0x82e99950
	ctx.lr = 0x82A63A94;
	sub_82E99950(ctx, base);
	// lwz r11,596(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 596);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// rlwinm r11,r11,18,26,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 18) & 0x3F;
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a63a48
	if (ctx.cr6.lt) goto loc_82A63A48;
loc_82A63AAC:
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8308b234
	ctx.lr = 0x82A63AB4;
	__imp__VdGetCurrentDisplayInformation(ctx, base);
	// lwz r11,604(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 604);
	// srawi. r11,r11,29
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1FFFFFFF) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 29;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a63acc
	if (!ctx.cr0.eq) goto loc_82A63ACC;
	// lis r10,21415
	ctx.r10.s64 = 1403453440;
	// ori r10,r10,8884
	ctx.r10.u64 = ctx.r10.u64 | 8884;
	// b 0x82a63af0
	goto loc_82A63AF0;
loc_82A63ACC:
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82a63ae0
	if (!ctx.cr6.eq) goto loc_82A63AE0;
	// lis r10,21415
	ctx.r10.s64 = 1403453440;
	// ori r10,r10,8885
	ctx.r10.u64 = ctx.r10.u64 | 8885;
	// b 0x82a63af0
	goto loc_82A63AF0;
loc_82A63AE0:
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82a63af4
	if (!ctx.cr6.eq) goto loc_82A63AF4;
	// lis r10,21415
	ctx.r10.s64 = 1403453440;
	// ori r10,r10,8886
	ctx.r10.u64 = ctx.r10.u64 | 8886;
loc_82A63AF0:
	// stw r10,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r10.u32);
loc_82A63AF4:
	// lis r10,1
	ctx.r10.s64 = 65536;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stw r10,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r10.u32);
	// beq cr6,0x82a63b30
	if (ctx.cr6.eq) goto loc_82A63B30;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x82a63b30
	if (ctx.cr6.eq) goto loc_82A63B30;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82a63b50
	if (!ctx.cr6.eq) goto loc_82A63B50;
	// li r10,400
	ctx.r10.s64 = 400;
	// li r11,224
	ctx.r11.s64 = 224;
	// stw r10,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, ctx.r10.u32);
	// stw r11,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r11.u32);
	// stw r10,216(r1)
	PPC_STORE_U32(ctx.r1.u32 + 216, ctx.r10.u32);
	// b 0x82a63b4c
	goto loc_82A63B4C;
loc_82A63B30:
	// lhz r11,368(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 368);
	// stw r11,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, ctx.r11.u32);
	// lhz r11,370(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 370);
	// stw r11,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r11.u32);
	// lhz r11,168(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 168);
	// stw r11,216(r1)
	PPC_STORE_U32(ctx.r1.u32 + 216, ctx.r11.u32);
	// lhz r11,170(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 170);
loc_82A63B4C:
	// stw r11,220(r1)
	PPC_STORE_U32(ctx.r1.u32 + 220, ctx.r11.u32);
loc_82A63B50:
	// bl 0x8308af24
	ctx.lr = 0x82A63B54;
	__imp__KeQueryPerformanceFrequency(ctx, base);
	// lwz r10,596(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 596);
	// mr r9,r26
	ctx.r9.u64 = ctx.r26.u64;
	// stw r3,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, ctx.r3.u32);
	// rlwinm r11,r10,6,26,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0x3F;
	// stw r9,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, ctx.r9.u32);
	// clrlwi. r8,r11,31
	ctx.r8.u64 = ctx.r11.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a63b78
	if (ctx.cr0.eq) goto loc_82A63B78;
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r9,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, ctx.r9.u32);
loc_82A63B78:
	// rlwinm. r11,r11,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a63b88
	if (ctx.cr0.eq) goto loc_82A63B88;
	// ori r9,r9,2
	ctx.r9.u64 = ctx.r9.u64 | 2;
	// stw r9,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, ctx.r9.u32);
loc_82A63B88:
	// rlwinm. r11,r10,0,0,0
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a63b98
	if (ctx.cr0.eq) goto loc_82A63B98;
	// lwz r4,592(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 592);
	// b 0x82a63b9c
	goto loc_82A63B9C;
loc_82A63B98:
	// addi r4,r25,15004
	ctx.r4.s64 = ctx.r25.s64 + 15004;
loc_82A63B9C:
	// lbz r11,101(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 101);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r3,r1,288
	ctx.r3.s64 = ctx.r1.s64 + 288;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// bne cr6,0x82a63bc0
	if (!ctx.cr6.eq) goto loc_82A63BC0;
	// ori r11,r9,4
	ctx.r11.u64 = ctx.r9.u64 | 4;
	// stw r11,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, ctx.r11.u32);
	// bl 0x82a5ede8
	ctx.lr = 0x82A63BBC;
	sub_82A5EDE8(ctx, base);
	// b 0x82a63bc4
	goto loc_82A63BC4;
loc_82A63BC0:
	// bl 0x82a5ed50
	ctx.lr = 0x82A63BC4;
	sub_82A5ED50(ctx, base);
loc_82A63BC4:
	// lwz r30,596(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 596);
	// addi r3,r1,232
	ctx.r3.s64 = ctx.r1.s64 + 232;
	// li r5,56
	ctx.r5.s64 = 56;
	// addi r4,r25,13724
	ctx.r4.s64 = ctx.r25.s64 + 13724;
	// rlwinm. r11,r30,0,5,5
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 0) & 0x4000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a63be0
	if (!ctx.cr0.eq) goto loc_82A63BE0;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
loc_82A63BE0:
	// bl 0x82d5c630
	ctx.lr = 0x82A63BE4;
	sub_82D5C630(ctx, base);
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// rlwinm. r11,r11,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a63c04
	if (ctx.cr0.eq) goto loc_82A63C04;
	// lwz r11,380(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 380);
	// stw r11,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, ctx.r11.u32);
	// rlwinm r11,r30,12,26,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 12) & 0x3F;
	// stw r11,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r11.u32);
	// b 0x82a63c10
	goto loc_82A63C10;
loc_82A63C04:
	// li r11,2048
	ctx.r11.s64 = 2048;
	// stw r26,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r26.u32);
	// stw r11,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, ctx.r11.u32);
loc_82A63C10:
	// addi r7,r31,348
	ctx.r7.s64 = ctx.r31.s64 + 348;
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stw r26,356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 356, ctx.r26.u32);
	// li r5,2048
	ctx.r5.s64 = 2048;
	// stw r26,360(r31)
	PPC_STORE_U32(ctx.r31.u32 + 360, ctx.r26.u32);
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// bl 0x82a3a500
	ctx.lr = 0x82A63C30;
	sub_82A3A500(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r3,364(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 364);
	// bl 0x82a3a980
	ctx.lr = 0x82A63C3C;
	sub_82A3A980(ctx, base);
	// lwz r3,364(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 364);
	// bl 0x82a3a2c0
	ctx.lr = 0x82A63C44;
	sub_82A3A2C0(ctx, base);
loc_82A63C44:
	// mr r30,r26
	ctx.r30.u64 = ctx.r26.u64;
	// addi r31,r31,20
	ctx.r31.s64 = ctx.r31.s64 + 20;
loc_82A63C4C:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmpwi cr6,r3,-1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, -1, ctx.xer);
	// beq cr6,0x82a63c6c
	if (ctx.cr6.eq) goto loc_82A63C6C;
	// bl 0x82a3a2c0
	ctx.lr = 0x82A63C5C;
	sub_82A3A2C0(ctx, base);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r30,41
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 41, ctx.xer);
	// blt cr6,0x82a63c4c
	if (ctx.cr6.lt) goto loc_82A63C4C;
loc_82A63C6C:
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2020(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2020);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a63c9c
	if (ctx.cr6.eq) goto loc_82A63C9C;
	// rotlwi r11,r10,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a63cc8
	if (ctx.cr0.eq) goto loc_82A63CC8;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a63cc8
	if (ctx.cr0.eq) goto loc_82A63CC8;
	// b 0x82a63cb4
	goto loc_82A63CB4;
loc_82A63C9C:
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2332(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a63cc8
	if (ctx.cr0.eq) goto loc_82A63CC8;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
loc_82A63CB4:
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// li r3,27
	ctx.r3.s64 = 27;
	// addi r4,r10,24664
	ctx.r4.s64 = ctx.r10.s64 + 24664;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A63CC8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A63CC8:
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82a62a68
	ctx.lr = 0x82A63CD0;
	sub_82A62A68(ctx, base);
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// addi r3,r11,-26232
	ctx.r3.s64 = ctx.r11.s64 + -26232;
	// bl 0x8308b354
	ctx.lr = 0x82A63CDC;
	__imp__ObDeleteSymbolicLink(ctx, base);
	// lis r11,-31980
	ctx.r11.s64 = -2095841280;
	// mr r10,r26
	ctx.r10.u64 = ctx.r26.u64;
	// addi r11,r11,27342
	ctx.r11.s64 = ctx.r11.s64 + 27342;
	// stb r10,-2(r11)
	PPC_STORE_U8(ctx.r11.u32 + -2, ctx.r10.u8);
	// stb r10,-1(r11)
	PPC_STORE_U8(ctx.r11.u32 + -1, ctx.r10.u8);
	// stb r10,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r10.u8);
	// addi r1,r1,2320
	ctx.r1.s64 = ctx.r1.s64 + 2320;
	// b 0x82d5c508
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A63D00"))) PPC_WEAK_FUNC(sub_82A63D00);
PPC_FUNC_IMPL(__imp__sub_82A63D00) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4ac
	ctx.lr = 0x82A63D08;
	__savegprlr_21(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// li r6,16
	ctx.r6.s64 = 16;
	// li r5,112
	ctx.r5.s64 = 112;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r30,r31,21680
	ctx.r30.s64 = ctx.r31.s64 + 21680;
	// bl 0x82a49cd8
	ctx.lr = 0x82A63D28;
	sub_82A49CD8(ctx, base);
	// ld r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// cmpldi cr6,r4,0
	ctx.cr6.compare<uint64_t>(ctx.r4.u64, 0, ctx.xer);
	// beq cr6,0x82a63e48
	if (ctx.cr6.eq) goto loc_82A63E48;
	// ld r11,40(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 40);
	// and r11,r11,r4
	ctx.r11.u64 = ctx.r11.u64 & ctx.r4.u64;
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82a63d54
	if (ctx.cr6.eq) goto loc_82A63D54;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r5,10560(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10560);
	// bl 0x82a598a8
	ctx.lr = 0x82A63D50;
	sub_82A598A8(ctx, base);
	// std r3,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r3.u64);
loc_82A63D54:
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// clrldi r10,r11,52
	ctx.r10.u64 = ctx.r11.u64 & 0xFFF;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// beq cr6,0x82a63d84
	if (ctx.cr6.eq) goto loc_82A63D84;
	// addi r6,r31,10548
	ctx.r6.s64 = ctx.r31.s64 + 10548;
	// li r5,8704
	ctx.r5.s64 = 8704;
	// rldicr r4,r11,52,11
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u64, 52) & 0xFFF0000000000000;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a59c40
	ctx.lr = 0x82A63D78;
	sub_82A59C40(ctx, base);
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// rldicr r11,r11,0,51
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u64, 0) & 0xFFFFFFFFFFFFF000;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
loc_82A63D84:
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// rlwinm r10,r11,0,15,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1F000;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// beq cr6,0x82a63dbc
	if (ctx.cr6.eq) goto loc_82A63DBC;
	// addi r6,r31,10528
	ctx.r6.s64 = ctx.r31.s64 + 10528;
	// li r5,8576
	ctx.r5.s64 = 8576;
	// rldicr r4,r11,47,4
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u64, 47) & 0xF800000000000000;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a59c40
	ctx.lr = 0x82A63DA8;
	sub_82A59C40(ctx, base);
	// lis r12,-2
	ctx.r12.s64 = -131072;
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r12,r12,4095
	ctx.r12.u64 = ctx.r12.u64 | 4095;
	// and r11,r11,r12
	ctx.r11.u64 = ctx.r11.u64 & ctx.r12.u64;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
loc_82A63DBC:
	// lis r12,0
	ctx.r12.s64 = 0;
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r12,r12,65535
	ctx.r12.u64 = ctx.r12.u64 | 65535;
	// rldicr r12,r12,42,21
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 42) & 0xFFFFFC0000000000;
	// and r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 & ctx.r12.u64;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// beq cr6,0x82a63e04
	if (ctx.cr6.eq) goto loc_82A63E04;
	// addi r6,r31,10368
	ctx.r6.s64 = ctx.r31.s64 + 10368;
	// li r5,8192
	ctx.r5.s64 = 8192;
	// rldicr r4,r11,6,15
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u64, 6) & 0xFFFF000000000000;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a59c40
	ctx.lr = 0x82A63DEC;
	sub_82A59C40(ctx, base);
	// lis r12,-1
	ctx.r12.s64 = -65536;
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r12,r12,0
	ctx.r12.u64 = ctx.r12.u64 | 0;
	// rldicr r12,r12,42,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 42) & 0xFFFFFFFFFFFFFFFF;
	// and r11,r11,r12
	ctx.r11.u64 = ctx.r11.u64 & ctx.r12.u64;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
loc_82A63E04:
	// lis r12,-32
	ctx.r12.s64 = -2097152;
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// clrldi r12,r12,22
	ctx.r12.u64 = ctx.r12.u64 & 0x3FFFFFFFFFF;
	// and r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 & ctx.r12.u64;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// beq cr6,0x82a63e48
	if (ctx.cr6.eq) goto loc_82A63E48;
	// addi r6,r31,10444
	ctx.r6.s64 = ctx.r31.s64 + 10444;
	// li r5,8448
	ctx.r5.s64 = 8448;
	// rldicr r4,r11,22,20
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u64, 22) & 0xFFFFF80000000000;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a59c40
	ctx.lr = 0x82A63E30;
	sub_82A59C40(ctx, base);
	// lis r12,-32
	ctx.r12.s64 = -2097152;
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r12,r12,0
	ctx.r12.u64 = ctx.r12.u64 | 0;
	// rldicr r12,r12,21,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 21) & 0xFFFFFFFFFFFFFFFF;
	// and r11,r11,r12
	ctx.r11.u64 = ctx.r11.u64 & ctx.r12.u64;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
loc_82A63E48:
	// ld r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 24);
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82a63e98
	if (ctx.cr6.eq) goto loc_82A63E98;
	// lis r12,31
	ctx.r12.s64 = 2031616;
	// ori r12,r12,65535
	ctx.r12.u64 = ctx.r12.u64 | 65535;
	// rldicr r12,r12,34,29
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 34) & 0xFFFFFFFC00000000;
	// and r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 & ctx.r12.u64;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// beq cr6,0x82a63e98
	if (ctx.cr6.eq) goto loc_82A63E98;
	// addi r6,r31,10596
	ctx.r6.s64 = ctx.r31.s64 + 10596;
	// li r5,8832
	ctx.r5.s64 = 8832;
	// rldicr r4,r11,9,20
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u64, 9) & 0xFFFFF80000000000;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a59c40
	ctx.lr = 0x82A63E80;
	sub_82A59C40(ctx, base);
	// lis r12,-32
	ctx.r12.s64 = -2097152;
	// ld r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 24);
	// ori r12,r12,0
	ctx.r12.u64 = ctx.r12.u64 | 0;
	// rldicr r12,r12,34,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 34) & 0xFFFFFFFFFFFFFFFF;
	// and r11,r11,r12
	ctx.r11.u64 = ctx.r11.u64 & ctx.r12.u64;
	// std r11,24(r31)
	PPC_STORE_U64(ctx.r31.u32 + 24, ctx.r11.u64);
loc_82A63E98:
	// ld r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82a63ed0
	if (ctx.cr6.eq) goto loc_82A63ED0;
	// clrldi r10,r11,26
	ctx.r10.u64 = ctx.r11.u64 & 0x3FFFFFFFFF;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// beq cr6,0x82a63ed0
	if (ctx.cr6.eq) goto loc_82A63ED0;
	// addi r6,r31,10680
	ctx.r6.s64 = ctx.r31.s64 + 10680;
	// li r5,8960
	ctx.r5.s64 = 8960;
	// rldicr r4,r11,26,37
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u64, 26) & 0xFFFFFFFFFC000000;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a59c40
	ctx.lr = 0x82A63EC4;
	sub_82A59C40(ctx, base);
	// ld r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// rldicr r11,r11,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u64, 0) & 0xFFFFFFC000000000;
	// std r11,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r11.u64);
loc_82A63ED0:
	// lwz r11,604(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 604);
	// lis r10,-32240
	ctx.r10.s64 = -2112880640;
	// srawi. r11,r11,29
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1FFFFFFF) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 29;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// addi r25,r10,17664
	ctx.r25.s64 = ctx.r10.s64 + 17664;
	// bne 0x82a63ef8
	if (!ctx.cr0.eq) goto loc_82A63EF8;
	// lis r26,1792
	ctx.r26.s64 = 117440512;
	// li r28,525
	ctx.r28.s64 = 525;
	// mr r27,r25
	ctx.r27.u64 = ctx.r25.u64;
	// ori r26,r26,21
	ctx.r26.u64 = ctx.r26.u64 | 21;
	// b 0x82a63f3c
	goto loc_82A63F3C;
loc_82A63EF8:
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82a63f14
	if (!ctx.cr6.eq) goto loc_82A63F14;
	// lis r26,1792
	ctx.r26.s64 = 117440512;
	// addi r27,r25,2160
	ctx.r27.s64 = ctx.r25.s64 + 2160;
	// li r28,933
	ctx.r28.s64 = 933;
	// ori r26,r26,19
	ctx.r26.u64 = ctx.r26.u64 | 19;
	// b 0x82a63f3c
	goto loc_82A63F3C;
loc_82A63F14:
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82a63f30
	if (!ctx.cr6.eq) goto loc_82A63F30;
	// lis r26,1792
	ctx.r26.s64 = 117440512;
	// addi r27,r25,5896
	ctx.r27.s64 = ctx.r25.s64 + 5896;
	// li r28,210
	ctx.r28.s64 = 210;
	// ori r26,r26,15
	ctx.r26.u64 = ctx.r26.u64 | 15;
	// b 0x82a63f3c
	goto loc_82A63F3C;
loc_82A63F30:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r27,80(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r26,80(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82A63F3C:
	// addi r4,r28,5
	ctx.r4.s64 = ctx.r28.s64 + 5;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50f88
	ctx.lr = 0x82A63F48;
	sub_82A50F88(ctx, base);
	// lis r11,-16384
	ctx.r11.s64 = -1073741824;
	// li r10,768
	ctx.r10.s64 = 768;
	// ori r11,r11,15104
	ctx.r11.u64 = ctx.r11.u64 | 15104;
	// lis r8,-16384
	ctx.r8.s64 = -1073741824;
	// addi r9,r28,1
	ctx.r9.s64 = ctx.r28.s64 + 1;
	// ori r8,r8,11008
	ctx.r8.u64 = ctx.r8.u64 | 11008;
	// li r22,0
	ctx.r22.s64 = 0;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// rlwimi r8,r9,16,2,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r9.u32, 16) & 0x3FFF0000) | (ctx.r8.u64 & 0xFFFFFFFFC000FFFF);
	// mr r7,r22
	ctx.r7.u64 = ctx.r22.u64;
	// clrlwi r9,r28,18
	ctx.r9.u64 = ctx.r28.u32 & 0x3FFF;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// rlwinm r28,r28,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// stwu r8,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r3.u32 = ea;
	// stwu r7,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r3.u32 = ea;
	// stwu r9,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r3.u32 = ea;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// addi r3,r27,4
	ctx.r3.s64 = ctx.r27.s64 + 4;
	// bl 0x82d5c630
	ctx.lr = 0x82A63F9C;
	sub_82D5C630(ctx, base);
	// add r3,r28,r27
	ctx.r3.u64 = ctx.r28.u64 + ctx.r27.u64;
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
	// ble cr6,0x82a63fb8
	if (!ctx.cr6.gt) goto loc_82A63FB8;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50d68
	ctx.lr = 0x82A63FB8;
	sub_82A50D68(ctx, base);
loc_82A63FB8:
	// lis r11,-16368
	ctx.r11.s64 = -1072693248;
	// li r10,1
	ctx.r10.s64 = 1;
	// ori r11,r11,11008
	ctx.r11.u64 = ctx.r11.u64 | 11008;
	// li r9,15
	ctx.r9.s64 = 15;
	// addi r4,r25,2100
	ctx.r4.s64 = ctx.r25.s64 + 2100;
	// li r5,60
	ctx.r5.s64 = 60;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// stwu r9,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r3.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// addi r3,r28,4
	ctx.r3.s64 = ctx.r28.s64 + 4;
	// bl 0x82d5c630
	ctx.lr = 0x82A63FE8;
	sub_82D5C630(ctx, base);
	// lis r10,1
	ctx.r10.s64 = 65536;
	// addi r11,r28,60
	ctx.r11.s64 = ctx.r28.s64 + 60;
	// ori r10,r10,8576
	ctx.r10.u64 = ctx.r10.u64 | 8576;
	// oris r9,r26,4096
	ctx.r9.u64 = ctx.r26.u64 | 268435456;
	// mr r8,r22
	ctx.r8.u64 = ctx.r22.u64;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// cmplw cr6,r3,r10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r10.u32, ctx.xer);
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
	// ble cr6,0x82a64024
	if (!ctx.cr6.gt) goto loc_82A64024;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50d68
	ctx.lr = 0x82A64024;
	sub_82A50D68(ctx, base);
loc_82A64024:
	// lis r11,2
	ctx.r11.s64 = 131072;
	// mr r9,r22
	ctx.r9.u64 = ctx.r22.u64;
	// ori r10,r11,8448
	ctx.r10.u64 = ctx.r11.u64 | 8448;
	// lis r11,0
	ctx.r11.s64 = 0;
	// mr r7,r22
	ctx.r7.u64 = ctx.r22.u64;
	// ori r11,r11,65535
	ctx.r11.u64 = ctx.r11.u64 | 65535;
	// li r6,8851
	ctx.r6.s64 = 8851;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// lis r10,2
	ctx.r10.s64 = 131072;
	// li r27,768
	ctx.r27.s64 = 768;
	// ori r4,r10,8708
	ctx.r4.u64 = ctx.r10.u64 | 8708;
	// stwu r8,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r3.u32 = ea;
	// lis r10,1
	ctx.r10.s64 = 65536;
	// li r26,8978
	ctx.r26.s64 = 8978;
	// mr r28,r10
	ctx.r28.u64 = ctx.r10.u64;
	// li r25,8205
	ctx.r25.s64 = 8205;
	// mr r24,r22
	ctx.r24.u64 = ctx.r22.u64;
	// stwu r9,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r3.u32 = ea;
	// li r23,8704
	ctx.r23.s64 = 8704;
	// mr r21,r22
	ctx.r21.u64 = ctx.r22.u64;
	// stwu r7,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r3.u32 = ea;
	// stwu r6,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r3.u32 = ea;
	// stwu r5,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	ctx.r3.u32 = ea;
	// stwu r4,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r4.u32);
	ctx.r3.u32 = ea;
	// stwu r28,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r28.u32);
	ctx.r3.u32 = ea;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// stwu r27,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r27.u32);
	ctx.r3.u32 = ea;
	// stwu r26,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r26.u32);
	ctx.r3.u32 = ea;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// stwu r25,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r25.u32);
	ctx.r3.u32 = ea;
	// stwu r24,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r24.u32);
	ctx.r3.u32 = ea;
	// stwu r23,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r23.u32);
	ctx.r3.u32 = ea;
	// stwu r21,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r21.u32);
	ctx.r3.u32 = ea;
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
	// ble cr6,0x82a640c8
	if (!ctx.cr6.gt) goto loc_82A640C8;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50d68
	ctx.lr = 0x82A640C8;
	sub_82A50D68(ctx, base);
loc_82A640C8:
	// lis r11,5
	ctx.r11.s64 = 327680;
	// addi r28,r30,392
	ctx.r28.s64 = ctx.r30.s64 + 392;
	// ori r11,r11,18432
	ctx.r11.u64 = ctx.r11.u64 | 18432;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// lwz r10,28(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 28);
	// lhz r11,372(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 372);
	// rlwinm r10,r10,0,22,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x3FC;
	// rlwinm r11,r11,17,0,9
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 17) & 0xFFC00000;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// oris r11,r11,32768
	ctx.r11.u64 = ctx.r11.u64 | 2147483648;
	// ori r11,r11,18434
	ctx.r11.u64 = ctx.r11.u64 | 18434;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// lwz r11,32(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 32);
	// rlwinm r9,r11,12,20,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 12) & 0xFFF;
	// clrlwi r10,r11,3
	ctx.r10.u64 = ctx.r11.u32 & 0x1FFFFFFF;
	// addi r11,r9,512
	ctx.r11.s64 = ctx.r9.s64 + 512;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r11,r11,0,19,19
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// lwz r11,36(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 36);
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// lwz r11,40(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 40);
	// rotlwi r10,r11,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// rlwinm r11,r11,13,0,18
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 13) & 0xFFFFE000;
	// rlwinm r10,r10,0,19,7
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFF001FFF;
	// srawi r11,r11,13
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1FFF) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 13;
	// rlwinm r10,r10,0,7,0
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFF81FFFFFF;
	// rlwimi r11,r9,24,19,12
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r9.u32, 24) & 0xFFFFFFFFFFF81FFF) | (ctx.r11.u64 & 0x7E000);
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// lwz r11,44(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 44);
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// lwz r11,48(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 48);
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
	// lwz r11,596(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 596);
	// lwz r10,584(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 584);
	// rlwinm r27,r11,2,30,31
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0x3;
	// lwz r11,604(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 604);
	// rlwinm r10,r10,2,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0x4;
	// clrlwi r24,r27,31
	ctx.r24.u64 = ctx.r27.u32 & 0x1;
	// srawi. r11,r11,29
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1FFFFFFF) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 29;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// mulli r9,r24,56
	ctx.r9.s64 = ctx.r24.s64 * 56;
	// lwzx r25,r10,r30
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r30.u32);
	// rlwinm r10,r27,31,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 31) & 0x1;
	// addi r9,r9,527
	ctx.r9.s64 = ctx.r9.s64 + 527;
	// mulli r10,r10,1536
	ctx.r10.s64 = ctx.r10.s64 * 1536;
	// rlwinm r9,r9,0,0,22
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFE00;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// add r29,r10,r25
	ctx.r29.u64 = ctx.r10.u64 + ctx.r25.u64;
	// bne 0x82a641c0
	if (!ctx.cr0.eq) goto loc_82A641C0;
loc_82A64198:
	// lwz r8,8(r28)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// rlwinm r9,r29,0,3,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x1FFFFFFC;
	// rlwinm r10,r29,12,20,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 12) & 0xFFF;
	// addi r10,r10,512
	ctx.r10.s64 = ctx.r10.s64 + 512;
	// rlwinm r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// andi. r9,r8,49400
	ctx.r9.u64 = ctx.r8.u64 & 49400;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// oris r9,r9,19200
	ctx.r9.u64 = ctx.r9.u64 | 1258291200;
	// ori r9,r9,1536
	ctx.r9.u64 = ctx.r9.u64 | 1536;
	// b 0x82a641f4
	goto loc_82A641F4;
loc_82A641C0:
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x82a64198
	if (ctx.cr6.eq) goto loc_82A64198;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82a6421c
	if (!ctx.cr6.eq) goto loc_82A6421C;
	// lwz r8,8(r28)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// rlwinm r9,r29,0,3,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x1FFFFFFC;
	// rlwinm r10,r29,12,20,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 12) & 0xFFF;
	// addi r10,r10,512
	ctx.r10.s64 = ctx.r10.s64 + 512;
	// rlwinm r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// andi. r9,r8,49400
	ctx.r9.u64 = ctx.r8.u64 & 49400;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// oris r9,r9,19200
	ctx.r9.u64 = ctx.r9.u64 | 1258291200;
	// ori r9,r9,2560
	ctx.r9.u64 = ctx.r9.u64 | 2560;
loc_82A641F4:
	// lis r7,16384
	ctx.r7.s64 = 1073741824;
	// lwz r11,388(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 388);
	// li r6,75
	ctx.r6.s64 = 75;
	// stw r9,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r9.u32);
	// rlwimi r7,r10,30,2,31
	ctx.r7.u64 = (__builtin_rotateleft32(ctx.r10.u32, 30) & 0x3FFFFFFF) | (ctx.r7.u64 & 0xFFFFFFFFC0000000);
	// lis r10,19200
	ctx.r10.s64 = 1258291200;
	// rlwimi r11,r6,24,0,8
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r6.u32, 24) & 0xFF800000) | (ctx.r11.u64 & 0xFFFFFFFF007FFFFF);
	// stw r7,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r7.u32);
	// stw r10,4(r28)
	PPC_STORE_U32(ctx.r28.u32 + 4, ctx.r10.u32);
	// stw r11,12(r28)
	PPC_STORE_U32(ctx.r28.u32 + 12, ctx.r11.u32);
loc_82A6421C:
	// li r4,49
	ctx.r4.s64 = 49;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50f88
	ctx.lr = 0x82A64228;
	sub_82A50F88(ctx, base);
	// lis r11,47
	ctx.r11.s64 = 3080192;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// ori r11,r11,16384
	ctx.r11.u64 = ctx.r11.u64 | 16384;
	// li r5,192
	ctx.r5.s64 = 192;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// addi r3,r28,4
	ctx.r3.s64 = ctx.r28.s64 + 4;
	// bl 0x82d5c630
	ctx.lr = 0x82A64248;
	sub_82D5C630(ctx, base);
	// addi r11,r28,192
	ctx.r11.s64 = ctx.r28.s64 + 192;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// lbz r11,608(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 608);
	// rlwinm. r11,r11,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a64268
	if (ctx.cr0.eq) goto loc_82A64268;
	// li r4,-1
	ctx.r4.s64 = -1;
	// lwz r3,364(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 364);
	// bl 0x82a3a980
	ctx.lr = 0x82A64268;
	sub_82A3A980(ctx, base);
loc_82A64268:
	// lhz r10,14(r30)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r30.u32 + 14);
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// rotlwi r10,r10,9
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 9);
	// addi r11,r11,-26256
	ctx.r11.s64 = ctx.r11.s64 + -26256;
	// add r9,r10,r29
	ctx.r9.u64 = ctx.r10.u64 + ctx.r29.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A64280:
	// mfmsr r7
	ctx.r7.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r8,0,r10
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r10.u32);
	ctx.r8.u64 = __builtin_bswap32(ctx.reserved.u32);
	// stwcx. r9,0,r10
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r10.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r9.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r7,1
	ctx.msr = (ctx.r7.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82a64280
	if (!ctx.cr0.eq) goto loc_82A64280;
	// mr r11,r8
	ctx.r11.u64 = ctx.r8.u64;
	// lwz r8,8(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// li r7,6144
	ctx.r7.s64 = 6144;
	// subf r11,r8,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r8.s64;
	// divwu r11,r11,r7
	ctx.r11.u32 = ctx.r11.u32 / ctx.r7.u32;
	// cmplwi cr6,r11,14
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 14, ctx.xer);
	// mr r23,r11
	ctx.r23.u64 = ctx.r11.u64;
	// blt cr6,0x82a642bc
	if (ctx.cr6.lt) goto loc_82A642BC;
	// li r23,14
	ctx.r23.s64 = 14;
loc_82A642BC:
	// lwz r11,584(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 584);
	// lis r10,-25768
	ctx.r10.s64 = -1688731648;
	// stw r9,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r9.u32);
	// clrlwi r8,r29,3
	ctx.r8.u64 = ctx.r29.u32 & 0x1FFFFFFF;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// lwz r7,596(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 596);
	// ori r6,r10,59162
	ctx.r6.u64 = ctx.r10.u64 | 59162;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// rlwinm r5,r11,2,29,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0x4;
	// lwz r3,48(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// rlwinm r11,r29,12,20,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 12) & 0xFFF;
	// lwz r4,56(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// rlwinm r7,r7,4,30,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0x3;
	// addi r9,r11,512
	ctx.r9.s64 = ctx.r11.s64 + 512;
	// cmplw cr6,r3,r4
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r4.u32, ctx.xer);
	// lwzx r11,r5,r30
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r30.u32);
	// rlwinm r9,r9,0,19,19
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x1000;
	// addi r11,r11,-4
	ctx.r11.s64 = ctx.r11.s64 + -4;
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// stwu r6,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r11.u32 = ea;
	// stw r9,10392(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10392, ctx.r9.u32);
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r23,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r23.u32);
	ctx.r11.u32 = ea;
	// ble cr6,0x82a64328
	if (!ctx.cr6.gt) goto loc_82A64328;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50d68
	ctx.lr = 0x82A64328;
	sub_82A50D68(ctx, base);
loc_82A64328:
	// li r11,8198
	ctx.r11.s64 = 8198;
	// mr r10,r22
	ctx.r10.u64 = ctx.r22.u64;
	// mr r28,r22
	ctx.r28.u64 = ctx.r22.u64;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// lwz r11,13504(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13504);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
	// stw r11,13504(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13504, ctx.r11.u32);
	// lwz r29,376(r30)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r30.u32 + 376);
loc_82A64350:
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a6436c
	if (!ctx.cr6.gt) goto loc_82A6436C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50d68
	ctx.lr = 0x82A64368;
	sub_82A50D68(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82A6436C:
	// li r9,8450
	ctx.r9.s64 = 8450;
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
	// cmplwi cr6,r29,65535
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 65535, ctx.xer);
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r28,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r28.u32);
	ctx.r11.u32 = ea;
	// ble cr6,0x82a6438c
	if (!ctx.cr6.gt) goto loc_82A6438C;
	// lis r10,0
	ctx.r10.s64 = 0;
	// ori r10,r10,65534
	ctx.r10.u64 = ctx.r10.u64 | 65534;
loc_82A6438C:
	// lis r9,-16384
	ctx.r9.s64 = -1073741824;
	// li r8,129
	ctx.r8.s64 = 129;
	// ori r9,r9,13825
	ctx.r9.u64 = ctx.r9.u64 | 13825;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// subf. r29,r10,r29
	ctx.r29.s64 = ctx.r29.s64 - ctx.r10.s64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// beq 0x82a643b8
	if (ctx.cr0.eq) goto loc_82A643B8;
	// add r28,r10,r28
	ctx.r28.u64 = ctx.r10.u64 + ctx.r28.u64;
	// b 0x82a64350
	goto loc_82A64350;
loc_82A643B8:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// stw r22,10392(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10392, ctx.r22.u32);
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a643d4
	if (!ctx.cr6.gt) goto loc_82A643D4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50d68
	ctx.lr = 0x82A643D4;
	sub_82A50D68(ctx, base);
loc_82A643D4:
	// li r11,8198
	ctx.r11.s64 = 8198;
	// mr r10,r22
	ctx.r10.u64 = ctx.r22.u64;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// lwz r10,13504(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13504);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lwz r9,56(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// stw r10,13504(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13504, ctx.r10.u32);
	// ble cr6,0x82a64410
	if (!ctx.cr6.gt) goto loc_82A64410;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a50d68
	ctx.lr = 0x82A6440C;
	sub_82A50D68(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82A64410:
	// lis r10,-16384
	ctx.r10.s64 = -1073741824;
	// li r9,6
	ctx.r9.s64 = 6;
	// ori r10,r10,17920
	ctx.r10.u64 = ctx.r10.u64 | 17920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r11,r11,8
	ctx.r11.u64 = ctx.r11.u64 | 8;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// oris r11,r11,8
	ctx.r11.u64 = ctx.r11.u64 | 524288;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// oris r11,r11,16
	ctx.r11.u64 = ctx.r11.u64 | 1048576;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// ld r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 24);
	// oris r11,r11,65024
	ctx.r11.u64 = ctx.r11.u64 | 4261412864;
	// std r11,24(r31)
	PPC_STORE_U64(ctx.r31.u32 + 24, ctx.r11.u64);
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r11,r11,2048
	ctx.r11.u64 = ctx.r11.u64 | 2048;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// ori r11,r11,256
	ctx.r11.u64 = ctx.r11.u64 | 256;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// lwz r26,588(r30)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r30.u32 + 588);
	// bl 0x82a50e68
	ctx.lr = 0x82A64470;
	sub_82A50E68(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,588(r30)
	PPC_STORE_U32(ctx.r30.u32 + 588, ctx.r11.u32);
	// bl 0x82a49cd8
	ctx.lr = 0x82A6448C;
	sub_82A49CD8(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a49cd8
	ctx.lr = 0x82A644A0;
	sub_82A49CD8(ctx, base);
	// lwz r11,596(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 596);
	// clrlwi r28,r27,30
	ctx.r28.u64 = ctx.r27.u32 & 0x3;
	// rlwinm r11,r11,0,4,1
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFCFFFFFFF;
	// rlwinm r10,r28,28,0,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 28) & 0xF0000000;
	// addi r29,r25,16
	ctx.r29.s64 = ctx.r25.s64 + 16;
	// or r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 | ctx.r11.u64;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// stw r11,596(r30)
	PPC_STORE_U32(ctx.r30.u32 + 596, ctx.r11.u32);
	// beq cr6,0x82a644d8
	if (ctx.cr6.eq) goto loc_82A644D8;
	// li r5,56
	ctx.r5.s64 = 56;
	// addi r4,r31,13724
	ctx.r4.s64 = ctx.r31.s64 + 13724;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82d5c630
	ctx.lr = 0x82A644D4;
	sub_82D5C630(ctx, base);
	// addi r29,r29,56
	ctx.r29.s64 = ctx.r29.s64 + 56;
loc_82A644D8:
	// subf r11,r25,r29
	ctx.r11.s64 = ctx.r29.s64 - ctx.r25.s64;
	// rlwinm. r10,r27,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r11,r11,511
	ctx.r11.s64 = ctx.r11.s64 + 511;
	// rlwinm r11,r11,0,0,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFE00;
	// add r29,r11,r25
	ctx.r29.u64 = ctx.r11.u64 + ctx.r25.u64;
	// beq 0x82a64528
	if (ctx.cr0.eq) goto loc_82A64528;
	// lbz r11,600(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 600);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,592(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 592);
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// rlwinm. r11,r11,0,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a64510
	if (ctx.cr0.eq) goto loc_82A64510;
	// bl 0x82a5ede8
	ctx.lr = 0x82A6450C;
	sub_82A5EDE8(ctx, base);
	// b 0x82a64514
	goto loc_82A64514;
loc_82A64510:
	// bl 0x82a5ed50
	ctx.lr = 0x82A64514;
	sub_82A5ED50(ctx, base);
loc_82A64514:
	// li r5,1536
	ctx.r5.s64 = 1536;
	// lwz r4,592(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 592);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82d5c630
	ctx.lr = 0x82A64524;
	sub_82D5C630(ctx, base);
	// addi r29,r29,1536
	ctx.r29.s64 = ctx.r29.s64 + 1536;
loc_82A64528:
	// lwz r8,584(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 584);
	// rlwinm r7,r28,26,0,5
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 26) & 0xFC000000;
	// lhz r9,12(r30)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r30.u32 + 12);
	// mulli r11,r23,12
	ctx.r11.s64 = ctx.r23.s64 * 12;
	// lwz r6,596(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 596);
	// lbz r5,608(r30)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r30.u32 + 608);
	// lhz r10,14(r30)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r30.u32 + 14);
	// rlwinm r8,r8,2,29,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0x4;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// or r7,r7,r6
	ctx.r7.u64 = ctx.r7.u64 | ctx.r6.u64;
	// rlwinm r31,r11,9,0,22
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 9) & 0xFFFFFE00;
	// clrlwi r9,r7,2
	ctx.r9.u64 = ctx.r7.u32 & 0x3FFFFFFF;
	// lwzx r8,r8,r30
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r30.u32);
	// subf r11,r8,r29
	ctx.r11.s64 = ctx.r29.s64 - ctx.r8.s64;
	// rlwinm r11,r11,23,9,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 23) & 0x7FFFFF;
	// stw r9,596(r30)
	PPC_STORE_U32(ctx.r30.u32 + 596, ctx.r9.u32);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// sth r11,12(r30)
	PPC_STORE_U16(ctx.r30.u32 + 12, ctx.r11.u16);
	// rlwinm. r7,r5,0,0,24
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFFFF80;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq 0x82a645d8
	if (ctx.cr0.eq) goto loc_82A645D8;
	// lwz r11,380(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 380);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// stw r22,360(r30)
	PPC_STORE_U32(ctx.r30.u32 + 360, ctx.r22.u32);
	// stw r11,356(r30)
	PPC_STORE_U32(ctx.r30.u32 + 356, ctx.r11.u32);
	// bl 0x82a50928
	ctx.lr = 0x82A6458C;
	sub_82A50928(ctx, base);
	// lwz r11,596(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 596);
	// addi r7,r30,348
	ctx.r7.s64 = ctx.r30.s64 + 348;
	// lwz r10,584(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 584);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// rlwinm r11,r11,12,26,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 12) & 0x3F;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r11,r11,5
	ctx.r11.s64 = ctx.r11.s64 + 5;
	// rlwinm r10,r10,2,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0x4;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// lwzx r4,r10,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r30.u32);
	// lwzx r3,r11,r30
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// bl 0x82a3a500
	ctx.lr = 0x82A645C0;
	sub_82A3A500(ctx, base);
	// lbz r11,608(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 608);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// ori r11,r11,64
	ctx.r11.u64 = ctx.r11.u64 | 64;
	// stb r11,608(r30)
	PPC_STORE_U8(ctx.r30.u32 + 608, ctx.r11.u8);
	// bl 0x82a63828
	ctx.lr = 0x82A645D8;
	sub_82A63828(ctx, base);
loc_82A645D8:
	// lbz r10,608(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 608);
	// lwz r11,584(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 584);
	// ori r10,r10,128
	ctx.r10.u64 = ctx.r10.u64 | 128;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stb r10,608(r30)
	PPC_STORE_U8(ctx.r30.u32 + 608, ctx.r10.u8);
	// stw r11,584(r30)
	PPC_STORE_U32(ctx.r30.u32 + 584, ctx.r11.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82d5c4fc
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A645F8"))) PPC_WEAK_FUNC(sub_82A645F8);
PPC_FUNC_IMPL(__imp__sub_82A645F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x82a638e0
	ctx.lr = 0x82A64608;
	sub_82A638E0(ctx, base);
	// lis r10,-31980
	ctx.r10.s64 = -2095841280;
	// li r11,0
	ctx.r11.s64 = 0;
	// stb r11,27343(r10)
	PPC_STORE_U8(ctx.r10.u32 + 27343, ctx.r11.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A64628"))) PPC_WEAK_FUNC(sub_82A64628);
PPC_FUNC_IMPL(__imp__sub_82A64628) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b8
	ctx.lr = 0x82A64630;
	__savegprlr_24(ctx, base);
	// stwu r1,-816(r1)
	ea = -816 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r29,r24,21680
	ctx.r29.s64 = ctx.r24.s64 + 21680;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// lbz r11,608(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 608);
	// rlwinm. r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a64660
	if (ctx.cr0.eq) goto loc_82A64660;
loc_82A64650:
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82a638e0
	ctx.lr = 0x82A64658;
	sub_82A638E0(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82a649b4
	goto loc_82A649B4;
loc_82A64660:
	// li r5,260
	ctx.r5.s64 = 260;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82d5e188
	ctx.lr = 0x82A6466C;
	sub_82D5E188(ctx, base);
	// li r25,0
	ctx.r25.s64 = 0;
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// stb r25,371(r1)
	PPC_STORE_U8(ctx.r1.u32 + 371, ctx.r25.u8);
loc_82A6467C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82a6467c
	if (!ctx.cr6.eq) goto loc_82A6467C;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r31,r11,-1
	ctx.r31.s64 = ctx.r11.s64 + -1;
	// cmplw cr6,r31,r9
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82a646cc
	if (ctx.cr6.lt) goto loc_82A646CC;
loc_82A646B0:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,92
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 92, ctx.xer);
	// beq cr6,0x82a646cc
	if (ctx.cr6.eq) goto loc_82A646CC;
	// addi r31,r31,-1
	ctx.r31.s64 = ctx.r31.s64 + -1;
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82a646b0
	if (!ctx.cr6.lt) goto loc_82A646B0;
loc_82A646CC:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,92
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 92, ctx.xer);
	// beq cr6,0x82a646e8
	if (ctx.cr6.eq) goto loc_82A646E8;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r3,r11,24792
	ctx.r3.s64 = ctx.r11.s64 + 24792;
	// bl 0x82a5bb90
	ctx.lr = 0x82A646E4;
	sub_82A5BB90(ctx, base);
	// b 0x82a64650
	goto loc_82A64650;
loc_82A646E8:
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// stb r25,0(r31)
	PPC_STORE_U8(ctx.r31.u32 + 0, ctx.r25.u8);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x8308ad54
	ctx.lr = 0x82A646F8;
	__imp__RtlInitAnsiString(ctx, base);
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// addi r3,r11,-26232
	ctx.r3.s64 = ctx.r11.s64 + -26232;
	// bl 0x8308b364
	ctx.lr = 0x82A64708;
	__imp__ObCreateSymbolicLink(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a64724
	if (!ctx.cr0.lt) goto loc_82A64724;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r3,r11,24756
	ctx.r3.s64 = ctx.r11.s64 + 24756;
loc_82A64718:
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x82a5bb90
	ctx.lr = 0x82A64720;
	sub_82A5BB90(ctx, base);
	// b 0x82a64650
	goto loc_82A64650;
loc_82A64724:
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r6,r31,1
	ctx.r6.s64 = ctx.r31.s64 + 1;
	// addi r5,r11,24748
	ctx.r5.s64 = ctx.r11.s64 + 24748;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r3,r1,480
	ctx.r3.s64 = ctx.r1.s64 + 480;
	// addi r4,r11,24740
	ctx.r4.s64 = ctx.r11.s64 + 24740;
	// bl 0x8308b1d4
	ctx.lr = 0x82A64740;
	__imp__sprintf(ctx, base);
	// addi r5,r1,480
	ctx.r5.s64 = ctx.r1.s64 + 480;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82a62b78
	ctx.lr = 0x82A64750;
	sub_82A62B78(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a64650
	if (ctx.cr0.lt) goto loc_82A64650;
	// li r5,260
	ctx.r5.s64 = 260;
	// addi r4,r1,480
	ctx.r4.s64 = ctx.r1.s64 + 480;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82d5e188
	ctx.lr = 0x82A64768;
	sub_82D5E188(ctx, base);
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// stb r25,371(r1)
	PPC_STORE_U8(ctx.r1.u32 + 371, ctx.r25.u8);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A64774:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82a64774
	if (!ctx.cr6.eq) goto loc_82A64774;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// mr r30,r11
	ctx.r30.u64 = ctx.r11.u64;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82a647d4
	if (ctx.cr6.lt) goto loc_82A647D4;
loc_82A647AC:
	// lbz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,46
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 46, ctx.xer);
	// beq cr6,0x82a647d4
	if (ctx.cr6.eq) goto loc_82A647D4;
	// cmpwi cr6,r10,92
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 92, ctx.xer);
	// beq cr6,0x82a647d4
	if (ctx.cr6.eq) goto loc_82A647D4;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// cmplw cr6,r30,r10
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82a647ac
	if (!ctx.cr6.lt) goto loc_82A647AC;
loc_82A647D4:
	// lbz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// cmplwi cr6,r10,46
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 46, ctx.xer);
	// beq cr6,0x82a647e4
	if (ctx.cr6.eq) goto loc_82A647E4;
	// mr r30,r11
	ctx.r30.u64 = ctx.r11.u64;
loc_82A647E4:
	// lwz r11,596(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 596);
	// mr r31,r25
	ctx.r31.u64 = ctx.r25.u64;
	// rlwinm. r11,r11,0,12,17
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFC000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r27,r11,-10640
	ctx.r27.s64 = ctx.r11.s64 + -10640;
	// beq 0x82a648cc
	if (ctx.cr0.eq) goto loc_82A648CC;
	// addi r28,r29,20
	ctx.r28.s64 = ctx.r29.s64 + 20;
	// lis r26,-31980
	ctx.r26.s64 = -2095841280;
loc_82A64804:
	// lbz r11,27340(r26)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r26.u32 + 27340);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82a64650
	if (!ctx.cr0.eq) goto loc_82A64650;
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// addi r10,r1,480
	ctx.r10.s64 = ctx.r1.s64 + 480;
	// subf r11,r11,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r11.s64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// add r6,r11,r10
	ctx.r6.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8308b1d4
	ctx.lr = 0x82A64830;
	__imp__sprintf(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// lis r8,26624
	ctx.r8.s64 = 1744830464;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lis r4,16384
	ctx.r4.s64 = 1073741824;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82a3a308
	ctx.lr = 0x82A64850;
	sub_82A3A308(ctx, base);
	// cmpwi cr6,r3,-1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, -1, ctx.xer);
	// stw r3,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82a649bc
	if (ctx.cr6.eq) goto loc_82A649BC;
	// lwz r11,596(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 596);
	// rlwinm r11,r11,18,26,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 18) & 0x3F;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82a64890
	if (!ctx.cr6.eq) goto loc_82A64890;
	// lwz r11,384(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 384);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a64884
	if (ctx.cr0.eq) goto loc_82A64884;
	// clrldi r11,r11,32
	ctx.r11.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// b 0x82a64898
	goto loc_82A64898;
loc_82A64884:
	// li r11,1
	ctx.r11.s64 = 1;
	// rldicr r11,r11,32,63
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// b 0x82a64898
	goto loc_82A64898;
loc_82A64890:
	// li r11,0
	ctx.r11.s64 = 0;
	// oris r11,r11,65520
	ctx.r11.u64 = ctx.r11.u64 | 4293918720;
loc_82A64898:
	// li r6,0
	ctx.r6.s64 = 0;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x82a3b1e0
	ctx.lr = 0x82A648AC;
	sub_82A3B1E0(ctx, base);
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// bl 0x82e99950
	ctx.lr = 0x82A648B4;
	sub_82E99950(ctx, base);
	// lwz r11,596(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 596);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// rlwinm r11,r11,18,26,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 18) & 0x3F;
	// addi r28,r28,4
	ctx.r28.s64 = ctx.r28.s64 + 4;
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a64804
	if (ctx.cr6.lt) goto loc_82A64804;
loc_82A648CC:
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// addi r10,r1,480
	ctx.r10.s64 = ctx.r1.s64 + 480;
	// subf r11,r11,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r11.s64;
	// add r28,r11,r10
	ctx.r28.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82A648DC:
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8308b1d4
	ctx.lr = 0x82A648F0;
	__imp__sprintf(ctx, base);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// bl 0x82a3b888
	ctx.lr = 0x82A648FC;
	sub_82A3B888(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a648dc
	if (!ctx.cr0.eq) goto loc_82A648DC;
	// addi r31,r29,348
	ctx.r31.s64 = ctx.r29.s64 + 348;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r25,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r25.u32);
	// stw r25,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r25.u32);
	// stw r25,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r25.u32);
	// stw r25,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r25.u32);
	// stw r25,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r25.u32);
	// bl 0x82a3a8b8
	ctx.lr = 0x82A6492C;
	sub_82A3A8B8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,364(r29)
	PPC_STORE_U32(ctx.r29.u32 + 364, ctx.r3.u32);
	// beq 0x82a64650
	if (ctx.cr0.eq) goto loc_82A64650;
	// li r5,2048
	ctx.r5.s64 = 2048;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r25,356(r29)
	PPC_STORE_U32(ctx.r29.u32 + 356, ctx.r25.u32);
	// stw r25,360(r29)
	PPC_STORE_U32(ctx.r29.u32 + 360, ctx.r25.u32);
	// bl 0x82d5cb60
	ctx.lr = 0x82A64950;
	sub_82D5CB60(ctx, base);
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// lwz r4,0(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r5,2048
	ctx.r5.s64 = 2048;
	// lwz r3,20(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// bl 0x82a3a500
	ctx.lr = 0x82A64968;
	sub_82A3A500(ctx, base);
	// li r4,-1
	ctx.r4.s64 = -1;
	// lwz r3,364(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 364);
	// bl 0x82a3a980
	ctx.lr = 0x82A64974;
	sub_82A3A980(ctx, base);
	// addi r3,r1,384
	ctx.r3.s64 = ctx.r1.s64 + 384;
	// bl 0x8308b234
	ctx.lr = 0x82A6497C;
	__imp__VdGetCurrentDisplayInformation(ctx, base);
	// lbz r11,389(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 389);
	// lbz r10,600(r29)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r29.u32 + 600);
	// li r9,2048
	ctx.r9.s64 = 2048;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// lwz r8,596(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 596);
	// stw r25,584(r29)
	PPC_STORE_U32(ctx.r29.u32 + 584, ctx.r25.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r8,r8,0,12,5
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFC0FFFFF;
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// stw r9,380(r29)
	PPC_STORE_U32(ctx.r29.u32 + 380, ctx.r9.u32);
	// rlwimi r10,r11,7,24,24
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r11.u32, 7) & 0x80) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFF7F);
	// stw r8,596(r29)
	PPC_STORE_U32(ctx.r29.u32 + 596, ctx.r8.u32);
	// stb r10,600(r29)
	PPC_STORE_U8(ctx.r29.u32 + 600, ctx.r10.u8);
loc_82A649B4:
	// addi r1,r1,816
	ctx.r1.s64 = ctx.r1.s64 + 816;
	// b 0x82d5c508
	__restgprlr_24(ctx, base);
	return;
loc_82A649BC:
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r3,r11,24684
	ctx.r3.s64 = ctx.r11.s64 + 24684;
	// b 0x82a64718
	goto loc_82A64718;
}

__attribute__((alias("__imp__sub_82A649C8"))) PPC_WEAK_FUNC(sub_82A649C8);
PPC_FUNC_IMPL(__imp__sub_82A649C8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31980
	ctx.r11.s64 = -2095841280;
	// addi r5,r11,27080
	ctx.r5.s64 = ctx.r11.s64 + 27080;
	// lbz r11,262(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 262);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a64aa8
	if (ctx.cr0.eq) goto loc_82A64AA8;
	// lbz r11,22288(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 22288);
	// rlwinm. r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a64a84
	if (!ctx.cr0.eq) goto loc_82A64A84;
	// bl 0x82a64628
	ctx.lr = 0x82A649F8;
	sub_82A64628(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a64a08
	if (ctx.cr0.eq) goto loc_82A64A08;
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82a64a10
	goto loc_82A64A10;
loc_82A64A08:
	// lis r6,-32768
	ctx.r6.s64 = -2147483648;
	// ori r6,r6,16389
	ctx.r6.u64 = ctx.r6.u64 | 16389;
loc_82A64A10:
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r5,r11,24856
	ctx.r5.s64 = ctx.r11.s64 + 24856;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r4,r11,24844
	ctx.r4.s64 = ctx.r11.s64 + 24844;
	// bl 0x8308b1d4
	ctx.lr = 0x82A64A28;
	__imp__sprintf(ctx, base);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2020(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2020);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a64a58
	if (ctx.cr6.eq) goto loc_82A64A58;
	// rotlwi r11,r10,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a64aa8
	if (ctx.cr0.eq) goto loc_82A64AA8;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a64aa8
	if (ctx.cr0.eq) goto loc_82A64AA8;
	// b 0x82a64a70
	goto loc_82A64A70;
loc_82A64A58:
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2332(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a64aa8
	if (ctx.cr0.eq) goto loc_82A64AA8;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
loc_82A64A70:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,27
	ctx.r3.s64 = 27;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A64A80;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82a64aa8
	goto loc_82A64AA8;
loc_82A64A84:
	// lbz r11,260(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 260);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a64a98
	if (ctx.cr0.eq) goto loc_82A64A98;
	// bl 0x82a638e0
	ctx.lr = 0x82A64A94;
	sub_82A638E0(ctx, base);
	// b 0x82a64aa8
	goto loc_82A64AA8;
loc_82A64A98:
	// lbz r11,261(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 261);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a64aa8
	if (ctx.cr0.eq) goto loc_82A64AA8;
	// bl 0x82a63d00
	ctx.lr = 0x82A64AA8;
	sub_82A63D00(ctx, base);
loc_82A64AA8:
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A64AB8"))) PPC_WEAK_FUNC(sub_82A64AB8);
PPC_FUNC_IMPL(__imp__sub_82A64AB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// rlwinm r4,r3,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
loc_82A64AD0:
	// lfs f0,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// cmplwi cr6,r3,1
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 1, ctx.xer);
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// ble cr6,0x82a64b18
	if (!ctx.cr6.gt) goto loc_82A64B18;
	// addi r8,r5,4
	ctx.r8.s64 = ctx.r5.s64 + 4;
	// addi r7,r10,4
	ctx.r7.s64 = ctx.r10.s64 + 4;
	// addi r9,r3,-1
	ctx.r9.s64 = ctx.r3.s64 + -1;
loc_82A64AF4:
	// lfs f0,0(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// lfs f13,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// fmadds f0,f0,f13,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// bne 0x82a64af4
	if (!ctx.cr0.eq) goto loc_82A64AF4;
loc_82A64B18:
	// addic. r6,r6,-1
	ctx.xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r6.s32, 0, ctx.xer);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// add r10,r4,r10
	ctx.r10.u64 = ctx.r4.u64 + ctx.r10.u64;
	// bne 0x82a64ad0
	if (!ctx.cr0.eq) goto loc_82A64AD0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A64B30"))) PPC_WEAK_FUNC(sub_82A64B30);
PPC_FUNC_IMPL(__imp__sub_82A64B30) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82A64B38;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c540
	ctx.lr = 0x82A64B40;
	__savefpr_14(ctx, base);
	// ld r12,-4096(r1)
	ctx.r12.u64 = PPC_LOAD_U64(ctx.r1.u32 + -4096);
	// stwu r1,-5104(r1)
	ea = -5104 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// addi r6,r31,4
	ctx.r6.s64 = ctx.r31.s64 + 4;
	// lfs f20,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// addi r5,r29,4
	ctx.r5.s64 = ctx.r29.s64 + 4;
	// lfs f23,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f23.f64 = double(temp.f32);
	// addi r4,r1,4288
	ctx.r4.s64 = ctx.r1.s64 + 4288;
	// lfs f25,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f25.f64 = double(temp.f32);
	// li r3,3
	ctx.r3.s64 = 3;
	// lfs f17,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// stw r31,5124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 5124, ctx.r31.u32);
	// lfs f19,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// stw r29,5148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 5148, ctx.r29.u32);
	// lfs f18,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// lfs f28,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f30.f64 = double(temp.f32);
	// lfs f31,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f31.f64 = double(temp.f32);
	// lfs f0,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fneg f0,f25
	ctx.f0.u64 = ctx.f25.u64 ^ 0x8000000000000000;
	// stfs f0,4308(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4308, temp.u32);
	// fneg f0,f18
	ctx.f0.u64 = ctx.f18.u64 ^ 0x8000000000000000;
	// stfs f0,4300(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4300, temp.u32);
	// fneg f0,f28
	ctx.f0.u64 = ctx.f28.u64 ^ 0x8000000000000000;
	// stfs f0,4316(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4316, temp.u32);
	// fneg f0,f30
	ctx.f0.u64 = ctx.f30.u64 ^ 0x8000000000000000;
	// stfs f20,964(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 964, temp.u32);
	// stfs f23,448(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// stfs f25,564(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 564, temp.u32);
	// stfs f17,1068(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1068, temp.u32);
	// stfs f19,956(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 956, temp.u32);
	// stfs f18,404(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// stfs f20,4320(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4320, temp.u32);
	// stfs f23,4296(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4296, temp.u32);
	// stfs f17,4312(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4312, temp.u32);
	// stfs f19,4288(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4288, temp.u32);
	// stfs f0,4292(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4292, temp.u32);
	// stfs f31,4304(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4304, temp.u32);
	// bl 0x82a64ab8
	ctx.lr = 0x82A64BEC;
	sub_82A64AB8(ctx, base);
	// cmplwi cr6,r28,2
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 2, ctx.xer);
	// bgt cr6,0x82a64bf8
	if (ctx.cr6.gt) goto loc_82A64BF8;
	// b 0x82a76e10
	goto loc_82A76E10;
loc_82A64BF8:
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// fmuls f4,f30,f20
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f20.f64));
	// stfs f4,2336(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2336, temp.u32);
	// fmuls f12,f30,f17
	ctx.f12.f64 = double(float(ctx.f30.f64 * ctx.f17.f64));
	// fmuls f2,f17,f23
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f23.f64));
	// stfs f2,104(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmuls f1,f19,f20
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f20.f64));
	// stfs f1,88(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmuls f3,f19,f25
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f25.f64));
	// stfs f3,168(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfd f0,-1192(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -1192);
	// lis r11,-32248
	ctx.r11.s64 = -2113404928;
	// fsqrts f0,f0
	ctx.f0.f64 = double(float(sqrt(ctx.f0.f64)));
	// stfs f0,212(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fneg f4,f4
	ctx.f4.u64 = ctx.f4.u64 ^ 0x8000000000000000;
	// fneg f16,f12
	ctx.f16.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// fadds f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// lfd f13,7072(r11)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r11.u32 + 7072);
	// fsqrts f13,f13
	ctx.f13.f64 = double(float(sqrt(ctx.f13.f64)));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f13,f18,f25
	ctx.f13.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// fmuls f9,f17,f20
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f20.f64));
	// fmuls f10,f19,f23
	ctx.f10.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// fmuls f7,f28,f17
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// lfs f11,-29724(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29724);
	ctx.f11.f64 = double(temp.f32);
	// lis r11,-32245
	ctx.r11.s64 = -2113208320;
	// fmuls f6,f30,f19
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f19.f64));
	// fmuls f5,f28,f20
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f20.f64));
	// fmuls f29,f20,f20
	ctx.f29.f64 = double(float(ctx.f20.f64 * ctx.f20.f64));
	// fmuls f22,f23,f23
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f23.f64));
	// fmuls f14,f17,f17
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f17.f64));
	// fmuls f15,f0,f30
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmuls f8,f19,f19
	ctx.f8.f64 = double(float(ctx.f19.f64 * ctx.f19.f64));
	// fmuls f26,f28,f28
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// fmuls f27,f30,f30
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// stfs f4,80(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f2,4288(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4288, temp.u32);
	// fmuls f4,f28,f19
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fmuls f24,f31,f31
	ctx.f24.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f12,f0,f31
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fneg f3,f3
	ctx.f3.u64 = ctx.f3.u64 ^ 0x8000000000000000;
	// stfs f13,288(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fmuls f13,f30,f23
	ctx.f13.f64 = double(float(ctx.f30.f64 * ctx.f23.f64));
	// stfs f9,112(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f10,92(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// stfs f7,200(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// stfs f6,556(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 556, temp.u32);
	// stfs f5,244(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// stfs f29,452(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// stfs f22,424(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// stfs f14,400(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// stfs f8,268(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// stfs f13,348(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fmuls f13,f23,f20
	ctx.f13.f64 = double(float(ctx.f23.f64 * ctx.f20.f64));
	// stfs f13,160(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fmuls f13,f19,f17
	ctx.f13.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmuls f13,f18,f23
	ctx.f13.f64 = double(float(ctx.f18.f64 * ctx.f23.f64));
	// stfs f13,196(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fmuls f13,f31,f19
	ctx.f13.f64 = double(float(ctx.f31.f64 * ctx.f19.f64));
	// stfs f13,1528(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1528, temp.u32);
	// fmuls f13,f18,f19
	ctx.f13.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// fsubs f4,f16,f4
	ctx.f4.f64 = double(float(ctx.f16.f64 - ctx.f4.f64));
	// stfs f13,116(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f4,4292(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4292, temp.u32);
	// fmuls f4,f28,f23
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmuls f13,f25,f23
	ctx.f13.f64 = double(float(ctx.f25.f64 * ctx.f23.f64));
	// lfs f16,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f16.f64 = double(temp.f32);
	// stfs f13,124(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fmuls f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// lfs f13,19764(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 19764);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f21,-29000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29000);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,304(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fsubs f4,f16,f4
	ctx.f4.f64 = double(float(ctx.f16.f64 - ctx.f4.f64));
	// stfs f4,4300(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4300, temp.u32);
	// lfs f4,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f4.f64 = double(temp.f32);
	// lfs f2,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// stfs f4,4304(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4304, temp.u32);
	// lfs f4,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f4.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fsubs f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// stfs f4,4308(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4308, temp.u32);
	// fmuls f4,f30,f18
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f18.f64));
	// lfs f3,1528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1528);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f1,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f12,f30
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f16,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// addi r6,r31,16
	ctx.r6.s64 = ctx.r31.s64 + 16;
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// addi r5,r29,16
	ctx.r5.s64 = ctx.r29.s64 + 16;
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// addi r4,r1,4288
	ctx.r4.s64 = ctx.r1.s64 + 4288;
	// li r3,5
	ctx.r3.s64 = 5;
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// stfs f4,4312(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4312, temp.u32);
	// lfs f4,-18936(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18936);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f31,f23
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// stfs f4,356(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// fmuls f4,f15,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// stfs f4,4296(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4296, temp.u32);
	// fmuls f4,f30,f25
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lis r11,-32244
	ctx.r11.s64 = -2113142784;
	// fmuls f15,f26,f0
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// stfs f4,4320(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4320, temp.u32);
	// lfs f3,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// stfs f4,4324(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4324, temp.u32);
	// fmuls f4,f12,f18
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f18.f64));
	// fmuls f3,f9,f13
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f4,f4,f11
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmsubs f3,f1,f11,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 - ctx.f3.f64));
	// fmuls f1,f10,f13
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,-20200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -20200);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// stfs f10,4316(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4316, temp.u32);
	// fmuls f2,f27,f0
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmsubs f10,f7,f13,f4
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 - ctx.f4.f64));
	// fmuls f4,f22,f0
	ctx.f4.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmsubs f7,f3,f0,f1
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f1.f64));
	// stfs f7,4328(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4328, temp.u32);
	// fadds f3,f8,f14
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f14.f64));
	// fadds f8,f8,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f29.f64));
	// fnmsubs f1,f26,f21,f24
	ctx.f1.f64 = double(float(-(ctx.f26.f64 * ctx.f21.f64 - ctx.f24.f64)));
	// fmadds f10,f6,f13,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f10.f64));
	// stfs f10,4332(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4332, temp.u32);
	// fmuls f6,f17,f25
	ctx.f6.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// stfs f6,156(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmuls f6,f18,f17
	ctx.f6.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// stfs f6,144(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f6,f25,f20
	ctx.f6.f64 = double(float(ctx.f25.f64 * ctx.f20.f64));
	// stfs f6,192(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// fmuls f6,f12,f25
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// fmuls f10,f18,f18
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f18.f64));
	// stfs f10,120(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fmuls f10,f25,f25
	ctx.f10.f64 = double(float(ctx.f25.f64 * ctx.f25.f64));
	// stfs f10,96(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fmuls f10,f18,f20
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// stfs f10,132(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f10,-29728(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29728);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// fmuls f7,f29,f10
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f11,f6,f11
	ctx.f11.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// fmuls f6,f22,f21
	ctx.f6.f64 = double(float(ctx.f22.f64 * ctx.f21.f64));
	// fmsubs f11,f5,f13,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 - ctx.f11.f64));
	// fmuls f5,f12,f28
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// lfs f12,-28016(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28016);
	ctx.f12.f64 = double(temp.f32);
	// fmsubs f8,f8,f21,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f21.f64 - ctx.f6.f64));
	// stfs f12,620(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 620, temp.u32);
	// fnmsubs f6,f27,f21,f1
	ctx.f6.f64 = double(float(-(ctx.f27.f64 * ctx.f21.f64 - ctx.f1.f64)));
	// stfs f6,4336(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4336, temp.u32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fmadds f11,f16,f13,f11
	ctx.f11.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 + ctx.f11.f64));
	// stfs f11,4340(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4340, temp.u32);
	// fmsubs f12,f15,f12,f2
	ctx.f12.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f2.f64));
	// lfs f11,-20200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -20200);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// stfs f11,4356(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4356, temp.u32);
	// lfs f11,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// stfs f11,4368(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4368, temp.u32);
	// lfs f9,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f9.f64 = double(temp.f32);
	// lfs f11,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// stfs f11,4372(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4372, temp.u32);
	// lfs f9,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f9.f64 = double(temp.f32);
	// lfs f11,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f11.f64 = double(temp.f32);
	// stfs f12,4376(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4376, temp.u32);
	// fsubs f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// lfs f12,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// stfs f11,4380(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4380, temp.u32);
	// fmuls f11,f12,f0
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f12,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f12.f64 = double(temp.f32);
	// fneg f9,f12
	ctx.f9.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// fnmsubs f12,f14,f21,f8
	ctx.f12.f64 = double(float(-(ctx.f14.f64 * ctx.f21.f64 - ctx.f8.f64)));
	// stfs f12,4384(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4384, temp.u32);
	// fmuls f12,f28,f18
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfs f8,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f12,f31,f17,f12
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f17.f64 + ctx.f12.f64));
	// stfs f12,4352(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4352, temp.u32);
	// fmuls f12,f28,f25
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmadds f12,f31,f20,f12
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f20.f64 + ctx.f12.f64));
	// stfs f12,4360(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4360, temp.u32);
	// lfs f12,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// stfs f12,4364(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4364, temp.u32);
	// lfs f12,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f12,f12,f13,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + ctx.f7.f64));
	// lfs f8,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// stfs f9,4348(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4348, temp.u32);
	// fmuls f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fmsubs f0,f11,f13,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 - ctx.f0.f64));
	// fnmsubs f0,f4,f10,f0
	ctx.f0.f64 = double(float(-(ctx.f4.f64 * ctx.f10.f64 - ctx.f0.f64)));
	// fmadds f0,f3,f10,f0
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 + ctx.f0.f64));
	// stfs f0,4344(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4344, temp.u32);
	// bl 0x82a64ab8
	ctx.lr = 0x82A64F30;
	sub_82A64AB8(ctx, base);
	// cmplwi cr6,r28,3
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 3, ctx.xer);
	// bgt cr6,0x82a64f3c
	if (ctx.cr6.gt) goto loc_82A64F3C;
	// b 0x82a76e10
	goto loc_82A76E10;
loc_82A64F3C:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f8,268(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f8.f64 = double(temp.f32);
	// lfd f0,-18976(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -18976);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fsqrts f16,f0
	ctx.f16.f64 = double(float(sqrt(ctx.f0.f64)));
	// stfs f16,280(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfd f0,-30120(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -30120);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fsqrts f15,f0
	ctx.f15.f64 = double(float(sqrt(ctx.f0.f64)));
	// fmuls f11,f15,f16
	ctx.f11.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// lfd f0,-30128(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -30128);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fsqrts f13,f0
	ctx.f13.f64 = double(float(sqrt(ctx.f0.f64)));
	// stfs f15,580(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 580, temp.u32);
	// fmuls f5,f13,f14
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f14.f64));
	// fmuls f4,f13,f22
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f22.f64));
	// fmuls f3,f13,f29
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// fmuls f2,f13,f8
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// fmuls f6,f13,f16
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f16.f64));
	// lfd f0,-30256(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -30256);
	// fsqrts f10,f0
	ctx.f10.f64 = double(float(sqrt(ctx.f0.f64)));
	// fmuls f1,f10,f27
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f7,f10,f30
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// stfs f5,136(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// stfs f4,228(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// stfs f3,596(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// stfs f2,80(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f6,240(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfd f0,-30136(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -30136);
	// fsqrts f9,f0
	ctx.f9.f64 = double(float(sqrt(ctx.f0.f64)));
	// fmuls f0,f14,f19
	ctx.f0.f64 = double(float(ctx.f14.f64 * ctx.f19.f64));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f7,1584(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1584, temp.u32);
	// fmuls f7,f7,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// stfs f0,1172(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1172, temp.u32);
	// stfs f1,1048(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1048, temp.u32);
	// fmuls f1,f22,f23
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// lfs f0,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f12,f0,f23
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// stfs f1,1212(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1212, temp.u32);
	// lfs f1,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// stfs f12,720(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 720, temp.u32);
	// fmuls f12,f29,f19
	ctx.f12.f64 = double(float(ctx.f29.f64 * ctx.f19.f64));
	// stfs f12,1204(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1204, temp.u32);
	// fmuls f12,f22,f19
	ctx.f12.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// stfs f1,1592(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1592, temp.u32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// stfs f12,1608(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1608, temp.u32);
	// fmuls f12,f0,f30
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// stfs f7,520(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// fmuls f0,f0,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lfs f7,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f7.f64 = double(temp.f32);
	// stfs f0,1180(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1180, temp.u32);
	// fmuls f0,f29,f23
	ctx.f0.f64 = double(float(ctx.f29.f64 * ctx.f23.f64));
	// stfs f1,828(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 828, temp.u32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// lfs f1,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f1.f64 = double(temp.f32);
	// stfs f0,1616(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1616, temp.u32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// stfs f7,1624(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1624, temp.u32);
	// fmuls f0,f10,f13
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// stfs f0,252(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fmuls f7,f26,f23
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// stfs f1,1196(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1196, temp.u32);
	// fmuls f0,f9,f16
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f16.f64));
	// lfs f1,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f1.f64 = double(temp.f32);
	// stfs f7,256(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmuls f7,f5,f30
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f12,1600(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1600, temp.u32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f0,216(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fmuls f12,f9,f15
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f15.f64));
	// stfs f7,748(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 748, temp.u32);
	// fmuls f0,f13,f11
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// stfs f12,172(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fmuls f7,f4,f30
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// stfs f0,428(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// stfs f1,332(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// stfs f7,248(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fmuls f4,f10,f28
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// lfs f7,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f15,f22
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f22.f64));
	// fmuls f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// stfs f7,1188(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1188, temp.u32);
	// fmuls f7,f3,f30
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// stfs f7,708(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 708, temp.u32);
	// fmuls f7,f2,f30
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f7,716(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 716, temp.u32);
	// fmuls f7,f6,f9
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// stfs f7,220(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f7,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f15,f14
	ctx.f3.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// fmuls f7,f7,f13
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// stfs f7,944(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 944, temp.u32);
	// lfs f7,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f2,f15,f29
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f29.f64));
	// fmuls f13,f7,f13
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// stfs f13,1576(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1576, temp.u32);
	// fmuls f13,f10,f16
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f16.f64));
	// stfs f13,316(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// stfs f4,868(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 868, temp.u32);
	// fmuls f4,f15,f8
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f8.f64));
	// fmuls f13,f15,f18
	ctx.f13.f64 = double(float(ctx.f15.f64 * ctx.f18.f64));
	// fmuls f7,f9,f18
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f18.f64));
	// stfs f7,1568(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1568, temp.u32);
	// fmuls f6,f9,f25
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// stfs f6,1560(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1560, temp.u32);
	// fmuls f5,f15,f25
	ctx.f5.f64 = double(float(ctx.f15.f64 * ctx.f25.f64));
	// fmuls f10,f10,f26
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// fmuls f4,f4,f18
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f18.f64));
	// stfs f4,968(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 968, temp.u32);
	// fmuls f4,f3,f18
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// stfs f4,936(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 936, temp.u32);
	// lfs f4,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// stfs f4,1032(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1032, temp.u32);
	// fmuls f4,f2,f25
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f4,984(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 984, temp.u32);
	// fmuls f4,f1,f25
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// stfs f4,1008(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1008, temp.u32);
	// fmuls f4,f13,f22
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f22.f64));
	// stfs f4,1024(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1024, temp.u32);
	// fmuls f13,f13,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// stfs f13,992(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 992, temp.u32);
	// lfs f13,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// stfs f13,188(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f13,f7,f26
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// stfs f13,928(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 928, temp.u32);
	// fmuls f13,f7,f27
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// stfs f13,920(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 920, temp.u32);
	// fmuls f13,f6,f26
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// stfs f13,976(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 976, temp.u32);
	// fmuls f13,f6,f27
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// stfs f13,896(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 896, temp.u32);
	// fmuls f13,f5,f14
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// stfs f13,912(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 912, temp.u32);
	// fmuls f13,f5,f8
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// stfs f13,904(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 904, temp.u32);
	// lfs f13,868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 868);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f27
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f27.f64));
	// stfs f13,1036(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1036, temp.u32);
	// fmuls f13,f10,f28
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// stfs f13,1164(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1164, temp.u32);
	// lfs f13,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// stfs f13,880(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 880, temp.u32);
	// lfs f13,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// stfs f13,1000(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1000, temp.u32);
	// lfs f13,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// stfs f13,872(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 872, temp.u32);
	// lfs f13,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// stfs f13,888(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 888, temp.u32);
	// fmuls f13,f29,f20
	ctx.f13.f64 = double(float(ctx.f29.f64 * ctx.f20.f64));
	// stfs f13,1028(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1028, temp.u32);
	// fmuls f13,f14,f20
	ctx.f13.f64 = double(float(ctx.f14.f64 * ctx.f20.f64));
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// stfs f13,952(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 952, temp.u32);
	// fmuls f13,f8,f20
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f20.f64));
	// stfs f13,1016(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1016, temp.u32);
	// fmuls f13,f22,f20
	ctx.f13.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// stfs f13,960(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 960, temp.u32);
	// lfs f13,720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 720);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f10,828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 828);
	ctx.f10.f64 = double(temp.f32);
	// lis r30,-32239
	ctx.r30.s64 = -2112815104;
	// lfs f22,26980(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 26980);
	ctx.f22.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f8,1048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1048);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,1212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1212);
	ctx.f2.f64 = double(temp.f32);
	// lfs f29,-19000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -19000);
	ctx.f29.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f5,f13,f29
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// lfs f20,1188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1188);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f14,1180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1180);
	ctx.f14.f64 = double(temp.f32);
	// stfs f22,640(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 640, temp.u32);
	// lfs f13,-29732(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29732);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f9,f10,f13
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// stfs f9,228(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// stfs f13,128(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f10,-30144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30144);
	ctx.f10.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f8,f8,f10
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// stfs f8,672(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 672, temp.u32);
	// lfs f8,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f8.f64 = double(temp.f32);
	// fadds f4,f8,f7
	ctx.f4.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// stfs f10,184(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fmuls f8,f6,f28
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f4,f4,f11
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmuls f3,f8,f0
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// lfs f8,-29736(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29736);
	ctx.f8.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// stfs f8,100(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f7,-12748(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -12748);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// stfs f7,140(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f7,1204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1204);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f5,f7,f22,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f22.f64 + ctx.f5.f64));
	// lfs f7,1196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1196);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f3,f13
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f1,f7,f0
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f7,f27,f19
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// fmadds f2,f14,f29,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 * ctx.f29.f64 + ctx.f2.f64));
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmadds f4,f4,f8,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f3.f64));
	// lfs f8,1172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1172);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f5,f8,f22,f5
	ctx.f5.f64 = double(float(-(ctx.f8.f64 * ctx.f22.f64 - ctx.f5.f64)));
	// fmuls f7,f7,f12
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// fmuls f8,f26,f19
	ctx.f8.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// fmuls f3,f1,f13
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f1,1624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1624);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f4,f20,f13,f4
	ctx.f4.f64 = double(float(-(ctx.f20.f64 * ctx.f13.f64 - ctx.f4.f64)));
	// lfs f20,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f11,f20,f11
	ctx.f11.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// lfs f20,1616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1616);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// lfs f10,-30152(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -30152);
	ctx.f10.f64 = double(temp.f32);
	// fmsubs f2,f20,f22,f2
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f22.f64 - ctx.f2.f64));
	// fmuls f20,f14,f25
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// lfs f14,1608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1608);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmuls f8,f8,f12
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmuls f10,f27,f23
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// fnmsubs f5,f14,f22,f5
	ctx.f5.f64 = double(float(-(ctx.f14.f64 * ctx.f22.f64 - ctx.f5.f64)));
	// lfs f14,1600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1600);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f0,1592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1592);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f9,f0,f13,f9
	ctx.f9.f64 = double(float(-(ctx.f0.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// lfs f0,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f8,f8,f0,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f7.f64));
	// fmuls f10,f10,f12
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f0,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f6,f6,f18
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// fmuls f7,f0,f12
	ctx.f7.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfs f13,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,-30148(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -30148);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f0,f13,f0,f12
	ctx.f0.f64 = double(float(-(ctx.f13.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// lfs f12,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f12.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmr f0,f12
	ctx.f0.f64 = ctx.f12.f64;
	// lfs f13,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f1,f13,f0,f1
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f1.f64));
	// lfs f13,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f4,f11,f0,f4
	ctx.f4.f64 = double(float(-(ctx.f11.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// fmuls f0,f15,f16
	ctx.f0.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// fmsubs f11,f9,f13,f3
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 - ctx.f3.f64));
	// fmuls f9,f12,f0
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f12,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f0,f12,f23
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f23.f64));
	// fmadds f3,f0,f22,f2
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f22.f64 + ctx.f2.f64));
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f2,f20,f0
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f0,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f20,f0,f13
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f13,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f12,f19
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f19.f64));
	// lfs f12,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f0,f0,f13,f5
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f5.f64));
	// lfs f13,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,4288(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4288, temp.u32);
	// fnmsubs f0,f14,f13,f11
	ctx.f0.f64 = double(float(-(ctx.f14.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// stfs f0,4292(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4292, temp.u32);
	// lfs f0,-30152(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -30152);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f0,f7,f0,f8
	ctx.f0.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 + ctx.f8.f64));
	// stfs f0,4296(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4296, temp.u32);
	// fmuls f0,f15,f16
	ctx.f0.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// lfs f11,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f11.f64 = double(temp.f32);
	// lfs f8,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f7,f6,f13,f2
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 - ctx.f2.f64));
	// fmuls f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// lfs f5,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f28
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// fmuls f6,f20,f23
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// fmuls f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// stfs f0,4300(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4300, temp.u32);
	// lfs f0,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f0,f1,f0,f10
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 - ctx.f10.f64));
	// lfs f11,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f11.f64 = double(temp.f32);
	// stfs f0,4304(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4304, temp.u32);
	// fnmsubs f0,f9,f11,f4
	ctx.f0.f64 = double(float(-(ctx.f9.f64 * ctx.f11.f64 - ctx.f4.f64)));
	// stfs f0,4308(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4308, temp.u32);
	// lfs f0,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f23
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// lfs f10,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f0,f0,f22,f3
	ctx.f0.f64 = double(float(-(ctx.f0.f64 * ctx.f22.f64 - ctx.f3.f64)));
	// stfs f0,4312(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4312, temp.u32);
	// fmuls f0,f10,f12
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f9,f0,f31
	ctx.f9.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fmuls f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// stfs f9,136(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f9,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f4,f9,f30,f8
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f30.f64 + ctx.f8.f64));
	// lfs f9,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f3,f9,f18
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f18.f64));
	// lfs f9,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f5,f9,f30,f5
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f30.f64 + ctx.f5.f64));
	// lfs f8,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f9,f28,f19
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fmuls f2,f8,f12
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmuls f1,f9,f0
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f9,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f20,f9,f31
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f9,f28,f23
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmuls f14,f9,f0
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f9,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f9,f9,f30,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64 + ctx.f4.f64));
	// fmuls f4,f2,f25
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfs f2,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f2,f2,f28,f9
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64 + ctx.f9.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f9,f28,f18
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lis r6,-32239
	ctx.r6.s64 = -2112815104;
	// fmadds f8,f8,f31,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f31.f64 + ctx.f5.f64));
	// lfs f5,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f5,f5,f19,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f19.f64 + ctx.f3.f64));
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmuls f3,f1,f31
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmuls f20,f20,f30
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f30.f64));
	// fnmsubs f7,f6,f13,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// fmuls f14,f14,f31
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f31.f64));
	// fmadds f10,f10,f31,f2
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64 + ctx.f2.f64));
	// fmuls f1,f9,f0
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f9,f28,f25
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f12,f5,f12
	ctx.f12.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f5,f4,f13
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fmuls f2,f20,f28
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f28.f64));
	// fmuls f4,f1,f30
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lfs f1,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f0,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f8,f0,f28,f8
	ctx.f8.f64 = double(float(-(ctx.f0.f64 * ctx.f28.f64 - ctx.f8.f64)));
	// lfs f0,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f12,f12,f13,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 - ctx.f5.f64));
	// lfs f13,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f6,f0,f25
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmuls f20,f0,f18
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f18.f64));
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f5,f13,f17
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f17.f64));
	// fmuls f0,f0,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fnmsubs f8,f1,f30,f8
	ctx.f8.f64 = double(float(-(ctx.f1.f64 * ctx.f30.f64 - ctx.f8.f64)));
	// lfs f1,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f13,f1
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// lfs f13,-29740(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29740);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,208(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f13,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f13,f19
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// fmuls f11,f0,f11
	ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f13,f6,f0,f7
	ctx.f13.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// stfs f13,4316(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4316, temp.u32);
	// lfs f13,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f20,f0,f12
	ctx.f0.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f12.f64));
	// fmadds f13,f13,f31,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f10.f64));
	// stfs f13,4320(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4320, temp.u32);
	// lfs f13,-30156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30156);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,864(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 864, temp.u32);
	// fmuls f13,f2,f13
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// stfs f13,4328(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4328, temp.u32);
	// lfs f13,-29744(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -29744);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f5,f13
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f10,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f1,f13
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// stfs f0,4340(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4340, temp.u32);
	// lfs f0,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f10,f10,f31,f8
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f31.f64 - ctx.f8.f64)));
	// lfs f12,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f12.f64 = double(temp.f32);
	// stfs f10,4336(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4336, temp.u32);
	// fmuls f10,f0,f12
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// stfs f10,392(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f8,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// lfs f0,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f5,f8,f0,f11
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f11.f64));
	// lfs f11,-29748(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29748);
	ctx.f11.f64 = double(temp.f32);
	// fmsubs f8,f3,f11,f7
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 - ctx.f7.f64));
	// fmsubs f11,f14,f11,f6
	ctx.f11.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 - ctx.f6.f64));
	// fnmsubs f8,f4,f13,f8
	ctx.f8.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// stfs f8,4324(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4324, temp.u32);
	// fnmsubs f13,f9,f13,f11
	ctx.f13.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// stfs f13,4332(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4332, temp.u32);
	// lfs f13,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// stfs f11,876(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 876, temp.u32);
	// lfs f11,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f19
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// lfs f4,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f4.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f8,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f8,f25
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// lfs f20,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f3,f13,f8
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// lis r7,-32239
	ctx.r7.s64 = -2112815104;
	// fmuls f20,f13,f20
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f20.f64));
	// lfs f9,-29752(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29752);
	ctx.f9.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f9,568(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 568, temp.u32);
	// fmuls f7,f12,f11
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f11,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f19
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// fmuls f20,f20,f31
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f31.f64));
	// fmuls f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// fmuls f11,f27,f19
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// fmadds f9,f6,f9,f4
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 + ctx.f4.f64));
	// lfs f4,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f2,f11,f22
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f22.f64));
	// lfs f11,-29760(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29760);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f7,f7,f11
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// stfs f11,176(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fmuls f11,f31,f30
	ctx.f11.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lfs f6,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// fmuls f4,f10,f19
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f19.f64));
	// lfs f10,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// lfs f8,21356(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21356);
	ctx.f8.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f8,432(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// fmsubs f7,f5,f12,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 - ctx.f7.f64));
	// fmuls f1,f11,f25
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// fmsubs f5,f24,f19,f2
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f19.f64 - ctx.f2.f64));
	// fmuls f2,f11,f18
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f18.f64));
	// lfs f11,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f14,f11,f24
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f24.f64));
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmadds f9,f9,f12,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 + ctx.f7.f64));
	// fmsubs f8,f1,f8,f6
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f8.f64 - ctx.f6.f64));
	// lfs f6,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f13
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// lfs f13,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f11,f13
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f13,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f19
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// fnmsubs f9,f4,f0,f9
	ctx.f9.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f7,f12,f13
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f13,f28
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// fadds f11,f13,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
	// lfs f13,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f5,f2,f13,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f5.f64));
	// lfs f13,1584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1584);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f4,f14,f13
	ctx.f4.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// lfs f14,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f13,f27,f23
	ctx.f13.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// fnmsubs f8,f13,f22,f8
	ctx.f8.f64 = double(float(-(ctx.f13.f64 * ctx.f22.f64 - ctx.f8.f64)));
	// lfs f13,876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f2,f13,f30
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// lfs f13,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f9,f7,f13,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 + ctx.f9.f64));
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f23
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// fmuls f7,f12,f13
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,-29764(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29764);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f14,f11,f13,f14
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f14.f64));
	// lfs f13,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f11,f3,f31,f2
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f31.f64 + ctx.f2.f64));
	// lfs f3,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f5,f13,f21,f5
	ctx.f5.f64 = double(float(-(ctx.f13.f64 * ctx.f21.f64 - ctx.f5.f64)));
	// lfs f2,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f2.f64 = double(temp.f32);
	// lfs f13,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f3,f13,f2,f3
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 + ctx.f3.f64));
	// lfs f13,864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 864);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f8,f24,f23,f8
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f23.f64 + ctx.f8.f64));
	// fmuls f4,f4,f13
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// lfs f13,-29756(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -29756);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f6,f6,f13,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f1.f64));
	// lfs f1,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f2.f64 = double(temp.f32);
	// lis r8,-32239
	ctx.r8.s64 = -2112815104;
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmuls f1,f11,f13
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f11,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f11,f7,f11,f9
	ctx.f11.f64 = double(float(-(ctx.f7.f64 * ctx.f11.f64 - ctx.f9.f64)));
	// stfs f11,4344(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4344, temp.u32);
	// fmuls f11,f26,f19
	ctx.f11.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// lfs f9,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f9.f64 = double(temp.f32);
	// lis r5,-32239
	ctx.r5.s64 = -2112815104;
	// fnmsubs f11,f11,f9,f5
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f9.f64 - ctx.f5.f64)));
	// lfs f9,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f9.f64 = double(temp.f32);
	// stfs f11,4352(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4352, temp.u32);
	// fmsubs f11,f3,f9,f4
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 - ctx.f4.f64));
	// stfs f11,4356(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4356, temp.u32);
	// lfs f11,1576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1576);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// stfs f11,256(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f11,944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 944);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f7,f11,f9
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f11,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// fmuls f3,f7,f30
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// lfs f7,-29768(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -29768);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f11,f11,f21,f8
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f21.f64 - ctx.f8.f64)));
	// stfs f11,4360(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4360, temp.u32);
	// lfs f11,-29764(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29764);
	ctx.f11.f64 = double(temp.f32);
	// fmsubs f11,f10,f11,f1
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 - ctx.f1.f64));
	// lfs f10,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f4,f2,f8,f6
	ctx.f4.f64 = double(float(-(ctx.f2.f64 * ctx.f8.f64 - ctx.f6.f64)));
	// lfs f6,1024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1024);
	ctx.f6.f64 = double(temp.f32);
	// stfs f7,136(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fnmsubs f11,f20,f13,f11
	ctx.f11.f64 = double(float(-(ctx.f20.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// lfs f20,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f7,f3,f7,f4
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f7.f64 + ctx.f4.f64));
	// fmadds f11,f14,f10,f11
	ctx.f11.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 + ctx.f11.f64));
	// stfs f11,4348(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4348, temp.u32);
	// lfs f11,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f11,f18
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f18.f64));
	// lfs f11,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f6,f11
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f6,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f14,f9,f6
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// lfs f9,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// stfs f9,80(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f9,f20,f25
	ctx.f9.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// lfs f6,-29772(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29772);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f11,f15
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// lfs f20,-29776(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -29776);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,344(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// fnmsubs f6,f14,f6,f7
	ctx.f6.f64 = double(float(-(ctx.f14.f64 * ctx.f6.f64 - ctx.f7.f64)));
	// lfs f7,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f5,f9,f5
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// lfs f9,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f4,f2,f9
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// lfs f9,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f3,f1,f9
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// fmuls f9,f15,f18
	ctx.f9.f64 = double(float(ctx.f15.f64 * ctx.f18.f64));
	// fmadds f5,f5,f20,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f20.f64 + ctx.f3.f64));
	// fmuls f2,f9,f11
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// lfs f9,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f23
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// fmuls f9,f9,f12
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// lfs f1,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// stfs f9,80(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f9,f7,f23
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// lfs f7,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmuls f3,f2,f7
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// fmsubs f4,f9,f8,f4
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 - ctx.f4.f64));
	// lfs f9,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fnmsubs f6,f1,f13,f6
	ctx.f6.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f6.f64)));
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f19
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f2,f10,f9
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f9,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f14,f8
	ctx.f8.f64 = double(float(ctx.f14.f64 * ctx.f8.f64));
	// fnmsubs f5,f3,f20,f5
	ctx.f5.f64 = double(float(-(ctx.f3.f64 * ctx.f20.f64 - ctx.f5.f64)));
	// fmuls f7,f7,f23
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// fmadds f4,f13,f9,f4
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 + ctx.f4.f64));
	// lfs f13,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f23
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// lfs f9,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f8,f4,f12,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 - ctx.f8.f64));
	// fmuls f1,f13,f9
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f13,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// fmuls f9,f11,f15
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// fmadds f7,f7,f0,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 + ctx.f1.f64));
	// fmuls f9,f13,f9
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f13,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f3,f13,f30
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// lfs f13,968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 968);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f14,f13,f11
	ctx.f14.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f13,-29764(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29764);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f6,f2,f13,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f6.f64));
	// lfs f13,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f4,f13,f15
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f15.f64));
	// lfs f13,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f8,f7,f12,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + ctx.f8.f64));
	// fmadds f5,f9,f20,f5
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f20.f64 + ctx.f5.f64));
	// lfs f9,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f2,f9,f13
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f9,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f4,f4,f18
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f18.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f1,f9,f13
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f9,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f9,f10,f9
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f10,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f6,f3,f10,f6
	ctx.f6.f64 = double(float(-(ctx.f3.f64 * ctx.f10.f64 - ctx.f6.f64)));
	// lfs f10,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f10,f23
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f23.f64));
	// lfs f10,936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 936);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f7,f10,f11
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f5,f14,f10,f5
	ctx.f5.f64 = double(float(-(ctx.f14.f64 * ctx.f10.f64 - ctx.f5.f64)));
	// lfs f14,992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 992);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f10
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// lfs f10,-29764(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29764);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f6,f9,f10,f6
	ctx.f6.f64 = double(float(-(ctx.f9.f64 * ctx.f10.f64 - ctx.f6.f64)));
	// lfs f9,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f8,f3,f0,f8
	ctx.f8.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f8.f64)));
	// fmuls f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f9,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f10,f9,f23
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// fmuls f3,f10,f12
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f12,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f7,f7,f12,f5
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f12.f64 - ctx.f5.f64)));
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f5,f4,f12,f14
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f14.f64));
	// fmsubs f4,f2,f10,f1
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f10.f64 - ctx.f1.f64));
	// lfs f10,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f2,f10,f13
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,-29772(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29772);
	ctx.f10.f64 = double(temp.f32);
	// lfs f1,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f10,f1,f10,f6
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f6.f64));
	// stfs f10,4364(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4364, temp.u32);
	// lfs f10,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f6,f10,f13
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f10,f3,f10,f8
	ctx.f10.f64 = double(float(-(ctx.f3.f64 * ctx.f10.f64 - ctx.f8.f64)));
	// stfs f10,4368(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4368, temp.u32);
	// fmadds f10,f5,f11,f7
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 + ctx.f7.f64));
	// stfs f10,4372(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4372, temp.u32);
	// lfs f10,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f7,f2,f0,f4
	ctx.f7.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// lfs f14,928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 928);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f7,f6,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fmuls f8,f10,f12
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f10,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f5,f10,f13
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,1568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1568);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f10,f11
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 896);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f10,f11
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f12,f9,f31
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f4,f4,f24
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f24.f64));
	// fmuls f2,f10,f13
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f9,f12,f13
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f3,f3,f12
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// lfs f12,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fmadds f1,f10,f0,f8
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f8.f64));
	// lfs f10,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// lfs f8,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f1,f12,f0,f1
	ctx.f1.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// lfs f12,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fmuls f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// fmuls f6,f12,f13
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,1032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1032);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f8,f12,f8
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// lfs f12,-30152(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -30152);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,384(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fmuls f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// lfs f12,920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 920);
	ctx.f12.f64 = double(temp.f32);
	// fadds f14,f12,f14
	ctx.f14.f64 = double(float(ctx.f12.f64 + ctx.f14.f64));
	// fnmsubs f7,f6,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// lfs f12,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f3,f10,f12,f3
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + ctx.f3.f64));
	// lfs f12,976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 976);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f10,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f10.f64 = double(temp.f32);
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f12,f10,f28
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmsubs f11,f1,f13,f5
	ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 - ctx.f5.f64));
	// lfs f10,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f5,f12,f13
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fmadds f1,f10,f31,f12
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f31.f64 + ctx.f12.f64));
	// lfs f12,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// lfs f10,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fmuls f6,f12,f13
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,-30152(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -30152);
	ctx.f12.f64 = double(temp.f32);
	// fmsubs f8,f8,f12,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 - ctx.f4.f64));
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f2,f2,f12,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 + ctx.f11.f64));
	// fmuls f12,f27,f31
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f11,f26,f31
	ctx.f11.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fmuls f4,f14,f10
	ctx.f4.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// fadds f11,f11,f12
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// lfs f12,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f12.f64 = double(temp.f32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f3,f14,f12,f3
	ctx.f3.f64 = double(float(ctx.f14.f64 * ctx.f12.f64 + ctx.f3.f64));
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f12,f31,f30
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fmuls f12,f12,f23
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f23.f64));
	// fmuls f14,f12,f14
	ctx.f14.f64 = double(float(ctx.f12.f64 * ctx.f14.f64));
	// lfs f12,1560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1560);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f12,f10
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f12,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fnmsubs f7,f6,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// lfs f6,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f13,f6,f30
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f6,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f6.f64 = double(temp.f32);
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f24
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f24.f64));
	// fnmsubs f9,f9,f12,f2
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// fmuls f2,f11,f29
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f29.f64));
	// fmuls f6,f13,f6
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// lfs f13,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f8,f4,f13,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f8.f64));
	// lfs f4,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f13,f31,f30
	ctx.f13.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fnmsubs f9,f5,f0,f9
	ctx.f9.f64 = double(float(-(ctx.f5.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// fnmsubs f7,f6,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// stfs f7,4376(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4376, temp.u32);
	// fmuls f13,f13,f19
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// fmadds f9,f1,f0,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f9.f64));
	// lfs f1,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f4,f13,f4
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// lfs f13,-30152(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -30152);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f5,f14,f13,f3
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 + ctx.f3.f64));
	// lfs f14,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f8,f4,f13,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f8.f64));
	// stfs f8,4380(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4380, temp.u32);
	// fnmsubs f13,f10,f13,f5
	ctx.f13.f64 = double(float(-(ctx.f10.f64 * ctx.f13.f64 - ctx.f5.f64)));
	// stfs f13,4388(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4388, temp.u32);
	// lfs f10,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f10.f64 = double(temp.f32);
	// fmsubs f8,f24,f31,f2
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f31.f64 - ctx.f2.f64));
	// lfs f13,912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 912);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f10,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f10.f64 = double(temp.f32);
	// stfs f8,4384(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4384, temp.u32);
	// lfs f11,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f3,f11,f31
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fmuls f11,f15,f25
	ctx.f11.f64 = double(float(ctx.f15.f64 * ctx.f25.f64));
	// fmuls f11,f11,f14
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f14.f64));
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f15.f64));
	// fmuls f8,f11,f10
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// fmuls f11,f14,f25
	ctx.f11.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// fnmsubs f10,f3,f0,f9
	ctx.f10.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// stfs f10,4392(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4392, temp.u32);
	// lfs f9,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f10,f11,f12,f13
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f12.f64 + ctx.f13.f64));
	// lfs f13,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f13,f17
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f17.f64));
	// lfs f13,876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f6,f13,f28
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f13,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f23
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f5,f13,f9
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f13,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f4,f13,f17
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f17.f64));
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f13,f28
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f13,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f7,f5,f12,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 + ctx.f7.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f3,f11,f13
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f11,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f13,f11
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f11,1164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1164);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// stfs f11,248(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f11,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f10,f11
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,-29756(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -29756);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,188(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f6,f6,f10
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// lfs f10,904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 904);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f14,f10,f11
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f17
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f17.f64));
	// fmsubs f8,f8,f20,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f20.f64 - ctx.f1.f64));
	// fmuls f9,f10,f9
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f10,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f25
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// fmsubs f6,f3,f12,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 - ctx.f6.f64));
	// lfs f3,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f3.f64 = double(temp.f32);
	// lfs f12,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f5,f2,f31
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// fmuls f10,f3,f30
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// fmuls f11,f11,f15
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// stfs f11,136(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fadds f10,f10,f12
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fmuls f12,f28,f18
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// fmuls f3,f12,f31
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fmuls f12,f26,f17
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// fmuls f2,f12,f22
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f22.f64));
	// lfs f12,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f18
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f18.f64));
	// fmuls f11,f12,f11
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f12,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f1,f14,f12,f8
	ctx.f1.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// lfs f12,1008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1008);
	ctx.f12.f64 = double(temp.f32);
	// lfs f8,984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 984);
	ctx.f8.f64 = double(temp.f32);
	// fadds f14,f12,f8
	ctx.f14.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// lfs f12,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f12.f64 = double(temp.f32);
	// fmsubs f7,f9,f12,f7
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 - ctx.f7.f64));
	// lfs f12,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// lfs f9,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f12,f12,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// lfs f9,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f4,f8,f9,f4
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f9.f64 + ctx.f4.f64));
	// lfs f8,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f6,f5,f8,f6
	ctx.f6.f64 = double(float(-(ctx.f5.f64 * ctx.f8.f64 - ctx.f6.f64)));
	// lfs f9,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f5,f10,f13
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmsubs f3,f3,f9,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 - ctx.f2.f64));
	// lfs f9,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f2,f11,f20,f1
	ctx.f2.f64 = double(float(-(ctx.f11.f64 * ctx.f20.f64 - ctx.f1.f64)));
	// lfs f11,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f14,f11
	ctx.f1.f64 = double(float(ctx.f14.f64 * ctx.f11.f64));
	// lfs f11,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f11
	ctx.f10.f64 = ctx.f11.f64;
	// lfs f11,-29764(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29764);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f14,f12,f9,f7
	ctx.f14.f64 = double(float(-(ctx.f12.f64 * ctx.f9.f64 - ctx.f7.f64)));
	// lfs f12,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// fmadds f6,f5,f11,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 + ctx.f6.f64));
	// fmadds f2,f1,f9,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f2.f64));
	// lfs f9,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f18
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f18.f64));
	// lfs f1,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f4,f12,f10,f4
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 + ctx.f4.f64));
	// fmuls f12,f28,f19
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fmuls f1,f9,f1
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// lfs f9,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fnmsubs f3,f12,f21,f3
	ctx.f3.f64 = double(float(-(ctx.f12.f64 * ctx.f21.f64 - ctx.f3.f64)));
	// lfs f12,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f12.f64 = double(temp.f32);
	// lfs f7,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f5,f7,f31
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// lfs f7,868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 868);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f12
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// stfs f7,80(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmr f7,f9
	ctx.f7.f64 = ctx.f9.f64;
	// lfs f9,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f17
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f17.f64));
	// fnmsubs f8,f5,f8,f6
	ctx.f8.f64 = double(float(-(ctx.f5.f64 * ctx.f8.f64 - ctx.f6.f64)));
	// lfs f5,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f4,f4,f7,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f7.f64 + ctx.f14.f64));
	// fmuls f7,f9,f7
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f9,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fmuls f6,f9,f13
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f9,f27,f17
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f17.f64));
	// fnmsubs f9,f9,f5,f3
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f5.f64 - ctx.f3.f64)));
	// fnmsubs f3,f1,f20,f2
	ctx.f3.f64 = double(float(-(ctx.f1.f64 * ctx.f20.f64 - ctx.f2.f64)));
	// lfs f5,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f24
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// fmadds f11,f6,f11,f8
	ctx.f11.f64 = double(float(ctx.f6.f64 * ctx.f11.f64 + ctx.f8.f64));
	// stfs f11,4404(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4404, temp.u32);
	// fmadds f11,f24,f17,f9
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f17.f64 + ctx.f9.f64));
	// stfs f11,4408(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4408, temp.u32);
	// lfs f11,1036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1036);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f7,f7,f10,f4
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f9,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f8,f11,f9,f8
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f9.f64 + ctx.f8.f64));
	// lfs f11,864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 864);
	ctx.f11.f64 = double(temp.f32);
	// stfs f7,4400(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4400, temp.u32);
	// fmuls f7,f5,f11
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// lfs f11,880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 880);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f6,f11,f12
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f11,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f5,f11,f13
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f11,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f4,f11,f28
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// lfs f11,1000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1000);
	ctx.f11.f64 = double(temp.f32);
	// stfs f3,4396(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4396, temp.u32);
	// fmuls f3,f11,f12
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f9,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f9.f64 = double(temp.f32);
	// lfs f11,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f11,f9
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f11,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfs f14,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfs f0,-29768(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -29768);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f11,f13
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f11,-29772(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29772);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f6,f6,f11
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f11,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f19
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// fmadds f6,f4,f0,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 + ctx.f6.f64));
	// fmuls f0,f28,f23
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmuls f11,f11,f14
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f14.f64));
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f9,f14,f9
	ctx.f9.f64 = double(float(ctx.f14.f64 * ctx.f9.f64));
	// lfs f14,1016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1016);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f10,f14,f10
	ctx.f10.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// lfs f14,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f0,f0,f30
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmuls f4,f0,f21
	ctx.f4.f64 = double(float(ctx.f0.f64 * ctx.f21.f64));
	// lfs f0,872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 872);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f12,f0,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfs f0,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f0,f13
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f0,1028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1028);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f14
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f14.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f11,f11,f14,f2
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f14.f64 - ctx.f2.f64));
	// lfs f2,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f2.f64 = double(temp.f32);
	// lfs f0,-29756(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -29756);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f10,f9,f2,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f2.f64 + ctx.f10.f64));
	// fmsubs f9,f5,f0,f6
	ctx.f9.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 - ctx.f6.f64));
	// stfs f0,188(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f0,992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 992);
	ctx.f0.f64 = double(temp.f32);
	// lfs f6,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f0,f6
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// lfs f14,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f14.f64 = double(temp.f32);
	// lfs f0,944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 944);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f5,f24,f14,f4
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f14.f64 - ctx.f4.f64));
	// fmuls f4,f0,f28
	ctx.f4.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fnmsubs f9,f3,f0,f9
	ctx.f9.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// lfs f3,888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 888);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// lfs f2,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f11,f2,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// lfs f0,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f0.f64 = double(temp.f32);
	// lfs f2,952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 952);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f10,f2,f0,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f0,1024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1024);
	ctx.f0.f64 = double(temp.f32);
	// lfs f2,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f0,f2
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f0,f26,f14
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f14.f64));
	// fnmsubs f5,f0,f22,f5
	ctx.f5.f64 = double(float(-(ctx.f0.f64 * ctx.f22.f64 - ctx.f5.f64)));
	// lfs f0,-29764(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29764);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f9,f1,f0,f9
	ctx.f9.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// stfs f0,228(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f0,-29768(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -29768);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f4,f4,f0,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 + ctx.f3.f64));
	// lfs f0,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f11,f10,f0,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f11.f64));
	// lfs f3,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f3.f64 = double(temp.f32);
	// lfs f10,960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 960);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f6,f2,f0,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f6.f64));
	// lfs f0,936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 936);
	ctx.f0.f64 = double(temp.f32);
	// lfs f2,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f0,f2
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// lfs f0,-29772(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29772);
	ctx.f0.f64 = double(temp.f32);
	// lfs f1,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f12,f12,f0,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f9.f64));
	// lfs f9,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f0,f27,f14
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f14.f64));
	// fmuls f3,f3,f18
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// fnmsubs f9,f0,f9,f5
	ctx.f9.f64 = double(float(-(ctx.f0.f64 * ctx.f9.f64 - ctx.f5.f64)));
	// fmuls f0,f28,f25
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f5,f0,f31
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// lfs f0,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f30
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmuls f1,f0,f1
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f11,f10,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f10.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// lfs f10,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f10.f64 = double(temp.f32);
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fnmsubs f13,f13,f10,f12
	ctx.f13.f64 = double(float(-(ctx.f13.f64 * ctx.f10.f64 - ctx.f12.f64)));
	// stfs f13,136(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmadds f6,f2,f0,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f6.f64));
	// lfs f10,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// fmr f13,f10
	ctx.f13.f64 = ctx.f10.f64;
	// fmuls f12,f12,f25
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// fmuls f2,f12,f13
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f12.f64 = double(temp.f32);
	// fmsubs f10,f8,f12,f7
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 - ctx.f7.f64));
	// stfs f10,4412(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4412, temp.u32);
	// lfs f10,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f10,f5,f10,f9
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 + ctx.f9.f64));
	// stfs f10,4416(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4416, temp.u32);
	// lfs f10,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f10.f64 = double(temp.f32);
	// fmr f11,f10
	ctx.f11.f64 = ctx.f10.f64;
	// fmuls f10,f11,f25
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// fmuls f8,f10,f13
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f10,f3,f10,f9
	ctx.f10.f64 = double(float(-(ctx.f3.f64 * ctx.f10.f64 - ctx.f9.f64)));
	// lfs f9,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f12,f4,f12,f9
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f9.f64));
	// stfs f10,4424(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4424, temp.u32);
	// lfs f10,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f7,f2,f10,f6
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f10.f64 + ctx.f6.f64));
	// lfs f10,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f12,f1,f10,f12
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f12.f64));
	// stfs f12,4420(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4420, temp.u32);
	// fmuls f12,f9,f31
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// lfs f10,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f6,f12,f21
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// lfs f12,984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 984);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f5,f12,f0
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f12,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// fadds f4,f10,f12
	ctx.f4.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// lfs f10,928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 928);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f3,f10,f12
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f10,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmsubs f6,f10,f21,f6
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f21.f64 - ctx.f6.f64));
	// fmuls f10,f11,f18
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f18.f64));
	// fmuls f10,f10,f13
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmuls f13,f9,f17
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f17.f64));
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lfs f1,976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 976);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f12
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// fmuls f9,f13,f22
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f22.f64));
	// lfs f13,1008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1008);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f5,f13,f0,f5
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 - ctx.f5.f64));
	// fmuls f13,f11,f31
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// lfs f11,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fadds f4,f4,f13
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f13.f64));
	// lfs f13,920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 920);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f2,f13,f12
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f13,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// lfs f12,912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 912);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f5,f12,f0,f5
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f5.f64));
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f0,f12,f31
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fnmsubs f6,f13,f21,f6
	ctx.f6.f64 = double(float(-(ctx.f13.f64 * ctx.f21.f64 - ctx.f6.f64)));
	// lfs f13,648(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 648);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,188(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f3,f3,f13
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfs f13,-29744(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -29744);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// stfs f13,136(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmadds f6,f0,f21,f6
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f21.f64 + ctx.f6.f64));
	// fmuls f0,f12,f17
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// fmsubs f12,f0,f22,f9
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f22.f64 - ctx.f9.f64));
	// lfs f0,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f31
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fsubs f9,f4,f0
	ctx.f9.f64 = double(float(ctx.f4.f64 - ctx.f0.f64));
	// lfs f0,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f4,f2,f0,f3
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f3.f64));
	// lfs f0,1032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1032);
	ctx.f0.f64 = double(temp.f32);
	// lfs f3,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f0,f3
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f2,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f0,f27,f31
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f2,f0,f2
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// lfs f0,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// fsubs f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f0.f64));
	// fmuls f0,f31,f30
	ctx.f0.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// stfs f0,388(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fmuls f0,f0,f23
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// fmsubs f11,f0,f13,f11
	ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 - ctx.f11.f64));
	// lfs f0,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f0,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f10,f5,f0,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f5,904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 904);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// lfs f0,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f23
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// fnmsubs f13,f3,f13,f4
	ctx.f13.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f4.f64)));
	// fnmsubs f12,f0,f29,f12
	ctx.f12.f64 = double(float(-(ctx.f0.f64 * ctx.f29.f64 - ctx.f12.f64)));
	// lfs f0,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f30
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fsubs f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f0.f64));
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f7,f8,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f8.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// lfs f8,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f8.f64 = double(temp.f32);
	// lfs f0,968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 968);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f8,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f8.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f0,f8,f30
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// lfs f8,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f0.f64));
	// lfs f0,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// fmuls f4,f0,f8
	ctx.f4.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f8,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f0,f26,f31
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fmuls f3,f0,f8
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f0,-30152(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -30152);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,384(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfs f0,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f0.f64 = double(temp.f32);
	// addi r6,r31,36
	ctx.r6.s64 = ctx.r31.s64 + 36;
	// fmsubs f1,f11,f0,f1
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f1.f64));
	// lfs f11,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 896);
	ctx.f0.f64 = double(temp.f32);
	// addi r5,r29,36
	ctx.r5.s64 = ctx.r29.s64 + 36;
	// fmuls f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f11,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f11.f64 = double(temp.f32);
	// stfs f0,228(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f0,f11,f30
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfs f11,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f11.f64 = double(temp.f32);
	// addi r4,r1,4288
	ctx.r4.s64 = ctx.r1.s64 + 4288;
	// lfs f8,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f8.f64 = double(temp.f32);
	// li r3,7
	ctx.r3.s64 = 7;
	// fadds f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f0.f64));
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f10,f5,f0,f10
	ctx.f10.f64 = double(float(-(ctx.f5.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// lfs f0,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f18
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f18.f64));
	// fmuls f5,f0,f11
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f0,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f17
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f17.f64));
	// lfs f11,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f0,f0,f22,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f22.f64 + ctx.f12.f64));
	// lfs f12,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f12,f12,f8,f7
	ctx.f12.f64 = double(float(-(ctx.f12.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// stfs f12,4428(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4428, temp.u32);
	// lfs f12,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f12.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f0,f12,f30
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f0,f9,f0
	ctx.f0.f64 = double(float(ctx.f9.f64 - ctx.f0.f64));
	// stfs f0,4432(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4432, temp.u32);
	// lfs f0,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f0,f4,f0,f13
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 + ctx.f13.f64));
	// stfs f0,4436(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4436, temp.u32);
	// fmsubs f0,f3,f11,f2
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 - ctx.f2.f64));
	// stfs f0,4440(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4440, temp.u32);
	// lfs f13,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f0,f13,f0,f1
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f1.f64));
	// stfs f0,4444(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4444, temp.u32);
	// lfs f0,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// lfs f13,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f13.f64 = double(temp.f32);
	// lfs f9,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fadds f0,f6,f0
	ctx.f0.f64 = double(float(ctx.f6.f64 + ctx.f0.f64));
	// stfs f0,4448(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4448, temp.u32);
	// fnmsubs f0,f5,f12,f10
	ctx.f0.f64 = double(float(-(ctx.f5.f64 * ctx.f12.f64 - ctx.f10.f64)));
	// stfs f0,4452(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4452, temp.u32);
	// lfs f0,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f17
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f17.f64));
	// lfs f10,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f0,f0,f13,f10
	ctx.f0.f64 = double(float(-(ctx.f0.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// stfs f0,4456(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4456, temp.u32);
	// fmuls f0,f15,f16
	ctx.f0.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// lfs f13,1000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1000);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f13,f0
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f13,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f10,f13,f30
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// lfs f13,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// fmuls f6,f10,f13
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 888);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f5,f10,f0
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f10,960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 960);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f10,f22
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f22.f64));
	// lfs f10,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fadds f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// lfs f10,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f3,f10,f13
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmuls f10,f28,f23
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// stfs f10,436(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmuls f7,f10,f11
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 880);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f2,f10,f0
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f10,1016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1016);
	ctx.f10.f64 = double(temp.f32);
	// fmsubs f4,f10,f22,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f22.f64 - ctx.f4.f64));
	// fmuls f10,f28,f19
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// stfs f10,656(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 656, temp.u32);
	// fmadds f8,f6,f12,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 + ctx.f8.f64));
	// fmuls f6,f3,f12
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// fmuls f9,f9,f13
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmsubs f9,f9,f12,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 - ctx.f6.f64));
	// lfs f12,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fmuls f3,f10,f11
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f11,f27,f17
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f17.f64));
	// fmuls f6,f12,f13
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fmuls f12,f26,f17
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// fmuls f1,f11,f10
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// lfs f11,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f27,f14
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f14.f64));
	// fmadds f10,f10,f11,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 + ctx.f7.f64));
	// lfs f7,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f8,f5,f7,f8
	ctx.f8.f64 = double(float(-(ctx.f5.f64 * ctx.f7.f64 - ctx.f8.f64)));
	// lfs f5,952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 952);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f5,f5,f22,f4
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f22.f64 - ctx.f4.f64)));
	// lfs f7,872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 872);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f4,f12,f11,f3
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 - ctx.f3.f64));
	// lfs f12,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f3,f1,f11
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// lfs f11,1036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1036);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fnmsubs f8,f2,f12,f8
	ctx.f8.f64 = double(float(-(ctx.f2.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// lfs f12,-30148(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -30148);
	ctx.f12.f64 = double(temp.f32);
	// lfs f2,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f2,f11,f12,f2
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f12.f64 - ctx.f2.f64));
	// lfs f11,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f26,f14
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f14.f64));
	// fmuls f0,f2,f0
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f0,4468(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4468, temp.u32);
	// fmuls f1,f12,f11
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f12,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// lfs f0,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,1028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1028);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f10,f13,f10,f5
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64 + ctx.f5.f64));
	// lfs f13,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f8,f7,f13,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 + ctx.f8.f64));
	// lfs f13,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f0,f1,f0,f11
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 - ctx.f11.f64));
	// stfs f0,4472(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4472, temp.u32);
	// fmadds f9,f6,f13,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f9.f64));
	// stfs f9,4460(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4460, temp.u32);
	// lfs f9,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f9,f4,f9,f3
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 - ctx.f3.f64));
	// stfs f9,4464(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4464, temp.u32);
	// fnmsubs f0,f12,f13,f8
	ctx.f0.f64 = double(float(-(ctx.f12.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// stfs f0,4476(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4476, temp.u32);
	// lfs f0,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// fmadds f0,f0,f29,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f29.f64 + ctx.f10.f64));
	// stfs f0,4480(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4480, temp.u32);
	// bl 0x82a64ab8
	ctx.lr = 0x82A66334;
	sub_82A64AB8(ctx, base);
	// cmplwi cr6,r28,4
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 4, ctx.xer);
	// bgt cr6,0x82a66340
	if (ctx.cr6.gt) goto loc_82A66340;
	// b 0x82a76e10
	goto loc_82A76E10;
loc_82A66340:
	// lfs f11,452(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f0,f16,f19
	ctx.f0.f64 = double(float(ctx.f16.f64 * ctx.f19.f64));
	// stfs f0,204(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fmuls f0,f11,f14
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f14.f64));
	// lfs f8,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f2,f16,f17
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// stfs f0,180(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmuls f0,f8,f14
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f14.f64));
	// stfs f0,832(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 832, temp.u32);
	// fmuls f0,f11,f17
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f17.f64));
	// lfs f10,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f8,f17
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f17.f64));
	// stfs f0,700(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 700, temp.u32);
	// fmuls f0,f10,f28
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// stfs f0,256(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmuls f0,f11,f28
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f0,f15,f16
	ctx.f0.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// stfs f0,164(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fmuls f0,f8,f28
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// lfs f9,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f5,f10,f23
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f23.f64));
	// stfs f0,520(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// fmuls f0,f9,f28
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// stfs f0,332(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fmuls f3,f9,f19
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f19.f64));
	// lfs f0,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f7,f0,f9
	ctx.f7.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// lfs f6,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f6.f64 = double(temp.f32);
	// stfs f7,708(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 708, temp.u32);
	// fmuls f7,f6,f10
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// stfs f7,1024(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1024, temp.u32);
	// lfs f7,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f7,f30
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f1,136(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f1,f7,f28
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// stfs f1,872(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 872, temp.u32);
	// fmuls f1,f11,f30
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// stfs f1,716(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 716, temp.u32);
	// fmuls f1,f10,f30
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// stfs f1,724(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 724, temp.u32);
	// fmuls f1,f9,f30
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// stfs f1,384(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fmuls f1,f16,f8
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f8.f64));
	// stfs f1,588(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 588, temp.u32);
	// fmuls f1,f26,f6
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// lfs f12,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f6,f27,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// stfs f6,228(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f6,f26,f0
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// stfs f6,720(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 720, temp.u32);
	// fmuls f0,f27,f0
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// stfs f0,828(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 828, temp.u32);
	// lfs f0,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f12,f15
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f15.f64));
	// fmuls f0,f0,f30
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// stfs f0,1120(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1120, temp.u32);
	// fmuls f0,f12,f17
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f0,464(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// fmuls f0,f27,f30
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// stfs f0,188(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f0,f12,f19
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f19.f64));
	// stfs f0,696(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 696, temp.u32);
	// fmuls f0,f26,f14
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f14.f64));
	// stfs f0,248(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fmuls f0,f12,f14
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f14.f64));
	// lfs f6,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f6.f64 = double(temp.f32);
	// stfs f0,856(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 856, temp.u32);
	// fmuls f0,f12,f23
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f23.f64));
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f0,1176(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1176, temp.u32);
	// stfs f6,824(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 824, temp.u32);
	// fmuls f0,f27,f7
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// lfs f6,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f6.f64 = double(temp.f32);
	// stfs f2,152(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// stfs f4,1164(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1164, temp.u32);
	// stfs f5,896(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 896, temp.u32);
	// stfs f3,1560(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1560, temp.u32);
	// stfs f13,284(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// stfs f1,596(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// stfs f0,1048(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1048, temp.u32);
	// fmuls f0,f6,f27
	ctx.f0.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// stfs f0,1204(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1204, temp.u32);
	// fmuls f0,f26,f7
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// stfs f0,1188(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1188, temp.u32);
	// fmuls f0,f16,f14
	ctx.f0.f64 = double(float(ctx.f16.f64 * ctx.f14.f64));
	// stfs f0,108(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f1,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f0,f8,f30
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// stfs f0,672(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 672, temp.u32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// fmuls f0,f6,f28
	ctx.f0.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// stfs f1,928(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 928, temp.u32);
	// stfs f0,1196(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1196, temp.u32);
	// fmuls f0,f16,f23
	ctx.f0.f64 = double(float(ctx.f16.f64 * ctx.f23.f64));
	// lfs f1,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// stfs f0,364(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// fmuls f0,f6,f30
	ctx.f0.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f1,920(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 920, temp.u32);
	// stfs f0,1212(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1212, temp.u32);
	// fmuls f0,f16,f11
	ctx.f0.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// lfs f1,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f1.f64 = double(temp.f32);
	// stfs f0,692(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 692, temp.u32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// fmuls f0,f6,f10
	ctx.f0.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// stfs f1,936(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 936, temp.u32);
	// stfs f0,912(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 912, temp.u32);
	// lfs f0,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f0.f64 = double(temp.f32);
	// lfs f1,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f0,f0,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f0,876(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 876, temp.u32);
	// stfs f1,1032(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1032, temp.u32);
	// fmuls f0,f4,f23
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// fmuls f1,f16,f5
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f5.f64));
	// stfs f0,868(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 868, temp.u32);
	// stfs f1,1072(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1072, temp.u32);
	// fmuls f0,f5,f17
	ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f17.f64));
	// lfs f1,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f1.f64 = double(temp.f32);
	// stfs f0,864(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 864, temp.u32);
	// fmuls f1,f16,f1
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f1.f64));
	// fmuls f0,f3,f14
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f14.f64));
	// stfs f1,1144(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1144, temp.u32);
	// stfs f0,992(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 992, temp.u32);
	// fmuls f1,f9,f14
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f14.f64));
	// fmuls f0,f16,f3
	ctx.f0.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// stfs f1,428(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// stfs f0,812(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 812, temp.u32);
	// fmuls f1,f11,f23
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// lfs f0,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f0.f64 = double(temp.f32);
	// stfs f1,1052(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1052, temp.u32);
	// fmuls f0,f0,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// fmuls f1,f11,f25
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// stfs f0,944(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 944, temp.u32);
	// stfs f1,392(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fmuls f1,f10,f25
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// lfs f0,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f0.f64 = double(temp.f32);
	// stfs f1,532(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// fmuls f0,f0,f23
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// fmuls f1,f11,f19
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// stfs f0,748(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 748, temp.u32);
	// stfs f1,728(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 728, temp.u32);
	// fmuls f0,f16,f4
	ctx.f0.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// fmuls f1,f9,f18
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f18.f64));
	// stfs f0,844(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 844, temp.u32);
	// stfs f1,264(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fmuls f0,f13,f19
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// fmuls f1,f11,f18
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f18.f64));
	// stfs f0,308(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// stfs f1,380(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fmuls f0,f13,f17
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f17.f64));
	// fmuls f1,f8,f19
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f19.f64));
	// stfs f0,604(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 604, temp.u32);
	// stfs f1,816(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 816, temp.u32);
	// fmuls f1,f8,f18
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f18.f64));
	// lfs f0,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f0.f64 = double(temp.f32);
	// stfs f1,668(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 668, temp.u32);
	// fmuls f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// fmuls f1,f10,f19
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f19.f64));
	// stfs f0,224(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// stfs f1,600(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// fmuls f6,f6,f11
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// stfs f6,968(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 968, temp.u32);
	// lfs f6,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f1,f10,f18
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f18.f64));
	// fmuls f6,f6,f23
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f6,976(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 976, temp.u32);
	// fmuls f6,f4,f19
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// stfs f6,1000(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1000, temp.u32);
	// fmuls f6,f5,f14
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// stfs f6,880(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 880, temp.u32);
	// stfs f1,220(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fmuls f1,f8,f25
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// lfs f6,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f23
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f6,888(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 888, temp.u32);
	// fmuls f6,f3,f17
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// stfs f6,960(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 960, temp.u32);
	// fmuls f6,f16,f18
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f18.f64));
	// stfs f6,172(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// stfs f1,252(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fmuls f6,f16,f9
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// fmuls f1,f8,f23
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f23.f64));
	// stfs f6,1080(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1080, temp.u32);
	// stfs f1,1008(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1008, temp.u32);
	// fmuls f6,f3,f31
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f1,f9,f23
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// stfs f6,1416(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1416, temp.u32);
	// stfs f1,1044(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1044, temp.u32);
	// fmuls f1,f9,f25
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// lfs f6,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f6.f64 = double(temp.f32);
	// stfs f1,524(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// fmuls f1,f6,f18
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// stfs f1,1400(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1400, temp.u32);
	// fmuls f1,f6,f31
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f6,f6,f25
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// stfs f6,1324(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1324, temp.u32);
	// lfs f6,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f23
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f6,904(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 904, temp.u32);
	// lfs f6,1052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1052);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f6,1500(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1500, temp.u32);
	// lfs f6,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f6,1028(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1028, temp.u32);
	// lfs f6,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,1440(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1440, temp.u32);
	// lfs f6,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,952(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 952, temp.u32);
	// lfs f6,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f6,1036(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1036, temp.u32);
	// lfs f6,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,1432(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1432, temp.u32);
	// lfs f6,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f6,1016(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1016, temp.u32);
	// stfs f1,1360(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1360, temp.u32);
	// fmuls f1,f13,f14
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f14.f64));
	// stfs f1,336(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f6,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,1424(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1424, temp.u32);
	// lfs f6,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f1,f6,f26
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// stfs f1,1180(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1180, temp.u32);
	// fmuls f1,f26,f18
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f18.f64));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1352(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1352, temp.u32);
	// fmuls f1,f27,f31
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f1,f1,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// stfs f1,1376(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1376, temp.u32);
	// fmuls f1,f26,f19
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1384(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1384, temp.u32);
	// fmuls f1,f26,f25
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1408(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1408, temp.u32);
	// fmuls f1,f27,f23
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1616(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1616, temp.u32);
	// lfs f7,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1392(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1392, temp.u32);
	// fmuls f1,f26,f23
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1368(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1368, temp.u32);
	// fmuls f1,f5,f31
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// stfs f1,1340(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1340, temp.u32);
	// lfs f1,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1596(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1596, temp.u32);
	// lfs f1,1008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1008);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1508(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1508, temp.u32);
	// lfs f1,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1612(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1612, temp.u32);
	// lfs f1,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1692(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1692, temp.u32);
	// lfs f1,1044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1044);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1516(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1516, temp.u32);
	// lfs f1,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1344(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1344, temp.u32);
	// fmuls f1,f30,f28
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,840(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 840, temp.u32);
	// fmuls f1,f31,f18
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f18.f64));
	// stfs f1,480(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// lfs f1,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f18
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f18.f64));
	// stfs f1,504(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// fmuls f1,f13,f18
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f18.f64));
	// stfs f1,1088(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1088, temp.u32);
	// fmuls f1,f12,f16
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f16.f64));
	// stfs f1,232(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fmuls f1,f15,f4
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// stfs f1,1492(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1492, temp.u32);
	// fmuls f1,f15,f3
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// stfs f1,1484(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1484, temp.u32);
	// fmuls f1,f9,f17
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f17.f64));
	// stfs f1,1128(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1128, temp.u32);
	// fmuls f1,f10,f17
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f17.f64));
	// stfs f1,820(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 820, temp.u32);
	// fmuls f1,f12,f28
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// stfs f1,984(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 984, temp.u32);
	// fmuls f1,f16,f25
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// stfs f1,460(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// fmuls f1,f10,f14
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f14.f64));
	// stfs f1,216(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fmuls f1,f15,f5
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// stfs f1,1604(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1604, temp.u32);
	// lfs f1,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f1.f64));
	// stfs f1,1636(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1636, temp.u32);
	// lfs f1,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// stfs f1,1172(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1172, temp.u32);
	// fmuls f1,f15,f18
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f18.f64));
	// stfs f1,852(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 852, temp.u32);
	// fmuls f1,f15,f19
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f19.f64));
	// stfs f1,808(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 808, temp.u32);
	// lfs f1,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// stfs f1,1624(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1624, temp.u32);
	// fmuls f1,f7,f28
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// stfs f1,1608(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1608, temp.u32);
	// lfs f1,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// stfs f1,1600(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1600, temp.u32);
	// lfs f1,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1592(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1592, temp.u32);
	// fmuls f1,f7,f30
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f1,1584(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1584, temp.u32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1576(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1576, temp.u32);
	// fmuls f7,f6,f14
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// stfs f7,1700(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1700, temp.u32);
	// fmuls f7,f30,f25
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lfs f6,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1568(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1568, temp.u32);
	// fmuls f7,f16,f10
	ctx.f7.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// stfs f7,1436(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1436, temp.u32);
	// fmuls f7,f6,f17
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// stfs f7,1152(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1152, temp.u32);
	// lfs f7,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f7,f18
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f18.f64));
	// stfs f1,316(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fmuls f1,f7,f17
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f17.f64));
	// stfs f1,1208(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1208, temp.u32);
	// fmuls f1,f6,f23
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f1,1168(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1168, temp.u32);
	// fmuls f1,f7,f14
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f14.f64));
	// stfs f1,516(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// fmuls f1,f6,f14
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// stfs f1,800(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 800, temp.u32);
	// fmuls f1,f6,f25
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// stfs f1,1096(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1096, temp.u32);
	// fmuls f1,f6,f18
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// stfs f1,1676(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1676, temp.u32);
	// fmuls f1,f6,f16
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f16.f64));
	// stfs f1,1444(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1444, temp.u32);
	// fmuls f1,f7,f16
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f16.f64));
	// stfs f1,1572(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1572, temp.u32);
	// fmuls f1,f15,f17
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f17.f64));
	// stfs f1,804(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 804, temp.u32);
	// lfs f1,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f1,f19
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// stfs f16,1184(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1184, temp.u32);
	// fmuls f16,f1,f17
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// stfs f16,1588(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1588, temp.u32);
	// lfs f16,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// stfs f16,1412(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1412, temp.u32);
	// fmuls f16,f6,f19
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// fmuls f6,f6,f12
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// stfs f6,1200(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1200, temp.u32);
	// fmuls f6,f12,f10
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// stfs f6,1112(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1112, temp.u32);
	// fmuls f6,f12,f11
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// stfs f6,1468(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1468, temp.u32);
	// fmuls f6,f7,f12
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// stfs f6,1104(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1104, temp.u32);
	// lfs f6,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// stfs f16,1420(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1420, temp.u32);
	// lfs f16,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// stfs f16,1652(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1652, temp.u32);
	// fmuls f16,f7,f19
	ctx.f16.f64 = double(float(ctx.f7.f64 * ctx.f19.f64));
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// stfs f16,1668(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1668, temp.u32);
	// fmuls f16,f12,f18
	ctx.f16.f64 = double(float(ctx.f12.f64 * ctx.f18.f64));
	// stfs f16,1476(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1476, temp.u32);
	// fmuls f16,f26,f19
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// stfs f16,1640(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1640, temp.u32);
	// fmuls f16,f26,f23
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// stfs f16,1632(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1632, temp.u32);
	// fmuls f16,f12,f9
	ctx.f16.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// stfs f16,1160(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1160, temp.u32);
	// fmuls f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// stfs f12,1644(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1644, temp.u32);
	// lfs f12,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1548(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1548, temp.u32);
	// lfs f12,1168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1168);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// stfs f12,1388(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1388, temp.u32);
	// lfs f16,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f12,f6,f28
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// stfs f12,1556(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1556, temp.u32);
	// fmuls f12,f16,f31
	ctx.f12.f64 = double(float(ctx.f16.f64 * ctx.f31.f64));
	// stfs f12,1380(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1380, temp.u32);
	// lfs f12,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1396(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1396, temp.u32);
	// lfs f12,1044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1044);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// stfs f12,1628(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1628, temp.u32);
	// fmuls f12,f7,f23
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// stfs f12,1404(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1404, temp.u32);
	// lfs f12,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1684(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1684, temp.u32);
	// fmuls f12,f15,f8
	ctx.f12.f64 = double(float(ctx.f15.f64 * ctx.f8.f64));
	// stfs f12,1928(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1928, temp.u32);
	// fmuls f12,f8,f8
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// stfs f12,676(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 676, temp.u32);
	// fmuls f12,f11,f11
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f11.f64));
	// stfs f12,1136(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1136, temp.u32);
	// fmuls f12,f9,f9
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f9.f64));
	// stfs f12,440(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fmuls f12,f10,f10
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f10.f64));
	// stfs f12,1064(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1064, temp.u32);
	// fmuls f12,f7,f15
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f15.f64));
	// stfs f12,1452(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1452, temp.u32);
	// fmuls f12,f15,f9
	ctx.f12.f64 = double(float(ctx.f15.f64 * ctx.f9.f64));
	// stfs f12,1580(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1580, temp.u32);
	// fmuls f12,f15,f11
	ctx.f12.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// stfs f12,1460(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1460, temp.u32);
	// fmuls f12,f15,f14
	ctx.f12.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// stfs f12,1428(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1428, temp.u32);
	// lfs f12,1128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1128);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1372(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1372, temp.u32);
	// lfs f12,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1620(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1620, temp.u32);
	// lfs f12,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1540(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1540, temp.u32);
	// fmuls f12,f4,f31
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// stfs f12,1364(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1364, temp.u32);
	// fmuls f12,f27,f31
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,1660(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1660, temp.u32);
	// fmuls f12,f26,f17
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1488(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1488, temp.u32);
	// fmuls f12,f26,f28
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmuls f10,f12,f18
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f18.f64));
	// stfs f10,1532(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1532, temp.u32);
	// fmuls f10,f12,f31
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f10,1348(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1348, temp.u32);
	// fmuls f12,f12,f25
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// stfs f12,1336(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1336, temp.u32);
	// lfs f12,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f27,f14
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f14.f64));
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// stfs f12,1688(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1688, temp.u32);
	// fmuls f12,f16,f28
	ctx.f12.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// stfs f12,1696(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1696, temp.u32);
	// lfs f12,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1524(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1524, temp.u32);
	// fmuls f12,f6,f31
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f12,1704(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1704, temp.u32);
	// lfs f12,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// stfs f12,1680(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1680, temp.u32);
	// lfs f12,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// stfs f12,1480(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1480, temp.u32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// stfs f10,1496(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1496, temp.u32);
	// lfs f10,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f12,f3,f23
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// stfs f12,1672(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1672, temp.u32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f12,f5,f19
	ctx.f12.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// stfs f10,1356(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1356, temp.u32);
	// stfs f12,1664(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1664, temp.u32);
	// lfs f12,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,1656(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1656, temp.u32);
	// fmuls f12,f4,f14
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f14.f64));
	// stfs f12,1648(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1648, temp.u32);
	// lfs f12,812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 812);
	ctx.f12.f64 = double(temp.f32);
	// lis r9,-32253
	ctx.r9.s64 = -2113732608;
	// fmuls f9,f12,f28
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// lfs f12,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f8,f12,f30
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// lfs f12,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f7,f10,f12
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f10,872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 872);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f10,f2
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// lfs f10,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f5,f10,f13
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 992);
	ctx.f10.f64 = double(temp.f32);
	// lfs f4,876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f10,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 + ctx.f4.f64));
	// lfs f10,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
	// lfs f3,868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 868);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f21.f64));
	// lfs f16,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f17,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f12,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f14,f12,f13
	ctx.f14.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmsubs f10,f8,f10,f9
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f10.f64 - ctx.f9.f64));
	// lfs f8,720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 720);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f9,f4,f21,f3
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f21.f64 - ctx.f3.f64));
	// lfs f4,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f4,f4,f2,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64 + ctx.f16.f64));
	// lfs f3,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f3.f64 = double(temp.f32);
	// lfs f16,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// fmuls f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fmsubs f5,f14,f12,f5
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f12.f64 - ctx.f5.f64));
	// lfs f14,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f10,f7,f29,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f29.f64 + ctx.f10.f64));
	// lfs f7,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f16
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f16.f64));
	// lfs f16,864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 864);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f16,f16,f21,f9
	ctx.f16.f64 = double(float(-(ctx.f16.f64 * ctx.f21.f64 - ctx.f9.f64)));
	// lfs f9,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// lfs f9,824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 824);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f14,f9,f14
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f14.f64));
	// lfs f9,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f8,f8,f12,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 + ctx.f5.f64));
	// fmuls f5,f27,f9
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// fnmsubs f6,f6,f29,f10
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f29.f64 - ctx.f10.f64)));
	// lfs f10,-11152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11152);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// lfs f10,944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 944);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f1.f64));
	// fnmsubs f1,f10,f29,f16
	ctx.f1.f64 = double(float(-(ctx.f10.f64 * ctx.f29.f64 - ctx.f16.f64)));
	// lfs f10,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f10.f64 = double(temp.f32);
	// lfs f16,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f10,f16
	ctx.f16.f64 = double(float(ctx.f10.f64 + ctx.f16.f64));
	// lfs f10,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f9,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f9.f64 = double(temp.f32);
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f10,-11152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11152);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f6,f17,f22,f6
	ctx.f6.f64 = double(float(-(ctx.f17.f64 * ctx.f22.f64 - ctx.f6.f64)));
	// fnmsubs f17,f14,f9,f8
	ctx.f17.f64 = double(float(-(ctx.f14.f64 * ctx.f9.f64 - ctx.f8.f64)));
	// lfs f9,828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 828);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f14,f9,f13
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f8,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f9,f26,f28
	ctx.f9.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmsubs f5,f5,f10,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 - ctx.f3.f64));
	// lfs f10,-3204(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -3204);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// fmadds f1,f16,f29,f1
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f29.f64 + ctx.f1.f64));
	// fmuls f3,f9,f8
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// fmuls f8,f11,f28
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// lfs f16,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f6,f4,f22,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f22.f64 + ctx.f6.f64));
	// lfs f4,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f7,f5,f0,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 + ctx.f7.f64));
	// lfs f5,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f3,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f9,f9,f15
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f15.f64));
	// fmuls f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fnmsubs f6,f2,f22,f6
	ctx.f6.f64 = double(float(-(ctx.f2.f64 * ctx.f22.f64 - ctx.f6.f64)));
	// lfs f2,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f4,f14,f12,f17
	ctx.f4.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f17.f64)));
	// lfs f17,1120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1120);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// stfs f3,1544(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1544, temp.u32);
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f3,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f11,f3,f11
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// stfs f11,1552(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1552, temp.u32);
	// lfs f11,1024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1024);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fnmsubs f11,f11,f29,f1
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f29.f64 - ctx.f1.f64)));
	// stfs f11,4288(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4288, temp.u32);
	// lfs f11,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f11.f64 = double(temp.f32);
	// lfs f3,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// lfs f1,1196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1196);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,1204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1204);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f13
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f16,920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 920);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fmadds f11,f17,f11,f4
	ctx.f11.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f4.f64));
	// stfs f11,4296(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4296, temp.u32);
	// fnmsubs f11,f5,f10,f7
	ctx.f11.f64 = double(float(-(ctx.f5.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// lfs f7,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f7.f64 = double(temp.f32);
	// stfs f11,4300(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4300, temp.u32);
	// fmadds f11,f7,f22,f6
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f22.f64 + ctx.f6.f64));
	// lfs f10,928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 928);
	ctx.f10.f64 = double(temp.f32);
	// lfs f17,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f0,f17
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f17.f64));
	// fnmsubs f11,f8,f22,f11
	ctx.f11.f64 = double(float(-(ctx.f8.f64 * ctx.f22.f64 - ctx.f11.f64)));
	// stfs f11,4292(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4292, temp.u32);
	// lfs f11,1144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1144);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f8,f11,f30
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfs f11,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f7,f11,f22
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f22.f64));
	// lfs f11,1072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1072);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f6,f11,f28
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// lfs f11,1048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1048);
	ctx.f11.f64 = double(temp.f32);
	// fadds f5,f11,f10
	ctx.f5.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// lfs f11,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,1212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1212);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f17,f17,f27
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f27.f64));
	// fmuls f4,f10,f11
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f8,f10
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// fmadds f7,f1,f29,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f7.f64));
	// lfs f1,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f11,f1
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// fmuls f5,f5,f13
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmsubs f10,f6,f10,f8
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f10.f64 - ctx.f8.f64));
	// lfs f6,1188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1188);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f8,f3,f30
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// lfs f3,936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 936);
	ctx.f3.f64 = double(temp.f32);
	// fadds f6,f6,f3
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// lfs f3,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f11,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// lfs f11,968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 968);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f14,f11,f29
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f29.f64));
	// lfs f11,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f7,f7,f11,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f11.f64 + ctx.f10.f64));
	// lfs f10,-11152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11152);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f8,f8,f10
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// lfs f10,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f15,f11,f15
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// fmuls f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// fmsubs f10,f2,f12,f5
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 - ctx.f5.f64));
	// fmuls f6,f6,f13
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fnmsubs f16,f16,f12,f10
	ctx.f16.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f10.f64)));
	// lfs f10,-11152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11152);
	ctx.f10.f64 = double(temp.f32);
	// lfs f2,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f17,f17,f10,f8
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 - ctx.f8.f64));
	// lfs f5,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f7,f4,f29,f7
	ctx.f7.f64 = double(float(-(ctx.f4.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// fmuls f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// lfs f8,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f2,f15,f28
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// lfs f4,912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 912);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f15,f11,f8
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f8,1176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1176);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f11,f26,f28
	ctx.f11.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmsubs f4,f4,f29,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 - ctx.f14.f64));
	// fmadds f6,f6,f12,f16
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 + ctx.f16.f64));
	// lfs f16,976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 976);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f7,f1,f22,f7
	ctx.f7.f64 = double(float(-(ctx.f1.f64 * ctx.f22.f64 - ctx.f7.f64)));
	// fmuls f1,f8,f11
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// lfs f11,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f26
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f26.f64));
	// fmuls f8,f28,f23
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fnmsubs f4,f16,f29,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f29.f64 - ctx.f4.f64)));
	// lfs f16,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f7,f3,f22,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 + ctx.f7.f64));
	// fmuls f3,f2,f21
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// fmuls f14,f11,f13
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f11,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f11,-3204(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -3204);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f2,f15,f11,f17
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 + ctx.f17.f64));
	// lfs f17,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// lfs f17,1032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1032);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f15,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f7,f5,f22,f7
	ctx.f7.f64 = double(float(-(ctx.f5.f64 * ctx.f22.f64 - ctx.f7.f64)));
	// lfs f5,1000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1000);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f9,f9,f21,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f21.f64 - ctx.f3.f64));
	// stfs f9,4304(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4304, temp.u32);
	// fmuls f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// fmadds f5,f5,f21,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f21.f64 + ctx.f4.f64));
	// fnmsubs f6,f14,f12,f6
	ctx.f6.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f6.f64)));
	// fnmsubs f9,f1,f11,f2
	ctx.f9.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f2.f64)));
	// stfs f9,4308(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4308, temp.u32);
	// fmadds f9,f17,f12,f6
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f6.f64));
	// stfs f9,4312(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4312, temp.u32);
	// lfs f6,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f6.f64 = double(temp.f32);
	// lfs f9,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f9,f9,f22,f7
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f22.f64 - ctx.f7.f64)));
	// lfs f7,880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 880);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f4,f7,f21,f5
	ctx.f4.f64 = double(float(-(ctx.f7.f64 * ctx.f21.f64 - ctx.f5.f64)));
	// lfs f7,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f7.f64 = double(temp.f32);
	// lfs f5,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f9,f16,f22,f9
	ctx.f9.f64 = double(float(ctx.f16.f64 * ctx.f22.f64 + ctx.f9.f64));
	// stfs f9,4316(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4316, temp.u32);
	// fmuls f9,f30,f25
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// fmuls f3,f9,f7
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f7,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f25
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// stfs f7,228(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f29.f64));
	// fmuls f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// lfs f6,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f6.f64 = double(temp.f32);
	// fadds f2,f5,f6
	ctx.f2.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// lfs f6,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f6,f8
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f17,f5,f9
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f9,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f9.f64 = double(temp.f32);
	// lfs f6,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f9,f6
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// lfs f8,1440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1440);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 952);
	ctx.f9.f64 = double(temp.f32);
	// fadds f14,f9,f8
	ctx.f14.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// lfs f9,1052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1052);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// stfs f9,80(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f15,f7,f29
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// fmuls f9,f28,f25
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmadds f2,f2,f9,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f1.f64));
	// lfs f7,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f7.f64 = double(temp.f32);
	// lfs f9,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f3,f17,f29,f3
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f29.f64 - ctx.f3.f64));
	// fmuls f1,f9,f7
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f9,1028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1028);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f17,f16,f22,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f22.f64 - ctx.f15.f64));
	// fadds f16,f14,f9
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f9.f64));
	// lfs f9,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f15,f9,f6
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// lfs f6,812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 812);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f14,f6,f25
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// fmuls f6,f31,f23
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// fmadds f3,f2,f29,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f29.f64 + ctx.f3.f64));
	// lfs f2,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f2,f2,f22,f17
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f22.f64 - ctx.f17.f64)));
	// fmuls f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// fmadds f7,f16,f22,f3
	ctx.f7.f64 = double(float(ctx.f16.f64 * ctx.f22.f64 + ctx.f3.f64));
	// lfs f16,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f3,f1,f22,f2
	ctx.f3.f64 = double(float(-(ctx.f1.f64 * ctx.f22.f64 - ctx.f2.f64)));
	// lfs f2,896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 896);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f8,f2
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f2.f64));
	// lfs f1,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f8,f28,f18
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// fmuls f1,f8,f1
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// lfs f8,1080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1080);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f17,f8,f9
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f8,888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 888);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f8,f8,f21,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f21.f64 + ctx.f4.f64));
	// lfs f4,1416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1416);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f7,f4,f16,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f16.f64 + ctx.f7.f64));
	// lfs f16,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f4,f15,f22,f3
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f22.f64 + ctx.f3.f64));
	// lfs f15,904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 904);
	ctx.f15.f64 = double(temp.f32);
	// lfs f3,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f16.f64));
	// lfs f16,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f9,f16
	ctx.f16.f64 = double(float(ctx.f9.f64 + ctx.f16.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// stfs f9,1564(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1564, temp.u32);
	// lfs f9,960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 960);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f15,f15,f29,f8
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f29.f64 + ctx.f8.f64));
	// lfs f8,1036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1036);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f8,f8,f22,f7
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f22.f64 - ctx.f7.f64)));
	// stfs f8,80(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f7,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f8,f31,f28
	ctx.f8.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fnmsubs f4,f14,f7,f4
	ctx.f4.f64 = double(float(-(ctx.f14.f64 * ctx.f7.f64 - ctx.f4.f64)));
	// fmuls f3,f3,f18
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fnmsubs f9,f9,f21,f15
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f21.f64 - ctx.f15.f64)));
	// stfs f9,4320(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4320, temp.u32);
	// fmuls f7,f8,f0
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// stfs f7,136(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmadds f5,f5,f22,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 + ctx.f4.f64));
	// fmuls f4,f16,f27
	ctx.f4.f64 = double(float(ctx.f16.f64 * ctx.f27.f64));
	// lfs f16,1432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1432);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f9,f6,f29,f15
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f29.f64 + ctx.f15.f64));
	// lfs f6,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// stfs f6,1048(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1048, temp.u32);
	// fnmsubs f9,f16,f22,f9
	ctx.f9.f64 = double(float(-(ctx.f16.f64 * ctx.f22.f64 - ctx.f9.f64)));
	// lfs f16,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f5,f2,f16,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f16.f64 + ctx.f5.f64));
	// lfs f2,1016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1016);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f9,f1,f29,f9
	ctx.f9.f64 = double(float(-(ctx.f1.f64 * ctx.f29.f64 - ctx.f9.f64)));
	// fnmsubs f5,f17,f22,f5
	ctx.f5.f64 = double(float(-(ctx.f17.f64 * ctx.f22.f64 - ctx.f5.f64)));
	// fnmsubs f9,f2,f22,f9
	ctx.f9.f64 = double(float(-(ctx.f2.f64 * ctx.f22.f64 - ctx.f9.f64)));
	// fmadds f5,f3,f29,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f29.f64 + ctx.f5.f64));
	// stfs f5,4324(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4324, temp.u32);
	// lfs f5,1424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1424);
	ctx.f5.f64 = double(temp.f32);
	// lfs f3,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f9,f5,f22,f9
	ctx.f9.f64 = double(float(-(ctx.f5.f64 * ctx.f22.f64 - ctx.f9.f64)));
	// stfs f9,4328(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4328, temp.u32);
	// fmuls f9,f31,f30
	ctx.f9.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// lfs f5,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f9,f5
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// lfs f9,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f9.f64 = double(temp.f32);
	// fadds f3,f9,f3
	ctx.f3.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// lfs f9,1564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1564);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f2,f9,f26
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// lfs f9,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f1,f9,f0
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// stfs f1,332(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f1,1400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1400);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lis r6,-32254
	ctx.r6.s64 = -2113798144;
	// fmuls f16,f9,f27
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// lfs f9,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f8,f9
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f9,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f15,f0,f9
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f9,f30,f28
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// lfs f17,1408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1408);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// fmuls f6,f6,f26
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// fmuls f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// fmadds f7,f3,f7,f5
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f7.f64 + ctx.f5.f64));
	// lfs f3,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f5,f1,f11
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// lfs f1,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f1,19620(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 19620);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,376(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fmuls f8,f8,f12
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmuls f9,f9,f14
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f14.f64));
	// lfs f14,1352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1352);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f13
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// fmuls f1,f17,f10
	ctx.f1.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// lfs f17,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f31,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f31.f64 + ctx.f16.f64));
	// fmuls f16,f15,f31
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// lfs f15,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f7,f7,f12,f2
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + ctx.f2.f64));
	// fmuls f2,f9,f0
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f9,f30,f28
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmsubs f5,f14,f10,f5
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 - ctx.f5.f64));
	// lfs f14,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f8,f17,f11,f8
	ctx.f8.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f8.f64));
	// lfs f17,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f7,f4,f11,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 - ctx.f7.f64));
	// fmuls f4,f16,f11
	ctx.f4.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// fmuls f15,f15,f9
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f9.f64));
	// lfs f9,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f14,f14,f9
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f9.f64));
	// fnmsubs f7,f6,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// lfs f6,1180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1180);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f22
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// fmsubs f8,f8,f0,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f4.f64));
	// fmuls f16,f15,f0
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f2,f2,f12,f7
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f12.f64 - ctx.f7.f64)));
	// lfs f7,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f7.f64 = double(temp.f32);
	// lfs f9,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f3,f3,f9,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 + ctx.f1.f64));
	// lfs f9,1392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1392);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f1,f9,f13
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f9,f30,f28
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fnmsubs f3,f1,f10,f3
	ctx.f3.f64 = double(float(-(ctx.f1.f64 * ctx.f10.f64 - ctx.f3.f64)));
	// lfs f1,1368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1368);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f17,f17,f9
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// fmuls f9,f31,f30
	ctx.f9.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fmuls f4,f17,f0
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fmuls f9,f9,f15
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f15.f64));
	// lfs f15,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f5,f14,f15,f5
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f15.f64 + ctx.f5.f64));
	// lfs f15,1376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1376);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fmadds f3,f1,f10,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f3.f64));
	// fmuls f17,f9,f0
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f9,1384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1384);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f5,f15,f10,f5
	ctx.f5.f64 = double(float(-(ctx.f15.f64 * ctx.f10.f64 - ctx.f5.f64)));
	// fmuls f15,f9,f13
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f9,1360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1360);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f6,f9,f7,f6
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f7.f64 - ctx.f6.f64));
	// lfs f9,1324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1324);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f2,f16,f12,f2
	ctx.f2.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f1,f9,f13
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f9,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f10,f15,f10,f5
	ctx.f10.f64 = double(float(ctx.f15.f64 * ctx.f10.f64 + ctx.f5.f64));
	// stfs f10,4336(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4336, temp.u32);
	// lfs f10,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f8,f4,f12,f8
	ctx.f8.f64 = double(float(-(ctx.f4.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// fmuls f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// stfs f10,4340(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4340, temp.u32);
	// fmuls f4,f9,f26
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// lfs f6,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f6.f64 = double(temp.f32);
	// lfs f9,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f9.f64 = double(temp.f32);
	// lfs f15,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f9,f0
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// stfs f16,520(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// fmadds f10,f17,f12,f2
	ctx.f10.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f2.f64));
	// stfs f10,4332(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4332, temp.u32);
	// fnmsubs f10,f1,f11,f3
	ctx.f10.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f3.f64)));
	// stfs f10,4344(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4344, temp.u32);
	// fmuls f10,f28,f18
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfs f17,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f1,f9,f26
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// fmuls f9,f9,f15
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f15.f64));
	// lfs f15,1340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1340);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f5,f4,f11,f8
	ctx.f5.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 - ctx.f8.f64)));
	// lfs f8,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f10,f8
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// fmuls f8,f28,f19
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fmuls f9,f9,f22
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f22.f64));
	// fmuls f3,f6,f8
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// lfs f6,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f6.f64 = double(temp.f32);
	// lfs f8,1528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1528);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f2,f8,f6
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// fmuls f8,f4,f29
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// lfs f4,1500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1500);
	ctx.f4.f64 = double(temp.f32);
	// fmsubs f4,f4,f22,f8
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f22.f64 - ctx.f8.f64));
	// fmuls f8,f30,f28
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fnmsubs f7,f15,f7,f4
	ctx.f7.f64 = double(float(-(ctx.f15.f64 * ctx.f7.f64 - ctx.f4.f64)));
	// lfs f4,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f17,f17,f8
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f8.f64));
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f8,f30,f18
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f18.f64));
	// fmadds f4,f4,f31,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64 + ctx.f1.f64));
	// fnmsubs f7,f3,f29,f7
	ctx.f7.f64 = double(float(-(ctx.f3.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// lfs f3,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f1,f17,f12
	ctx.f1.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f17,1072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1072);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f8,f6
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// lfs f8,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f28,f25
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f17,f17,f25
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// fmuls f3,f0,f3
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// fmadds f4,f4,f11,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 + ctx.f1.f64));
	// lfs f1,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f10,f1
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f1.f64));
	// lfs f10,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f6,f8
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f8,f15,f8
	ctx.f8.f64 = double(float(ctx.f15.f64 * ctx.f8.f64));
	// lfs f15,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f10,f15
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f15.f64));
	// lfs f10,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f14,f10,f14
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f14.f64));
	// lfs f10,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
	// fmsubs f9,f17,f10,f9
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 - ctx.f9.f64));
	// lfs f10,1596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1596);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f7,f10,f22,f7
	ctx.f7.f64 = double(float(-(ctx.f10.f64 * ctx.f22.f64 - ctx.f7.f64)));
	// lfs f10,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f25
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// lfs f17,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f5,f4,f0,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 + ctx.f5.f64));
	// fmuls f4,f3,f31
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// lfs f3,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f9,f15,f22,f9
	ctx.f9.f64 = double(float(-(ctx.f15.f64 * ctx.f22.f64 - ctx.f9.f64)));
	// fnmsubs f7,f2,f29,f7
	ctx.f7.f64 = double(float(-(ctx.f2.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// fmuls f17,f10,f17
	ctx.f17.f64 = double(float(ctx.f10.f64 * ctx.f17.f64));
	// fmuls f10,f30,f18
	ctx.f10.f64 = double(float(ctx.f30.f64 * ctx.f18.f64));
	// fmadds f2,f14,f23,f17
	ctx.f2.f64 = double(float(ctx.f14.f64 * ctx.f23.f64 + ctx.f17.f64));
	// fmuls f10,f10,f3
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f3,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// fnmsubs f12,f8,f12,f5
	ctx.f12.f64 = double(float(-(ctx.f8.f64 * ctx.f12.f64 - ctx.f5.f64)));
	// lfs f5,1508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1508);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f7,f5,f22,f7
	ctx.f7.f64 = double(float(-(ctx.f5.f64 * ctx.f22.f64 - ctx.f7.f64)));
	// lfs f5,1612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1612);
	ctx.f5.f64 = double(temp.f32);
	// lfs f8,812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 812);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f9,f2,f29,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f29.f64 + ctx.f9.f64));
	// fmuls f8,f8,f18
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f18.f64));
	// lfs f2,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f2.f64 = double(temp.f32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f14,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f14.f64 = double(temp.f32);
	// lis r7,-32239
	ctx.r7.s64 = -2112815104;
	// fnmsubs f12,f4,f11,f12
	ctx.f12.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 - ctx.f12.f64)));
	// fmadds f7,f5,f22,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 + ctx.f7.f64));
	// lfs f5,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f5,f8,f5,f9
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f5.f64 + ctx.f9.f64));
	// lfs f9,868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 868);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f12,f3,f11,f12
	ctx.f12.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 - ctx.f12.f64)));
	// stfs f12,4348(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4348, temp.u32);
	// lfs f12,1692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1692);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f12,f12,f22,f7
	ctx.f12.f64 = double(float(-(ctx.f12.f64 * ctx.f22.f64 - ctx.f7.f64)));
	// lfs f11,1516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1516);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f7,f13,f9
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f9,864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 864);
	ctx.f9.f64 = double(temp.f32);
	// lfs f3,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f12,f16,f29,f12
	ctx.f12.f64 = double(float(-(ctx.f16.f64 * ctx.f29.f64 - ctx.f12.f64)));
	// fmadds f12,f6,f29,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f29.f64 + ctx.f12.f64));
	// fmuls f6,f13,f9
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// fmadds f12,f11,f22,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f22.f64 + ctx.f12.f64));
	// lfs f11,1344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1344);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f12,f1,f29,f12
	ctx.f12.f64 = double(float(-(ctx.f1.f64 * ctx.f29.f64 - ctx.f12.f64)));
	// fmadds f12,f10,f29,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f29.f64 + ctx.f12.f64));
	// fmadds f12,f11,f22,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f22.f64 + ctx.f12.f64));
	// stfs f12,4352(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4352, temp.u32);
	// lfs f12,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f13,f12
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f12,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f13,f12
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f12,876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f8,f13,f12
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f12,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f12,848(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 848, temp.u32);
	// fmuls f9,f11,f20
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f20.f64));
	// lfs f11,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// stfs f11,544(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// fmuls f11,f31,f25
	ctx.f11.f64 = double(float(ctx.f31.f64 * ctx.f25.f64));
	// fmsubs f1,f10,f20,f9
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f20.f64 - ctx.f9.f64));
	// lfs f10,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// stfs f11,188(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f11,992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 992);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f4,f13,f11
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f11,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f3,f11,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// lfs f11,1088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1088);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f11,f2
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f2.f64));
	// lfs f11,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f18,f11,f10
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// fmuls f11,f28,f25
	ctx.f11.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f17,f11,f9
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f11,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f11.f64 = double(temp.f32);
	// lfs f9,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f16,f11,f9
	ctx.f16.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f11,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f1,f8,f11,f1
	ctx.f1.f64 = double(float(-(ctx.f8.f64 * ctx.f11.f64 - ctx.f1.f64)));
	// fmuls f8,f28,f23
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fnmsubs f5,f16,f22,f5
	ctx.f5.f64 = double(float(-(ctx.f16.f64 * ctx.f22.f64 - ctx.f5.f64)));
	// fmadds f7,f7,f11,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f11.f64 + ctx.f1.f64));
	// lfs f1,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f18,f15,f8,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f8.f64 + ctx.f18.f64));
	// lfs f15,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f8,f31,f23
	ctx.f8.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// fmuls f9,f1,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// fmuls f1,f18,f0
	ctx.f1.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fmuls f8,f8,f15
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f15.f64));
	// lfs f15,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// fnmsubs f11,f6,f11,f7
	ctx.f11.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// lfs f7,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f5,f15,f22,f5
	ctx.f5.f64 = double(float(-(ctx.f15.f64 * ctx.f22.f64 - ctx.f5.f64)));
	// fmadds f9,f7,f6,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f6.f64 + ctx.f9.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f10,f12
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f6,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f14.f64));
	// fmuls f6,f6,f12
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// lfs f14,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f14.f64 = double(temp.f32);
	// lfs f12,1492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1492);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f12,f12,f14
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f14.f64));
	// stfs f12,524(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// lfs f18,944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 944);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f4,f4,f12,f11
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f11.f64));
	// lfs f11,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f18,f13,f18
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f18.f64));
	// fmuls f14,f11,f12
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f11,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmadds f9,f9,f22,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f22.f64 + ctx.f5.f64));
	// stfs f9,4356(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4356, temp.u32);
	// lfs f5,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f9,1484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1484);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f9,f9,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// stfs f9,508(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// lfs f9,1128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1128);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// stfs f9,748(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 748, temp.u32);
	// lfs f9,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f9.f64 = double(temp.f32);
	// lfs f5,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f5.f64 = double(temp.f32);
	// lfs f11,-29780(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29780);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f5,f5,f9
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// fnmsubs f9,f3,f11,f4
	ctx.f9.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 - ctx.f4.f64)));
	// stfs f12,136(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f12,-29784(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -29784);
	ctx.f12.f64 = double(temp.f32);
	// lfs f7,1024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1024);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f13,f7
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fmadds f9,f6,f12,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 + ctx.f9.f64));
	// fmadds f11,f2,f11,f9
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f9.f64));
	// fnmsubs f11,f14,f12,f11
	ctx.f11.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f11.f64)));
	// lfs f4,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f11,f15,f12,f11
	ctx.f11.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f11.f64));
	// fmuls f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// fmsubs f6,f1,f20,f4
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f20.f64 - ctx.f4.f64));
	// fnmsubs f9,f17,f12,f6
	ctx.f9.f64 = double(float(-(ctx.f17.f64 * ctx.f12.f64 - ctx.f6.f64)));
	// lfs f6,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f6.f64 = double(temp.f32);
	// lfs f17,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f9,f8,f12,f9
	ctx.f9.f64 = double(float(-(ctx.f8.f64 * ctx.f12.f64 - ctx.f9.f64)));
	// fmadds f8,f16,f12,f9
	ctx.f8.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f9.f64));
	// lfs f9,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f11,f9,f12,f11
	ctx.f11.f64 = double(float(-(ctx.f9.f64 * ctx.f12.f64 - ctx.f11.f64)));
	// lfs f9,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f5,f5,f12,f8
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// fmadds f11,f18,f20,f11
	ctx.f11.f64 = double(float(ctx.f18.f64 * ctx.f20.f64 + ctx.f11.f64));
	// lfs f18,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f8,f31,f28
	ctx.f8.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fnmsubs f11,f7,f20,f11
	ctx.f11.f64 = double(float(-(ctx.f7.f64 * ctx.f20.f64 - ctx.f11.f64)));
	// stfs f11,4360(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4360, temp.u32);
	// fmuls f11,f30,f25
	ctx.f11.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lfs f7,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f4,f7,f30
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// lfs f7,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f7,f28
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// lfs f7,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// fmuls f2,f11,f0
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f11,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f8,f11
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// fmuls f11,f27,f10
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fmuls f11,f11,f21
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f21.f64));
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lis r8,-32255
	ctx.r8.s64 = -2113863680;
	// fmuls f17,f7,f28
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// lfs f7,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f16,f6,f28
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fmuls f6,f7,f28
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// lfs f7,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f5,f2,f12,f5
	ctx.f5.f64 = double(float(-(ctx.f2.f64 * ctx.f12.f64 - ctx.f5.f64)));
	// fmsubs f2,f1,f7,f11
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f7.f64 - ctx.f11.f64));
	// lfs f11,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f11,f30
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfs f11,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f11.f64 = double(temp.f32);
	// fadds f15,f11,f9
	ctx.f15.f64 = double(float(ctx.f11.f64 + ctx.f9.f64));
	// lfs f11,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f9,f30,f28
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmadds f18,f18,f30,f6
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 + ctx.f6.f64));
	// lfs f6,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f5,f4,f6,f5
	ctx.f5.f64 = double(float(-(ctx.f4.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// fmuls f4,f11,f9
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// fmuls f11,f26,f10
	ctx.f11.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// fmuls f18,f18,f0
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fnmsubs f6,f3,f6,f5
	ctx.f6.f64 = double(float(-(ctx.f3.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// fnmsubs f2,f11,f21,f2
	ctx.f2.f64 = double(float(-(ctx.f11.f64 * ctx.f21.f64 - ctx.f2.f64)));
	// lfs f11,1152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1152);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f14,f11,f0
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f11,f31,f30
	ctx.f11.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fmuls f3,f14,f30
	ctx.f3.f64 = double(float(ctx.f14.f64 * ctx.f30.f64));
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f5,f15,f11,f4
	ctx.f5.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 + ctx.f4.f64));
	// lfs f11,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f4,f9,f11,f2
	ctx.f4.f64 = double(float(-(ctx.f9.f64 * ctx.f11.f64 - ctx.f2.f64)));
	// lfs f11,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f19
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// stfs f11,596(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// fmadds f5,f8,f14,f5
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f14.f64 + ctx.f5.f64));
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f9,f9,f14,f4
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f14.f64 - ctx.f4.f64)));
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f2,f11,f0
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f11,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f19
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// stfs f11,228(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmadds f5,f5,f7,f9
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 + ctx.f9.f64));
	// lfs f9,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f4,f2,f28
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// lfs f2,1208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1208);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f15,f11,f0
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f11,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f6,f17,f11,f6
	ctx.f6.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f6.f64));
	// lfs f17,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f10,f17
	ctx.f17.f64 = double(float(ctx.f10.f64 + ctx.f17.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// fnmsubs f6,f16,f11,f6
	ctx.f6.f64 = double(float(-(ctx.f16.f64 * ctx.f11.f64 - ctx.f6.f64)));
	// lfs f16,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f9
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// fmuls f9,f27,f30
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmadds f5,f17,f24,f5
	ctx.f5.f64 = double(float(ctx.f17.f64 * ctx.f24.f64 + ctx.f5.f64));
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// fnmsubs f6,f1,f11,f6
	ctx.f6.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f6.f64)));
	// fmuls f14,f9,f14
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f14.f64));
	// lfs f9,-18724(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -18724);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,276(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fmuls f1,f16,f9
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// fmadds f18,f18,f11,f6
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 + ctx.f6.f64));
	// lfs f6,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f9,f27,f6
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fnmsubs f3,f3,f20,f18
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f20.f64 - ctx.f18.f64)));
	// fnmsubs f5,f9,f21,f5
	ctx.f5.f64 = double(float(-(ctx.f9.f64 * ctx.f21.f64 - ctx.f5.f64)));
	// fmuls f9,f26,f6
	ctx.f9.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// fnmsubs f9,f9,f21,f5
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f21.f64 - ctx.f5.f64)));
	// stfs f9,4368(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4368, temp.u32);
	// fmadds f9,f4,f20,f3
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f20.f64 + ctx.f3.f64));
	// fnmsubs f9,f15,f20,f9
	ctx.f9.f64 = double(float(-(ctx.f15.f64 * ctx.f20.f64 - ctx.f9.f64)));
	// fmadds f9,f2,f20,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f20.f64 + ctx.f9.f64));
	// stfs f9,4364(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4364, temp.u32);
	// lfs f9,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f6,f9,f30
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// lfs f9,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f5,f24,f9
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// lfs f9,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f4,f9,f8
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// lfs f9,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f3,f9,f30
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// lfs f15,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f9,f31,f30
	ctx.f9.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// lfs f2,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f18,f6,f28,f5
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f28.f64 + ctx.f5.f64));
	// lfs f6,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f24,f30
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// fmuls f17,f6,f9
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// fmuls f2,f2,f9
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// lfs f9,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f5,f5,f15
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f15.f64));
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f6,f26,f28
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmsubs f1,f14,f9,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 * ctx.f9.f64 - ctx.f1.f64));
	// lfs f14,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f18,f24,f15,f18
	ctx.f18.f64 = double(float(-(ctx.f24.f64 * ctx.f15.f64 - ctx.f18.f64)));
	// lfs f15,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f15.f64));
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// lfs f9,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f17,f14,f8,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f8.f64 + ctx.f17.f64));
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f8,f24,f30
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// fmuls f16,f6,f9
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// fnmsubs f4,f4,f7,f18
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f7.f64 - ctx.f18.f64)));
	// fmuls f14,f8,f14
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f14.f64));
	// lfs f8,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f1,f16,f8,f1
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f8.f64 + ctx.f1.f64));
	// lfs f16,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f8,f24,f28
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// fnmsubs f4,f3,f28,f4
	ctx.f4.f64 = double(float(-(ctx.f3.f64 * ctx.f28.f64 - ctx.f4.f64)));
	// lfs f3,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f1,f14,f29,f1
	ctx.f1.f64 = double(float(-(ctx.f14.f64 * ctx.f29.f64 - ctx.f1.f64)));
	// lfs f14,984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 984);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f5,f16,f8,f5
	ctx.f5.f64 = double(float(ctx.f16.f64 * ctx.f8.f64 + ctx.f5.f64));
	// lfs f8,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f18,f15,f8
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f8.f64));
	// fmuls f8,f27,f28
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// fnmsubs f4,f2,f7,f4
	ctx.f4.f64 = double(float(-(ctx.f2.f64 * ctx.f7.f64 - ctx.f4.f64)));
	// fmadds f5,f5,f29,f18
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f29.f64 + ctx.f18.f64));
	// lfs f18,936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 936);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f8,f9
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f8,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f15,f6,f8
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f8,f27,f30
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmadds f7,f17,f7,f4
	ctx.f7.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f4.f64));
	// fmadds f1,f16,f22,f1
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f22.f64 + ctx.f1.f64));
	// fmuls f14,f8,f14
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f14.f64));
	// fmuls f8,f26,f30
	ctx.f8.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// fmadds f16,f15,f30,f14
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f30.f64 + ctx.f14.f64));
	// fmuls f3,f3,f8
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// lfs f8,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f6,f8
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// lfs f8,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f8,f8,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmsubs f5,f3,f22,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 - ctx.f5.f64));
	// lfs f3,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f3.f64 = double(temp.f32);
	// fadds f18,f18,f8
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f8.f64));
	// fmuls f8,f24,f28
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// fmuls f2,f9,f8
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// fmuls f8,f27,f28
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// fnmsubs f4,f2,f29,f1
	ctx.f4.f64 = double(float(-(ctx.f2.f64 * ctx.f29.f64 - ctx.f1.f64)));
	// lfs f2,984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 984);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f6,f8,f22,f6
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f22.f64 + ctx.f6.f64));
	// fmuls f8,f26,f30
	ctx.f8.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// fmuls f1,f16,f21
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f21.f64));
	// fmuls f3,f3,f8
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// fmuls f8,f24,f30
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// fmuls f2,f8,f2
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f2.f64));
	// lfs f8,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f6,f6,f8,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f8.f64 + ctx.f5.f64));
	// lfs f5,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f8,f27,f30
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmuls f5,f5,f8
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// lfs f8,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f8,f8,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f26.f64));
	// fmadds f17,f8,f21,f7
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f21.f64 + ctx.f7.f64));
	// fmadds f8,f3,f22,f4
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 + ctx.f4.f64));
	// stfs f8,4372(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4372, temp.u32);
	// lfs f8,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f8,f2,f8,f1
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f8.f64 - ctx.f1.f64));
	// stfs f8,4376(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4376, temp.u32);
	// lfs f8,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f8,f5,f8,f6
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f8.f64 + ctx.f6.f64));
	// stfs f8,4380(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4380, temp.u32);
	// lfs f8,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f26,f8
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// lfs f3,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f7,f7,f21,f17
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f21.f64 - ctx.f17.f64)));
	// fmadds f6,f18,f21,f7
	ctx.f6.f64 = double(float(ctx.f18.f64 * ctx.f21.f64 + ctx.f7.f64));
	// fmuls f7,f27,f8
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// fnmsubs f7,f7,f21,f6
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f21.f64 - ctx.f6.f64)));
	// lfs f6,928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 928);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f2,f6,f21,f7
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f21.f64 + ctx.f7.f64));
	// lfs f7,1008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1008);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f7,f0
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// stfs f6,80(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f7,f30,f3
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f3.f64));
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fmuls f5,f7,f4
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f4.f64));
	// lfs f7,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f23
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// fmuls f16,f5,f12
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f5,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f0,f7
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// lfs f7,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// stfs f7,460(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// lfs f7,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f14,f0,f5
	ctx.f14.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// fmuls f7,f7,f23
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// fadds f5,f10,f5
	ctx.f5.f64 = double(float(ctx.f10.f64 + ctx.f5.f64));
	// lfs f10,1528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1528);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f10,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// lfs f10,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmuls f18,f7,f28
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// lfs f7,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f17,f7,f0
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f7,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f0,f7
	ctx.f7.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// stfs f7,724(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 724, temp.u32);
	// lfs f7,1052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1052);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f15,f7,f0
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f7,f28,f19
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fmuls f1,f1,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f20.f64));
	// fmadds f18,f18,f20,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f20.f64 + ctx.f16.f64));
	// fmuls f16,f15,f28
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// lfs f15,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f15.f64));
	// lfs f14,1604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1604);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f28
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f28.f64));
	// fmuls f7,f17,f7
	ctx.f7.f64 = double(float(ctx.f17.f64 * ctx.f7.f64));
	// lfs f17,1044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1044);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f17,392(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f17,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f1,f18,f0,f1
	ctx.f1.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 - ctx.f1.f64));
	// fmuls f18,f13,f10
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// stfs f18,716(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 716, temp.u32);
	// lfs f18,1636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1636);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmuls f17,f0,f17
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f17.f64));
	// fmadds f18,f18,f30,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 + ctx.f14.f64));
	// fnmsubs f7,f7,f20,f1
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f20.f64 - ctx.f1.f64)));
	// lfs f1,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f5,f1,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 + ctx.f4.f64));
	// lfs f1,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f1.f64 = double(temp.f32);
	// lfs f4,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f0,f4
	ctx.f4.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// fmuls f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// fmuls f1,f18,f1
	ctx.f1.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// fmuls f18,f10,f20
	ctx.f18.f64 = double(float(ctx.f10.f64 * ctx.f20.f64));
	// lfs f10,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f14,f10,f30
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmuls f10,f28,f3
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f3.f64));
	// lfs f3,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f10,f10,f3,f5
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f3.f64 + ctx.f5.f64));
	// fmuls f5,f4,f30
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fnmsubs f7,f6,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// lfs f6,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f4,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// lfs f4,920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 920);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f4,f4,f21,f2
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f21.f64 - ctx.f2.f64)));
	// lfs f2,912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 912);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 976);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f10,f10,f12,f18
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + ctx.f18.f64));
	// fadds f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f2.f64));
	// lfs f2,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// lfs f18,1032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1032);
	ctx.f18.f64 = double(temp.f32);
	// lis r8,-32239
	ctx.r8.s64 = -2112815104;
	// fnmsubs f7,f14,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f14.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// fnmsubs f4,f18,f21,f4
	ctx.f4.f64 = double(float(-(ctx.f18.f64 * ctx.f21.f64 - ctx.f4.f64)));
	// stfs f4,4384(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4384, temp.u32);
	// fmuls f4,f3,f13
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfs f3,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f23
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// fmadds f7,f16,f11,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 + ctx.f7.f64));
	// fmuls f3,f3,f12
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// fnmsubs f7,f15,f20,f7
	ctx.f7.f64 = double(float(-(ctx.f15.f64 * ctx.f20.f64 - ctx.f7.f64)));
	// lfs f15,1652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1652);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f4,f4,f20,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f20.f64 - ctx.f3.f64));
	// fmadds f7,f17,f11,f7
	ctx.f7.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f7.f64));
	// fnmsubs f7,f6,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// lfs f6,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f7,f1,f6,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f6.f64 + ctx.f7.f64));
	// lfs f6,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f7,f2,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// fmadds f10,f10,f0,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f7.f64));
	// lfs f7,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f10,f5,f20,f10
	ctx.f10.f64 = double(float(-(ctx.f5.f64 * ctx.f20.f64 - ctx.f10.f64)));
	// lfs f5,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f10,f8,f12,f10
	ctx.f10.f64 = double(float(-(ctx.f8.f64 * ctx.f12.f64 - ctx.f10.f64)));
	// lfs f8,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f2,f8,f11
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// lfs f8,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f1,f8,f5
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// lfs f8,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f21,f8,f7
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// lfs f8,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f7,f8
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f8,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f18,f6,f8
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f17,f7,f8
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// stfs f10,4388(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4388, temp.u32);
	// lfs f10,-29788(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -29788);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f2,f8,f10,f2
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f10.f64 + ctx.f2.f64));
	// lfs f8,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f16,f8,f25
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// lfs f8,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f6,f8
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// lfs f8,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmadds f4,f3,f12,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f4.f64));
	// fmuls f3,f18,f13
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// lfs f18,904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 904);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f8,f15
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f15.f64));
	// stfs f15,248(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f15,968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 968);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// lfs f15,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f7,f15
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f15.f64));
	// lfs f7,896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 896);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f21,f21,f0
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f4,f3,f12,f4
	ctx.f4.f64 = double(float(-(ctx.f3.f64 * ctx.f12.f64 - ctx.f4.f64)));
	// fmsubs f3,f2,f25,f1
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f25.f64 - ctx.f1.f64));
	// lfs f1,1172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1172);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f8,f7
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fmuls f7,f13,f23
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// fmuls f1,f1,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// fmadds f7,f18,f20,f17
	ctx.f7.f64 = double(float(ctx.f18.f64 * ctx.f20.f64 + ctx.f17.f64));
	// fmadds f3,f21,f20,f3
	ctx.f3.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f3.f64));
	// lfs f21,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f4,f7,f13,f4
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 + ctx.f4.f64));
	// lfs f7,1000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1000);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f18,f15,f0
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f14,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// lfs f15,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f21,f7,f13
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f7,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// lfs f17,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f7,f0
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f7,888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 888);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f13
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// stfs f7,136(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f7,-29780(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29780);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fnmsubs f3,f16,f11,f3
	ctx.f3.f64 = double(float(-(ctx.f16.f64 * ctx.f11.f64 - ctx.f3.f64)));
	// lfs f16,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f4,f1,f7,f4
	ctx.f4.f64 = double(float(-(ctx.f1.f64 * ctx.f7.f64 - ctx.f4.f64)));
	// lfs f7,960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 960);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f7,f13
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f7,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f5,f7,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// lfs f7,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f16,f7,f16
	ctx.f16.f64 = double(float(ctx.f7.f64 * ctx.f16.f64));
	// lfs f7,880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 880);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f19.f64));
	// fmuls f17,f17,f23
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f23.f64));
	// fnmsubs f6,f6,f12,f3
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f12.f64 - ctx.f3.f64)));
	// fmuls f3,f7,f13
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f7,-29780(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29780);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f7,f15,f7,f4
	ctx.f7.f64 = double(float(-(ctx.f15.f64 * ctx.f7.f64 - ctx.f4.f64)));
	// lfs f4,1096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1096);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f8,f4
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// lfs f8,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f8,f8,f23
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f23.f64));
	// fmadds f12,f18,f12,f6
	ctx.f12.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 + ctx.f6.f64));
	// fnmsubs f7,f21,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f21.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fmadds f12,f2,f11,f12
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f12.f64));
	// lfs f2,1036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1036);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f13
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmadds f12,f17,f11,f12
	ctx.f12.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f12.f64));
	// lfs f17,1600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1600);
	ctx.f17.f64 = double(temp.f32);
	// lfs f6,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f7,f6,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// lfs f6,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f12,f8,f6,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f6.f64 + ctx.f12.f64));
	// lfs f8,1624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1624);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f7,f1,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// lfs f1,1616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1616);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f0,f3,f0,f7
	ctx.f0.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// stfs f0,4392(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4392, temp.u32);
	// fnmsubs f0,f19,f11,f12
	ctx.f0.f64 = double(float(-(ctx.f19.f64 * ctx.f11.f64 - ctx.f12.f64)));
	// lfs f3,952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 952);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f13
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fnmsubs f0,f5,f11,f0
	ctx.f0.f64 = double(float(-(ctx.f5.f64 * ctx.f11.f64 - ctx.f0.f64)));
	// lfs f5,872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 872);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f7,f16,f20,f0
	ctx.f7.f64 = double(float(-(ctx.f16.f64 * ctx.f20.f64 - ctx.f0.f64)));
	// lfs f0,1016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1016);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f0,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f6,f0,f8
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f8,1088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1088);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f5,f8,f5
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// fmuls f1,f0,f1
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// fmuls f10,f12,f10
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f12,1608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1608);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f21,f0,f12
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfs f12,1028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1028);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f19,f12,f13
	ctx.f19.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,1440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1440);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f18,f12,f13
	ctx.f18.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f17,f12,f17
	ctx.f17.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// fmsubs f10,f6,f20,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f20.f64 - ctx.f10.f64));
	// lfs f6,1592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1592);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f0,f6
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// lfs f0,1432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1432);
	ctx.f0.f64 = double(temp.f32);
	// lis r5,-32239
	ctx.r5.s64 = -2112815104;
	// fmuls f16,f0,f13
	ctx.f16.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f0,1424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1424);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f15,f0,f13
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f0,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f14,1584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1584);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f12,f14
	ctx.f14.f64 = double(float(ctx.f12.f64 * ctx.f14.f64));
	// fnmsubs f12,f5,f20,f10
	ctx.f12.f64 = double(float(-(ctx.f5.f64 * ctx.f20.f64 - ctx.f10.f64)));
	// lfs f10,1676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1676);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// stfs f10,672(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 672, temp.u32);
	// lfs f10,1416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1416);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f20,f10,f13
	ctx.f20.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f10.f64 = double(temp.f32);
	// lfs f5,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmuls f0,f0,f31
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f0,f27,f23
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// fnmsubs f12,f3,f11,f12
	ctx.f12.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 - ctx.f12.f64)));
	// lfs f3,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fmuls f5,f0,f22
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f22.f64));
	// fmuls f0,f24,f25
	ctx.f0.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// fmuls f22,f10,f30
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmadds f12,f2,f11,f12
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f12.f64));
	// fmuls f10,f9,f0
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f0,1576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1576);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f8,f0
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// stfs f0,136(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f0,f26,f25
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmuls f11,f0,f9
	ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// lfs f9,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f0,f26,f23
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// fmadds f9,f0,f9,f5
	ctx.f9.f64 = double(float(ctx.f0.f64 * ctx.f9.f64 + ctx.f5.f64));
	// lfs f0,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f8,f4,f0
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// lfs f5,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f5.f64 = double(temp.f32);
	// lfs f0,1700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1700);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f4,f5,f0
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// lfs f5,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f5.f64 = double(temp.f32);
	// lfs f0,1568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1568);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f5,f0
	ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// lfs f5,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f5.f64 = double(temp.f32);
	// stfs f0,228(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmr f0,f5
	ctx.f0.f64 = ctx.f5.f64;
	// lfs f5,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f10,f9,f3,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f3.f64 - ctx.f10.f64));
	// lfs f9,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f8,f8,f9,f7
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f9.f64 - ctx.f7.f64)));
	// stfs f8,4396(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4396, temp.u32);
	// fnmsubs f12,f1,f0,f12
	ctx.f12.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// fmadds f11,f11,f5,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f5.f64 + ctx.f10.f64));
	// lfs f10,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f2,f10,f30
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f10,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f8,f21,f0,f12
	ctx.f8.f64 = double(float(-(ctx.f21.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// lfs f12,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f1,f4,f10,f11
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f10.f64 + ctx.f11.f64));
	// fnmsubs f7,f19,f12,f8
	ctx.f7.f64 = double(float(-(ctx.f19.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// lfs f8,-29788(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -29788);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,184(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fmadds f11,f18,f8,f7
	ctx.f11.f64 = double(float(ctx.f18.f64 * ctx.f8.f64 + ctx.f7.f64));
	// fnmsubs f11,f17,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// fnmsubs f11,f6,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// lfs f6,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f6.f64 = double(temp.f32);
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f13,-29792(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -29792);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,384(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fmadds f11,f16,f12,f11
	ctx.f11.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f11.f64));
	// fnmsubs f7,f15,f8,f11
	ctx.f7.f64 = double(float(-(ctx.f15.f64 * ctx.f8.f64 - ctx.f11.f64)));
	// lfs f11,-29784(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -29784);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,240(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fmadds f7,f6,f11,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f11.f64 + ctx.f7.f64));
	// fnmsubs f13,f14,f13,f7
	ctx.f13.f64 = double(float(-(ctx.f14.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// fmadds f13,f20,f12,f13
	ctx.f13.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f13.f64));
	// lfs f7,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f13,f22,f9,f13
	ctx.f13.f64 = double(float(-(ctx.f22.f64 * ctx.f9.f64 - ctx.f13.f64)));
	// fnmsubs f9,f7,f11,f13
	ctx.f9.f64 = double(float(-(ctx.f7.f64 * ctx.f11.f64 - ctx.f13.f64)));
	// lfs f13,-29780(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29780);
	ctx.f13.f64 = double(temp.f32);
	// lfs f7,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f7.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stfs f13,236(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f14,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f13,f7,f13,f9
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 + ctx.f9.f64));
	// lfs f7,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f9,f31,f30
	ctx.f9.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fmadds f13,f2,f11,f13
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f13.f64));
	// stfs f13,4400(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4400, temp.u32);
	// lfs f13,1068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1068);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f28,f13
	ctx.f13.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// fmuls f4,f9,f13
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f13,f24,f31
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// fmuls f21,f4,f29
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// fmuls f6,f7,f13
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// stfs f6,532(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// fmuls f6,f30,f25
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// fmuls f4,f28,f23
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmuls f22,f13,f23
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// fmuls f2,f24,f6
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmuls f6,f28,f25
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// stfs f4,80(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fadds f20,f4,f6
	ctx.f20.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// lfs f4,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// stfs f4,1120(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1120, temp.u32);
	// fmuls f19,f3,f4
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f4,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f22,f2,f4,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f4.f64 + ctx.f22.f64));
	// lfs f4,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f4.f64 = double(temp.f32);
	// fmsubs f18,f13,f4,f21
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f4.f64 - ctx.f21.f64));
	// lfs f13,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// lfs f21,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f17,f13,f6
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fmuls f13,f24,f21
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f21.f64));
	// lfs f6,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,-29796(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29796);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,932(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 932, temp.u32);
	// fmuls f16,f6,f13
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmuls f13,f28,f4
	ctx.f13.f64 = double(float(ctx.f28.f64 * ctx.f4.f64));
	// lfs f4,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f15,f13,f4
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// lfs f13,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f14,f14,f13,f1
	ctx.f14.f64 = double(float(-(ctx.f14.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// lfs f13,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f13.f64 = double(temp.f32);
	// lfs f1,1408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1408);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f1,f1,f13,f22
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f22.f64)));
	// fmadds f22,f20,f4,f19
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f4.f64 + ctx.f19.f64));
	// lfs f20,1400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1400);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f20,f20,f13,f18
	ctx.f20.f64 = double(float(-(ctx.f20.f64 * ctx.f13.f64 - ctx.f18.f64)));
	// lfs f19,1392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1392);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f18,f17,f10,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f16.f64));
	// fmuls f17,f15,f31
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// fnmsubs f19,f19,f2,f1
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// lfs f1,1384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1384);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f20,f1,f13,f20
	ctx.f20.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f20.f64)));
	// fmuls f1,f24,f23
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// fnmsubs f18,f17,f10,f18
	ctx.f18.f64 = double(float(-(ctx.f17.f64 * ctx.f10.f64 - ctx.f18.f64)));
	// fnmsubs f1,f3,f1,f14
	ctx.f1.f64 = double(float(-(ctx.f3.f64 * ctx.f1.f64 - ctx.f14.f64)));
	// lfs f3,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// stfs f3,828(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 828, temp.u32);
	// fmadds f22,f6,f3,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 + ctx.f22.f64));
	// lfs f3,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// stfs f3,188(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f16,f3,f29
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f29.f64));
	// fmuls f3,f30,f21
	ctx.f3.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// fmuls f15,f24,f3
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// lfs f3,1376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1376);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f2,f3,f2,f20
	ctx.f2.f64 = double(float(-(ctx.f3.f64 * ctx.f2.f64 - ctx.f20.f64)));
	// fmuls f3,f9,f26
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// fmuls f20,f7,f3
	ctx.f20.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// lfs f3,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f3,f30
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// lfs f3,1368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1368);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f19,f3,f13,f19
	ctx.f19.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f19.f64)));
	// lfs f3,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f1,f22,f10,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 + ctx.f1.f64));
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f20,f20,f13,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f14.f64));
	// fmuls f17,f3,f17
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// fmuls f3,f27,f25
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// fmadds f18,f17,f10,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f18.f64));
	// fmadds f22,f3,f13,f16
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f16.f64));
	// lfs f3,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f2,f15,f3,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f3.f64 + ctx.f2.f64));
	// lfs f3,1360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1360);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f7,f3
	ctx.f16.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// lfs f3,1324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1324);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f19,f3,f13,f19
	ctx.f19.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f19.f64)));
	// lfs f3,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f9,f3
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// fmuls f3,f28,f21
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// fmuls f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// fmadds f3,f22,f6,f1
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 + ctx.f1.f64));
	// lfs f1,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f1.f64 = double(temp.f32);
	// stfs f3,4404(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4404, temp.u32);
	// lfs f3,1352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1352);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f3,f3,f13,f2
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f2.f64)));
	// stfs f3,4408(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4408, temp.u32);
	// fmadds f2,f16,f13,f20
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 + ctx.f20.f64));
	// stfs f2,4412(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4412, temp.u32);
	// fnmsubs f2,f15,f29,f19
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f29.f64 - ctx.f19.f64)));
	// stfs f2,4416(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4416, temp.u32);
	// lfs f2,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,1436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1436);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f9,f3
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// fnmsubs f4,f4,f10,f18
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f10.f64 - ctx.f18.f64)));
	// lfs f10,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmadds f17,f3,f13,f4
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f4.f64));
	// lfs f4,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f22,f10,f0
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f10,f1,f25
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// fmuls f3,f24,f25
	ctx.f3.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// fmuls f20,f10,f30
	ctx.f20.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f10,1344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1344);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f19,f10,f8
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f10,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f18,f2,f10
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmuls f10,f27,f21
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// fmuls f16,f6,f10
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// lfs f10,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmadds f22,f10,f4,f22
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 + ctx.f22.f64));
	// lfs f10,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f10.f64 = double(temp.f32);
	// lfs f4,1340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1340);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f15,f4,f10
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f4,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f14,f9,f4
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// lfs f4,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f20,f20,f4,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f4.f64 + ctx.f19.f64));
	// lfs f4,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// fmuls f19,f18,f0
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fnmsubs f18,f4,f3,f17
	ctx.f18.f64 = double(float(-(ctx.f4.f64 * ctx.f3.f64 - ctx.f17.f64)));
	// lfs f3,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f9,f3
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// fmuls f3,f10,f23
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f23.f64));
	// fmadds f19,f15,f12,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f19.f64));
	// fnmsubs f18,f16,f13,f18
	ctx.f18.f64 = double(float(-(ctx.f16.f64 * ctx.f13.f64 - ctx.f18.f64)));
	// fmuls f22,f22,f3
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f3.f64));
	// lfs f3,1612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1612);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// stfs f3,80(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f3,f1,f23
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// stfs f3,1168(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1168, temp.u32);
	// fmadds f22,f20,f10,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 + ctx.f22.f64));
	// fmuls f1,f3,f31
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// lfs f3,1516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1516);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f3,f8
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// fmuls f3,f26,f21
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// fmuls f3,f3,f6
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f6,1692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1692);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f6,f10
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmuls f6,f26,f25
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmadds f18,f14,f5,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f5.f64 + ctx.f18.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// fmadds f1,f1,f11,f16
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 + ctx.f16.f64));
	// lfs f16,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f6,f4
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// lfs f6,1080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1080);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f19,f9,f6
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// lfs f6,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f18,f17,f5,f18
	ctx.f18.f64 = double(float(-(ctx.f17.f64 * ctx.f5.f64 - ctx.f18.f64)));
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fnmsubs f22,f14,f12,f22
	ctx.f22.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f22.f64)));
	// fnmsubs f3,f3,f5,f18
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f5.f64 - ctx.f18.f64)));
	// fmuls f2,f2,f6
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f6,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f16,f6
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// lfs f6,1508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1508);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f22,f20,f8,f22
	ctx.f22.f64 = double(float(-(ctx.f20.f64 * ctx.f8.f64 - ctx.f22.f64)));
	// lfs f20,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f1,f6,f12,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 + ctx.f1.f64));
	// fmuls f6,f27,f25
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// fmadds f5,f15,f5,f3
	ctx.f5.f64 = double(float(ctx.f15.f64 * ctx.f5.f64 + ctx.f3.f64));
	// fmuls f16,f16,f31
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f31.f64));
	// fmadds f1,f1,f10,f22
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f22.f64));
	// lfs f22,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f4,f6
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f4,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f5,f19,f13,f5
	ctx.f5.f64 = double(float(-(ctx.f19.f64 * ctx.f13.f64 - ctx.f5.f64)));
	// fmadds f2,f2,f0,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f1.f64));
	// lfs f1,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f14,f4,f6
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f4,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f6,f4,f23
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// stfs f6,720(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 720, temp.u32);
	// fmuls f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f25.f64));
	// fmadds f13,f17,f13,f5
	ctx.f13.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f5.f64));
	// lfs f5,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f5,f16,f5,f2
	ctx.f5.f64 = double(float(-(ctx.f16.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f2,1444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1444);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f18,f10,f6
	ctx.f18.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// fmuls f4,f10,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// fnmsubs f13,f9,f2,f13
	ctx.f13.f64 = double(float(-(ctx.f9.f64 * ctx.f2.f64 - ctx.f13.f64)));
	// lfs f2,1572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1572);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f5,f14,f0,f5
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 + ctx.f5.f64));
	// fmuls f3,f18,f31
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f31.f64));
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fmadds f13,f9,f2,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f2.f64 + ctx.f13.f64));
	// stfs f13,4420(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4420, temp.u32);
	// lfs f13,1604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1604);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f9,f22,f8
	ctx.f9.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// fmuls f13,f7,f13
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// stfs f13,708(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 708, temp.u32);
	// lfs f13,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f23
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// fnmsubs f5,f3,f11,f5
	ctx.f5.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 - ctx.f5.f64)));
	// fmuls f8,f13,f25
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// fmuls f13,f20,f23
	ctx.f13.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// fmuls f19,f8,f12
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// lfs f8,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f3,f13,f25
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// lfs f13,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f2,f13,f25
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// lfs f13,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// stfs f1,392(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fmadds f1,f20,f12,f9
	ctx.f1.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f9.f64));
	// lfs f9,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f18,f8,f9
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f9,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f25
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// lfs f8,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f17,f9,f8
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// lfs f8,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f3,f8,f21,f3
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f21.f64 + ctx.f3.f64));
	// lfs f8,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f16,f8,f21
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f21.f64));
	// lfs f8,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f15,f7,f8
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f8,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f8.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f8,f8,f25
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// lfs f14,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f14.f64 = double(temp.f32);
	// stfs f8,596(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// fmuls f3,f3,f13
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fnmsubs f4,f4,f11,f5
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 - ctx.f5.f64)));
	// lfs f5,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f6,f6,f25
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// fmuls f14,f14,f8
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f8.f64));
	// lfs f8,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f1,f1,f8,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f8.f64 + ctx.f19.f64));
	// lfs f8,-29800(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29800);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,80(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f8,f17,f8
	ctx.f8.f64 = double(float(ctx.f17.f64 * ctx.f8.f64));
	// lfs f17,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f17,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f17.f64));
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f13,1500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1500);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f15,f13,f10
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f13,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f14,f14,f13,f8
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 + ctx.f8.f64));
	// fmuls f13,f5,f28
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// fmuls f8,f10,f25
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// fnmsubs f4,f15,f12,f4
	ctx.f4.f64 = double(float(-(ctx.f15.f64 * ctx.f12.f64 - ctx.f4.f64)));
	// fmadds f14,f19,f0,f14
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 + ctx.f14.f64));
	// lfs f19,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f19,f25
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f25.f64));
	// lfs f19,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f8,f13,f8
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// lfs f13,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f23
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// stfs f13,228(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f7,f7,f13
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f13,1652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1652);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// stfs f13,136(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f13,f5,f31
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// lfs f5,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f13,f5,f13,f8
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 + ctx.f8.f64));
	// fmuls f8,f7,f9
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// lfs f7,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f7.f64 = double(temp.f32);
	// lfs f9,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f9,f9,f7,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f7.f64 + ctx.f6.f64));
	// lfs f7,1492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1492);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f7,f7,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f19.f64));
	// fmadds f4,f13,f0,f4
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f4.f64));
	// lfs f13,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f13.f64 = double(temp.f32);
	// lfs f5,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f6,f5,f6,f14
	ctx.f6.f64 = double(float(-(ctx.f5.f64 * ctx.f6.f64 - ctx.f14.f64)));
	// lfs f5,1596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1596);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f10,f5,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f5,f15,f12,f1
	ctx.f5.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f1.f64));
	// lfs f15,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f15.f64 = double(temp.f32);
	// lfs f1,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f15.f64));
	// fmuls f15,f9,f13
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f9,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f13,f22,f23
	ctx.f13.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// fnmsubs f7,f7,f0,f6
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f6.f64)));
	// lfs f6,1484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1484);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f10,f10,f12,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + ctx.f4.f64));
	// stfs f10,4424(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4424, temp.u32);
	// fnmsubs f5,f2,f14,f5
	ctx.f5.f64 = double(float(-(ctx.f2.f64 * ctx.f14.f64 - ctx.f5.f64)));
	// fmuls f6,f6,f23
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// fmuls f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// fmadds f10,f13,f0,f7
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f7.f64));
	// fmadds f13,f3,f12,f5
	ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f5.f64));
	// fnmsubs f13,f18,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f18.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmadds f7,f16,f12,f13
	ctx.f7.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f13.f64));
	// lfs f13,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f7,f17,f13,f7
	ctx.f7.f64 = double(float(-(ctx.f17.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// fnmsubs f7,f1,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fnmsubs f13,f8,f13,f7
	ctx.f13.f64 = double(float(-(ctx.f8.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// fmadds f13,f15,f11,f13
	ctx.f13.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 + ctx.f13.f64));
	// stfs f13,4428(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4428, temp.u32);
	// fnmsubs f6,f6,f0,f10
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// lfs f8,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f8.f64 = double(temp.f32);
	// lfs f13,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f4,f8,f13
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f13,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,1128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1128);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f8,f30
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fmuls f3,f10,f13
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// lfs f5,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f5.f64 = double(temp.f32);
	// lfs f7,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f7.f64 = double(temp.f32);
	// lfs f15,1184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1184);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f4,f4,f0,f6
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f6.f64)));
	// lfs f6,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// fmuls f2,f13,f10
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f10,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f1,f5,f10
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// lfs f10,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f5,f14,f5
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f5.f64));
	// fmuls f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// fmuls f18,f10,f11
	ctx.f18.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f17,f7,f10
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// fmuls f10,f20,f25
	ctx.f10.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// fmsubs f3,f3,f12,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 - ctx.f2.f64));
	// fmadds f18,f8,f12,f18
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 + ctx.f18.f64));
	// fmuls f8,f22,f25
	ctx.f8.f64 = double(float(ctx.f22.f64 * ctx.f25.f64));
	// fmuls f16,f10,f6
	ctx.f16.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// lfs f10,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmadds f3,f18,f13,f3
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f3.f64));
	// lfs f18,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f6,f8,f6
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// lfs f8,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f2,f8,f0
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// lfs f8,1208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1208);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f15,f15,f10
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// lfs f10,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f4,f1,f10,f4
	ctx.f4.f64 = double(float(-(ctx.f1.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// fmuls f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// stfs f8,1204(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1204, temp.u32);
	// fmadds f2,f18,f10,f2
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f10.f64 + ctx.f2.f64));
	// lfs f18,1668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1668);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f3,f15,f10,f3
	ctx.f3.f64 = double(float(ctx.f15.f64 * ctx.f10.f64 + ctx.f3.f64));
	// lfs f15,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f4,f17,f10,f4
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f4.f64));
	// lfs f17,1168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1168);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f1,f13,f8
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// fmuls f8,f7,f31
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f17,f9,f17
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f17.f64));
	// fmuls f15,f13,f15
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f15.f64));
	// fmuls f18,f13,f18
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f18.f64));
	// fnmsubs f4,f16,f10,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f16,1560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1560);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// fmuls f7,f13,f8
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// fmuls f8,f20,f23
	ctx.f8.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// fmuls f15,f15,f31
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// fnmsubs f6,f6,f10,f4
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f10,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f4,f1,f11,f3
	ctx.f4.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f3.f64)));
	// lfs f11,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f28
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// stfs f11,1212(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1212, temp.u32);
	// fmuls f8,f8,f9
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f9,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmuls f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f1,f13,f21
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// fmuls f3,f13,f11
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f11,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f28
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// fmuls f9,f13,f9
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// fadds f14,f10,f11
	ctx.f14.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// lfs f11,1164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1164);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f16,f11,f28,f16
	ctx.f16.f64 = double(float(ctx.f11.f64 * ctx.f28.f64 + ctx.f16.f64));
	// lfs f10,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfs f11,720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 720);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f10,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f6,f2,f10,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f10.f64 + ctx.f6.f64));
	// lfs f10,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f7,f7,f10,f4
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f4,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f11,f4,f28
	ctx.f11.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// lfs f4,1184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1184);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f2,f1,f14
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f14.f64));
	// fmuls f1,f16,f13
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fmadds f8,f8,f0,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f6.f64));
	// fnmsubs f7,f18,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f18.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// fmuls f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// lfs f11,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f16,f15,f11
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// lfs f11,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f8,f17,f11,f8
	ctx.f8.f64 = double(float(-(ctx.f17.f64 * ctx.f11.f64 - ctx.f8.f64)));
	// fmadds f10,f9,f10,f7
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f10.f64 + ctx.f7.f64));
	// fmadds f2,f2,f11,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f16.f64));
	// fnmsubs f9,f5,f0,f8
	ctx.f9.f64 = double(float(-(ctx.f5.f64 * ctx.f0.f64 - ctx.f8.f64)));
	// lfs f8,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f10,f3,f8,f10
	ctx.f10.f64 = double(float(-(ctx.f3.f64 * ctx.f8.f64 - ctx.f10.f64)));
	// fnmsubs f4,f4,f0,f2
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fmadds f3,f1,f12,f10
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 + ctx.f10.f64));
	// lfs f10,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f9,f8,f11,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f11.f64 + ctx.f9.f64));
	// stfs f9,4432(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4432, temp.u32);
	// lfs f9,828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 828);
	ctx.f9.f64 = double(temp.f32);
	// fadds f5,f10,f9
	ctx.f5.f64 = double(float(ctx.f10.f64 + ctx.f9.f64));
	// lfs f9,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,1120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1120);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f1,f9,f10
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f8,1476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1476);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f10,f26,f25
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmuls f2,f5,f8
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// lfs f5,1588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1588);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f18,f10,f8
	ctx.f18.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f10,-18732(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -18732);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,188(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f10,f30,f25
	ctx.f10.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfs f7,-18872(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -18872);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,252(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fmuls f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f17,f9,f10
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// fmuls f10,f28,f25
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f6,f10,f31
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// lfs f10,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f16,f10,f6
	ctx.f16.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// lfs f6,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f15,f6,f5
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// fmuls f6,f27,f19
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// fmadds f4,f15,f11,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 + ctx.f4.f64));
	// lfs f11,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f11,f13
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmuls f11,f28,f23
	ctx.f11.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmuls f14,f10,f6
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// lfs f6,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// fmuls f5,f6,f5
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// fmuls f6,f26,f23
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// fmuls f15,f10,f11
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f11,1676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1676);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f13,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f11,f24,f25
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// lfs f10,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f6,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// lfs f6,1420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1420);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f13,f6
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fmuls f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// fmsubs f8,f1,f10,f7
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 - ctx.f7.f64));
	// fmuls f10,f26,f28
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// lfs f7,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f7.f64 = double(temp.f32);
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// stfs f11,228(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmr f11,f7
	ctx.f11.f64 = ctx.f7.f64;
	// fmuls f7,f2,f30
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// fmuls f10,f11,f10
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// stfs f10,256(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fnmsubs f10,f5,f0,f4
	ctx.f10.f64 = double(float(-(ctx.f5.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// lfs f4,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f0,f27,f30
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// stfs f0,136(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f11,f24,f23
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f0,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f5,f0,f13
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f0,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f2,f0,f11
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f11,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f8,f18,f11,f8
	ctx.f8.f64 = double(float(-(ctx.f18.f64 * ctx.f11.f64 - ctx.f8.f64)));
	// lfs f11,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f10,f6,f11,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f11.f64 + ctx.f10.f64));
	// lfs f6,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f11,f24,f19
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// fmuls f5,f5,f28
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// fmuls f6,f6,f11
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f11,1412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1412);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f13,f11
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// fmuls f11,f27,f23
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// fmuls f18,f11,f0
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f0,1152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1152);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// lfs f11,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f8,f17,f11,f8
	ctx.f8.f64 = double(float(-(ctx.f17.f64 * ctx.f11.f64 - ctx.f8.f64)));
	// stfs f0,828(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 828, temp.u32);
	// fmuls f17,f13,f0
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f0,f27,f25
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// fnmsubs f13,f7,f12,f10
	ctx.f13.f64 = double(float(-(ctx.f7.f64 * ctx.f12.f64 - ctx.f10.f64)));
	// lfs f12,1476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1476);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f10,f16,f11,f8
	ctx.f10.f64 = double(float(-(ctx.f16.f64 * ctx.f11.f64 - ctx.f8.f64)));
	// lfs f8,20396(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 20396);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,720(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 720, temp.u32);
	// lfs f8,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,1068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1068);
	ctx.f7.f64 = double(temp.f32);
	// lfs f16,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f0,f26,f19
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// lfs f12,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f8,f4,f8,f13
	ctx.f8.f64 = double(float(-(ctx.f4.f64 * ctx.f8.f64 - ctx.f13.f64)));
	// lfs f13,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfs f12,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f24,f12
	ctx.f12.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// stfs f0,596(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// fmuls f4,f12,f13
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f13.f64 = double(temp.f32);
	// fmr f0,f13
	ctx.f0.f64 = ctx.f13.f64;
	// lfs f13,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f12,f14,f0,f10
	ctx.f12.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 + ctx.f10.f64));
	// fnmsubs f10,f5,f13,f8
	ctx.f10.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// lfs f8,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f8.f64 = double(temp.f32);
	// lfs f5,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f0,f9,f0,f12
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 + ctx.f12.f64));
	// lfs f9,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f9.f64 = double(temp.f32);
	// lfs f12,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f9,f1,f9,f10
	ctx.f9.f64 = double(float(-(ctx.f1.f64 * ctx.f9.f64 - ctx.f10.f64)));
	// lfs f10,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// fmadds f1,f15,f10,f0
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f10.f64 + ctx.f0.f64));
	// lfs f0,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f9,f17,f0,f9
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f9.f64));
	// fmadds f17,f8,f5,f12
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f5.f64 + ctx.f12.f64));
	// fmadds f12,f16,f11,f1
	ctx.f12.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 + ctx.f1.f64));
	// fadds f11,f3,f9
	ctx.f11.f64 = double(float(ctx.f3.f64 + ctx.f9.f64));
	// lfs f9,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f9.f64 = double(temp.f32);
	// stfs f11,4436(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4436, temp.u32);
	// fnmsubs f12,f2,f9,f12
	ctx.f12.f64 = double(float(-(ctx.f2.f64 * ctx.f9.f64 - ctx.f12.f64)));
	// fnmsubs f11,f6,f9,f12
	ctx.f11.f64 = double(float(-(ctx.f6.f64 * ctx.f9.f64 - ctx.f12.f64)));
	// lfs f12,19620(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 19620);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,376(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fmadds f11,f18,f12,f11
	ctx.f11.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 + ctx.f11.f64));
	// lfs f6,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f8,f23
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f23.f64));
	// fmuls f8,f28,f7
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f7.f64));
	// fmuls f7,f27,f21
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// fnmsubs f11,f6,f9,f11
	ctx.f11.f64 = double(float(-(ctx.f6.f64 * ctx.f9.f64 - ctx.f11.f64)));
	// lfs f6,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f12,f6,f12,f11
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 + ctx.f11.f64));
	// stfs f12,4440(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4440, temp.u32);
	// lfs f6,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f11,f26,f25
	ctx.f11.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// lfs f12,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f12.f64 = double(temp.f32);
	// fadds f3,f12,f6
	ctx.f3.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
	// lfs f12,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f2,f12,f21
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// fmuls f12,f27,f25
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// fmuls f3,f3,f24
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fmuls f2,f2,f9
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// fadds f1,f11,f12
	ctx.f1.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// lfs f12,1160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1160);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f18,f27,f12
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// lfs f11,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f28,f23
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmadds f3,f1,f31,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f31.f64 + ctx.f3.f64));
	// lfs f1,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fmuls f15,f11,f12
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f11,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f28,f5
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f5.f64));
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fmuls f5,f11,f12
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f11,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f27,f8
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// stfs f12,1172(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1172, temp.u32);
	// fmuls f7,f11,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fmuls f3,f3,f11
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// fmuls f14,f11,f12
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f12,-11152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11152);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// stfs f12,612(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 612, temp.u32);
	// fmadds f2,f17,f12,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f2.f64));
	// lfs f17,1160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1160);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f24,f17
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f17.f64));
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fmsubs f18,f15,f10,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f10.f64 - ctx.f18.f64));
	// fmuls f15,f7,f31
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// lfs f7,720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 720);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f4,f4,f7,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f7.f64 - ctx.f2.f64));
	// fmuls f2,f24,f8
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// lfs f8,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f3,f3,f7,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f7.f64 - ctx.f16.f64));
	// lfs f16,1640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1640);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f11,f16
	ctx.f16.f64 = double(float(ctx.f11.f64 * ctx.f16.f64));
	// fnmsubs f5,f5,f10,f18
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f10.f64 - ctx.f18.f64)));
	// fmuls f18,f8,f25
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// lfs f8,1200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1200);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f8,f27,f8
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// stfs f8,80(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f8,f26,f21
	ctx.f8.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// fnmsubs f4,f14,f12,f4
	ctx.f4.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f4.f64)));
	// fnmsubs f3,f1,f12,f3
	ctx.f3.f64 = double(float(-(ctx.f1.f64 * ctx.f12.f64 - ctx.f3.f64)));
	// fmadds f17,f17,f10,f5
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f5.f64));
	// lfs f5,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f2,f8,f31,f2
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f31.f64 + ctx.f2.f64));
	// fmuls f8,f24,f26
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f26.f64));
	// fmadds f4,f15,f7,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f7.f64 + ctx.f4.f64));
	// fnmsubs f3,f18,f9,f3
	ctx.f3.f64 = double(float(-(ctx.f18.f64 * ctx.f9.f64 - ctx.f3.f64)));
	// fmuls f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// fmuls f14,f8,f5
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// fmuls f8,f6,f27
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f6,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f4,f16,f12,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f4.f64)));
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f8,1112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	ctx.f8.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f17,f15,f10,f17
	ctx.f17.f64 = double(float(-(ctx.f15.f64 * ctx.f10.f64 - ctx.f17.f64)));
	// fmuls f15,f27,f8
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// fmuls f8,f27,f26
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// fmsubs f14,f8,f6,f14
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f6.f64 - ctx.f14.f64));
	// fmuls f8,f27,f27
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f27.f64));
	// lfs f18,1632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1632);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f6,f26,f26
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f26.f64));
	// fmuls f18,f11,f18
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f18.f64));
	// lfs f11,1468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1468);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f16,f24,f11
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// lis r11,-32245
	ctx.r11.s64 = -2113208320;
	// fmuls f11,f24,f27
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// fmadds f7,f2,f7,f4
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f7.f64 + ctx.f4.f64));
	// stfs f7,4444(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4444, temp.u32);
	// lfs f7,1104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f17,f15,f12,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f17.f64));
	// fmuls f4,f24,f7
	ctx.f4.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// lfs f15,1588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1588);
	ctx.f15.f64 = double(temp.f32);
	// fadds f6,f6,f8
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// lfs f8,28844(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28844);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,688(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 688, temp.u32);
	// fnmsubs f11,f11,f5,f14
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f5.f64 - ctx.f14.f64)));
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f5,f1,f12,f3
	ctx.f5.f64 = double(float(-(ctx.f1.f64 * ctx.f12.f64 - ctx.f3.f64)));
	// fmuls f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f15.f64));
	// lfs f14,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f11,f24,f24,f11
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f24.f64 + ctx.f11.f64));
	// fnmsubs f7,f18,f12,f5
	ctx.f7.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f5.f64)));
	// stfs f7,4452(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4452, temp.u32);
	// lfs f7,1644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1644);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f5,f16,f10,f17
	ctx.f5.f64 = double(float(-(ctx.f16.f64 * ctx.f10.f64 - ctx.f17.f64)));
	// fmadds f11,f6,f8,f11
	ctx.f11.f64 = double(float(ctx.f6.f64 * ctx.f8.f64 + ctx.f11.f64));
	// stfs f11,4448(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4448, temp.u32);
	// lfs f11,1112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f6,f27,f7
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// fmuls f3,f26,f11
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f11,1200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1200);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f26,f11
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f8,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f11,f28,f25
	ctx.f11.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fnmsubs f5,f4,f9,f5
	ctx.f5.f64 = double(float(-(ctx.f4.f64 * ctx.f9.f64 - ctx.f5.f64)));
	// lfs f9,1468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1468);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f4,f27,f9
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// fmuls f7,f24,f7
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// fmuls f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// stfs f11,228(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f1,f8,f11
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// lfs f11,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f8,f30,f25
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// fmuls f11,f11,f23
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// stfs f11,1176(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1176, temp.u32);
	// fmuls f8,f8,f31
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// fmuls f18,f11,f8
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f8,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f11,f28,f21
	ctx.f11.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// fmuls f17,f11,f8
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f11,-3204(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -3204);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f16,f6,f11
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f6,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f8,f22,f23
	ctx.f8.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// stfs f11,680(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 680, temp.u32);
	// fmadds f5,f4,f11,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 + ctx.f5.f64));
	// fmuls f17,f17,f31
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f31.f64));
	// fmsubs f3,f3,f11,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 - ctx.f16.f64));
	// lfs f11,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f16,f15,f31
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// fmuls f15,f26,f9
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// fmuls f6,f6,f14
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// lfs f14,1104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f26,f14
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f14.f64));
	// fnmsubs f3,f2,f10,f3
	ctx.f3.f64 = double(float(-(ctx.f2.f64 * ctx.f10.f64 - ctx.f3.f64)));
	// lfs f10,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f10,f25
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// lfs f10,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// stfs f10,136(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f8,f8,f30
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fnmsubs f4,f1,f11,f3
	ctx.f4.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f3.f64)));
	// fmuls f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f10,1200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1200);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f2,f24,f10
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// lfs f10,1112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fmuls f10,f24,f10
	ctx.f10.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// lfs f11,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f8,f16,f11,f8
	ctx.f8.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 + ctx.f8.f64));
	// lfs f3,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f11,f30,f21
	ctx.f11.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// lfs f1,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f1.f64 = double(temp.f32);
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f10,f1,f25
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// fmadds f8,f6,f13,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f8.f64));
	// fmuls f3,f11,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// lfs f11,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f28
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// fmuls f6,f3,f31
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// lfs f3,1548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1548);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f1,f10,f11
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f11,1644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1644);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f26,f11
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f11,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f5,f2,f11,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f5.f64));
	// lfs f11,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f25
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// fnmsubs f5,f10,f12,f5
	ctx.f5.f64 = double(float(-(ctx.f10.f64 * ctx.f12.f64 - ctx.f5.f64)));
	// lfs f10,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f2,f11,f31
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// lfs f11,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f11,f18,f11,f4
	ctx.f11.f64 = double(float(-(ctx.f18.f64 * ctx.f11.f64 - ctx.f4.f64)));
	// lfs f4,1388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1388);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// lfs f18,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f3,f18,f3
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// lfs f18,1160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1160);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f26,f18
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f18.f64));
	// fmadds f17,f17,f10,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f11.f64));
	// lfs f11,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f9,f9,f11,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f11.f64 + ctx.f8.f64));
	// lfs f10,1104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f4,f2,f11,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f4.f64));
	// lfs f11,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f16,f27,f10
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f8,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f10,f11,f25
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// lfs f11,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f11.f64 = double(temp.f32);
	// stfs f10,1096(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1096, temp.u32);
	// fmadds f9,f1,f8,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f8.f64 + ctx.f9.f64));
	// lfs f1,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmuls f2,f11,f10
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// lfs f10,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f5,f18,f10,f5
	ctx.f5.f64 = double(float(-(ctx.f18.f64 * ctx.f10.f64 - ctx.f5.f64)));
	// lfs f10,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f7,f7,f10,f17
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64 + ctx.f17.f64));
	// fmadds f9,f3,f0,f9
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f9.f64));
	// lfs f3,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmadds f7,f14,f10,f7
	ctx.f7.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 + ctx.f7.f64));
	// fmsubs f9,f4,f11,f9
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 - ctx.f9.f64));
	// lfs f4,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f12,f15,f12,f7
	ctx.f12.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f7.f64));
	// lfs f7,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f12,f7,f10,f12
	ctx.f12.f64 = double(float(-(ctx.f7.f64 * ctx.f10.f64 - ctx.f12.f64)));
	// lfs f7,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f2,f2,f7,f9
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f7.f64 - ctx.f9.f64)));
	// lfs f9,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f12,f6,f9,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 + ctx.f12.f64));
	// fmadds f12,f16,f10,f12
	ctx.f12.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f12.f64));
	// lfs f10,1460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1460);
	ctx.f10.f64 = double(temp.f32);
	// fadds f12,f5,f12
	ctx.f12.f64 = double(float(ctx.f5.f64 + ctx.f12.f64));
	// stfs f12,4456(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4456, temp.u32);
	// lfs f12,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f10,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f10,f30
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f5,1396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1396);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f6,f9,f19
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f19.f64));
	// lfs f9,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// stfs f9,720(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 720, temp.u32);
	// fadds f5,f5,f9
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// lfs f9,1184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1184);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f4,f4,f9
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f9.f64));
	// lfs f9,1928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1928);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f3,f3,f9
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// fmuls f18,f7,f0
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f7,1380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1380);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f17,f7,f0
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f7,f10,f28
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f15,f5,f0
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmsubs f18,f3,f13,f18
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 - ctx.f18.f64));
	// lfs f3,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f1,f1,f13,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fmadds f16,f7,f23,f6
	ctx.f16.f64 = double(float(ctx.f7.f64 * ctx.f23.f64 + ctx.f6.f64));
	// lfs f6,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f6,f23
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// lfs f7,1580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1580);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f14,f22,f7
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f7.f64));
	// fmuls f17,f4,f8
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// lfs f4,1428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1428);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// stfs f5,80(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f3,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f16,f16,f3,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 + ctx.f15.f64));
	// lfs f3,-29804(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29804);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f10,f4
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// lfs f10,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f18,f14,f10,f18
	ctx.f18.f64 = double(float(-(ctx.f14.f64 * ctx.f10.f64 - ctx.f18.f64)));
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f5,f14,f25
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// fmsubs f1,f1,f11,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 - ctx.f17.f64));
	// fmuls f17,f15,f23
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f23.f64));
	// lfs f15,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f11,f15
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// fmuls f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f4,f4,f5,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f5.f64 + ctx.f14.f64));
	// lfs f5,1628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1628);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f16,f5,f10,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 + ctx.f16.f64));
	// lfs f5,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// lfs f14,1404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1404);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f11,f14
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f14.f64));
	// fmadds f4,f4,f3,f18
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 + ctx.f18.f64));
	// lfs f3,1452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1452);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f1,f16,f11,f1
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 + ctx.f1.f64));
	// fmuls f5,f5,f11
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fmuls f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fmuls f16,f20,f9
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f9.f64));
	// fnmsubs f4,f17,f0,f4
	ctx.f4.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// lfs f17,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f1,f14,f0,f1
	ctx.f1.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// fmuls f18,f5,f30
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fmuls f5,f20,f23
	ctx.f5.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// fnmsubs f8,f3,f8,f4
	ctx.f8.f64 = double(float(-(ctx.f3.f64 * ctx.f8.f64 - ctx.f4.f64)));
	// lfs f4,1556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1556);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,1684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1684);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// fmadds f2,f18,f13,f2
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f2.f64));
	// fmuls f5,f5,f11
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// stfs f5,80(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f5,f17,f28
	ctx.f5.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// stfs f5,596(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// fmuls f17,f12,f9
	ctx.f17.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fnmsubs f8,f16,f10,f8
	ctx.f8.f64 = double(float(-(ctx.f16.f64 * ctx.f10.f64 - ctx.f8.f64)));
	// fmuls f16,f22,f9
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f9.f64));
	// fmuls f5,f11,f5
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// fmuls f11,f11,f3
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmadds f8,f17,f0,f8
	ctx.f8.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f8.f64));
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f30
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// fnmsubs f3,f18,f13,f2
	ctx.f3.f64 = double(float(-(ctx.f18.f64 * ctx.f13.f64 - ctx.f2.f64)));
	// fnmsubs f2,f15,f13,f1
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// lfs f1,1460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1460);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f22,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fmuls f18,f20,f7
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// fmadds f10,f4,f10,f3
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f10.f64 + ctx.f3.f64));
	// fnmsubs f5,f5,f0,f2
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fmadds f8,f1,f13,f8
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 + ctx.f8.f64));
	// fnmsubs f11,f11,f0,f5
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f0.f64 - ctx.f5.f64)));
	// fnmsubs f4,f18,f13,f8
	ctx.f4.f64 = double(float(-(ctx.f18.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// stfs f11,4460(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4460, temp.u32);
	// lfs f11,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f11.f64 = double(temp.f32);
	// lfs f8,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f8.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f10,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// fmuls f2,f10,f19
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f19.f64));
	// stfs f11,256(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f11,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f6,f12,f6
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// lfs f5,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f9,f11,f9
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f10,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f11,f5
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// fmuls f1,f12,f10
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f10,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f10.f64 = double(temp.f32);
	// lfs f18,1064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1064);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f4,f16,f13,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f13.f64 - ctx.f4.f64)));
	// fadds f18,f18,f10
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f10.f64));
	// lfs f10,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f10.f64 = double(temp.f32);
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f10,f17
	ctx.f17.f64 = double(float(ctx.f10.f64 * ctx.f17.f64));
	// lfs f10,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f5,f5,f10
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// stfs f5,332(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,1152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1152);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f6,f6,f22
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f5,f3,f10
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// lfs f3,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f2,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// lfs f15,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmuls f10,f10,f15
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f15.f64));
	// lfs f15,1136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1136);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// fmuls f15,f12,f12
	ctx.f15.f64 = double(float(ctx.f12.f64 * ctx.f12.f64));
	// fmuls f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// lfs f7,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f16,f16,f31
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f31.f64));
	// fmadds f5,f5,f0,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 + ctx.f3.f64));
	// lfs f3,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// fmuls f14,f10,f25
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// lfs f10,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f10.f64 = double(temp.f32);
	// fadds f18,f18,f10
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f10.f64));
	// lfs f10,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f8,f10
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// lfs f10,-29808(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29808);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f15,f11,f11,f15
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f11.f64 + ctx.f15.f64));
	// fnmsubs f5,f1,f0,f5
	ctx.f5.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f5.f64)));
	// lfs f1,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f10,f18,f10
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f10.f64));
	// fmuls f8,f8,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// lfs f1,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f22
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f22.f64));
	// fadds f18,f22,f20
	ctx.f18.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// fmadds f10,f15,f7,f10
	ctx.f10.f64 = double(float(ctx.f15.f64 * ctx.f7.f64 + ctx.f10.f64));
	// lfs f7,1096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1096);
	ctx.f7.f64 = double(temp.f32);
	// lfs f15,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f7,f15,f7
	ctx.f7.f64 = double(float(ctx.f15.f64 * ctx.f7.f64));
	// lfs f15,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f1,f15,f25,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f25.f64 + ctx.f1.f64));
	// lfs f15,1580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1580);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f11,f11,f15
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// lfs f15,1452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1452);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f12,f18,f15,f12
	ctx.f12.f64 = double(float(ctx.f18.f64 * ctx.f15.f64 + ctx.f12.f64));
	// lfs f15,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f21
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f21.f64));
	// fmsubs f10,f10,f15,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f15.f64 - ctx.f9.f64));
	// lfs f15,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f15.f64 = double(temp.f32);
	// lfs f9,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f21
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f21.f64));
	// fnmsubs f7,f7,f15,f5
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f15.f64 - ctx.f5.f64)));
	// lfs f15,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f15.f64 = double(temp.f32);
	// lfs f5,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f15
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f15.f64));
	// lfs f15,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f1,f1,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f15.f64));
	// fnmsubs f6,f6,f0,f10
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// lfs f10,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f15,f10,f28
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// lfs f10,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f7,f17,f10,f7
	ctx.f7.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f7.f64));
	// fmadds f12,f12,f0,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f6.f64));
	// lfs f6,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f7,f2,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f2.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// fnmsubs f12,f11,f0,f12
	ctx.f12.f64 = double(float(-(ctx.f11.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// lfs f11,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f7,f14,f11,f7
	ctx.f7.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 + ctx.f7.f64));
	// fadds f12,f4,f12
	ctx.f12.f64 = double(float(ctx.f4.f64 + ctx.f12.f64));
	// stfs f12,4464(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4464, temp.u32);
	// fnmsubs f12,f3,f13,f7
	ctx.f12.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// lfs f7,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f12,f8,f13,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 + ctx.f12.f64));
	// lfs f8,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f12,f5,f13,f12
	ctx.f12.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// lfs f5,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f12,f1,f13,f12
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 + ctx.f12.f64));
	// fnmsubs f12,f18,f13,f12
	ctx.f12.f64 = double(float(-(ctx.f18.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// fnmsubs f12,f9,f11,f12
	ctx.f12.f64 = double(float(-(ctx.f9.f64 * ctx.f11.f64 - ctx.f12.f64)));
	// stfs f12,4468(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4468, temp.u32);
	// lfs f12,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f4,f15,f12
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfs f9,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f12,f5,f30
	ctx.f12.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fmsubs f17,f16,f0,f4
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 - ctx.f4.f64));
	// lfs f4,1620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1620);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f8,f12
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// lfs f12,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f2,f12,f28
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// fmuls f12,f6,f31
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmuls f10,f7,f28
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// fmuls f1,f9,f12
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// fmuls f12,f7,f30
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// fmuls f15,f8,f10
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// fmuls f10,f7,f31
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f18,f9,f12
	ctx.f18.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// lfs f12,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f16,f12,f4
	ctx.f16.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// lfs f4,1088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1088);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f7,f4,f10
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fmuls f10,f6,f30
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fmuls f6,f4,f10
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f10,1372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1372);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f10,f10,f13,f17
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fmuls f13,f5,f28
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// fmsubs f10,f10,f12,f3
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 - ctx.f3.f64));
	// lfs f3,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f9,f9,f13
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f13,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f5,f8,f13
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f13,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f8,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f12,f13
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,1700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1700);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f13,1540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1540);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f17,f12,f13
	ctx.f17.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fmuls f3,f3,f13
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfs f13,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// fmuls f14,f12,f13
	ctx.f14.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f13,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// stfs f13,1196(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1196, temp.u32);
	// fmuls f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// fmadds f11,f2,f0,f10
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f0,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f0.f64 = double(temp.f32);
	// lfs f10,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f0,f10
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// lfs f0,1208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1208);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f12,f0,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// fmuls f0,f27,f25
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// lfs f2,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f8,f3,f29,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f29.f64 + ctx.f8.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfs f0,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// lfs f3,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f3.f64 = double(temp.f32);
	// stfs f0,228(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmadds f3,f0,f3,f13
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f3.f64 + ctx.f13.f64));
	// lfs f0,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f11,f1,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// lfs f13,1364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1364);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f0,f13
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fmuls f13,f12,f31
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f13,f28,f23
	ctx.f13.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// stfs f13,436(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// lfs f12,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f10,f10,f12,f8
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// lfs f8,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f12,f13,f31
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fmuls f13,f28,f25
	ctx.f13.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f13,136(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fadds f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfs f13,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f11,f18,f13,f11
	ctx.f11.f64 = double(float(-(ctx.f18.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// lfs f18,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f18.f64 = double(temp.f32);
	// lfs f13,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f13,824(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 824, temp.u32);
	// fmuls f13,f8,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f8,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f2,f2,f8,f10
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f8.f64 + ctx.f10.f64));
	// lfs f10,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f11,f16,f10,f11
	ctx.f11.f64 = double(float(-(ctx.f16.f64 * ctx.f10.f64 - ctx.f11.f64)));
	// fmadds f18,f12,f18,f13
	ctx.f18.f64 = double(float(ctx.f12.f64 * ctx.f18.f64 + ctx.f13.f64));
	// lfs f12,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f24,f19
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// fnmsubs f12,f12,f13,f2
	ctx.f12.f64 = double(float(-(ctx.f12.f64 * ctx.f13.f64 - ctx.f2.f64)));
	// lfs f13,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f2,f15,f13,f11
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// lfs f11,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f13,f24,f25
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// fnmsubs f16,f11,f13,f12
	ctx.f16.f64 = double(float(-(ctx.f11.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// lfs f12,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f12,f7,f12,f2
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + ctx.f2.f64));
	// lfs f7,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f7.f64 = double(temp.f32);
	// lfs f2,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f12,f6,f7,f12
	ctx.f12.f64 = double(float(-(ctx.f6.f64 * ctx.f7.f64 - ctx.f12.f64)));
	// lfs f6,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f12,f9,f7,f12
	ctx.f12.f64 = double(float(-(ctx.f9.f64 * ctx.f7.f64 - ctx.f12.f64)));
	// fmadds f12,f5,f7,f12
	ctx.f12.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 + ctx.f12.f64));
	// fmuls f5,f28,f21
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// fnmsubs f9,f4,f10,f12
	ctx.f9.f64 = double(float(-(ctx.f4.f64 * ctx.f10.f64 - ctx.f12.f64)));
	// lfs f12,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f4,f2,f13
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f13,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f9,f17,f12,f9
	ctx.f9.f64 = double(float(-(ctx.f17.f64 * ctx.f12.f64 - ctx.f9.f64)));
	// fnmsubs f12,f14,f12,f9
	ctx.f12.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f9.f64)));
	// lfs f9,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f12,f3,f0,f12
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f12.f64));
	// lfs f3,1444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1444);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f12,f6,f9,f12
	ctx.f12.f64 = double(float(-(ctx.f6.f64 * ctx.f9.f64 - ctx.f12.f64)));
	// fmuls f6,f28,f25
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmadds f12,f1,f10,f12
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f12.f64));
	// stfs f12,4472(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4472, temp.u32);
	// lfs f12,1660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f1,f24,f5
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// fmuls f17,f12,f13
	ctx.f17.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,1496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1496);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f14,f12,f13
	ctx.f14.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fmuls f12,f31,f28
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmuls f15,f24,f6
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmadds f4,f12,f3,f4
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 + ctx.f4.f64));
	// stfs f4,80(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f4,f27,f25
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// lfs f3,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f1,f1,f3,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f3.f64 - ctx.f17.f64));
	// fmsubs f3,f15,f3,f14
	ctx.f3.f64 = double(float(ctx.f15.f64 * ctx.f3.f64 - ctx.f14.f64));
	// fmuls f2,f2,f4
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// lfs f4,1572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1572);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f5,f5,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// fmsubs f17,f12,f4,f17
	ctx.f17.f64 = double(float(ctx.f12.f64 * ctx.f4.f64 - ctx.f17.f64));
	// lfs f15,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f15.f64 = double(temp.f32);
	// lfs f4,1488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1488);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f1,f4,f15,f1
	ctx.f1.f64 = double(float(-(ctx.f4.f64 * ctx.f15.f64 - ctx.f1.f64)));
	// lfs f4,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f2,f2,f8,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f8.f64 + ctx.f17.f64));
	// lfs f17,1068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1068);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f4,f15
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f15.f64));
	// fnmsubs f4,f6,f13,f3
	ctx.f4.f64 = double(float(-(ctx.f6.f64 * ctx.f13.f64 - ctx.f3.f64)));
	// lfs f6,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f6,188(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmadds f3,f11,f6,f18
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f6.f64 + ctx.f18.f64));
	// fmuls f6,f27,f19
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// fmuls f18,f6,f8
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f6,f24,f31
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// fmadds f1,f6,f17,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f17.f64 + ctx.f1.f64));
	// fmadds f17,f6,f19,f4
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f19.f64 + ctx.f4.f64));
	// lfs f4,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f6,f31,f30
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fmuls f14,f6,f4
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// lfs f4,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f3,f3,f4,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f4.f64 + ctx.f16.f64));
	// lfs f16,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f2,f15,f4,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f4.f64 + ctx.f2.f64));
	// lfs f15,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f4,f26,f19
	ctx.f4.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// fmuls f15,f11,f15
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// fnmsubs f17,f14,f29,f17
	ctx.f17.f64 = double(float(-(ctx.f14.f64 * ctx.f29.f64 - ctx.f17.f64)));
	// fmadds f18,f4,f13,f18
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f18.f64));
	// lfs f4,1532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1532);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f1,f4,f13,f1
	ctx.f1.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// lfs f4,1348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1348);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f16,f16,f4
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// lfs f4,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// stfs f4,80(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f4,f24,f21
	ctx.f4.f64 = double(float(ctx.f24.f64 * ctx.f21.f64));
	// fmuls f15,f15,f31
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// fnmsubs f1,f5,f13,f1
	ctx.f1.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// lfs f5,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f28,f5
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f5.f64));
	// fmadds f2,f11,f4,f2
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f4.f64 + ctx.f2.f64));
	// lfs f4,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f3,f18,f4,f3
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f3.f64));
	// fmuls f4,f26,f25
	ctx.f4.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmuls f18,f6,f5
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f6,f12,f27
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f27.f64));
	// stfs f6,136(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f4,f4,f11
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmadds f4,f4,f13,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f3.f64));
	// stfs f4,4476(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4476, temp.u32);
	// fnmsubs f4,f18,f29,f1
	ctx.f4.f64 = double(float(-(ctx.f18.f64 * ctx.f29.f64 - ctx.f1.f64)));
	// stfs f4,4480(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4480, temp.u32);
	// lfs f4,1436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1436);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f12,f4
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f16,f13,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f14.f64));
	// fmuls f14,f5,f6
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,1356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1356);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f17,f6,f5,f17
	ctx.f17.f64 = double(float(-(ctx.f6.f64 * ctx.f5.f64 - ctx.f17.f64)));
	// lfs f5,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f6,f28,f21
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// fnmsubs f2,f15,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f15,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f3,f14,f13,f16
	ctx.f3.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f3,4484(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4484, temp.u32);
	// lfs f3,1336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1336);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f3,f3,f13,f17
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f17.f64)));
	// stfs f3,4488(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4488, temp.u32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fmuls f6,f15,f6
	ctx.f6.f64 = double(float(ctx.f15.f64 * ctx.f6.f64));
	// fnmsubs f3,f6,f5,f2
	ctx.f3.f64 = double(float(-(ctx.f6.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f6,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f4,f4,f8,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f3.f64));
	// fmuls f6,f6,f25
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// lfs f5,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f5.f64 = double(temp.f32);
	// lfs f14,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f2,f6,f28
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f6,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f1,f6,f31
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// lfs f6,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f18,f6,f31
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// lfs f6,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f6,1180(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1180, temp.u32);
	// fmuls f2,f2,f9
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// fmuls f17,f0,f6
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// fmuls f6,f5,f30
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fmsubs f2,f1,f9,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 - ctx.f2.f64));
	// fmuls f16,f6,f7
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// fmuls f7,f5,f28
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// fmuls f6,f0,f23
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// fmuls f5,f18,f9
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// lfs f9,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f6,f7,f6
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// lfs f7,1688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1688);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f18,f0,f7
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// lfs f7,1696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1696);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f15,f0,f7
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// lfs f7,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// fmsubs f5,f2,f0,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f5.f64));
	// lfs f2,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f16,f7,f14,f16
	ctx.f16.f64 = double(float(ctx.f7.f64 * ctx.f14.f64 + ctx.f16.f64));
	// lfs f7,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f9,f7
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f9,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// lfs f7,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f14,f7,f9
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// lfs f9,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f7,f9,f31
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// lfs f9,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fadds f7,f7,f9
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// lfs f9,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f9,f30
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fmuls f9,f0,f25
	ctx.f9.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmuls f8,f8,f9
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// fmuls f9,f27,f21
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// fmuls f3,f11,f9
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f9,1704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1704);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// lfs f9,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f4,f1,f9,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f4.f64));
	// lfs f9,1080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1080);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f1,f12,f9
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fmuls f9,f0,f23
	ctx.f9.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// fmadds f8,f7,f9,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f9.f64 + ctx.f8.f64));
	// lfs f9,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f7,f17,f10,f5
	ctx.f7.f64 = double(float(-(ctx.f17.f64 * ctx.f10.f64 - ctx.f5.f64)));
	// lfs f17,1524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1524);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f2,f17,f10,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f2.f64));
	// lfs f10,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f4,f3,f10,f4
	ctx.f4.f64 = double(float(-(ctx.f3.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f3,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f5,f12,f9
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// lfs f9,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// lfs f12,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// stfs f9,1188(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1188, temp.u32);
	// fmadds f7,f16,f12,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f7.f64));
	// lfs f12,1680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1680);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f17,f0,f12
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfs f16,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f12,f0,f25
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmuls f9,f0,f9
	ctx.f9.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fmuls f12,f26,f21
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// fmuls f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fnmsubs f11,f1,f10,f4
	ctx.f11.f64 = double(float(-(ctx.f1.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f10,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f10.f64 = double(temp.f32);
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f12,f10,f25
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// fnmsubs f5,f5,f13,f11
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// lfs f11,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f11.f64 = double(temp.f32);
	// lfs f4,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f1,f16,f31
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f31.f64));
	// fmuls f10,f12,f28
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// lfs f12,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f7,f6,f12,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 + ctx.f7.f64));
	// lfs f12,1480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1480);
	ctx.f12.f64 = double(temp.f32);
	// lfs f6,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f12,f6
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// fmuls f12,f26,f25
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmadds f7,f18,f11,f7
	ctx.f7.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 + ctx.f7.f64));
	// lfs f18,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f4,f12,f4
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// lfs f12,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f6,f10,f12,f6
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + ctx.f6.f64));
	// fmadds f10,f3,f13,f5
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f5.f64));
	// lfs f5,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f7,f15,f5,f7
	ctx.f7.f64 = double(float(-(ctx.f15.f64 * ctx.f5.f64 - ctx.f7.f64)));
	// lfs f5,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f5,f5,f13,f10
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// lfs f10,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f7,f14,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f14.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// fmadds f13,f4,f13,f5
	ctx.f13.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f5.f64));
	// stfs f13,4492(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4492, temp.u32);
	// fmadds f13,f8,f10,f7
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f10.f64 + ctx.f7.f64));
	// lfs f10,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f13,f2,f0,f13
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f13.f64));
	// fnmsubs f13,f9,f11,f13
	ctx.f13.f64 = double(float(-(ctx.f9.f64 * ctx.f11.f64 - ctx.f13.f64)));
	// lfs f9,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f13,f17,f11,f13
	ctx.f13.f64 = double(float(-(ctx.f17.f64 * ctx.f11.f64 - ctx.f13.f64)));
	// fnmsubs f13,f1,f10,f13
	ctx.f13.f64 = double(float(-(ctx.f1.f64 * ctx.f10.f64 - ctx.f13.f64)));
	// lfs f10,1636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1636);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f13,f6,f0,f13
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f13.f64));
	// stfs f13,4496(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4496, temp.u32);
	// lfs f13,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// stfs f10,248(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f10,1428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1428);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f13,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f9,f13,f9
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f13,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f8,f13,f11
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f11,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f11,f13
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f13,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f6,f13,f25
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// fmuls f13,f11,f25
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// fmuls f5,f10,f13
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f13,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f10,f13
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f13,1672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1672);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f3,f0,f13
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f13,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f7,f7,f13
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmadds f8,f10,f13,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + ctx.f8.f64));
	// fmuls f10,f18,f25
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f3,f3,f12
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// fmadds f8,f8,f25,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f25.f64 + ctx.f7.f64));
	// fmuls f2,f10,f21
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f21.f64));
	// lfs f10,1664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1664);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f1,f10,f12
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f10,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f17,f10,f22
	ctx.f17.f64 = double(float(ctx.f10.f64 * ctx.f22.f64));
	// fmuls f7,f10,f20
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f20.f64));
	// lfs f10,1656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1656);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f16,f10,f0
	ctx.f16.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f10,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f25
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// fmsubs f4,f4,f13,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 - ctx.f3.f64));
	// lfs f3,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f2,f2,f13,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f1.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f1,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f4,f2,f0,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fmuls f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// lfs f1,1648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1648);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f12,f1,f12
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f2,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,1048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1048);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f10,f10,f21
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f21.f64));
	// fmuls f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// lfs f14,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f25
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// lfs f1,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f3,f3,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f21.f64));
	// fmuls f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// fmadds f13,f11,f13,f12
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f12.f64));
	// lfs f12,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f12,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f12,f16,f12,f4
	ctx.f12.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f4.f64)));
	// lfs f11,1564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1564);
	ctx.f11.f64 = double(temp.f32);
	// lfs f4,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// fmuls f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// lfs f11,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f11.f64 = double(temp.f32);
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f11,f16
	ctx.f16.f64 = double(float(ctx.f11.f64 * ctx.f16.f64));
	// lfs f11,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f11.f64 = double(temp.f32);
	// fmsubs f5,f14,f11,f5
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 - ctx.f5.f64));
	// lfs f11,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f14,f11,f21
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f21.f64));
	// lfs f11,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f0,f0,f25
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fnmsubs f12,f10,f11,f12
	ctx.f12.f64 = double(float(-(ctx.f10.f64 * ctx.f11.f64 - ctx.f12.f64)));
	// lfs f10,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f16,f10
	ctx.f10.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// lfs f16,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f9,f9,f16,f5
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f16.f64 - ctx.f5.f64)));
	// lfs f5,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f13,f13,f5,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f5.f64 + ctx.f12.f64));
	// lfs f12,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f12.f64 = double(temp.f32);
	// fmr f0,f12
	ctx.f0.f64 = ctx.f12.f64;
	// fnmsubs f12,f6,f0,f9
	ctx.f12.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// fnmsubs f9,f2,f11,f13
	ctx.f9.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 - ctx.f13.f64)));
	// lfs f13,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f8,f8,f13,f12
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 + ctx.f12.f64));
	// lfs f12,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f9,f12,f11,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f9.f64));
	// lfs f12,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f8,f17,f12,f8
	ctx.f8.f64 = double(float(-(ctx.f17.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// lfs f17,1668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1668);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f6,f10,f11,f9
	ctx.f6.f64 = double(float(-(ctx.f10.f64 * ctx.f11.f64 - ctx.f9.f64)));
	// lfs f9,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f0,f7,f0,f8
	ctx.f0.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f8.f64)));
	// lfs f7,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f0,f3,f12,f0
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f0.f64));
	// fnmsubs f10,f1,f12,f0
	ctx.f10.f64 = double(float(-(ctx.f1.f64 * ctx.f12.f64 - ctx.f0.f64)));
	// lfs f0,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f10,f15,f0,f10
	ctx.f10.f64 = double(float(-(ctx.f15.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// fnmsubs f10,f4,f0,f10
	ctx.f10.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// fmadds f12,f14,f12,f10
	ctx.f12.f64 = double(float(ctx.f14.f64 * ctx.f12.f64 + ctx.f10.f64));
	// stfs f12,4500(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4500, temp.u32);
	// lfs f12,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f31,f25
	ctx.f10.f64 = double(float(ctx.f31.f64 * ctx.f25.f64));
	// fmuls f4,f12,f28
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// lfs f12,1420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1420);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f3,f13,f12
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// fmuls f12,f28,f25
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f5,f10,f9
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// fmuls f2,f7,f12
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// fmuls f12,f30,f25
	ctx.f12.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// fmuls f5,f5,f13
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmuls f2,f2,f13
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmuls f1,f12,f8
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// fmuls f12,f31,f28
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmuls f7,f12,f7
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f5,f5,f11,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 + ctx.f4.f64));
	// fmadds f1,f10,f16,f1
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f16.f64 + ctx.f1.f64));
	// lfs f15,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f10,f31,f30
	ctx.f10.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fmuls f17,f13,f17
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f17.f64));
	// fmsubs f5,f3,f0,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f5.f64));
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fmuls f16,f10,f8
	ctx.f16.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f8,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f7,f8
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f7,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f15,f10,f15
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f15.f64));
	// lfs f10,1212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1212);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f14,f13,f10
	ctx.f14.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f10,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fnmsubs f5,f2,f11,f5
	ctx.f5.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 - ctx.f5.f64)));
	// lfs f2,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f12,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f4,f24,f9,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 + ctx.f4.f64));
	// fmuls f9,f12,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// lfs f12,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f3,f13,f10
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f10,1412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1412);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f7,f13,f7
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fmadds f5,f1,f11,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 + ctx.f5.f64));
	// fnmsubs f8,f16,f8,f4
	ctx.f8.f64 = double(float(-(ctx.f16.f64 * ctx.f8.f64 - ctx.f4.f64)));
	// lfs f4,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f10,f4,f31
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// lfs f4,1204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1204);
	ctx.f4.f64 = double(temp.f32);
	// lfs f16,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f8,f15,f12,f8
	ctx.f8.f64 = double(float(-(ctx.f15.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// lfs f12,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f12.f64 = double(temp.f32);
	// fadds f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f4.f64));
	// lfs f4,828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 828);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fmuls f4,f13,f4
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// lfs f10,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f1,f10,f30
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f10,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// fnmsubs f9,f17,f0,f5
	ctx.f9.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f5.f64)));
	// lfs f5,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f8,f5,f27,f8
	ctx.f8.f64 = double(float(-(ctx.f5.f64 * ctx.f27.f64 - ctx.f8.f64)));
	// lfs f17,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f5,f12,f13
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fmuls f12,f26,f31
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmuls f12,f24,f30
	ctx.f12.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// fmuls f16,f12,f16
	ctx.f16.f64 = double(float(ctx.f12.f64 * ctx.f16.f64));
	// fnmsubs f12,f10,f11,f6
	ctx.f12.f64 = double(float(-(ctx.f10.f64 * ctx.f11.f64 - ctx.f6.f64)));
	// stfs f12,4504(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4504, temp.u32);
	// fnmsubs f10,f7,f0,f9
	ctx.f10.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// lfs f12,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f9,f12,f26,f8
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f26.f64 + ctx.f8.f64));
	// lfs f8,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f12,f24,f28
	ctx.f12.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// lfs f7,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f10,f14,f0,f10
	ctx.f10.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 + ctx.f10.f64));
	// fmadds f6,f8,f12,f17
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 + ctx.f17.f64));
	// lfs f12,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f9,f24,f12,f9
	ctx.f9.f64 = double(float(-(ctx.f24.f64 * ctx.f12.f64 - ctx.f9.f64)));
	// lfs f8,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f12,f12,f27
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f27.f64));
	// fnmsubs f10,f3,f0,f10
	ctx.f10.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// fmadds f9,f2,f8,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f8.f64 + ctx.f9.f64));
	// fnmsubs f7,f7,f0,f10
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// lfs f10,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f26
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// fsubs f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// fnmsubs f9,f4,f0,f7
	ctx.f9.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// stfs f12,4512(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4512, temp.u32);
	// lfs f10,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f12,f5,f0,f9
	ctx.f12.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 + ctx.f9.f64));
	// fmadds f12,f1,f10,f12
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f12.f64));
	// stfs f12,4508(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4508, temp.u32);
	// fmuls f12,f31,f30
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// lfs f10,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f10.f64 = double(temp.f32);
	// lfs f5,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f15,f24,f18
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f18.f64));
	// lfs f3,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// lfs f7,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f9,f7,f27
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// lfs f4,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f10,f10,f12
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f12,f31,f28
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmadds f7,f7,f26,f15
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64 + ctx.f15.f64));
	// fmsubs f6,f16,f29,f6
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f29.f64 - ctx.f6.f64));
	// lfs f16,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f3,f3,f12,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f10.f64));
	// lfs f10,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f1,f10,f27
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// fmuls f10,f27,f22
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f22.f64));
	// fmuls f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// lfs f12,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f2,f9,f12
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// fmuls f9,f26,f31
	ctx.f9.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fmadds f17,f24,f20,f10
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f20.f64 + ctx.f10.f64));
	// lfs f10,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f25
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// stfs f10,460(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// fmsubs f8,f3,f8,f2
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f8.f64 - ctx.f2.f64));
	// lfs f2,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f14,f9,f10
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f9,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f10,f24,f27
	ctx.f10.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// fmadds f17,f17,f12,f8
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f8.f64));
	// fmuls f8,f24,f26
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f26.f64));
	// fmuls f15,f14,f29
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f29.f64));
	// lfs f14,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f3,f10,f9
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// fmuls f10,f26,f28
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmuls f8,f8,f9
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f9,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f23
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// stfs f9,364(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fmuls f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f29.f64));
	// fmuls f2,f2,f10
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmuls f10,f27,f30
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmsubs f3,f8,f29,f3
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f29.f64 - ctx.f3.f64));
	// lfs f8,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f2,f2,f12,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 - ctx.f15.f64));
	// fmuls f14,f10,f14
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f14.f64));
	// fmuls f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f10,f26,f16
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// lfs f9,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f15,f24,f16
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f16.f64));
	// fnmsubs f6,f14,f12,f6
	ctx.f6.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f6.f64)));
	// fadds f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// lfs f10,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f5,f5,f10,f17
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f10.f64 - ctx.f17.f64)));
	// fmuls f10,f27,f31
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f17,f9,f10
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// fmuls f9,f26,f26
	ctx.f9.f64 = double(float(ctx.f26.f64 * ctx.f26.f64));
	// fmadds f6,f17,f29,f6
	ctx.f6.f64 = double(float(ctx.f17.f64 * ctx.f29.f64 + ctx.f6.f64));
	// fmuls f14,f8,f9
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// fmuls f9,f24,f28
	ctx.f9.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// lfs f8,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f2,f8,f12,f2
	ctx.f2.f64 = double(float(-(ctx.f8.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f8,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// stfs f9,80(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f9,f24,f30
	ctx.f9.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// lfs f8,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f8,f4,f8,f5
	ctx.f8.f64 = double(float(-(ctx.f4.f64 * ctx.f8.f64 - ctx.f5.f64)));
	// lfs f5,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f5,f9,f5
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmuls f9,f26,f28
	ctx.f9.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmadds f1,f1,f12,f8
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 + ctx.f8.f64));
	// lfs f8,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f9,f4
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// fmuls f9,f27,f27
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f27.f64));
	// lfs f17,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f3,f14,f8,f3
	ctx.f3.f64 = double(float(-(ctx.f14.f64 * ctx.f8.f64 - ctx.f3.f64)));
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f20.f64));
	// fmuls f9,f17,f9
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f2,f17,f29,f2
	ctx.f2.f64 = double(float(-(ctx.f17.f64 * ctx.f29.f64 - ctx.f2.f64)));
	// lfs f17,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f5,f10,f17,f5
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f17.f64 + ctx.f5.f64));
	// lfs f10,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f17,f10,f26
	ctx.f17.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// fmadds f10,f4,f12,f6
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f6.f64));
	// stfs f10,4516(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4516, temp.u32);
	// fmuls f10,f27,f18
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// lfs f4,1396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1396);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f6,f24,f22
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// fmadds f9,f9,f8,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 + ctx.f3.f64));
	// stfs f9,4520(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4520, temp.u32);
	// lfs f8,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f9,f5,f29,f2
	ctx.f9.f64 = double(float(ctx.f5.f64 * ctx.f29.f64 + ctx.f2.f64));
	// stfs f9,4524(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4524, temp.u32);
	// lfs f5,1628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1628);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// lfs f4,1548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1548);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f10,f10,f12,f1
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f4,f13,f4
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fmadds f10,f7,f12,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + ctx.f10.f64));
	// lfs f7,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// lfs f7,1404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1404);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f13,f7
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fnmsubs f9,f15,f12,f10
	ctx.f9.f64 = double(float(-(ctx.f15.f64 * ctx.f12.f64 - ctx.f10.f64)));
	// lfs f15,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f10,f26,f20
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// fmuls f8,f8,f11
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// fnmsubs f10,f10,f12,f9
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f12.f64 - ctx.f9.f64)));
	// fmadds f8,f5,f0,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 + ctx.f8.f64));
	// lfs f5,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f9,f17,f12,f10
	ctx.f9.f64 = double(float(-(ctx.f17.f64 * ctx.f12.f64 - ctx.f10.f64)));
	// lfs f10,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f12,f28,f21
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// fmuls f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f10,1556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1556);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmuls f3,f12,f13
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f2,f10,f0
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f10,1064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1064);
	ctx.f10.f64 = double(temp.f32);
	// fadds f1,f10,f12
	ctx.f1.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// lfs f10,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,1136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1136);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f17,f12,f10
	ctx.f17.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f12,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f15,f12,f15
	ctx.f15.f64 = double(float(ctx.f12.f64 * ctx.f15.f64));
	// fmsubs f3,f3,f11,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 - ctx.f2.f64));
	// lfs f11,1388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1388);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f13,f11
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// fmuls f11,f30,f21
	ctx.f11.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// fnmsubs f7,f7,f0,f3
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f3.f64)));
	// lfs f3,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// fmuls f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// fmsubs f5,f1,f10,f17
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 - ctx.f17.f64));
	// lfs f1,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f10,f15,f10
	ctx.f10.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// lfs f15,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f1,f1,f16,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f16.f64 + ctx.f14.f64));
	// lfs f17,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// fmadds f8,f8,f13,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 + ctx.f7.f64));
	// lfs f7,1684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1684);
	ctx.f7.f64 = double(temp.f32);
	// fadds f7,f7,f15
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f15.f64));
	// lfs f15,1544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1544);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmsubs f10,f5,f12,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 - ctx.f10.f64));
	// lfs f5,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f1,f12
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// fmuls f12,f15,f12
	ctx.f12.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfs f15,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fmadds f10,f1,f0,f10
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f14,720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 720);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f7,f7,f13
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmuls f14,f13,f14
	ctx.f14.f64 = double(float(ctx.f13.f64 * ctx.f14.f64));
	// lfs f13,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f8,f4,f0,f8
	ctx.f8.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f8.f64)));
	// lfs f4,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f13,f4
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// lfs f13,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f20,f13
	ctx.f1.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// lfs f13,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f18,f13
	ctx.f13.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f15.f64));
	// fnmsubs f10,f17,f0,f10
	ctx.f10.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// lfs f17,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f17.f64 = double(temp.f32);
	// fmr f13,f17
	ctx.f13.f64 = ctx.f17.f64;
	// fmadds f8,f2,f0,f8
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f8.f64));
	// lfs f2,1380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1380);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f12,f12,f0,f10
	ctx.f12.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// lfs f10,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f2,f13,f2
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f4,f4,f13
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// lfs f13,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f17,f18,f13
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// lfs f13,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f11,f11,f13,f8
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// fnmsubs f10,f6,f10,f9
	ctx.f10.f64 = double(float(-(ctx.f6.f64 * ctx.f10.f64 - ctx.f9.f64)));
	// stfs f10,4528(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4528, temp.u32);
	// fmadds f10,f15,f0,f12
	ctx.f10.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 + ctx.f12.f64));
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f11,f3,f12,f11
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f11.f64));
	// fnmsubs f10,f1,f0,f10
	ctx.f10.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// fnmsubs f12,f5,f12,f11
	ctx.f12.f64 = double(float(-(ctx.f5.f64 * ctx.f12.f64 - ctx.f11.f64)));
	// fmadds f12,f7,f0,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 + ctx.f12.f64));
	// lfs f11,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f11,f11,f0,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f10,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f12,f14,f0,f12
	ctx.f12.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// fnmsubs f9,f17,f0,f11
	ctx.f9.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// lfs f11,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f13,f4,f13,f12
	ctx.f13.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// lfs f12,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f13,f2,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// stfs f13,4532(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4532, temp.u32);
	// fmuls f13,f28,f25
	ctx.f13.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// lfs f2,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f8,f13,f12
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// fmuls f12,f30,f21
	ctx.f12.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// fmuls f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f12,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f25
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// fmuls f6,f12,f11
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f11,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f31,f23
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// stfs f12,4788(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4788, temp.u32);
	// fmuls f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// fmuls f5,f12,f11
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f12,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f4,f12,f25
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// fmuls f12,f30,f25
	ctx.f12.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// fmuls f3,f12,f11
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f12,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f11,f12,f11,f8
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f8.f64));
	// lfs f12,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f12.f64 = double(temp.f32);
	// lfs f8,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f2,f12,f2
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// fmuls f8,f12,f8
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// lfs f12,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f1,f12,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f18,f25
	ctx.f12.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// fmuls f17,f11,f29
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f29.f64));
	// fmuls f11,f22,f25
	ctx.f11.f64 = double(float(ctx.f22.f64 * ctx.f25.f64));
	// fmuls f15,f12,f13
	ctx.f15.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f6,f4,f12,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f6.f64));
	// fmuls f4,f11,f13
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f13,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f11,1540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1540);
	ctx.f11.f64 = double(temp.f32);
	// fmsubs f7,f7,f29,f17
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f29.f64 - ctx.f17.f64));
	// fadds f14,f13,f11
	ctx.f14.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
	// lfs f11,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,1552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1552);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f12,f8,f12,f6
	ctx.f12.f64 = double(float(-(ctx.f8.f64 * ctx.f12.f64 - ctx.f6.f64)));
	// fmuls f17,f13,f11
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f13,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// lfs f8,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f13,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f23
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// stfs f13,364(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fnmsubs f7,f5,f29,f7
	ctx.f7.f64 = double(float(-(ctx.f5.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// fmadds f9,f17,f0,f9
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f9.f64));
	// lfs f17,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f13,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f6,f16,f13
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// lfs f13,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f5,f2,f13,f12
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f12.f64));
	// lfs f12,1372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1372);
	ctx.f12.f64 = double(temp.f32);
	// lfs f2,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f12.f64));
	// fmuls f12,f11,f23
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// fnmsubs f7,f3,f29,f7
	ctx.f7.f64 = double(float(-(ctx.f3.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// lfs f3,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f10,f10,f21
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f21.f64));
	// fnmsubs f9,f6,f0,f9
	ctx.f9.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// fmuls f0,f30,f25
	ctx.f0.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// fnmsubs f6,f15,f13,f5
	ctx.f6.f64 = double(float(-(ctx.f15.f64 * ctx.f13.f64 - ctx.f5.f64)));
	// lfs f5,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f5.f64 = double(temp.f32);
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f12,f17,f12
	ctx.f12.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f17,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f3,f3,f17
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// lfs f17,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f5,f0,f5
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// lfs f0,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f25
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fmuls f0,f20,f25
	ctx.f0.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// fmuls f15,f0,f15
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f15.f64));
	// lfs f0,1620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1620);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f7,f0,f13,f7
	ctx.f7.f64 = double(float(-(ctx.f0.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// lfs f0,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f12,f12,f0,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f9.f64));
	// fmadds f9,f4,f13,f6
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f6.f64));
	// lfs f6,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f6.f64 = double(temp.f32);
	// lfs f4,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f4.f64 = double(temp.f32);
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fmadds f7,f1,f29,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f7.f64));
	// fnmsubs f0,f17,f0,f12
	ctx.f0.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// stfs f0,4536(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4536, temp.u32);
	// lfs f0,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f12,f8,f13,f9
	ctx.f12.f64 = double(float(-(ctx.f8.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// fmuls f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// fnmsubs f12,f10,f29,f12
	ctx.f12.f64 = double(float(-(ctx.f10.f64 * ctx.f29.f64 - ctx.f12.f64)));
	// lfs f10,1196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1196);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f0,f0,f13,f7
	ctx.f0.f64 = double(float(-(ctx.f0.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// fmadds f12,f3,f13,f12
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f12.f64));
	// fmadds f0,f14,f13,f0
	ctx.f0.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 + ctx.f0.f64));
	// fnmsubs f12,f15,f13,f12
	ctx.f12.f64 = double(float(-(ctx.f15.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// stfs f12,4540(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4540, temp.u32);
	// fnmsubs f0,f10,f13,f0
	ctx.f0.f64 = double(float(-(ctx.f10.f64 * ctx.f13.f64 - ctx.f0.f64)));
	// lfs f12,1364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1364);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f15,f30,f28
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmadds f0,f2,f13,f0
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f0.f64));
	// fnmsubs f0,f5,f29,f0
	ctx.f0.f64 = double(float(-(ctx.f5.f64 * ctx.f29.f64 - ctx.f0.f64)));
	// fnmsubs f0,f12,f10,f0
	ctx.f0.f64 = double(float(-(ctx.f12.f64 * ctx.f10.f64 - ctx.f0.f64)));
	// stfs f0,4544(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4544, temp.u32);
	// fmuls f0,f31,f28
	ctx.f0.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// lfs f12,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f15,f31
	ctx.f10.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// fmuls f8,f0,f12
	ctx.f8.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfs f12,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f7,f0,f12
	ctx.f7.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfs f0,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f12,f31,f30
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fmuls f5,f12,f0
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f9,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f8,f6,f15,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f15.f64 + ctx.f8.f64));
	// fmuls f4,f10,f9
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// fmuls f9,f11,f23
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f3,f10,f9
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// fmuls f9,f22,f28
	ctx.f9.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// fmuls f10,f16,f28
	ctx.f10.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// fadds f2,f10,f9
	ctx.f2.f64 = double(float(ctx.f10.f64 + ctx.f9.f64));
	// lfs f10,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f6,f10,f0
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fadds f1,f9,f10
	ctx.f1.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// lfs f10,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f5,f5,f10
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// lfs f10,1532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1532);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f17,f11,f10
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// lfs f10,1356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1356);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f14,f11,f10
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// lfs f10,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f12,f12,f10,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 + ctx.f8.f64));
	// lfs f10,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f7,f10
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// fmuls f4,f4,f9
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f9.f64));
	// fmuls f7,f3,f9
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// lfs f9,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f3,f9,f10
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f9,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f6,f6,f26
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmr f12,f9
	ctx.f12.f64 = ctx.f9.f64;
	// fmuls f9,f28,f21
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// fmsubs f8,f5,f10,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 - ctx.f8.f64));
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// fmsubs f5,f17,f12,f4
	ctx.f5.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f4.f64));
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f9,f9,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// fmsubs f3,f17,f10,f3
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 - ctx.f3.f64));
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fmuls f4,f11,f9
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f9,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f7,f14,f9,f7
	ctx.f7.f64 = double(float(ctx.f14.f64 * ctx.f9.f64 - ctx.f7.f64));
	// lfs f14,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f9,f28,f25
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmadds f3,f3,f15,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f15.f64 + ctx.f2.f64));
	// lfs f2,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f9,f9,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// fmuls f9,f11,f9
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f10,f17,f10,f8
	ctx.f10.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f8.f64));
	// lfs f8,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f8,f27,f8
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// lfs f17,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f5,f4,f17,f5
	ctx.f5.f64 = double(float(-(ctx.f4.f64 * ctx.f17.f64 - ctx.f5.f64)));
	// lfs f4,1660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// lfs f17,1348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1348);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f14.f64));
	// lfs f14,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f26,f14
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f14.f64));
	// fnmsubs f6,f6,f12,f10
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f12.f64 - ctx.f10.f64)));
	// lfs f10,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f9,f9,f10,f7
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// lfs f7,1496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1496);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f11,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fmuls f8,f8,f12
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fnmsubs f5,f4,f10,f5
	ctx.f5.f64 = double(float(-(ctx.f4.f64 * ctx.f10.f64 - ctx.f5.f64)));
	// lfs f4,1488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1488);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// fmadds f6,f1,f12,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 + ctx.f6.f64));
	// lfs f1,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f1,f1,f13,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 - ctx.f17.f64));
	// fnmsubs f9,f7,f10,f9
	ctx.f9.f64 = double(float(-(ctx.f7.f64 * ctx.f10.f64 - ctx.f9.f64)));
	// lfs f7,1336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1336);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f11,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fmsubs f8,f3,f0,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f8.f64));
	// fmuls f11,f18,f28
	ctx.f11.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f3,f2,f26
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// fmadds f10,f4,f10,f5
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f10.f64 + ctx.f5.f64));
	// stfs f10,4552(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4552, temp.u32);
	// lfs f10,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f6,f14,f12,f6
	ctx.f6.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f6.f64)));
	// fmuls f10,f1,f10
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// stfs f10,4556(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4556, temp.u32);
	// fmadds f10,f7,f12,f9
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + ctx.f9.f64));
	// lfs f7,1524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1524);
	ctx.f7.f64 = double(temp.f32);
	// stfs f6,4548(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4548, temp.u32);
	// lfs f6,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f6.f64 = double(temp.f32);
	// stfs f10,4560(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4560, temp.u32);
	// lfs f10,1144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1144);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f5,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f9,f3,f12,f8
	ctx.f9.f64 = double(float(-(ctx.f3.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// lfs f4,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f10,f10,f25
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// lfs f1,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f1.f64 = double(temp.f32);
	// lfs f14,1188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1188);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f8,f11,f31
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// lfs f11,1480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1480);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fnmsubs f9,f8,f12,f9
	ctx.f9.f64 = double(float(-(ctx.f8.f64 * ctx.f12.f64 - ctx.f9.f64)));
	// lfs f8,1680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1680);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f7,f7,f13,f11
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 - ctx.f11.f64));
	// fmuls f11,f30,f21
	ctx.f11.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// fmuls f6,f11,f6
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// fmuls f11,f16,f25
	ctx.f11.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// fmuls f5,f11,f5
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// lfs f11,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f11.f64 = double(temp.f32);
	// fadds f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 + ctx.f4.f64));
	// lfs f11,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f3,f10,f11
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f11,1704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1704);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f28,f21
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// fnmsubs f7,f11,f13,f7
	ctx.f7.f64 = double(float(-(ctx.f11.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// lfs f11,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f4,f4,f17
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// lfs f17,1688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1688);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f5,f5,f13,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 - ctx.f3.f64));
	// lfs f3,1696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1696);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f6,f10,f11,f6
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 + ctx.f6.f64));
	// lfs f11,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f11,f26
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f26.f64));
	// fmuls f11,f31,f30
	ctx.f11.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fnmsubs f7,f14,f13,f7
	ctx.f7.f64 = double(float(-(ctx.f14.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// fadds f3,f3,f17
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f17.f64));
	// lfs f17,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f21
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f21.f64));
	// fmadds f5,f4,f13,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f5.f64));
	// lfs f4,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f2,f14,f27,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 * ctx.f27.f64 + ctx.f2.f64));
	// lfs f14,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f1,f11,f1
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// fnmsubs f8,f8,f13,f7
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// lfs f7,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f11,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fmuls f11,f30,f25
	ctx.f11.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// fmuls f1,f1,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f14.f64));
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f10,f14
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f14.f64));
	// fmuls f10,f18,f25
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// fmadds f8,f6,f29,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f29.f64 + ctx.f8.f64));
	// fmuls f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// fmadds f4,f2,f12,f1
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 + ctx.f1.f64));
	// lfs f2,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f11,f2
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f2.f64));
	// lfs f11,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f5,f17,f11,f5
	ctx.f5.f64 = double(float(-(ctx.f17.f64 * ctx.f11.f64 - ctx.f5.f64)));
	// lfs f1,1528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1528);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f11,f30,f21
	ctx.f11.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// fadds f1,f11,f1
	ctx.f1.f64 = double(float(ctx.f11.f64 + ctx.f1.f64));
	// lfs f11,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// lfs f11,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f25
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// lfs f6,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f5,f10,f13,f5
	ctx.f5.f64 = double(float(-(ctx.f10.f64 * ctx.f13.f64 - ctx.f5.f64)));
	// fmuls f6,f11,f6
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// fmuls f11,f20,f28
	ctx.f11.f64 = double(float(ctx.f20.f64 * ctx.f28.f64));
	// fmadds f8,f3,f13,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f8.f64));
	// fmadds f4,f4,f0,f9
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 + ctx.f9.f64));
	// lfs f9,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f1,f1,f9,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f17.f64));
	// lfs f9,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f6,f6,f29,f5
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f29.f64 - ctx.f5.f64)));
	// fmuls f10,f0,f11
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f10,f22,f25
	ctx.f10.f64 = double(float(ctx.f22.f64 * ctx.f25.f64));
	// fnmsubs f8,f14,f29,f8
	ctx.f8.f64 = double(float(-(ctx.f14.f64 * ctx.f29.f64 - ctx.f8.f64)));
	// fmuls f14,f17,f9
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// lfs f17,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f3,f10,f9
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f10,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f7,f7,f10,f4
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f10,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f10.f64 = double(temp.f32);
	// lfs f4,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f8,f2,f29,f8
	ctx.f8.f64 = double(float(-(ctx.f2.f64 * ctx.f29.f64 - ctx.f8.f64)));
	// fmuls f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f2,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f9,f3,f13,f6
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f6.f64));
	// lfs f6,1180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1180);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fnmsubs f7,f5,f12,f7
	ctx.f7.f64 = double(float(-(ctx.f5.f64 * ctx.f12.f64 - ctx.f7.f64)));
	// stfs f7,4564(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4564, temp.u32);
	// fnmsubs f7,f4,f13,f9
	ctx.f7.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// lfs f5,812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 812);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f9,f1,f29,f8
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f8.f64));
	// lfs f8,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f8.f64 = double(temp.f32);
	// lfs f1,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f4,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// fmadds f9,f6,f8,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f8.f64 + ctx.f9.f64));
	// stfs f9,4568(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4568, temp.u32);
	// fmuls f9,f18,f28
	ctx.f9.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f6,1672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1672);
	ctx.f6.f64 = double(temp.f32);
	// fadds f9,f9,f11
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// lfs f11,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f6,f6,f11
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// fmuls f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f10,1664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1664);
	ctx.f10.f64 = double(temp.f32);
	// fmsubs f6,f10,f11,f6
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 - ctx.f6.f64));
	// lfs f10,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f10,f26
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// fmuls f10,f26,f28
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmuls f9,f9,f13
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f2,f10,f2
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// fmuls f10,f22,f30
	ctx.f10.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// fmsubs f9,f5,f8,f9
	ctx.f9.f64 = double(float(ctx.f5.f64 * ctx.f8.f64 - ctx.f9.f64));
	// lfs f5,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f5.f64 = double(temp.f32);
	// lfs f8,1648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1648);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f10,f10,f1
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f1.f64));
	// lfs f1,1656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1656);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f6,f1,f11,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 + ctx.f6.f64));
	// lfs f11,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// fnmsubs f8,f8,f5,f6
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f5.f64 - ctx.f6.f64)));
	// lfs f6,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f1,f11,f29
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f29.f64));
	// lfs f11,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f3,f11,f27,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f27.f64 + ctx.f3.f64));
	// lfs f11,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// fmuls f6,f6,f18
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// fmuls f17,f11,f17
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f17.f64));
	// lfs f11,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lfs f11,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f23
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f11,f22,f28
	ctx.f11.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// fmadds f5,f11,f13,f1
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f1.f64));
	// lfs f13,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f12,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f1,f13,f29
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// lfs f13,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f9,f4,f13,f9
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f9.f64));
	// lfs f13,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f13,f27
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f27.f64));
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f26.f64));
	// fadds f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// lfs f13,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f4,f3,f13
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfs f13,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f3,f17,f13
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f13,1172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1172);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// stfs f0,136(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f0,f27,f30
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// lfs f13,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f13.f64 = double(temp.f32);
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f8,f17,f29,f8
	ctx.f8.f64 = double(float(-(ctx.f17.f64 * ctx.f29.f64 - ctx.f8.f64)));
	// lfs f17,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f0,f16,f23
	ctx.f0.f64 = double(float(ctx.f16.f64 * ctx.f23.f64));
	// lfs f13,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f10,f10,f13,f9
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// fmadds f9,f0,f17,f6
	ctx.f9.f64 = double(float(ctx.f0.f64 * ctx.f17.f64 + ctx.f6.f64));
	// fmuls f0,f20,f30
	ctx.f0.f64 = double(float(ctx.f20.f64 * ctx.f30.f64));
	// fmadds f9,f9,f29,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f29.f64 + ctx.f8.f64));
	// lfs f8,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f6,f0,f13,f1
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f1.f64));
	// lfs f13,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f4,f4,f13,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f3.f64));
	// lfs f0,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmsubs f4,f11,f13,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 - ctx.f4.f64));
	// lfs f13,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,1640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1640);
	ctx.f11.f64 = double(temp.f32);
	// lfs f3,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f3,f3,f12,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 - ctx.f2.f64));
	// lfs f2,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f1,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f10,f5,f1,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 + ctx.f10.f64));
	// fmuls f5,f14,f23
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f23.f64));
	// lfs f14,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f1,f8,f22
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f22.f64));
	// lfs f8,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f14,f8,f14
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f14.f64));
	// lfs f8,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f10,f6,f13,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f10.f64));
	// lfs f13,824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 824);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f6,f8,f13
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f13,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f3,f2,f13,f3
	ctx.f3.f64 = double(float(-(ctx.f2.f64 * ctx.f13.f64 - ctx.f3.f64)));
	// lfs f2,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// fnmsubs f11,f5,f29,f7
	ctx.f11.f64 = double(float(-(ctx.f5.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// stfs f11,4572(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4572, temp.u32);
	// fnmsubs f11,f1,f29,f9
	ctx.f11.f64 = double(float(-(ctx.f1.f64 * ctx.f29.f64 - ctx.f9.f64)));
	// stfs f11,4576(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4576, temp.u32);
	// lfs f11,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f9,f26,f18
	ctx.f9.f64 = double(float(ctx.f26.f64 * ctx.f18.f64));
	// fmuls f7,f26,f0
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fnmsubs f10,f14,f11,f10
	ctx.f10.f64 = double(float(-(ctx.f14.f64 * ctx.f11.f64 - ctx.f10.f64)));
	// stfs f10,4580(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4580, temp.u32);
	// lfs f10,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f10,f6,f10,f4
	ctx.f10.f64 = double(float(-(ctx.f6.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// stfs f10,4584(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4584, temp.u32);
	// fmadds f12,f2,f12,f3
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 + ctx.f3.f64));
	// stfs f12,4588(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4588, temp.u32);
	// lfs f12,1144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1144);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f18,f30
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// fmuls f6,f12,f28
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// fmuls f12,f27,f18
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// fmuls f5,f12,f13
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f23
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f23.f64));
	// fmuls f4,f12,f10
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f10,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f10.f64 = double(temp.f32);
	// lfs f3,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f2,f27,f16,f9
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f16.f64 + ctx.f9.f64));
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// lfs f10,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f6,f10
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// lfs f9,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f10,f16,f28
	ctx.f10.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// fmuls f7,f7,f22
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f22.f64));
	// fmuls f1,f27,f0
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmsubs f5,f2,f13,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 - ctx.f5.f64));
	// fmsubs f6,f3,f11,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 - ctx.f6.f64));
	// lfs f3,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f4,f9,f10,f4
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f10.f64 + ctx.f4.f64));
	// lfs f10,1072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1072);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f14,f10,f30
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmuls f10,f26,f28
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmuls f7,f7,f13
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmuls f2,f1,f20
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f20.f64));
	// fmadds f6,f4,f11,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 + ctx.f6.f64));
	// lfs f11,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f11.f64 = double(temp.f32);
	// lfs f4,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmuls f10,f28,f17
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// fmsubs f7,f5,f0,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 - ctx.f7.f64));
	// fmuls f5,f3,f11
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// lfs f11,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f3,1176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1176);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f7,f2,f13,f7
	ctx.f7.f64 = double(float(-(ctx.f2.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// lfs f2,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// fnmsubs f6,f14,f2,f6
	ctx.f6.f64 = double(float(-(ctx.f14.f64 * ctx.f2.f64 - ctx.f6.f64)));
	// lfs f14,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f5,f5,f13
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmuls f8,f8,f10
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// lfs f10,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f13,f16,f30
	ctx.f13.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// fmuls f9,f11,f9
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f11,1632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1632);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f4,f4,f11
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmuls f11,f27,f30
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmuls f1,f12,f10
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// fmuls f2,f12,f13
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fmuls f13,f27,f27
	ctx.f13.f64 = double(float(ctx.f27.f64 * ctx.f27.f64));
	// fmuls f12,f26,f26
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f26.f64));
	// fmuls f3,f3,f11
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// fmuls f10,f27,f22
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f22.f64));
	// fmuls f11,f26,f16
	ctx.f11.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// fadds f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fmuls f13,f27,f26
	ctx.f13.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f14,f13,f14
	ctx.f14.f64 = double(float(ctx.f13.f64 * ctx.f14.f64));
	// lfs f13,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f3,f3,f13
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f13,f26,f20
	ctx.f13.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f0,f22,f28
	ctx.f0.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// lfs f13,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f8,f8,f13,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 + ctx.f7.f64));
	// lfs f13,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f7,f1,f29,f6
	ctx.f7.f64 = double(float(-(ctx.f1.f64 * ctx.f29.f64 - ctx.f6.f64)));
	// fmsubs f6,f4,f13,f5
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 - ctx.f5.f64));
	// lfs f13,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f5,f13,f0
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f13,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f27
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f27.f64));
	// lfs f0,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f4,f12,f0
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f0,-11880(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11880);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,220(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f0,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f1,f14,f0
	ctx.f1.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmuls f14,f12,f13
	ctx.f14.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f10,f10,f13,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + ctx.f8.f64));
	// lfs f12,824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 824);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f8,f3,f13,f6
	ctx.f8.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f6.f64)));
	// lfs f13,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f9,f9,f29,f7
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// addi r6,r31,64
	ctx.r6.s64 = ctx.r31.s64 + 64;
	// fmuls f7,f13,f12
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f12,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f18,f28
	ctx.f13.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// addi r5,r29,64
	ctx.r5.s64 = ctx.r29.s64 + 64;
	// addi r4,r1,4288
	ctx.r4.s64 = ctx.r1.s64 + 4288;
	// li r3,9
	ctx.r3.s64 = 9;
	// fmuls f6,f12,f13
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,1064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1064);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f12.f64 = double(temp.f32);
	// fadds f3,f13,f12
	ctx.f3.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// lfs f12,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f12.f64 = double(temp.f32);
	// fmsubs f13,f4,f12,f1
	ctx.f13.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 - ctx.f1.f64));
	// stfs f13,4592(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4592, temp.u32);
	// lfs f13,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f11,f11,f13,f10
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// fnmsubs f10,f2,f0,f9
	ctx.f10.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// lfs f9,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f9,f14,f9,f8
	ctx.f9.f64 = double(float(ctx.f14.f64 * ctx.f9.f64 + ctx.f8.f64));
	// lfs f8,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// stfs f9,4596(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4596, temp.u32);
	// lfs f9,1136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1136);
	ctx.f9.f64 = double(temp.f32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fadds f9,f3,f9
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f9.f64));
	// fmadds f13,f8,f13,f11
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 + ctx.f11.f64));
	// fmadds f11,f5,f0,f10
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f10,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f22,f20
	ctx.f8.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// fnmsubs f13,f7,f10,f13
	ctx.f13.f64 = double(float(-(ctx.f7.f64 * ctx.f10.f64 - ctx.f13.f64)));
	// stfs f13,4600(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4600, temp.u32);
	// fnmsubs f13,f6,f0,f11
	ctx.f13.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// stfs f13,4604(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4604, temp.u32);
	// lfs f13,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f10,f22,f16
	ctx.f10.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// fmuls f13,f14,f13
	ctx.f13.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// lfs f7,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f7.f64 = double(temp.f32);
	// lfs f11,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f11.f64 = double(temp.f32);
	// fadds f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fmuls f9,f18,f20
	ctx.f9.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// fmuls f13,f13,f7
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fmuls f7,f16,f18
	ctx.f7.f64 = double(float(ctx.f16.f64 * ctx.f18.f64));
	// fmadds f13,f11,f12,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f12.f64 + ctx.f13.f64));
	// lfs f12,1552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1552);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f10,f0,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f13.f64));
	// fnmsubs f13,f12,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// lfs f12,1544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1544);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f9,f0,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 + ctx.f13.f64));
	// fnmsubs f13,f8,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f8.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fnmsubs f13,f12,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fnmsubs f0,f7,f0,f13
	ctx.f0.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// stfs f0,4608(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4608, temp.u32);
	// bl 0x82a64ab8
	ctx.lr = 0x82A6A0E4;
	sub_82A64AB8(ctx, base);
	// cmplwi cr6,r28,5
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 5, ctx.xer);
	// bgt cr6,0x82a6a0f0
	if (ctx.cr6.gt) goto loc_82A6A0F0;
	// b 0x82a76e10
	goto loc_82A76E10;
loc_82A6A0F0:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f3,280(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f4,f22,f23
	ctx.f4.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// stfs f4,780(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 780, temp.u32);
	// fmuls f13,f18,f17
	ctx.f13.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// stfs f13,260(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fmuls f11,f20,f19
	ctx.f11.f64 = double(float(ctx.f20.f64 * ctx.f19.f64));
	// stfs f11,1308(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1308, temp.u32);
	// fmuls f7,f16,f17
	ctx.f7.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// stfs f7,364(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// lfd f0,-30176(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -30176);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fsqrts f12,f0
	ctx.f12.f64 = double(float(sqrt(ctx.f0.f64)));
	// lfs f0,1068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1068);
	ctx.f0.f64 = double(temp.f32);
	// stfs f12,1472(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1472, temp.u32);
	// fmuls f10,f16,f0
	ctx.f10.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f2,f11,f0
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f5,f20,f17
	ctx.f5.f64 = double(float(ctx.f20.f64 * ctx.f17.f64));
	// lfd f9,-30168(r11)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r11.u32 + -30168);
	// fsqrts f8,f9
	ctx.f8.f64 = double(float(sqrt(ctx.f9.f64)));
	// fmuls f9,f12,f3
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fmuls f6,f10,f19
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f19.f64));
	// fmuls f1,f13,f28
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// stfs f10,456(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// stfs f5,684(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 684, temp.u32);
	// stfs f8,148(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f9,240(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fmuls f9,f20,f20
	ctx.f9.f64 = double(float(ctx.f20.f64 * ctx.f20.f64));
	// stfs f10,256(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmuls f10,f18,f28
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// stfs f9,208(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fmuls f9,f22,f22
	ctx.f9.f64 = double(float(ctx.f22.f64 * ctx.f22.f64));
	// stfs f9,496(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 496, temp.u32);
	// fmuls f9,f16,f16
	ctx.f9.f64 = double(float(ctx.f16.f64 * ctx.f16.f64));
	// stfs f9,484(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 484, temp.u32);
	// fmuls f9,f18,f18
	ctx.f9.f64 = double(float(ctx.f18.f64 * ctx.f18.f64));
	// stfs f9,512(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// fmuls f9,f18,f0
	ctx.f9.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f9,344(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// fmuls f9,f4,f17
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// stfs f9,80(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f9,f13,f23
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// stfs f9,516(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// fmuls f9,f8,f12
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmuls f12,f22,f28
	ctx.f12.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// stfs f12,416(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fmuls f12,f20,f28
	ctx.f12.f64 = double(float(ctx.f20.f64 * ctx.f28.f64));
	// stfs f12,472(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// fmuls f12,f22,f17
	ctx.f12.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// stfs f12,648(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 648, temp.u32);
	// fmuls f12,f13,f16
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f16.f64));
	// stfs f12,4024(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4024, temp.u32);
	// fmuls f12,f13,f20
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f20.f64));
	// stfs f12,360(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// fmuls f12,f22,f13
	ctx.f12.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// stfs f12,420(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// fmuls f12,f22,f19
	ctx.f12.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// stfs f12,576(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 576, temp.u32);
	// fmuls f12,f16,f28
	ctx.f12.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// stfs f12,264(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fmuls f12,f18,f30
	ctx.f12.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// stfs f12,252(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fmuls f12,f16,f30
	ctx.f12.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// stfs f12,676(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 676, temp.u32);
	// fmuls f12,f22,f30
	ctx.f12.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// stfs f12,184(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fmuls f12,f20,f30
	ctx.f12.f64 = double(float(ctx.f20.f64 * ctx.f30.f64));
	// stfs f12,316(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fmuls f12,f20,f23
	ctx.f12.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// stfs f12,368(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// lfs f12,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f8,f8,f12
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmuls f12,f26,f13
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// stfs f12,4032(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4032, temp.u32);
	// fmuls f12,f7,f20
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f20.f64));
	// stfs f12,2360(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2360, temp.u32);
	// fmuls f12,f6,f23
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f12,2300(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2300, temp.u32);
	// fmuls f12,f2,f23
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// stfs f12,100(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f12,f7,f22
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f22.f64));
	// stfs f12,2124(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2124, temp.u32);
	// fmuls f12,f5,f22
	ctx.f12.f64 = double(float(ctx.f5.f64 * ctx.f22.f64));
	// stfs f12,2024(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2024, temp.u32);
	// fmuls f12,f6,f30
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f12,2540(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2540, temp.u32);
	// lfs f12,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,340(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// lfs f12,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,3880(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3880, temp.u32);
	// lfs f12,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,352(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfs f12,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,2140(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2140, temp.u32);
	// fmuls f12,f4,f14
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f14.f64));
	// stfs f12,2208(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2208, temp.u32);
	// lfs f12,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// lfs f6,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f12,f6
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// stfs f6,1824(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1824, temp.u32);
	// lfs f6,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,4272(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4272, temp.u32);
	// lfs f6,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,3420(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3420, temp.u32);
	// fmuls f6,f28,f17
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// stfs f6,656(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 656, temp.u32);
	// stfs f10,392(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fmuls f10,f26,f5
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// stfs f10,2176(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2176, temp.u32);
	// lfs f10,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// stfs f10,1044(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1044, temp.u32);
	// fmuls f10,f26,f12
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// stfs f10,872(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 872, temp.u32);
	// lfs f10,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// stfs f10,880(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 880, temp.u32);
	// fmuls f10,f26,f7
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// stfs f10,2264(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2264, temp.u32);
	// lfs f10,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f6,f11
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// stfs f6,2492(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2492, temp.u32);
	// fmuls f6,f28,f0
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// stfs f6,200(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fmuls f10,f10,f27
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// stfs f10,2076(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2076, temp.u32);
	// fmuls f10,f27,f30
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// stfs f10,1284(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1284, temp.u32);
	// fmuls f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// stfs f6,2516(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2516, temp.u32);
	// fmuls f6,f1,f19
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// stfs f6,3412(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3412, temp.u32);
	// lfs f6,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f23
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f6,2500(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2500, temp.u32);
	// fmuls f6,f2,f30
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// lfd f2,-30200(r11)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r11.u32 + -30200);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f6,4096(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4096, temp.u32);
	// fmuls f6,f27,f13
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// stfs f6,4212(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4212, temp.u32);
	// fmuls f6,f9,f0
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// stfs f6,568(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 568, temp.u32);
	// fsqrts f2,f2
	ctx.f2.f64 = double(float(sqrt(ctx.f2.f64)));
	// stfs f2,332(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfd f1,-30216(r11)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r11.u32 + -30216);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fsqrts f1,f1
	ctx.f1.f64 = double(float(sqrt(ctx.f1.f64)));
	// stfs f1,388(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fmuls f1,f27,f27
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f27.f64));
	// fmuls f6,f26,f28
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// stfs f1,752(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 752, temp.u32);
	// lfd f1,-30272(r11)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r11.u32 + -30272);
	// fsqrts f1,f1
	ctx.f1.f64 = double(float(sqrt(ctx.f1.f64)));
	// stfs f1,180(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmuls f1,f26,f26
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f26.f64));
	// fmuls f7,f27,f7
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// stfs f1,772(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 772, temp.u32);
	// fmuls f1,f26,f30
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// stfs f7,2084(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2084, temp.u32);
	// fmuls f7,f27,f5
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// stfs f1,372(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f1,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// stfs f1,248(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fmuls f1,f16,f23
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f23.f64));
	// stfs f1,176(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fmuls f1,f26,f17
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// stfs f1,1292(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1292, temp.u32);
	// lfs f1,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// stfs f1,2788(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2788, temp.u32);
	// fmuls f1,f26,f23
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// stfs f1,292(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fmuls f1,f2,f16
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// stfs f1,584(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 584, temp.u32);
	// fmuls f1,f26,f20
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// stfs f1,800(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 800, temp.u32);
	// fmuls f1,f26,f16
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// stfs f7,2288(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2288, temp.u32);
	// stfs f1,832(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 832, temp.u32);
	// fmuls f7,f9,f17
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f17.f64));
	// fmuls f1,f2,f18
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// stfs f7,1128(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1128, temp.u32);
	// stfs f1,712(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 712, temp.u32);
	// fmuls f7,f27,f12
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fmuls f1,f2,f22
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f7,1016(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1016, temp.u32);
	// stfs f1,500(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// fmuls f1,f2,f20
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f20.f64));
	// lfs f7,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f7.f64 = double(temp.f32);
	// stfs f1,776(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 776, temp.u32);
	// fmuls f5,f2,f7
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// fmuls f1,f11,f28
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// stfs f1,1220(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1220, temp.u32);
	// stfs f5,1940(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1940, temp.u32);
	// fmuls f5,f10,f14
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f14.f64));
	// lfs f1,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// stfs f5,2132(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2132, temp.u32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lfs f5,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f5.f64 = double(temp.f32);
	// stfs f1,2224(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2224, temp.u32);
	// fmuls f5,f6,f5
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f1,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f1.f64 = double(temp.f32);
	// stfs f5,1236(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1236, temp.u32);
	// fmuls f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// lfs f5,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f5.f64 = double(temp.f32);
	// stfs f1,2200(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2200, temp.u32);
	// fmuls f1,f6,f5
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// stfs f1,2116(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2116, temp.u32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f10,f1
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f1.f64));
	// stfs f1,1300(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1300, temp.u32);
	// lfs f1,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f7,f1,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// stfs f7,1316(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1316, temp.u32);
	// lfs f7,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f10,f7
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// stfs f7,2148(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2148, temp.u32);
	// lfs f7,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f26,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// stfs f7,2188(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2188, temp.u32);
	// lfs f7,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f26,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// stfs f7,2276(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2276, temp.u32);
	// fmuls f7,f6,f12
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// stfs f7,2284(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2284, temp.u32);
	// fmuls f7,f9,f23
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// stfs f7,760(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 760, temp.u32);
	// fmuls f7,f9,f19
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f19.f64));
	// stfs f7,532(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// lfs f7,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f26,f7
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// stfs f1,2308(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2308, temp.u32);
	// fmuls f7,f27,f7
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// stfs f7,2332(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2332, temp.u32);
	// fmuls f7,f18,f23
	ctx.f7.f64 = double(float(ctx.f18.f64 * ctx.f23.f64));
	// stfs f7,476(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// lfs f7,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f7.f64 = double(temp.f32);
	// lfs f1,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f7,f1
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f1.f64));
	// fmuls f7,f27,f28
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// fmuls f5,f7,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f5,4228(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4228, temp.u32);
	// lfs f5,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f7,4220(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4220, temp.u32);
	// fmuls f7,f15,f12
	ctx.f7.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// stfs f7,840(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 840, temp.u32);
	// lfs f7,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f7.f64 = double(temp.f32);
	// lfs f5,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f7,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f5,4236(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4236, temp.u32);
	// fmuls f7,f7,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f14.f64));
	// stfs f7,3484(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3484, temp.u32);
	// lfs f5,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f5.f64 = double(temp.f32);
	// lfs f7,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f7,3404(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3404, temp.u32);
	// lfs f7,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f7,2772(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2772, temp.u32);
	// fmuls f7,f6,f0
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// lfs f5,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,2156(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2156, temp.u32);
	// lfs f7,1292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1292);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// stfs f7,2228(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2228, temp.u32);
	// lfs f7,2788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2788);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// stfs f7,2908(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2908, temp.u32);
	// lfs f7,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// fmuls f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f7,2828(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2828, temp.u32);
	// fmuls f7,f1,f30
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f7,3556(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3556, temp.u32);
	// lfs f7,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f23
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// lfs f5,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f7,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f5,2780(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2780, temp.u32);
	// lfs f5,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f7,3548(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3548, temp.u32);
	// lfs f7,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// stfs f7,2180(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2180, temp.u32);
	// lfs f7,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// stfs f7,1244(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1244, temp.u32);
	// fmuls f7,f6,f19
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,2164(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2164, temp.u32);
	// lfs f7,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f5,f7,f6
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// stfs f5,2196(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2196, temp.u32);
	// fmuls f5,f27,f28
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// fmuls f1,f5,f12
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// stfs f1,3628(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3628, temp.u32);
	// fmuls f5,f7,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f5,3980(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3980, temp.u32);
	// lfs f5,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f10
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// stfs f5,4144(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4144, temp.u32);
	// lfs f5,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f5,4128(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4128, temp.u32);
	// lfs f5,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f5,2932(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2932, temp.u32);
	// lfs f5,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f10
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// stfs f5,3620(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3620, temp.u32);
	// lfs f5,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f10
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// stfs f5,2916(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2916, temp.u32);
	// lfs f5,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f10
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// stfs f5,3972(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3972, temp.u32);
	// fmuls f5,f7,f15
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f15.f64));
	// stfs f5,524(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// lfs f5,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f5,f26
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// stfs f1,2316(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2316, temp.u32);
	// fmuls f5,f5,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// stfs f5,2292(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2292, temp.u32);
	// lfs f5,1220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1220);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f5,3652(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3652, temp.u32);
	// fmuls f5,f7,f27
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// stfs f5,876(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 876, temp.u32);
	// lfs f5,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f5,f23
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// stfs f1,308(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fmuls f1,f11,f21
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f21.f64));
	// stfs f1,1984(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1984, temp.u32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// stfs f1,80(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f1,f13,f19
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// stfs f1,756(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 756, temp.u32);
	// fmuls f1,f20,f21
	ctx.f1.f64 = double(float(ctx.f20.f64 * ctx.f21.f64));
	// stfs f1,164(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fmuls f1,f22,f25
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f25.f64));
	// stfs f1,108(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmuls f1,f18,f21
	ctx.f1.f64 = double(float(ctx.f18.f64 * ctx.f21.f64));
	// stfs f1,128(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fmuls f1,f20,f0
	ctx.f1.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// stfs f1,560(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 560, temp.u32);
	// fmuls f1,f22,f21
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f21.f64));
	// stfs f1,704(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 704, temp.u32);
	// fmuls f1,f11,f17
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f17.f64));
	// stfs f1,552(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 552, temp.u32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f1,508(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// fmuls f1,f16,f21
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f21.f64));
	// stfs f1,536(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 536, temp.u32);
	// fmuls f1,f18,f25
	ctx.f1.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// stfs f1,792(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 792, temp.u32);
	// fmuls f1,f5,f17
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f17.f64));
	// stfs f1,544(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// fmuls f1,f4,f0
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// stfs f1,216(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fmuls f1,f16,f19
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f19.f64));
	// stfs f1,152(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f1,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// stfs f1,2348(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2348, temp.u32);
	// lfs f1,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// stfs f1,2340(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2340, temp.u32);
	// fmuls f1,f7,f26
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// stfs f1,708(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 708, temp.u32);
	// lfs f1,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,748(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 748, temp.u32);
	// fmuls f1,f26,f4
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// stfs f1,4152(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4152, temp.u32);
	// fmuls f1,f27,f4
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// stfs f1,2980(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2980, temp.u32);
	// lfs f1,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// stfs f1,2844(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2844, temp.u32);
	// fmuls f1,f5,f28
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// fmuls f5,f5,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// fmuls f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// stfs f1,3580(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3580, temp.u32);
	// lfs f1,1220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1220);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f5,f5,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f17.f64));
	// fmuls f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// stfs f1,3948(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3948, temp.u32);
	// lfs f1,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f4
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// stfs f1,2820(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2820, temp.u32);
	// stfs f5,2296(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2296, temp.u32);
	// fmuls f5,f14,f13
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// stfs f5,2040(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2040, temp.u32);
	// lfs f5,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f18
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f18.f64));
	// stfs f5,2056(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2056, temp.u32);
	// fmuls f5,f11,f0
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f5,f5,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f17.f64));
	// stfs f5,2216(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2216, temp.u32);
	// lfs f5,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// stfs f5,2900(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2900, temp.u32);
	// fmuls f5,f4,f16
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f16.f64));
	// stfs f5,3660(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3660, temp.u32);
	// lfs f5,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// stfs f5,2672(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2672, temp.u32);
	// lfs f5,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// stfs f5,3020(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3020, temp.u32);
	// lfs f5,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// stfs f5,3228(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3228, temp.u32);
	// fmuls f5,f4,f18
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f18.f64));
	// stfs f5,2988(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2988, temp.u32);
	// fmuls f5,f4,f20
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f20.f64));
	// stfs f5,3988(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3988, temp.u32);
	// lfs f5,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// stfs f5,2048(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2048, temp.u32);
	// fmuls f5,f18,f19
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// stfs f5,204(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fmuls f5,f18,f20
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// fmuls f1,f5,f30
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f1,4208(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4208, temp.u32);
	// fmuls f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// stfs f5,1252(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1252, temp.u32);
	// fmuls f5,f16,f20
	ctx.f5.f64 = double(float(ctx.f16.f64 * ctx.f20.f64));
	// fmuls f1,f16,f20
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f20.f64));
	// fmuls f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// stfs f5,2032(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2032, temp.u32);
	// fmuls f5,f22,f20
	ctx.f5.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,2804(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2804, temp.u32);
	// lfs f1,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f5,3940(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3940, temp.u32);
	// fmuls f5,f18,f16
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f5,1840(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1840, temp.u32);
	// fmuls f5,f22,f16
	ctx.f5.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f5,3564(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3564, temp.u32);
	// fmuls f5,f22,f18
	ctx.f5.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f5,2836(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2836, temp.u32);
	// lfs f5,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// stfs f5,3304(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3304, temp.u32);
	// lfs f1,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f1.f64 = double(temp.f32);
	// lfs f5,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// stfs f5,2860(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2860, temp.u32);
	// lfs f5,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f25
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// stfs f5,3960(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3960, temp.u32);
	// lfs f5,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f25
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// stfs f5,3904(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3904, temp.u32);
	// lfs f5,1984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1984);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// stfs f5,3936(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3936, temp.u32);
	// lfs f5,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// stfs f5,2944(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2944, temp.u32);
	// lfs f5,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f5.f64 = double(temp.f32);
	// lfs f1,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// stfs f5,3976(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3976, temp.u32);
	// lfs f5,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// stfs f5,3992(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3992, temp.u32);
	// lfs f5,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f5.f64 = double(temp.f32);
	// lfs f1,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// stfs f1,3968(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3968, temp.u32);
	// lfs f1,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f4
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// stfs f1,3928(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3928, temp.u32);
	// lfs f1,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f7,f1,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// stfs f7,3896(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3896, temp.u32);
	// lfs f7,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f3,f17
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// fmuls f7,f7,f25
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// stfs f7,3944(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3944, temp.u32);
	// lfs f7,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f21
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f21.f64));
	// stfs f7,3920(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3920, temp.u32);
	// lfs f7,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// stfs f12,3848(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3848, temp.u32);
	// lfs f7,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f7.f64 = double(temp.f32);
	// lfs f12,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// stfs f12,3888(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3888, temp.u32);
	// lfs f12,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f21
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// stfs f12,2384(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2384, temp.u32);
	// lfs f12,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f25
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// stfs f12,3872(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3872, temp.u32);
	// lfs f7,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f7.f64 = double(temp.f32);
	// lfs f12,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// stfs f12,2696(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2696, temp.u32);
	// lfs f12,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f1,336(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// stfs f12,4008(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4008, temp.u32);
	// fmuls f1,f27,f23
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// lfs f12,1984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1984);
	ctx.f12.f64 = double(temp.f32);
	// stfs f1,320(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// lfs f7,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f7.f64 = double(temp.f32);
	// lfs f1,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f1.f64 = double(temp.f32);
	// stfs f12,4016(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4016, temp.u32);
	// fmuls f1,f1,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// fmuls f12,f2,f7
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// stfs f1,528(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 528, temp.u32);
	// fmuls f7,f4,f21
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// stfs f7,296(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f7,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f25
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// stfs f7,1812(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1812, temp.u32);
	// fmuls f7,f13,f25
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// stfs f7,1004(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1004, temp.u32);
	// fmuls f7,f3,f0
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// stfs f7,616(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 616, temp.u32);
	// fmuls f7,f27,f19
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// stfs f7,80(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f7,f26,f25
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// stfs f7,572(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 572, temp.u32);
	// fmuls f7,f27,f25
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// stfs f7,652(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 652, temp.u32);
	// fmuls f7,f10,f31
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// stfs f7,136(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f7,f22,f31
	ctx.f7.f64 = double(float(ctx.f22.f64 * ctx.f31.f64));
	// stfs f7,1056(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1056, temp.u32);
	// fmuls f7,f22,f0
	ctx.f7.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f7,988(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 988, temp.u32);
	// fmuls f7,f16,f25
	ctx.f7.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// stfs f7,492(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// lfs f7,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,3912(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3912, temp.u32);
	// fmuls f7,f5,f30
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f7,1536(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1536, temp.u32);
	// fmuls f7,f18,f31
	ctx.f7.f64 = double(float(ctx.f18.f64 * ctx.f31.f64));
	// stfs f7,3384(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3384, temp.u32);
	// stfs f12,972(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 972, temp.u32);
	// fmuls f7,f5,f28
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// stfs f7,1080(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1080, temp.u32);
	// lfs f7,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,4000(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4000, temp.u32);
	// lfs f7,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,3952(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3952, temp.u32);
	// fmuls f7,f5,f27
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// stfs f7,1620(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1620, temp.u32);
	// fmuls f7,f28,f25
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// stfs f7,172(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,1108(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1108, temp.u32);
	// fmuls f7,f3,f21
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f21.f64));
	// stfs f7,1076(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1076, temp.u32);
	// lfs f7,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,3432(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3432, temp.u32);
	// fmuls f7,f3,f16
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f16.f64));
	// stfs f7,680(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 680, temp.u32);
	// fmuls f7,f28,f21
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// stfs f7,232(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,1116(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1116, temp.u32);
	// fmuls f7,f3,f18
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// stfs f7,1280(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1280, temp.u32);
	// lfs f7,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,2204(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2204, temp.u32);
	// lfs f7,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1120(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1120, temp.u32);
	// lfs f7,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,4796(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4796, temp.u32);
	// lfs f7,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1588(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1588, temp.u32);
	// lfs f7,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1644(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1644, temp.u32);
	// lfs f7,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1248(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1248, temp.u32);
	// fmuls f7,f5,f26
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// stfs f7,1364(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1364, temp.u32);
	// lfs f7,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// stfs f7,1296(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1296, temp.u32);
	// fmuls f7,f3,f13
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// stfs f7,692(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 692, temp.u32);
	// lfs f7,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// stfs f7,4188(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4188, temp.u32);
	// lfs f7,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// stfs f7,4040(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4040, temp.u32);
	// lfs f7,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,804(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 804, temp.u32);
	// lfs f7,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f5,f7,f28
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// stfs f5,1336(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1336, temp.u32);
	// fmuls f5,f7,f30
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f5,460(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// fmuls f5,f28,f23
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// stfs f5,436(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// fmuls f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// stfs f5,1088(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1088, temp.u32);
	// fmuls f5,f7,f26
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// stfs f5,3472(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3472, temp.u32);
	// fmuls f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// stfs f7,3488(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3488, temp.u32);
	// lfs f7,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f7.f64 = double(temp.f32);
	// lfs f5,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// stfs f7,3416(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3416, temp.u32);
	// fmuls f5,f5,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f7,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f7.f64 = double(temp.f32);
	// stfs f5,3424(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3424, temp.u32);
	// fmuls f5,f7,f19
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f19.f64));
	// fmuls f7,f7,f23
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// stfs f7,1144(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1144, temp.u32);
	// fmuls f7,f12,f17
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f7,732(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 732, temp.u32);
	// lfs f7,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// stfs f7,3984(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3984, temp.u32);
	// lfs f7,1812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1812);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,4772(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4772, temp.u32);
	// lfs f7,1004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1004);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// stfs f7,1856(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1856, temp.u32);
	// lfs f7,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f19.f64));
	// stfs f7,860(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 860, temp.u32);
	// lfs f7,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f7.f64 = double(temp.f32);
	// stfs f5,464(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// fmuls f5,f31,f30
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1096(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1096, temp.u32);
	// fmuls f7,f12,f0
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f7,236(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fmuls f12,f12,f21
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// stfs f12,728(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 728, temp.u32);
	// lfs f12,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// stfs f12,1980(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1980, temp.u32);
	// lfs f7,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f7.f64 = double(temp.f32);
	// lfs f12,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// stfs f12,600(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// fmuls f12,f26,f19
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// fmuls f7,f5,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// stfs f7,820(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 820, temp.u32);
	// lfs f7,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,852(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 852, temp.u32);
	// lfs f7,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,696(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 696, temp.u32);
	// lfs f7,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// stfs f7,4140(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4140, temp.u32);
	// fmuls f7,f12,f31
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f7,1152(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1152, temp.u32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// stfs f12,2256(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2256, temp.u32);
	// lfs f12,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f12,4132(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4132, temp.u32);
	// fmuls f12,f1,f17
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// stfs f12,1228(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1228, temp.u32);
	// fmuls f12,f27,f28
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// lfs f7,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f5,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// stfs f7,580(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 580, temp.u32);
	// lfs f7,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// stfs f7,4180(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4180, temp.u32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1276(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1276, temp.u32);
	// fmuls f12,f1,f0
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// stfs f12,764(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 764, temp.u32);
	// fmuls f12,f11,f23
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// stfs f12,836(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 836, temp.u32);
	// fmuls f12,f4,f19
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// stfs f12,376(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fmuls f12,f6,f23
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f12,520(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// fmuls f12,f26,f21
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// stfs f12,632(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 632, temp.u32);
	// fmuls f12,f3,f23
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// stfs f12,948(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 948, temp.u32);
	// fmuls f12,f11,f25
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// stfs f12,2352(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2352, temp.u32);
	// fmuls f12,f4,f25
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f25.f64));
	// stfs f12,892(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 892, temp.u32);
	// lfs f12,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f21
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// stfs f12,2160(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2160, temp.u32);
	// lfs f7,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f12,f13,f21
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,700(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 700, temp.u32);
	// lfs f7,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// stfs f7,4056(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4056, temp.u32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// lfs f7,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f1.f64));
	// stfs f7,612(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 612, temp.u32);
	// fmuls f1,f10,f31
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// stfs f12,900(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 900, temp.u32);
	// fmuls f12,f20,f25
	ctx.f12.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// stfs f12,396(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// fmuls f12,f6,f31
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// stfs f7,4156(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4156, temp.u32);
	// lfs f7,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f19.f64));
	// stfs f7,668(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 668, temp.u32);
	// fmuls f7,f1,f19
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// stfs f7,4172(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4172, temp.u32);
	// lfs f7,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// stfs f7,4124(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4124, temp.u32);
	// lfs f7,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f23
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// stfs f12,4148(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4148, temp.u32);
	// stfs f7,1092(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1092, temp.u32);
	// fmuls f7,f27,f17
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f17.f64));
	// lfs f12,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f12.f64 = double(temp.f32);
	// stfs f7,644(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 644, temp.u32);
	// fmuls f7,f12,f18
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f18.f64));
	// stfs f7,824(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 824, temp.u32);
	// fmuls f7,f15,f31
	ctx.f7.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// stfs f7,2212(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2212, temp.u32);
	// fmuls f7,f12,f19
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f19.f64));
	// stfs f7,428(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// lfs f7,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// stfs f7,1736(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1736, temp.u32);
	// lfs f7,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// stfs f7,1880(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1880, temp.u32);
	// fmuls f7,f12,f23
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f23.f64));
	// stfs f7,816(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 816, temp.u32);
	// fmuls f7,f12,f20
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f20.f64));
	// stfs f7,1744(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1744, temp.u32);
	// fmuls f12,f12,f16
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f16.f64));
	// stfs f12,312(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fmuls f12,f3,f19
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// stfs f12,1100(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1100, temp.u32);
	// lfs f12,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,3496(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3496, temp.u32);
	// fmuls f12,f3,f25
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// stfs f12,1168(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1168, temp.u32);
	// fmuls f12,f3,f22
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// stfs f12,1104(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1104, temp.u32);
	// fmuls f12,f3,f20
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// stfs f12,604(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 604, temp.u32);
	// fmuls f12,f18,f28
	ctx.f12.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f7,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// stfs f7,4204(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4204, temp.u32);
	// lfs f7,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// stfs f7,1428(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1428, temp.u32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1460(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1460, temp.u32);
	// lfs f12,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,3504(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3504, temp.u32);
	// fmuls f12,f3,f11
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// stfs f12,1160(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1160, temp.u32);
	// fmuls f12,f3,f4
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// stfs f12,1444(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1444, temp.u32);
	// lfs f12,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,4268(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4268, temp.u32);
	// lfs f12,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// stfs f12,620(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 620, temp.u32);
	// lfs f12,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// stfs f12,1580(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1580, temp.u32);
	// lfs f12,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,4260(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4260, temp.u32);
	// lfs f12,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f13,3844(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3844, temp.u32);
	// lfs f13,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f13,f31
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// stfs f12,4244(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4244, temp.u32);
	// lfs f12,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f13,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// fmuls f7,f12,f31
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f7,4252(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4252, temp.u32);
	// fmuls f7,f6,f17
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// stfs f13,4284(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4284, temp.u32);
	// fmuls f12,f12,f25
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// stfs f12,3356(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3356, temp.u32);
	// lfs f12,1812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1812);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,2436(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2436, temp.u32);
	// lfs f12,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f21
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// stfs f12,4184(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4184, temp.u32);
	// lfs f12,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,4108(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4108, temp.u32);
	// fmuls f7,f6,f21
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,4048(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4048, temp.u32);
	// lfs f7,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,4116(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4116, temp.u32);
	// fmuls f7,f6,f25
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,4164(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4164, temp.u32);
	// lfs f7,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,1564(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1564, temp.u32);
	// lfs f7,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f10,f7
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// stfs f7,1816(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1816, temp.u32);
	// lfs f7,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// stfs f7,588(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 588, temp.u32);
	// lfs f7,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1272(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1272, temp.u32);
	// lfs f7,2352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2352);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,4776(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4776, temp.u32);
	// lfs f7,892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 892);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// stfs f7,4784(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4784, temp.u32);
	// lfs f7,2160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2160);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,4800(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4800, temp.u32);
	// lfs f7,900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 900);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// stfs f7,4780(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4780, temp.u32);
	// lfs f7,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// stfs f12,4276(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4276, temp.u32);
	// lfs f7,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f7.f64 = double(temp.f32);
	// lfs f12,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// stfs f12,2420(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2420, temp.u32);
	// lfs f7,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f7.f64 = double(temp.f32);
	// lfs f12,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// stfs f12,3380(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3380, temp.u32);
	// lfs f12,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f12.f64 = double(temp.f32);
	// lfs f7,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// stfs f12,2396(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2396, temp.u32);
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f13,2412(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2412, temp.u32);
	// lfs f12,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f13,4080(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4080, temp.u32);
	// lfs f12,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f13,2404(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2404, temp.u32);
	// lfs f13,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f21
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// stfs f13,2428(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2428, temp.u32);
	// lfs f12,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f13,4072(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4072, temp.u32);
	// lfs f13,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f21
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// stfs f13,3364(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3364, temp.u32);
	// lfs f13,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f21
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// lfs f7,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// stfs f13,3372(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3372, temp.u32);
	// fmuls f13,f7,f17
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f17.f64));
	// stfs f13,548(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 548, temp.u32);
	// fmuls f13,f7,f19
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f19.f64));
	// stfs f13,608(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 608, temp.u32);
	// fmuls f13,f7,f23
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// lfs f12,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// stfs f13,796(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 796, temp.u32);
	// fmuls f13,f12,f23
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f23.f64));
	// stfs f13,736(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 736, temp.u32);
	// fmuls f13,f12,f19
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f19.f64));
	// stfs f13,540(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 540, temp.u32);
	// fmuls f13,f12,f17
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f13,788(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 788, temp.u32);
	// fmuls f13,f7,f0
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// stfs f13,980(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 980, temp.u32);
	// fmuls f13,f12,f0
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f13,1448(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1448, temp.u32);
	// lfs f13,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f13,3396(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3396, temp.u32);
	// lfs f13,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f13,2468(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2468, temp.u32);
	// lfs f13,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// stfs f13,3388(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3388, temp.u32);
	// fmuls f13,f9,f21
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f21.f64));
	// stfs f13,2600(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2600, temp.u32);
	// lfs f13,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f13,3860(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3860, temp.u32);
	// lfs f13,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// stfs f13,2220(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2220, temp.u32);
	// lfs f13,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f13,2616(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2616, temp.u32);
	// fmuls f13,f9,f16
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f16.f64));
	// stfs f13,1052(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1052, temp.u32);
	// lfs f13,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f7
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// stfs f13,3852(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3852, temp.u32);
	// lfs f13,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f23
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// stfs f13,2364(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2364, temp.u32);
	// fmuls f13,f3,f28
	ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// stfs f13,1504(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1504, temp.u32);
	// lfs f13,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f13,2252(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2252, temp.u32);
	// lfs f13,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f13,1328(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1328, temp.u32);
	// lfs f13,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// stfs f13,1912(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1912, temp.u32);
	// fmuls f13,f4,f30
	ctx.f13.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// stfs f13,848(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 848, temp.u32);
	// lfs f13,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f13,2260(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2260, temp.u32);
	// lfs f13,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// stfs f13,1728(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1728, temp.u32);
	// fmuls f13,f11,f30
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// stfs f13,2028(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2028, temp.u32);
	// lfs f13,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f13,f30
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f11,2268(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2268, temp.u32);
	// lfs f11,1076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1076);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmuls f11,f11,f19
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// stfs f11,1372(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1372, temp.u32);
	// lfs f11,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f25
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// stfs f11,1452(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1452, temp.u32);
	// lfs f11,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// stfs f11,740(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 740, temp.u32);
	// lfs f11,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// stfs f11,2508(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2508, temp.u32);
	// lfs f11,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// stfs f11,2236(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2236, temp.u32);
	// lfs f11,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f23
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// stfs f11,3436(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3436, temp.u32);
	// lfs f11,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f19
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// stfs f11,4192(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4192, temp.u32);
	// lfs f11,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// stfs f11,1920(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1920, temp.u32);
	// lfs f11,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// stfs f11,2244(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2244, temp.u32);
	// lfs f11,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// stfs f11,812(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 812, temp.u32);
	// lfs f11,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f17
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f17.f64));
	// stfs f11,2484(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2484, temp.u32);
	// lfs f11,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f14
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f14.f64));
	// stfs f11,2532(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2532, temp.u32);
	// lfs f11,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f15
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// stfs f13,2612(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2612, temp.u32);
	// stfs f11,4240(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4240, temp.u32);
	// fmuls f13,f24,f23
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f11,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f11.f64 = double(temp.f32);
	// stfs f13,504(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// fmuls f11,f11,f15
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// lfs f13,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f13.f64 = double(temp.f32);
	// stfs f11,3876(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3876, temp.u32);
	// fmuls f11,f22,f13
	ctx.f11.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmuls f13,f20,f13
	ctx.f13.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// stfs f13,2452(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2452, temp.u32);
	// lfs f13,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f23
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// stfs f13,2592(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2592, temp.u32);
	// lfs f13,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f13.f64 = double(temp.f32);
	// stfs f11,2460(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2460, temp.u32);
	// fmuls f11,f13,f28
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f13,1520(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1520, temp.u32);
	// stfs f11,1332(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1332, temp.u32);
	// lfs f13,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// stfs f13,2476(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2476, temp.u32);
	// lfs f13,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// stfs f13,2012(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2012, temp.u32);
	// lfs f13,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f13,f28
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// stfs f11,1876(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1876, temp.u32);
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f13,1264(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1264, temp.u32);
	// lfs f13,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f15,f13
	ctx.f13.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// stfs f13,2548(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2548, temp.u32);
	// lfs f13,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// lfs f11,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f11.f64 = double(temp.f32);
	// stfs f13,2596(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2596, temp.u32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfs f13,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f13.f64 = double(temp.f32);
	// stfs f11,2044(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2044, temp.u32);
	// fmuls f11,f27,f13
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// fmuls f13,f26,f13
	ctx.f13.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// stfs f13,2572(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2572, temp.u32);
	// lfs f13,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// stfs f13,2524(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2524, temp.u32);
	// lfs f13,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f13,3892(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3892, temp.u32);
	// fmuls f13,f30,f25
	ctx.f13.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// stfs f13,664(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 664, temp.u32);
	// stfs f11,3444(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3444, temp.u32);
	// lfs f11,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// stfs f13,1312(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1312, temp.u32);
	// lfs f13,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f13,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// stfs f11,3884(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3884, temp.u32);
	// lfs f11,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// stfs f11,1040(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1040, temp.u32);
	// lfs f11,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f15,f11
	ctx.f11.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// stfs f11,2580(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2580, temp.u32);
	// lfs f11,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// stfs f13,3468(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3468, temp.u32);
	// lfs f13,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f27,f13
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// stfs f11,3452(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3452, temp.u32);
	// fmuls f13,f26,f13
	ctx.f13.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// stfs f13,3428(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3428, temp.u32);
	// lfs f13,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f13,188(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f13,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// lfs f11,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f11.f64 = double(temp.f32);
	// stfs f13,2588(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2588, temp.u32);
	// fmuls f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// lfs f13,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f13.f64 = double(temp.f32);
	// stfs f11,3644(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3644, temp.u32);
	// fmuls f13,f14,f13
	ctx.f13.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// lfs f11,1448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1448);
	ctx.f11.f64 = double(temp.f32);
	// stfs f13,2556(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2556, temp.u32);
	// fmuls f11,f15,f11
	ctx.f11.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// lfs f13,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f13.f64 = double(temp.f32);
	// stfs f11,2620(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2620, temp.u32);
	// fmuls f11,f13,f3
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fmuls f13,f24,f30
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// stfs f13,468(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// fmuls f13,f27,f21
	ctx.f13.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// stfs f13,1084(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1084, temp.u32);
	// fmuls f13,f24,f17
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f17.f64));
	// stfs f13,272(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f13,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f20
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f20.f64));
	// stfs f13,2380(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2380, temp.u32);
	// lfs f13,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f14
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f14.f64));
	// stfs f13,4104(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4104, temp.u32);
	// lfs f13,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f13,2564(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2564, temp.u32);
	// lfs f13,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f13.f64 = double(temp.f32);
	// stfs f11,380(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f13,3460(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3460, temp.u32);
	// fmuls f13,f31,f25
	ctx.f13.f64 = double(float(ctx.f31.f64 * ctx.f25.f64));
	// stfs f13,212(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fmuls f13,f15,f13
	ctx.f13.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// stfs f13,1060(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1060, temp.u32);
	// fmuls f13,f26,f31
	ctx.f13.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// stfs f13,1304(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1304, temp.u32);
	// lfs f13,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// stfs f13,3476(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3476, temp.u32);
	// fmuls f13,f27,f31
	ctx.f13.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// stfs f13,1288(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1288, temp.u32);
	// fmuls f13,f24,f28
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// stfs f13,1192(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1192, temp.u32);
	// lfs f13,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f13,2628(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2628, temp.u32);
	// fmuls f13,f1,f21
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// stfs f13,2636(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2636, temp.u32);
	// lfs f13,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f24,f13
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// stfs f13,3900(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3900, temp.u32);
	// lfs f13,1292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1292);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// stfs f13,2644(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2644, temp.u32);
	// lfs f13,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// stfs f13,2660(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2660, temp.u32);
	// fmuls f13,f1,f25
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// stfs f13,3492(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3492, temp.u32);
	// lfs f13,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// stfs f13,2668(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2668, temp.u32);
	// lfs f13,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// stfs f13,3908(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3908, temp.u32);
	// lfs f13,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f5
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// stfs f13,2676(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2676, temp.u32);
	// fmuls f13,f2,f12
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f13,1712(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1712, temp.u32);
	// fmuls f13,f2,f7
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// stfs f13,2928(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2928, temp.u32);
	// lfs f13,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// stfs f13,2684(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2684, temp.u32);
	// lfs f13,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// stfs f13,2708(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2708, temp.u32);
	// lfs f13,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f13,4120(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4120, temp.u32);
	// lfs f13,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f13,3532(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3532, temp.u32);
	// lfs f13,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f15
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f15.f64));
	// stfs f13,3524(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3524, temp.u32);
	// lfs f13,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f13,2748(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2748, temp.u32);
	// lfs f13,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f15
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f15.f64));
	// stfs f13,1760(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1760, temp.u32);
	// lfs f13,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f15,f13
	ctx.f13.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// stfs f13,1832(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1832, temp.u32);
	// lfs f13,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f14,f13
	ctx.f13.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// stfs f13,2692(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2692, temp.u32);
	// lfs f13,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f13,3516(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3516, temp.u32);
	// lfs f13,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// stfs f13,3540(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3540, temp.u32);
	// lfs f13,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f13.f64 = double(temp.f32);
	// lfs f1,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f13,f13,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// stfs f13,2716(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2716, temp.u32);
	// lfs f13,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f27,f13
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// stfs f1,2740(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2740, temp.u32);
	// fmuls f13,f26,f13
	ctx.f13.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// stfs f13,3924(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3924, temp.u32);
	// lfs f13,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// lfs f1,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f1.f64 = double(temp.f32);
	// stfs f13,2732(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2732, temp.u32);
	// fmuls f13,f26,f1
	ctx.f13.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// stfs f13,1896(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1896, temp.u32);
	// fmuls f13,f30,f21
	ctx.f13.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// stfs f13,284(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// stfs f13,2972(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2972, temp.u32);
	// fmuls f13,f27,f1
	ctx.f13.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// stfs f13,2724(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2724, temp.u32);
	// lfs f13,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f15,f13
	ctx.f13.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// stfs f13,4264(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4264, temp.u32);
	// lfs f13,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f15,f13
	ctx.f13.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// stfs f13,2756(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2756, temp.u32);
	// fmuls f13,f2,f11
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lfs f2,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f11,f2,f11
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lfs f1,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1136(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1136, temp.u32);
	// fmuls f2,f26,f12
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lfs f1,1084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1084);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,4112(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4112, temp.u32);
	// fmuls f2,f24,f20
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f20.f64));
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,2652(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2652, temp.u32);
	// lfs f2,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// stfs f2,1064(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1064, temp.u32);
	// fmuls f2,f24,f18
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f18.f64));
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,4200(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4200, temp.u32);
	// fmuls f2,f7,f30
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// fmuls f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// stfs f2,2700(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2700, temp.u32);
	// fmuls f2,f24,f22
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,3508(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3508, temp.u32);
	// lfs f2,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2764(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2764, temp.u32);
	// lfs f2,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,3932(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3932, temp.u32);
	// lfs f2,1292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1292);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,3916(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3916, temp.u32);
	// lfs f2,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,724(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 724, temp.u32);
	// fmuls f2,f3,f7
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// stfs f2,1176(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1176, temp.u32);
	// lfs f2,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f30
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f1,2108(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2108, temp.u32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,1544(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1544, temp.u32);
	// lfs f2,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1072(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1072, temp.u32);
	// lfs f2,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1512(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1512, temp.u32);
	// lfs f2,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// lfs f1,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f1.f64 = double(temp.f32);
	// stfs f2,1892(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1892, temp.u32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// lfs f2,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f2.f64 = double(temp.f32);
	// stfs f1,1884(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1884, temp.u32);
	// fmuls f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f2,2852(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2852, temp.u32);
	// fmuls f2,f13,f0
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f2,2924(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2924, temp.u32);
	// lfs f1,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1752(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1752, temp.u32);
	// lfs f2,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3500(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3500, temp.u32);
	// fmuls f2,f13,f19
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// stfs f2,300(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f2,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,768(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 768, temp.u32);
	// fmuls f2,f2,f3
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// stfs f2,1132(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1132, temp.u32);
	// fmuls f2,f7,f25
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// stfs f2,636(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 636, temp.u32);
	// fmuls f1,f12,f25
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// stfs f1,624(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 624, temp.u32);
	// fmuls f2,f20,f7
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// stfs f2,884(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 884, temp.u32);
	// lfs f2,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f7,f21
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f21.f64));
	// stfs f1,408(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// fmuls f1,f2,f17
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// fmuls f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// stfs f2,440(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// lfs f2,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// stfs f2,4136(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4136, temp.u32);
	// lfs f2,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1900(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1900, temp.u32);
	// lfs f2,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,1320(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1320, temp.u32);
	// lfs f2,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// stfs f2,3408(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3408, temp.u32);
	// lfs f2,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,3208(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3208, temp.u32);
	// stfs f1,384(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// lfs f1,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3612(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3612, temp.u32);
	// lfs f2,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// stfs f2,4248(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4248, temp.u32);
	// lfs f2,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f7
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// stfs f1,2884(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2884, temp.u32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,2868(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2868, temp.u32);
	// lfs f2,1004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1004);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,2892(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2892, temp.u32);
	// lfs f2,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,2876(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2876, temp.u32);
	// lfs f2,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,3216(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3216, temp.u32);
	// lfs f2,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,3604(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3604, temp.u32);
	// lfs f2,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,3240(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3240, temp.u32);
	// lfs f2,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// stfs f2,3232(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3232, temp.u32);
	// fmuls f2,f12,f21
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// stfs f2,744(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 744, temp.u32);
	// lfs f1,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,1216(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1216, temp.u32);
	// lfs f1,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1224(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1224, temp.u32);
	// lfs f1,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// stfs f1,1956(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1956, temp.u32);
	// lfs f1,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,2312(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2312, temp.u32);
	// lfs f2,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,1256(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1256, temp.u32);
	// lfs f2,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,2052(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2052, temp.u32);
	// lfs f2,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,2036(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2036, temp.u32);
	// lfs f2,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,328(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f2,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,3092(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3092, temp.u32);
	// lfs f2,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,2280(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2280, temp.u32);
	// lfs f1,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1916(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1916, temp.u32);
	// lfs f1,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,2104(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2104, temp.u32);
	// lfs f2,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1844(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1844, temp.u32);
	// fmuls f2,f5,f1
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// stfs f2,2120(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2120, temp.u32);
	// lfs f2,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f15.f64));
	// stfs f2,2016(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2016, temp.u32);
	// lfs f2,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f15.f64));
	// stfs f2,1232(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1232, temp.u32);
	// fmuls f2,f31,f28
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// stfs f2,224(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,2064(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2064, temp.u32);
	// lfs f1,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// stfs f1,2248(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2248, temp.u32);
	// fmuls f1,f24,f25
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// stfs f1,1260(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1260, temp.u32);
	// lfs f1,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1952(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1952, temp.u32);
	// fmuls f2,f24,f21
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f21.f64));
	// stfs f2,1140(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1140, temp.u32);
	// fmuls f2,f15,f24
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f24.f64));
	// stfs f2,4196(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4196, temp.u32);
	// lfs f2,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// stfs f2,1820(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1820, temp.u32);
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f0
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f1,1924(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1924, temp.u32);
	// lfs f1,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// stfs f2,908(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 908, temp.u32);
	// fmuls f1,f1,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// lfs f2,884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	ctx.f2.f64 = double(temp.f32);
	// stfs f1,2008(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2008, temp.u32);
	// fmuls f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f1,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f1.f64 = double(temp.f32);
	// stfs f2,3956(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3956, temp.u32);
	// fmuls f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// lfs f2,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f2.f64 = double(temp.f32);
	// stfs f1,784(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 784, temp.u32);
	// fmuls f1,f2,f30
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f1,1936(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1936, temp.u32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,2192(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2192, temp.u32);
	// lfs f1,1132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1132);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2092(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2092, temp.u32);
	// lfs f2,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f21
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f1,1972(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1972, temp.u32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f2,1456(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1456, temp.u32);
	// lfs f1,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,356(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f2,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f19
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f19.f64));
	// stfs f1,2020(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2020, temp.u32);
	// fmuls f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// stfs f2,1996(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1996, temp.u32);
	// lfs f1,1132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1132);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3048(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3048, temp.u32);
	// lfs f2,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f15.f64));
	// stfs f2,1960(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1960, temp.u32);
	// lfs f2,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f5,f2
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f1,2136(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2136, temp.u32);
	// lfs f1,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,2304(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2304, temp.u32);
	// fmuls f2,f4,f28
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// stfs f2,1012(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1012, temp.u32);
	// lfs f2,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfs f1,1132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1132);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2184(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2184, temp.u32);
	// lfs f1,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1932(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1932, temp.u32);
	// lfs f2,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f5,f2
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f1,2320(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2320, temp.u32);
	// fmuls f1,f15,f2
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// stfs f1,2080(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2080, temp.u32);
	// lfs f1,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// stfs f1,3004(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3004, temp.u32);
	// lfs f1,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// stfs f1,2528(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2528, temp.u32);
	// lfs f1,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f3
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// stfs f1,444(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// lfs f1,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// stfs f3,592(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 592, temp.u32);
	// lfs f3,1472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1472);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f1,f3,f0
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// stfs f1,1968(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1968, temp.u32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// stfs f1,256(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// stfs f1,248(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f1,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// stfs f1,2356(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2356, temp.u32);
	// lfs f1,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// stfs f1,3012(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3012, temp.u32);
	// lfs f1,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// stfs f1,2372(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2372, temp.u32);
	// lfs f1,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,2368(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2368, temp.u32);
	// lfs f1,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,1716(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1716, temp.u32);
	// lfs f2,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f3,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// stfs f2,2172(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2172, temp.u32);
	// fmuls f2,f3,f17
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// stfs f2,4088(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4088, temp.u32);
	// fmuls f2,f12,f12
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f12.f64));
	// stfs f2,1124(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1124, temp.u32);
	// fmuls f2,f3,f16
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f16.f64));
	// stfs f2,2444(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2444, temp.u32);
	// fmuls f2,f7,f7
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f7.f64));
	// stfs f2,1268(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1268, temp.u32);
	// lfs f2,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f18
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// stfs f1,4280(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4280, temp.u32);
	// fmuls f1,f2,f21
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f1,2112(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2112, temp.u32);
	// fmuls f2,f2,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// stfs f2,1836(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1836, temp.u32);
	// lfs f2,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,2240(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2240, temp.u32);
	// lfs f1,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,2272(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2272, temp.u32);
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,1148(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1148, temp.u32);
	// lfs f2,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,3868(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3868, temp.u32);
	// lfs f1,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2604(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2604, temp.u32);
	// lfs f1,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2000(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2000, temp.u32);
	// lfs f2,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f2,856(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 856, temp.u32);
	// lfs f2,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f2,1184(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1184, temp.u32);
	// lfs f2,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,808(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 808, temp.u32);
	// lfs f2,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f26,f2
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// stfs f1,1908(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1908, temp.u32);
	// fmuls f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// stfs f2,1828(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1828, temp.u32);
	// lfs f2,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,2004(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2004, temp.u32);
	// lfs f2,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,2128(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2128, temp.u32);
	// lfs f2,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,2376(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2376, temp.u32);
	// lfs f2,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f19.f64));
	// stfs f2,1740(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1740, temp.u32);
	// fmuls f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// fmuls f2,f24,f24
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f24.f64));
	// stfs f2,1464(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1464, temp.u32);
	// stfs f1,2072(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2072, temp.u32);
	// lfs f2,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1988(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1988, temp.u32);
	// lfs f2,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f26,f2
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// stfs f1,1756(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1756, temp.u32);
	// fmuls f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// stfs f2,1764(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1764, temp.u32);
	// lfs f2,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f4
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// stfs f2,628(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// lfs f2,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f2,844(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 844, temp.u32);
	// lfs f2,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,1944(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1944, temp.u32);
	// lfs f1,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,1772(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1772, temp.u32);
	// lfs f2,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f3
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// stfs f2,2964(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2964, temp.u32);
	// lfs f2,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,1732(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1732, temp.u32);
	// lfs f1,1968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1968);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,1784(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1784, temp.u32);
	// lfs f1,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,924(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 924, temp.u32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,1992(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1992, temp.u32);
	// lfs f1,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,2144(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2144, temp.u32);
	// lfs f1,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,2996(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2996, temp.u32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// stfs f1,136(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,1240(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1240, temp.u32);
	// lfs f1,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,3668(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3668, temp.u32);
	// fmuls f2,f22,f12
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// stfs f2,3572(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3572, temp.u32);
	// lfs f1,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,1780(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1780, temp.u32);
	// fmuls f2,f20,f12
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// stfs f2,1864(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1864, temp.u32);
	// fmuls f2,f22,f7
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f7.f64));
	// stfs f2,2324(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2324, temp.u32);
	// fmuls f2,f16,f7
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f7.f64));
	// stfs f2,1768(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1768, temp.u32);
	// fmuls f2,f16,f12
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// stfs f2,1776(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1776, temp.u32);
	// fmuls f2,f7,f12
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// stfs f2,2152(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2152, temp.u32);
	// lfs f2,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2168(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2168, temp.u32);
	// fmuls f2,f18,f12
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// stfs f2,2796(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2796, temp.u32);
	// fmuls f2,f18,f7
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f7.f64));
	// stfs f2,2812(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2812, temp.u32);
	// fmuls f2,f3,f4
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// stfs f2,3596(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3596, temp.u32);
	// lfs f2,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f3,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// stfs f2,3964(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3964, temp.u32);
	// fmuls f2,f3,f23
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// stfs f2,2096(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2096, temp.u32);
	// fmuls f2,f3,f20
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// stfs f2,3588(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3588, temp.u32);
	// lfs f2,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f2,3400(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3400, temp.u32);
	// lfs f2,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f2,3264(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3264, temp.u32);
	// lfs f1,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,3312(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3312, temp.u32);
	// lfs f1,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,3360(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3360, temp.u32);
	// lfs f2,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,3328(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3328, temp.u32);
	// lfs f2,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,3676(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3676, temp.u32);
	// lfs f2,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f3
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// stfs f1,916(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 916, temp.u32);
	// fmuls f1,f3,f21
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f21.f64));
	// stfs f1,1872(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1872, temp.u32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1800(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1800, temp.u32);
	// lfs f2,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,2100(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2100, temp.u32);
	// lfs f2,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f3,f2
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f2,916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 916);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f18
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// stfs f2,3044(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3044, temp.u32);
	// lfs f2,1308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1308);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f2,332(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1688(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1688, temp.u32);
	// lfs f2,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1640(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1640, temp.u32);
	// lfs f2,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f2,1680(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1680, temp.u32);
	// fmuls f2,f4,f17
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1672(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1672, temp.u32);
	// lfs f2,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,3028(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3028, temp.u32);
	// lfs f2,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f20.f64));
	// stfs f2,3272(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3272, temp.u32);
	// fmuls f2,f18,f16
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,3336(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3336, temp.u32);
	// lfs f2,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f20.f64));
	// stfs f2,1552(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1552, temp.u32);
	// fmuls f2,f1,f21
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// stfs f2,1648(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1648, temp.u32);
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,3036(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3036, temp.u32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,3052(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3052, temp.u32);
	// lfs f2,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f19.f64));
	// lfs f1,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1632(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1632, temp.u32);
	// lfs f2,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,4004(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4004, temp.u32);
	// fmr f2,f1
	ctx.f2.f64 = ctx.f1.f64;
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,3684(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3684, temp.u32);
	// lfs f2,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,3392(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3392, temp.u32);
	// lfs f1,2444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2444);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3060(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3060, temp.u32);
	// lfs f1,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3376(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3376, temp.u32);
	// lfs f2,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,4224(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4224, temp.u32);
	// lfs f2,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,3068(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3068, temp.u32);
	// lfs f2,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f0
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f1,1868(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1868, temp.u32);
	// fmuls f1,f2,f21
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f1,1792(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1792, temp.u32);
	// lfs f1,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f22
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f22.f64));
	// stfs f1,2060(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2060, temp.u32);
	// fmuls f1,f2,f23
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// stfs f1,2088(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2088, temp.u32);
	// lfs f1,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1496(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1496, temp.u32);
	// fmuls f1,f2,f17
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// stfs f1,1860(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1860, temp.u32);
	// fmuls f1,f2,f19
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f19.f64));
	// stfs f1,1708(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1708, temp.u32);
	// lfs f1,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// stfs f1,4012(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4012, temp.u32);
	// fmuls f1,f16,f2
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// stfs f1,2232(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2232, temp.u32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1848(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1848, temp.u32);
	// fmuls f2,f7,f28
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// lfs f1,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,3100(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3100, temp.u32);
	// lfs f1,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f18
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f18.f64));
	// stfs f1,1976(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1976, temp.u32);
	// lfs f1,1308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1308);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f2,1948(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1948, temp.u32);
	// lfs f2,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1660(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1660, temp.u32);
	// lfs f2,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f18
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// stfs f2,2068(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2068, temp.u32);
	// lfs f2,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1488(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1488, temp.u32);
	// lfs f2,908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 908);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,3076(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3076, temp.u32);
	// lfs f2,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,1480(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1480, temp.u32);
	// lfs f2,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1704(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1704, temp.u32);
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3700(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3700, temp.u32);
	// lfs f2,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// fmuls f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f19.f64));
	// stfs f2,3084(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3084, temp.u32);
	// fmuls f2,f4,f17
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1524(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1524, temp.u32);
	// lfs f2,1872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1872);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,1348(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1348, temp.u32);
	// lfs f1,916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 916);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f20.f64));
	// stfs f1,4160(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4160, temp.u32);
	// lfs f1,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,1656(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1656, temp.u32);
	// lfs f1,916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 916);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f22
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f22.f64));
	// stfs f1,3692(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3692, temp.u32);
	// lfs f1,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1664(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1664, temp.u32);
	// lfs f2,1004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1004);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,1696(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1696, temp.u32);
	// lfs f2,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f19.f64));
	// lfs f1,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1356(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1356, temp.u32);
	// lfs f2,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1888(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1888, temp.u32);
	// lfs f2,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,488(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// lfs f2,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// stfs f2,3132(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3132, temp.u32);
	// lfs f2,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,4028(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4028, temp.u32);
	// lfs f2,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f2,4256(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4256, temp.u32);
	// lfs f1,1260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1260);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,3116(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3116, temp.u32);
	// fmr f2,f1
	ctx.f2.f64 = ctx.f1.f64;
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,3732(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3732, temp.u32);
	// lfs f2,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,3740(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3740, temp.u32);
	// lfs f2,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// stfs f2,4020(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4020, temp.u32);
	// lfs f2,1800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1800);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f27
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f1,3124(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3124, temp.u32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// stfs f2,3724(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3724, temp.u32);
	// lfs f2,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f24
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f1,3716(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3716, temp.u32);
	// lfs f1,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// stfs f1,4168(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4168, temp.u32);
	// stfs f2,3188(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3188, temp.u32);
	// lfs f1,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,3148(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3148, temp.u32);
	// lfs f1,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// stfs f1,3708(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3708, temp.u32);
	// lfs f1,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// stfs f1,3156(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3156, temp.u32);
	// lfs f1,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// stfs f1,3172(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3172, temp.u32);
	// lfs f1,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,3108(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3108, temp.u32);
	// lfs f1,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// stfs f1,3180(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3180, temp.u32);
	// lfs f1,1448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1448);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,4176(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4176, temp.u32);
	// lfs f1,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,4036(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4036, temp.u32);
	// fmuls f2,f27,f20
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// stfs f2,1532(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1532, temp.u32);
	// fmuls f2,f27,f22
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f22.f64));
	// stfs f2,1208(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1208, temp.u32);
	// fmuls f2,f26,f18
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f18.f64));
	// stfs f2,1468(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1468, temp.u32);
	// fmuls f2,f27,f16
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f16.f64));
	// stfs f2,1112(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1112, temp.u32);
	// fmuls f2,f27,f18
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// stfs f2,1200(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1200, temp.u32);
	// lfs f2,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f2,3140(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3140, temp.u32);
	// lfs f1,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1020(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1020, temp.u32);
	// lfs f2,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,3748(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3748, temp.u32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3164(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3164, temp.u32);
	// lfs f2,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f0
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f1,1852(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1852, temp.u32);
	// fmuls f1,f2,f17
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// stfs f1,1964(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1964, temp.u32);
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,1808(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1808, temp.u32);
	// fmuls f2,f24,f31
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// fmuls f1,f2,f14
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f1,3196(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3196, temp.u32);
	// lfs f1,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f6
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// stfs f1,1380(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1380, temp.u32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,3756(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3756, temp.u32);
	// lfs f1,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// stfs f1,1668(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1668, temp.u32);
	// lfs f1,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// stfs f1,1412(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1412, temp.u32);
	// lfs f1,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f6
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// stfs f1,1540(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1540, temp.u32);
	// lfs f1,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// stfs f1,1388(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1388, temp.u32);
	// lfs f1,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// stfs f1,1420(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1420, temp.u32);
	// fmuls f1,f10,f31
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// stfs f1,1684(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1684, temp.u32);
	// lfs f1,1084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1084);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// stfs f1,3236(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3236, temp.u32);
	// lfs f1,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,4064(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4064, temp.u32);
	// fmuls f1,f6,f0
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1628(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1628, temp.u32);
	// lfs f1,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f27,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// stfs f1,3440(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3440, temp.u32);
	// lfs f1,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// stfs f1,3204(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3204, temp.u32);
	// lfs f1,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,3220(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3220, temp.u32);
	// lfs f1,1304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1304);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f27,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// stfs f1,3448(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3448, temp.u32);
	// fmuls f1,f2,f26
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// stfs f1,1788(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1788, temp.u32);
	// fmuls f1,f2,f27
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f1,3780(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3780, temp.u32);
	// lfs f1,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,3764(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3764, temp.u32);
	// lfs f1,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// stfs f1,1396(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1396, temp.u32);
	// lfs f1,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// stfs f1,1548(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1548, temp.u32);
	// lfs f1,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// stfs f1,3212(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3212, temp.u32);
	// lfs f1,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,4044(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4044, temp.u32);
	// lfs f1,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// stfs f1,3456(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3456, temp.u32);
	// fmuls f1,f10,f31
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// stfs f1,1556(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1556, temp.u32);
	// fmuls f1,f6,f19
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1404(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1404, temp.u32);
	// lfs f1,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// stfs f1,4076(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4076, temp.u32);
	// lfs f1,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// stfs f1,4216(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4216, temp.u32);
	// lfs f1,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// stfs f1,2940(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2940, temp.u32);
	// lfs f1,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// stfs f1,3480(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3480, temp.u32);
	// lfs f1,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f6,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// stfs f1,1636(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1636, temp.u32);
	// fmuls f1,f7,f31
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f1,80(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f1,f27,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// stfs f1,4052(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4052, temp.u32);
	// fmuls f1,f27,f12
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,3788(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3788, temp.u32);
	// lfs f1,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f26,f1
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// stfs f1,3244(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3244, temp.u32);
	// fmuls f1,f2,f16
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// stfs f1,3276(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3276, temp.u32);
	// fmuls f1,f26,f12
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,3772(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3772, temp.u32);
	// lfs f1,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// stfs f1,1436(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1436, temp.u32);
	// lfs f1,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// stfs f1,1572(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1572, temp.u32);
	// lfs f1,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f6
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// stfs f1,1700(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1700, temp.u32);
	// lfs f1,1056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1056);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// stfs f1,3464(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3464, temp.u32);
	// fmuls f1,f2,f22
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f1,3300(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3300, temp.u32);
	// fmuls f1,f2,f18
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// stfs f1,3804(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3804, temp.u32);
	// fmuls f2,f2,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f20.f64));
	// stfs f2,4100(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4100, temp.u32);
	// lfs f2,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// stfs f2,3812(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3812, temp.u32);
	// lfs f2,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f2,3308(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3308, temp.u32);
	// lfs f2,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// stfs f2,3340(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3340, temp.u32);
	// lfs f2,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f2,2392(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2392, temp.u32);
	// lfs f2,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f14,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 * ctx.f2.f64));
	// stfs f2,2448(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2448, temp.u32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,1084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1084);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2456(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2456, temp.u32);
	// lfs f2,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,2464(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2464, temp.u32);
	// lfs f1,1140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1140);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f14.f64));
	// stfs f1,3828(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3828, temp.u32);
	// lfs f1,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3324(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3324, temp.u32);
	// lfs f1,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2956(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2956, temp.u32);
	// lfs f1,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,3268(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3268, temp.u32);
	// lfs f2,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f2,4084(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4084, temp.u32);
	// lfs f2,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f2,4060(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4060, temp.u32);
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,2948(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2948, temp.u32);
	// fmuls f2,f2,f3
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// stfs f2,2344(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2344, temp.u32);
	// fmuls f2,f3,f25
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// stfs f2,224(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f2,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f3,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// stfs f2,3996(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3996, temp.u32);
	// fmuls f2,f27,f1
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// stfs f2,3332(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3332, temp.u32);
	// lfs f1,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,412(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,2948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2948);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// stfs f2,4068(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4068, temp.u32);
	// lfs f2,1140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1140);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3260(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3260, temp.u32);
	// lfs f2,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3636(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3636, temp.u32);
	// lfs f2,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// stfs f2,3796(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3796, temp.u32);
	// lfs f2,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f24
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f1,3252(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3252, temp.u32);
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f2,4092(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4092, temp.u32);
	// lfs f2,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,3292(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3292, temp.u32);
	// lfs f2,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,3284(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3284, temp.u32);
	// lfs f2,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f2,3316(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3316, temp.u32);
	// lfs f2,2372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2372);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,2472(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2472, temp.u32);
	// lfs f2,900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 900);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,1492(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1492, temp.u32);
	// lfs f2,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// lfs f1,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// stfs f1,3820(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3820, temp.u32);
	// lfs f1,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,1344(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1344, temp.u32);
	// lfs f2,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,940(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 940, temp.u32);
	// fmuls f2,f18,f20
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,3528(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3528, temp.u32);
	// fmuls f2,f22,f20
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,3552(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3552, temp.u32);
	// lfs f2,1776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1776);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,2480(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2480, temp.u32);
	// lfs f2,3572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3572);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,2440(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2440, temp.u32);
	// fmuls f2,f22,f18
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1516(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1516, temp.u32);
	// lfs f2,1220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1220);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1484(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1484, temp.u32);
	// fmuls f2,f16,f20
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f20.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1476(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1476, temp.u32);
	// lfs f2,2812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2812);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,2400(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2400, temp.u32);
	// lfs f2,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2408(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2408, temp.u32);
	// lfs f2,1864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1864);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,2424(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2424, temp.u32);
	// lfs f2,892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 892);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,1676(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1676, temp.u32);
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2432(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2432, temp.u32);
	// lfs f2,1768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1768);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,2416(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2416, temp.u32);
	// fmuls f2,f22,f16
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,3592(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3592, temp.u32);
	// lfs f2,884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,4232(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4232, temp.u32);
	// fmuls f2,f18,f16
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,3568(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3568, temp.u32);
	// lfs f2,2796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2796);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,3836(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3836, temp.u32);
	// lfs f2,2356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2356);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,2388(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2388, temp.u32);
	// lfs f2,2324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2324);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,3348(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3348, temp.u32);
	// lfs f2,3964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3964);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1508(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1508, temp.u32);
	// lfs f1,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,3544(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3544, temp.u32);
	// fmuls f2,f22,f18
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f1,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1692(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1692, temp.u32);
	// lfs f2,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,1612(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1612, temp.u32);
	// fmuls f2,f22,f16
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,3512(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3512, temp.u32);
	// lfs f2,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3600(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3600, temp.u32);
	// lfs f2,2344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2344);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f22,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// stfs f2,2512(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2512, temp.u32);
	// lfs f1,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1652(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1652, temp.u32);
	// lfs f2,3996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3996);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1368(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1368, temp.u32);
	// lfs f1,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3584(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3584, temp.u32);
	// lfs f2,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// stfs f2,2520(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2520, temp.u32);
	// lfs f1,3588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3588);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2488(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2488, temp.u32);
	// fmuls f2,f22,f20
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// lfs f1,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,3576(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3576, temp.u32);
	// lfs f2,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f19.f64));
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,1340(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1340, temp.u32);
	// lfs f2,2324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2324);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,2544(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2544, temp.u32);
	// fmuls f2,f18,f20
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,3520(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3520, temp.u32);
	// lfs f2,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2576(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2576, temp.u32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2560(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2560, temp.u32);
	// lfs f2,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,1604(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1604, temp.u32);
	// lfs f2,884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,2552(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2552, temp.u32);
	// fmuls f2,f4,f17
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,1500(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1500, temp.u32);
	// lfs f2,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2568(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2568, temp.u32);
	// lfs f2,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,3536(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3536, temp.u32);
	// lfs f1,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1360(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1360, temp.u32);
	// fmuls f2,f3,f19
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// stfs f2,2328(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2328, temp.u32);
	// lfs f1,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3688(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3688, temp.u32);
	// lfs f2,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// lfs f1,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f1.f64 = double(temp.f32);
	// stfs f2,2584(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2584, temp.u32);
	// fmuls f2,f1,f18
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f18.f64));
	// stfs f2,3560(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3560, temp.u32);
	// fmuls f2,f16,f20
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f20.f64));
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1596(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1596, temp.u32);
	// fmuls f2,f1,f7
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// stfs f2,2536(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2536, temp.u32);
	// lfs f2,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// stfs f3,1724(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1724, temp.u32);
	// lfs f3,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f3,f20
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// stfs f2,1376(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1376, temp.u32);
	// fmuls f3,f3,f7
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// lfs f2,1984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1984);
	ctx.f2.f64 = double(temp.f32);
	// stfs f3,2632(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2632, temp.u32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfs f3,2344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2344);
	ctx.f3.f64 = double(temp.f32);
	// stfs f2,2624(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2624, temp.u32);
	// fmuls f2,f3,f18
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// stfs f2,2496(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2496, temp.u32);
	// fmuls f3,f3,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f16.f64));
	// lfs f2,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,2608(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2608, temp.u32);
	// lfs f2,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f4
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// stfs f2,1324(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1324, temp.u32);
	// lfs f2,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f3,2504(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2504, temp.u32);
	// stfs f2,1384(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1384, temp.u32);
	// fmuls f3,f27,f24
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f24.f64));
	// lfs f2,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f2.f64 = double(temp.f32);
	// stfs f3,80(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmr f3,f2
	ctx.f3.f64 = ctx.f2.f64;
	// fmuls f2,f3,f22
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// stfs f2,2664(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2664, temp.u32);
	// lfs f2,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f3,f3,f20
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f2,1352(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1352, temp.u32);
	// lfs f2,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f2,1408(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1408, temp.u32);
	// lfs f2,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// stfs f3,1796(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1796, temp.u32);
	// stfs f2,1400(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1400, temp.u32);
	// lfs f2,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// stfs f3,3640(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3640, temp.u32);
	// lfs f3,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f12
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// stfs f3,2656(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2656, temp.u32);
	// lfs f3,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f12
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// stfs f3,2648(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2648, temp.u32);
	// lfs f3,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f12
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// lfs f2,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f2.f64 = double(temp.f32);
	// stfs f3,2640(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2640, temp.u32);
	// fmuls f3,f2,f23
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// stfs f3,1392(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1392, temp.u32);
	// lfs f3,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// stfs f4,3672(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3672, temp.u32);
	// lfs f3,1308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1308);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// stfs f4,3704(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3704, temp.u32);
	// lfs f4,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// lfs f1,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f4,f4,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// stfs f4,3656(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3656, temp.u32);
	// lfs f4,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// stfs f4,3648(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3648, temp.u32);
	// lfs f4,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// fmuls f4,f4,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// stfs f4,3632(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3632, temp.u32);
	// fmuls f4,f2,f30
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f4,3624(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3624, temp.u32);
	// lfs f4,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f16.f64));
	// stfs f4,2680(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2680, temp.u32);
	// lfs f4,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// stfs f4,3712(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3712, temp.u32);
	// lfs f4,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// stfs f4,3680(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3680, temp.u32);
	// lfs f4,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f26
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f26.f64));
	// stfs f4,1432(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1432, temp.u32);
	// lfs f2,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// stfs f4,2840(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2840, temp.u32);
	// lfs f2,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// stfs f4,2704(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2704, temp.u32);
	// lfs f4,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f26,f4
	ctx.f4.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// stfs f4,2816(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2816, temp.u32);
	// lfs f4,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f15,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// stfs f4,1804(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1804, temp.u32);
	// lfs f4,1448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1448);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f26,f4
	ctx.f4.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// stfs f4,2784(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2784, temp.u32);
	// fmuls f4,f31,f28
	ctx.f4.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmuls f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// stfs f1,2800(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2800, temp.u32);
	// lfs f1,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,2824(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2824, temp.u32);
	// lfs f2,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// stfs f2,2768(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2768, temp.u32);
	// lfs f2,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// stfs f2,2792(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2792, temp.u32);
	// lfs f2,1448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1448);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// stfs f2,2752(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2752, temp.u32);
	// lfs f2,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f24
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f1,2760(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2760, temp.u32);
	// lfs f1,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// stfs f1,2808(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2808, temp.u32);
	// lfs f1,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1440(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1440, temp.u32);
	// lfs f1,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// stfs f1,1424(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1424, temp.u32);
	// fmuls f1,f26,f2
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// fmuls f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// stfs f2,1036(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1036, temp.u32);
	// lfs f2,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f2,952(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 952, temp.u32);
	// lfs f2,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,2848(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2848, temp.u32);
	// stfs f1,1416(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1416, temp.u32);
	// lfs f1,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// fmuls f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// stfs f2,2744(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2744, temp.u32);
	// stfs f1,2776(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2776, temp.u32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,1156(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1156, temp.u32);
	// lfs f2,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// stfs f2,2736(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2736, temp.u32);
	// lfs f2,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f4,f2
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// stfs f2,2832(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2832, temp.u32);
	// lfs f1,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2720(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2720, temp.u32);
	// lfs f2,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// stfs f2,2712(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2712, temp.u32);
	// lfs f2,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f4,f2
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// stfs f2,2688(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2688, temp.u32);
	// lfs f2,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// stfs f2,1028(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1028, temp.u32);
	// lfs f2,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,2728(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2728, temp.u32);
	// fmuls f2,f10,f2
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// stfs f2,888(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 888, temp.u32);
	// fmuls f2,f6,f14
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// stfs f2,960(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 960, temp.u32);
	// lfs f2,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f6,f2
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// stfs f2,968(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 968, temp.u32);
	// lfs f1,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f6,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// fmuls f2,f10,f2
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// stfs f2,1000(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1000, temp.u32);
	// stfs f1,2856(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2856, temp.u32);
	// lfs f1,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,2864(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2864, temp.u32);
	// lfs f2,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f2,2872(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2872, temp.u32);
	// fmuls f2,f26,f0
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmuls f23,f2,f24
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f23,2880(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2880, temp.u32);
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f2,928(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 928, temp.u32);
	// fmuls f2,f10,f1
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f1.f64));
	// stfs f2,904(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 904, temp.u32);
	// fmuls f2,f6,f17
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// lfs f1,1288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1288);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,896(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 896, temp.u32);
	// lfs f2,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2888(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2888, temp.u32);
	// fmuls f2,f6,f21
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,2896(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2896, temp.u32);
	// fmuls f2,f27,f28
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,2952(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2952, temp.u32);
	// lfs f2,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,1748(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1748, temp.u32);
	// lfs f2,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,912(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 912, temp.u32);
	// fmuls f2,f27,f19
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,2904(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2904, temp.u32);
	// fmuls f2,f26,f19
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// fmuls f23,f2,f24
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f23,2920(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2920, temp.u32);
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// lfs f23,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f23.f64 = double(temp.f32);
	// stfs f2,944(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 944, temp.u32);
	// fmuls f2,f23,f10
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// stfs f2,984(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 984, temp.u32);
	// fmuls f2,f6,f25
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,2936(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2936, temp.u32);
	// lfs f2,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f23,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// stfs f2,2968(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2968, temp.u32);
	// lfs f2,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f23,f27,f7
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2976(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2976, temp.u32);
	// fmuls f2,f24,f22
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// fmuls f1,f24,f16
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f16.f64));
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,1720(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1720, temp.u32);
	// lfs f2,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f10,f2
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// stfs f2,936(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 936, temp.u32);
	// fmuls f2,f24,f20
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f20.f64));
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,2912(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2912, temp.u32);
	// fmuls f2,f27,f12
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,996(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 996, temp.u32);
	// fmuls f2,f24,f18
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f18.f64));
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,3032(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3032, temp.u32);
	// lfs f2,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// stfs f10,920(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 920, temp.u32);
	// lfs f10,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f4,f10
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// stfs f10,3040(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3040, temp.u32);
	// fmuls f10,f1,f28
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// stfs f10,3008(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3008, temp.u32);
	// fmuls f10,f23,f28
	ctx.f10.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// stfs f10,3000(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3000, temp.u32);
	// lfs f10,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f10.f64 = double(temp.f32);
	// lfs f2,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f10,f2
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// stfs f2,3152(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3152, temp.u32);
	// lfs f2,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f24
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f1,3128(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3128, temp.u32);
	// fmuls f1,f2,f26
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// stfs f1,868(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 868, temp.u32);
	// lfs f1,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f1.f64));
	// stfs f1,3136(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3136, temp.u32);
	// lfs f1,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f1.f64));
	// stfs f1,3120(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3120, temp.u32);
	// lfs f1,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// stfs f1,3112(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3112, temp.u32);
	// lfs f1,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// stfs f1,3056(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3056, temp.u32);
	// lfs f1,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f4,f4,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// stfs f4,3016(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3016, temp.u32);
	// lfs f4,1084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1084);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// stfs f10,2992(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2992, temp.u32);
	// lfs f4,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f4.f64 = double(temp.f32);
	// lfs f10,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// stfs f10,2984(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2984, temp.u32);
	// lfs f10,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f1,f26,f10
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// stfs f1,3096(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3096, temp.u32);
	// fmuls f10,f27,f10
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// stfs f10,3088(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3088, temp.u32);
	// lfs f10,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f15
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f15.f64));
	// stfs f10,3024(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3024, temp.u32);
	// lfs f10,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f15,f10
	ctx.f10.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// lfs f1,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f1.f64 = double(temp.f32);
	// stfs f10,3160(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3160, temp.u32);
	// fmuls f10,f1,f24
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// stfs f10,3144(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3144, temp.u32);
	// lfs f10,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f23,f27,f10
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// stfs f23,3104(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3104, temp.u32);
	// fmuls f10,f26,f10
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// stfs f10,3176(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3176, temp.u32);
	// fmuls f10,f27,f1
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// stfs f10,976(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 976, temp.u32);
	// lfs f10,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f24,f10,f24
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f24.f64));
	// stfs f24,3168(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3168, temp.u32);
	// fmuls f24,f10,f26
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// stfs f24,1008(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1008, temp.u32);
	// lfs f24,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// stfs f24,660(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 660, temp.u32);
	// lfs f23,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,1292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1292);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f15.f64));
	// fmuls f24,f24,f4
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f4.f64));
	// stfs f23,3072(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3072, temp.u32);
	// stfs f24,3080(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3080, temp.u32);
	// fmuls f15,f18,f28
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f23,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,1012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1012);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f4,f23
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// fmuls f24,f24,f30
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// stfs f23,3064(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3064, temp.u32);
	// stfs f24,864(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 864, temp.u32);
	// fmuls f23,f26,f1
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// lfs f24,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f24.f64 = double(temp.f32);
	// stfs f23,1032(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1032, temp.u32);
	// fmuls f24,f24,f30
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// fmuls f23,f2,f27
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f23,992(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 992, temp.u32);
	// stfs f24,1172(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1172, temp.u32);
	// fmuls f23,f10,f27
	ctx.f23.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// lfs f24,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f24.f64 = double(temp.f32);
	// stfs f23,1024(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1024, temp.u32);
	// fmuls f23,f24,f22
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// stfs f23,1616(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1616, temp.u32);
	// fmuls f23,f24,f18
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f18.f64));
	// stfs f23,1568(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1568, temp.u32);
	// lfs f23,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// stfs f23,3184(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3184, temp.u32);
	// lfs f23,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// stfs f23,3224(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3224, temp.u32);
	// fmuls f23,f15,f20
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f20.f64));
	// stfs f23,1576(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1576, temp.u32);
	// lfs f23,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// stfs f23,1592(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1592, temp.u32);
	// lfs f23,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// stfs f23,1560(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1560, temp.u32);
	// lfs f23,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// stfs f23,3192(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3192, temp.u32);
	// lfs f23,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// stfs f15,212(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// stfs f23,1608(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1608, temp.u32);
	// lfs f23,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// stfs f23,1600(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1600, temp.u32);
	// fmuls f23,f15,f22
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f22.f64));
	// stfs f23,1584(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1584, temp.u32);
	// fmuls f23,f24,f20
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f20.f64));
	// stfs f23,1624(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1624, temp.u32);
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// lfs f23,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f15.f64));
	// stfs f23,1180(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1180, temp.u32);
	// lfs f23,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// stfs f23,3256(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3256, temp.u32);
	// lfs f23,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f23,f19
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f19.f64));
	// stfs f15,256(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmuls f15,f10,f18
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f18.f64));
	// stfs f15,596(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// fmuls f15,f10,f7
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// stfs f15,3200(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3200, temp.u32);
	// lfs f15,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// fmuls f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f15.f64));
	// stfs f15,3352(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3352, temp.u32);
	// lfs f15,1812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1812);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f21.f64));
	// stfs f21,3296(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3296, temp.u32);
	// lfs f21,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f22,f21
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f21.f64));
	// stfs f21,3288(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3288, temp.u32);
	// lfs f21,1472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1472);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// stfs f21,324(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f21,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f4,f21
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// stfs f21,248(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f21,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f15.f64));
	// stfs f21,3368(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3368, temp.u32);
	// fmuls f21,f2,f12
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f7,3344(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3344, temp.u32);
	// fmuls f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// stfs f12,3320(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3320, temp.u32);
	// lfs f12,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f12.f64 = double(temp.f32);
	// lfs f7,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// stfs f12,720(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 720, temp.u32);
	// fmuls f12,f10,f22
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f22.f64));
	// stfs f12,332(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f12,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,672(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 672, temp.u32);
	// lfs f12,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,716(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 716, temp.u32);
	// fmuls f12,f2,f22
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f12,520(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f25
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// stfs f12,3248(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3248, temp.u32);
	// lfs f12,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f12,3616(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3616, temp.u32);
	// lfs f12,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f12,f18
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f18.f64));
	// stfs f10,3696(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3696, temp.u32);
	// lfs f10,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// stfs f10,3608(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3608, temp.u32);
	// fmuls f10,f23,f0
	ctx.f10.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f10,3728(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3728, temp.u32);
	// fmuls f10,f12,f22
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f22.f64));
	// stfs f10,3720(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3720, temp.u32);
	// fmuls f10,f12,f20
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f20.f64));
	// stfs f10,3664(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3664, temp.u32);
	// fmuls f10,f27,f12
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// stfs f21,3280(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3280, temp.u32);
	// stfs f10,3768(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3768, temp.u32);
	// fmuls f12,f26,f12
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lis r24,-32239
	ctx.r24.s64 = -2112815104;
	// lfs f7,4024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4024);
	ctx.f7.f64 = double(temp.f32);
	// lis r30,-32239
	ctx.r30.s64 = -2112815104;
	// lfs f2,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f2.f64 = double(temp.f32);
	// lfs f25,3880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3880);
	ctx.f25.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fadds f23,f2,f25
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f25.f64));
	// stfs f12,3776(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3776, temp.u32);
	// lfs f2,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f2.f64 = double(temp.f32);
	// lis r31,-32244
	ctx.r31.s64 = -2113142784;
	// lfs f10,-30260(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -30260);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// lfs f12,-29812(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -29812);
	ctx.f12.f64 = double(temp.f32);
	// lfs f25,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f25.f64 = double(temp.f32);
	// lis r9,-32245
	ctx.r9.s64 = -2113208320;
	// fmuls f0,f25,f0
	ctx.f0.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// stfs f0,1164(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1164, temp.u32);
	// fmuls f0,f25,f19
	ctx.f0.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// stfs f0,1904(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1904, temp.u32);
	// lfs f0,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f0.f64 = double(temp.f32);
	// lis r8,-32244
	ctx.r8.s64 = -2113142784;
	// fmuls f25,f0,f6
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// stfs f25,2960(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2960, temp.u32);
	// lfs f17,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,3420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3420);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f8
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// fmsubs f21,f2,f12,f7
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 - ctx.f7.f64));
	// lfs f7,-30232(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -30232);
	ctx.f7.f64 = double(temp.f32);
	// lfs f2,25992(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 25992);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f25,f23,f12,f21
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 + ctx.f21.f64));
	// lfs f12,4272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4272);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f23,f12,f8
	ctx.f23.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// lfs f12,2540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2540);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f21,f12,f8
	ctx.f21.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// lfs f12,-29816(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29816);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f25,f17,f10,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f25.f64));
	// lfs f17,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f0,f17
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f17.f64));
	// lfs f0,2492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2492);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f15,f0,f8
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f0,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f4
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// stfs f0,3744(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3744, temp.u32);
	// fmuls f0,f27,f28
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// fmuls f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fmuls f0,f0,f14
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f14.f64));
	// stfs f0,3760(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3760, temp.u32);
	// lfs f0,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f23,f21,f12,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 - ctx.f23.f64));
	// fnmsubs f10,f0,f10,f25
	ctx.f10.f64 = double(float(-(ctx.f0.f64 * ctx.f10.f64 - ctx.f25.f64)));
	// lfs f25,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f0,f27,f28
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// lfs f21,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f0,f0,f25
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// stfs f0,3752(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3752, temp.u32);
	// lfs f0,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f21,f0,f21
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f21.f64));
	// stfs f21,3736(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3736, temp.u32);
	// fmuls f21,f17,f28
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// stfs f21,3856(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3856, temp.u32);
	// lfs f21,1748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1748);
	ctx.f21.f64 = double(temp.f32);
	// lfs f17,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f17.f64));
	// stfs f21,3864(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3864, temp.u32);
	// lfs f21,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f0
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// stfs f21,3824(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3824, temp.u32);
	// lfs f21,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f0,f0,f21
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f21.f64));
	// stfs f0,3832(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3832, temp.u32);
	// lfs f0,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// stfs f0,3808(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3808, temp.u32);
	// lfs f0,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// stfs f0,3792(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3792, temp.u32);
	// lfs f21,2140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2140);
	ctx.f21.f64 = double(temp.f32);
	// lfs f0,-16900(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -16900);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f0,f21,f0,f10
	ctx.f0.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f10,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// stfs f10,3816(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3816, temp.u32);
	// fmadds f10,f20,f12,f23
	ctx.f10.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f23.f64));
	// lfs f23,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f6,f23,f6
	ctx.f6.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// stfs f6,3800(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3800, temp.u32);
	// fmuls f6,f26,f3
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// stfs f6,1196(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1196, temp.u32);
	// fmuls f6,f27,f3
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// stfs f6,1204(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1204, temp.u32);
	// fmuls f6,f3,f18
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// stfs f6,1212(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1212, temp.u32);
	// lfs f6,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f6.f64 = double(temp.f32);
	// lis r7,-32239
	ctx.r7.s64 = -2112815104;
	// fmuls f6,f6,f19
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// stfs f6,828(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 828, temp.u32);
	// lfs f6,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f6.f64 = double(temp.f32);
	// lis r6,-32239
	ctx.r6.s64 = -2112815104;
	// fmuls f6,f6,f19
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// stfs f6,1048(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1048, temp.u32);
	// fmuls f6,f3,f16
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f16.f64));
	// stfs f6,136(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f6,2360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2360);
	ctx.f6.f64 = double(temp.f32);
	// lis r3,-32239
	ctx.r3.s64 = -2112815104;
	// fnmsubs f23,f6,f7,f0
	ctx.f23.f64 = double(float(-(ctx.f6.f64 * ctx.f7.f64 - ctx.f0.f64)));
	// lfs f0,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// stfs f0,228(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f0,f3,f22
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f6,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f22,f15,f12,f10
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f12.f64 - ctx.f10.f64)));
	// lfs f0,2328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2328);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// stfs f0,1188(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1188, temp.u32);
	// lfs f0,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// lfs f10,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f10.f64 = double(temp.f32);
	// lfs f6,1164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1164);
	ctx.f6.f64 = double(temp.f32);
	// stfs f0,4792(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4792, temp.u32);
	// fmuls f0,f10,f6
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// stfs f0,1928(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1928, temp.u32);
	// lfs f0,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f6,f0,f6
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// stfs f6,3784(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3784, temp.u32);
	// lfs f6,2960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2960);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f27,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// stfs f6,1164(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1164, temp.u32);
	// lfs f6,1904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1904);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f0,f0,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// stfs f0,1904(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1904, temp.u32);
	// lfs f0,2208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2208);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f3,f0,f2,f23
	ctx.f3.f64 = double(float(-(ctx.f0.f64 * ctx.f2.f64 - ctx.f23.f64)));
	// fmuls f0,f10,f6
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// lfs f10,2300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2300);
	ctx.f10.f64 = double(temp.f32);
	// stfs f0,3840(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3840, temp.u32);
	// lfs f0,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f0,-29820(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -29820);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f6,f10,f2,f3
	ctx.f6.f64 = double(float(-(ctx.f10.f64 * ctx.f2.f64 - ctx.f3.f64)));
	// lfs f3,1824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1824);
	ctx.f3.f64 = double(temp.f32);
	// lfs f10,31108(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 31108);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f10,f3,f10,f6
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 + ctx.f6.f64));
	// lfs f6,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f6.f64 = double(temp.f32);
	// lfs f3,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f10,f6,f2,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 + ctx.f10.f64));
	// lfs f6,2024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2024);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f10,f6,f7,f10
	ctx.f10.f64 = double(float(-(ctx.f6.f64 * ctx.f7.f64 - ctx.f10.f64)));
	// lfs f6,2124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2124);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f10,f6,f7,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f7.f64 + ctx.f10.f64));
	// stfs f10,4288(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4288, temp.u32);
	// lfs f10,4212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4212);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f2,f10,f9
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f10,4032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4032);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f23,f10,f9
	ctx.f23.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f10,2516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2516);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f21,f10,f12
	ctx.f21.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f10,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f20,f10,f3
	ctx.f20.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f6,-29824(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -29824);
	ctx.f6.f64 = double(temp.f32);
	// lfs f10,-29828(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + -29828);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f1,f1,f0,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f21.f64));
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f2,f2,f6
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f18,3412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3412);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,2500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2500);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f24,f17,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f24.f64));
	// fmuls f21,f21,f12
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfs f7,2176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2176);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f18,f18,f8
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// lis r29,-32239
	ctx.r29.s64 = -2112815104;
	// fmuls f19,f7,f9
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// lfs f15,872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 872);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,1044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1044);
	ctx.f17.f64 = double(temp.f32);
	// lis r4,-32239
	ctx.r4.s64 = -2112815104;
	// lfs f16,880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 880);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f3
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f15.f64 = double(temp.f32);
	// lfs f7,-29832(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -29832);
	ctx.f7.f64 = double(temp.f32);
	// lis r5,-32239
	ctx.r5.s64 = -2112815104;
	// fmadds f1,f1,f8,f22
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f8.f64 + ctx.f22.f64));
	// lfs f22,2264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2264);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f6,f23,f6,f2
	ctx.f6.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 - ctx.f2.f64));
	// lfs f2,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f8
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f23,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f24,f24,f0,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 + ctx.f21.f64));
	// lfs f21,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f23,f23,f25
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f25.f64));
	// fmuls f4,f4,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// lfs f21,2076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2076);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f22,f22,f9
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f9.f64));
	// fmuls f21,f21,f9
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// fmuls f3,f16,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// lfs f16,4096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4096);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f8
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f8.f64));
	// fnmsubs f1,f18,f12,f1
	ctx.f1.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmadds f6,f20,f10,f6
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 + ctx.f6.f64));
	// lfs f20,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// fmuls f20,f20,f8
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// fmuls f23,f23,f8
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fmuls f4,f4,f8
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// fmadds f1,f24,f8,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f8.f64 + ctx.f1.f64));
	// lfs f24,2200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2200);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f19,f19,f7,f6
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 + ctx.f6.f64));
	// lfs f6,2224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2224);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f18,f6,f9
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// lfs f6,-29836(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + -29836);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f14.f64));
	// fmuls f24,f24,f9
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// fnmsubs f2,f2,f0,f1
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// lfs f1,2084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2084);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f19,f17,f10,f19
	ctx.f19.f64 = double(float(-(ctx.f17.f64 * ctx.f10.f64 - ctx.f19.f64)));
	// lfs f17,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f25,f17,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// lfs f17,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f17.f64));
	// lfs f15,2288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2288);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f1,f1,f9
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// fmuls f15,f15,f9
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f9.f64));
	// fnmsubs f2,f23,f0,f2
	ctx.f2.f64 = double(float(-(ctx.f23.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// lfs f23,1128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1128);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f10,f3,f10,f19
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 + ctx.f19.f64));
	// lfs f19,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f3,f25,f8
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// lfs f25,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f23.f64));
	// lfs f23,1016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1016);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f19.f64));
	// fmuls f19,f17,f8
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f8.f64));
	// fnmsubs f4,f4,f0,f2
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fnmsubs f10,f22,f7,f10
	ctx.f10.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f10.f64)));
	// fmadds f4,f20,f0,f4
	ctx.f4.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fmadds f10,f21,f7,f10
	ctx.f10.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 + ctx.f10.f64));
	// fnmsubs f4,f16,f12,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f4.f64)));
	// fnmsubs f10,f18,f6,f10
	ctx.f10.f64 = double(float(-(ctx.f18.f64 * ctx.f6.f64 - ctx.f10.f64)));
	// fmadds f4,f3,f0,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fnmsubs f10,f24,f7,f10
	ctx.f10.f64 = double(float(-(ctx.f24.f64 * ctx.f7.f64 - ctx.f10.f64)));
	// fnmsubs f4,f19,f0,f4
	ctx.f4.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// fmadds f10,f1,f7,f10
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f7.f64 + ctx.f10.f64));
	// stfs f4,4292(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4292, temp.u32);
	// fnmsubs f4,f15,f7,f10
	ctx.f4.f64 = double(float(-(ctx.f15.f64 * ctx.f7.f64 - ctx.f10.f64)));
	// lfs f10,-29840(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -29840);
	ctx.f10.f64 = double(temp.f32);
	// lis r27,-32239
	ctx.r27.s64 = -2112815104;
	// lfs f22,2196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2196);
	ctx.f22.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f17,2780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2780);
	ctx.f17.f64 = double(temp.f32);
	// lis r28,-32239
	ctx.r28.s64 = -2112815104;
	// lfs f20,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f20.f64 = double(temp.f32);
	// lis r23,-32239
	ctx.r23.s64 = -2112815104;
	// lfs f18,3548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3548);
	ctx.f18.f64 = double(temp.f32);
	// lis r26,-32239
	ctx.r26.s64 = -2112815104;
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f19,2228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2228);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,2180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2180);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,2156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2156);
	ctx.f15.f64 = double(temp.f32);
	// lfs f3,2188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2188);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f1,f25,f10,f4
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f10,3628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3628);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f10,f0
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f10,1940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1940);
	ctx.f10.f64 = double(temp.f32);
	// lfs f25,4236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4236);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// lfs f2,4228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4228);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f25.f64));
	// lfs f25,3484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3484);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f10
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// lfs f24,3980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3980);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f10
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// lfs f16,2276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2276);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f22,f22,f12,f4
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f4.f64));
	// lfs f4,4220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4220);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f21,f4,f0
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// lfs f4,4144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4144);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f20,f4,f20
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f20.f64));
	// lfs f4,1316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1316);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f19,f19,f4
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// fmuls f17,f17,f4
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f4.f64));
	// fmuls f15,f15,f4
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// lfs f4,-30236(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -30236);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,440(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fmuls f3,f3,f6
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// lis r27,-32239
	ctx.r27.s64 = -2112815104;
	// fmuls f2,f2,f10
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmsubs f3,f22,f10,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f3.f64));
	// lfs f22,2132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2132);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f12,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f21.f64));
	// lfs f21,4128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4128);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f2,f2,f0,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f25.f64));
	// lfs f25,2932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2932);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// lfs f16,1236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1236);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f10
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// fmuls f21,f21,f10
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// fnmsubs f3,f24,f0,f3
	ctx.f3.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f3.f64)));
	// fmuls f24,f19,f4
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// lfs f4,2772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2772);
	ctx.f4.f64 = double(temp.f32);
	// lfs f19,3404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3404);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f2,f22,f10,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 + ctx.f2.f64));
	// fadds f19,f4,f19
	ctx.f19.f64 = double(float(ctx.f4.f64 + ctx.f19.f64));
	// lfs f4,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f4.f64 = double(temp.f32);
	// lfs f22,2828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2828);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f18,f4
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f4.f64));
	// fmuls f22,f22,f4
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f4.f64));
	// fmuls f25,f25,f10
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// fnmsubs f2,f16,f12,f2
	ctx.f2.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f4,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f17,f17,f4
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f4.f64));
	// lfs f4,-29844(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29844);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f20,f20,f4,f3
	ctx.f20.f64 = double(float(-(ctx.f20.f64 * ctx.f4.f64 - ctx.f3.f64)));
	// lfs f4,2116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2116);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// stfs f4,1012(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1012, temp.u32);
	// lfs f4,-30224(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -30224);
	ctx.f4.f64 = double(temp.f32);
	// fmsubs f24,f15,f4,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f4.f64 - ctx.f24.f64));
	// lfs f3,2908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2908);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f16,f3,f4
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f3,-30184(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -30184);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f19,f4
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// lfs f15,1012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1012);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f21,f21,f6,f20
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f6.f64 - ctx.f20.f64)));
	// fnmsubs f15,f15,f12,f2
	ctx.f15.f64 = double(float(-(ctx.f15.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f2,1300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1300);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f10
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// stfs f2,1012(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1012, temp.u32);
	// fmuls f22,f22,f3
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f3.f64));
	// lfs f3,-30220(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -30220);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f20,f18,f3,f17
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f3.f64 - ctx.f17.f64));
	// lfs f17,1316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1316);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,1244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1244);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f24,f19,f3,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f3.f64 + ctx.f24.f64));
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f3,2148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2148);
	ctx.f3.f64 = double(temp.f32);
	// lfs f17,3620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3620);
	ctx.f17.f64 = double(temp.f32);
	// lis r27,-32239
	ctx.r27.s64 = -2112815104;
	// fmuls f17,f17,f4
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f4.f64));
	// fmadds f25,f25,f6,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f21.f64));
	// lfs f21,1316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1316);
	ctx.f21.f64 = double(temp.f32);
	// fmr f2,f21
	ctx.f2.f64 = ctx.f21.f64;
	// fmuls f21,f3,f2
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f3,-30188(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -30188);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f22,f16,f3,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 - ctx.f22.f64));
	// lfs f3,3556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3556);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f3,f4
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f3,-30224(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -30224);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f20,f18,f3,f20
	ctx.f20.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f20.f64)));
	// lfs f18,2164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2164);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f2
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f2.f64));
	// lfs f2,2916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2916);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f16,f2,f4
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// lfs f2,-29828(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + -29828);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,-29844(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29844);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f1,f23,f2,f1
	ctx.f1.f64 = double(float(-(ctx.f23.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// fmadds f25,f17,f4,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 + ctx.f25.f64));
	// stfs f1,4296(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4296, temp.u32);
	// lfs f23,2292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2292);
	ctx.f23.f64 = double(temp.f32);
	// lfs f17,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f23,f23,f9
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// lfs f1,1012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1012);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f1,f1,f12,f15
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f12.f64 - ctx.f15.f64)));
	// stfs f1,4300(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4300, temp.u32);
	// fnmsubs f1,f21,f3,f24
	ctx.f1.f64 = double(float(-(ctx.f21.f64 * ctx.f3.f64 - ctx.f24.f64)));
	// stfs f1,4304(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4304, temp.u32);
	// lfs f1,-30160(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -30160);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f3,f18,f3,f20
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f3.f64 + ctx.f20.f64));
	// fnmsubs f1,f19,f1,f22
	ctx.f1.f64 = double(float(-(ctx.f19.f64 * ctx.f1.f64 - ctx.f22.f64)));
	// stfs f1,4308(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4308, temp.u32);
	// stfs f3,4312(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4312, temp.u32);
	// fnmsubs f1,f16,f4,f25
	ctx.f1.f64 = double(float(-(ctx.f16.f64 * ctx.f4.f64 - ctx.f25.f64)));
	// lfs f4,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f4,f3
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f24,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// lfs f19,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f19.f64 = double(temp.f32);
	// lfs f24,2316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2316);
	ctx.f24.f64 = double(temp.f32);
	// lfs f22,1044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1044);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f24,f24,f9
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// lfs f16,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f22,f4,f22
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f22.f64));
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// fmuls f2,f3,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f3,2308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2308);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f21,f3,f7
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// lfs f3,876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f3,f4
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f3,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f3,f19
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// lfs f3,2332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2332);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f3,f9
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// lfs f3,-29840(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -29840);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f3,f25,f3,f2
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f2.f64));
	// lfs f2,3652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3652);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f2,f2,f6,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f21.f64));
	// lfs f25,4208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4208);
	ctx.f25.f64 = double(temp.f32);
	// lfs f21,2348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2348);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f25,f25,f8
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// fmuls f21,f21,f9
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fnmsubs f3,f24,f7,f3
	ctx.f3.f64 = double(float(-(ctx.f24.f64 * ctx.f7.f64 - ctx.f3.f64)));
	// lfs f24,1840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1840);
	ctx.f24.f64 = double(temp.f32);
	// lfs f15,3940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3940);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmuls f25,f25,f6
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// lis r5,-32239
	ctx.r5.s64 = -2112815104;
	// fmsubs f6,f15,f6,f19
	ctx.f6.f64 = double(float(ctx.f15.f64 * ctx.f6.f64 - ctx.f19.f64));
	// lfs f19,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f8
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// lfs f15,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f4
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// lfs f16,2340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2340);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f9
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// fmadds f7,f23,f7,f3
	ctx.f7.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 + ctx.f3.f64));
	// fmadds f3,f17,f0,f24
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f24.f64));
	// lfs f24,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f4
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f4.f64));
	// lfs f4,3564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3564);
	ctx.f4.f64 = double(temp.f32);
	// fmsubs f6,f6,f8,f25
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f8.f64 - ctx.f25.f64));
	// lfs f25,2284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2284);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f10
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// lfs f10,-29828(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + -29828);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f23,f4,f8
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// lfs f17,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f4,f19,f30
	ctx.f4.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// fnmsubs f10,f22,f10,f7
	ctx.f10.f64 = double(float(-(ctx.f22.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// lfs f7,4152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4152);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f22,f7,f9
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// lfs f7,2804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2804);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f19,f7,f8
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// fmadds f7,f3,f8,f6
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f8.f64 + ctx.f6.f64));
	// lfs f6,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f8
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// lfs f3,3972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3972);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f1,f25,f12,f1
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f3,f3,f17
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// fmadds f2,f2,f9,f10
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f10.f64));
	// lfs f10,2980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2980);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f25,f10,f9
	ctx.f25.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f10,-29848(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -29848);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f17,f4,f10,f7
	ctx.f17.f64 = double(float(-(ctx.f4.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// lfs f4,-29836(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + -29836);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f7,f6,f30
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f7,1012(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1012, temp.u32);
	// lfs f7,-29828(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + -29828);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,-29844(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29844);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f6,f3,f6,f1
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f6.f64 + ctx.f1.f64));
	// stfs f6,4316(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4316, temp.u32);
	// lfs f6,-29832(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -29832);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f2,f20,f7,f2
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f2.f64));
	// fnmsubs f3,f23,f4,f17
	ctx.f3.f64 = double(float(-(ctx.f23.f64 * ctx.f4.f64 - ctx.f17.f64)));
	// fnmsubs f2,f18,f6,f2
	ctx.f2.f64 = double(float(-(ctx.f18.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// fmadds f3,f19,f4,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f4.f64 + ctx.f3.f64));
	// fnmsubs f2,f21,f6,f2
	ctx.f2.f64 = double(float(-(ctx.f21.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// fmadds f6,f16,f6,f2
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 + ctx.f2.f64));
	// lfs f2,2836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2836);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// lfs f2,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f8
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// fnmsubs f6,f15,f7,f6
	ctx.f6.f64 = double(float(-(ctx.f15.f64 * ctx.f7.f64 - ctx.f6.f64)));
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// lfs f1,1012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1012);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f3,f1,f10,f3
	ctx.f3.f64 = double(float(-(ctx.f1.f64 * ctx.f10.f64 - ctx.f3.f64)));
	// lfs f1,2296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2296);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f6,f24,f7,f6
	ctx.f6.f64 = double(float(-(ctx.f24.f64 * ctx.f7.f64 - ctx.f6.f64)));
	// lfs f7,-29824(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -29824);
	ctx.f7.f64 = double(temp.f32);
	// lfs f24,3020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3020);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f6,f22,f7,f6
	ctx.f6.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f6.f64)));
	// fmadds f7,f25,f7,f6
	ctx.f7.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 + ctx.f6.f64));
	// stfs f7,4320(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4320, temp.u32);
	// lfs f6,25992(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 25992);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,2040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2040);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// fmsubs f1,f1,f6,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f6.f64 - ctx.f7.f64));
	// lfs f7,2844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2844);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f4,f7,f12,f4
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + ctx.f4.f64));
	// lfs f7,3580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3580);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f25,f7,f8
	ctx.f25.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f7,3228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3228);
	ctx.f7.f64 = double(temp.f32);
	// fadds f24,f7,f24
	ctx.f24.f64 = double(float(ctx.f7.f64 + ctx.f24.f64));
	// lfs f7,3948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3948);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f23,f7,f8
	ctx.f23.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f7,-30232(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -30232);
	ctx.f7.f64 = double(temp.f32);
	// lfs f22,2056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2056);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f4,f4,f8,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f3.f64));
	// fnmsubs f1,f22,f7,f1
	ctx.f1.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f1.f64)));
	// lfs f3,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f3.f64 = double(temp.f32);
	// lfs f22,2672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2672);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f3,f3,f8
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// fadds f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// lfs f21,3304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3304);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,2860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2860);
	ctx.f22.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f21.f64));
	// lfs f21,1252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1252);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,2032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2032);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f2,f2,f10,f4
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f4,-29852(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29852);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f1,f21,f7,f1
	ctx.f1.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 + ctx.f1.f64));
	// fmuls f21,f3,f30
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// lfs f3,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f3,f8
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// lfs f3,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f3,f19
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// fnmsubs f2,f25,f12,f2
	ctx.f2.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f25,3960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3960);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f7,f18,f7,f1
	ctx.f7.f64 = double(float(-(ctx.f18.f64 * ctx.f7.f64 - ctx.f1.f64)));
	// lfs f1,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f25,f25,f12
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f18,2216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2216);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f1,f20,f1
	ctx.f1.f64 = double(float(ctx.f20.f64 * ctx.f1.f64));
	// lfs f20,3936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3936);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f8
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// fmuls f19,f19,f8
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// fnmsubs f2,f23,f12,f2
	ctx.f2.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f23,2944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2944);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f6,f18,f6,f7
	ctx.f6.f64 = double(float(-(ctx.f18.f64 * ctx.f6.f64 - ctx.f7.f64)));
	// lfs f7,3976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3976);
	ctx.f7.f64 = double(temp.f32);
	// fadds f23,f7,f23
	ctx.f23.f64 = double(float(ctx.f7.f64 + ctx.f23.f64));
	// lfs f7,3904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3904);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f25,f7,f12,f25
	ctx.f25.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 - ctx.f25.f64));
	// lfs f7,2820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2820);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f18,f7,f8
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f7,-29812(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -29812);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmadds f7,f24,f7,f6
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 + ctx.f6.f64));
	// fnmsubs f6,f21,f10,f2
	ctx.f6.f64 = double(float(-(ctx.f21.f64 * ctx.f10.f64 - ctx.f2.f64)));
	// lfs f10,3992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3992);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f24,f10,f8
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f10,-30260(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -30260);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f2,f23,f8
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// lfs f23,3660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3660);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f25,f25,f8,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f8.f64 - ctx.f20.f64));
	// fmadds f23,f23,f10,f7
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 + ctx.f7.f64));
	// lfs f7,31108(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 31108);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f6,f22,f4,f6
	ctx.f6.f64 = double(float(-(ctx.f22.f64 * ctx.f4.f64 - ctx.f6.f64)));
	// fmadds f4,f2,f0,f25
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f25.f64));
	// lfs f2,2900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2900);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f7,f2,f7,f23
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f7.f64 + ctx.f23.f64));
	// lfs f2,2988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2988);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f6,f1,f0,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f6.f64));
	// lfs f1,3928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3928);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f25,f1,f8
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fnmsubs f7,f2,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f2.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// lfs f2,3988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3988);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f6,f19,f0,f6
	ctx.f6.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f6.f64)));
	// fnmsubs f7,f2,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f2.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// lfs f2,1336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1336);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f10,f18,f12,f6
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 + ctx.f6.f64));
	// stfs f10,4324(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4324, temp.u32);
	// lfs f6,2048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2048);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// lfs f10,-16900(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -16900);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f10,f6,f10,f7
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f10.f64 + ctx.f7.f64));
	// stfs f10,4328(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4328, temp.u32);
	// lfs f10,3968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3968);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f7,f24,f0,f4
	ctx.f7.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// fmuls f6,f10,f8
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f4,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f4.f64 = double(temp.f32);
	// lfs f10,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fnmsubs f7,f6,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// lfs f6,3896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3896);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f6,f8
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// lfs f1,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f1.f64 = double(temp.f32);
	// lfs f6,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f4,f6,f1,f4
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f1.f64 + ctx.f4.f64));
	// lfs f6,1536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1536);
	ctx.f6.f64 = double(temp.f32);
	// lfs f1,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f2,f6,f1,f2
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f1.f64 + ctx.f2.f64));
	// lfs f6,3944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3944);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f6,f8
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// lfs f6,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f6.f64 = double(temp.f32);
	// lfs f19,3984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3984);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f25,f25,f12,f7
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f12.f64 + ctx.f7.f64));
	// lfs f7,3848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3848);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f22,f7,f0
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f7,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f4,f6,f7,f4
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f7.f64 + ctx.f4.f64));
	// lfs f7,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f21,f2,f7
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// lfs f2,3384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3384);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f20,f2,f29
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f29.f64));
	// lfs f2,3912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3912);
	ctx.f2.f64 = double(temp.f32);
	// fadds f19,f2,f19
	ctx.f19.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// lfs f2,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f25,f24,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// fmuls f24,f10,f2
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// lfs f10,3920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3920);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f22,f10,f12,f22
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + ctx.f22.f64));
	// lfs f10,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f4,f4,f29,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 + ctx.f21.f64));
	// fmadds f21,f10,f7,f20
	ctx.f21.f64 = double(float(ctx.f10.f64 * ctx.f7.f64 + ctx.f20.f64));
	// lfs f10,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f10.f64 = double(temp.f32);
	// lfs f20,3888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3888);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f8
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// fnmsubs f25,f23,f12,f25
	ctx.f25.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f25.f64)));
	// lfs f23,4008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4008);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f6,f6,f18,f24
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f18.f64 + ctx.f24.f64));
	// lfs f24,1080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1080);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f23,f10
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// fmuls f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f14.f64));
	// fmadds f4,f19,f10,f4
	ctx.f4.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 + ctx.f4.f64));
	// lfs f19,4016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4016);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f25,f22,f8,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f8.f64 + ctx.f25.f64));
	// lfs f22,2384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2384);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f8
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// fmsubs f23,f6,f29,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f29.f64 - ctx.f23.f64));
	// lfs f6,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f4,f21,f6,f4
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 - ctx.f4.f64));
	// lfs f6,2696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2696);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f21,f6,f0
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// lfs f6,1856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1856);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f0,f20,f0,f25
	ctx.f0.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// lfs f25,3952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3952);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f6,f25
	ctx.f25.f64 = double(float(ctx.f6.f64 + ctx.f25.f64));
	// lfs f20,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f20.f64 = double(temp.f32);
	// lfs f6,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f23,f19,f10,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 + ctx.f23.f64));
	// fmuls f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// fmadds f7,f24,f7,f4
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 + ctx.f4.f64));
	// lfs f4,3872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3872);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f4,f4,f12,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f21.f64));
	// lfs f24,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// lfs f21,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f21.f64));
	// fnmsubs f0,f22,f12,f0
	ctx.f0.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f0.f64)));
	// lfs f22,4000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4000);
	ctx.f22.f64 = double(temp.f32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// lfs f22,4772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4772);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f23,f20,f29,f23
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f29.f64 - ctx.f23.f64)));
	// fnmsubs f7,f22,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f22.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// fmadds f0,f4,f8,f0
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f0.f64));
	// stfs f0,4332(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4332, temp.u32);
	// lfs f0,1108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f24,f24,f29,f23
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f29.f64 - ctx.f23.f64)));
	// fmadds f25,f25,f10,f7
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 + ctx.f7.f64));
	// lfs f10,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f23,f0,f10
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// lfs f7,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f7.f64 = double(temp.f32);
	// lfs f0,1620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1620);
	ctx.f0.f64 = double(temp.f32);
	// lfs f4,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f22,f0,f7
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fmuls f21,f6,f4
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// lfs f6,1076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1076);
	ctx.f6.f64 = double(temp.f32);
	// lfs f4,872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 872);
	ctx.f4.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f20,f6,f4
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// lfs f4,1588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1588);
	ctx.f4.f64 = double(temp.f32);
	// lfs f19,4796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4796);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f4,f19
	ctx.f19.f64 = double(float(ctx.f4.f64 + ctx.f19.f64));
	// lfs f4,1088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1088);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f18,f4,f10
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f4,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f4.f64 = double(temp.f32);
	// lfs f10,1056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1056);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// fmuls f17,f10,f1
	ctx.f17.f64 = double(float(ctx.f10.f64 * ctx.f1.f64));
	// lfs f1,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f1.f64 = double(temp.f32);
	// lfs f10,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f10.f64 = double(temp.f32);
	// lfs f0,-29856(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29856);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f21,f1,f10,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f21.f64));
	// lfs f10,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f10.f64 = double(temp.f32);
	// lfs f15,1644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1644);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f1,f1,f3
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// fmuls f15,f15,f10
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// lfs f14,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,3432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3432);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f19,f19,f7
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f7.f64));
	// fmuls f16,f16,f10
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// fmsubs f23,f22,f0,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 - ctx.f23.f64));
	// lfs f22,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f14.f64));
	// lfs f14,1016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1016);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f6,f14
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// fmadds f24,f21,f29,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f29.f64 + ctx.f24.f64));
	// lfs f21,3472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3472);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f7
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f7.f64));
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fnmsubs f3,f20,f0,f23
	ctx.f3.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// lfs f20,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f20.f64));
	// lfs f20,3424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3424);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f10
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// fnmsubs f24,f17,f29,f24
	ctx.f24.f64 = double(float(-(ctx.f17.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// lfs f17,3488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3488);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f7
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f7.f64));
	// fmsubs f19,f15,f0,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 - ctx.f19.f64));
	// lfs f15,1116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1116);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f18,f18,f4,f3
	ctx.f18.f64 = double(float(-(ctx.f18.f64 * ctx.f4.f64 - ctx.f3.f64)));
	// lfs f3,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f15,f3
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// fmadds f24,f22,f29,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f29.f64 + ctx.f24.f64));
	// lfs f22,4788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4788);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f2,f22,f2,f23
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f2.f64 + ctx.f23.f64));
	// fmadds f23,f21,f0,f19
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f19.f64));
	// lfs f21,1120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1120);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f3,f21,f3
	ctx.f3.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// lfs f19,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f22,f16,f0,f18
	ctx.f22.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f18.f64)));
	// lfs f21,1248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1248);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f19.f64));
	// lfs f19,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,1116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1116);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f1,f1,f29,f24
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// lfs f24,1528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1528);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// lfs f19,1280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1280);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,1044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1044);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f23,f17,f0,f23
	ctx.f23.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// fmadds f3,f6,f18,f3
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f18.f64 + ctx.f3.f64));
	// fmadds f22,f14,f0,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 + ctx.f22.f64));
	// fmadds f2,f2,f29,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f29.f64 + ctx.f1.f64));
	// lfs f1,3416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3416);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f10,f1,f10
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// lfs f1,880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 880);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f6,f6,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// fmadds f4,f21,f4,f23
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 + ctx.f23.f64));
	// lfs f23,1144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1144);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f1,f20,f0,f22
	ctx.f1.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// lfs f22,1108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f10,f10,f0,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f4.f64));
	// lis r8,-32239
	ctx.r8.s64 = -2112815104;
	// fmadds f4,f15,f0,f1
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 + ctx.f1.f64));
	// lfs f16,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// lfs f22,2204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2204);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f2,f24,f29,f2
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f29.f64 - ctx.f2.f64)));
	// lfs f17,1980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1980);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f3,f22,f7,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 + ctx.f3.f64));
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,1152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1152);
	ctx.f15.f64 = double(temp.f32);
	// lis r6,-32239
	ctx.r6.s64 = -2112815104;
	// lfs f14,1276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1276);
	ctx.f14.f64 = double(temp.f32);
	// lis r25,-32239
	ctx.r25.s64 = -2112815104;
	// lfs f18,4140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4140);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f1,f6,f0,f10
	ctx.f1.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// lfs f6,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f10,f19,f0,f4
	ctx.f10.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// lfs f4,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f21,f6,f4
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// lfs f6,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f6.f64 = double(temp.f32);
	// fadds f2,f25,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// stfs f2,4336(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4336, temp.u32);
	// lfs f2,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f20,f6,f4
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// lfs f6,-29860(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -29860);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f16,f2
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// lfs f19,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f4
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// fmadds f25,f3,f0,f10
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f10,1096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1096);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f24,f10,f2
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// lfs f3,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f3.f64 = double(temp.f32);
	// lfs f10,4188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4188);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// fmuls f22,f10,f3
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f10,-29864(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29864);
	ctx.f10.f64 = double(temp.f32);
	// lfs f15,1228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1228);
	ctx.f15.f64 = double(temp.f32);
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmuls f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// lfs f14,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmadds f24,f22,f10,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 + ctx.f24.f64));
	// lfs f22,4132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4132);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f14.f64));
	// lfs f14,-29868(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -29868);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,584(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 584, temp.u32);
	// lfs f14,1364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1364);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f7
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f7.f64));
	// lfs f7,4040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4040);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f7,f3
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// lfs f7,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f2,f7,f4,f2
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f4.f64 + ctx.f2.f64));
	// lfs f4,-29876(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29876);
	ctx.f4.f64 = double(temp.f32);
	// lfs f7,-29872(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -29872);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f15,f15,f7
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f7.f64));
	// fmsubs f4,f21,f4,f24
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 - ctx.f24.f64));
	// lfs f24,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f1,f23,f24,f1
	ctx.f1.f64 = double(float(ctx.f23.f64 * ctx.f24.f64 + ctx.f1.f64));
	// lfs f23,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f24.f64));
	// lfs f23,1296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1296);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// lfs f5,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f5.f64 = double(temp.f32);
	// lfs f21,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f5,f21
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f21.f64));
	// fnmsubs f4,f20,f6,f4
	ctx.f4.f64 = double(float(-(ctx.f20.f64 * ctx.f6.f64 - ctx.f4.f64)));
	// fnmsubs f1,f14,f0,f1
	ctx.f1.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// lfs f0,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f0.f64 = double(temp.f32);
	// lfs f5,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f22,f22,f5,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64 + ctx.f15.f64));
	// lfs f5,4108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4108);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f20,f0,f5
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// lfs f15,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f5,f31,f28
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmuls f5,f5,f15
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f15.f64));
	// lfs f15,4180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4180);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f24,f24,f7,f22
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f7.f64 - ctx.f22.f64)));
	// lfs f7,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f6,f19,f6,f4
	ctx.f6.f64 = double(float(ctx.f19.f64 * ctx.f6.f64 + ctx.f4.f64));
	// lfs f22,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f4,f23,f7,f1
	ctx.f4.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 + ctx.f1.f64));
	// lfs f7,4156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4156);
	ctx.f7.f64 = double(temp.f32);
	// lfs f1,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f1.f64 = double(temp.f32);
	// lis r26,-32239
	ctx.r26.s64 = -2112815104;
	// fmuls f1,f7,f1
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f1.f64));
	// lfs f7,4124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4124);
	ctx.f7.f64 = double(temp.f32);
	// lfs f23,4172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4172);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f7,f23
	ctx.f23.f64 = double(float(ctx.f7.f64 + ctx.f23.f64));
	// lfs f7,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f7.f64 = double(temp.f32);
	// lfs f14,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f22,f7,f22
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f22.f64));
	// lfs f7,2256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2256);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// lfs f19,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,4056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4056);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f19,f7,f19
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f19.f64));
	// lfs f7,4048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4048);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f14,f0,f14
	ctx.f14.f64 = double(float(ctx.f0.f64 * ctx.f14.f64));
	// fmuls f0,f0,f7
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// stfs f0,2204(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2204, temp.u32);
	// lfs f7,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f6,f18,f10,f6
	ctx.f6.f64 = double(float(-(ctx.f18.f64 * ctx.f10.f64 - ctx.f6.f64)));
	// fnmsubs f24,f20,f7,f24
	ctx.f24.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f24.f64)));
	// lfs f20,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f5,f5,f20,f4
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f20.f64 - ctx.f4.f64)));
	// lfs f0,-30192(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -30192);
	ctx.f0.f64 = double(temp.f32);
	// lfs f4,4148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4148);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f20,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f20.f64 = double(temp.f32);
	// lfs f0,-29872(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -29872);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f20,f4,f20
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f20.f64));
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// lfs f0,-29860(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -29860);
	ctx.f0.f64 = double(temp.f32);
	// lfs f4,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// fnmsubs f18,f17,f0,f6
	ctx.f18.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f6.f64)));
	// fmadds f24,f14,f7,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 * ctx.f7.f64 + ctx.f24.f64));
	// fadds f6,f25,f5
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// stfs f6,4340(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4340, temp.u32);
	// lfs f6,-30192(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -30192);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f6,f20,f6,f1
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 - ctx.f1.f64));
	// stfs f6,4352(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4352, temp.u32);
	// lfs f20,1880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1880);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f1,f23,f7,f22
	ctx.f1.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 - ctx.f22.f64));
	// lfs f5,2204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2204);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f6,f5,f7,f24
	ctx.f6.f64 = double(float(-(ctx.f5.f64 * ctx.f7.f64 - ctx.f24.f64)));
	// stfs f6,4348(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4348, temp.u32);
	// fnmsubs f6,f16,f0,f18
	ctx.f6.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f18.f64)));
	// fmadds f6,f2,f0,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f6.f64));
	// lfs f2,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f5,f3,f10,f6
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 + ctx.f6.f64));
	// lfs f6,-29876(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29876);
	ctx.f6.f64 = double(temp.f32);
	// lfs f3,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f6,f21,f6,f5
	ctx.f6.f64 = double(float(-(ctx.f21.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// lfs f5,824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 824);
	ctx.f5.f64 = double(temp.f32);
	// lfs f21,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f6,f15,f10,f6
	ctx.f6.f64 = double(float(ctx.f15.f64 * ctx.f10.f64 + ctx.f6.f64));
	// fmadds f6,f19,f0,f6
	ctx.f6.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 + ctx.f6.f64));
	// stfs f6,4344(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4344, temp.u32);
	// lfs f6,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f25,f2,f6
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f6,2212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2212);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f6,f5
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f23,f5,f3
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f5,1564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1564);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f2,f5
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// lfs f5,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f21,f5
	ctx.f5.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// stfs f5,2212(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2212, temp.u32);
	// lfs f5,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f5.f64 = double(temp.f32);
	// lfs f21,1736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1736);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f5,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// fmuls f21,f5,f21
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f21.f64));
	// fmadds f25,f25,f31,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f31.f64 + ctx.f24.f64));
	// fmuls f24,f23,f0
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// lfs f23,1428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1428);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f25,f25,f0,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 - ctx.f24.f64));
	// fmuls f23,f19,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// lfs f18,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f18.f64 = double(temp.f32);
	// lfs f24,1292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1292);
	ctx.f24.f64 = double(temp.f32);
	// lfs f19,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f17,4204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4204);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,1816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1816);
	ctx.f18.f64 = double(temp.f32);
	// lfs f24,1744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1744);
	ctx.f24.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f17,1100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1100);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,1276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1276);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f25,f22,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// lfs f22,4116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4116);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f24,f24,f6,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 + ctx.f23.f64));
	// lfs f23,1588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1588);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// lfs f17,1272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1272);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// fmuls f16,f2,f31
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// lfs f2,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f22,f4,f22
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f22.f64));
	// fmuls f18,f18,f5
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f5.f64));
	// fmadds f24,f2,f3,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 + ctx.f24.f64));
	// lfs f2,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f15,f2,f3
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f3,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f17,f3
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// lfs f2,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f2.f64 = double(temp.f32);
	// lfs f17,1116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1116);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// fnmsubs f2,f21,f10,f25
	ctx.f2.f64 = double(float(-(ctx.f21.f64 * ctx.f10.f64 - ctx.f25.f64)));
	// lfs f25,4164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4164);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f1,f22,f7,f1
	ctx.f1.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f1.f64)));
	// lfs f22,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f25.f64));
	// lfs f21,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f22,f5,f22
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f22.f64));
	// lfs f5,3496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3496);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f5,f21
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f21.f64));
	// lfs f5,1092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1092);
	ctx.f5.f64 = double(temp.f32);
	// lfs f25,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f14,f5,f14
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// fmuls f25,f25,f6
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// lfs f5,1168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1168);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f2,f20,f10,f2
	ctx.f2.f64 = double(float(-(ctx.f20.f64 * ctx.f10.f64 - ctx.f2.f64)));
	// lfs f20,876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f5
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f5.f64));
	// fnmsubs f4,f4,f7,f1
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f7.f64 - ctx.f1.f64)));
	// lfs f7,2212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2212);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f22,f6
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// fmadds f23,f27,f7,f23
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 + ctx.f23.f64));
	// fmuls f22,f26,f7
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// lfs f7,-29872(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -29872);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f6,f19,f0,f2
	ctx.f6.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// lfs f2,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f2.f64 = double(temp.f32);
	// lfs f19,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f7,f14,f7,f4
	ctx.f7.f64 = double(float(ctx.f14.f64 * ctx.f7.f64 + ctx.f4.f64));
	// stfs f7,4356(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4356, temp.u32);
	// fmuls f2,f19,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 * ctx.f2.f64));
	// fmadds f7,f24,f0,f6
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 + ctx.f6.f64));
	// lfs f6,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f24,f6,f5,f22
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f5.f64 + ctx.f22.f64));
	// lfs f6,-29856(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29856);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f4,f23,f6,f3
	ctx.f4.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f3.f64));
	// lfs f3,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f7,f18,f10,f7
	ctx.f7.f64 = double(float(ctx.f18.f64 * ctx.f10.f64 + ctx.f7.f64));
	// fmsubs f4,f17,f3,f4
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 - ctx.f4.f64));
	// fnmsubs f7,f16,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fmadds f4,f21,f6,f4
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 + ctx.f4.f64));
	// fmadds f7,f15,f0,f7
	ctx.f7.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 + ctx.f7.f64));
	// fnmsubs f23,f20,f6,f4
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f6.f64 - ctx.f4.f64)));
	// fnmsubs f7,f25,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f25.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fnmsubs f0,f1,f0,f7
	ctx.f0.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// stfs f0,4360(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4360, temp.u32);
	// lfs f1,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f1.f64 = double(temp.f32);
	// lfs f0,1088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1088);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f4,f0,f1
	ctx.f4.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// lfs f0,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f27,f2,f27
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// lfs f18,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f0,f5
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// lfs f25,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f18,f18,f5,f4
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f5.f64 + ctx.f4.f64));
	// fmuls f0,f30,f25
	ctx.f0.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lfs f4,1100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1100);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,1364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1364);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// fmuls f17,f5,f4
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f5,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f5.f64));
	// lfs f7,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f7.f64 = double(temp.f32);
	// lfs f20,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f19.f64 = double(temp.f32);
	// stfs f5,284(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f15,4776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4776);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f21,f0,f7
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// lfs f7,1120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1120);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f20,f7,f20
	ctx.f20.f64 = double(float(ctx.f7.f64 * ctx.f20.f64));
	// lfs f7,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f19,f7,f19
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f19.f64));
	// fmuls f16,f5,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f16.f64));
	// fmuls f5,f28,f25
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// lfs f25,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f21,f21,f29
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f29.f64));
	// fmadds f25,f5,f25,f19
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f25.f64 + ctx.f19.f64));
	// fmuls f19,f18,f6
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f6.f64));
	// fmuls f18,f7,f4
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f4.f64));
	// lfs f7,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f21,f15,f7,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f7.f64 - ctx.f21.f64));
	// lfs f15,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f0,f15
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f15.f64));
	// fmadds f25,f14,f0,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 + ctx.f25.f64));
	// lfs f0,1108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f22,f22,f6,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 - ctx.f19.f64));
	// lfs f19,1104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f24,f0,f19,f24
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f19.f64 + ctx.f24.f64));
	// lfs f19,1460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1460);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f1,f0,f1
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// lfs f14,3504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3504);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f21,f16,f29,f21
	ctx.f21.f64 = double(float(-(ctx.f16.f64 * ctx.f29.f64 - ctx.f21.f64)));
	// lfs f16,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfs f16,1620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1620);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,2380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2380);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f31
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f31.f64));
	// fmadds f0,f20,f3,f22
	ctx.f0.f64 = double(float(ctx.f20.f64 * ctx.f3.f64 + ctx.f22.f64));
	// lfs f20,1116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1116);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f24,f24,f6,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 + ctx.f23.f64));
	// lfs f23,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// fmadds f25,f25,f29,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f29.f64 + ctx.f21.f64));
	// fmuls f22,f16,f4
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// lfs f4,1160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1160);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f26,f17,f6,f0
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f6.f64 - ctx.f0.f64)));
	// lfs f17,1444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1444);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f0,f31,f30
	ctx.f0.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fnmsubs f1,f1,f6,f24
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f6.f64 - ctx.f24.f64)));
	// fnmsubs f25,f15,f29,f25
	ctx.f25.f64 = double(float(-(ctx.f15.f64 * ctx.f29.f64 - ctx.f25.f64)));
	// fmuls f21,f0,f4
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// lfs f0,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f0.f64 = double(temp.f32);
	// lfs f4,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f2,f2,f6,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f1.f64));
	// fmuls f24,f0,f4
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// lfs f4,1144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1144);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f20,f4,f20
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f20.f64));
	// fmuls f4,f31,f28
	ctx.f4.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fnmsubs f1,f14,f29,f25
	ctx.f1.f64 = double(float(-(ctx.f14.f64 * ctx.f29.f64 - ctx.f25.f64)));
	// fnmsubs f3,f20,f3,f2
	ctx.f3.f64 = double(float(-(ctx.f20.f64 * ctx.f3.f64 - ctx.f2.f64)));
	// fmuls f17,f4,f17
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// fmadds f4,f18,f6,f26
	ctx.f4.f64 = double(float(ctx.f18.f64 * ctx.f6.f64 + ctx.f26.f64));
	// lfs f26,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f0,f26
	ctx.f26.f64 = double(float(ctx.f0.f64 * ctx.f26.f64));
	// fnmsubs f2,f23,f29,f1
	ctx.f2.f64 = double(float(-(ctx.f23.f64 * ctx.f29.f64 - ctx.f1.f64)));
	// fnmsubs f4,f27,f6,f4
	ctx.f4.f64 = double(float(-(ctx.f27.f64 * ctx.f6.f64 - ctx.f4.f64)));
	// fnmsubs f4,f19,f6,f4
	ctx.f4.f64 = double(float(-(ctx.f19.f64 * ctx.f6.f64 - ctx.f4.f64)));
	// lfs f23,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f2,f24,f29,f2
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 + ctx.f2.f64));
	// lfs f16,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f1,f22,f6,f4
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 + ctx.f4.f64));
	// lfs f4,4268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4268);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f2,f4,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f4.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// lfs f4,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f4.f64 = double(temp.f32);
	// lfs f22,4184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4184);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f8,f22
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f22.f64));
	// fnmsubs f1,f21,f4,f1
	ctx.f1.f64 = double(float(-(ctx.f21.f64 * ctx.f4.f64 - ctx.f1.f64)));
	// fnmsubs f2,f26,f29,f2
	ctx.f2.f64 = double(float(-(ctx.f26.f64 * ctx.f29.f64 - ctx.f2.f64)));
	// lfs f26,3844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3844);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f4,f17,f4,f1
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 + ctx.f1.f64));
	// lfs f17,4260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4260);
	ctx.f17.f64 = double(temp.f32);
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// stfs f4,4364(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4364, temp.u32);
	// lfs f4,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f0,f0,f4
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// lfs f4,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f5,f4
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f5,1580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1580);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f1,f4,f5
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// lfs f4,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f27,f5,f4
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f5,3356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3356);
	ctx.f5.f64 = double(temp.f32);
	// fadds f26,f5,f26
	ctx.f26.f64 = double(float(ctx.f5.f64 + ctx.f26.f64));
	// lfs f5,2436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2436);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f25,f8,f5
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// lfs f5,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f24,f0,f5
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// lfs f0,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f31,f0
	ctx.f0.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f27,f27,f28
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// fmuls f26,f26,f8
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// fmuls f25,f25,f12
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// fmadds f3,f3,f29,f24
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f29.f64 + ctx.f24.f64));
	// lfs f24,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f0,f23
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// fmuls f24,f0,f24
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f24.f64));
	// lfs f0,4276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4276);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f21,f8,f0
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// lfs f0,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f30
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmuls f20,f0,f4
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// lfs f0,2420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2420);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f19,f8,f0
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmsubs f0,f26,f12,f25
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 - ctx.f25.f64));
	// lfs f26,4784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4784);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f3,f26,f7,f3
	ctx.f3.f64 = double(float(-(ctx.f26.f64 * ctx.f7.f64 - ctx.f3.f64)));
	// lfs f26,1056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1056);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f4
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// lfs f4,3380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3380);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f25,f8,f4
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// lfs f4,2396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2396);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f18,f8,f4
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fnmsubs f4,f22,f12,f0
	ctx.f4.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f0.f64)));
	// lfs f0,4284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4284);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f3,f1,f5,f3
	ctx.f3.f64 = double(float(-(ctx.f1.f64 * ctx.f5.f64 - ctx.f3.f64)));
	// lfs f22,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f1,f8,f0
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// lfs f0,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f22,f0,f22
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f22.f64));
	// lfs f0,4244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4244);
	ctx.f0.f64 = double(temp.f32);
	// fadds f17,f0,f17
	ctx.f17.f64 = double(float(ctx.f0.f64 + ctx.f17.f64));
	// lfs f0,-29820(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -29820);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f21,f21,f0,f4
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f4.f64));
	// lfs f4,2412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2412);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f3,f27,f5,f3
	ctx.f3.f64 = double(float(-(ctx.f27.f64 * ctx.f5.f64 - ctx.f3.f64)));
	// fmuls f27,f8,f4
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// lfs f4,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f28,f4
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f4.f64));
	// stfs f4,232(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fnmsubs f2,f22,f29,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f29.f64 - ctx.f2.f64)));
	// lfs f22,4080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4080);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f8,f22
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f22.f64));
	// fnmsubs f21,f19,f0,f21
	ctx.f21.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f21.f64)));
	// fnmsubs f3,f23,f29,f3
	ctx.f3.f64 = double(float(-(ctx.f23.f64 * ctx.f29.f64 - ctx.f3.f64)));
	// fmuls f4,f4,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f16.f64));
	// fmadds f3,f24,f29,f3
	ctx.f3.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 + ctx.f3.f64));
	// lfs f23,2404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2404);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f4,f4,f29,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 + ctx.f2.f64));
	// lis r7,-32239
	ctx.r7.s64 = -2112815104;
	// fmadds f2,f25,f0,f21
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f21.f64));
	// lis r6,-32239
	ctx.r6.s64 = -2112815104;
	// fmuls f23,f8,f23
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f23.f64));
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f16,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f16.f64 = double(temp.f32);
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmuls f16,f9,f16
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f16.f64));
	// lfs f15,2592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2592);
	ctx.f15.f64 = double(temp.f32);
	// lis r27,-32239
	ctx.r27.s64 = -2112815104;
	// lfs f19,2428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2428);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f8,f19
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f19.f64));
	// fmadds f3,f20,f5,f3
	ctx.f3.f64 = double(float(ctx.f20.f64 * ctx.f5.f64 + ctx.f3.f64));
	// fnmsubs f2,f18,f0,f2
	ctx.f2.f64 = double(float(-(ctx.f18.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// lfs f18,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f3,f26,f29,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f29.f64 + ctx.f3.f64));
	// fnmsubs f2,f1,f12,f2
	ctx.f2.f64 = double(float(-(ctx.f1.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f1,4800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4800);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f3,f1,f7,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f7.f64 + ctx.f3.f64));
	// lfs f1,4780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4780);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f2,f27,f0,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 + ctx.f2.f64));
	// fnmsubs f3,f1,f7,f3
	ctx.f3.f64 = double(float(-(ctx.f1.f64 * ctx.f7.f64 - ctx.f3.f64)));
	// lfs f1,2616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2616);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f2,f22,f0,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fmadds f3,f17,f7,f3
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f3.f64));
	// fnmsubs f25,f23,f0,f2
	ctx.f25.f64 = double(float(-(ctx.f23.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// lfs f2,4252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4252);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f7,f2,f7,f3
	ctx.f7.f64 = double(float(-(ctx.f2.f64 * ctx.f7.f64 - ctx.f3.f64)));
	// lfs f2,2220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2220);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,2452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2452);
	ctx.f3.f64 = double(temp.f32);
	// fadds f7,f4,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// stfs f7,4368(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4368, temp.u32);
	// lfs f7,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f27,f7,f2
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f2.f64));
	// lfs f7,-29880(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -29880);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f26,f3,f7
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// lfs f7,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f24,f9,f7
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f4,-29884(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -29884);
	ctx.f4.f64 = double(temp.f32);
	// lfs f7,2360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2360);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f23,f9,f7
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f7,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f9,f7
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f7,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f22,f7,f1
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f1.f64));
	// lfs f1,2208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2208);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f7,f15
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f15.f64));
	// fmuls f21,f9,f1
	ctx.f21.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// lfs f1,-29896(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -29896);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f20,f27,f4,f26
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f4.f64 - ctx.f26.f64));
	// lfs f27,-29888(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29888);
	ctx.f27.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// lfs f27,-29900(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29900);
	ctx.f27.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f26,-29904(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29904);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f24,f20,f9,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 - ctx.f24.f64));
	// fmuls f18,f18,f26
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f26.f64));
	// lfs f20,2140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2140);
	ctx.f20.f64 = double(temp.f32);
	// lfs f26,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f9,f26
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// lfs f26,-29892(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29892);
	ctx.f26.f64 = double(temp.f32);
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmadds f27,f20,f27,f18
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f27.f64 + ctx.f18.f64));
	// lfs f20,1052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1052);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f2,f20,f2
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f2.f64));
	// lfs f20,2364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2364);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f7,f20
	ctx.f20.f64 = double(float(ctx.f7.f64 * ctx.f20.f64));
	// lfs f7,-29848(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -29848);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f18,f16,f7
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f7.f64));
	// lfs f7,-29836(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + -29836);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f7,f23,f7,f24
	ctx.f7.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 + ctx.f24.f64));
	// lfs f23,3880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3880);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,3852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3852);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f9,f24
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f24.f64));
	// fmadds f27,f23,f26,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 + ctx.f27.f64));
	// lfs f26,3396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3396);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f9,f26
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// fmadds f7,f22,f4,f7
	ctx.f7.f64 = double(float(ctx.f22.f64 * ctx.f4.f64 + ctx.f7.f64));
	// lfs f22,3364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3364);
	ctx.f22.f64 = double(temp.f32);
	// lfs f4,3372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3372);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f25,f19,f12,f25
	ctx.f25.f64 = double(float(-(ctx.f19.f64 * ctx.f12.f64 - ctx.f25.f64)));
	// fadds f4,f4,f22
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f22.f64));
	// lfs f22,4072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4072);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f0,f22,f0
	ctx.f0.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// lfs f14,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f27,f27,f9,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 - ctx.f18.f64));
	// lfs f18,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f3,f18
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// lfs f16,2468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2468);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f3,f3,f14
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f14.f64));
	// lfs f23,2024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2024);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f9,f16
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f16.f64));
	// lfs f22,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f23,f9,f23
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// lis r28,-32239
	ctx.r28.s64 = -2112815104;
	// fmuls f22,f9,f22
	ctx.f22.f64 = double(float(ctx.f9.f64 * ctx.f22.f64));
	// lis r8,-32231
	ctx.r8.s64 = -2112290816;
	// fnmsubs f7,f21,f1,f7
	ctx.f7.f64 = double(float(-(ctx.f21.f64 * ctx.f1.f64 - ctx.f7.f64)));
	// lfs f1,2300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2300);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f12
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f21,2460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2460);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f9,f21
	ctx.f21.f64 = double(float(ctx.f9.f64 * ctx.f21.f64));
	// fmadds f19,f4,f12,f0
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f0.f64));
	// lfs f0,-29848(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -29848);
	ctx.f0.f64 = double(temp.f32);
	// lfs f4,-29908(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29908);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f27,f18,f4,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f27.f64));
	// fnmsubs f17,f17,f0,f7
	ctx.f17.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// lfs f7,-29844(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29844);
	ctx.f7.f64 = double(temp.f32);
	// lfs f0,2124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2124);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f1,f0,f7,f1
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f7.f64 + ctx.f1.f64));
	// lfs f0,4024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4024);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f14,f9,f0
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmadds f0,f19,f8,f25
	ctx.f0.f64 = double(float(ctx.f19.f64 * ctx.f8.f64 + ctx.f25.f64));
	// stfs f0,4372(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4372, temp.u32);
	// lfs f0,-29884(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -29884);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f4,f3,f4,f27
	ctx.f4.f64 = double(float(-(ctx.f3.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// fnmsubs f25,f15,f0,f17
	ctx.f25.f64 = double(float(-(ctx.f15.f64 * ctx.f0.f64 - ctx.f17.f64)));
	// fnmsubs f3,f2,f0,f25
	ctx.f3.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// lfs f0,-29880(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -29880);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f4,f26,f0,f4
	ctx.f4.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f4.f64));
	// lfs f25,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f3,f20,f12,f3
	ctx.f3.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f3.f64));
	// fnmsubs f4,f16,f0,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// fmadds f3,f24,f0,f3
	ctx.f3.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 + ctx.f3.f64));
	// fmadds f4,f21,f0,f4
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f4.f64));
	// lfs f0,-29904(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29904);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,200(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fnmsubs f7,f23,f7,f3
	ctx.f7.f64 = double(float(-(ctx.f23.f64 * ctx.f7.f64 - ctx.f3.f64)));
	// lfs f3,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f27,f14,f0,f4
	ctx.f27.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// lfs f4,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f0,f22,f12,f7
	ctx.f0.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f7.f64)));
	// lfs f7,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f1,f1,f9,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f0.f64));
	// lfs f0,1504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1504);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f2,f7,f0
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f7,f3,f31
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f26,f4,f7
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// lfs f7,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f31,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f7.f64));
	// stfs f7,212(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fmuls f25,f25,f7
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f7.f64));
	// fmuls f7,f3,f28
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// lfs f3,1372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1372);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f24,f7,f3
	ctx.f24.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// lfs f7,-29912(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -29912);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f23,f2,f7
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// lfs f2,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f7,f2,f28
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// lfs f3,1452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1452);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f22,f7,f3
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// lfs f7,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f7.f64 = double(temp.f32);
	// lfs f3,1076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1076);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f21,f3,f7
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// lfs f7,1876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1876);
	ctx.f7.f64 = double(temp.f32);
	// lfs f3,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f23,f3,f7,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f7.f64 + ctx.f23.f64));
	// fmuls f7,f2,f31
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmadds f22,f4,f7,f22
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f7.f64 + ctx.f22.f64));
	// stfs f7,1876(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1876, temp.u32);
	// lfs f7,2508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2508);
	ctx.f7.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f20,f7,f0
	ctx.f20.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f7,2236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2236);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f19,f3,f7
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// lfs f7,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f4,f26,f7,f23
	ctx.f4.f64 = double(float(-(ctx.f26.f64 * ctx.f7.f64 - ctx.f23.f64)));
	// lfs f2,3436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3436);
	ctx.f2.f64 = double(temp.f32);
	// lfs f7,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f7.f64 = double(temp.f32);
	// lis r15,-32239
	ctx.r15.s64 = -2112815104;
	// fmuls f26,f2,f7
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// lfs f2,2476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2476);
	ctx.f2.f64 = double(temp.f32);
	// lfs f23,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f21,f21,f31
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f31.f64));
	// fmuls f23,f23,f2
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// lfs f2,-29916(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29916);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,776(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 776, temp.u32);
	// lfs f2,3388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3388);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f18,f9,f2
	ctx.f18.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// lfs f2,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f2.f64 = double(temp.f32);
	// lfs f17,2044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2044);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f17,f2,f17,f4
	ctx.f17.f64 = double(float(-(ctx.f2.f64 * ctx.f17.f64 - ctx.f4.f64)));
	// lfs f4,2600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2600);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f16,f16,f4
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// lfs f4,1920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1920);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f15,f2,f4
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// lfs f4,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f4.f64 = double(temp.f32);
	// lfs f14,4192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4192);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f26,f14,f4,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 * ctx.f4.f64 + ctx.f26.f64));
	// lfs f14,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f27,f23,f14,f27
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f14.f64 - ctx.f27.f64)));
	// lfs f23,2244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2244);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f2,f23
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f2,3860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3860);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f14,f9,f2
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// lfs f2,16816(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 16816);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f2,f25,f2,f17
	ctx.f2.f64 = double(float(-(ctx.f25.f64 * ctx.f2.f64 - ctx.f17.f64)));
	// lfs f17,812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 812);
	ctx.f17.f64 = double(temp.f32);
	// lfs f25,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f3,f17
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// lfs f3,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f25,f16,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// fmuls f16,f3,f0
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// lfs f3,-29920(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + -29920);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f3,f18,f3,f27
	ctx.f3.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f27.f64)));
	// lfs f27,2484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2484);
	ctx.f27.f64 = double(temp.f32);
	// lfs f18,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f27,f27,f0
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f18,f18,f0
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// lfs f0,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f2,f24,f0,f2
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// lfs f0,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f0.f64 = double(temp.f32);
	// lfs f24,1504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1504);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f0,f24
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f24.f64));
	// lfs f0,-29884(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -29884);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f16,f16,f4
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// fmadds f3,f25,f0,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f3.f64));
	// lfs f0,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f2,f22,f0,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 + ctx.f2.f64));
	// lfs f0,-29880(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -29880);
	ctx.f0.f64 = double(temp.f32);
	// lfs f22,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f25,f18,f4,f16
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 - ctx.f16.f64));
	// fnmsubs f18,f14,f0,f3
	ctx.f18.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f3.f64)));
	// lfs f3,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f0,f22,f28
	ctx.f0.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// fnmsubs f2,f3,f0,f2
	ctx.f2.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fadds f0,f1,f18
	ctx.f0.f64 = double(float(ctx.f1.f64 + ctx.f18.f64));
	// stfs f0,4376(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4376, temp.u32);
	// lfs f0,16816(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 16816);
	ctx.f0.f64 = double(temp.f32);
	// lfs f1,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f2,f21,f0,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f2.f64));
	// lfs f0,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f2,f0,f1,f2
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f1.f64 + ctx.f2.f64));
	// lfs f1,1264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1264);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f2,f3,f1,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f1.f64 + ctx.f2.f64));
	// lfs f1,1504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1504);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f2,f20,f4,f2
	ctx.f2.f64 = double(float(-(ctx.f20.f64 * ctx.f4.f64 - ctx.f2.f64)));
	// fnmsubs f2,f19,f4,f2
	ctx.f2.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f2.f64)));
	// fmadds f2,f26,f1,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 + ctx.f2.f64));
	// lfs f1,1296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1296);
	ctx.f1.f64 = double(temp.f32);
	// lfs f21,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f21.f64 = double(temp.f32);
	// lis r16,-32239
	ctx.r16.s64 = -2112815104;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f16,2612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2612);
	ctx.f16.f64 = double(temp.f32);
	// lis r17,-32239
	ctx.r17.s64 = -2112815104;
	// lfs f26,-29924(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29924);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f2,f15,f4,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f4.f64 + ctx.f2.f64));
	// fnmsubs f2,f23,f4,f2
	ctx.f2.f64 = double(float(-(ctx.f23.f64 * ctx.f4.f64 - ctx.f2.f64)));
	// lfs f23,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f19,f21,f23
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f23.f64));
	// lfs f23,1328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1328);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f2,f17,f4,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 + ctx.f2.f64));
	// fnmsubs f20,f27,f7,f2
	ctx.f20.f64 = double(float(-(ctx.f27.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// lfs f27,2336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2336);
	ctx.f27.f64 = double(temp.f32);
	// lfs f2,-29912(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -29912);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// fnmsubs f2,f24,f2,f25
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// lfs f25,1076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1076);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,2532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2532);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// lfs f27,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f0,f27
	ctx.f27.f64 = double(float(ctx.f0.f64 * ctx.f27.f64));
	// fnmsubs f2,f1,f4,f2
	ctx.f2.f64 = double(float(-(ctx.f1.f64 * ctx.f4.f64 - ctx.f2.f64)));
	// lfs f1,2252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2252);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f1,f25,f1,f2
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f1.f64 - ctx.f2.f64)));
	// lfs f2,-30276(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + -30276);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f1,f25,f23,f1
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f23.f64 + ctx.f1.f64));
	// lfs f23,2076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2076);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f2,f23,f2,f24
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 - ctx.f24.f64));
	// lfs f24,1912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1912);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f1,f0,f24,f1
	ctx.f1.f64 = double(float(-(ctx.f0.f64 * ctx.f24.f64 - ctx.f1.f64)));
	// lfs f24,4240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4240);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f2,f24,f6,f2
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// lfs f24,2028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2028);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f18,f3,f24
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// lfs f24,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f21,f27,f26,f1
	ctx.f21.f64 = double(float(-(ctx.f27.f64 * ctx.f26.f64 - ctx.f1.f64)));
	// lfs f27,3876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3876);
	ctx.f27.f64 = double(temp.f32);
	// lfs f1,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f17,f27,f1,f2
	ctx.f17.f64 = double(float(-(ctx.f27.f64 * ctx.f1.f64 - ctx.f2.f64)));
	// lfs f2,-30112(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + -30112);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f27,f24,f31
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// fnmsubs f17,f16,f29,f17
	ctx.f17.f64 = double(float(-(ctx.f16.f64 * ctx.f29.f64 - ctx.f17.f64)));
	// lfs f16,1280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1280);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f21,f23,f27,f21
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f27.f64 + ctx.f21.f64));
	// fnmsubs f27,f16,f27,f21
	ctx.f27.f64 = double(float(-(ctx.f16.f64 * ctx.f27.f64 - ctx.f21.f64)));
	// lfs f21,2548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2548);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f1,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 + ctx.f17.f64));
	// lfs f17,1332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1332);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f3,f3,f17,f27
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f17.f64 + ctx.f27.f64));
	// lfs f27,2596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2596);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f27,f27,f7,f21
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f7.f64 - ctx.f21.f64)));
	// lfs f17,2260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2260);
	ctx.f17.f64 = double(temp.f32);
	// lfs f21,1168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1168);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f3,f17,f21,f3
	ctx.f3.f64 = double(float(-(ctx.f17.f64 * ctx.f21.f64 - ctx.f3.f64)));
	// lfs f17,3444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3444);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f27,f17,f7,f27
	ctx.f27.f64 = double(float(-(ctx.f17.f64 * ctx.f7.f64 - ctx.f27.f64)));
	// lfs f17,1520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1520);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f3,f0,f17,f3
	ctx.f3.f64 = double(float(-(ctx.f0.f64 * ctx.f17.f64 - ctx.f3.f64)));
	// lfs f17,2084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2084);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f27,f17,f2,f27
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 + ctx.f27.f64));
	// fmadds f3,f19,f26,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f26.f64 + ctx.f3.f64));
	// lfs f26,2200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2200);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f26,f26,f2,f27
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f27,1728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1728);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f25,f25,f27,f3
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f27.f64 - ctx.f3.f64)));
	// lfs f3,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f27,f3,f31
	ctx.f27.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmadds f25,f23,f27,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f27.f64 + ctx.f25.f64));
	// fmuls f27,f22,f30
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// fmadds f27,f0,f27,f25
	ctx.f27.f64 = double(float(ctx.f0.f64 * ctx.f27.f64 + ctx.f25.f64));
	// lfs f25,2012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2012);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f27,f18,f4,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f27.f64));
	// fnmsubs f0,f0,f25,f27
	ctx.f0.f64 = double(float(-(ctx.f0.f64 * ctx.f25.f64 - ctx.f27.f64)));
	// lfs f27,2268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2268);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f0,f27,f21,f0
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f21.f64 + ctx.f0.f64));
	// fadds f0,f20,f0
	ctx.f0.f64 = double(float(ctx.f20.f64 + ctx.f0.f64));
	// stfs f0,4380(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4380, temp.u32);
	// lfs f27,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f27.f64 = double(temp.f32);
	// lis r18,-32239
	ctx.r18.s64 = -2112815104;
	// lfs f0,1040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1040);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f27,f0
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// lfs f22,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f22.f64 = double(temp.f32);
	// lfs f27,1108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f22.f64));
	// lfs f16,2572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2572);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,2524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2524);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f23,2556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2556);
	ctx.f23.f64 = double(temp.f32);
	// lfs f16,2580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2580);
	ctx.f16.f64 = double(temp.f32);
	// lfs f25,3468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3468);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f23.f64));
	// lfs f23,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,4032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4032);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f21,f0,f5
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// fmuls f0,f31,f31
	ctx.f0.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmadds f17,f17,f7,f26
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f26.f64));
	// lfs f26,1312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1312);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f21,f27,f5,f21
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 - ctx.f21.f64));
	// lfs f27,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f0,f23
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// lfs f0,3644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3644);
	ctx.f0.f64 = double(temp.f32);
	// lfs f23,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f27,f18
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// fmuls f19,f23,f0
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fnmsubs f21,f16,f29,f21
	ctx.f21.f64 = double(float(-(ctx.f16.f64 * ctx.f29.f64 - ctx.f21.f64)));
	// fmuls f16,f27,f0
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// lfs f0,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f15,f0,f26
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f26.f64));
	// lfs f0,-29928(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + -29928);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f21,f25,f29,f21
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f29.f64 + ctx.f21.f64));
	// lfs f25,2288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2288);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f17,f25,f2,f17
	ctx.f17.f64 = double(float(-(ctx.f25.f64 * ctx.f2.f64 - ctx.f17.f64)));
	// lfs f25,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// lfs f2,-16900(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -16900);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f21,f14,f2,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f2.f64 + ctx.f21.f64));
	// lfs f2,2224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2224);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f17,f2,f1,f17
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f1.f64 + ctx.f17.f64));
	// lfs f2,1088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1088);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f26,f2,f22,f26
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 + ctx.f26.f64));
	// lfs f22,4212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4212);
	ctx.f22.f64 = double(temp.f32);
	// lfs f2,-29812(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -29812);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f2,f22,f2,f21
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f21.f64)));
	// lfs f22,3892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3892);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f29,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f29.f64 + ctx.f17.f64));
	// lfs f21,2176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2176);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f2,f20,f4,f2
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f4.f64 + ctx.f2.f64));
	// fnmsubs f22,f21,f0,f22
	ctx.f22.f64 = double(float(-(ctx.f21.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// fmadds f2,f19,f5,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 * ctx.f5.f64 + ctx.f2.f64));
	// fmadds f26,f26,f5,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f5.f64 + ctx.f22.f64));
	// lfs f22,2620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2620);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f2,f22,f29,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f29.f64 + ctx.f2.f64));
	// lfs f22,3884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3884);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f26,f22,f29,f26
	ctx.f26.f64 = double(float(-(ctx.f22.f64 * ctx.f29.f64 - ctx.f26.f64)));
	// lfs f22,3452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3452);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f2,f22,f7,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 + ctx.f2.f64));
	// lfs f22,3428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3428);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f2,f22,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// lfs f22,2588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2588);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f2,f18,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f18.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// fnmsubs f2,f22,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// lfs f22,4104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4104);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f2,f16,f5,f2
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f5.f64 + ctx.f2.f64));
	// fnmsubs f2,f15,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// fnmsubs f2,f22,f1,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f1.f64 - ctx.f2.f64)));
	// lfs f1,2564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2564);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f2,f1,f29,f2
	ctx.f2.f64 = double(float(-(ctx.f1.f64 * ctx.f29.f64 - ctx.f2.f64)));
	// lfs f1,2264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2264);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f0,f1,f0,f2
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f2.f64));
	// lfs f2,3460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3460);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f0,f2,f29,f0
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f29.f64 + ctx.f0.f64));
	// lfs f2,1060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1060);
	ctx.f2.f64 = double(temp.f32);
	// fadds f0,f26,f0
	ctx.f0.f64 = double(float(ctx.f26.f64 + ctx.f0.f64));
	// stfs f0,4384(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4384, temp.u32);
	// lfs f0,2924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2924);
	ctx.f0.f64 = double(temp.f32);
	// lfs f26,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f22,f2,f0
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfs f1,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f1.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f18,f1,f13
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f2,1304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1304);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,1288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1288);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f3,f2
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f17,f3,f1
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f3,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f13,f3
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// lfs f0,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f21,f0,f26
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f26.f64));
	// lfs f0,-29932(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29932);
	ctx.f0.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f16,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f16.f64 = double(temp.f32);
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmuls f25,f25,f26
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// lfs f26,4220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4220);
	ctx.f26.f64 = double(temp.f32);
	// lis r19,-32239
	ctx.r19.s64 = -2112815104;
	// fmuls f19,f24,f2
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// lis r29,-32239
	ctx.r29.s64 = -2112815104;
	// fmuls f24,f24,f1
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// lis r22,-32239
	ctx.r22.s64 = -2112815104;
	// lis r20,-32239
	ctx.r20.s64 = -2112815104;
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// fmadds f22,f16,f3,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 + ctx.f22.f64));
	// lfs f3,-29936(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29936);
	ctx.f3.f64 = double(temp.f32);
	// lfs f16,3476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3476);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmuls f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// lfs f3,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// lfs f3,-29940(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29940);
	ctx.f3.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmuls f24,f24,f0
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f22,f22,f3
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f3.f64));
	// lfs f3,1236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1236);
	ctx.f3.f64 = double(temp.f32);
	// fadds f15,f3,f26
	ctx.f15.f64 = double(float(ctx.f3.f64 + ctx.f26.f64));
	// lfs f3,2116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2116);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f17,f17,f0,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f16.f64));
	// lfs f16,2636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2636);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f11
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// lfs f26,-29960(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29960);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f3,f13
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfs f3,1192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1192);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f27,f27,f3
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// fmuls f23,f23,f3
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f3,2628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2628);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f22,f21,f0,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 - ctx.f22.f64));
	// lfs f21,4228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4228);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// fmuls f15,f3,f11
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// lfs f3,-29944(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -29944);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// lfs f3,4236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4236);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fnmsubs f22,f20,f0,f22
	ctx.f22.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// fadds f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f3.f64));
	// lfs f3,3900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3900);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f11
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// stfs f3,1312(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1312, temp.u32);
	// lfs f3,-29948(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -29948);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f27,f13
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// fmsubs f16,f15,f3,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f3.f64 - ctx.f16.f64));
	// lfs f27,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f27.f64 = double(temp.f32);
	// lfs f3,2644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2644);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f22,f19,f0,f22
	ctx.f22.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// lfs f19,3404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3404);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f26,f21,f26,f24
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f26.f64 + ctx.f24.f64));
	// fmuls f24,f3,f27
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f3,1300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1300);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f21,f3,f13
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfs f3,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fnmsubs f22,f18,f0,f22
	ctx.f22.f64 = double(float(-(ctx.f18.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// lfs f18,3484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3484);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,1312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1312);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f16,f15,f27,f16
	ctx.f16.f64 = double(float(-(ctx.f15.f64 * ctx.f27.f64 - ctx.f16.f64)));
	// lfs f27,-29952(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -29952);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f18,f18,f27,f26
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f27.f64 + ctx.f26.f64));
	// lfs f26,1752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1752);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f22,f17,f13,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f22.f64));
	// lfs f27,-29948(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -29948);
	ctx.f27.f64 = double(temp.f32);
	// lis r22,-32239
	ctx.r22.s64 = -2112815104;
	// fmadds f27,f26,f27,f24
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f27.f64 + ctx.f24.f64));
	// lfs f26,2132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2132);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f24,f26,f13
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// lfs f26,2772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2772);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f26,f3
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// lfs f26,2156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2156);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f11
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// stfs f26,1312(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1312, temp.u32);
	// lfs f26,-29956(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -29956);
	ctx.f26.f64 = double(temp.f32);
	// lis r21,-32239
	ctx.r21.s64 = -2112815104;
	// lis r20,-32239
	ctx.r20.s64 = -2112815104;
	// lis r14,-32239
	ctx.r14.s64 = -2112815104;
	// fnmsubs f25,f25,f0,f22
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// fmadds f27,f27,f11,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f16.f64));
	// fmadds f22,f19,f26,f27
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f26.f64 + ctx.f27.f64));
	// lfs f27,-29960(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29960);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f25,f14,f27,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 * ctx.f27.f64 + ctx.f25.f64));
	// lfs f27,-29968(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -29968);
	ctx.f27.f64 = double(temp.f32);
	// lis r21,-32239
	ctx.r21.s64 = -2112815104;
	// lfs f19,1244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1244);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// fnmsubs f22,f15,f27,f22
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f27.f64 - ctx.f22.f64)));
	// lfs f15,3556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3556);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f25,f23,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f23.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// fnmsubs f25,f20,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// fmadds f23,f18,f13,f25
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f25.f64));
	// lfs f25,-29896(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -29896);
	ctx.f25.f64 = double(temp.f32);
	// lfs f18,2780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2780);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f23,f21,f25,f23
	ctx.f23.f64 = double(float(-(ctx.f21.f64 * ctx.f25.f64 - ctx.f23.f64)));
	// lfs f25,-29964(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -29964);
	ctx.f25.f64 = double(temp.f32);
	// lis r22,-32239
	ctx.r22.s64 = -2112815104;
	// fmadds f25,f24,f25,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f25.f64 + ctx.f23.f64));
	// stfs f25,4388(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4388, temp.u32);
	// lfs f25,3548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3548);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f25,f27
	ctx.f24.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f27,2164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2164);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f23,f27,f11
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// lfs f27,4200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4200);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f21,f27,f10
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f25,-29972(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -29972);
	ctx.f25.f64 = double(temp.f32);
	// lfs f27,2180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2180);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f27,f11
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// lfs f27,-29980(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -29980);
	ctx.f27.f64 = double(temp.f32);
	// lis r22,-32239
	ctx.r22.s64 = -2112815104;
	// fmsubs f18,f18,f26,f24
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f26.f64 - ctx.f24.f64));
	// lfs f26,-29976(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -29976);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f23,f26
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f26.f64));
	// lfs f26,4128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4128);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f26,f13
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// lfs f26,2188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2188);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f25,f26,f25,f21
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f25.f64 + ctx.f21.f64));
	// lfs f21,2788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2788);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f26,f31,f31
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// lfs f24,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f16,f24,f2
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// fmuls f24,f24,f1
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// fmsubs f23,f18,f3,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f3.f64 - ctx.f23.f64));
	// lfs f18,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f1
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fmuls f21,f21,f26
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f26.f64));
	// lfs f26,-30180(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -30180);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,500(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// lfs f26,-30184(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -30184);
	ctx.f26.f64 = double(temp.f32);
	// lis r23,-32239
	ctx.r23.s64 = -2112815104;
	// fmuls f26,f15,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f26.f64));
	// lfs f15,3492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3492);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f11
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// fnmsubs f23,f20,f27,f23
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f27.f64 - ctx.f23.f64)));
	// lfs f1,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f21,f21,f1,f26
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 + ctx.f26.f64));
	// lfs f26,2828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2828);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f20,f26,f3
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// lfs f26,-29984(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -29984);
	ctx.f26.f64 = double(temp.f32);
	// lfs f1,-30208(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -30208);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f25,f17,f26,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 - ctx.f25.f64));
	// lfs f26,2668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2668);
	ctx.f26.f64 = double(temp.f32);
	// lis r23,-32239
	ctx.r23.s64 = -2112815104;
	// fmuls f17,f26,f11
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f26,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f24,f26,f2,f24
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 + ctx.f24.f64));
	// lfs f26,-29976(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -29976);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f25,f16,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// lfs f16,2676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2676);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// lfs f2,-29988(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -29988);
	ctx.f2.f64 = double(temp.f32);
	// lis r23,-32239
	ctx.r23.s64 = -2112815104;
	// fnmsubs f23,f19,f2,f23
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f2.f64 - ctx.f23.f64)));
	// lfs f19,1312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1312);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f26,f19,f26,f22
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// lfs f19,2908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2908);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f19,f1,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f1.f64 + ctx.f21.f64));
	// lfs f22,2228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2228);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// lfs f1,-30220(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -30220);
	ctx.f1.f64 = double(temp.f32);
	// lis r23,-32239
	ctx.r23.s64 = -2112815104;
	// fmuls f20,f20,f1
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f1.f64));
	// lfs f1,-29944(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -29944);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f25,f18,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f18.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// lfs f18,1060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1060);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f23,f15,f1,f23
	ctx.f23.f64 = double(float(-(ctx.f15.f64 * ctx.f1.f64 - ctx.f23.f64)));
	// lfs f1,3908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3908);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f1,f11
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// lfs f1,3500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	ctx.f1.f64 = double(temp.f32);
	// fadds f16,f1,f16
	ctx.f16.f64 = double(float(ctx.f1.f64 + ctx.f16.f64));
	// lfs f1,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f18,f1,f18
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f18.f64));
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f22,f22,f27,f26
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f27.f64 - ctx.f26.f64)));
	// lfs f1,1192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1192);
	ctx.f1.f64 = double(temp.f32);
	// lfs f27,2148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2148);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f24,f15,f1,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f1.f64 + ctx.f24.f64));
	// fmuls f15,f27,f11
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// lfs f27,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f21,f21,f3,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 - ctx.f20.f64));
	// lfs f26,2660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2660);
	ctx.f26.f64 = double(temp.f32);
	// lfs f20,1136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1136);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f26,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// lfs f26,-29940(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29940);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f23,f17,f27,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f27.f64 + ctx.f23.f64));
	// fmuls f17,f16,f11
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// fnmsubs f26,f18,f26,f25
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f26.f64 - ctx.f25.f64)));
	// lfs f18,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f25,f24,f13
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// lfs f24,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// fnmsubs f2,f15,f2,f22
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f2.f64 - ctx.f22.f64)));
	// stfs f2,4392(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4392, temp.u32);
	// lfs f2,-30192(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -30192);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f2,f20,f2,f21
	ctx.f2.f64 = double(float(-(ctx.f20.f64 * ctx.f2.f64 - ctx.f21.f64)));
	// stfs f2,4396(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4396, temp.u32);
	// fnmsubs f27,f19,f27,f23
	ctx.f27.f64 = double(float(-(ctx.f19.f64 * ctx.f27.f64 - ctx.f23.f64)));
	// lfs f2,-29948(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -29948);
	ctx.f2.f64 = double(temp.f32);
	// lfs f20,2928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2928);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,2916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2916);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,3620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3620);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// fmadds f26,f25,f0,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f26.f64));
	// fmuls f25,f1,f13
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f1,1284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1284);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f2,f17,f2,f27
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 + ctx.f27.f64));
	// stfs f2,4400(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4400, temp.u32);
	// lfs f2,1712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1712);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f24,f1,f2
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f2,4112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4112);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f23,f2,f13
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f27,-29992(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -29992);
	ctx.f27.f64 = double(temp.f32);
	// lis r23,-32239
	ctx.r23.s64 = -2112815104;
	// lfs f2,4144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4144);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f1,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f20.f64));
	// lfs f20,2652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2652);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f22,f2,f3
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// stfs f27,352(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// lfs f2,-29996(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -29996);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// fmuls f23,f23,f10
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f17,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f1,f3
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f3,2732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2732);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f1,f24,f27,f23
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f27.f64 - ctx.f23.f64));
	// lfs f24,2924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2924);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f3,f3,f7
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// lfs f27,1064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1064);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f24.f64));
	// lfs f24,3972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3972);
	ctx.f24.f64 = double(temp.f32);
	// lfs f15,3628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3628);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f26,f25,f0,f26
	ctx.f26.f64 = double(float(-(ctx.f25.f64 * ctx.f0.f64 - ctx.f26.f64)));
	// lfs f14,2348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2348);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,2276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2276);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// lfs f25,2196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2196);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fmadds f24,f24,f2,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f2.f64 + ctx.f19.f64));
	// lfs f19,2972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2972);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f17,1896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1896);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f2,f22,f2,f1
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// lfs f1,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f17,f17,f7,f3
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 - ctx.f3.f64));
	// lfs f3,2932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2932);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f22,f3,f13
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f3,f31,f31
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f16,f1,f3
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f3,3508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3508);
	ctx.f3.f64 = double(temp.f32);
	// lfs f1,2700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2700);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f3,f1
	ctx.f1.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// lfs f3,-29960(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29960);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f15,f3
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// lfs f3,-30276(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + -30276);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f3,f14,f3,f17
	ctx.f3.f64 = double(float(-(ctx.f14.f64 * ctx.f3.f64 - ctx.f17.f64)));
	// lfs f17,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f2,f21,f17,f2
	ctx.f2.f64 = double(float(-(ctx.f21.f64 * ctx.f17.f64 - ctx.f2.f64)));
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,1040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1040);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f17.f64));
	// lfs f21,2284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2284);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfs f14,2684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2684);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f13
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// fmadds f15,f1,f10,f15
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f15.f64));
	// lfs f1,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f3,f19,f5,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f5.f64 + ctx.f3.f64));
	// lfs f19,1120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1120);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f2,f18,f1,f2
	ctx.f2.f64 = double(float(-(ctx.f18.f64 * ctx.f1.f64 - ctx.f2.f64)));
	// lfs f18,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,3980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3980);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// fmadds f26,f15,f13,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f26.f64));
	// fnmsubs f16,f16,f4,f3
	ctx.f16.f64 = double(float(-(ctx.f16.f64 * ctx.f4.f64 - ctx.f3.f64)));
	// lfs f3,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f2,f20,f10,f2
	ctx.f2.f64 = double(float(-(ctx.f20.f64 * ctx.f10.f64 - ctx.f2.f64)));
	// lfs f20,3644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3644);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f3,f20
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// lfs f3,-29960(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29960);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f26,f18,f3,f26
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f26.f64)));
	// fnmsubs f18,f17,f5,f16
	ctx.f18.f64 = double(float(-(ctx.f17.f64 * ctx.f5.f64 - ctx.f16.f64)));
	// lfs f17,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f24,f24,f17,f2
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f17.f64 + ctx.f2.f64));
	// lfs f2,-29940(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29940);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f19,f19,f5,f18
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f5.f64 - ctx.f18.f64)));
	// fmadds f27,f27,f2,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f2.f64 + ctx.f24.f64));
	// lfs f2,2724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2724);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f24,f2,f7,f19
	ctx.f24.f64 = double(float(-(ctx.f2.f64 * ctx.f7.f64 - ctx.f19.f64)));
	// lfs f2,-29972(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -29972);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f27,f23,f2,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f27.f64));
	// lfs f2,4264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4264);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f24,f2,f29,f24
	ctx.f24.f64 = double(float(-(ctx.f2.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// lfs f2,-29984(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -29984);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f2,f22,f2,f27
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// fmadds f2,f21,f3,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 + ctx.f2.f64));
	// fnmsubs f3,f25,f3,f2
	ctx.f3.f64 = double(float(-(ctx.f25.f64 * ctx.f3.f64 - ctx.f2.f64)));
	// lfs f2,2332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2332);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f3,f14,f10,f3
	ctx.f3.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 + ctx.f3.f64));
	// fadds f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// stfs f3,4404(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4404, temp.u32);
	// lfs f3,-30112(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + -30112);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f26,f20,f5,f24
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f5.f64 + ctx.f24.f64));
	// fmuls f2,f2,f3
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f27,4120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4120);
	ctx.f27.f64 = double(temp.f32);
	// lfs f25,1040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1040);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,2708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2708);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f27,f27,f29,f2
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f29.f64 - ctx.f2.f64));
	// lfs f2,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f2,f25
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// fmadds f27,f24,f7,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 + ctx.f27.f64));
	// lfs f24,2972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2972);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f26,f25,f5,f26
	ctx.f26.f64 = double(float(-(ctx.f25.f64 * ctx.f5.f64 - ctx.f26.f64)));
	// lfs f25,1116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1116);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f23,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f23.f64));
	// lfs f23,3532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3532);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f27,f23,f29,f27
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f29.f64 - ctx.f27.f64)));
	// lfs f23,2756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2756);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f26,f23,f29,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f29.f64 + ctx.f26.f64));
	// lfs f23,3524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3524);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f27,f23,f6,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f27.f64));
	// lfs f23,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f2
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// fnmsubs f2,f24,f5,f26
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f5.f64 - ctx.f26.f64)));
	// lfs f26,2748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2748);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f27,f26,f29,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f29.f64 - ctx.f27.f64)));
	// lfs f26,1760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1760);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f2,f25,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f25.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f5,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f5.f64 = double(temp.f32);
	// lfs f25,4152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4152);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f27,f26,f5,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f5.f64 + ctx.f27.f64));
	// lfs f26,3932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3932);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f26,f26,f29,f2
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f29.f64 - ctx.f2.f64)));
	// lfs f2,1832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1832);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f27,f2,f5,f27
	ctx.f27.f64 = double(float(-(ctx.f2.f64 * ctx.f5.f64 - ctx.f27.f64)));
	// lfs f2,-16900(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -16900);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,300(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fnmsubs f2,f25,f2,f26
	ctx.f2.f64 = double(float(-(ctx.f25.f64 * ctx.f2.f64 - ctx.f26.f64)));
	// lfs f26,2292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2292);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,2980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2980);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f27,f26,f3,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f3.f64 + ctx.f27.f64));
	// fmadds f26,f23,f7,f2
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 + ctx.f2.f64));
	// lfs f2,2692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2692);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f27,f2,f5,f27
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f5.f64 + ctx.f27.f64));
	// lfs f2,-29812(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -29812);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f26,f25,f2,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 + ctx.f26.f64));
	// lfs f2,2764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2764);
	ctx.f2.f64 = double(temp.f32);
	// lfs f25,2316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2316);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f27,f2,f29,f27
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f29.f64 + ctx.f27.f64));
	// lfs f2,-29928(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + -29928);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f26,f25,f2,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 + ctx.f26.f64));
	// lfs f25,3652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3652);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f5,f25,f5,f27
	ctx.f5.f64 = double(float(-(ctx.f25.f64 * ctx.f5.f64 - ctx.f27.f64)));
	// lfs f27,3916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3916);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f26,f27,f6,f26
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f6.f64 + ctx.f26.f64));
	// lfs f6,3516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3516);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f6,f6,f29,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f29.f64 + ctx.f5.f64));
	// lfs f5,2308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2308);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f6,f5,f2,f6
	ctx.f6.f64 = double(float(-(ctx.f5.f64 * ctx.f2.f64 - ctx.f6.f64)));
	// lfs f5,2340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2340);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f6,f5,f3,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f3.f64 + ctx.f6.f64));
	// lfs f5,3540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3540);
	ctx.f5.f64 = double(temp.f32);
	// lfs f3,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f6,f5,f7,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 + ctx.f6.f64));
	// lfs f5,2716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2716);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f25,f5,f29,f6
	ctx.f25.f64 = double(float(-(ctx.f5.f64 * ctx.f29.f64 - ctx.f6.f64)));
	// lfs f6,1444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1444);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f27,f5,f6
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,1176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1176);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f24,f5,f6
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,1544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1544);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f23,f5,f6
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fmuls f22,f3,f6
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f5,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f5.f64 = double(temp.f32);
	// lis r23,-32239
	ctx.r23.s64 = -2112815104;
	// fmuls f21,f2,f5
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// lfs f5,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f18,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f2,f18
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// lfs f2,1280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1280);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f17,f2,f6
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f2,1104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f16,f6,f2
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// lfs f2,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f2.f64 = double(temp.f32);
	// lfs f15,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f21,f21,f30
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// fmuls f20,f3,f5
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f5,16816(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 16816);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f19,f27,f5
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// lfs f5,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f24,f24,f5
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// lfs f27,-30000(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -30000);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f23,f23,f2,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f19.f64));
	// lfs f2,2108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2108);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f24,f22,f5,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f5.f64 - ctx.f24.f64));
	// lfs f22,1144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1144);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f19,f18,f30
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// lfs f18,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// lfs f6,1884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1884);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f15,f15,f6
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f6.f64));
	// lfs f6,1512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1512);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f22,f22,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// fnmsubs f23,f6,f14,f23
	ctx.f23.f64 = double(float(-(ctx.f6.f64 * ctx.f14.f64 - ctx.f23.f64)));
	// lfs f6,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f24,f20,f5,f24
	ctx.f24.f64 = double(float(-(ctx.f20.f64 * ctx.f5.f64 - ctx.f24.f64)));
	// fmuls f20,f6,f2
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// lfs f2,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fnmsubs f27,f21,f27,f23
	ctx.f27.f64 = double(float(-(ctx.f21.f64 * ctx.f27.f64 - ctx.f23.f64)));
	// lfs f23,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f24,f17,f5,f24
	ctx.f24.f64 = double(float(-(ctx.f17.f64 * ctx.f5.f64 - ctx.f24.f64)));
	// lfs f17,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f23,f15,f23,f20
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f23.f64 + ctx.f20.f64));
	// lfs f20,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f20.f64));
	// lfs f15,1544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1544);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f6,f2
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// fmuls f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64));
	// lfs f15,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f15.f64 = double(temp.f32);
	// lfs f6,1504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1504);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,2364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2364);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f6,f2
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// stfs f2,1884(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1884, temp.u32);
	// lfs f21,2380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2380);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f27,f19,f15,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f15.f64 + ctx.f27.f64));
	// lfs f19,2740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2740);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f7,f25
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 + ctx.f25.f64));
	// lfs f25,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f25.f64 = double(temp.f32);
	// fmr f2,f25
	ctx.f2.f64 = ctx.f25.f64;
	// lfs f25,1280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1280);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f24,f16,f5,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f5.f64 + ctx.f24.f64));
	// fmuls f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// fmuls f20,f20,f30
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f30.f64));
	// fnmsubs f22,f22,f2,f27
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f27,1876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1876);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f24,f18,f5,f24
	ctx.f24.f64 = double(float(-(ctx.f18.f64 * ctx.f5.f64 - ctx.f24.f64)));
	// fmuls f18,f3,f27
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f27,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmadds f22,f14,f2,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f2.f64 + ctx.f22.f64));
	// fmadds f24,f23,f2,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f24.f64));
	// lfs f23,1892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1892);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f25,f27
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f27,3924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3924);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f27,f27,f7,f19
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f7.f64 - ctx.f19.f64)));
	// lfs f19,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f23,f23,f19,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f19.f64 - ctx.f18.f64));
	// fadds f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// stfs f27,4408(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4408, temp.u32);
	// lfs f27,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f28
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// lfs f26,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f23,f16,f5,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f5.f64 + ctx.f23.f64));
	// lfs f18,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f27,f26,f27,f22
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f27.f64 - ctx.f22.f64)));
	// lfs f26,1884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1884);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f26,f26,f4,f24
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f4.f64 - ctx.f24.f64)));
	// lfs f24,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f27,f21,f7,f27
	ctx.f27.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f27.f64)));
	// fmadds f26,f17,f2,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 + ctx.f26.f64));
	// lfs f2,-30000(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -30000);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f2,f20,f2,f27
	ctx.f2.f64 = double(float(-(ctx.f20.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f27,1072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1072);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f27,f24,f27,f26
	ctx.f27.f64 = double(float(-(ctx.f24.f64 * ctx.f27.f64 - ctx.f26.f64)));
	// lfs f26,1332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1332);
	ctx.f26.f64 = double(temp.f32);
	// lfs f24,1100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1100);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f2,f26,f24,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 + ctx.f2.f64));
	// lfs f24,2852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2852);
	ctx.f24.f64 = double(temp.f32);
	// fadds f22,f27,f2
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f2.f64));
	// lfs f27,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f2,f24,f6
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmuls f26,f27,f6
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f27,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f21,f6,f27
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f27,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f3,f27
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f27,4136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4136);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f27,f6
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f27,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f18,f27
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f27.f64));
	// lfs f27,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f3,f27
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// fmuls f14,f25,f27
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// fnmsubs f23,f2,f4,f23
	ctx.f23.f64 = double(float(-(ctx.f2.f64 * ctx.f4.f64 - ctx.f23.f64)));
	// lfs f2,-29912(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -29912);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f16,f26,f2
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// lfs f26,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f26,f15
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f15.f64));
	// fmuls f3,f3,f26
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f26.f64));
	// fmuls f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fmuls f18,f18,f30
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// fmadds f23,f21,f2,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f2.f64 + ctx.f23.f64));
	// lfs f2,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f21,f20,f2,f16
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f2.f64 + ctx.f16.f64));
	// lfs f16,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f16.f64 = double(temp.f32);
	// lfs f20,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// lfs f16,3216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3216);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f7,f19,f7,f23
	ctx.f7.f64 = double(float(-(ctx.f19.f64 * ctx.f7.f64 - ctx.f23.f64)));
	// lfs f23,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f23,f17,f23,f21
	ctx.f23.f64 = double(float(-(ctx.f17.f64 * ctx.f23.f64 - ctx.f21.f64)));
	// lfs f19,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,3408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3408);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f25,f20,f6
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// lfs f6,1052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1052);
	ctx.f6.f64 = double(temp.f32);
	// lfs f20,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f19.f64));
	// fmuls f20,f20,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// lfs f6,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f6.f64 = double(temp.f32);
	// lfs f17,3956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3956);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f18,f6,f7
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f6.f64 + ctx.f7.f64));
	// lfs f7,1128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1128);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,3240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3240);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f16,f7
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f7.f64));
	// fmuls f18,f6,f7
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f6,-29880(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -29880);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,1176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1176);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f17,f17,f6
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// fmadds f23,f15,f2,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f2.f64 + ctx.f23.f64));
	// fmuls f15,f7,f27
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// lfs f7,1900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1900);
	ctx.f7.f64 = double(temp.f32);
	// lfs f27,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f7,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 + ctx.f19.f64));
	// lfs f7,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f20,f20,f7,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f18.f64));
	// lfs f7,2876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2876);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f19,f7,f6,f17
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f6.f64 - ctx.f17.f64));
	// lfs f7,-29884(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -29884);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f23,f14,f2,f23
	ctx.f23.f64 = double(float(-(ctx.f14.f64 * ctx.f2.f64 - ctx.f23.f64)));
	// fmuls f18,f16,f7
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f7.f64));
	// lfs f16,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f23,f3,f2,f23
	ctx.f23.f64 = double(float(-(ctx.f3.f64 * ctx.f2.f64 - ctx.f23.f64)));
	// lfs f17,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f19,f19,f9,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f9.f64 - ctx.f18.f64));
	// fmuls f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// lfs f14,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,1320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1320);
	ctx.f16.f64 = double(temp.f32);
	// lis r14,-32239
	ctx.r14.s64 = -2112815104;
	// lfs f3,3604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3604);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f16,f14,f16,f27
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f16.f64 + ctx.f27.f64));
	// fmuls f14,f3,f9
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// lfs f3,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,3232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3232);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// lfs f27,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f20,f2,f3,f20
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 + ctx.f20.f64));
	// fmuls f2,f27,f28
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// lfs f18,1100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1100);
	ctx.f18.f64 = double(temp.f32);
	// stfs f2,376(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fmadds f25,f25,f4,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f4.f64 + ctx.f23.f64));
	// lfs f4,-30260(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -30260);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f23,f20,f7,f19
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f19.f64));
	// lfs f19,3612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3612);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f2,f2,f18,f16
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f18.f64 - ctx.f16.f64)));
	// lfs f18,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f20,3228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3228);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f26,f26,f4,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f4.f64 + ctx.f25.f64));
	// lfs f4,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f20,f20,f9
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f9.f64));
	// fmadds f25,f14,f6,f23
	ctx.f25.f64 = double(float(ctx.f14.f64 * ctx.f6.f64 + ctx.f23.f64));
	// lfs f23,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f2,f21,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f21.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// fmadds f25,f24,f12,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 + ctx.f25.f64));
	// lfs f24,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f4,f4,f23,f2
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f23.f64 - ctx.f2.f64)));
	// fmadds f2,f15,f5,f26
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f5.f64 + ctx.f26.f64));
	// lfs f5,16816(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 16816);
	ctx.f5.f64 = double(temp.f32);
	// fadds f4,f22,f4
	ctx.f4.f64 = double(float(ctx.f22.f64 + ctx.f4.f64));
	// fmadds f5,f17,f5,f2
	ctx.f5.f64 = double(float(ctx.f17.f64 * ctx.f5.f64 + ctx.f2.f64));
	// lfs f2,2988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2988);
	ctx.f2.f64 = double(temp.f32);
	// lfs f17,2032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2032);
	ctx.f17.f64 = double(temp.f32);
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// stfs f5,4412(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4412, temp.u32);
	// lfs f5,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f26,f5,f4
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f4,-29888(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -29888);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// lfs f2,3988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3988);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f23,f2,f9
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// lfs f2,3660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3660);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f22,f2,f9
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// lfs f2,3020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3020);
	ctx.f2.f64 = double(temp.f32);
	// lis r14,-32239
	ctx.r14.s64 = -2112815104;
	// fmuls f21,f2,f9
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// lfs f2,3208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3208);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f5,f9,f5
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmuls f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f2,-29908(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -29908);
	ctx.f2.f64 = double(temp.f32);
	// lis r14,-32239
	ctx.r14.s64 = -2112815104;
	// fmsubs f26,f26,f2,f4
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 - ctx.f4.f64));
	// lfs f4,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// fmuls f24,f5,f24
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// lfs f5,-29900(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -29900);
	ctx.f5.f64 = double(temp.f32);
	// lis r14,-32239
	ctx.r14.s64 = -2112815104;
	// fmsubs f26,f26,f9,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f9.f64 - ctx.f23.f64));
	// lfs f23,2048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2048);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// lfs f5,2056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2056);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f18,f5,f9
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f5,-29836(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + -29836);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f17,f17,f5
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f5.f64));
	// lfs f5,-29892(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -29892);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f25,f24,f2,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// fmadds f26,f22,f4,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f4.f64 + ctx.f26.f64));
	// lfs f4,2672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2672);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f24,f4,f5,f23
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f5.f64 + ctx.f23.f64));
	// lfs f5,4248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4248);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f23,f5,f9
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f5,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f27,f5,f27
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// lfs f5,2296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2296);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f5,f9
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f5,2216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2216);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f17,f5,f12,f17
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 + ctx.f17.f64));
	// lfs f5,2884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2884);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f16,f5,f9
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f4,-29848(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -29848);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,-29844(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29844);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f26,f21,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// fnmsubs f25,f18,f5,f25
	ctx.f25.f64 = double(float(-(ctx.f18.f64 * ctx.f5.f64 - ctx.f25.f64)));
	// lfs f18,2944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2944);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,2696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2696);
	ctx.f21.f64 = double(temp.f32);
	// lis r14,-32239
	ctx.r14.s64 = -2112815104;
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// lfs f18,1252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1252);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f9
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// lfs f15,2868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2868);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f9
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f9.f64));
	// lfs f14,3848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3848);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f27,f27,f6
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fnmsubs f3,f3,f7,f26
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// lfs f7,1940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1940);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f26,f17,f9,f25
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 + ctx.f25.f64));
	// lfs f25,2008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2008);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f7
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f7.f64));
	// lfs f17,2040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2040);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f9
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// fmuls f14,f14,f7
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f7.f64));
	// fmadds f27,f21,f12,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f27.f64));
	// lfs f21,2892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2892);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f9
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// fnmsubs f3,f20,f4,f3
	ctx.f3.f64 = double(float(-(ctx.f20.f64 * ctx.f4.f64 - ctx.f3.f64)));
	// lfs f4,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f22,f22,f12,f26
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f26.f64)));
	// fmuls f25,f25,f4
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// lfs f4,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f26,f4,f7
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// lfs f4,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f20,f4,f7
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// lfs f4,-29916(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -29916);
	ctx.f4.f64 = double(temp.f32);
	// stfs f26,1320(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1320, temp.u32);
	// fmuls f27,f27,f7
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// fnmsubs f4,f19,f4,f3
	ctx.f4.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f3.f64)));
	// lfs f3,-29896(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -29896);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f5,f18,f5,f22
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f5.f64 + ctx.f22.f64));
	// lfs f18,3912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3912);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f27,f25,f2,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 - ctx.f27.f64));
	// fmadds f4,f24,f9,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 + ctx.f4.f64));
	// fnmsubs f25,f17,f3,f5
	ctx.f25.f64 = double(float(-(ctx.f17.f64 * ctx.f3.f64 - ctx.f5.f64)));
	// lfs f17,3920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3920);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f24,f14,f12,f27
	ctx.f24.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f27.f64)));
	// lfs f27,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f5,f23,f6,f4
	ctx.f5.f64 = double(float(-(ctx.f23.f64 * ctx.f6.f64 - ctx.f4.f64)));
	// fmadds f5,f16,f6,f5
	ctx.f5.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 + ctx.f5.f64));
	// fnmsubs f4,f15,f6,f5
	ctx.f4.f64 = double(float(-(ctx.f15.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// lfs f5,-29920(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + -29920);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f5,f21,f5,f4
	ctx.f5.f64 = double(float(-(ctx.f21.f64 * ctx.f5.f64 - ctx.f4.f64)));
	// lfs f4,2384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2384);
	ctx.f4.f64 = double(temp.f32);
	// fadds f5,f25,f5
	ctx.f5.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// stfs f5,4416(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4416, temp.u32);
	// lfs f5,3872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3872);
	ctx.f5.f64 = double(temp.f32);
	// fadds f25,f5,f4
	ctx.f25.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// lfs f5,3888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3888);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,3896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3896);
	ctx.f4.f64 = double(temp.f32);
	// fadds f23,f5,f4
	ctx.f23.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// lfs f5,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f22,f4,f5
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// lfs f5,2312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2312);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f27,f5
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// lfs f5,3904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3904);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f19,f5,f7
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// lfs f5,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f18,f5,f18
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f18.f64));
	// fadds f17,f25,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 + ctx.f17.f64));
	// fmuls f23,f23,f7
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f7.f64));
	// fmuls f22,f22,f31
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f31.f64));
	// fmuls f21,f21,f0
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// lfs f25,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f17,f7
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f7.f64));
	// fmuls f20,f20,f25
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// lfs f25,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f25.f64 = double(temp.f32);
	// lfs f16,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fmuls f16,f16,f25
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// lfs f14,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f25,f14,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f22,f22,f10,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f21.f64));
	// lfs f14,1256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1256);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f26,f15
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f15.f64));
	// fmuls f14,f4,f14
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f14.f64));
	// fmadds f24,f20,f6,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 + ctx.f24.f64));
	// lfs f20,3928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3928);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f23,f17,f3,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 - ctx.f23.f64));
	// fmuls f21,f16,f7
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f7.f64));
	// lfs f16,3936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3936);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// fmuls f16,f25,f7
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f7.f64));
	// lfs f25,2052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2052);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f27,f25
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// lfs f25,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f22,f18,f1,f22
	ctx.f22.f64 = double(float(-(ctx.f18.f64 * ctx.f1.f64 - ctx.f22.f64)));
	// fmuls f18,f26,f25
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fnmsubs f23,f19,f3,f23
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f3.f64 - ctx.f23.f64)));
	// lfs f19,3960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3960);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f26,f21,f2,f24
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f2.f64 - ctx.f24.f64)));
	// lfs f21,3944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3944);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f24,f20,f7
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// lfs f20,3952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3952);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f19,f7
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f7.f64));
	// fmuls f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// fmadds f22,f14,f10,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 + ctx.f22.f64));
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f20,f5,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// fnmsubs f23,f15,f2,f23
	ctx.f23.f64 = double(float(-(ctx.f15.f64 * ctx.f2.f64 - ctx.f23.f64)));
	// fmadds f24,f24,f3,f26
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 + ctx.f26.f64));
	// lfs f26,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f14,f26
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f26.f64));
	// lfs f26,3968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3968);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f22,f17,f10,f22
	ctx.f22.f64 = double(float(-(ctx.f17.f64 * ctx.f10.f64 - ctx.f22.f64)));
	// fmuls f17,f26,f12
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lfs f26,3976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3976);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f21,f26,f12,f21
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f21.f64));
	// lfs f26,3984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3984);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f5,f26
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f26,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f25,f26
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fnmsubs f3,f19,f3,f24
	ctx.f3.f64 = double(float(-(ctx.f19.f64 * ctx.f3.f64 - ctx.f24.f64)));
	// fmadds f24,f16,f6,f23
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 + ctx.f23.f64));
	// fnmsubs f23,f20,f1,f22
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f1.f64 - ctx.f22.f64)));
	// fmadds f22,f14,f6,f17
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f6.f64 + ctx.f17.f64));
	// lfs f6,3992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3992);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f6,f7
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f6,4000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4000);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f19,f5,f6
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f25,f25,f31
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// fnmsubs f2,f18,f2,f24
	ctx.f2.f64 = double(float(-(ctx.f18.f64 * ctx.f2.f64 - ctx.f24.f64)));
	// lfs f24,2036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2036);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// fnmsubs f23,f15,f1,f23
	ctx.f23.f64 = double(float(-(ctx.f15.f64 * ctx.f1.f64 - ctx.f23.f64)));
	// fmadds f3,f22,f7,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 + ctx.f3.f64));
	// lfs f22,1920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1920);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f21,f7,f2
	ctx.f7.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 + ctx.f2.f64));
	// fmadds f2,f25,f10,f23
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 + ctx.f23.f64));
	// lfs f25,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f25.f64 = double(temp.f32);
	// lfs f23,4008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4008);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// fnmsubs f7,f20,f12,f7
	ctx.f7.f64 = double(float(-(ctx.f20.f64 * ctx.f12.f64 - ctx.f7.f64)));
	// fmadds f2,f19,f1,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 * ctx.f1.f64 + ctx.f2.f64));
	// fadds f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// lfs f3,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f3.f64 = double(temp.f32);
	// stfs f7,4420(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4420, temp.u32);
	// fmuls f3,f3,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f7,824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 824);
	ctx.f7.f64 = double(temp.f32);
	// lfs f25,1216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1216);
	ctx.f25.f64 = double(temp.f32);
	// fadds f7,f26,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 + ctx.f7.f64));
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// lfs f20,1580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1580);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f3,f3,f0,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f25.f64));
	// fmuls f7,f7,f20
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f20.f64));
	// lfs f17,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f2,f24,f10,f2
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f10.f64 - ctx.f2.f64)));
	// lfs f24,1328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1328);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f4,f24
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f24.f64));
	// lfs f16,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f17,f4,f17
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// lfs f21,4016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4016);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,1856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1856);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f5,f21
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f21.f64));
	// lfs f14,2008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2008);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f20,f5,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// lfs f25,1224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1224);
	ctx.f25.f64 = double(temp.f32);
	// lis r14,-32239
	ctx.r14.s64 = -2112815104;
	// lfs f19,1956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1956);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f25,f27,f25
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// lfs f18,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f19,f27,f19
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// fmuls f26,f18,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f26.f64));
	// lfs f18,1728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1728);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f2,f24,f10,f2
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f10.f64 - ctx.f2.f64)));
	// lfs f24,3092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3092);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f16.f64));
	// lfs f16,1924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1924);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64));
	// lfs f15,908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 908);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f5,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f16.f64));
	// fmuls f15,f5,f15
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f15.f64));
	// fmuls f18,f4,f18
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f18.f64));
	// fmadds f7,f3,f4,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f4.f64 + ctx.f7.f64));
	// lfs f3,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f5,f3
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// fmuls f5,f5,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// lfs f14,2192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2192);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f27,f14
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f14.f64));
	// fmuls f24,f24,f28
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// fmuls f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// fmadds f7,f23,f1,f7
	ctx.f7.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f7.f64));
	// lfs f1,1916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1916);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// lfs f23,1936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1936);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f4,f23
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fnmsubs f22,f22,f10,f7
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// lfs f7,-29940(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29940);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f1,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// lfs f7,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f6,f7
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f7,2280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2280);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f27,f27,f7
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// lfs f7,1844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1844);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f4,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// lfs f4,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f4.f64 = double(temp.f32);
	// stfs f7,328(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fmr f7,f4
	ctx.f7.f64 = ctx.f4.f64;
	// lfs f4,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f1,f14,f0,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 + ctx.f1.f64));
	// fnmsubs f22,f21,f7,f22
	ctx.f22.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f22.f64)));
	// lfs f21,2104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2104);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f4,f21
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// fmsubs f6,f6,f0,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 - ctx.f1.f64));
	// fmadds f7,f20,f7,f22
	ctx.f7.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f22.f64));
	// fnmsubs f7,f25,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f25.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// fnmsubs f7,f19,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f19.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// fadds f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// lfs f1,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f1,f0,f6
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f6.f64));
	// fmadds f7,f26,f10,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f10.f64 + ctx.f7.f64));
	// fnmsubs f7,f18,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f18.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// fmadds f6,f17,f0,f7
	ctx.f6.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f7.f64));
	// lfs f7,-29936(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -29936);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,760(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 760, temp.u32);
	// fnmsubs f6,f3,f7,f6
	ctx.f6.f64 = double(float(-(ctx.f3.f64 * ctx.f7.f64 - ctx.f6.f64)));
	// fmadds f6,f24,f10,f6
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f6.f64));
	// fmadds f6,f16,f7,f6
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f7.f64 + ctx.f6.f64));
	// lfs f3,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f3.f64 = double(temp.f32);
	// lfs f16,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 824);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f6,f15,f7,f6
	ctx.f6.f64 = double(float(ctx.f15.f64 * ctx.f7.f64 + ctx.f6.f64));
	// lfs f15,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fnmsubs f6,f23,f0,f6
	ctx.f6.f64 = double(float(-(ctx.f23.f64 * ctx.f0.f64 - ctx.f6.f64)));
	// fmuls f15,f15,f31
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// fnmsubs f7,f5,f7,f6
	ctx.f7.f64 = double(float(-(ctx.f5.f64 * ctx.f7.f64 - ctx.f6.f64)));
	// lfs f6,2016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2016);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f31,f30
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// stfs f5,388(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fnmsubs f25,f27,f0,f7
	ctx.f25.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fmuls f7,f5,f13
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f7,1728(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1728, temp.u32);
	// lfs f7,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f27,f5,f7
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// lfs f7,2120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2120);
	ctx.f7.f64 = double(temp.f32);
	// fadds f26,f6,f7
	ctx.f26.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// lfs f7,1068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1068);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f13,f7
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// lfs f6,1232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1232);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f6,f7
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// fmuls f6,f30,f28
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmuls f23,f3,f6
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// fmuls f3,f31,f28
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fmuls f2,f3,f13
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfs f3,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f6,f3,f6,f27
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f6.f64 + ctx.f27.f64));
	// lfs f3,2064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2064);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f22,f3,f7
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// lfs f7,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f13,f7
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// lfs f7,2248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2248);
	ctx.f7.f64 = double(temp.f32);
	// lfs f27,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f27.f64 = double(temp.f32);
	// stfs f3,1856(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1856, temp.u32);
	// fmuls f20,f7,f3
	ctx.f20.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// lfs f7,2092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2092);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f24,f26,f7,f24
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 + ctx.f24.f64));
	// lfs f7,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f7.f64 = double(temp.f32);
	// lfs f26,1260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1260);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f18,f27,f7,f6
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 + ctx.f6.f64));
	// fmuls f19,f26,f7
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// lfs f7,-29940(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29940);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f21,f21,f7,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 + ctx.f1.f64));
	// stfs f7,420(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// lfs f7,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f7.f64 = double(temp.f32);
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// lfs f27,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f27.f64 = double(temp.f32);
	// lfs f1,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f1.f64 = double(temp.f32);
	// stfs f7,1248(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1248, temp.u32);
	// lfs f6,-29952(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29952);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// stfs f6,600(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmuls f17,f27,f7
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// fmuls f7,f1,f31
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fnmsubs f21,f17,f0,f21
	ctx.f21.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f21.f64)));
	// fmuls f16,f16,f7
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f7.f64));
	// lfs f7,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f26,f26,f7
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// lfs f7,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f17,f7,f13
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// fmuls f26,f26,f13
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmuls f14,f7,f14
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f14.f64));
	// fmuls f7,f1,f30
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// fmadds f16,f4,f7,f16
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f7.f64 + ctx.f16.f64));
	// lfs f4,1812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1812);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f1,f4,f30
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// lfs f7,-29984(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -29984);
	ctx.f7.f64 = double(temp.f32);
	// lfs f4,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f24,f18,f7,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f7.f64 + ctx.f24.f64));
	// fmadds f21,f16,f0,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 + ctx.f21.f64));
	// fmuls f18,f4,f1
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// lfs f1,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f17,f17,f1
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f1.f64));
	// lfs f1,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f24,f23,f6,f24
	ctx.f24.f64 = double(float(-(ctx.f23.f64 * ctx.f6.f64 - ctx.f24.f64)));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lfs f16,1728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1728);
	ctx.f16.f64 = double(temp.f32);
	// lfs f23,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f21,f14,f10,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 + ctx.f21.f64));
	// fmadds f23,f23,f16,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f16.f64 + ctx.f22.f64));
	// lfs f22,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f22.f64 = double(temp.f32);
	// lfs f16,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f22,f2,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// fmuls f2,f16,f2
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmuls f16,f15,f30
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f30.f64));
	// fmuls f1,f27,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// lfs f27,1952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1952);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f3
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// lfs f3,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// fmadds f24,f23,f6,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f24.f64));
	// fmuls f3,f3,f13
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f15,f3,f31
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// lfs f3,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f23,f18,f3,f21
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f3.f64 + ctx.f21.f64));
	// lfs f3,-29860(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29860);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f24,f20,f3,f24
	ctx.f24.f64 = double(float(-(ctx.f20.f64 * ctx.f3.f64 - ctx.f24.f64)));
	// stfs f3,360(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f20,1140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1140);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f1,f1,f10,f23
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f10.f64 - ctx.f23.f64)));
	// fnmsubs f24,f19,f6,f24
	ctx.f24.f64 = double(float(-(ctx.f19.f64 * ctx.f6.f64 - ctx.f24.f64)));
	// fadds f1,f25,f1
	ctx.f1.f64 = double(float(ctx.f25.f64 + ctx.f1.f64));
	// stfs f1,4424(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4424, temp.u32);
	// fmadds f1,f22,f6,f24
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 + ctx.f24.f64));
	// fnmsubs f2,f2,f6,f1
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fnmsubs f2,f26,f6,f2
	ctx.f2.f64 = double(float(-(ctx.f26.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// fnmsubs f1,f17,f6,f2
	ctx.f1.f64 = double(float(-(ctx.f17.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// lfs f2,-29972(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -29972);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,712(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 712, temp.u32);
	// fnmsubs f1,f16,f2,f1
	ctx.f1.f64 = double(float(-(ctx.f16.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// fnmsubs f3,f27,f3,f1
	ctx.f3.f64 = double(float(-(ctx.f27.f64 * ctx.f3.f64 - ctx.f1.f64)));
	// lfs f1,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f22,f15,f2,f3
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f2.f64 - ctx.f3.f64)));
	// lfs f3,1448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1448);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f27,f5,f3
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f26,f5,f3
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f2,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f3.f64 = double(temp.f32);
	// fadds f25,f3,f2
	ctx.f25.f64 = double(float(ctx.f3.f64 + ctx.f2.f64));
	// lfs f3,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f30,f28
	ctx.f2.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmuls f19,f27,f6
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f27,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f26,f26,f13
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmuls f24,f3,f2
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f3,f31,f28
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmuls f26,f26,f7
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// fmadds f25,f25,f27,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f27.f64 + ctx.f24.f64));
	// lfs f27,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f23,f3,f1
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f1,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmadds f24,f5,f27,f23
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f27.f64 + ctx.f23.f64));
	// lfs f27,-29960(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29960);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f21,f1,f30
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lfs f1,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f20,f1
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f1.f64));
	// stfs f27,340(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fmuls f27,f21,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f27.f64));
	// lfs f21,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f23,f20,f6,f19
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 - ctx.f19.f64));
	// fmadds f21,f3,f21,f25
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f21.f64 + ctx.f25.f64));
	// lfs f25,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f20,f1,f13
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fmadds f24,f24,f7,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 + ctx.f27.f64));
	// lfs f27,1084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1084);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f1,f27
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// lfs f1,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f1.f64 = double(temp.f32);
	// lfs f27,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f23,f13,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f26.f64));
	// fmadds f23,f25,f1,f21
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f21.f64));
	// fmuls f21,f20,f27
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f27.f64));
	// fmadds f17,f24,f13,f26
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f26.f64));
	// lfs f26,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f26.f64 = double(temp.f32);
	// lfs f24,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fadds f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// lfs f26,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f23,f26,f1,f23
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 + ctx.f23.f64));
	// lfs f24,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f24.f64 = double(temp.f32);
	// lfs f26,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f26.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// fadds f15,f24,f26
	ctx.f15.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfs f27,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f26,f28,f28
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// lfs f18,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f1,f27
	ctx.f20.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// fmuls f18,f18,f2
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f2.f64));
	// fnmsubs f21,f21,f7,f17
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f17.f64)));
	// fmadds f23,f25,f27,f23
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f27.f64 + ctx.f23.f64));
	// lfs f25,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f26,f31
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// stfs f24,1304(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1304, temp.u32);
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// fnmsubs f21,f19,f7,f21
	ctx.f21.f64 = double(float(-(ctx.f19.f64 * ctx.f7.f64 - ctx.f21.f64)));
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fmuls f20,f20,f24
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f24.f64));
	// lfs f24,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f24,f2
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// fmuls f24,f2,f31
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f17,f15,f24
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f24.f64));
	// fmuls f15,f3,f25
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// fmuls f25,f30,f30
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// fmuls f3,f25,f28
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f28.f64));
	// stfs f3,1272(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1272, temp.u32);
	// fmadds f20,f16,f3,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 + ctx.f20.f64));
	// lfs f3,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f17,f3
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// fmuls f3,f26,f30
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// lfs f26,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f26.f64 = double(temp.f32);
	// stfs f3,372(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// fmuls f16,f14,f13
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// fmuls f17,f15,f13
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// lfs f14,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f20,f26,f3,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f3.f64 + ctx.f20.f64));
	// fmuls f3,f31,f31
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f26,f3,f28
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// stfs f26,1192(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1192, temp.u32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// stfs f3,472(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// fmuls f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f26.f64));
	// fmuls f14,f14,f26
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f26.f64));
	// fmadds f26,f23,f7,f21
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 + ctx.f21.f64));
	// lfs f21,4040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4040);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f23,f20,f29,f19
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f29.f64 + ctx.f19.f64));
	// lfs f20,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f20.f64 = double(temp.f32);
	// fadds f19,f1,f27
	ctx.f19.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// fnmsubs f26,f18,f7,f26
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// fmadds f21,f21,f20,f23
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f23.f64));
	// lfs f23,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f3,f30
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// fnmsubs f26,f16,f7,f26
	ctx.f26.f64 = double(float(-(ctx.f16.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// fmsubs f21,f15,f23,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f23.f64 - ctx.f21.f64));
	// fnmsubs f26,f17,f7,f26
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// fadds f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// stfs f26,4428(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4428, temp.u32);
	// lfs f26,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f26.f64 = double(temp.f32);
	// lfs f22,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f26,f22
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f22.f64));
	// lfs f26,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f26,f24
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// lfs f26,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f3
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// stfs f26,836(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 836, temp.u32);
	// fmuls f26,f25,f31
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// lfs f22,-18744(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -18744);
	ctx.f22.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f24,1068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1068);
	ctx.f24.f64 = double(temp.f32);
	// stfs f26,1288(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1288, temp.u32);
	// fmuls f25,f20,f23
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// fmuls f16,f27,f26
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// lfs f27,-30004(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -30004);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f18,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f24.f64));
	// lfs f20,1276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1276);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,1820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1820);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f19,f19,f3,f25
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64 + ctx.f25.f64));
	// fmuls f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f20.f64));
	// lfs f18,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f18.f64 = double(temp.f32);
	// lfs f20,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f20.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f25,-29944(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -29944);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// lfs f15,4196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4196);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f26,f1,f26
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// stfs f25,504(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// fmuls f18,f24,f25
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// lfs f24,1972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1972);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f15,f15,f24
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f24.f64));
	// lfs f24,-29868(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29868);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f23,f24
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f24.f64));
	// stfs f24,584(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 584, temp.u32);
	// lfs f24,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f1,f17,f22,f19
	ctx.f1.f64 = double(float(ctx.f17.f64 * ctx.f22.f64 + ctx.f19.f64));
	// fmuls f24,f28,f24
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f24.f64));
	// stfs f24,436(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// lfs f22,4048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4048);
	ctx.f22.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f19,4056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4056);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,4124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4124);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f22,f22,f27,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f27.f64 - ctx.f18.f64));
	// lfs f18,4108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4108);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// lfs f18,4116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4116);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f17,1276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1276);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f1,f16,f29,f1
	ctx.f1.f64 = double(float(-(ctx.f16.f64 * ctx.f29.f64 - ctx.f1.f64)));
	// lfs f16,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f24,f3,f24
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fmuls f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// lfs f24,1996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1996);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f17.f64));
	// lfs f17,4132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4132);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f22,f17,f27,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f27.f64 + ctx.f22.f64));
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f16,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f14.f64));
	// lfs f16,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfs f14,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,4140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4140);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f1,f16,f14,f1
	ctx.f1.f64 = double(float(-(ctx.f16.f64 * ctx.f14.f64 - ctx.f1.f64)));
	// fmuls f16,f3,f2
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f3,-30228(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -30228);
	ctx.f3.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stfs f3,264(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f3,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,4148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4148);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f23,f22,f3,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f23.f64));
	// lfs f3,-30180(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -30180);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f22,f2,f3
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// stfs f3,500(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// lfs f3,4156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4156);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f20,f20,f29,f1
	ctx.f20.f64 = double(float(-(ctx.f20.f64 * ctx.f29.f64 - ctx.f1.f64)));
	// fmuls f14,f2,f3
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f3,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f28,f3
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f3.f64));
	// lfs f2,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f2.f64 = double(temp.f32);
	// stfs f3,656(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 656, temp.u32);
	// lfs f1,-29948(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -29948);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,440(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fnmsubs f23,f15,f1,f23
	ctx.f23.f64 = double(float(-(ctx.f15.f64 * ctx.f1.f64 - ctx.f23.f64)));
	// fmuls f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f2,4164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4164);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f25,f2,f27,f25
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f27.f64 - ctx.f25.f64));
	// lfs f2,4172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4172);
	ctx.f2.f64 = double(temp.f32);
	// fadds f18,f18,f2
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f2.f64));
	// lfs f2,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f2.f64 = double(temp.f32);
	// stfs f3,328(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fmr f3,f2
	ctx.f3.f64 = ctx.f2.f64;
	// lfs f2,2020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2020);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f24,f2,f3,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 + ctx.f24.f64));
	// lfs f2,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f21,f17,f2,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 + ctx.f21.f64));
	// lfs f1,1456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1456);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f25,f18,f27,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f27.f64 + ctx.f25.f64));
	// fmuls f17,f1,f3
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f3,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f22,f16,f3,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 - ctx.f22.f64));
	// lfs f3,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f14,f3
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f3.f64));
	// lfs f1,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,4180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4180);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f20,f3,f1,f20
	ctx.f20.f64 = double(float(-(ctx.f3.f64 * ctx.f1.f64 - ctx.f20.f64)));
	// lfs f3,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f3.f64 = double(temp.f32);
	// lfs f18,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// lfs f15,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f23,f15,f18,f23
	ctx.f23.f64 = double(float(-(ctx.f15.f64 * ctx.f18.f64 - ctx.f23.f64)));
	// lfs f18,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f22,f22,f18,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 - ctx.f16.f64));
	// stfs f22,4440(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4440, temp.u32);
	// lfs f22,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f26,f26,f29,f20
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f29.f64 - ctx.f20.f64)));
	// fmadds f22,f25,f22,f24
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f22.f64 + ctx.f24.f64));
	// lfs f25,4188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4188);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,1192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1192);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f27,f19,f27,f23
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f23.f64));
	// lfs f23,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f26,f25,f1,f26
	ctx.f26.f64 = double(float(-(ctx.f25.f64 * ctx.f1.f64 - ctx.f26.f64)));
	// fmadds f3,f17,f3,f27
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 + ctx.f27.f64));
	// stfs f3,4436(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4436, temp.u32);
	// fadds f3,f21,f26
	ctx.f3.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// stfs f3,4432(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4432, temp.u32);
	// lfs f3,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// lfs f26,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f27,f5,f3
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// stfs f3,2260(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2260, temp.u32);
	// fmuls f27,f27,f29
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f29.f64));
	// fmuls f25,f5,f3
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,1272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1272);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f21,f23,f3
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f3,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f3,f26
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f26.f64));
	// lfs f3,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// fmuls f18,f25,f2
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// lfs f25,1304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1304);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f21,f21,f29,f27
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f29.f64 - ctx.f27.f64));
	// lfs f27,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f5,f3
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// fnmsubs f21,f20,f29,f21
	ctx.f21.f64 = double(float(-(ctx.f20.f64 * ctx.f29.f64 - ctx.f21.f64)));
	// fmuls f17,f5,f3
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f3,f24
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// lfs f3,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f18,f27,f3,f18
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f3.f64 + ctx.f18.f64));
	// lfs f27,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f3,f25
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// fmuls f14,f27,f25
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// lfs f25,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f24.f64));
	// lfs f23,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f25,f23
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f23.f64));
	// fmadds f21,f17,f29,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f29.f64 + ctx.f21.f64));
	// fnmsubs f20,f19,f2,f18
	ctx.f20.f64 = double(float(-(ctx.f19.f64 * ctx.f2.f64 - ctx.f18.f64)));
	// lfs f19,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f26,f19
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// lfs f26,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f26,f25
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// lfs f26,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmadds f20,f16,f2,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f2.f64 + ctx.f20.f64));
	// lfs f16,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f18,f5,f26
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f26,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmuls f17,f5,f26
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f26,4196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4196);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f16
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// lfs f26,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f21,f15,f29,f21
	ctx.f21.f64 = double(float(-(ctx.f15.f64 * ctx.f29.f64 - ctx.f21.f64)));
	// fnmsubs f20,f26,f27,f20
	ctx.f20.f64 = double(float(-(ctx.f26.f64 * ctx.f27.f64 - ctx.f20.f64)));
	// lfs f26,1288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1288);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f17,f27,f26,f17
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f26.f64 + ctx.f17.f64));
	// lfs f27,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f16,f16,f27
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f27.f64));
	// lfs f27,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f27.f64 = double(temp.f32);
	// lfs f15,1272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1272);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f26,f3,f26
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f26.f64));
	// fmuls f15,f27,f15
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f15.f64));
	// lfs f27,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f30,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f27.f64));
	// stfs f27,2336(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2336, temp.u32);
	// fmadds f21,f14,f29,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f29.f64 + ctx.f21.f64));
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f24,f24,f2,f20
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f2.f64 - ctx.f20.f64)));
	// lfs f20,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f27.f64));
	// fmuls f27,f30,f28
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fnmsubs f24,f23,f2,f24
	ctx.f24.f64 = double(float(-(ctx.f23.f64 * ctx.f2.f64 - ctx.f24.f64)));
	// fmuls f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 * ctx.f27.f64));
	// lfs f14,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f22,f16,f14,f22
	ctx.f22.f64 = double(float(-(ctx.f16.f64 * ctx.f14.f64 - ctx.f22.f64)));
	// lfs f16,4204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4204);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f21,f16,f1,f21
	ctx.f21.f64 = double(float(-(ctx.f16.f64 * ctx.f1.f64 - ctx.f21.f64)));
	// lfs f16,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f5,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f16.f64));
	// fmadds f2,f25,f2,f24
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 + ctx.f24.f64));
	// lfs f25,1816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1816);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f13
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// fmuls f23,f27,f13
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// lfs f27,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f27,f20,f27,f22
	ctx.f27.f64 = double(float(-(ctx.f20.f64 * ctx.f27.f64 - ctx.f22.f64)));
	// stfs f27,4444(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4444, temp.u32);
	// fmadds f27,f19,f29,f21
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f29.f64 + ctx.f21.f64));
	// lfs f22,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f5,f22
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f22.f64));
	// fnmsubs f2,f18,f29,f2
	ctx.f2.f64 = double(float(-(ctx.f18.f64 * ctx.f29.f64 - ctx.f2.f64)));
	// fmadds f27,f25,f1,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f27.f64));
	// lfs f25,1736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1736);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f22,f22,f13
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmadds f2,f17,f29,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f29.f64 + ctx.f2.f64));
	// fnmsubs f27,f25,f1,f27
	ctx.f27.f64 = double(float(-(ctx.f25.f64 * ctx.f1.f64 - ctx.f27.f64)));
	// lfs f25,1880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1880);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f2,f26,f29,f2
	ctx.f2.f64 = double(float(-(ctx.f26.f64 * ctx.f29.f64 - ctx.f2.f64)));
	// lfs f26,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f3
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// fmadds f1,f25,f1,f27
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f27.f64));
	// lfs f27,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f27.f64 = double(temp.f32);
	// lfs f25,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f5,f25
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// fmuls f19,f26,f13
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// lfs f26,1084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1084);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f1,f15,f29,f1
	ctx.f1.f64 = double(float(-(ctx.f15.f64 * ctx.f29.f64 - ctx.f1.f64)));
	// lfs f15,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f17,f25,f13
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fmuls f25,f26,f27
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fadds f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// stfs f2,4448(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4448, temp.u32);
	// lfs f2,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f13,f2
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// lfs f1,2080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2080);
	ctx.f1.f64 = double(temp.f32);
	// stfs f2,300(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// fmuls f1,f27,f13
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// fmuls f21,f2,f6
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f2,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f20,f1,f2
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f1,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f31,f28
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmsubs f23,f23,f7,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 - ctx.f21.f64));
	// lfs f21,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f2,f1
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f1,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f24,f24,f1
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// fmuls f1,f30,f28
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmuls f15,f2,f15
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f15.f64));
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// fmuls f21,f21,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64));
	// fnmsubs f23,f20,f7,f23
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f23.f64)));
	// lfs f20,1140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1140);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f27,f20,f27,f16
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f27.f64 + ctx.f16.f64));
	// lfs f16,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f2,f2,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// lfs f16,1260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1260);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f25,f13
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// lfs f25,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmuls f20,f15,f7
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f7.f64));
	// lfs f15,2136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2136);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fmuls f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmadds f23,f19,f7,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 + ctx.f23.f64));
	// lfs f19,1960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1960);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// fmuls f15,f2,f13
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f2,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f26,f26,f13
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmadds f20,f27,f6,f20
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f6.f64 + ctx.f20.f64));
	// lfs f27,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f28
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// stfs f27,1012(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1012, temp.u32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fnmsubs f23,f17,f7,f23
	ctx.f23.f64 = double(float(-(ctx.f17.f64 * ctx.f7.f64 - ctx.f23.f64)));
	// fmuls f17,f2,f1
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f2,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f25,f2
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// lfs f2,1308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1308);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,2028(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2028, temp.u32);
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fnmsubs f24,f24,f7,f23
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f7.f64 - ctx.f23.f64)));
	// fmuls f23,f17,f13
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f17,2184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2184);
	ctx.f17.f64 = double(temp.f32);
	// fadds f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 + ctx.f2.f64));
	// lfs f27,3048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3048);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f19,f27,f16
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f16.f64));
	// lfs f19,1932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1932);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f17,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// lfs f16,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,2304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2304);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f24,f22,f7,f24
	ctx.f24.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f24.f64)));
	// lfs f22,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f2,f2,f13
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmadds f27,f17,f16,f27
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f27.f64));
	// fnmsubs f24,f18,f7,f24
	ctx.f24.f64 = double(float(-(ctx.f18.f64 * ctx.f7.f64 - ctx.f24.f64)));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f27,f27,f6
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fmsubs f27,f2,f22,f27
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 - ctx.f27.f64));
	// lfs f22,2184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2184);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f2,f14,f7,f24
	ctx.f2.f64 = double(float(-(ctx.f14.f64 * ctx.f7.f64 - ctx.f24.f64)));
	// lfs f24,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f2,f21,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// lfs f21,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f2,f20,f13,f2
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f2.f64));
	// fnmsubs f2,f26,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f26.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// lfs f26,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f27,f19,f26,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f26.f64 + ctx.f27.f64));
	// lfs f26,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f5,f26
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f5,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f24,f5,f24
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// fnmsubs f2,f15,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// fnmsubs f2,f25,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f25.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// fnmsubs f2,f23,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f23.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// lfs f23,2320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2320);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// fmadds f25,f1,f7,f2
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f7.f64 + ctx.f2.f64));
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// lfs f1,3012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3012);
	ctx.f1.f64 = double(temp.f32);
	// stfs f2,1900(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1900, temp.u32);
	// fmuls f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// fmuls f2,f2,f13
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// fmuls f22,f2,f30
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// lfs f2,1292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1292);
	ctx.f2.f64 = double(temp.f32);
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f26,f26,f13
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// lfs f18,1140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1140);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f21,f21,f2
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f2.f64));
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f17,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f27,f22,f17,f27
	ctx.f27.f64 = double(float(-(ctx.f22.f64 * ctx.f17.f64 - ctx.f27.f64)));
	// lfs f22,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f1,f22
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f22.f64));
	// lfs f1,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1736(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1736, temp.u32);
	// lfs f2,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f24,f24,f31
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// fmuls f20,f2,f3
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f2,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f2.f64 = double(temp.f32);
	// lfs f19,1916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1916);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f2
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f2.f64));
	// lfs f14,2368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2368);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmadds f15,f26,f7,f27
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 + ctx.f27.f64));
	// lfs f26,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f5,f1
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,2372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2372);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f4,f1
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// fmuls f1,f31,f28
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmuls f20,f20,f7
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// fmadds f24,f24,f0,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 + ctx.f22.f64));
	// fmuls f16,f16,f28
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// fmuls f27,f1,f13
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fmadds f20,f18,f6,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f6.f64 + ctx.f20.f64));
	// lfs f18,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f26,f27
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fmuls f27,f30,f28
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmuls f27,f18,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f27.f64));
	// lfs f18,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f18.f64));
	// lfs f14,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f23,f23,f14,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f14.f64 + ctx.f15.f64));
	// lfs f15,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f24,f19,f15,f24
	ctx.f24.f64 = double(float(-(ctx.f19.f64 * ctx.f15.f64 - ctx.f24.f64)));
	// lfs f15,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f19.f64));
	// lfs f14,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f27,f13
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// lfs f27,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f28
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// stfs f27,1336(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1336, temp.u32);
	// fnmsubs f23,f21,f7,f23
	ctx.f23.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f23.f64)));
	// lfs f21,1728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1728);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f24,f17,f0,f24
	ctx.f24.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// fmuls f14,f27,f14
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f14.f64));
	// lfs f27,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f28,f27
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f27.f64));
	// fmadds f23,f20,f13,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f23.f64));
	// fmuls f27,f5,f27
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// stfs f27,328(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fmuls f27,f26,f31
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// lfs f26,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// stfs f27,1844(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1844, temp.u32);
	// lfs f21,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f1,f21,f19
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f21.f64 + ctx.f19.f64));
	// lfs f1,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f5,f1
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f24,f16,f1,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f24.f64));
	// lfs f1,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f1.f64 = double(temp.f32);
	// lfs f16,3004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3004);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f4,f16
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f16.f64));
	// fmuls f27,f27,f2
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmuls f19,f19,f31
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f31.f64));
	// lfs f20,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f1,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f1.f64 + ctx.f27.f64));
	// lfs f1,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// lfs f27,824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 824);
	ctx.f27.f64 = double(temp.f32);
	// stfs f1,1080(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1080, temp.u32);
	// fmuls f17,f1,f27
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// fnmsubs f23,f22,f6,f23
	ctx.f23.f64 = double(float(-(ctx.f22.f64 * ctx.f6.f64 - ctx.f23.f64)));
	// lfs f22,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f24,f18,f22,f24
	ctx.f24.f64 = double(float(-(ctx.f18.f64 * ctx.f22.f64 - ctx.f24.f64)));
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f22,f16,f30
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// fmadds f23,f15,f6,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f6.f64 + ctx.f23.f64));
	// fnmsubs f24,f14,f10,f24
	ctx.f24.f64 = double(float(-(ctx.f14.f64 * ctx.f10.f64 - ctx.f24.f64)));
	// fmuls f3,f3,f27
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// fnmsubs f26,f26,f6,f23
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f6.f64 - ctx.f23.f64)));
	// fmadds f24,f20,f0,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f24.f64));
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmadds f6,f21,f6,f26
	ctx.f6.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 + ctx.f26.f64));
	// fnmsubs f26,f19,f0,f24
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// fadds f6,f25,f6
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f6.f64));
	// stfs f6,4452(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4452, temp.u32);
	// lfs f6,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f25,f17,f10,f26
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f26.f64));
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f26,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f26.f64 = double(temp.f32);
	// lfs f17,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f24,f5,f6
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,1744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1744);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f1,f6
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f6,f26,f30
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// stfs f6,1816(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1816, temp.u32);
	// fmuls f21,f5,f6
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,2528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2528);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f1,f6
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// lfs f6,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f1,f22,f6,f3
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 + ctx.f3.f64));
	// lfs f6,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,1936(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1936, temp.u32);
	// fnmsubs f24,f24,f10,f1
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f10.f64 - ctx.f1.f64)));
	// lfs f1,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f5,f1
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// fmuls f1,f26,f28
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// stfs f1,1224(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1224, temp.u32);
	// fmuls f22,f6,f2
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// lfs f6,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f3,f6,f28
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f6,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f6.f64 = double(temp.f32);
	// stfs f3,1744(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1744, temp.u32);
	// lfs f26,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f24,f23,f10,f24
	ctx.f24.f64 = double(float(-(ctx.f23.f64 * ctx.f10.f64 - ctx.f24.f64)));
	// fmuls f15,f6,f1
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1328(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1328, temp.u32);
	// fmuls f19,f6,f3
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f3,2356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2356);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f4,f3
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// fmuls f14,f1,f2
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f1,2352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2352);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// fmuls f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// fmadds f21,f3,f17,f21
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f17.f64 + ctx.f21.f64));
	// lfs f17,1248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1248);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f3,f3,f27
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// fmadds f27,f16,f31,f15
	ctx.f27.f64 = double(float(ctx.f16.f64 * ctx.f31.f64 + ctx.f15.f64));
	// fmuls f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// fmuls f23,f14,f10
	ctx.f23.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// fmuls f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// stfs f1,328(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fmuls f1,f26,f30
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// fmadds f24,f21,f10,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 + ctx.f24.f64));
	// lfs f21,1716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// fmsubs f27,f27,f10,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f23.f64));
	// fmuls f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// fmuls f5,f26,f28
	ctx.f5.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// stfs f5,1880(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1880, temp.u32);
	// lfs f26,4244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4244);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f4,f26
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f26.f64));
	// fmuls f5,f6,f5
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f6,4252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4252);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f4,f6
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 900);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fmuls f23,f4,f6
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f6.f64 = double(temp.f32);
	// lfs f15,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f24,f20,f0,f24
	ctx.f24.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// fmuls f15,f6,f15
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f15.f64));
	// lfs f6,4260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4260);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f4,f6
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,4268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4268);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f14,f4,f6
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 892);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmadds f3,f3,f10,f27
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 + ctx.f27.f64));
	// fnmsubs f24,f22,f0,f24
	ctx.f24.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// lfs f22,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// fmuls f27,f4,f6
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,1080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1080);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// lfs f6,2160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2160);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fmuls f15,f4,f6
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f4,f26,f6,f3
	ctx.f4.f64 = double(float(-(ctx.f26.f64 * ctx.f6.f64 - ctx.f3.f64)));
	// lfs f26,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f3,f19,f0,f24
	ctx.f3.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// fnmsubs f4,f16,f6,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f6.f64 - ctx.f4.f64)));
	// lfs f16,4080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4080);
	ctx.f16.f64 = double(temp.f32);
	// fadds f3,f25,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 + ctx.f3.f64));
	// lfs f25,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f4,f20,f6,f4
	ctx.f4.f64 = double(float(-(ctx.f20.f64 * ctx.f6.f64 - ctx.f4.f64)));
	// fmadds f3,f18,f26,f3
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f26.f64 + ctx.f3.f64));
	// fnmsubs f4,f14,f6,f4
	ctx.f4.f64 = double(float(-(ctx.f14.f64 * ctx.f6.f64 - ctx.f4.f64)));
	// fnmsubs f3,f17,f0,f3
	ctx.f3.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f3.f64)));
	// lfs f17,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f26,f22,f10,f4
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 + ctx.f4.f64));
	// fnmsubs f4,f25,f6,f3
	ctx.f4.f64 = double(float(-(ctx.f25.f64 * ctx.f6.f64 - ctx.f3.f64)));
	// lfs f3,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f4,f1,f10,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f4.f64));
	// lfs f1,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f5,f10,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 + ctx.f4.f64));
	// lfs f4,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f5,f21,f0,f5
	ctx.f5.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f5.f64));
	// fnmsubs f5,f23,f6,f5
	ctx.f5.f64 = double(float(-(ctx.f23.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// lfs f23,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f1
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f1.f64));
	// lfs f1,4276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4276);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f2,f0,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f5.f64));
	// fnmsubs f27,f27,f6,f5
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// lfs f5,1940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1940);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f2,f4,f5
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// lfs f4,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f25,f4,f3
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f4,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f24,f4,f5
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// fmuls f22,f5,f1
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f1,-29908(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29908);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f25,f25,f1
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f1.f64));
	// stfs f1,272(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fmuls f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// lfs f3,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f23,f4,f3,f23
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 + ctx.f23.f64));
	// lfs f4,4284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4284);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f21,f5,f4
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f3,-29880(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -29880);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,4072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4072);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f22,f22,f12
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// fmuls f20,f5,f4
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f4,-29896(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -29896);
	ctx.f4.f64 = double(temp.f32);
	// stfs f3,148(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f4,292(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fmuls f19,f2,f3
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f2,3356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3356);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f25,f2,f4,f25
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f4.f64 - ctx.f25.f64));
	// lfs f2,2396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2396);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f18,f5,f2
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// lfs f2,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f23,f23,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// fmuls f17,f2,f17
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// fmsubs f24,f24,f3,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 - ctx.f19.f64));
	// lfs f14,2404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2404);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f25,f25,f5,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 - ctx.f22.f64));
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fnmsubs f22,f15,f6,f26
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f6.f64 - ctx.f26.f64)));
	// lfs f6,3364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3364);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f19,f5,f6
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,2412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2412);
	ctx.f6.f64 = double(temp.f32);
	// lfs f26,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f17,f31
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f31.f64));
	// fmuls f16,f5,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f16.f64));
	// fmuls f14,f5,f14
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// fmadds f3,f23,f3,f24
	ctx.f3.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 + ctx.f24.f64));
	// fmuls f24,f6,f12
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// lfs f6,3844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3844);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f5,f6
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fmuls f6,f30,f26
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f26.f64));
	// stfs f6,664(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 664, temp.u32);
	// fmadds f25,f21,f4,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 + ctx.f25.f64));
	// lfs f21,3372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3372);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f3,f20,f12,f3
	ctx.f3.f64 = double(float(-(ctx.f20.f64 * ctx.f12.f64 - ctx.f3.f64)));
	// lfs f20,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f24,f21,f4,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 + ctx.f24.f64));
	// lfs f21,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// fmuls f6,f2,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// fmadds f2,f17,f10,f22
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f22.f64));
	// lfs f22,2420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2420);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f25,f18,f12,f25
	ctx.f25.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f25.f64)));
	// lfs f18,2436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2436);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f5,f22
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f22.f64));
	// fmadds f17,f16,f12,f3
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f3.f64));
	// lfs f3,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f3.f64 = double(temp.f32);
	// lfs f16,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// lfs f6,2428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2428);
	ctx.f6.f64 = double(temp.f32);
	// fadds f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 + ctx.f2.f64));
	// fmuls f27,f5,f6
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,4184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4184);
	ctx.f6.f64 = double(temp.f32);
	// fadds f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 + ctx.f18.f64));
	// lfs f6,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// fmuls f6,f3,f31
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fnmsubs f25,f14,f12,f25
	ctx.f25.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f25.f64)));
	// fnmsubs f19,f19,f4,f17
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f17.f64)));
	// lfs f17,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f2,f20,f0,f2
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f2.f64));
	// lfs f20,3380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3380);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f5,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// fmuls f18,f18,f5
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f5.f64));
	// fmuls f6,f6,f16
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f16.f64));
	// lfs f16,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f25,f23,f4,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f25.f64));
	// lfs f23,1320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1320);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f3
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// fmadds f6,f6,f10,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f10.f64 + ctx.f2.f64));
	// stfs f6,4456(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4456, temp.u32);
	// fmadds f6,f24,f5,f19
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 + ctx.f19.f64));
	// lfs f24,-30008(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -30008);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f3,f22,f12,f25
	ctx.f3.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f25.f64)));
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f25,2172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2172);
	ctx.f25.f64 = double(temp.f32);
	// stfs f24,312(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fnmsubs f6,f27,f4,f6
	ctx.f6.f64 = double(float(-(ctx.f27.f64 * ctx.f4.f64 - ctx.f6.f64)));
	// lfs f27,4088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4088);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f3,f21,f1,f3
	ctx.f3.f64 = double(float(-(ctx.f21.f64 * ctx.f1.f64 - ctx.f3.f64)));
	// fmadds f22,f18,f4,f6
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f6.f64));
	// lfs f6,1124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1124);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f21,f20,f12,f3
	ctx.f21.f64 = double(float(-(ctx.f20.f64 * ctx.f12.f64 - ctx.f3.f64)));
	// lfs f3,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f6,f27
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f6,1316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1316);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f6,f3
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f3,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f3,f6
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f3,f25
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f3,-29892(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29892);
	ctx.f3.f64 = double(temp.f32);
	// stfs f3,544(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// fmuls f17,f17,f3
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// lfs f3,2444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2444);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// lfs f3,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f2,f3
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f20,f20,f4
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f4.f64));
	// lfs f2,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f6,f2
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// stfs f2,460(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// fmuls f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f26.f64));
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f19,f18,f3
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// lfs f18,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f18.f64 = double(temp.f32);
	// lfs f2,-29900(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29900);
	ctx.f2.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stfs f2,280(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// fmadds f18,f18,f2,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f2.f64 + ctx.f17.f64));
	// lfs f2,-29904(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29904);
	ctx.f2.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmadds f1,f15,f1,f20
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f1.f64 + ctx.f20.f64));
	// lfs f20,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f16,f2
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// lfs f16,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f25,f16,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f20,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f27.f64));
	// fmuls f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// lfs f15,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f15.f64 = double(temp.f32);
	// stfs f2,200(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fmuls f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f15.f64));
	// lfs f14,2460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2460);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f1,f26,f24,f1
	ctx.f1.f64 = double(float(-(ctx.f26.f64 * ctx.f24.f64 - ctx.f1.f64)));
	// lfs f24,3852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3852);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f27,f18,f27,f17
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f27.f64 + ctx.f17.f64));
	// lfs f18,2452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2452);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f25,f25,f3
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// fmuls f26,f20,f3
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// fmuls f20,f16,f6
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// fmuls f17,f15,f6
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f6.f64));
	// lfs f15,1472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1472);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// fmuls f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// fnmsubs f2,f19,f2,f1
	ctx.f2.f64 = double(float(-(ctx.f19.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// lfs f1,1924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1924);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// lfs f5,3388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3388);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f19,f6,f5
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f16,f5,f6
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f5,2140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2140);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f15,f15,f5
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// lfs f5,-29820(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29820);
	ctx.f5.f64 = double(temp.f32);
	// stfs f5,260(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fmuls f5,f14,f5
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f5.f64));
	// lfs f14,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f14.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fnmsubs f23,f23,f14,f21
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f14.f64 - ctx.f21.f64)));
	// lfs f21,1268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1268);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f2,f27,f3,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f3.f64 + ctx.f2.f64));
	// lfs f27,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// lfs f27,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f16,f27
	ctx.f27.f64 = double(float(ctx.f16.f64 * ctx.f27.f64));
	// lfs f16,4088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4088);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f16.f64));
	// lfs f16,2172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2172);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f16.f64));
	// lfs f14,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// lfs f14,2468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2468);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f14,f14,f12,f5
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f12.f64 + ctx.f5.f64));
	// lfs f5,-29888(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29888);
	ctx.f5.f64 = double(temp.f32);
	// stfs f5,508(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// fnmsubs f5,f25,f5,f2
	ctx.f5.f64 = double(float(-(ctx.f25.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f2,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f2,f1,f2,f23
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 + ctx.f23.f64));
	// lfs f1,3396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3396);
	ctx.f1.f64 = double(temp.f32);
	// lfs f25,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f1,f6,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f23,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f25.f64));
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f23,f21,f3
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// fmadds f21,f16,f12,f15
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f15.f64));
	// lfs f15,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f26,f26,f15,f5
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f15.f64 + ctx.f5.f64));
	// lfs f15,2112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2112);
	ctx.f15.f64 = double(temp.f32);
	// fadds f5,f22,f2
	ctx.f5.f64 = double(float(ctx.f22.f64 + ctx.f2.f64));
	// stfs f5,4460(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4460, temp.u32);
	// lfs f5,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f16,f14,f6
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f6.f64));
	// lfs f14,2300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2300);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f6,f14
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// fnmsubs f2,f20,f5,f26
	ctx.f2.f64 = double(float(-(ctx.f20.f64 * ctx.f5.f64 - ctx.f26.f64)));
	// lfs f26,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f22,f21,f3,f16
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 + ctx.f16.f64));
	// fnmsubs f2,f25,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f25.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// fnmsubs f22,f1,f12,f22
	ctx.f22.f64 = double(float(-(ctx.f1.f64 * ctx.f12.f64 - ctx.f22.f64)));
	// fmadds f2,f17,f26,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 + ctx.f2.f64));
	// fnmsubs f2,f24,f12,f2
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// fmadds f2,f18,f12,f2
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 + ctx.f2.f64));
	// fnmsubs f2,f19,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f19.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f19,2484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2484);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f5,f27,f5,f2
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f2.f64));
	// lfs f2,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f26,f23,f2,f5
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f5.f64));
	// lfs f5,2476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2476);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,1784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1784);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f5,f2
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// lfs f5,3860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3860);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f24,f6,f5
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f27,f6,f5
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,2124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2124);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f23,f6,f5
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f2,f5,f31
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// lfs f5,4280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4280);
	ctx.f5.f64 = double(temp.f32);
	// stfs f2,2252(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2252, temp.u32);
	// fmuls f21,f2,f5
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// lfs f5,2024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2024);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f20,f6,f5
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f5,f28
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// stfs f1,1284(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1284, temp.u32);
	// fmuls f19,f19,f1
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// lfs f1,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f18,f27,f1
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// lfs f1,1824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1824);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f17,f6,f1
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f27,2172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2172);
	ctx.f27.f64 = double(temp.f32);
	// lfs f1,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f1,f27
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// lfs f1,-29884(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -29884);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f25,f25,f1,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f22.f64));
	// lfs f22,1328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1328);
	ctx.f22.f64 = double(temp.f32);
	// lfs f27,-29876(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29876);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f15.f64));
	// lfs f15,1836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1836);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f21,f21,f27
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f27.f64));
	// fmuls f2,f2,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f15.f64));
	// lfs f15,2240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2240);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f5,f15
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f15.f64));
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stfs f27,100(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f1,320(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// fmuls f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// lfs f3,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f25,f24,f3,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f3.f64 - ctx.f25.f64)));
	// lfs f3,-30012(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -30012);
	ctx.f3.f64 = double(temp.f32);
	// stfs f3,372(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// fmsubs f21,f19,f10,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 - ctx.f21.f64));
	// lfs f24,908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 908);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f5,f24
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// fmuls f19,f15,f30
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f30.f64));
	// lfs f15,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f3,f15,f3
	ctx.f3.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// lfs f15,2208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2208);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f6,f15
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f15.f64));
	// fnmsubs f1,f18,f1,f25
	ctx.f1.f64 = double(float(-(ctx.f18.f64 * ctx.f1.f64 - ctx.f25.f64)));
	// fmadds f27,f22,f27,f21
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f27.f64 + ctx.f21.f64));
	// lfs f21,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f24,f24,f31
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// fmadds f21,f21,f0,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f3.f64));
	// lfs f3,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f3.f64 = double(temp.f32);
	// lfs f18,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f3,f18
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// lfs f22,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f3,f2,f0,f27
	ctx.f3.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f27.f64)));
	// stfs f3,328(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f25,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f25.f64));
	// lfs f27,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f27.f64 = double(temp.f32);
	// lfs f2,-29844(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29844);
	ctx.f2.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fnmsubs f1,f23,f2,f1
	ctx.f1.f64 = double(float(-(ctx.f23.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// lfs f22,2360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2360);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// stfs f2,180(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// fmuls f25,f25,f27
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f27,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f3,f27,f30
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// lfs f27,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f27.f64 = double(temp.f32);
	// stfs f3,756(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 756, temp.u32);
	// fmadds f20,f20,f2,f1
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f2.f64 + ctx.f1.f64));
	// lfs f1,2112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2112);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f23,f3,f27
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f27,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f20,f17,f12,f20
	ctx.f20.f64 = double(float(-(ctx.f17.f64 * ctx.f12.f64 - ctx.f20.f64)));
	// lfs f3,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f19,f19,f27,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f3.f64));
	// lfs f3,-29852(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29852);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f25,f18,f3,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f3.f64 + ctx.f25.f64));
	// stfs f3,296(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f3,1004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1004);
	ctx.f3.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f18,f5,f3
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,1148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1148);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f5,f3
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// stfs f3,1824(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1824, temp.u32);
	// lfs f3,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fnmsubs f24,f24,f27,f19
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f27.f64 - ctx.f19.f64)));
	// fmuls f19,f18,f31
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f31.f64));
	// fmadds f23,f3,f0,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f23.f64));
	// lfs f3,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmadds f24,f21,f31,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f31.f64 + ctx.f24.f64));
	// fnmsubs f21,f16,f12,f20
	ctx.f21.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f20.f64)));
	// lfs f20,1228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1228);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// stfs f3,328(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fmr f3,f20
	ctx.f3.f64 = ctx.f20.f64;
	// fmadds f24,f23,f3,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 + ctx.f24.f64));
	// fnmsubs f23,f14,f4,f21
	ctx.f23.f64 = double(float(-(ctx.f14.f64 * ctx.f4.f64 - ctx.f21.f64)));
	// fnmsubs f24,f19,f0,f24
	ctx.f24.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// fmadds f4,f15,f4,f23
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fnmsubs f4,f22,f2,f4
	ctx.f4.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f4.f64)));
	// fmadds f6,f25,f6,f4
	ctx.f6.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f4.f64));
	// lfs f4,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f4.f64 = double(temp.f32);
	// lfs f25,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f25.f64 = double(temp.f32);
	// fadds f6,f26,f6
	ctx.f6.f64 = double(float(ctx.f26.f64 + ctx.f6.f64));
	// stfs f6,4464(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4464, temp.u32);
	// fmuls f6,f4,f30
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// stfs f6,1520(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1520, temp.u32);
	// fmuls f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// stfs f4,1332(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1332, temp.u32);
	// lfs f26,-30016(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30016);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,784(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 784, temp.u32);
	// fmuls f2,f3,f6
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f6,1844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1844);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f6,f1
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f6,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f22,f4,f6
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f4,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f31,f4
	ctx.f4.f64 = double(float(ctx.f31.f64 * ctx.f4.f64));
	// fmuls f21,f4,f25
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f25.f64));
	// lfs f4,1824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1824);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f20,f4,f30
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// lfs f4,2492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2492);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f19,f5,f4
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f25,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f27.f64));
	// lfs f4,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f18,f2,f25
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// fmuls f2,f4,f28
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// lfs f15,1836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1836);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// lfs f14,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// fmadds f26,f23,f26,f18
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 + ctx.f18.f64));
	// fmuls f17,f3,f2
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f2,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f20,f4,f6
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f4,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmsubs f26,f14,f0,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 - ctx.f26.f64));
	// fmuls f23,f3,f4
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f4,4272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4272);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f18,f5,f4
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f4,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f27,f21,f4,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 + ctx.f27.f64));
	// lfs f4,2500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2500);
	ctx.f4.f64 = double(temp.f32);
	// lfs f21,3412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3412);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f3,f2
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fadds f21,f4,f21
	ctx.f21.f64 = double(float(ctx.f4.f64 + ctx.f21.f64));
	// lfs f4,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// lfs f2,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f4,2244(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2244, temp.u32);
	// fnmsubs f26,f22,f0,f26
	ctx.f26.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f26.f64)));
	// lfs f22,3868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3868);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f27,f16,f25,f27
	ctx.f27.f64 = double(float(ctx.f16.f64 * ctx.f25.f64 - ctx.f27.f64));
	// lfs f16,1284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1284);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f25,f21,f5
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// fmuls f15,f4,f15
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f15.f64));
	// lfs f4,1216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1216);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// fmuls f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// lfs f4,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fmadds f27,f20,f0,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f27.f64));
	// fmuls f14,f4,f6
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f4,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f5,f4,f30
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fmuls f21,f5,f6
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f5,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fmuls f22,f22,f5
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// lfs f5,2508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2508);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f16,f5,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f16.f64));
	// fmuls f5,f4,f28
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// fmuls f4,f3,f5
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f5,2272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2272);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f20,f5,f6
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f5,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f26,f19,f5,f26
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f5.f64 - ctx.f26.f64)));
	// lfs f5,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f19,3868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3868);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmadds f26,f17,f0,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f26.f64));
	// fmuls f19,f19,f5
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f5.f64));
	// lfs f5,2104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2104);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f5,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f5.f64 = double(temp.f32);
	// stfs f6,328(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fmuls f6,f5,f30
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fmadds f16,f3,f6,f16
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f6.f64 + ctx.f16.f64));
	// lfs f6,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f27,f18,f6,f27
	ctx.f27.f64 = double(float(-(ctx.f18.f64 * ctx.f6.f64 - ctx.f27.f64)));
	// lfs f6,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f6,f28
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f6,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f6.f64 = double(temp.f32);
	// stfs f5,376(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fmuls f18,f5,f6
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f5,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fmuls f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f5,2516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2516);
	ctx.f5.f64 = double(temp.f32);
	// lfs f3,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f4,f16,f10,f4
	ctx.f4.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 - ctx.f4.f64));
	// fmuls f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f3,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f27,f25,f3,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f27.f64));
	// lfs f17,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f2,f2,f0,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f26.f64));
	// lfs f26,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f26.f64 = double(temp.f32);
	// lfs f16,3876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3876);
	ctx.f16.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f4,f18,f0,f4
	ctx.f4.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f4.f64));
	// lfs f18,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f18.f64));
	// lfs f17,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f27,f14,f10,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 + ctx.f27.f64));
	// fmadds f2,f23,f26,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 + ctx.f2.f64));
	// lfs f26,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f27,f22,f26,f27
	ctx.f27.f64 = double(float(-(ctx.f22.f64 * ctx.f26.f64 - ctx.f27.f64)));
	// fnmsubs f26,f6,f10,f4
	ctx.f26.f64 = double(float(-(ctx.f6.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f4,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f6,f15,f0,f2
	ctx.f6.f64 = double(float(-(ctx.f15.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f2,f19,f0,f27
	ctx.f2.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f27.f64)));
	// lfs f19,2532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2532);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f5,f5,f3,f26
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f3.f64 - ctx.f26.f64)));
	// lfs f26,4096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4096);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f6,f1,f4,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f4.f64 + ctx.f6.f64));
	// lfs f1,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f11,f19
	ctx.f19.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// fmadds f2,f1,f4,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f4.f64 + ctx.f2.f64));
	// fnmsubs f6,f21,f0,f6
	ctx.f6.f64 = double(float(-(ctx.f21.f64 * ctx.f0.f64 - ctx.f6.f64)));
	// lfs f21,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f6,f20,f4,f6
	ctx.f6.f64 = double(float(-(ctx.f20.f64 * ctx.f4.f64 - ctx.f6.f64)));
	// lfs f20,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f20.f64 = double(temp.f32);
	// fadds f6,f24,f6
	ctx.f6.f64 = double(float(ctx.f24.f64 + ctx.f6.f64));
	// fadds f25,f6,f2
	ctx.f25.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// lfs f6,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f1,f6,f31
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// lfs f6,2224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2224);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f27,f6,f11
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f6,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,3420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3420);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f26,f6,f26
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// fmuls f24,f6,f2
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// lfs f2,2264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2264);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f23,f2,f11
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lfs f2,-30020(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30020);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,416(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fmuls f22,f1,f30
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// fmuls f1,f31,f31
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f20,f27,f20
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// lfs f27,2524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2524);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f7
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// fmadds f24,f24,f17,f5
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f17.f64 + ctx.f5.f64));
	// lfs f5,3428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3428);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f17,f5,f7
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// lfs f5,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmuls f21,f1,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// fnmsubs f24,f26,f3,f24
	ctx.f24.f64 = double(float(-(ctx.f26.f64 * ctx.f3.f64 - ctx.f24.f64)));
	// lfs f26,1260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1260);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f18,f15,f26,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f26.f64 + ctx.f18.f64));
	// lfs f26,2176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2176);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f17,f26,f2,f17
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 + ctx.f17.f64));
	// lfs f26,3436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3436);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f22,f16,f7,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f7.f64 - ctx.f22.f64));
	// lfs f16,2548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2548);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f27,f21,f5,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f5.f64 + ctx.f27.f64));
	// lfs f21,2540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2540);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// fmuls f16,f11,f16
	ctx.f16.f64 = double(float(ctx.f11.f64 * ctx.f16.f64));
	// fmsubs f22,f22,f11,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 - ctx.f20.f64));
	// fmuls f15,f27,f11
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// fmuls f27,f6,f28
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fmadds f24,f21,f3,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 + ctx.f24.f64));
	// lfs f3,2556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2556);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f21,f18,f11
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// fmuls f18,f11,f3
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmuls f14,f26,f27
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// lfs f26,2604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2604);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f20,f1,f26
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// fmuls f3,f30,f30
	ctx.f3.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmsubs f17,f17,f11,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 - ctx.f15.f64));
	// fnmsubs f23,f23,f2,f22
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f2.f64 - ctx.f22.f64)));
	// fnmsubs f24,f14,f10,f24
	ctx.f24.f64 = double(float(-(ctx.f14.f64 * ctx.f10.f64 - ctx.f24.f64)));
	// fmuls f15,f3,f26
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f26.f64));
	// lfs f3,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// lfs f26,1228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1228);
	ctx.f26.f64 = double(temp.f32);
	// stfs f3,812(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 812, temp.u32);
	// fmadds f23,f19,f7,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 + ctx.f23.f64));
	// fmuls f22,f26,f3
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// lfs f3,4192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4192);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f3,f27
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f3,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f3.f64 = double(temp.f32);
	// lfs f26,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f18,f18,f3,f17
	ctx.f18.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f17.f64)));
	// fmuls f17,f15,f26
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f26.f64));
	// lfs f27,1232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1232);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f20,f26
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// lfs f26,924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 924);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f19,f27,f26
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// lfs f27,2564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2564);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,3444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3444);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f23,f16,f7,f23
	ctx.f23.f64 = double(float(-(ctx.f16.f64 * ctx.f7.f64 - ctx.f23.f64)));
	// fmuls f15,f11,f26
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f26.f64));
	// lfs f16,1932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1932);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f24,f22,f10,f24
	ctx.f24.f64 = double(float(-(ctx.f22.f64 * ctx.f10.f64 - ctx.f24.f64)));
	// fmuls f22,f11,f27
	ctx.f22.f64 = double(float(ctx.f11.f64 * ctx.f27.f64));
	// lfs f27,-30024(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30024);
	ctx.f27.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f27,740(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 740, temp.u32);
	// lfs f26,-30028(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30028);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,300(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f26,-29848(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -29848);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,308(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fnmsubs f26,f17,f26,f18
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f26.f64 - ctx.f18.f64)));
	// lfs f18,2572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2572);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f24,f14,f10,f24
	ctx.f24.f64 = double(float(-(ctx.f14.f64 * ctx.f10.f64 - ctx.f24.f64)));
	// fmuls f18,f11,f18
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f18.f64));
	// lfs f14,3460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3460);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,2588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2588);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f11,f17
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f17.f64));
	// fnmsubs f26,f22,f27,f26
	ctx.f26.f64 = double(float(-(ctx.f22.f64 * ctx.f27.f64 - ctx.f26.f64)));
	// lfs f22,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f23,f21,f22,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f22.f64 + ctx.f23.f64));
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// stfs f25,4468(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4468, temp.u32);
	// fnmsubs f24,f18,f7,f26
	ctx.f24.f64 = double(float(-(ctx.f18.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// lfs f18,924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 924);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f26,f20,f7,f23
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f23.f64));
	// lfs f20,2248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2248);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f25,f19,f5,f26
	ctx.f25.f64 = double(float(-(ctx.f19.f64 * ctx.f5.f64 - ctx.f26.f64)));
	// lfs f19,2064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2064);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,3452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3452);
	ctx.f18.f64 = double(temp.f32);
	// lfs f26,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f23,f15,f26,f25
	ctx.f23.f64 = double(float(-(ctx.f15.f64 * ctx.f26.f64 - ctx.f25.f64)));
	// lfs f25,3884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3884);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f22,f11,f25
	ctx.f22.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// lfs f25,2580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2580);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f18,f18,f26
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f26.f64));
	// lfs f15,2596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2596);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f21,f11,f25
	ctx.f21.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// lfs f25,1992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1992);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f20,f20,f25
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// fmuls f25,f16,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// lfs f16,4104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4104);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f26.f64));
	// lfs f17,2000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2000);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f16,f7
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f7.f64));
	// fmuls f15,f11,f15
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// fmuls f22,f22,f27
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f27.f64));
	// fmadds f18,f14,f27,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f27.f64 + ctx.f18.f64));
	// lfs f14,2288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2288);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f27,f28,f28
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// fmsubs f22,f21,f3,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 - ctx.f22.f64));
	// lfs f21,2604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2604);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f27,f21
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// lfs f27,1732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1732);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f17,f27
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f27.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmsubs f26,f18,f11,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 - ctx.f26.f64));
	// lfs f18,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f24,f17,f5,f24
	ctx.f24.f64 = double(float(-(ctx.f17.f64 * ctx.f5.f64 - ctx.f24.f64)));
	// fmuls f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f18.f64));
	// fnmsubs f22,f20,f5,f22
	ctx.f22.f64 = double(float(-(ctx.f20.f64 * ctx.f5.f64 - ctx.f22.f64)));
	// lfs f20,2200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2200);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f16,f14,f2,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f2.f64 + ctx.f16.f64));
	// lfs f14,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,-30032(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30032);
	ctx.f18.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f18,1040(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1040, temp.u32);
	// fmuls f20,f20,f2
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f2.f64));
	// fmuls f14,f14,f27
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f27.f64));
	// lfs f18,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f27
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f27.f64));
	// lfs f17,-30036(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30036);
	ctx.f17.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f17,1056(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1056, temp.u32);
	// lfs f17,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f22,f19,f5,f22
	ctx.f22.f64 = double(float(-(ctx.f19.f64 * ctx.f5.f64 - ctx.f22.f64)));
	// lfs f19,2076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2076);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f26,f16,f11,f26
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 + ctx.f26.f64));
	// lfs f27,-29824(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29824);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f11,f17
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f17.f64));
	// stfs f27,216(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fmadds f27,f19,f27,f20
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f20.f64));
	// lfs f20,3892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3892);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f11,f20
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f20.f64));
	// fmadds f25,f25,f5,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 + ctx.f22.f64));
	// lfs f22,2084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2084);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f26,f14,f3,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 * ctx.f3.f64 + ctx.f26.f64));
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmadds f25,f15,f7,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 * ctx.f7.f64 + ctx.f25.f64));
	// fnmsubs f26,f22,f2,f26
	ctx.f26.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f26.f64)));
	// lfs f2,1952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1952);
	ctx.f2.f64 = double(temp.f32);
	// lfs f22,1992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1992);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f2,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// lfs f2,4240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4240);
	ctx.f2.f64 = double(temp.f32);
	// lfs f16,1040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1040);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f25,f21,f16,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f16.f64 - ctx.f25.f64)));
	// lfs f21,1980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1980);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,1056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1056);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f24,f18,f19,f24
	ctx.f24.f64 = double(float(-(ctx.f18.f64 * ctx.f19.f64 - ctx.f24.f64)));
	// lfs f18,2612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2612);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f27,f18,f3,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f3.f64 + ctx.f27.f64));
	// lfs f18,3468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3468);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f19,f17,f1
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f1.f64));
	// lfs f17,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f11,f18
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f18.f64));
	// fmadds f27,f2,f7,f27
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f7.f64 + ctx.f27.f64));
	// lfs f2,1972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1972);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f24,f19,f5,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f5.f64 + ctx.f24.f64));
	// lfs f19,2620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2620);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f11,f19
	ctx.f19.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// fmuls f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// fmadds f27,f27,f11,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f26.f64));
	// fnmsubs f26,f20,f3,f25
	ctx.f26.f64 = double(float(-(ctx.f20.f64 * ctx.f3.f64 - ctx.f25.f64)));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfs f23,2256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2256);
	ctx.f23.f64 = double(temp.f32);
	// fadds f21,f23,f21
	ctx.f21.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// fnmsubs f26,f18,f3,f26
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f26.f64)));
	// fadds f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// lfs f24,1236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1236);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f3,f19,f3,f26
	ctx.f3.f64 = double(float(-(ctx.f19.f64 * ctx.f3.f64 - ctx.f26.f64)));
	// fnmsubs f5,f22,f5,f3
	ctx.f5.f64 = double(float(-(ctx.f22.f64 * ctx.f5.f64 - ctx.f3.f64)));
	// fadds f5,f27,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 + ctx.f5.f64));
	// stfs f5,4472(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4472, temp.u32);
	// lfs f5,2072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2072);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f3,f2,f5
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// lfs f5,1456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1456);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,1060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1060);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f27,f5,f2
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// lfs f5,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f26,f5,f2
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// lfs f5,2628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2628);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f5,f2
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// lfs f5,2116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2116);
	ctx.f5.f64 = double(temp.f32);
	// fadds f24,f5,f24
	ctx.f24.f64 = double(float(ctx.f5.f64 + ctx.f24.f64));
	// lfs f5,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f5.f64 = double(temp.f32);
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// lfs f23,3476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3476);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f5,f23
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// lfs f23,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfs f3,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f3,f5
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f19,1464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1464);
	ctx.f19.f64 = double(temp.f32);
	// lfs f3,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f25,f19,f3,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f3.f64 - ctx.f25.f64));
	// lfs f3,-30260(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -30260);
	ctx.f3.f64 = double(temp.f32);
	// lfs f19,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// stfs f3,1236(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1236, temp.u32);
	// lfs f3,1184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1184);
	ctx.f3.f64 = double(temp.f32);
	// lfs f14,2636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2636);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f3.f64));
	// lfs f3,2132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2132);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f27,f27,f4,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f4.f64 - ctx.f23.f64));
	// lfs f23,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f23.f64 = double(temp.f32);
	// fadds f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f3.f64));
	// lfs f3,1300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1300);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfs f3,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f25,f14,f2,f25
	ctx.f25.f64 = double(float(-(ctx.f14.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// lfs f14,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f20,f20,f3
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// lfs f3,1740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1740);
	ctx.f3.f64 = double(temp.f32);
	// lfs f16,2376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2376);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f3,f16
	ctx.f16.f64 = double(float(ctx.f3.f64 + ctx.f16.f64));
	// lfs f3,1820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1820);
	ctx.f3.f64 = double(temp.f32);
	// lfs f15,2128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2128);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f3,f15
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f15.f64));
	// fnmsubs f27,f26,f14,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f14.f64 - ctx.f27.f64)));
	// lfs f26,16664(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16664);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,1300(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1300, temp.u32);
	// lfs f14,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f14.f64 = double(temp.f32);
	// lfs f26,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f14,f26,f19
	ctx.f26.f64 = double(float(ctx.f14.f64 * ctx.f26.f64 + ctx.f19.f64));
	// lfs f14,2156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2156);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f19,f18,f3
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// lfs f18,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f24,f24,f18,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f18.f64 + ctx.f23.f64));
	// lfs f23,1456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1456);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f18,f16,f23,f15
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f23.f64 + ctx.f15.f64));
	// lfs f15,1828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1828);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,2004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2004);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f27,f22,f0,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 + ctx.f27.f64));
	// lfs f22,3900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3900);
	ctx.f22.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,1300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1300);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f25,f22,f15,f25
	ctx.f25.f64 = double(float(-(ctx.f22.f64 * ctx.f15.f64 - ctx.f25.f64)));
	// fmadds f22,f21,f23,f19
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f23.f64 + ctx.f19.f64));
	// fmuls f21,f24,f5
	ctx.f21.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// lfs f24,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f20,f20,f24,f27
	ctx.f20.f64 = double(float(-(ctx.f20.f64 * ctx.f24.f64 - ctx.f27.f64)));
	// lfs f27,2644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2644);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f16,f3
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// fnmsubs f25,f27,f29,f25
	ctx.f25.f64 = double(float(-(ctx.f27.f64 * ctx.f29.f64 - ctx.f25.f64)));
	// lfs f27,1908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1908);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f16,f3,f27
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f27,1972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1972);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f22,f22,f10,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 + ctx.f21.f64));
	// lfs f21,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f15,f21,f27
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f27.f64));
	// lfs f21,2148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2148);
	ctx.f21.f64 = double(temp.f32);
	// fadds f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// fmadds f21,f18,f0,f20
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f20.f64));
	// lfs f20,1752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1752);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f20,f20,f2,f25
	ctx.f20.f64 = double(float(-(ctx.f20.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// lfs f25,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f18,f25,f27
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f25,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f30
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f30.f64));
	// stfs f25,696(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 696, temp.u32);
	// fmsubs f22,f17,f0,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 - ctx.f22.f64));
	// fmadds f16,f25,f27,f16
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f27.f64 + ctx.f16.f64));
	// lfs f27,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f30,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f27.f64));
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f25,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f25,f27
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// stfs f27,284(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fmadds f22,f16,f0,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 + ctx.f22.f64));
	// lfs f16,4112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4112);
	ctx.f16.f64 = double(temp.f32);
	// lfs f27,-11956(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11956);
	ctx.f27.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f27,1004(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1004, temp.u32);
	// lfs f27,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f19,f19,f27,f21
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f21.f64));
	// lfs f21,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f20,f14,f21,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f21.f64 + ctx.f20.f64));
	// lfs f14,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f27,f15,f27,f19
	ctx.f27.f64 = double(float(ctx.f15.f64 * ctx.f27.f64 + ctx.f19.f64));
	// lfs f15,1464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1464);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f27,f18,f4,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f27.f64));
	// fadds f27,f22,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// stfs f27,4476(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4476, temp.u32);
	// lfs f22,1244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1244);
	ctx.f22.f64 = double(temp.f32);
	// lfs f27,2164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2164);
	ctx.f27.f64 = double(temp.f32);
	// lfs f19,1004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1004);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f20,f17,f19,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f19.f64 + ctx.f20.f64));
	// lfs f19,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f20,f26,f19,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f19.f64 + ctx.f20.f64));
	// fadds f19,f27,f22
	ctx.f19.f64 = double(float(ctx.f27.f64 + ctx.f22.f64));
	// lfs f27,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f26,f27
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// lfs f27,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// lfs f26,-30192(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -30192);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f22,f1,f26
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// stfs f26,1752(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1752, temp.u32);
	// stfs f22,1320(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1320, temp.u32);
	// fmadds f21,f19,f21,f18
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f21.f64 + ctx.f18.f64));
	// lfs f19,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f27,f1
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// lfs f27,2652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2652);
	ctx.f27.f64 = double(temp.f32);
	// fadds f16,f27,f16
	ctx.f16.f64 = double(float(ctx.f27.f64 + ctx.f16.f64));
	// lfs f27,1988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1988);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f27,f15
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f15.f64));
	// stfs f15,1244(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1244, temp.u32);
	// lfs f15,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f19,f25,f19
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// fmuls f18,f17,f4
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f4.f64));
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64));
	// lfs f15,2180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2180);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f21,f15,f14,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f14.f64 + ctx.f21.f64));
	// fmadds f18,f16,f10,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f18.f64));
	// lfs f16,2660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2660);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f26
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f26.f64));
	// lfs f26,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f30
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// fmuls f17,f17,f24
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f24.f64));
	// fmadds f24,f19,f24,f18
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f24.f64 + ctx.f18.f64));
	// lfs f18,2020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2020);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f26,f27
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// lfs f26,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f25,f26
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// lfs f26,3492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3492);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f25,f26,f2,f21
	ctx.f25.f64 = double(float(-(ctx.f26.f64 * ctx.f2.f64 - ctx.f21.f64)));
	// lfs f26,1064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1064);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f23,f26
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f26.f64));
	// lfs f26,1996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1996);
	ctx.f26.f64 = double(temp.f32);
	// lfs f21,1908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1908);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f26,f21
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// lfs f26,-30208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30208);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,552(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 552, temp.u32);
	// fmsubs f24,f24,f5,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 - ctx.f17.f64));
	// fmuls f19,f15,f26
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f26.f64));
	// lfs f26,2668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2668);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f26,f26,f29,f25
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f29.f64 - ctx.f25.f64)));
	// lfs f25,2376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2376);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f21,f18,f25,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f25.f64 + ctx.f21.f64));
	// lfs f25,2188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2188);
	ctx.f25.f64 = double(temp.f32);
	// lfs f18,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f25,f18
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f18.f64));
	// lfs f25,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f25,f27
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f25,3908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3908);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,1300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1300);
	ctx.f15.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fnmsubs f15,f25,f15,f26
	ctx.f15.f64 = double(float(-(ctx.f25.f64 * ctx.f15.f64 - ctx.f26.f64)));
	// fmuls f25,f28,f28
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// fnmsubs f24,f23,f4,f24
	ctx.f24.f64 = double(float(-(ctx.f23.f64 * ctx.f4.f64 - ctx.f24.f64)));
	// fmuls f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// lfs f26,-30224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30224);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,384(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fnmsubs f25,f25,f26,f22
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// lfs f26,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f30
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// lfs f22,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f24,f21,f0,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f24.f64));
	// lfs f21,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f23,f5,f26
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f26,2196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2196);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f22,f26,f22,f18
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f22.f64 + ctx.f18.f64));
	// lfs f26,1244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1244);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f18,f26,f30
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// lfs f26,1004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1004);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f15,f14,f26,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f26.f64 + ctx.f15.f64));
	// fmuls f26,f30,f30
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// fmuls f23,f23,f1
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f1.f64));
	// lfs f1,2228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2228);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f1,f21,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f21.f64 + ctx.f20.f64));
	// stfs f1,4480(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4480, temp.u32);
	// lfs f1,1464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1464);
	ctx.f1.f64 = double(temp.f32);
	// lfs f21,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f26,f26,f30
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// stfs f26,1284(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1284, temp.u32);
	// fmadds f21,f1,f21,f15
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f21.f64 + ctx.f15.f64));
	// lfs f20,1764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1764);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f25,f25,f26,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f26.f64 + ctx.f16.f64));
	// lfs f16,4200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4200);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f1,f5,f26
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// fmadds f26,f22,f5,f24
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f5.f64 + ctx.f24.f64));
	// lfs f24,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f27,f25,f27,f19
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f27.f64 - ctx.f19.f64));
	// lfs f25,2676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2676);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f25,f2,f21
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f2.f64 - ctx.f21.f64)));
	// lfs f19,1980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1980);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f26,f23,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f23.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// fnmsubs f27,f18,f24,f27
	ctx.f27.f64 = double(float(-(ctx.f18.f64 * ctx.f24.f64 - ctx.f27.f64)));
	// lfs f24,3500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f2,f24,f2,f25
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// stfs f2,4488(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4488, temp.u32);
	// lfs f2,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f2.f64 = double(temp.f32);
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f2,f17,f2,f27
	ctx.f2.f64 = double(float(-(ctx.f17.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// stfs f2,4484(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4484, temp.u32);
	// lfs f2,1756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1756);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f3,f2
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f27,1828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1828);
	ctx.f27.f64 = double(temp.f32);
	// lfs f2,1996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1996);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f3,f3,f20
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// fmuls f24,f2,f27
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// lfs f2,1060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1060);
	ctx.f2.f64 = double(temp.f32);
	// lfs f27,2020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2020);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f23,f27,f2
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// lfs f2,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f22,f1,f2
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f2,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// lfs f20,2276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2276);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64));
	// lfs f17,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,2284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2284);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f20,f5,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// fmuls f19,f5,f19
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmuls f17,f1,f17
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// fmuls f21,f5,f2
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// lfs f2,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// fmsubs f25,f24,f18,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f18.f64 - ctx.f25.f64));
	// lfs f18,1456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1456);
	ctx.f18.f64 = double(temp.f32);
	// lfs f24,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f18,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f24.f64));
	// lfs f18,2684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2684);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f5,f18
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f18.f64));
	// fmuls f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// fmadds f25,f23,f4,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f25.f64));
	// lfs f4,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f4.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f23,f24,f28
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// fmuls f24,f1,f4
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// lfs f4,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f26,f17,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// lfs f15,2692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2692);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f11
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// lfs f17,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f5,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f16.f64));
	// lfs f4,-29964(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29964);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,676(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 676, temp.u32);
	// fmuls f17,f17,f4
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f4.f64));
	// lfs f4,3508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3508);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f14,f5,f4
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f4,1220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1220);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fnmsubs f25,f22,f10,f25
	ctx.f25.f64 = double(float(-(ctx.f22.f64 * ctx.f10.f64 - ctx.f25.f64)));
	// fmadds f26,f24,f10,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f26.f64));
	// lfs f24,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f22,f15,f7
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f7.f64));
	// lfs f15,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f1,f1,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f15.f64));
	// lfs f15,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f24,f24,f15,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f15.f64 + ctx.f17.f64));
	// lfs f17,2700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2700);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f5,f17
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f17.f64));
	// lfs f5,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f4,f11
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fnmsubs f25,f21,f5,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f5.f64 - ctx.f25.f64)));
	// lfs f5,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f5.f64 = double(temp.f32);
	// lfs f21,1456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1456);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// lfs f5,3916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3916);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f15,f5,f11
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// lfs f5,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f4,f4,f5,f22
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f5.f64 - ctx.f22.f64));
	// fnmsubs f4,f15,f7,f4
	ctx.f4.f64 = double(float(-(ctx.f15.f64 * ctx.f7.f64 - ctx.f4.f64)));
	// lfs f5,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f1,f1,f5,f26
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f5.f64 - ctx.f26.f64)));
	// lfs f5,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f26,f24,f5
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// lfs f5,2292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2292);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f24,f5,f11
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// lfs f5,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f25,f2,f5,f25
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f5.f64 + ctx.f25.f64));
	// fmuls f2,f31,f31
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f15,f11,f2
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f2.f64));
	// stfs f15,328(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f15,1284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1284);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f22,f21,f2
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f2.f64));
	// fmadds f1,f26,f15,f1
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f15.f64 + ctx.f1.f64));
	// lfs f26,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f3,f3,f26,f25
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f26.f64 - ctx.f25.f64)));
	// lfs f21,2708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2708);
	ctx.f21.f64 = double(temp.f32);
	// lfs f25,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f21,f21,f11
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// fnmsubs f4,f24,f25,f4
	ctx.f4.f64 = double(float(-(ctx.f24.f64 * ctx.f25.f64 - ctx.f4.f64)));
	// lfs f24,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f5,f20,f5,f3
	ctx.f5.f64 = double(float(-(ctx.f20.f64 * ctx.f5.f64 - ctx.f3.f64)));
	// lfs f3,3516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3516);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f21,f21,f24,f4
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f24.f64 + ctx.f4.f64));
	// lfs f4,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f5,f27,f10,f5
	ctx.f5.f64 = double(float(-(ctx.f27.f64 * ctx.f10.f64 - ctx.f5.f64)));
	// fnmsubs f5,f19,f4,f5
	ctx.f5.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f5.f64)));
	// fmadds f5,f23,f10,f5
	ctx.f5.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 + ctx.f5.f64));
	// fnmsubs f4,f18,f10,f5
	ctx.f4.f64 = double(float(-(ctx.f18.f64 * ctx.f10.f64 - ctx.f5.f64)));
	// lfs f5,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f4,f16,f5,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f5.f64 - ctx.f4.f64)));
	// fmadds f4,f14,f5,f4
	ctx.f4.f64 = double(float(ctx.f14.f64 * ctx.f5.f64 + ctx.f4.f64));
	// fnmsubs f4,f17,f10,f4
	ctx.f4.f64 = double(float(-(ctx.f17.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// fnmsubs f4,f22,f0,f4
	ctx.f4.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// fadds f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// stfs f4,4492(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4492, temp.u32);
	// lfs f4,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f23,f3,f4
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f1,2304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2304);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,2080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2080);
	ctx.f3.f64 = double(temp.f32);
	// fadds f22,f3,f1
	ctx.f22.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// lfs f1,2144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2144);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,1932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1932);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f3,f1
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f26,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f3,f30,f30
	ctx.f3.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// lfs f27,2996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2996);
	ctx.f27.f64 = double(temp.f32);
	// lfs f17,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f26,f2
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// lfs f16,1056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1056);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f19,f3,f26
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f26.f64));
	// lfs f3,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f3,f27
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f3,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f17,f3
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// lfs f3,2716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2716);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f23,f3,f4,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f4.f64 - ctx.f23.f64));
	// lfs f3,1240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1240);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f22,f22,f3,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f20.f64));
	// lfs f3,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f2,f3
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f3,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fmuls f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// lfs f16,4120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4120);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fmuls f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// lfs f15,2308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2308);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f25,f15,f25,f23
	ctx.f25.f64 = double(float(ctx.f15.f64 * ctx.f25.f64 + ctx.f23.f64));
	// lfs f15,3524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3524);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f22,f22,f5
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// lfs f23,2724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2724);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f15,f11
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// fmuls f23,f23,f11
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// fmadds f19,f19,f2,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f2.f64 + ctx.f18.f64));
	// lfs f2,2732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2732);
	ctx.f2.f64 = double(temp.f32);
	// lfs f18,3924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3924);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f2,f18
	ctx.f18.f64 = double(float(ctx.f2.f64 + ctx.f18.f64));
	// lfs f2,2740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2740);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f24,f2,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// lfs f2,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f21,f17,f2,f21
	ctx.f21.f64 = double(float(-(ctx.f17.f64 * ctx.f2.f64 - ctx.f21.f64)));
	// fmuls f2,f28,f28
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// fmadds f25,f25,f11,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 + ctx.f22.f64));
	// fmadds f20,f20,f5,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f5.f64 + ctx.f16.f64));
	// fnmsubs f22,f15,f7,f19
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f7.f64 - ctx.f19.f64)));
	// fmuls f19,f14,f3
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f3.f64));
	// fmadds f24,f18,f7,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f7.f64 + ctx.f24.f64));
	// lfs f18,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// lfs f26,3532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3532);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f25,f23,f18,f25
	ctx.f25.f64 = double(float(-(ctx.f23.f64 * ctx.f18.f64 - ctx.f25.f64)));
	// lfs f18,1040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1040);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f26,f26,f11
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// fmadds f23,f20,f11,f21
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f11.f64 + ctx.f21.f64));
	// fnmsubs f22,f19,f7,f22
	ctx.f22.f64 = double(float(-(ctx.f19.f64 * ctx.f7.f64 - ctx.f22.f64)));
	// lfs f19,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f21,f2,f3
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f2,2748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2748);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f20,f2,f11
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lfs f2,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f19,f19,f2
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f2.f64));
	// lfs f2,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f26,f26,f2,f25
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// lfs f25,4264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4264);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f25,f25,f4,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f4.f64 + ctx.f24.f64));
	// lfs f24,2756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2756);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f11
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// fmadds f23,f21,f18,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f18.f64 + ctx.f23.f64));
	// lfs f21,1952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1952);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,2320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2320);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f21,f21,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64));
	// fmuls f1,f18,f1
	ctx.f1.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// fmadds f26,f20,f4,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f4.f64 + ctx.f26.f64));
	// lfs f20,2764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2764);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f25,f25,f11,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 + ctx.f22.f64));
	// lfs f22,3540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3540);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmuls f20,f20,f11
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// fnmsubs f23,f19,f5,f23
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f5.f64 - ctx.f23.f64)));
	// lfs f19,1944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1944);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f26,f24,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f24.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// lfs f24,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f1,f1,f5,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64 + ctx.f23.f64));
	// lfs f23,1864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1864);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f25,f21,f5,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f5.f64 - ctx.f25.f64)));
	// lfs f21,892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 892);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f19,f27
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f27.f64));
	// lfs f16,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// lfs f24,884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// lfs f17,1140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1140);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// lfs f18,1896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1896);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// lfs f14,2272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2272);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,1092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1092);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f18,f18,f11
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// fnmsubs f26,f22,f7,f26
	ctx.f26.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// lfs f22,2316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2316);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmadds f2,f20,f2,f25
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f2.f64 + ctx.f25.f64));
	// lfs f25,3932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3932);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f4
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// lfs f20,1760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1760);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f4,f27,f4
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fmuls f27,f24,f30
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// fmuls f20,f20,f11
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// fmuls f24,f23,f30
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// lfs f23,2324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2324);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fadds f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// lfs f26,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f31
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fmadds f2,f19,f5,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 * ctx.f5.f64 + ctx.f2.f64));
	// lfs f19,1832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1832);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// fmuls f27,f27,f10
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// fmuls f26,f26,f30
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// fadds f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fmsubs f27,f24,f10,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f27.f64));
	// fmadds f26,f26,f0,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f25.f64));
	// fmuls f25,f21,f31
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f31.f64));
	// lfs f21,1768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1768);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// fmsubs f26,f26,f11,f4
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f11.f64 - ctx.f4.f64));
	// lfs f4,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// stfs f4,1512(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1512, temp.u32);
	// fmuls f24,f21,f30
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// fmadds f27,f25,f0,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f27.f64));
	// fmuls f16,f4,f16
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f16.f64));
	// lfs f4,900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 900);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f21,f6,f4
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// lfs f4,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f26,f22,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f22.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// lfs f4,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// lfs f22,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f27,f23,f5,f27
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f5.f64 - ctx.f27.f64)));
	// lfs f23,2356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2356);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// fnmsubs f26,f20,f7,f26
	ctx.f26.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// lfs f20,2348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2348);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f22,f4,f22
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f22.f64));
	// lfs f4,2332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2332);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f15,f4,f11
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// lfs f4,2340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2340);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f25,f4,f11
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// lfs f4,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f14,f14,f4
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f4.f64));
	// fmuls f20,f20,f11
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// fmadds f1,f19,f7,f26
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 + ctx.f26.f64));
	// lfs f26,1268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1268);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f22,f21,f31,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f31.f64 + ctx.f22.f64));
	// lfs f21,1776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1776);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// fmuls f26,f6,f26
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// fmadds f27,f24,f10,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f27.f64));
	// lfs f24,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// stfs f24,1760(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1760, temp.u32);
	// lfs f24,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f1,f18,f7,f1
	ctx.f1.f64 = double(float(-(ctx.f18.f64 * ctx.f7.f64 - ctx.f1.f64)));
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// stfs f24,1864(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1864, temp.u32);
	// fmuls f24,f23,f31
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f31.f64));
	// lfs f23,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f23,1896(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1896, temp.u32);
	// lfs f23,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f23,1776(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1776, temp.u32);
	// lfs f23,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f23.f64 = double(temp.f32);
	// stfs f2,628(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// fmr f2,f23
	ctx.f2.f64 = ctx.f23.f64;
	// stfs f26,1832(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1832, temp.u32);
	// fmuls f26,f21,f30
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// lfs f21,1124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1124);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// stfs f21,1768(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1768, temp.u32);
	// fnmsubs f27,f16,f2,f27
	ctx.f27.f64 = double(float(-(ctx.f16.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// fnmsubs f2,f17,f2,f1
	ctx.f2.f64 = double(float(-(ctx.f17.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// lfs f1,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f27,f22,f0,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 + ctx.f27.f64));
	// fmadds f23,f15,f1,f2
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f1.f64 + ctx.f2.f64));
	// lfs f2,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f27,f14,f2,f27
	ctx.f27.f64 = double(float(-(ctx.f14.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// fnmsubs f1,f25,f1,f23
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f1.f64 - ctx.f23.f64)));
	// lfs f25,1092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1092);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f27,f26,f10,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f10.f64 - ctx.f27.f64)));
	// lfs f26,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f1,f20,f26,f1
	ctx.f1.f64 = double(float(-(ctx.f20.f64 * ctx.f26.f64 - ctx.f1.f64)));
	// lfs f26,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f24,f24,f26,f27
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f26.f64 - ctx.f27.f64)));
	// lfs f27,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f27.f64 = double(temp.f32);
	// fadds f1,f27,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// stfs f1,4496(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4496, temp.u32);
	// lfs f1,1772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1772);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f1,f4
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// lfs f1,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// lfs f27,1228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1228);
	ctx.f27.f64 = double(temp.f32);
	// stfs f1,328(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fmuls f23,f27,f1
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// lfs f1,3668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3668);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f1,f25
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// lfs f1,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmuls f21,f27,f1
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// lfs f1,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// lfs f27,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f1,f27
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// lfs f1,2796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2796);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f1,f5
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// lfs f1,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f18,f1,f4
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// lfs f1,3940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3940);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f27,f26,f2
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// lfs f26,3564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3564);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f6,f1
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,2804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2804);
	ctx.f1.f64 = double(temp.f32);
	// fadds f16,f1,f26
	ctx.f16.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// lfs f1,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// lfs f26,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f26.f64 = double(temp.f32);
	// stfs f1,1312(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1312, temp.u32);
	// fmuls f15,f1,f26
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// lfs f26,1332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1332);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f26,f4
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// lfs f26,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f23,f23,f26,f27
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 - ctx.f27.f64));
	// lfs f27,2812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2812);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f19,f27,f5,f19
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 - ctx.f19.f64));
	// lfs f27,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// lfs f25,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f17,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// lfs f17,4208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4208);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f16,f6,f1
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fnmsubs f23,f22,f2,f23
	ctx.f23.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f23.f64)));
	// fmuls f22,f19,f6
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f6.f64));
	// lfs f19,1836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1836);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f26,f15,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f26.f64));
	// lfs f15,2364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2364);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f19,f1,f19
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// fmuls f1,f6,f28
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// stfs f1,1284(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1284, temp.u32);
	// fmsubs f25,f22,f30,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f30.f64 - ctx.f25.f64));
	// lfs f22,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f23,f21,f0,f23
	ctx.f23.f64 = double(float(-(ctx.f21.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// lfs f21,2820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2820);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// fmadds f22,f16,f22,f19
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f22.f64 + ctx.f19.f64));
	// lfs f19,3572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3572);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f1.f64));
	// lfs f15,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f26,f17,f15,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 + ctx.f26.f64));
	// lfs f16,1840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1840);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f19,f6,f19
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// lfs f17,2152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2152);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f23,f20,f0,f23
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// lfs f20,2168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2168);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f6,f17
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// lfs f15,2372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2372);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f6,f15
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f15.f64));
	// fmuls f16,f6,f16
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f16.f64));
	// fmadds f26,f26,f6,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f6.f64 + ctx.f25.f64));
	// fmuls f25,f19,f30
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// lfs f19,1092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1092);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64));
	// lfs f19,-30040(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30040);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,1840(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1840, temp.u32);
	// fmadds f23,f18,f0,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f23.f64));
	// fmuls f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// lfs f18,2836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2836);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f19,f15,f31
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// lfs f15,1780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1780);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f4,f15,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// fmuls f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// fmadds f1,f1,f10,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f26.f64));
	// lfs f26,3948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3948);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f6,f26
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// fnmsubs f23,f14,f0,f23
	ctx.f23.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// fmadds f24,f17,f2,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 + ctx.f24.f64));
	// lfs f17,3580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3580);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f6,f17
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// fnmsubs f27,f27,f0,f23
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// lfs f23,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f27,f22,f0,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 + ctx.f27.f64));
	// lfs f15,1840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1840);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f24,f20,f15,f24
	ctx.f24.f64 = double(float(-(ctx.f20.f64 * ctx.f15.f64 - ctx.f24.f64)));
	// lfs f20,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f1,f16,f20,f1
	ctx.f1.f64 = double(float(-(ctx.f16.f64 * ctx.f20.f64 - ctx.f1.f64)));
	// fnmsubs f23,f19,f23,f1
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f23.f64 - ctx.f1.f64)));
	// lfs f1,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f27,f21,f1,f27
	ctx.f27.f64 = double(float(-(ctx.f21.f64 * ctx.f1.f64 - ctx.f27.f64)));
	// fnmsubs f26,f26,f1,f23
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f1.f64 - ctx.f23.f64)));
	// fmadds f5,f25,f5,f27
	ctx.f5.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 + ctx.f27.f64));
	// fmadds f26,f18,f12,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 + ctx.f26.f64));
	// fnmsubs f5,f4,f2,f5
	ctx.f5.f64 = double(float(-(ctx.f4.f64 * ctx.f2.f64 - ctx.f5.f64)));
	// lfs f4,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f4.f64 = double(temp.f32);
	// fadds f27,f24,f5
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f5.f64));
	// lfs f5,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f31,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f5.f64));
	// fmuls f25,f5,f4
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f5,2844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2844);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f24,f6,f5
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f6,4136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4136);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,2852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2852);
	ctx.f5.f64 = double(temp.f32);
	// fadds f23,f6,f5
	ctx.f23.f64 = double(float(ctx.f6.f64 + ctx.f5.f64));
	// lfs f4,1316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1316);
	ctx.f4.f64 = double(temp.f32);
	// lfs f6,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f22,f4,f6
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f24,f1
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// lfs f5,1228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1228);
	ctx.f5.f64 = double(temp.f32);
	// stfs f6,1072(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1072, temp.u32);
	// fnmsubs f1,f17,f1,f26
	ctx.f1.f64 = double(float(-(ctx.f17.f64 * ctx.f1.f64 - ctx.f26.f64)));
	// lfs f19,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,2380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2380);
	ctx.f18.f64 = double(temp.f32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// lfs f18,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f18,2860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2860);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f16.f64 = double(temp.f32);
	// lfs f26,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f26.f64 = double(temp.f32);
	// lfs f15,1864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1864);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,1896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1896);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f15,f30
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f30.f64));
	// fmuls f21,f5,f6
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f5,3596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3596);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f14,f14,f30
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f30.f64));
	// fmuls f20,f5,f6
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,3588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3588);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f19,f6,f19
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// lfs f6,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f25,f25,f6
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// fmuls f18,f18,f6
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f6.f64));
	// fmuls f6,f20,f3
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// fmuls f20,f19,f3
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// lfs f19,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f5,f5,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// fmadds f2,f25,f2,f24
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 + ctx.f24.f64));
	// lfs f24,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f24.f64));
	// lfs f25,1284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1284);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f25.f64));
	// lfs f22,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,1124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1124);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// lfs f22,1832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1832);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f30
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// fmuls f19,f5,f3
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f5,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f2,f21,f5,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 * ctx.f5.f64 + ctx.f2.f64));
	// lfs f5,1768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1768);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f5,f30
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f5,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f6,f6,f5,f24
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f5.f64 + ctx.f24.f64));
	// lfs f24,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f24,f16,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f16.f64 + ctx.f23.f64));
	// lfs f16,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f16.f64 = double(temp.f32);
	// lfs f23,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f23.f64));
	// lfs f16,1760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1760);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// fmsubs f2,f25,f10,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 - ctx.f2.f64));
	// lfs f25,908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 908);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f4
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// fmsubs f20,f20,f5,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f5.f64 - ctx.f6.f64));
	// lfs f6,2096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2096);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmuls f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// fmadds f2,f18,f0,f2
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f2.f64));
	// lfs f18,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f18.f64));
	// lfs f18,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f20,f19,f18,f20
	ctx.f20.f64 = double(float(-(ctx.f19.f64 * ctx.f18.f64 - ctx.f20.f64)));
	// lfs f18,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,1268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1268);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// lfs f6,1776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1776);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,628(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// fmr f6,f26
	ctx.f6.f64 = ctx.f26.f64;
	// lfs f26,2032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2032);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f4
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// fmadds f24,f24,f3,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 + ctx.f20.f64));
	// fnmsubs f2,f22,f6,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// lfs f22,1252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1252);
	ctx.f22.f64 = double(temp.f32);
	// fadds f1,f27,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fnmsubs f27,f21,f6,f2
	ctx.f27.f64 = double(float(-(ctx.f21.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// lfs f6,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f24,f23,f6,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f24.f64));
	// lfs f23,1472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1472);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f20,f18,f3
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// lfs f17,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f22,f22,f4
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f4.f64));
	// lfs f18,4248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4248);
	ctx.f18.f64 = double(temp.f32);
	// lfs f2,-29996(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29996);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f18,f18,f4
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f4.f64));
	// stfs f2,1252(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1252, temp.u32);
	// fnmsubs f27,f16,f2,f27
	ctx.f27.f64 = double(float(-(ctx.f16.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f16,2096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2096);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f25,f25,f6,f24
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f6.f64 - ctx.f24.f64)));
	// lfs f6,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f6.f64 = double(temp.f32);
	// lfs f24,2296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2296);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f27,f15,f5,f27
	ctx.f27.f64 = double(float(-(ctx.f15.f64 * ctx.f5.f64 - ctx.f27.f64)));
	// lfs f15,2216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2216);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f25,f19,f6,f25
	ctx.f25.f64 = double(float(-(ctx.f19.f64 * ctx.f6.f64 - ctx.f25.f64)));
	// lfs f19,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f5,f14,f5,f27
	ctx.f5.f64 = double(float(-(ctx.f14.f64 * ctx.f5.f64 - ctx.f27.f64)));
	// lfs f27,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f20,f27,f25
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f27.f64 + ctx.f25.f64));
	// lfs f25,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f5,f25,f2,f5
	ctx.f5.f64 = double(float(-(ctx.f25.f64 * ctx.f2.f64 - ctx.f5.f64)));
	// lfs f2,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f27,f26,f2,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f26,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,2040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2040);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// lfs f24,2048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2048);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f23,2876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2876);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// fadds f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// stfs f5,4500(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4500, temp.u32);
	// lfs f5,3956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3956);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f27,f22,f2,f27
	ctx.f27.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f1,2868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2868);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// lfs f5,3596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3596);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f26,f5,f26
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f22,3604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3604);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// fmuls f21,f1,f12
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f1,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f26,f3
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// fmuls f20,f1,f4
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// fmuls f19,f19,f1
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// fmadds f25,f25,f17,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f17.f64 + ctx.f21.f64));
	// lfs f21,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f5,f5,f21
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f21.f64));
	// lfs f17,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f26,f26,f12
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lfs f21,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// lfs f16,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f21.f64));
	// lfs f20,2884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2884);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f4
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f4.f64));
	// fmuls f19,f19,f4
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// fmadds f25,f22,f16,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f16.f64 + ctx.f25.f64));
	// lfs f22,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f16,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f26,f24,f22,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f22.f64 - ctx.f26.f64));
	// lfs f22,3964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3964);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// lfs f16,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f24,2892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2892);
	ctx.f24.f64 = double(temp.f32);
	// lfs f16,2900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2900);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f24,f24,f4
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f4.f64));
	// fmuls f16,f16,f4
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// fmadds f27,f5,f12,f27
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 + ctx.f27.f64));
	// lfs f5,2964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2964);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f26,f25,f4,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f4.f64 + ctx.f26.f64));
	// lfs f25,3264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3264);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f5
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f5.f64));
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f1,f1,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f14.f64));
	// lfs f14,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f22,f22,f14,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f14.f64 + ctx.f17.f64));
	// lfs f17,2056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2056);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// lfs f2,3612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3612);
	ctx.f2.f64 = double(temp.f32);
	// lfs f14,1784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1784);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f26,f23,f12,f26
	ctx.f26.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f26.f64)));
	// fmuls f14,f2,f14
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// lfs f2,3400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3400);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f23,f2,f5
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// lfs f2,-30044(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30044);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,480(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// fnmsubs f27,f16,f12,f27
	ctx.f27.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f27.f64)));
	// fmuls f2,f25,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// lfs f16,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f15,f4
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// lfs f25,3312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3312);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f16.f64));
	// lfs f16,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f16.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f17,f1,f16,f17
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f16.f64 + ctx.f17.f64));
	// lfs f1,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f1.f64 = double(temp.f32);
	// lfs f16,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f26,f21,f6,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 + ctx.f26.f64));
	// fmuls f16,f1,f16
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f16.f64));
	// lfs f1,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f1.f64 = double(temp.f32);
	// lfs f21,3360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3360);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// fnmsubs f27,f15,f1,f27
	ctx.f27.f64 = double(float(-(ctx.f15.f64 * ctx.f1.f64 - ctx.f27.f64)));
	// lfs f1,-30048(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30048);
	ctx.f1.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f1,644(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 644, temp.u32);
	// fnmsubs f26,f19,f6,f26
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f6.f64 - ctx.f26.f64)));
	// fmadds f4,f17,f4,f27
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 + ctx.f27.f64));
	// lfs f15,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f23,f23,f15,f2
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f15.f64 - ctx.f2.f64));
	// lfs f2,1968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1968);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f25,f2
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// lfs f2,-30052(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30052);
	ctx.f2.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f15,3328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3328);
	ctx.f15.f64 = double(temp.f32);
	// stfs f2,212(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fmuls f15,f15,f5
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// fmadds f27,f25,f1,f23
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f23.f64));
	// lfs f25,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f26,f18,f25,f26
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f25.f64 - ctx.f26.f64)));
	// fnmsubs f25,f21,f2,f27
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// fnmsubs f27,f20,f12,f26
	ctx.f27.f64 = double(float(-(ctx.f20.f64 * ctx.f12.f64 - ctx.f26.f64)));
	// lfs f26,3052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3052);
	ctx.f26.f64 = double(temp.f32);
	// lfs f20,1632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1632);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f27,f24,f6,f27
	ctx.f27.f64 = double(float(-(ctx.f24.f64 * ctx.f6.f64 - ctx.f27.f64)));
	// fmadds f3,f22,f3,f27
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f27.f64));
	// lfs f27,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f27.f64 = double(temp.f32);
	// lfs f22,1124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1124);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f3,f14,f27,f3
	ctx.f3.f64 = double(float(ctx.f14.f64 * ctx.f27.f64 + ctx.f3.f64));
	// fmadds f3,f16,f6,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 + ctx.f3.f64));
	// fadds f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// stfs f4,4504(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4504, temp.u32);
	// lfs f3,1872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1872);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f27,f3,f4
	ctx.f27.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f3,-30056(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30056);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f26,f26,f3
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// stfs f3,892(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 892, temp.u32);
	// lfs f3,3676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3676);
	ctx.f3.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f24,f3,f5
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f3,4004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4004);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f3,f5
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f3,-30060(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30060);
	ctx.f3.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f3,1872(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1872, temp.u32);
	// fmuls f22,f27,f22
	ctx.f22.f64 = double(float(ctx.f27.f64 * ctx.f22.f64));
	// lfs f27,3044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3044);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f21,f27,f4
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// lfs f27,-30064(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30064);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f26,f20,f2,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f2.f64 + ctx.f26.f64));
	// stfs f27,780(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 780, temp.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fnmsubs f25,f15,f2,f25
	ctx.f25.f64 = double(float(-(ctx.f15.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// fmuls f22,f22,f27
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f27.f64));
	// lfs f19,1688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1688);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f5
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f5.f64));
	// lfs f20,3684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3684);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f5
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f5.f64));
	// lfs f17,1640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1640);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f5
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f5.f64));
	// lfs f18,3392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3392);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,-30068(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30068);
	ctx.f16.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f16,900(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 900, temp.u32);
	// fmuls f18,f18,f5
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f5.f64));
	// lfs f16,1348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1348);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f4
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// lfs f15,-30072(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30072);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f1,f24,f1,f25
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f1.f64 + ctx.f25.f64));
	// stfs f15,908(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 908, temp.u32);
	// fmsubs f26,f26,f5,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f5.f64 - ctx.f22.f64));
	// lfs f25,4160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4160);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,1648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1648);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f25,f25,f4
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// fmuls f24,f24,f4
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f4.f64));
	// lfs f22,1680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1680);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f5
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// fmadds f1,f21,f27,f1
	ctx.f1.f64 = double(float(ctx.f21.f64 * ctx.f27.f64 + ctx.f1.f64));
	// lfs f27,3060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3060);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f21,f27,f4
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// lfs f27,1672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1672);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f27,f5
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// lfs f27,1656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1656);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f14,f27,f4
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fnmsubs f27,f23,f3,f26
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f3.f64 - ctx.f26.f64)));
	// lfs f23,3692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3692);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// lfs f26,3028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3028);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f5
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fnmsubs f1,f19,f2,f1
	ctx.f1.f64 = double(float(-(ctx.f19.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// lfs f19,916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 916);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f4,f19,f4
	ctx.f4.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// lfs f19,3272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3272);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f5
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f5.f64));
	// fnmsubs f3,f20,f3,f27
	ctx.f3.f64 = double(float(-(ctx.f20.f64 * ctx.f3.f64 - ctx.f27.f64)));
	// lfs f27,3336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3336);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f27,f5
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// lfs f27,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f1,f17,f2,f1
	ctx.f1.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 + ctx.f1.f64));
	// fmuls f17,f4,f27
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// lfs f4,1552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1552);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f3,f18,f2,f3
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f2.f64 + ctx.f3.f64));
	// lfs f2,1664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1664);
	ctx.f2.f64 = double(temp.f32);
	// lfs f18,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f2,f18
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// lfs f2,900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 900);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f2,f24,f2,f1
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// lfs f24,892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 892);
	ctx.f24.f64 = double(temp.f32);
	// lfs f1,3036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3036);
	ctx.f1.f64 = double(temp.f32);
	// lfs f27,908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 908);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f4,f4,f27
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// lfs f27,3376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3376);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f5
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// stfs f27,628(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// fmr f27,f24
	ctx.f27.f64 = ctx.f24.f64;
	// fmadds f24,f1,f27,f4
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f27.f64 + ctx.f4.f64));
	// lfs f4,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f1,f25,f4,f3
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f4.f64 - ctx.f3.f64)));
	// lfs f3,908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 908);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f2,f22,f3,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f2.f64));
	// lfs f3,900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 900);
	ctx.f3.f64 = double(temp.f32);
	// lfs f22,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f25,f16,f3,f1
	ctx.f25.f64 = double(float(-(ctx.f16.f64 * ctx.f3.f64 - ctx.f1.f64)));
	// lfs f1,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f2,f15,f1,f2
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f1.f64 - ctx.f2.f64)));
	// fmadds f25,f21,f4,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 + ctx.f25.f64));
	// fnmsubs f26,f26,f22,f2
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f22.f64 - ctx.f2.f64)));
	// lfs f2,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f25,f14,f3,f25
	ctx.f25.f64 = double(float(-(ctx.f14.f64 * ctx.f3.f64 - ctx.f25.f64)));
	// fmadds f26,f19,f2,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f2.f64 + ctx.f26.f64));
	// fnmsubs f4,f23,f4,f25
	ctx.f4.f64 = double(float(-(ctx.f23.f64 * ctx.f4.f64 - ctx.f25.f64)));
	// fnmsubs f2,f20,f2,f26
	ctx.f2.f64 = double(float(-(ctx.f20.f64 * ctx.f2.f64 - ctx.f26.f64)));
	// fmadds f4,f17,f27,f4
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f27.f64 + ctx.f4.f64));
	// lfs f25,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f26,f24,f5,f2
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 + ctx.f2.f64));
	// lfs f2,1868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1868);
	ctx.f2.f64 = double(temp.f32);
	// lfs f16,1496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1496);
	ctx.f16.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f16,f16,f6
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,1704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1704);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f4,f25,f1,f4
	ctx.f4.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f4.f64));
	// lfs f1,2088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2088);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f25,f18,f3,f4
	ctx.f25.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f4.f64)));
	// lfs f4,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f27,f1,f4
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// lfs f4,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// lfs f3,2232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2232);
	ctx.f3.f64 = double(temp.f32);
	// stfs f4,1876(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1876, temp.u32);
	// fmuls f24,f4,f3
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f4,1248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1248);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,1860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1860);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f3,f4
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f3,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// lfs f4,2312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2312);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f22,f2,f4
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// lfs f4,1792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1792);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f24,f27,f31,f24
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f31.f64 + ctx.f24.f64));
	// lfs f27,1148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1148);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f27,f31
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// lfs f27,-30076(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30076);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,1148(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1148, temp.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f21,f4,f3
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,2060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2060);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f3,f4
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f3,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f28,f3
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f3.f64));
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmuls f19,f1,f3
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f3,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f3.f64 = double(temp.f32);
	// lfs f1,1480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1480);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f15,f3
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// fmuls f18,f1,f3
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f1,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f22,f1
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fmuls f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f14.f64));
	// lfs f14,3700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3700);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f3
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f3.f64));
	// fmadds f22,f20,f6,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 + ctx.f22.f64));
	// fmadds f20,f17,f27,f16
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f27.f64 + ctx.f16.f64));
	// lfs f27,3084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3084);
	ctx.f27.f64 = double(temp.f32);
	// lfs f17,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f27,f17
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f17.f64));
	// lfs f27,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f16,f4,f27
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// lfs f27,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// lfs f4,-29916(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29916);
	ctx.f4.f64 = double(temp.f32);
	// fmsubs f24,f23,f4,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 - ctx.f24.f64));
	// stfs f4,776(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 776, temp.u32);
	// fnmsubs f23,f19,f1,f22
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f1.f64 - ctx.f22.f64)));
	// lfs f19,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f2,f19
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f19.f64));
	// lfs f22,1524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1524);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f6,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 + ctx.f17.f64));
	// lfs f17,1216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1216);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f27,f27,f6
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fnmsubs f24,f21,f4,f24
	ctx.f24.f64 = double(float(-(ctx.f21.f64 * ctx.f4.f64 - ctx.f24.f64)));
	// lfs f21,4224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4224);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f23,f20,f3,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f3.f64 + ctx.f23.f64));
	// lfs f20,1696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1696);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// fmuls f20,f20,f3
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// fmuls f19,f19,f31
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f31.f64));
	// fmadds f27,f17,f1,f27
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f1.f64 + ctx.f27.f64));
	// lfs f1,3068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3068);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f17,f1,f5
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmadds f1,f18,f6,f24
	ctx.f1.f64 = double(float(ctx.f18.f64 * ctx.f6.f64 + ctx.f24.f64));
	// lfs f24,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f25,f21,f24,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f24.f64 + ctx.f25.f64));
	// lfs f18,1844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1844);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f24,f16,f4,f23
	ctx.f24.f64 = double(float(-(ctx.f16.f64 * ctx.f4.f64 - ctx.f23.f64)));
	// lfs f23,1268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1268);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f16,f15,f6,f1
	ctx.f16.f64 = double(float(-(ctx.f15.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// lfs f1,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// lfs f15,1848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1848);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// lfs f5,1356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1356);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f5,f3
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f5,1860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1860);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f18,f5,f18
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f18.f64));
	// fmadds f27,f27,f5,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f24.f64));
	// lfs f24,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f1,f1,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f15.f64));
	// lfs f15,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f25,f17,f15,f25
	ctx.f25.f64 = double(float(-(ctx.f17.f64 * ctx.f15.f64 - ctx.f25.f64)));
	// lfs f17,4012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4012);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f24.f64));
	// lfs f23,1708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1708);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f17,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f23.f64));
	// lfs f17,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f17,f14,f17,f16
	ctx.f17.f64 = double(float(-(ctx.f14.f64 * ctx.f17.f64 - ctx.f16.f64)));
	// fnmsubs f27,f19,f6,f27
	ctx.f27.f64 = double(float(-(ctx.f19.f64 * ctx.f6.f64 - ctx.f27.f64)));
	// lfs f19,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f25,f24,f19,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f19.f64 - ctx.f25.f64)));
	// fmadds f24,f22,f3,f17
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f17.f64));
	// lfs f22,2232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2232);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f27,f18,f4,f27
	ctx.f27.f64 = double(float(-(ctx.f18.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// stfs f26,4508(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4508, temp.u32);
	// lfs f26,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f25,f20,f6,f24
	ctx.f25.f64 = double(float(-(ctx.f20.f64 * ctx.f6.f64 - ctx.f24.f64)));
	// fnmsubs f27,f23,f26,f27
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f26.f64 - ctx.f27.f64)));
	// lfs f23,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f25,f21,f6,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f6.f64 - ctx.f25.f64)));
	// fmadds f1,f1,f4,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f4.f64 + ctx.f25.f64));
	// fadds f24,f1,f27
	ctx.f24.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// lfs f1,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lfs f27,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f27.f64 = double(temp.f32);
	// stfs f1,1892(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1892, temp.u32);
	// fmuls f25,f1,f27
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// lfs f27,1792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1792);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f22,f1,f22
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f22.f64));
	// lfs f1,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmuls f23,f27,f23
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// fmuls f18,f25,f3
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// fmuls f22,f22,f6
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// fmuls f21,f2,f1
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f1,2068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2068);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f1,f27
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// lfs f1,3100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3100);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f1,f3
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f1,1660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f17,f1,f3
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f1,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmuls f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// fmsubs f22,f21,f6,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 - ctx.f22.f64));
	// lfs f21,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f2,f1
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f1,1328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1328);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f5,f1
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f14,f2,f1
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f1,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f25,f1,f31
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmadds f23,f18,f26,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f26.f64 + ctx.f23.f64));
	// fmuls f25,f25,f2
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// stfs f25,628(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// fmuls f25,f21,f31
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f31.f64));
	// fmadds f23,f20,f6,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 + ctx.f23.f64));
	// fmuls f21,f2,f25
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfs f25,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f18,f14,f25
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// lfs f25,1936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1936);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f14,f5,f25
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// lfs f25,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f22,f19,f25,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f25.f64 + ctx.f22.f64));
	// lfs f25,1976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1976);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f20,f25,f2
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// lfs f25,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f30
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f30.f64));
	// fmadds f26,f16,f26,f22
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f26.f64 + ctx.f22.f64));
	// lfs f22,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f22.f64 = double(temp.f32);
	// lfs f16,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f25,f5,f25,f21
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f25.f64 + ctx.f21.f64));
	// lfs f5,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// lfs f21,1948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1948);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f5.f64));
	// lfs f5,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// stfs f5,2280(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2280, temp.u32);
	// fmuls f2,f2,f5
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f5,f1,f28
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmadds f1,f17,f6,f23
	ctx.f1.f64 = double(float(ctx.f17.f64 * ctx.f6.f64 + ctx.f23.f64));
	// lfs f17,812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 812);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f19,f27,f5
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// lfs f5,1488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1488);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f27,f27,f17
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f17.f64));
	// lfs f17,1848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1848);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f2,f21,f17,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 * ctx.f17.f64 + ctx.f2.f64));
	// lfs f21,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f23,f5,f3
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f5,1136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1136);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f1,f15,f21,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f21.f64 - ctx.f1.f64));
	// lfs f21,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f22,f22,f5
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// lfs f17,2240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2240);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f26,f21,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// lfs f21,3076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3076);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// lfs f15,1888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1888);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f3,f17,f3
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// lfs f17,1800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1800);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// lfs f16,2016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2016);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// lfs f15,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f18,f18,f15,f1
	ctx.f18.f64 = double(float(-(ctx.f18.f64 * ctx.f15.f64 - ctx.f1.f64)));
	// lfs f1,3716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3716);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f26,f25,f6,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f26.f64));
	// lfs f25,4168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4168);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fadds f15,f25,f1
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f1.f64));
	// lfs f1,-29836(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + -29836);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f25,f31,f31
	ctx.f25.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// stfs f1,516(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// fmuls f22,f22,f1
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fmadds f18,f14,f4,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f4.f64 + ctx.f18.f64));
	// fnmsubs f26,f20,f6,f26
	ctx.f26.f64 = double(float(-(ctx.f20.f64 * ctx.f6.f64 - ctx.f26.f64)));
	// fmuls f20,f15,f5
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// fmuls f17,f17,f25
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// fnmsubs f19,f19,f4,f18
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f18.f64)));
	// fmadds f26,f2,f4,f26
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f4.f64 + ctx.f26.f64));
	// lfs f2,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f22,f17,f6,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f6.f64 - ctx.f22.f64));
	// fmadds f23,f23,f6,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f19.f64));
	// fmadds f27,f27,f6,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f6.f64 + ctx.f26.f64));
	// lfs f26,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f22,f16,f2,f22
	ctx.f22.f64 = double(float(-(ctx.f16.f64 * ctx.f2.f64 - ctx.f22.f64)));
	// fnmsubs f26,f21,f26,f23
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f26.f64 - ctx.f23.f64)));
	// lfs f21,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f21.f64 = double(temp.f32);
	// fadds f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// lfs f24,1148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1148);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f3,f3,f24,f26
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f24.f64 - ctx.f26.f64)));
	// lfs f26,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f26.f64 = double(temp.f32);
	// fadds f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// stfs f3,4512(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4512, temp.u32);
	// fmuls f3,f31,f28
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// lfs f27,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f3,f27
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// fmuls f27,f28,f28
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// fmuls f23,f26,f27
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// lfs f26,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f21,f26,f21
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// fmuls f26,f30,f30
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// lfs f19,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f22,f20,f2,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f2.f64 + ctx.f22.f64));
	// lfs f20,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,3140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3140);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f21,f3,f20,f21
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f20.f64 + ctx.f21.f64));
	// lfs f18,4036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4036);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f24,f24,f1
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f3,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f23,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f15,2120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2120);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,3172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3172);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f19,f19,f26
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f26.f64));
	// fnmsubs f23,f23,f3,f22
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f3.f64 - ctx.f22.f64)));
	// lfs f22,3188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3188);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f5
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// fmuls f20,f19,f3
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// lfs f19,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64));
	// lfs f19,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f25
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f25.f64));
	// lfs f25,-29828(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + -29828);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f24,f18,f25,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f25.f64 + ctx.f24.f64));
	// lfs f18,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f18.f64 = double(temp.f32);
	// stfs f25,1216(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1216, temp.u32);
	// fmsubs f21,f21,f1,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 - ctx.f20.f64));
	// lfs f20,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// lfs f18,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f26,f27
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f26.f64 + ctx.f27.f64));
	// lfs f27,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,4176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4176);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f19,f19,f27,f24
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f24.f64));
	// fmuls f17,f26,f27
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// lfs f24,1020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1020);
	ctx.f24.f64 = double(temp.f32);
	// lfs f26,2064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2064);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// lfs f26,-29832(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29832);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f22,f22,f26,f23
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f26.f64 - ctx.f23.f64)));
	// lfs f23,1888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1888);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f15.f64));
	// stfs f26,884(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 884, temp.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f21,f14,f27,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f27.f64 + ctx.f21.f64));
	// fmuls f20,f20,f5
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f5.f64));
	// fmadds f18,f18,f3,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64 + ctx.f17.f64));
	// lfs f3,3748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3748);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f19,f3,f2,f19
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f2.f64 + ctx.f19.f64));
	// lfs f3,3148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3148);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f16,f2
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// fmuls f16,f3,f5
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f3,3156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3156);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f22,f15,f2,f22
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f2.f64 - ctx.f22.f64)));
	// fmuls f15,f3,f26
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f26.f64));
	// lfs f3,2100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2100);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// lfs f26,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f20,f20,f1
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f1.f64));
	// fmadds f19,f19,f5,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f5.f64 + ctx.f17.f64));
	// lfs f17,3708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3708);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f22,f16,f27,f22
	ctx.f22.f64 = double(float(-(ctx.f16.f64 * ctx.f27.f64 - ctx.f22.f64)));
	// lfs f16,3108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3108);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f17,f2,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 + ctx.f15.f64));
	// lfs f15,1232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1232);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f21,f3,f1,f21
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f1.f64 + ctx.f21.f64));
	// lfs f3,3180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3180);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f18,f3,f2,f18
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f2.f64 + ctx.f18.f64));
	// lfs f3,2000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2000);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f26,f3
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// lfs f3,-30080(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30080);
	ctx.f3.f64 = double(temp.f32);
	// stfs f3,1800(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1800, temp.u32);
	// fmuls f24,f15,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f24.f64));
	// fmsubs f21,f21,f5,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64 - ctx.f20.f64));
	// lfs f20,3164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3164);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f18,f16,f1,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f18.f64));
	// lfs f16,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f5,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// fmuls f16,f26,f16
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// fmsubs f19,f14,f3,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f3.f64 - ctx.f19.f64));
	// fnmsubs f25,f20,f25,f19
	ctx.f25.f64 = double(float(-(ctx.f20.f64 * ctx.f25.f64 - ctx.f19.f64)));
	// lfs f19,1964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1964);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f18,f5,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f5.f64 + ctx.f21.f64));
	// lfs f15,3732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3732);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f22,f17,f5,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f5.f64 + ctx.f22.f64));
	// lfs f14,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,4256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4256);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f5
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f5.f64));
	// fmadds f25,f16,f3,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 + ctx.f25.f64));
	// lfs f3,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f26,f26,f3
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// lfs f3,1960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1960);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfs f3,3132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3132);
	ctx.f3.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f16,3116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3116);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f21,f3,f5
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f3,1096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1096);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f3,f6
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f3,f19
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// lfs f3,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f3.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f15,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f18,f3,f18
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// stfs f18,1232(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1232, temp.u32);
	// lfs f18,4028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4028);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f5
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f5.f64));
	// fmuls f26,f26,f2
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// fnmsubs f25,f24,f2,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// fmadds f20,f15,f14,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f14.f64 + ctx.f20.f64));
	// lfs f15,1808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1808);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64));
	// lfs f19,1828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1828);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f15.f64));
	// lfs f15,1852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1852);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,4020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4020);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f16,f16,f5
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f5.f64));
	// fmuls f14,f14,f5
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f5.f64));
	// fmsubs f26,f23,f2,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 - ctx.f26.f64));
	// lfs f23,3196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3196);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// fmadds f27,f20,f15,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f15.f64 + ctx.f27.f64));
	// lfs f20,1380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1380);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f3,f20
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// lfs f15,884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f26,f21,f15,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f15.f64 + ctx.f26.f64));
	// lfs f21,3740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3740);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// fmuls f15,f15,f5
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// lfs f5,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f19,f19,f4,f27
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// lfs f27,1964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1964);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f20,f5,f27,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f27.f64 + ctx.f20.f64));
	// lfs f5,1216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1216);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f26,f18,f5,f26
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f5.f64 - ctx.f26.f64)));
	// lfs f5,3124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3124);
	ctx.f5.f64 = double(temp.f32);
	// lfs f18,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f5,f18
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f18.f64));
	// lfs f5,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f24,f15,f5
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// lfs f5,1260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1260);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f28
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// lfs f15,1852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1852);
	ctx.f15.f64 = double(temp.f32);
	// stfs f5,1848(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1848, temp.u32);
	// fnmsubs f25,f24,f1,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f1.f64 - ctx.f25.f64)));
	// lfs f1,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f5,f15
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f15.f64));
	// lfs f5,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f23,f23,f5,f19
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f5.f64 - ctx.f19.f64)));
	// lfs f5,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f26,f17,f5,f26
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f5.f64 - ctx.f26.f64)));
	// lfs f17,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,3724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3724);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f17,2072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2072);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f27
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f27.f64));
	// fmadds f24,f20,f6,f23
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 + ctx.f23.f64));
	// lfs f23,1232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1232);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f20,f16,f5,f26
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f5.f64 + ctx.f26.f64));
	// lfs f5,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f28
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// lfs f26,1852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1852);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f23,f1
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f1.f64));
	// lfs f1,1808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1808);
	ctx.f1.f64 = double(temp.f32);
	// fadds f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// lfs f22,1152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1152);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f26
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f26.f64));
	// lfs f16,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f1
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f1.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f5,f5,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f26,1148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1148);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f23,f26,f24
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 + ctx.f24.f64));
	// lfs f23,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f24,f21,f2,f20
	ctx.f24.f64 = double(float(-(ctx.f21.f64 * ctx.f2.f64 - ctx.f20.f64)));
	// fmadds f5,f23,f27,f5
	ctx.f5.f64 = double(float(ctx.f23.f64 * ctx.f27.f64 + ctx.f5.f64));
	// lfs f23,884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f26,f15,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f15.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// lfs f15,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f24,f14,f23,f24
	ctx.f24.f64 = double(float(-(ctx.f14.f64 * ctx.f23.f64 - ctx.f24.f64)));
	// lfs f23,1184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1184);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f23,f1,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f5.f64));
	// fnmsubs f5,f17,f4,f26
	ctx.f5.f64 = double(float(-(ctx.f17.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// lfs f17,3236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3236);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f26,f18,f12,f24
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f24.f64)));
	// fmadds f24,f16,f6,f5
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 + ctx.f5.f64));
	// lfs f16,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f5,f19,f12,f26
	ctx.f5.f64 = double(float(-(ctx.f19.f64 * ctx.f12.f64 - ctx.f26.f64)));
	// lfs f26,1464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1464);
	ctx.f26.f64 = double(temp.f32);
	// fadds f5,f25,f5
	ctx.f5.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// stfs f5,4516(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4516, temp.u32);
	// lfs f5,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f26,f5
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// lfs f5,1908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1908);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f20,f5,f1
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f26,1420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1420);
	ctx.f26.f64 = double(temp.f32);
	// lfs f5,1388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1388);
	ctx.f5.f64 = double(temp.f32);
	// fadds f19,f26,f5
	ctx.f19.f64 = double(float(ctx.f26.f64 + ctx.f5.f64));
	// lfs f26,-30084(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30084);
	ctx.f26.f64 = double(temp.f32);
	// lfs f5,4064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4064);
	ctx.f5.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f18,f5,f26
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f5,1988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1988);
	ctx.f5.f64 = double(temp.f32);
	// lfs f25,1276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1276);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f5,f25
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// stfs f25,1888(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1888, temp.u32);
	// stfs f26,488(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// lfs f25,-30088(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30088);
	ctx.f25.f64 = double(temp.f32);
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// stfs f25,1020(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1020, temp.u32);
	// fmuls f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f25.f64));
	// fmuls f21,f20,f4
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f4.f64));
	// lfs f20,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f27.f64));
	// lfs f20,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f5,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// stfs f20,1808(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1808, temp.u32);
	// lfs f20,2004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2004);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f18,f17,f16,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f18.f64));
	// lfs f16,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f20,f1
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f1.f64));
	// lfs f17,1628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1628);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f5,f17
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f17.f64));
	// fmadds f25,f19,f16,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 + ctx.f25.f64));
	// lfs f19,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f22,f22,f19,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 - ctx.f21.f64));
	// lfs f21,2128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2128);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64));
	// lfs f19,1540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1540);
	ctx.f19.f64 = double(temp.f32);
	// lfs f1,1412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1412);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f19,f1
	ctx.f1.f64 = double(float(ctx.f19.f64 + ctx.f1.f64));
	// lfs f16,1684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1684);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,3440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3440);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f5,f19
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// fmadds f25,f16,f15,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 + ctx.f25.f64));
	// fmadds f23,f23,f6,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f22.f64));
	// lfs f22,3220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3220);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f26
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f26.f64));
	// lfs f26,-4324(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4324);
	ctx.f26.f64 = double(temp.f32);
	// lfs f16,1788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1788);
	ctx.f16.f64 = double(temp.f32);
	// lis r11,-32244
	ctx.r11.s64 = -2113142784;
	// lfs f14,1668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1668);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f16,f16,f26
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f26.f64));
	// fadds f14,f1,f14
	ctx.f14.f64 = double(float(ctx.f1.f64 + ctx.f14.f64));
	// lfs f1,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f27,f27,f1,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f23.f64));
	// lfs f1,3204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3204);
	ctx.f1.f64 = double(temp.f32);
	// lfs f23,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f25,f25,f5
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f5.f64));
	// fmadds f23,f1,f23,f22
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f23.f64 + ctx.f22.f64));
	// lfs f1,31108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 31108);
	ctx.f1.f64 = double(temp.f32);
	// lfs f22,3448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3448);
	ctx.f22.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f1,1784(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1784, temp.u32);
	// lfs f15,3756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3756);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f3,f15
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f15.f64));
	// fmsubs f22,f22,f1,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f1.f64 - ctx.f16.f64));
	// lfs f1,1396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1396);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f5,f1
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f20,f20,f4,f27
	ctx.f20.f64 = double(float(-(ctx.f20.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// lfs f27,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1148(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1148, temp.u32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// stfs f27,1792(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1792, temp.u32);
	// fmsubs f25,f18,f5,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f5.f64 - ctx.f25.f64));
	// fmuls f14,f14,f3
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f3.f64));
	// fnmsubs f21,f21,f4,f20
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f4.f64 - ctx.f20.f64)));
	// fadds f27,f27,f1
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// lfs f1,3764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3764);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f18,f5,f1
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,3780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3780);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f26,f1,f26,f22
	ctx.f26.f64 = double(float(-(ctx.f1.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// lfs f1,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f16,f1
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f1.f64));
	// lfs f1,1068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1068);
	ctx.f1.f64 = double(temp.f32);
	// lfs f16,1888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1888);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f1
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f1.f64));
	// lfs f1,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f25,f17,f1,f25
	ctx.f25.f64 = double(float(-(ctx.f17.f64 * ctx.f1.f64 - ctx.f25.f64)));
	// lfs f1,1548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1548);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f5,f1
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f1.f64 = double(temp.f32);
	// lfs f17,1808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1808);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f1
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f1.f64));
	// lfs f1,-30232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30232);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,2220(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2220, temp.u32);
	// fmadds f27,f27,f1,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f26.f64));
	// lfs f26,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f26.f64 = double(temp.f32);
	// lfs f1,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f22,f18,f1,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f1.f64 - ctx.f22.f64));
	// fnmsubs f25,f19,f26,f25
	ctx.f25.f64 = double(float(-(ctx.f19.f64 * ctx.f26.f64 - ctx.f25.f64)));
	// lfs f19,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f21,f15,f19,f21
	ctx.f21.f64 = double(float(-(ctx.f15.f64 * ctx.f19.f64 - ctx.f21.f64)));
	// lfs f19,4044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4044);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f1
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// lfs f1,1464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1464);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f1,f31,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64 + ctx.f27.f64));
	// stfs f1,4528(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4528, temp.u32);
	// lfs f1,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f22,f20,f1,f22
	ctx.f22.f64 = double(float(-(ctx.f20.f64 * ctx.f1.f64 - ctx.f22.f64)));
	// lfs f1,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f27,f23,f5,f25
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f25.f64));
	// fmadds f25,f14,f6,f21
	ctx.f25.f64 = double(float(ctx.f14.f64 * ctx.f6.f64 + ctx.f21.f64));
	// fnmsubs f27,f16,f1,f27
	ctx.f27.f64 = double(float(-(ctx.f16.f64 * ctx.f1.f64 - ctx.f27.f64)));
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfs f25,4520(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4520, temp.u32);
	// fnmsubs f1,f17,f1,f27
	ctx.f1.f64 = double(float(-(ctx.f17.f64 * ctx.f1.f64 - ctx.f27.f64)));
	// stfs f1,4524(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4524, temp.u32);
	// lfs f1,1208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1208);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f27,f1,f31
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// lfs f1,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fadds f27,f1,f27
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// lfs f1,1468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1468);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmuls f25,f3,f1
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f1,1112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmuls f27,f27,f3
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// lfs f18,3212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3212);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f25,f25,f12
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f17,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f18,f17,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f19.f64));
	// lfs f17,3456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3456);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f1,f3,f1
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f16,1404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1404);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f5,f17
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f17.f64));
	// lfs f15,1808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1808);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f5,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f16.f64));
	// lfs f24,3276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3276);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f3,f24
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// lfs f23,3772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3772);
	ctx.f23.f64 = double(temp.f32);
	// lfs f21,1436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1436);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfs f20,1572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1572);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f3,f21
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f21.f64));
	// lfs f18,1700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1700);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f20,f3,f20
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// fmuls f18,f3,f18
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// lfs f14,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f27,f27,f2,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f2.f64 - ctx.f25.f64));
	// lfs f2,1200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1200);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f22,f19,f5,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f5.f64 + ctx.f22.f64));
	// lfs f25,1556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1556);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// lfs f19,3464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3464);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f25,f5,f25
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// lfs f5,3300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3300);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f19,f3,f19
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// fnmsubs f1,f1,f12,f27
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f12.f64 - ctx.f27.f64)));
	// fmuls f27,f3,f5
	ctx.f27.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f5,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f15,f15,f5
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// lfs f5,3804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3804);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f26,f17,f26,f22
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// lfs f17,1888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1888);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f22,f3,f5
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f5,2940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2940);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f2,f3,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f3,1848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1848);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f5,f3
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f5,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f17,f17,f5
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f5.f64));
	// lfs f5,-29920(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + -29920);
	ctx.f5.f64 = double(temp.f32);
	// stfs f5,916(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 916, temp.u32);
	// fmadds f5,f24,f5,f1
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 + ctx.f1.f64));
	// lfs f1,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f1.f64 = double(temp.f32);
	// lfs f24,1232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1232);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f1
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// lfs f1,4216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4216);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f14,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 * ctx.f1.f64));
	// lfs f14,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f26,f25,f14,f26
	ctx.f26.f64 = double(float(-(ctx.f25.f64 * ctx.f14.f64 - ctx.f26.f64)));
	// lfs f14,1244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1244);
	ctx.f14.f64 = double(temp.f32);
	// lfs f25,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f3,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f25,f14,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// lfs f14,1852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1852);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f5,f23,f3,f5
	ctx.f5.f64 = double(float(-(ctx.f23.f64 * ctx.f3.f64 - ctx.f5.f64)));
	// lfs f3,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f3.f64 = double(temp.f32);
	// lfs f23,1232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1232);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f3
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f3,3480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3480);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f14
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f14.f64));
	// lfs f14,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f26,f16,f14,f26
	ctx.f26.f64 = double(float(-(ctx.f16.f64 * ctx.f14.f64 - ctx.f26.f64)));
	// lfs f14,1988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1988);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,4076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4076);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f4,f1,f6,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f6.f64 - ctx.f4.f64));
	// lfs f1,4100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4100);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f16.f64));
	// lfs f14,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f1
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f1.f64));
	// lfs f1,1964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1964);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f21,f6,f5
	ctx.f5.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 + ctx.f5.f64));
	// lfs f6,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,1564(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1564, temp.u32);
	// fmuls f21,f6,f1
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f6,f31,f31
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f6,f1,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// lfs f1,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f1.f64 = double(temp.f32);
	// stfs f6,488(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fmr f6,f1
	ctx.f6.f64 = ctx.f1.f64;
	// lfs f1,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f3,f3,f1,f4
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f1.f64 - ctx.f4.f64)));
	// lfs f4,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f5,f20,f4,f5
	ctx.f5.f64 = double(float(-(ctx.f20.f64 * ctx.f4.f64 - ctx.f5.f64)));
	// fnmsubs f26,f15,f6,f26
	ctx.f26.f64 = double(float(-(ctx.f15.f64 * ctx.f6.f64 - ctx.f26.f64)));
	// lfs f15,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f21,f21,f4,f3
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f4.f64 - ctx.f3.f64)));
	// lfs f3,1020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1020);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f5,f18,f4,f5
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f5.f64));
	// fnmsubs f6,f17,f6,f26
	ctx.f6.f64 = double(float(-(ctx.f17.f64 * ctx.f6.f64 - ctx.f26.f64)));
	// lfs f26,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f6,f25,f3,f6
	ctx.f6.f64 = double(float(-(ctx.f25.f64 * ctx.f3.f64 - ctx.f6.f64)));
	// lfs f3,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f5,f2,f3,f5
	ctx.f5.f64 = double(float(-(ctx.f2.f64 * ctx.f3.f64 - ctx.f5.f64)));
	// lfs f2,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f6,f16,f2,f6
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f2.f64 + ctx.f6.f64));
	// stfs f6,4532(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4532, temp.u32);
	// fmadds f5,f19,f12,f5
	ctx.f5.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 + ctx.f5.f64));
	// lfs f6,916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 916);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f5,f27,f6,f5
	ctx.f5.f64 = double(float(-(ctx.f27.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// fmadds f2,f22,f6,f5
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 + ctx.f5.f64));
	// lfs f5,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f2,f24,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// fmadds f5,f23,f5,f2
	ctx.f5.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f2.f64));
	// lfs f2,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f25,f14,f6,f5
	ctx.f25.f64 = double(float(-(ctx.f14.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// lfs f6,1964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1964);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f27,f2,f6
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f5,2940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2940);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f6,f5
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f2,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f6,f30,f30
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// fmuls f23,f6,f2
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// lfs f2,1220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1220);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f22,f2,f26
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// lfs f2,2072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2072);
	ctx.f2.f64 = double(temp.f32);
	// lfs f26,4216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4216);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f20,f2,f26
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// lfs f2,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f19,f2,f6
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f6,1428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1428);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,1852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1852);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f18,f6,f2
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// lfs f26,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f6,f31,f28
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmadds f21,f27,f26,f21
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f26.f64 + ctx.f21.f64));
	// lfs f27,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f6,f27
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f6,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f27,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f24,f24,f1,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64 + ctx.f21.f64));
	// lfs f1,3260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3260);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f23,f23,f27,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f27.f64 + ctx.f22.f64));
	// fmuls f16,f6,f5
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f6,1136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1136);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f21,f6,f1
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f5,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f31,f31
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f22,f19,f6
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f6.f64));
	// lfs f19,3788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3788);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f5,f19
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// fmuls f17,f17,f6
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// fmuls f23,f23,f6
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// fnmsubs f26,f20,f26,f24
	ctx.f26.f64 = double(float(-(ctx.f20.f64 * ctx.f26.f64 - ctx.f24.f64)));
	// fmuls f15,f15,f1
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f1.f64));
	// lfs f1,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmuls f14,f5,f1
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,1532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1532);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,2236(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2236, temp.u32);
	// fmuls f24,f5,f1
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,2304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2304);
	ctx.f1.f64 = double(temp.f32);
	// lfs f20,3636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3636);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f27,f22,f27,f23
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f27.f64 - ctx.f23.f64));
	// fmuls f20,f1,f20
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f20.f64));
	// lfs f1,2948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2948);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f23,f15,f1
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f1.f64));
	// lfs f1,1636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1636);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f5,f1
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,4052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4052);
	ctx.f1.f64 = double(temp.f32);
	// lfs f15,3244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3244);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f26,f18,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// fadds f15,f15,f1
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f1.f64));
	// lfs f1,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmadds f4,f16,f4,f26
	ctx.f4.f64 = double(float(ctx.f16.f64 * ctx.f4.f64 + ctx.f26.f64));
	// fmuls f18,f6,f1
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,1140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1140);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f1,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f1,f17,f1,f27
	ctx.f1.f64 = double(float(-(ctx.f17.f64 * ctx.f1.f64 - ctx.f27.f64)));
	// lfs f27,3796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3796);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f15,f5
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// lfs f5,3252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3252);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f26,f6,f5
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,3292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3292);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f16,f6,f5
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f27,f6,f27
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// fmuls f15,f2,f28
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// fnmsubs f2,f21,f5,f1
	ctx.f2.f64 = double(float(-(ctx.f21.f64 * ctx.f5.f64 - ctx.f1.f64)));
	// lfs f5,3820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3820);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f6,f5
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f1,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f5,f28,f28
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// lfs f5,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f19,f19,f5,f4
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f5.f64 - ctx.f4.f64)));
	// lfs f5,3284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3284);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f4,4092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4092);
	ctx.f4.f64 = double(temp.f32);
	// stfs f5,488(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fmuls f4,f6,f4
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// stfs f4,1020(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1020, temp.u32);
	// fmuls f3,f16,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// fmr f5,f16
	ctx.f5.f64 = ctx.f16.f64;
	// fnmsubs f23,f23,f5,f2
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f2,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f2.f64 = double(temp.f32);
	// fmr f4,f2
	ctx.f4.f64 = ctx.f2.f64;
	// lfs f2,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f19,f14,f4,f19
	ctx.f19.f64 = double(float(-(ctx.f14.f64 * ctx.f4.f64 - ctx.f19.f64)));
	// fmadds f23,f20,f4,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f4.f64 + ctx.f23.f64));
	// lfs f20,2456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2456);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f24,f24,f12,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 + ctx.f19.f64));
	// fnmsubs f24,f22,f5,f24
	ctx.f24.f64 = double(float(-(ctx.f22.f64 * ctx.f5.f64 - ctx.f24.f64)));
	// lfs f5,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f5.f64 = double(temp.f32);
	// lfs f16,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f1,f2,f16
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 + ctx.f16.f64));
	// lfs f14,1020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1020);
	ctx.f14.f64 = double(temp.f32);
	// lfs f1,884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f14,f14,f1,f3
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f1.f64 - ctx.f3.f64));
	// lfs f3,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f23,f18,f3,f23
	ctx.f23.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f23.f64)));
	// fmadds f24,f17,f5,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f5.f64 + ctx.f24.f64));
	// fnmsubs f27,f27,f4,f23
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f4.f64 - ctx.f23.f64)));
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f27,f26,f4,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// lfs f26,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f15,f26,f24
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f26.f64 + ctx.f24.f64));
	// lfs f24,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f22,f21,f4,f27
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 + ctx.f27.f64));
	// lfs f21,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f21.f64 = double(temp.f32);
	// fadds f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f27,4536(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4536, temp.u32);
	// fmuls f27,f28,f28
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// fmadds f25,f16,f6,f14
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 + ctx.f14.f64));
	// fmuls f26,f23,f27
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f27.f64));
	// lfs f27,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// fmuls f21,f21,f27
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f27.f64));
	// lfs f19,2464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2464);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f18,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,1084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1084);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// fmuls f18,f26,f6
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// lfs f26,3324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3324);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f6,f26
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// lfs f26,1800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1800);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f16,f24,f26,f25
	ctx.f16.f64 = double(float(-(ctx.f24.f64 * ctx.f26.f64 - ctx.f25.f64)));
	// lfs f25,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f26,f31,f28
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// lfs f24,2956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2956);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f18,f18,f2
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f2.f64));
	// lfs f2,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f15,f26,f25
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// lfs f26,1960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1960);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f24,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 + ctx.f21.f64));
	// lfs f25,2448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2448);
	ctx.f25.f64 = double(temp.f32);
	// fadds f21,f20,f25
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// lfs f25,3316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3316);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f20,f19,f3
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fmuls f19,f6,f25
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// lfs f25,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f14,f25,f2
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// lfs f2,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f18,f17,f2,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 - ctx.f18.f64));
	// fmuls f17,f15,f6
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f6.f64));
	// fmadds f16,f26,f4,f16
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f4.f64 + ctx.f16.f64));
	// lfs f26,1216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1216);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f21,f21,f26,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f26.f64 + ctx.f20.f64));
	// lfs f20,3308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3308);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f2
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f2.f64));
	// fmuls f15,f14,f6
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f6.f64));
	// fmadds f18,f17,f3,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 + ctx.f18.f64));
	// lfs f17,2080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2080);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f19,f19,f4,f16
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f16.f64)));
	// lfs f16,3340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3340);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f21,f16,f1,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f21.f64));
	// lfs f16,3812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3812);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f20,f16,f1,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f20.f64));
	// lfs f16,2136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2136);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f24.f64));
	// lfs f16,3636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3636);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f25,f16
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f16.f64));
	// lfs f25,2392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2392);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f19,f15,f3,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f3.f64 + ctx.f19.f64));
	// lfs f15,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f21,f25,f2,f21
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 + ctx.f21.f64));
	// fmuls f25,f31,f31
	ctx.f25.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f20,f20,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// fmadds f24,f24,f4,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f18.f64));
	// fmuls f18,f16,f6
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// fmadds f4,f17,f4,f19
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 + ctx.f19.f64));
	// lfs f17,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,3828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3828);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f6,f19
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// fmuls f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 * ctx.f25.f64));
	// lfs f15,3268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3268);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f6,f15
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f15.f64));
	// fmsubs f21,f21,f6,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 - ctx.f20.f64));
	// lfs f20,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f17.f64));
	// lfs f17,4084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4084);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f6,f17
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// fnmsubs f4,f18,f3,f4
	ctx.f4.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f4.f64)));
	// lfs f18,4060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4060);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// fmuls f25,f25,f2
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// fnmsubs f24,f15,f2,f24
	ctx.f24.f64 = double(float(-(ctx.f15.f64 * ctx.f2.f64 - ctx.f24.f64)));
	// fnmsubs f2,f19,f2,f21
	ctx.f2.f64 = double(float(-(ctx.f19.f64 * ctx.f2.f64 - ctx.f21.f64)));
	// lfs f21,3332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3332);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// fadds f4,f22,f4
	ctx.f4.f64 = double(float(ctx.f22.f64 + ctx.f4.f64));
	// fmadds f3,f20,f3,f25
	ctx.f3.f64 = double(float(ctx.f20.f64 * ctx.f3.f64 + ctx.f25.f64));
	// lfs f25,1944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1944);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// fmadds f26,f17,f26,f24
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 + ctx.f24.f64));
	// fmadds f6,f3,f6,f2
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f6.f64 + ctx.f2.f64));
	// lfs f2,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f3,f18,f1,f26
	ctx.f3.f64 = double(float(-(ctx.f18.f64 * ctx.f1.f64 - ctx.f26.f64)));
	// lfs f1,1708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1708);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f1,f2
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// fadds f26,f4,f6
	ctx.f26.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// lfs f6,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f28,f6
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f6.f64));
	// lfs f4,2088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2088);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f25,f21,f12,f3
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f3.f64));
	// lfs f3,2408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2408);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f24,f4,f6
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f21,f3,f6
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// fmuls f3,f23,f28
	ctx.f3.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// fmuls f1,f1,f3
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f3,2424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2424);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f3,f6
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f20,f3,f6
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// lfs f3,1676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1676);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f3,f6
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// fmuls f3,f2,f30
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// lfs f2,2232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2232);
	ctx.f2.f64 = double(temp.f32);
	// stfs f3,460(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// fmuls f2,f3,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f3,2432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2432);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f3,f6
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,1256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f4,f3
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f20,f3
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// lfs f3,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f24,f22,f3,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f24.f64));
	// lfs f3,2152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2152);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f22,f3,f6
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,2416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2416);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f3,f6
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f3,f4
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f4,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// lfs f3,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f3.f64 = double(temp.f32);
	// stfs f4,1536(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1536, temp.u32);
	// fmadds f24,f24,f5,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 + ctx.f21.f64));
	// lfs f21,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f22,f22,f31
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f31.f64));
	// fmuls f14,f4,f3
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f4,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// lfs f3,1860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1860);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// stfs f4,412(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fmuls f4,f21,f28
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f28.f64));
	// lfs f3,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f2,f2,f3,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 + ctx.f20.f64));
	// lfs f21,1868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1868);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f14,f6
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f6.f64));
	// fmsubs f3,f1,f3,f24
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f3.f64 - ctx.f24.f64));
	// lfs f24,2016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2016);
	ctx.f24.f64 = double(temp.f32);
	// lfs f1,3592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3592);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f6
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f4,f21,f4
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f4.f64));
	// fmuls f21,f15,f30
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f30.f64));
	// lfs f15,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f2,f17,f15,f2
	ctx.f2.f64 = double(float(-(ctx.f17.f64 * ctx.f15.f64 - ctx.f2.f64)));
	// lfs f15,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,2956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2956);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f24,f24,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f17.f64));
	// lfs f17,4232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4232);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f6
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// fmadds f20,f4,f15,f20
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f15.f64 + ctx.f20.f64));
	// lfs f4,1800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1800);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f27,f27,f4,f25
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f4.f64 - ctx.f25.f64)));
	// lfs f4,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f2,f22,f4,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f4.f64 - ctx.f2.f64)));
	// lfs f4,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f25,f23,f5,f3
	ctx.f25.f64 = double(float(-(ctx.f23.f64 * ctx.f5.f64 - ctx.f3.f64)));
	// fmuls f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// lfs f3,1708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1708);
	ctx.f3.f64 = double(temp.f32);
	// stfs f4,2192(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2192, temp.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f23,f3,f4
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f4,4068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4068);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f22,f3,f4
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f4,1716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,1868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1868);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f3,f4
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f4,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f27,f24,f4,f27
	ctx.f27.f64 = double(float(-(ctx.f24.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// lfs f4,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f2,f21,f4,f2
	ctx.f2.f64 = double(float(-(ctx.f21.f64 * ctx.f4.f64 - ctx.f2.f64)));
	// lfs f21,1916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1916);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f25,f19,f4,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f4.f64 + ctx.f25.f64));
	// lfs f19,2088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2088);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// lfs f19,-30092(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30092);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,1716(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1716, temp.u32);
	// lfs f19,1744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1744);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f3,f19
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// lfs f3,1492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1492);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f3,f6
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f24,2472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2472);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmadds f3,f22,f12,f27
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f27.f64));
	// lfs f22,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f27,f20,f4,f2
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f4.f64 + ctx.f2.f64));
	// lfs f2,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f25,f18,f2,f25
	ctx.f25.f64 = double(float(-(ctx.f18.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// lfs f20,2440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2440);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,2388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2388);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f20,f20,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// fmuls f18,f18,f6
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f6.f64));
	// fadds f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// stfs f3,4540(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4540, temp.u32);
	// lfs f3,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f27,f23,f3,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 + ctx.f27.f64));
	// lfs f23,1536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1536);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f26,f16,f5,f25
	ctx.f26.f64 = double(float(-(ctx.f16.f64 * ctx.f5.f64 - ctx.f25.f64)));
	// lfs f25,1860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1860);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// lfs f16,1124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1124);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,3528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3528);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f16,f31
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f31.f64));
	// fmuls f22,f22,f6
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// fnmsubs f2,f24,f2,f27
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f27,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f27,f27,f4,f26
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// lfs f24,940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 940);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f23,f6
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// fmadds f26,f19,f3,f2
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f3.f64 + ctx.f2.f64));
	// lfs f19,1516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1516);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f2,f1,f12,f27
	ctx.f2.f64 = double(float(-(ctx.f1.f64 * ctx.f12.f64 - ctx.f27.f64)));
	// fmuls f19,f19,f6
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f6.f64));
	// fmadds f2,f17,f5,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f5.f64 + ctx.f2.f64));
	// lfs f17,1484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1484);
	ctx.f17.f64 = double(temp.f32);
	// lfs f1,1716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f17,f17,f6
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// fnmsubs f2,f15,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f15,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f27,f21,f1,f2
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 + ctx.f2.f64));
	// lfs f2,1224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1224);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,1868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1868);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f2,1736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1736);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f25,f2
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// lfs f21,3552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3552);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f12
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfs f2,1708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1708);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f24,f2,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// fmuls f1,f1,f4
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// fmsubs f1,f25,f3,f1
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 - ctx.f1.f64));
	// lfs f25,2480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2480);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f25,f25,f5,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 + ctx.f21.f64));
	// lfs f21,3568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3568);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f12
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fnmsubs f1,f24,f15,f1
	ctx.f1.f64 = double(float(-(ctx.f24.f64 * ctx.f15.f64 - ctx.f1.f64)));
	// lfs f15,3836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3836);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f21,f15,f5,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f5.f64 + ctx.f21.f64));
	// lfs f15,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f15.f64 = double(temp.f32);
	// lfs f24,3348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3348);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f15.f64));
	// fmuls f24,f24,f5
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// lfs f15,1976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1976);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f26,f14,f4,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 * ctx.f4.f64 + ctx.f26.f64));
	// lfs f14,1476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1476);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f15,f2
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// fmuls f14,f14,f6
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f6.f64));
	// fmadds f3,f23,f3,f1
	ctx.f3.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 + ctx.f1.f64));
	// lfs f1,916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 916);
	ctx.f1.f64 = double(temp.f32);
	// lfs f23,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f2,f23
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// fmadds f24,f16,f1,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f24.f64));
	// lfs f16,1816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1816);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f21,f21,f6,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 - ctx.f18.f64));
	// lfs f18,1344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1344);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f26,f15,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f15.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// lfs f15,1860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1860);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// fmuls f18,f18,f6
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f6.f64));
	// fnmsubs f22,f22,f12,f3
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f3.f64)));
	// lfs f3,2400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2400);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f3,f6
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f23,f3
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f3,1880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1880);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f24,f24,f6,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 + ctx.f21.f64));
	// lfs f21,1868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1868);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// lfs f3,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// fmadds f26,f18,f4,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f26.f64));
	// fmadds f25,f25,f6,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f22.f64));
	// fnmsubs f24,f23,f5,f24
	ctx.f24.f64 = double(float(-(ctx.f23.f64 * ctx.f5.f64 - ctx.f24.f64)));
	// lfs f23,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f2,f3
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f3,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fadds f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// lfs f26,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f25,f20,f5,f25
	ctx.f25.f64 = double(float(-(ctx.f20.f64 * ctx.f5.f64 - ctx.f25.f64)));
	// fmuls f26,f18,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f26.f64));
	// fadds f22,f2,f3
	ctx.f22.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfs f2,1268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1268);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f3,f2,f31
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f3,412(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fmuls f3,f23,f31
	ctx.f3.f64 = double(float(ctx.f23.f64 * ctx.f31.f64));
	// fadds f23,f22,f3
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f3.f64));
	// lfs f3,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f25,f19,f3,f25
	ctx.f25.f64 = double(float(-(ctx.f19.f64 * ctx.f3.f64 - ctx.f25.f64)));
	// fmadds f4,f17,f4,f25
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 + ctx.f25.f64));
	// lfs f25,2560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2560);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f4,f14,f3,f4
	ctx.f4.f64 = double(float(-(ctx.f14.f64 * ctx.f3.f64 - ctx.f4.f64)));
	// lfs f3,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f3.f64 = double(temp.f32);
	// lfs f22,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f1
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// lfs f1,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f24,f21,f1,f24
	ctx.f24.f64 = double(float(-(ctx.f21.f64 * ctx.f1.f64 - ctx.f24.f64)));
	// lfs f21,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f4,f16,f1,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f1.f64 - ctx.f4.f64)));
	// fmadds f23,f23,f21,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f21.f64 + ctx.f22.f64));
	// lfs f22,1500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1500);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f26,f26,f5,f24
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f5.f64 - ctx.f24.f64)));
	// lfs f24,892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 892);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f5,f15,f5,f4
	ctx.f5.f64 = double(float(-(ctx.f15.f64 * ctx.f5.f64 - ctx.f4.f64)));
	// fmuls f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// lfs f24,2552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2552);
	ctx.f24.f64 = double(temp.f32);
	// fadds f1,f27,f5
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f5.f64));
	// lfs f5,2544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2544);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f3
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f5,2964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2964);
	ctx.f5.f64 = double(temp.f32);
	// lfs f27,2576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2576);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f5,f24
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// fmuls f27,f5,f27
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// fmuls f22,f5,f22
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f22.f64));
	// lfs f20,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f6,f23,f6,f26
	ctx.f6.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f26.f64));
	// lfs f21,3520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3520);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f21,f21,f20,f4
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 - ctx.f4.f64));
	// lfs f4,1872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1872);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f27,f27,f4
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// lfs f4,2568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2568);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f20,f5,f4
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f19,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f19.f64 = double(temp.f32);
	// lfs f4,1604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1604);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f25,f4,f19,f25
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f19.f64 + ctx.f25.f64));
	// lfs f16,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f16.f64 = double(temp.f32);
	// lfs f4,3536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3536);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f19,f5,f4
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f4,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f4.f64 = double(temp.f32);
	// lfs f23,1708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1708);
	ctx.f23.f64 = double(temp.f32);
	// lfs f26,2368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2368);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f26.f64));
	// lfs f23,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,1360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1360);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f27,f21,f5,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f5.f64 - ctx.f27.f64));
	// lfs f21,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f2,f21,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 * ctx.f2.f64));
	// lfs f21,2344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2344);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f16.f64));
	// lfs f17,3688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3688);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,2504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2504);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f18,f4,f18
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f18.f64));
	// fmuls f17,f4,f17
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// lfs f15,2328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2328);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f4,f16
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f16.f64));
	// lfs f14,3560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3560);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f5,f14
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// fmadds f27,f25,f5,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 + ctx.f27.f64));
	// lfs f25,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfs f25,1652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1652);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f4,f25
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f25.f64));
	// fmuls f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64));
	// lfs f15,2584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2584);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f5,f15
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f15.f64));
	// fnmsubs f27,f24,f3,f27
	ctx.f27.f64 = double(float(-(ctx.f24.f64 * ctx.f3.f64 - ctx.f27.f64)));
	// lfs f24,892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 892);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f2,f21,f24,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 * ctx.f24.f64 - ctx.f2.f64));
	// lfs f24,900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 900);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// lfs f21,908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 908);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,1596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1596);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f21.f64));
	// lfs f21,1508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1508);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f4,f21
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// fmadds f27,f22,f23,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 + ctx.f27.f64));
	// lfs f23,2512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2512);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f2,f23,f22,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 + ctx.f2.f64));
	// lfs f22,2536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2536);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,1124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1124);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f24,f22,f3,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f24.f64));
	// lfs f3,2496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2496);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f22,f4,f3
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,1368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1368);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,1716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// fmadds f6,f26,f3,f6
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f3.f64 + ctx.f6.f64));
	// lfs f3,1872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1872);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f26,f20,f3,f27
	ctx.f26.f64 = double(float(-(ctx.f20.f64 * ctx.f3.f64 - ctx.f27.f64)));
	// lfs f27,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f27.f64 = double(temp.f32);
	// lfs f3,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f2,f2,f27,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64 - ctx.f25.f64));
	// fmuls f25,f23,f3
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f3,1692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1692);
	ctx.f3.f64 = double(temp.f32);
	// lfs f23,908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 908);
	ctx.f23.f64 = double(temp.f32);
	// fadds f6,f1,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 + ctx.f6.f64));
	// fmuls f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfs f3,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f1,f19,f3,f26
	ctx.f1.f64 = double(float(-(ctx.f19.f64 * ctx.f3.f64 - ctx.f26.f64)));
	// stfs f6,4544(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4544, temp.u32);
	// lfs f6,900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 900);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f2,f21,f6,f2
	ctx.f2.f64 = double(float(-(ctx.f21.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// fnmsubs f1,f18,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f18.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// stfs f4,412(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// lfs f26,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f26.f64 = double(temp.f32);
	// fmr f4,f26
	ctx.f4.f64 = ctx.f26.f64;
	// lfs f26,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f1,f17,f26,f1
	ctx.f1.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 + ctx.f1.f64));
	// lfs f19,1124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1124);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,1968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1968);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f20.f64));
	// lfs f18,3544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3544);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f23,f18,f3,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f3.f64 + ctx.f23.f64));
	// lfs f21,1376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1376);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f2,f22,f4,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f4.f64 - ctx.f2.f64)));
	// lfs f26,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f22,f26,f6,f2
	ctx.f22.f64 = double(float(-(ctx.f26.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// lfs f26,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f6,f16,f4,f1
	ctx.f6.f64 = double(float(-(ctx.f16.f64 * ctx.f4.f64 - ctx.f1.f64)));
	// lfs f4,892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 892);
	ctx.f4.f64 = double(temp.f32);
	// lfs f2,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f2.f64 = double(temp.f32);
	// lfs f16,2608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2608);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f23,f23,f5,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f22.f64));
	// lfs f22,2624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2624);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f6,f15,f4,f6
	ctx.f6.f64 = double(float(ctx.f15.f64 * ctx.f4.f64 + ctx.f6.f64));
	// lfs f4,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f4.f64 = double(temp.f32);
	// lfs f15,3576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3576);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f5,f15
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f15.f64));
	// fnmsubs f6,f14,f26,f6
	ctx.f6.f64 = double(float(-(ctx.f14.f64 * ctx.f26.f64 - ctx.f6.f64)));
	// lfs f14,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f6,f24,f5,f6
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 + ctx.f6.f64));
	// fnmsubs f25,f25,f2,f6
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f2.f64 - ctx.f6.f64)));
	// lfs f6,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f1,f4,f6
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f4,1724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1724);
	ctx.f4.f64 = double(temp.f32);
	// lfs f6,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f19,f4,f19
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// fmuls f24,f4,f6
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,1316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1316);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f2,f20,f2
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f2.f64));
	// lfs f20,3512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3512);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// stfs f1,628(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// fmuls f26,f20,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// lfs f20,2632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2632);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// fmuls f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// fmuls f24,f24,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f18.f64));
	// lfs f18,1612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1612);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f5,f18
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f18.f64));
	// fmadds f2,f19,f12,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 + ctx.f2.f64));
	// lfs f19,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f4,f19
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// lfs f4,3584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3584);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f17.f64));
	// fmuls f17,f5,f4
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f4,3600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3600);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f26,f4,f3,f26
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 + ctx.f26.f64));
	// lfs f4,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f3,f18,f3,f23
	ctx.f3.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f23.f64)));
	// lfs f18,2096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2096);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f4,f23
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// lfs f4,2488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2488);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f27,f27,f4
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// lfs f4,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f19,f19,f4
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// lfs f16,2520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2520);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f5,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f16.f64));
	// fmadds f3,f26,f5,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f5.f64 + ctx.f3.f64));
	// fmuls f4,f18,f4
	ctx.f4.f64 = double(float(ctx.f18.f64 * ctx.f4.f64));
	// lfs f18,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f1,f14,f18,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 * ctx.f18.f64 + ctx.f1.f64));
	// lfs f18,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f26,f23,f6
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// lfs f23,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// fnmsubs f3,f17,f18,f3
	ctx.f3.f64 = double(float(-(ctx.f17.f64 * ctx.f18.f64 - ctx.f3.f64)));
	// lfs f18,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f14,1324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1324);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f17.f64));
	// lfs f14,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f14.f64));
	// lfs f14,1340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1340);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f5,f14
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// lfs f5,1384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1384);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,1968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1968);
	ctx.f5.f64 = double(temp.f32);
	// stfs f6,412(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fmr f6,f5
	ctx.f6.f64 = ctx.f5.f64;
	// lfs f5,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f3,f27,f5,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f3.f64));
	// lfs f5,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f5.f64 = double(temp.f32);
	// lfs f27,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f5
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// lfs f5,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f1,f1,f6,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f6.f64 + ctx.f24.f64));
	// fmadds f24,f18,f5,f17
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f5.f64 + ctx.f17.f64));
	// lfs f5,2664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2664);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f18,f5,f12
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f5,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f1,f1,f5,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64 - ctx.f21.f64));
	// lfs f21,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f3,f16,f21,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 * ctx.f21.f64 + ctx.f3.f64));
	// lfs f21,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f2,f2,f5,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64 + ctx.f1.f64));
	// lfs f5,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f3,f15,f5,f3
	ctx.f3.f64 = double(float(-(ctx.f15.f64 * ctx.f5.f64 - ctx.f3.f64)));
	// lfs f5,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f5.f64 = double(temp.f32);
	// lfs f1,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f2,f22,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f22,1268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1268);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f3,f14,f1,f3
	ctx.f3.f64 = double(float(-(ctx.f14.f64 * ctx.f1.f64 - ctx.f3.f64)));
	// fmuls f22,f22,f6
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// fnmsubs f2,f20,f12,f2
	ctx.f2.f64 = double(float(-(ctx.f20.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f1,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f1.f64 = double(temp.f32);
	// fadds f3,f25,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 + ctx.f3.f64));
	// stfs f3,4548(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4548, temp.u32);
	// lfs f3,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f3.f64 = double(temp.f32);
	// lfs f25,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f6
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// lfs f6,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f6.f64 = double(temp.f32);
	// lfs f20,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f3,f19,f3,f2
	ctx.f3.f64 = double(float(-(ctx.f19.f64 * ctx.f3.f64 - ctx.f2.f64)));
	// lfs f2,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f3,f26,f5,f3
	ctx.f3.f64 = double(float(-(ctx.f26.f64 * ctx.f5.f64 - ctx.f3.f64)));
	// lfs f26,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f4,f4,f2,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64 + ctx.f3.f64));
	// lfs f3,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f4,f23,f5,f4
	ctx.f4.f64 = double(float(-(ctx.f23.f64 * ctx.f5.f64 - ctx.f4.f64)));
	// lfs f5,1316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1316);
	ctx.f5.f64 = double(temp.f32);
	// lfs f23,1352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1352);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f4,f24,f5,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 + ctx.f4.f64));
	// lfs f24,1472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1472);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f24.f64));
	// lfs f23,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// fnmsubs f1,f1,f3,f4
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f3.f64 - ctx.f4.f64)));
	// lfs f4,1724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1724);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f26,f4,f26
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f26.f64));
	// fmuls f26,f26,f6
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// lfs f6,1408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1408);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f3,f6,f3
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f6,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f23,f6
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// lfs f6,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// lfs f6,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f26,f25,f6,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 - ctx.f26.f64));
	// lfs f25,1400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1400);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f3,f25,f20,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f20.f64 + ctx.f3.f64));
	// lfs f25,3640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3640);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f2,f23,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// lfs f20,2656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2656);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,2008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2008);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f25,f5,f25
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// fmuls f23,f23,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// fmuls f20,f5,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// fmadds f6,f24,f6,f26
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 + ctx.f26.f64));
	// lfs f24,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f24.f64 = double(temp.f32);
	// lfs f26,1796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1796);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f24,f3
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 + ctx.f3.f64));
	// lfs f19,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f17.f64 = double(temp.f32);
	// lfs f3,2648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2648);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f21,f17,f19,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f19.f64 + ctx.f21.f64));
	// fmuls f24,f5,f3
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,3672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3672);
	ctx.f3.f64 = double(temp.f32);
	// lfs f19,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// lfs f3,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f23,f3
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f3,2640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2640);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f5,f3
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f22,f22,f3,f6
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f6.f64));
	// lfs f6,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f3,f6,f31
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// lfs f6,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// fmuls f16,f3,f6
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,1392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1392);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f5,f3
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// lfs f3,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f4,f3
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f4,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// lfs f3,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f19,f16,f0,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 - ctx.f19.f64));
	// lfs f16,1924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1924);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f22,f22,f3,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 - ctx.f2.f64));
	// lfs f3,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f3.f64 = double(temp.f32);
	// stfs f4,488(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fmuls f4,f3,f28
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// lfs f3,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f3.f64 = double(temp.f32);
	// stfs f4,2012(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2012, temp.u32);
	// lfs f2,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f26,f26,f5,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f5.f64 + ctx.f22.f64));
	// lfs f22,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// stfs f4,412(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// lfs f3,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f4,f22,f30
	ctx.f4.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// fmadds f27,f27,f3,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64 + ctx.f18.f64));
	// stfs f4,2268(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2268, temp.u32);
	// fmuls f18,f14,f2
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f2.f64));
	// lfs f2,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f16,f2,f16
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// fnmsubs f26,f25,f12,f26
	ctx.f26.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f26.f64)));
	// lfs f25,1984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1984);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f1,f27,f5,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f1.f64));
	// fmuls f16,f16,f31
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f31.f64));
	// lfs f27,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f27.f64 = double(temp.f32);
	// lfs f22,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f4,f4,f10,f22
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f10.f64 + ctx.f22.f64));
	// fnmsubs f22,f27,f0,f19
	ctx.f22.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f19.f64)));
	// lfs f27,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f27.f64 = double(temp.f32);
	// lfs f19,2008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2008);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f27
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f27.f64));
	// fmadds f4,f4,f6,f22
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f6.f64 + ctx.f22.f64));
	// fmadds f22,f25,f0,f19
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f19.f64));
	// lfs f25,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f26,f21,f25,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f25.f64 + ctx.f26.f64));
	// fnmsubs f21,f16,f27,f4
	ctx.f21.f64 = double(float(-(ctx.f16.f64 * ctx.f27.f64 - ctx.f4.f64)));
	// fnmsubs f4,f23,f3,f26
	ctx.f4.f64 = double(float(-(ctx.f23.f64 * ctx.f3.f64 - ctx.f26.f64)));
	// lfs f3,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f4,f20,f12,f4
	ctx.f4.f64 = double(float(-(ctx.f20.f64 * ctx.f12.f64 - ctx.f4.f64)));
	// fmadds f4,f24,f12,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 + ctx.f4.f64));
	// fnmsubs f4,f17,f3,f4
	ctx.f4.f64 = double(float(-(ctx.f17.f64 * ctx.f3.f64 - ctx.f4.f64)));
	// lfs f3,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f4,f15,f3,f4
	ctx.f4.f64 = double(float(-(ctx.f15.f64 * ctx.f3.f64 - ctx.f4.f64)));
	// lfs f3,3704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3704);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f4,f18,f12,f4
	ctx.f4.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f4.f64)));
	// fadds f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// stfs f4,4552(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4552, temp.u32);
	// lfs f4,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f22,f22,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// lfs f23,3632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3632);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f1,f3,f4
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// fmuls f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// lfs f4,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f20,f4,f6
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f4,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// lfs f3,3648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3648);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f26,f2,f3
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f3,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f3.f64 = double(temp.f32);
	// lfs f25,1948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1948);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f3
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// lfs f24,2240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2240);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f28
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// fmadds f22,f22,f31,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f31.f64 + ctx.f21.f64));
	// lfs f21,2060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2060);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// fmuls f19,f4,f3
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f26,f3
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// lfs f4,3656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3656);
	ctx.f4.f64 = double(temp.f32);
	// lfs f26,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f18,f4,f3,f1
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 - ctx.f1.f64));
	// lfs f4,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f25,f25,f26
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fmuls f1,f4,f30
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// lfs f4,1228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1228);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f24,f24,f27,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f27.f64 + ctx.f23.f64));
	// stfs f1,1264(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1264, temp.u32);
	// fmsubs f18,f18,f2,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f2.f64 - ctx.f17.f64));
	// fmsubs f20,f20,f0,f25
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 - ctx.f25.f64));
	// lfs f25,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f4,f1
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// fmuls f1,f25,f31
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// fnmsubs f19,f19,f26,f18
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f26.f64 - ctx.f18.f64)));
	// fnmsubs f23,f23,f0,f20
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f0.f64 - ctx.f20.f64)));
	// fmuls f17,f1,f0
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f1,3624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3624);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f24,f1,f3,f24
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f3.f64 + ctx.f24.f64));
	// lfs f3,2680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2680);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f4,f3
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,2104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2104);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f4,f3
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f1,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,2312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2312);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f20,f3,f1,f17
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f1.f64 + ctx.f17.f64));
	// lfs f3,2168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2168);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f3,f6
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// stfs f3,2036(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2036, temp.u32);
	// fmadds f24,f24,f2,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f2.f64 + ctx.f19.f64));
	// lfs f19,1520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1520);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f6
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f6.f64));
	// fmuls f17,f4,f3
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,1824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1824);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f3,f28
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// lfs f3,2112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2112);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f23,f20,f3,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f3.f64 + ctx.f23.f64));
	// lfs f20,1812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1812);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f24,f16,f10,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f24.f64));
	// lfs f16,2068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2068);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f2,f20
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f20.f64));
	// fmuls f16,f16,f6
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// fnmsubs f22,f14,f27,f22
	ctx.f22.f64 = double(float(-(ctx.f14.f64 * ctx.f27.f64 - ctx.f22.f64)));
	// lfs f27,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// stfs f27,1884(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1884, temp.u32);
	// fmadds f23,f15,f1,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f1.f64 + ctx.f23.f64));
	// lfs f15,1836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1836);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f20,f20,f31
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f31.f64));
	// fnmsubs f18,f18,f1,f24
	ctx.f18.f64 = double(float(-(ctx.f18.f64 * ctx.f1.f64 - ctx.f24.f64)));
	// fmuls f15,f27,f15
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f15.f64));
	// lfs f27,1976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1976);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f14,f27,f3
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// lfs f27,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// stfs f27,2044(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2044, temp.u32);
	// fmuls f27,f4,f27
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// stfs f27,412(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fnmsubs f23,f17,f10,f23
	ctx.f23.f64 = double(float(-(ctx.f17.f64 * ctx.f10.f64 - ctx.f23.f64)));
	// lfs f24,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f22,f20,f0,f22
	ctx.f22.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// fmuls f27,f24,f30
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// stfs f27,812(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 812, temp.u32);
	// fnmsubs f21,f21,f10,f18
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f10.f64 - ctx.f18.f64)));
	// lfs f18,2720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2720);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,2688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2688);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f23,f19,f0,f23
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// fnmsubs f22,f14,f0,f22
	ctx.f22.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// fmuls f20,f27,f6
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f27,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f27,f28
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// stfs f24,1956(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1956, temp.u32);
	// fmadds f21,f16,f10,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f21.f64));
	// lfs f16,2248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2248);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// stfs f27,1912(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1912, temp.u32);
	// fmadds f23,f15,f10,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f10.f64 + ctx.f23.f64));
	// lfs f15,924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 924);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// fnmsubs f23,f20,f10,f23
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f10.f64 - ctx.f23.f64)));
	// fmadds f23,f24,f26,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f26.f64 + ctx.f23.f64));
	// lfs f24,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f31,f24
	ctx.f24.f64 = double(float(ctx.f31.f64 * ctx.f24.f64));
	// stfs f24,480(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// lfs f19,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f19,f0,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 + ctx.f21.f64));
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f21,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f24.f64));
	// fmuls f21,f27,f6
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f27,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f4,f27
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// lfs f27,1512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1512);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f27,f6
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fmuls f27,f25,f30
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f30.f64));
	// stfs f27,1920(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1920, temp.u32);
	// fmuls f25,f4,f27
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// lfs f27,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// stfs f27,1020(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1020, temp.u32);
	// fmuls f27,f27,f6
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f6,1092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1092);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f24,f6
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// lfs f24,3712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3712);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f2,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// lfs f2,2832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2832);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f18,f2
	ctx.f2.f64 = double(float(ctx.f18.f64 + ctx.f2.f64));
	// lfs f18,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f18.f64));
	// lfs f17,1952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1952);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,2120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2120);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// fmuls f1,f6,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f6,1332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1332);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f15,f4,f6
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f4,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f6,f31,f31
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmsubs f1,f21,f26,f1
	ctx.f1.f64 = double(float(ctx.f21.f64 * ctx.f26.f64 - ctx.f1.f64));
	// lfs f26,1156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1156);
	ctx.f26.f64 = double(temp.f32);
	// lfs f21,1036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1036);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f4,f6
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f4,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f2,f2,f4,f18
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f4.f64 + ctx.f18.f64));
	// stfs f6,2052(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2052, temp.u32);
	// fmuls f18,f6,f3
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f6,1732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1732);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f17,f17,f6,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f6.f64 + ctx.f16.f64));
	// fmuls f6,f30,f30
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// fmuls f26,f26,f6
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// lfs f6,1416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1416);
	ctx.f6.f64 = double(temp.f32);
	// fadds f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f6.f64));
	// lfs f6,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f14,f6
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f6.f64));
	// lfs f14,2712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2712);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f2,f14,f7,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 * ctx.f7.f64 + ctx.f2.f64));
	// fmuls f6,f17,f6
	ctx.f6.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// lfs f14,940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 940);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f1,f20,f0,f1
	ctx.f1.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f1.f64));
	// lfs f20,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// lfs f20,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f21,f21,f20,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f16.f64));
	// lfs f17,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f14,f3
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f3.f64));
	// lfs f20,3680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3680);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f20.f64));
	// lfs f17,1028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1028);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fmadds f2,f2,f11,f6
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f6.f64));
	// lfs f6,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f6,1224(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1224, temp.u32);
	// fnmsubs f1,f19,f0,f1
	ctx.f1.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// fmuls f19,f6,f3
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f6,1992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1992);
	ctx.f6.f64 = double(temp.f32);
	// lfs f3,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f1,f25,f10,f1
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f10.f64 - ctx.f1.f64)));
	// fmuls f16,f3,f6
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f6,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f6.f64 = double(temp.f32);
	// lfs f3,2776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2776);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f3,f3,f6,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f6.f64 + ctx.f21.f64));
	// lfs f6,952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 952);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f21,f6,f11
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f6,1040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1040);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f2,f26,f6,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f6.f64 + ctx.f2.f64));
	// lfs f6,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f26,2728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2728);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f22,f26,f11
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f26,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f3,f3,f11
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// fmsubs f25,f17,f26,f2
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 - ctx.f2.f64));
	// lfs f26,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f6,f6,f11
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f2,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f1,f27,f26,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f26.f64 + ctx.f1.f64));
	// lfs f17,2704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2704);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f27,f21,f2,f3
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f2.f64 - ctx.f3.f64));
	// lfs f3,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f21,f16,f3,f25
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 + ctx.f25.f64));
	// lfs f25,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// lfs f16,1804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1804);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f1,f24,f25,f1
	ctx.f1.f64 = double(float(-(ctx.f24.f64 * ctx.f25.f64 - ctx.f1.f64)));
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f16,2816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2816);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f21,f22,f4,f21
	ctx.f21.f64 = double(float(-(ctx.f22.f64 * ctx.f4.f64 - ctx.f21.f64)));
	// lfs f22,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f24,f6,f0,f27
	ctx.f24.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f27.f64)));
	// lfs f27,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f6,f15,f0,f1
	ctx.f6.f64 = double(float(-(ctx.f15.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// lfs f1,924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 924);
	ctx.f1.f64 = double(temp.f32);
	// lfs f15,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f6,f18,f0,f6
	ctx.f6.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f6.f64));
	// lfs f18,2840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2840);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f11
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// fnmsubs f6,f14,f27,f6
	ctx.f6.f64 = double(float(-(ctx.f14.f64 * ctx.f27.f64 - ctx.f6.f64)));
	// fmadds f6,f20,f25,f6
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f25.f64 + ctx.f6.f64));
	// lfs f20,1448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1448);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f6,f19,f26,f6
	ctx.f6.f64 = double(float(-(ctx.f19.f64 * ctx.f26.f64 - ctx.f6.f64)));
	// lfs f19,2848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2848);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// fadds f6,f23,f6
	ctx.f6.f64 = double(float(ctx.f23.f64 + ctx.f6.f64));
	// stfs f6,4556(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4556, temp.u32);
	// lfs f6,2016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2016);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f1,f6,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f6,1432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1432);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f6,f11
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// fmuls f6,f31,f28
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// stfs f6,224(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fmuls f1,f1,f3
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// fmuls f6,f31,f31
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmuls f20,f20,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// fnmsubs f24,f19,f7,f24
	ctx.f24.f64 = double(float(-(ctx.f19.f64 * ctx.f7.f64 - ctx.f24.f64)));
	// lfs f19,2744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2744);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f23,f23,f2,f1
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 - ctx.f1.f64));
	// lfs f14,2768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2768);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// lfs f1,1156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1156);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// lfs f15,2824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2824);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// fmuls f20,f20,f3
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// fmuls f14,f1,f6
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// lfs f6,2752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2752);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f23,f22,f27,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f27.f64 + ctx.f23.f64));
	// fnmsubs f22,f19,f4,f24
	ctx.f22.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f24.f64)));
	// fmuls f24,f28,f28
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// stfs f24,924(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 924, temp.u32);
	// fmadds f17,f17,f7,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f16.f64));
	// fmadds f20,f15,f7,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f7.f64 + ctx.f20.f64));
	// fmuls f16,f6,f11
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f6,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f19,f14,f6
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f6.f64));
	// fmuls f24,f1,f24
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// lfs f1,2784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2784);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f1,f11
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// lfs f1,2792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2792);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f20,f1,f4,f20
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f4.f64 + ctx.f20.f64));
	// lfs f1,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f23,f18,f1,f23
	ctx.f23.f64 = double(float(-(ctx.f18.f64 * ctx.f1.f64 - ctx.f23.f64)));
	// lfs f18,2760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2760);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f16,f7
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f7.f64));
	// fmuls f18,f18,f7
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f7.f64));
	// fmadds f22,f19,f7,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 + ctx.f22.f64));
	// lfs f19,2000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2000);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// lfs f6,1992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1992);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f19,f6,f19
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// fmadds f23,f17,f11,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f23.f64));
	// lfs f17,2736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2736);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f20,f20,f11,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64 - ctx.f16.f64));
	// lfs f16,2808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2808);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f1,f16,f1,f18
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f18.f64));
	// lfs f16,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// lfs f18,2800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2800);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f11
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// fnmsubs f24,f24,f16,f22
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f16.f64 - ctx.f22.f64)));
	// lfs f22,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f22,f6
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// lfs f22,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f6,f6,f22
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// lfs f22,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f23,f15,f22,f23
	ctx.f23.f64 = double(float(-(ctx.f15.f64 * ctx.f22.f64 - ctx.f23.f64)));
	// lfs f22,1440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1440);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f1,f1,f11,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 + ctx.f20.f64));
	// fmuls f20,f22,f11
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// lfs f22,1260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1260);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f17,f17,f7,f24
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f24.f64));
	// lfs f24,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f15,f22,f24
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f24.f64));
	// lfs f22,1424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1424);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f2,f22,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// lfs f22,1056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1056);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f23,f19,f22,f23
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f22.f64 - ctx.f23.f64)));
	// lfs f19,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,1908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1908);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f1,f16,f4,f1
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f4.f64 + ctx.f1.f64));
	// fmuls f22,f22,f27
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f27.f64));
	// stfs f22,488(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fadds f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// fmadds f2,f15,f27,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f27.f64 + ctx.f2.f64));
	// fmadds f23,f18,f4,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fnmsubs f1,f20,f19,f1
	ctx.f1.f64 = double(float(-(ctx.f20.f64 * ctx.f19.f64 - ctx.f1.f64)));
	// fnmsubs f6,f6,f3,f23
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f3.f64 - ctx.f23.f64)));
	// fmadds f2,f2,f11,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f1.f64));
	// lfs f1,1972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1972);
	ctx.f1.f64 = double(temp.f32);
	// fadds f6,f21,f6
	ctx.f6.f64 = double(float(ctx.f21.f64 + ctx.f6.f64));
	// fadds f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// stfs f6,4560(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4560, temp.u32);
	// lfs f6,1456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1456);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,1828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1828);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f21,f6,f2
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// lfs f2,1848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1848);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f20,f1,f2
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f2,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f2.f64 = double(temp.f32);
	// lfs f23,888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 888);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f19,f2,f23
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f16,1096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1096);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f21,f16,f1,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f21.f64));
	// lfs f23,2856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2856);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f2,f23
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f23,2004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2004);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f17,f6,f23
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// lfs f23,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f16,2376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2376);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 968);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f2,f15
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f15.f64));
	// fmuls f20,f20,f26
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// lfs f26,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f19,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f25.f64));
	// lfs f19,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f26.f64));
	// stfs f26,1156(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1156, temp.u32);
	// lfs f26,960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 960);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f19,f2,f26
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// lfs f26,1820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1820);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f16
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// fmsubs f21,f21,f0,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 - ctx.f20.f64));
	// lfs f20,1980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1980);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f26
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// fmsubs f25,f18,f0,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 - ctx.f25.f64));
	// lfs f18,2128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2128);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f22,f18,f27,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f27.f64 + ctx.f22.f64));
	// lfs f27,2256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2256);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f27,f26
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// lfs f27,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f28
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// stfs f27,600(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// fmadds f21,f17,f0,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f21.f64));
	// lfs f17,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f25,f24,f17,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f17.f64 - ctx.f25.f64)));
	// lfs f24,1184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1184);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f17,f6,f24
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// lfs f24,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f24,f23
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f23,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f27,f27,f1
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// lfs f24,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// stfs f24,412(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fnmsubs f23,f19,f23,f21
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f23.f64 - ctx.f21.f64)));
	// lfs f19,1060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1060);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// lfs f19,1152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1152);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f25,f22,f6,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 + ctx.f25.f64));
	// lfs f21,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f19,f1
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// lfs f22,2864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2864);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f21.f64));
	// lfs f21,1000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1000);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f2,f21
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// fmadds f23,f16,f0,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 + ctx.f23.f64));
	// lfs f16,1820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1820);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f25,f20,f10,f25
	ctx.f25.f64 = double(float(-(ctx.f20.f64 * ctx.f10.f64 - ctx.f25.f64)));
	// lfs f20,1740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1740);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f20.f64));
	// lfs f16,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f1,f16,f1,f26
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f26.f64));
	// fnmsubs f26,f18,f10,f23
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f10.f64 - ctx.f23.f64)));
	// lfs f23,896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 896);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f27,f27,f0,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 + ctx.f25.f64));
	// lfs f25,904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 904);
	ctx.f25.f64 = double(temp.f32);
	// fadds f18,f23,f25
	ctx.f18.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// lfs f25,1156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1156);
	ctx.f25.f64 = double(temp.f32);
	// lfs f23,1464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1464);
	ctx.f23.f64 = double(temp.f32);
	// fadds f16,f23,f25
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// lfs f25,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f25.f64 = double(temp.f32);
	// fmr f24,f25
	ctx.f24.f64 = ctx.f25.f64;
	// lfs f25,1068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1068);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f27,f17,f10,f27
	ctx.f27.f64 = double(float(-(ctx.f17.f64 * ctx.f10.f64 - ctx.f27.f64)));
	// fmsubs f22,f16,f25,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f25.f64 - ctx.f22.f64));
	// fnmsubs f26,f15,f24,f26
	ctx.f26.f64 = double(float(-(ctx.f15.f64 * ctx.f24.f64 - ctx.f26.f64)));
	// lfs f17,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f26,f14,f17,f26
	ctx.f26.f64 = double(float(-(ctx.f14.f64 * ctx.f17.f64 - ctx.f26.f64)));
	// lfs f17,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f27,f17,f10,f27
	ctx.f27.f64 = double(float(-(ctx.f17.f64 * ctx.f10.f64 - ctx.f27.f64)));
	// lfs f17,2872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2872);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f17,f17,f29,f22
	ctx.f17.f64 = double(float(-(ctx.f17.f64 * ctx.f29.f64 - ctx.f22.f64)));
	// lfs f22,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f26,f21,f24,f26
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f24.f64 - ctx.f26.f64)));
	// fmadds f21,f19,f22,f27
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 + ctx.f27.f64));
	// lfs f22,1300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1300);
	ctx.f22.f64 = double(temp.f32);
	// lfs f27,2880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2880);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f19,f27,f22,f17
	ctx.f19.f64 = double(float(-(ctx.f27.f64 * ctx.f22.f64 - ctx.f17.f64)));
	// lfs f27,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f1,f1,f27,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64 + ctx.f26.f64));
	// fmadds f26,f20,f0,f21
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f21.f64));
	// lfs f21,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f20,f18,f21,f19
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f21.f64 + ctx.f19.f64));
	// fadds f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// stfs f1,4564(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4564, temp.u32);
	// lfs f1,2904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2904);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f1,f29
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f29.f64));
	// lfs f1,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f28,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 * ctx.f1.f64));
	// lfs f26,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f26.f64 = double(temp.f32);
	// stfs f1,172(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fmuls f18,f26,f1
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// lfs f1,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f17,f1,f25
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// lfs f25,912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 912);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f19,f25,f21,f19
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f21.f64 - ctx.f19.f64));
	// lfs f25,1988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1988);
	ctx.f25.f64 = double(temp.f32);
	// lfs f21,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f21,f25
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f25.f64));
	// lfs f21,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f28,f21
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// stfs f21,232(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fmuls f15,f26,f21
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// lfs f21,1004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1004);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f19,f18,f21,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f21.f64 + ctx.f19.f64));
	// lfs f26,1236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1236);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f21,f30,f30
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// lfs f18,1320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1320);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f20,f17,f26,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 + ctx.f20.f64));
	// lfs f17,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f26,f1,f26,f23
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f26.f64 + ctx.f23.f64));
	// stfs f21,1732(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1732, temp.u32);
	// fmuls f1,f31,f31
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// lfs f23,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f21,f21,f17,f18
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f17.f64 - ctx.f18.f64)));
	// lfs f17,2952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2952);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,1752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1752);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f18.f64));
	// fmuls f17,f16,f28
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// fmuls f16,f1,f23
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// lfs f23,2920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2920);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f22,f23,f22,f19
	ctx.f22.f64 = double(float(-(ctx.f23.f64 * ctx.f22.f64 - ctx.f19.f64)));
	// lfs f23,1004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1004);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f20,f15,f23,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f23.f64 + ctx.f20.f64));
	// lfs f23,924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 924);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f28
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// lfs f19,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f6,f1
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// stfs f23,1740(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1740, temp.u32);
	// fmuls f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f19.f64));
	// fmuls f17,f16,f28
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// lfs f16,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f21,f21,f23,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f23.f64 + ctx.f18.f64));
	// lfs f18,1156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1156);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f26,f18
	ctx.f18.f64 = double(float(ctx.f26.f64 + ctx.f18.f64));
	// lfs f26,984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 984);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f22,f26,f16,f22
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f16.f64 + ctx.f22.f64));
	// lfs f26,920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 920);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// lfs f26,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f14,f26
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f26.f64));
	// lfs f26,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f26.f64 = double(temp.f32);
	// lfs f14,928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 928);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f20,f14,f26,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f26.f64 + ctx.f20.f64));
	// fmsubs f21,f21,f25,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f25.f64 - ctx.f19.f64));
	// lfs f19,1244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1244);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f28
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f28.f64));
	// lfs f14,944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 944);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f17,f17,f27,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f27.f64 + ctx.f16.f64));
	// fmadds f22,f14,f26,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f26.f64 + ctx.f22.f64));
	// lfs f26,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f15,f0
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,2888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2888);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f20,f15,f26,f20
	ctx.f20.f64 = double(float(-(ctx.f15.f64 * ctx.f26.f64 - ctx.f20.f64)));
	// lfs f15,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f21,f19,f15,f21
	ctx.f21.f64 = double(float(-(ctx.f19.f64 * ctx.f15.f64 - ctx.f21.f64)));
	// lfs f19,2936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2936);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f22,f19,f26,f22
	ctx.f22.f64 = double(float(-(ctx.f19.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// lfs f19,1748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1748);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f25
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f25.f64));
	// lfs f25,1996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1996);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f17,f17,f2,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 - ctx.f16.f64));
	// lfs f16,1060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1060);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f25,f16
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f16.f64));
	// lfs f25,2896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2896);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f25,f26,f20
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f26.f64 - ctx.f20.f64)));
	// stfs f25,4568(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4568, temp.u32);
	// fmuls f25,f2,f23
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f23,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f22,f18,f23,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f23.f64 + ctx.f22.f64));
	// lfs f23,1720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1720);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f21,f19,f20,f21
	ctx.f21.f64 = double(float(-(ctx.f19.f64 * ctx.f20.f64 - ctx.f21.f64)));
	// lfs f19,2968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2968);
	ctx.f19.f64 = double(temp.f32);
	// stfs f21,4572(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4572, temp.u32);
	// fmuls f23,f23,f10
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// lfs f21,996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 996);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f10
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// stfs f21,1748(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1748, temp.u32);
	// lfs f20,1820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1820);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,1064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1064);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f21.f64));
	// stfs f23,1320(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1320, temp.u32);
	// fmadds f20,f16,f27,f17
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f27.f64 + ctx.f17.f64));
	// fnmsubs f22,f19,f26,f22
	ctx.f22.f64 = double(float(-(ctx.f19.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// lfs f19,2976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2976);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f21,f21,f27,f20
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f27.f64 - ctx.f20.f64)));
	// fnmsubs f26,f19,f26,f22
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// stfs f26,4576(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4576, temp.u32);
	// fmuls f26,f2,f1
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f22,1756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1756);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f6,f22
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// lfs f22,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f19,f26,f22
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f22.f64));
	// lfs f26,2004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2004);
	ctx.f26.f64 = double(temp.f32);
	// lfs f22,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f18,f26,f0,f22
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f22.f64));
	// lfs f26,2912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2912);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f26,f3
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// lfs f26,1200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1200);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// lfs f22,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f22.f64 = double(temp.f32);
	// stfs f26,1156(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1156, temp.u32);
	// fmuls f19,f19,f28
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f28.f64));
	// fmadds f16,f26,f22,f23
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f22.f64 + ctx.f23.f64));
	// lfs f26,2020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2020);
	ctx.f26.f64 = double(temp.f32);
	// lfs f23,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f26,f23
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// lfs f23,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f21,f20,f23,f21
	ctx.f21.f64 = double(float(-(ctx.f20.f64 * ctx.f23.f64 - ctx.f21.f64)));
	// lfs f23,936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 936);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f20,f2,f23
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f23,1828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1828);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f26,f23
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// lfs f23,1112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f28
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// stfs f23,1756(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1756, temp.u32);
	// fmuls f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64));
	// fnmsubs f21,f15,f10,f21
	ctx.f21.f64 = double(float(-(ctx.f15.f64 * ctx.f10.f64 - ctx.f21.f64)));
	// fmadds f23,f23,f22,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 + ctx.f17.f64));
	// lfs f22,1764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1764);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,1292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1292);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// fmuls f17,f6,f17
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// lfs f6,1208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1208);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// stfs f6,1764(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1764, temp.u32);
	// fmuls f19,f2,f6
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f6,1748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1748);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// fadds f23,f23,f6
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f6.f64));
	// lfs f15,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f15.f64 = double(temp.f32);
	// lfs f6,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f21,f14,f0,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 + ctx.f21.f64));
	// fmuls f6,f6,f15
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f15.f64));
	// lfs f15,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f30,f18,f26,f27
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f26.f64 - ctx.f27.f64));
	// lfs f26,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// lfs f27,3032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3032);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f2,f27
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// lfs f18,3008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3008);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f2,f18
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// lfs f14,3000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3000);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f2,f14
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// fnmsubs f22,f22,f0,f21
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f21.f64)));
	// fmadds f6,f15,f10,f6
	ctx.f6.f64 = double(float(ctx.f15.f64 * ctx.f10.f64 + ctx.f6.f64));
	// lfs f15,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f21,f16,f2,f30
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f2.f64 + ctx.f30.f64));
	// lfs f30,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f25,f15
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f15.f64));
	// lfs f16,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// fmadds f22,f17,f10,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f22.f64));
	// lfs f17,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// stfs f6,996(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 996, temp.u32);
	// fnmsubs f24,f20,f24,f21
	ctx.f24.f64 = double(float(-(ctx.f20.f64 * ctx.f24.f64 - ctx.f21.f64)));
	// lfs f21,1532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1532);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f6,f21,f28
	ctx.f6.f64 = double(float(ctx.f21.f64 * ctx.f28.f64));
	// stfs f6,1724(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1724, temp.u32);
	// fmuls f17,f25,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f17.f64));
	// fmuls f21,f2,f6
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f6,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f25,f25,f6
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// lfs f6,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f30,f6
	ctx.f20.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// lfs f30,1740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1740);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f6,f26,f10,f22
	ctx.f6.f64 = double(float(-(ctx.f26.f64 * ctx.f10.f64 - ctx.f22.f64)));
	// fmadds f26,f23,f2,f24
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f24.f64));
	// lfs f23,996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 996);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f24,f23,f30,f6
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f30.f64 + ctx.f6.f64));
	// lfs f30,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f26,f19,f30,f26
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f30.f64 - ctx.f26.f64)));
	// lfs f6,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f6.f64 = double(temp.f32);
	// lfs f19,1240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1240);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f24,f15,f6,f24
	ctx.f24.f64 = double(float(-(ctx.f15.f64 * ctx.f6.f64 - ctx.f24.f64)));
	// fnmsubs f27,f27,f10,f26
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f10.f64 - ctx.f26.f64)));
	// lfs f26,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f26,f17,f26,f24
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f26.f64 - ctx.f24.f64)));
	// fnmsubs f27,f18,f3,f27
	ctx.f27.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f27.f64)));
	// fmadds f25,f25,f6,f26
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f26.f64));
	// lfs f6,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f27,f16,f6,f27
	ctx.f27.f64 = double(float(-(ctx.f16.f64 * ctx.f6.f64 - ctx.f27.f64)));
	// lfs f26,3152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3152);
	ctx.f26.f64 = double(temp.f32);
	// lfs f16,1732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1732);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f27,f14,f10,f27
	ctx.f27.f64 = double(float(-(ctx.f14.f64 * ctx.f10.f64 - ctx.f27.f64)));
	// fnmsubs f30,f21,f30,f27
	ctx.f30.f64 = double(float(-(ctx.f21.f64 * ctx.f30.f64 - ctx.f27.f64)));
	// fmadds f24,f20,f6,f30
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 + ctx.f30.f64));
	// lfs f6,976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 976);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f27,f6,f11
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f6,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f6.f64 = double(temp.f32);
	// lfs f30,2144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2144);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f23,f6,f30
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f6,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f22,f26,f6
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// lfs f26,1024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1024);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f21,f26,f11
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f26,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f20,f27,f26
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// lfs f27,2136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2136);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f27,f19
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// lfs f27,3168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3168);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f27,f11
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// lfs f27,3128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3128);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f22,f27,f7,f22
	ctx.f22.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 + ctx.f22.f64));
	// lfs f27,1008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1008);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f11,f27
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f27.f64));
	// lfs f27,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f23,f23,f3,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 + ctx.f20.f64));
	// lfs f15,868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 868);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f3,f19,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// lfs f19,3040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3040);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f22,f19,f6,f22
	ctx.f22.f64 = double(float(-(ctx.f19.f64 * ctx.f6.f64 - ctx.f22.f64)));
	// lfs f14,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f15,f11
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// lfs f6,3136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3136);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f1,f27
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// fmuls f16,f16,f27
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f27.f64));
	// fmuls f19,f6,f11
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f6,660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 660);
	ctx.f6.f64 = double(temp.f32);
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// stfs f25,4580(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4580, temp.u32);
	// lfs f25,3104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3104);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f11
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// fnmsubs f26,f21,f26,f23
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f26.f64 - ctx.f23.f64)));
	// lfs f23,924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 924);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f27.f64));
	// lfs f23,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f3,f22,f11,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 + ctx.f3.f64));
	// lfs f22,3120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3120);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// fmuls f21,f20,f6
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// lfs f20,3080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3080);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f16,f6
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmuls f20,f11,f20
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f20.f64));
	// fmadds f26,f18,f14,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f14.f64 + ctx.f26.f64));
	// lfs f18,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f6,f27,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f27,1900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1900);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f3,f15,f18,f3
	ctx.f3.f64 = double(float(-(ctx.f15.f64 * ctx.f18.f64 - ctx.f3.f64)));
	// lfs f15,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 864);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f15.f64));
	// lfs f15,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f30,f30,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f15.f64));
	// lfs f15,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f1,f15
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f15.f64));
	// lfs f1,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f26,f17,f1,f26
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f1.f64 - ctx.f26.f64)));
	// lfs f1,3112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3112);
	ctx.f1.f64 = double(temp.f32);
	// lfs f17,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f19,f19,f4,f3
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f3.f64)));
	// lfs f3,3024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3024);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f1,f17
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// lfs f1,2996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2996);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f14,f3,f7
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// lfs f3,1932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1932);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// stfs f3,660(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 660, temp.u32);
	// fmadds f27,f27,f0,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 + ctx.f18.f64));
	// lfs f18,1040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1040);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f26,f16,f18,f26
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f18.f64 + ctx.f26.f64));
	// lfs f18,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f18.f64 = double(temp.f32);
	// fmr f3,f18
	ctx.f3.f64 = ctx.f18.f64;
	// fnmsubs f23,f23,f4,f19
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f4.f64 - ctx.f19.f64)));
	// lfs f19,3160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3160);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f19,f19,f4,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f4.f64 - ctx.f14.f64));
	// fnmsubs f26,f21,f7,f26
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// fmadds f18,f15,f3,f17
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f3.f64 + ctx.f17.f64));
	// lfs f17,3144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3144);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f24,f22,f7,f23
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 + ctx.f23.f64));
	// lfs f22,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fmadds f6,f6,f22,f26
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f22.f64 + ctx.f26.f64));
	// fnmsubs f30,f30,f3,f24
	ctx.f30.f64 = double(float(-(ctx.f30.f64 * ctx.f3.f64 - ctx.f24.f64)));
	// fnmsubs f6,f20,f7,f6
	ctx.f6.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f6.f64)));
	// fmadds f30,f18,f11,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 + ctx.f30.f64));
	// fmadds f6,f27,f11,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f6.f64));
	// lfs f16,660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 660);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// fadds f27,f6,f30
	ctx.f27.f64 = double(float(ctx.f6.f64 + ctx.f30.f64));
	// lfs f6,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f30,f6,f28
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f6,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f6.f64 = double(temp.f32);
	// stfs f30,264(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fmadds f23,f19,f11,f16
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 + ctx.f16.f64));
	// fnmsubs f26,f17,f7,f23
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f7.f64 - ctx.f23.f64)));
	// lfs f24,2320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2320);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f26,f25,f7,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 + ctx.f26.f64));
	// fmuls f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// lfs f23,1944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1944);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,2144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2144);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f30,f6,f30
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fmuls f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f24.f64));
	// lfs f19,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f19.f64 = double(temp.f32);
	// lfs f25,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f19,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f25.f64));
	// lfs f18,1240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1240);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,1960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1960);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,1140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1140);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f21,2992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2992);
	ctx.f21.f64 = double(temp.f32);
	// lfs f17,1056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1056);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f1,f1,f3
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f23,3056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3056);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,3016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3016);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f23,f23,f11
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f21,3072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3072);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f11
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// lfs f20,3064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3064);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f11
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// lfs f16,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f25,f25,f11
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// stfs f30,1720(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1720, temp.u32);
	// fmadds f1,f24,f17,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f17.f64 + ctx.f1.f64));
	// lfs f17,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f17.f64 = double(temp.f32);
	// lfs f24,3192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3192);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fnmsubs f26,f21,f7,f26
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// fmuls f21,f18,f11
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// lfs f18,1032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1032);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f11
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// fmuls f24,f17,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f24.f64));
	// lfs f17,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f1,f23,f4,f1
	ctx.f1.f64 = double(float(-(ctx.f23.f64 * ctx.f4.f64 - ctx.f1.f64)));
	// lfs f23,1836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1836);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f26,f20,f7,f26
	ctx.f26.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// lfs f20,1608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1608);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// fmadds f24,f23,f17,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f17.f64 + ctx.f24.f64));
	// lfs f23,2984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2984);
	ctx.f23.f64 = double(temp.f32);
	// lfs f17,992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 992);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f23,f23,f11
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fmadds f22,f22,f4,f1
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f4.f64 + ctx.f1.f64));
	// fmuls f1,f31,f31
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmadds f3,f19,f3,f22
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f3.f64 + ctx.f22.f64));
	// fmuls f1,f11,f1
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// fmuls f16,f1,f16
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f16.f64));
	// lfs f1,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f26,f25,f1,f26
	ctx.f26.f64 = double(float(-(ctx.f25.f64 * ctx.f1.f64 - ctx.f26.f64)));
	// lfs f1,1600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1600);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f6,f1
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// lfs f25,3176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3176);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f14,f25,f11
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// lfs f25,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// stfs f1,472(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// lfs f25,3096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3096);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f22,f25,f11
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// lfs f25,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f26,f18,f25,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f25.f64 + ctx.f26.f64));
	// lfs f25,3088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3088);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f19,f25,f11
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// lfs f25,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f1,f6,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// fmuls f18,f1,f25
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// lfs f25,1092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1092);
	ctx.f25.f64 = double(temp.f32);
	// lfs f1,1772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1772);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// lfs f25,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lfs f25,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f21,f21,f25,f3
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f25.f64 - ctx.f3.f64)));
	// lfs f25,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f25.f64 = double(temp.f32);
	// lfs f3,1584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1584);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f17,f17,f25,f26
	ctx.f17.f64 = double(float(-(ctx.f17.f64 * ctx.f25.f64 - ctx.f26.f64)));
	// fmuls f3,f6,f3
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f26,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f26.f64 = double(temp.f32);
	// stfs f3,996(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 996, temp.u32);
	// fmuls f3,f26,f28
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// stfs f3,212(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fmadds f30,f24,f10,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f30.f64));
	// stfs f1,660(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 660, temp.u32);
	// fmadds f24,f23,f4,f21
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f21.f64));
	// fmuls f26,f6,f3
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f3,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// stfs f3,1772(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1772, temp.u32);
	// stfs f26,488(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fmuls f25,f6,f3
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f3,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f3.f64 = double(temp.f32);
	// fmr f1,f3
	ctx.f1.f64 = ctx.f3.f64;
	// lfs f3,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f21,f20,f3,f30
	ctx.f21.f64 = double(float(-(ctx.f20.f64 * ctx.f3.f64 - ctx.f30.f64)));
	// lfs f30,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f24,f16,f30,f24
	ctx.f24.f64 = double(float(-(ctx.f16.f64 * ctx.f30.f64 - ctx.f24.f64)));
	// stfs f25,412(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fmadds f23,f14,f1,f17
	ctx.f23.f64 = double(float(ctx.f14.f64 * ctx.f1.f64 + ctx.f17.f64));
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f1,f22,f1,f24
	ctx.f1.f64 = double(float(-(ctx.f22.f64 * ctx.f1.f64 - ctx.f24.f64)));
	// lfs f24,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f24.f64 = double(temp.f32);
	// fadds f27,f27,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f23.f64));
	// fnmsubs f23,f15,f3,f21
	ctx.f23.f64 = double(float(-(ctx.f15.f64 * ctx.f3.f64 - ctx.f21.f64)));
	// fnmsubs f1,f19,f7,f1
	ctx.f1.f64 = double(float(-(ctx.f19.f64 * ctx.f7.f64 - ctx.f1.f64)));
	// fmadds f30,f18,f30,f23
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 + ctx.f23.f64));
	// lfs f23,660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 660);
	ctx.f23.f64 = double(temp.f32);
	// fadds f1,f27,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// stfs f1,4584(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4584, temp.u32);
	// lfs f1,1172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1172);
	ctx.f1.f64 = double(temp.f32);
	// lfs f27,996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 996);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f24,f23,f24,f30
	ctx.f24.f64 = double(float(-(ctx.f23.f64 * ctx.f24.f64 - ctx.f30.f64)));
	// lfs f30,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f23,f1,f3
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f3,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f1,f3,f31
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// lfs f3,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f24,f27,f30,f24
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f30.f64 + ctx.f24.f64));
	// lfs f27,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f26,f27
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fmuls f22,f1,f3
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f1,1568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1568);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f21,f6,f1
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,1720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1720);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f1,f27
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// lfs f1,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f1,f31
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// lfs f1,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f1.f64 = double(temp.f32);
	// stfs f26,1240(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1240, temp.u32);
	// fmuls f18,f26,f1
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// lfs f26,1616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1616);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f23,f26,f30,f23
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f30.f64 - ctx.f23.f64));
	// lfs f26,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f22,f22,f26
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f26.f64));
	// lfs f26,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f31,f26
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f26.f64));
	// fmsubs f23,f23,f6,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 - ctx.f22.f64));
	// fmuls f17,f17,f26
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f26.f64));
	// lfs f26,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f25,f26
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// lfs f26,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// stfs f26,416(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fmuls f22,f17,f3
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// lfs f17,2152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2152);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// fmuls f16,f6,f26
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// lfs f26,3004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3004);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f6,f26
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// lfs f26,3184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3184);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f1,f26
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// lfs f26,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f31
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fmuls f26,f26,f1
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// fmuls f27,f16,f27
	ctx.f27.f64 = double(float(ctx.f16.f64 * ctx.f27.f64));
	// lfs f16,1624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1624);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f30,f21,f30,f23
	ctx.f30.f64 = double(float(-(ctx.f21.f64 * ctx.f30.f64 - ctx.f23.f64)));
	// lfs f21,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f23,2352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2352);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f21.f64));
	// lfs f21,3224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3224);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f1,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// lfs f1,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f26,f26,f1,f24
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f1.f64 - ctx.f24.f64)));
	// lfs f1,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// fmuls f15,f15,f31
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// fmadds f24,f17,f1,f16
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f1.f64 + ctx.f16.f64));
	// lfs f16,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f30,f20,f16,f30
	ctx.f30.f64 = double(float(-(ctx.f20.f64 * ctx.f16.f64 - ctx.f30.f64)));
	// lfs f16,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f22,f14,f10,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 - ctx.f22.f64));
	// lfs f20,4280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4280);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f16.f64));
	// lfs f17,1576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1576);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f6,f17
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// lfs f14,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f23,f23,f31
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f31.f64));
	// lfs f16,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f14.f64));
	// lfs f14,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f3
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f3.f64));
	// fmadds f26,f24,f6,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 + ctx.f26.f64));
	// lfs f24,1592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1592);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f30,f19,f10,f30
	ctx.f30.f64 = double(float(-(ctx.f19.f64 * ctx.f10.f64 - ctx.f30.f64)));
	// lfs f19,1520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1520);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f22,f21,f0,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f22.f64));
	// lfs f21,2160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2160);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fmadds f26,f20,f10,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 + ctx.f26.f64));
	// fmadds f20,f18,f0,f30
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f30.f64));
	// lfs f30,3012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3012);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f18,f6,f30
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f30,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f22,f17,f30,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 + ctx.f22.f64));
	// lfs f17,1560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1560);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f6,f17
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// lfs f6,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f21,f21,f31
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f31.f64));
	// fnmsubs f26,f19,f0,f26
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f26.f64)));
	// lfs f19,1840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1840);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f6,f25,f6,f20
	ctx.f6.f64 = double(float(-(ctx.f25.f64 * ctx.f6.f64 - ctx.f20.f64)));
	// lfs f20,2168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2168);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f25,f18,f31
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f31.f64));
	// fnmsubs f30,f24,f30,f22
	ctx.f30.f64 = double(float(-(ctx.f24.f64 * ctx.f30.f64 - ctx.f22.f64)));
	// lfs f22,3256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3256);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f20,f3
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// fmadds f27,f27,f10,f6
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 + ctx.f6.f64));
	// lfs f6,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f30,f21,f0,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f30.f64));
	// lfs f21,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f27,f15,f6,f27
	ctx.f27.f64 = double(float(-(ctx.f15.f64 * ctx.f6.f64 - ctx.f27.f64)));
	// fnmsubs f25,f25,f6,f30
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f6.f64 - ctx.f30.f64)));
	// fmadds f6,f23,f0,f27
	ctx.f6.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f27.f64));
	// lfs f27,1092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1092);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f6,f16,f10,f6
	ctx.f6.f64 = double(float(-(ctx.f16.f64 * ctx.f10.f64 - ctx.f6.f64)));
	// fmadds f6,f14,f0,f6
	ctx.f6.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 + ctx.f6.f64));
	// fadds f26,f26,f6
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f6.f64));
	// lfs f6,3668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3668);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f30,f6,f3
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f6,1180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1180);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f3,f6
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f6,2272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2272);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f6,f27
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f6,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// fmuls f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// fmuls f19,f30,f19
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f19.f64));
	// lfs f30,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f31
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// stfs f30,740(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 740, temp.u32);
	// fmuls f18,f30,f3
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f3.f64));
	// fmsubs f24,f24,f0,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 - ctx.f19.f64));
	// lfs f30,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f30.f64 = double(temp.f32);
	// lfs f19,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f19.f64 = double(temp.f32);
	// lfs f16,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f25,f17,f19,f25
	ctx.f25.f64 = double(float(-(ctx.f17.f64 * ctx.f19.f64 - ctx.f25.f64)));
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// lfs f14,1780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1780);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 * ctx.f27.f64));
	// lfs f14,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f30,f30,f12
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// fmuls f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f14.f64));
	// stfs f17,1780(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1780, temp.u32);
	// lfs f17,1512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1512);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f3
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// lfs f15,1776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1776);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,1896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1896);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// fnmsubs f24,f23,f1,f24
	ctx.f24.f64 = double(float(-(ctx.f23.f64 * ctx.f1.f64 - ctx.f24.f64)));
	// lfs f23,1020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1020);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f3,f23,f3
	ctx.f3.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f14,1768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1768);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,1832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1832);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f19,f19,f28
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f28.f64));
	// fmadds f25,f16,f10,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f25.f64));
	// lfs f16,1072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1072);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f6
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// lfs f6,1760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1760);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// stfs f6,660(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 660, temp.u32);
	// fmuls f14,f14,f28
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f28.f64));
	// fmuls f23,f23,f28
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// fnmsubs f24,f22,f0,f24
	ctx.f24.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// lfs f22,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f1,f27,f1,f25
	ctx.f1.f64 = double(float(-(ctx.f27.f64 * ctx.f1.f64 - ctx.f25.f64)));
	// lfs f25,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f25.f64 = double(temp.f32);
	// lfs f27,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f25,1472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1472);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f22.f64));
	// lfs f22,1864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1864);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f28
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// lfs f28,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f21,f28,f24
	ctx.f28.f64 = double(float(ctx.f21.f64 * ctx.f28.f64 + ctx.f24.f64));
	// lfs f21,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f21.f64));
	// lfs f21,1268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1268);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f1,f17,f0,f1
	ctx.f1.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// lfs f17,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f27,f21,f17,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f17.f64 + ctx.f27.f64));
	// lfs f21,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f21.f64 = double(temp.f32);
	// fmr f6,f21
	ctx.f6.f64 = ctx.f21.f64;
	// lfs f21,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f30,f21,f6,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 + ctx.f30.f64));
	// lfs f21,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f21.f64));
	// lfs f21,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f28,f20,f21,f28
	ctx.f28.f64 = double(float(-(ctx.f20.f64 * ctx.f21.f64 - ctx.f28.f64)));
	// lfs f21,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f5,f21
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f21.f64));
	// stfs f21,996(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 996, temp.u32);
	// lfs f21,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f1,f3,f21,f1
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f21.f64 + ctx.f1.f64));
	// lfs f3,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f3.f64 = double(temp.f32);
	// fadds f27,f27,f3
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// lfs f3,3200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3200);
	ctx.f3.f64 = double(temp.f32);
	// lfs f20,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f5,f3
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f30,f30,f3
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f3.f64));
	// fmuls f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f20.f64));
	// fmadds f20,f18,f0,f28
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f28.f64));
	// lfs f28,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f18,f16,f0,f1
	ctx.f18.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// lfs f1,1780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1780);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f24,f24,f28,f1
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f28.f64 + ctx.f1.f64));
	// lfs f1,2328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2328);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f17,f27,f1,f30
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f30.f64));
	// fnmsubs f27,f15,f6,f20
	ctx.f27.f64 = double(float(-(ctx.f15.f64 * ctx.f6.f64 - ctx.f20.f64)));
	// fadds f26,f26,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f18.f64));
	// lfs f30,1252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1252);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f25,f24,f5,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 + ctx.f25.f64));
	// fnmsubs f24,f19,f30,f27
	ctx.f24.f64 = double(float(-(ctx.f19.f64 * ctx.f30.f64 - ctx.f27.f64)));
	// lfs f27,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f27.f64 = double(temp.f32);
	// lfs f19,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f24,f14,f27,f24
	ctx.f24.f64 = double(float(-(ctx.f14.f64 * ctx.f27.f64 - ctx.f24.f64)));
	// fnmsubs f27,f23,f27,f24
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f27.f64 - ctx.f24.f64)));
	// lfs f24,660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 660);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f6,f24,f6,f27
	ctx.f6.f64 = double(float(-(ctx.f24.f64 * ctx.f6.f64 - ctx.f27.f64)));
	// fnmsubs f6,f22,f30,f6
	ctx.f6.f64 = double(float(-(ctx.f22.f64 * ctx.f30.f64 - ctx.f6.f64)));
	// fadds f6,f26,f6
	ctx.f6.f64 = double(float(ctx.f26.f64 + ctx.f6.f64));
	// stfs f6,4588(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4588, temp.u32);
	// lfs f6,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f30,f5,f6
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,3368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3368);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f27,f1,f6
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// lfs f6,1924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1924);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f6,f5
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f6,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f6.f64 = double(temp.f32);
	// lfs f26,3996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3996);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f26,f6
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// lfs f26,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f22,f5,f26
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f26,996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 996);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f20,f26,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// fmuls f30,f30,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f19.f64));
	// fmuls f19,f27,f6
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f27,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// lfs f27,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f27,f6
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f27,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f23,f23,f27
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f27.f64));
	// lfs f27,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f25,f21,f27,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f27.f64 - ctx.f25.f64)));
	// lfs f21,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f21.f64 = double(temp.f32);
	// lfs f27,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f22,f22,f27
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f27.f64));
	// fmuls f27,f27,f6
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fmuls f21,f30,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// lfs f30,3352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3352);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f16,f5,f30
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f30,3280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3280);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f5,f30
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f30,3296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3296);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f5,f30
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f30,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// fnmsubs f25,f22,f30,f25
	ctx.f25.f64 = double(float(-(ctx.f22.f64 * ctx.f30.f64 - ctx.f25.f64)));
	// lfs f22,3344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3344);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f27,f27,f3
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// fmuls f22,f5,f22
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f22.f64));
	// fmadds f30,f19,f30,f21
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f30.f64 + ctx.f21.f64));
	// lfs f21,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// lfs f19,3288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3288);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f5,f19
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// fnmsubs f25,f16,f12,f25
	ctx.f25.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f25.f64)));
	// lfs f16,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// fnmsubs f28,f24,f28,f30
	ctx.f28.f64 = double(float(-(ctx.f24.f64 * ctx.f28.f64 - ctx.f30.f64)));
	// lfs f30,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f24,f21,f30
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// lfs f30,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f21,f30,f6
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// lfs f30,3320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3320);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f16,f5,f30
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f30,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f25,f14,f30,f25
	ctx.f25.f64 = double(float(-(ctx.f14.f64 * ctx.f30.f64 - ctx.f25.f64)));
	// lfs f14,1124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1124);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f1,f1,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f14.f64));
	// lfs f14,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f28,f23,f14,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f14.f64 + ctx.f28.f64));
	// lfs f23,720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 720);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// fmuls f3,f21,f3
	ctx.f3.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// lfs f21,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f5,f21
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f21.f64));
	// fmuls f14,f5,f14
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// fmadds f25,f19,f12,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 + ctx.f25.f64));
	// fmuls f19,f1,f6
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmadds f1,f20,f30,f28
	ctx.f1.f64 = double(float(ctx.f20.f64 * ctx.f30.f64 + ctx.f28.f64));
	// lfs f30,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f28,f5,f30
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f30,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f30.f64 = double(temp.f32);
	// lfs f20,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f30,f20
	ctx.f20.f64 = double(float(ctx.f30.f64 * ctx.f20.f64));
	// lfs f30,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f27,f27,f12,f25
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f12.f64 - ctx.f25.f64)));
	// fnmsubs f1,f18,f30,f1
	ctx.f1.f64 = double(float(-(ctx.f18.f64 * ctx.f30.f64 - ctx.f1.f64)));
	// lfs f18,3052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3052);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f25,f20,f5
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f5.f64));
	// lfs f20,3044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3044);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f6,f17,f6,f27
	ctx.f6.f64 = double(float(ctx.f17.f64 * ctx.f6.f64 + ctx.f27.f64));
	// lfs f27,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f27.f64 = double(temp.f32);
	// lfs f17,1656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1656);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f1,f15,f12,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f1.f64));
	// lfs f15,1640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1640);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f6,f3,f27,f6
	ctx.f6.f64 = double(float(-(ctx.f3.f64 * ctx.f27.f64 - ctx.f6.f64)));
	// lfs f3,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f27,f22,f12,f1
	ctx.f27.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// lfs f1,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f22,f19,f1,f6
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f1.f64 + ctx.f6.f64));
	// lfs f6,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f6.f64 = double(temp.f32);
	// lfs f19,3684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3684);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f27,f24,f3,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 + ctx.f27.f64));
	// fmadds f24,f14,f6,f22
	ctx.f24.f64 = double(float(ctx.f14.f64 * ctx.f6.f64 + ctx.f22.f64));
	// lfs f22,4160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4160);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f6
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// lfs f14,3060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3060);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f3,f26,f3,f27
	ctx.f3.f64 = double(float(-(ctx.f26.f64 * ctx.f3.f64 - ctx.f27.f64)));
	// lfs f27,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,3036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3036);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f30,f17,f30,f22
	ctx.f30.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 + ctx.f22.f64));
	// lfs f17,1648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1648);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f3,f16,f27,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 * ctx.f27.f64 + ctx.f3.f64));
	// lfs f27,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f27.f64 = double(temp.f32);
	// lfs f16,1688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1688);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f15,1680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1680);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f12
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fnmsubs f3,f23,f12,f3
	ctx.f3.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f3.f64)));
	// lfs f23,1672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1672);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f3,f21,f27,f3
	ctx.f3.f64 = double(float(-(ctx.f21.f64 * ctx.f27.f64 - ctx.f3.f64)));
	// lfs f27,3676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3676);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f28,f28,f6,f3
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f6.f64 + ctx.f3.f64));
	// lfs f3,3028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3028);
	ctx.f3.f64 = double(temp.f32);
	// fadds f27,f3,f27
	ctx.f27.f64 = double(float(ctx.f3.f64 + ctx.f27.f64));
	// lfs f3,1940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1940);
	ctx.f3.f64 = double(temp.f32);
	// lfs f6,1552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1552);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f26,f26,f3
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// fmuls f21,f6,f3
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f6,1132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1132);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// fmuls f17,f6,f17
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// fmuls f14,f6,f14
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// fmuls f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// fmuls f23,f23,f3
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fmuls f27,f27,f3
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// fmuls f22,f21,f12
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfs f21,4004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4004);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// fmuls f27,f27,f12
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fmsubs f30,f30,f6,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f6.f64 - ctx.f22.f64));
	// lfs f22,1348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1348);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// lfs f6,1328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1328);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f27,f26,f1,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 - ctx.f27.f64));
	// lfs f1,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f1.f64 = double(temp.f32);
	// lfs f26,1844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1844);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f6,f1,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f26,f1,f26
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// lfs f1,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f1.f64 = double(temp.f32);
	// stfs f6,324(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fmr f6,f1
	ctx.f6.f64 = ctx.f1.f64;
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f28,f25,f1,f28
	ctx.f28.f64 = double(float(-(ctx.f25.f64 * ctx.f1.f64 - ctx.f28.f64)));
	// fmadds f16,f16,f6,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 + ctx.f15.f64));
	// fnmsubs f30,f18,f6,f30
	ctx.f30.f64 = double(float(-(ctx.f18.f64 * ctx.f6.f64 - ctx.f30.f64)));
	// fnmsubs f27,f23,f6,f27
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f6.f64 - ctx.f27.f64)));
	// lfs f6,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f25,f5,f6
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,1132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1132);
	ctx.f6.f64 = double(temp.f32);
	// lfs f1,3692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3692);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f26,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmuls f23,f6,f1
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,3068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3068);
	ctx.f1.f64 = double(temp.f32);
	// lfs f18,4224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4224);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f1,f18
	ctx.f18.f64 = double(float(ctx.f1.f64 + ctx.f18.f64));
	// lfs f1,1664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1664);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f6,f1
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f17,f17,f1,f30
	ctx.f17.f64 = double(float(-(ctx.f17.f64 * ctx.f1.f64 - ctx.f30.f64)));
	// lfs f6,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f6.f64 = double(temp.f32);
	// lfs f30,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f27,f20,f6,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 + ctx.f27.f64));
	// lfs f20,1912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1912);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f28,f25,f6,f28
	ctx.f28.f64 = double(float(-(ctx.f25.f64 * ctx.f6.f64 - ctx.f28.f64)));
	// lfs f25,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f26,f30,f0,f26
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 - ctx.f26.f64));
	// lfs f30,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f20,f30,f20
	ctx.f20.f64 = double(float(ctx.f30.f64 * ctx.f20.f64));
	// fmuls f25,f5,f25
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// fmuls f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// fmadds f17,f16,f3,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 + ctx.f17.f64));
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f27,f19,f16,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 + ctx.f27.f64));
	// lfs f16,824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 824);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,1632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1632);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fmadds f26,f20,f0,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f26.f64));
	// lfs f20,1892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1892);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f16.f64));
	// lfs f16,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f25,f25,f16,f28
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f16.f64 - ctx.f28.f64)));
	// lfs f28,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f30,f28
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// lfs f28,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f23,f23,f6,f17
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f6.f64 - ctx.f17.f64)));
	// fnmsubs f27,f21,f28,f27
	ctx.f27.f64 = double(float(-(ctx.f21.f64 * ctx.f28.f64 - ctx.f27.f64)));
	// lfs f28,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f28.f64 = double(temp.f32);
	// lfs f21,1956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1956);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f28,f21
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// fnmsubs f26,f20,f0,f26
	ctx.f26.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f26.f64)));
	// lfs f20,1356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1356);
	ctx.f20.f64 = double(temp.f32);
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfs f25,4592(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4592, temp.u32);
	// lfs f24,1496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1496);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f25,f18,f12,f23
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 + ctx.f23.f64));
	// lfs f23,1480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1480);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f6,f14,f6,f27
	ctx.f6.f64 = double(float(-(ctx.f14.f64 * ctx.f6.f64 - ctx.f27.f64)));
	// fnmsubs f27,f16,f0,f26
	ctx.f27.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f26.f64)));
	// fmadds f6,f22,f1,f6
	ctx.f6.f64 = double(float(ctx.f22.f64 * ctx.f1.f64 + ctx.f6.f64));
	// lfs f22,1704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1704);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f6,f15,f1,f6
	ctx.f6.f64 = double(float(-(ctx.f15.f64 * ctx.f1.f64 - ctx.f6.f64)));
	// lfs f1,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f6,f19,f1,f6
	ctx.f6.f64 = double(float(-(ctx.f19.f64 * ctx.f1.f64 - ctx.f6.f64)));
	// lfs f1,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f1.f64 = double(temp.f32);
	// lfs f19,3084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3084);
	ctx.f19.f64 = double(temp.f32);
	// fadds f6,f25,f6
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f6.f64));
	// stfs f6,4596(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4596, temp.u32);
	// lfs f6,3076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3076);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f26,f6,f1
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f6,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f6.f64 = double(temp.f32);
	// lfs f25,1488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1488);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// fmuls f25,f6,f25
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// fmuls f19,f6,f19
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// fmsubs f26,f20,f1,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f1.f64 - ctx.f26.f64));
	// lfs f20,1224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1224);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f28,f28,f20
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f20.f64));
	// lfs f20,3700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3700);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f25,f25,f1
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f1.f64));
	// fmuls f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// fmsubs f25,f26,f6,f25
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f6.f64 - ctx.f25.f64));
	// lfs f26,4012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4012);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f18,f26,f18,f28
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f18.f64 + ctx.f28.f64));
	// fnmsubs f21,f21,f0,f27
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f0.f64 - ctx.f27.f64)));
	// lfs f28,1248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1248);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f25,f24,f1,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f1.f64 - ctx.f25.f64)));
	// lfs f26,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f26.f64 = double(temp.f32);
	// lfs f27,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f26,f28
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// lfs f24,1936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1936);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmadds f26,f26,f24,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 + ctx.f18.f64));
	// lfs f28,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f30,f28
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// lfs f28,3092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3092);
	ctx.f28.f64 = double(temp.f32);
	// lfs f24,1948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1948);
	ctx.f24.f64 = double(temp.f32);
	// lfs f14,1240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1240);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f24,f24,f28
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// stfs f27,660(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 660, temp.u32);
	// lfs f18,1524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1524);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,1660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// fmadds f25,f23,f1,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f25.f64));
	// lfs f23,1696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1696);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f6,f15
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f15.f64));
	// fmuls f27,f27,f28
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// fmadds f28,f14,f28,f26
	ctx.f28.f64 = double(float(ctx.f14.f64 * ctx.f28.f64 + ctx.f26.f64));
	// lfs f26,2012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2012);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f26.f64));
	// lfs f26,3708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3708);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f7
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// lfs f14,3100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3100);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// fmuls f14,f6,f14
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// fnmsubs f25,f22,f1,f25
	ctx.f25.f64 = double(float(-(ctx.f22.f64 * ctx.f1.f64 - ctx.f25.f64)));
	// lfs f22,2280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2280);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f28,f28,f0,f21
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 + ctx.f21.f64));
	// lfs f21,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f22.f64));
	// lfs f21,4168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4168);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f26,f21,f7,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 - ctx.f26.f64));
	// lfs f21,3108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3108);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f13,f21
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// fmadds f25,f20,f1,f25
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f1.f64 + ctx.f25.f64));
	// lfs f20,3132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3132);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// fnmsubs f28,f27,f0,f28
	ctx.f28.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f28.f64)));
	// lfs f27,3716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3716);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f7,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 + ctx.f26.f64));
	// fnmsubs f26,f19,f1,f25
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f1.f64 - ctx.f25.f64)));
	// lfs f25,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f25.f64));
	// lfs f21,3116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3116);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f28,f18,f1,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f1.f64 + ctx.f28.f64));
	// lfs f18,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f27,f21,f4,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 + ctx.f27.f64));
	// lfs f21,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f26,f17,f0,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f26.f64));
	// fnmsubs f28,f23,f1,f28
	ctx.f28.f64 = double(float(-(ctx.f23.f64 * ctx.f1.f64 - ctx.f28.f64)));
	// lfs f23,3124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3124);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f26,f16,f0,f26
	ctx.f26.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f26.f64)));
	// fmadds f28,f14,f1,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 * ctx.f1.f64 + ctx.f28.f64));
	// fnmsubs f26,f24,f0,f26
	ctx.f26.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f26.f64)));
	// fmadds f26,f15,f1,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f1.f64 + ctx.f26.f64));
	// fmadds f30,f30,f0,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 + ctx.f26.f64));
	// fnmsubs f30,f22,f0,f30
	ctx.f30.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f30.f64)));
	// lfs f22,3724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3724);
	ctx.f22.f64 = double(temp.f32);
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f30,4600(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4600, temp.u32);
	// lfs f30,4020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4020);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f26,f30,f13
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// lfs f30,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f30.f64 = double(temp.f32);
	// lfs f28,1856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1856);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f24,f28,f30
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// lfs f30,1132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1132);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// fmuls f22,f22,f30
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// lfs f30,1288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1288);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f21,f30,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// fmuls f30,f19,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// lfs f19,4256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4256);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmuls f26,f26,f7
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// lfs f17,1304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1304);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f27,f27,f13,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 - ctx.f25.f64));
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f17,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f17.f64));
	// lfs f17,2000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2000);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f28,f17
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// lfs f28,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f26,f24,f28,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f28.f64 + ctx.f26.f64));
	// lfs f28,3140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3140);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f24,f13,f28
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f28,3732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3732);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f28,f13
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,3148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3148);
	ctx.f28.f64 = double(temp.f32);
	// lfs f15,4028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4028);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f28,f15
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// lfs f28,3156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3156);
	ctx.f28.f64 = double(temp.f32);
	// lfs f14,3740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3740);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f28,f14
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// lfs f28,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f28.f64 = double(temp.f32);
	// lfs f25,4176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4176);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f21,f30,f28,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f28.f64 - ctx.f21.f64));
	// lfs f28,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,3164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3164);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f25,f13,f25
	ctx.f25.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// fnmsubs f26,f23,f28,f26
	ctx.f26.f64 = double(float(-(ctx.f23.f64 * ctx.f28.f64 - ctx.f26.f64)));
	// lfs f23,3172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3172);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f30,f13,f30
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f30,324(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fadds f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// fmuls f15,f14,f7
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f7.f64));
	// lfs f14,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f14.f64 = double(temp.f32);
	// fmr f30,f14
	ctx.f30.f64 = ctx.f14.f64;
	// fnmsubs f27,f25,f4,f27
	ctx.f27.f64 = double(float(-(ctx.f25.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// fmadds f28,f22,f28,f26
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 + ctx.f26.f64));
	// lfs f26,3180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3180);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f13,f26
	ctx.f26.f64 = double(float(ctx.f13.f64 * ctx.f26.f64));
	// lfs f22,4036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4036);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f13,f22
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f22.f64));
	// fmadds f25,f23,f4,f15
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f15.f64));
	// lfs f23,1540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1540);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f21,f18,f30,f21
	ctx.f21.f64 = double(float(-(ctx.f18.f64 * ctx.f30.f64 - ctx.f21.f64)));
	// lfs f15,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,3748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3748);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f13,f18
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f18.f64));
	// fnmsubs f27,f26,f7,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f7.f64 - ctx.f27.f64)));
	// lfs f26,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// fnmsubs f21,f20,f7,f28
	ctx.f21.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f28.f64)));
	// lfs f28,3188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3188);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f20,f28,f13
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f28,f26
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f26.f64));
	// lfs f28,2100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2100);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f31,f28
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmadds f28,f28,f15,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f15.f64 + ctx.f25.f64));
	// lfs f25,3756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3756);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f25.f64));
	// lfs f15,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f23,f19,f4,f21
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f21.f64)));
	// lfs f19,1192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1192);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f19.f64));
	// lfs f19,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f15.f64));
	// fmadds f28,f28,f13,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 + ctx.f27.f64));
	// lfs f27,1412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1412);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// lfs f25,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f17,f25,f23
	ctx.f25.f64 = double(float(-(ctx.f17.f64 * ctx.f25.f64 - ctx.f23.f64)));
	// lfs f23,1304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1304);
	ctx.f23.f64 = double(temp.f32);
	// lfs f17,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f23,f23,f17,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f17.f64 + ctx.f21.f64));
	// lfs f21,1668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1668);
	ctx.f21.f64 = double(temp.f32);
	// fadds f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f21.f64));
	// fnmsubs f25,f24,f4,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f4.f64 - ctx.f25.f64)));
	// lfs f24,3196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3196);
	ctx.f24.f64 = double(temp.f32);
	// fadds f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// lfs f24,1380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1380);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f25,f16,f4,f25
	ctx.f25.f64 = double(float(-(ctx.f16.f64 * ctx.f4.f64 - ctx.f25.f64)));
	// fsubs f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// lfs f24,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f27,f26,f30,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f30.f64 - ctx.f27.f64)));
	// fnmsubs f25,f24,f4,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f4.f64 - ctx.f25.f64)));
	// lfs f17,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f17.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f16,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f23,f23,f30,f27
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64 + ctx.f27.f64));
	// fnmsubs f26,f18,f7,f25
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f7.f64 - ctx.f25.f64)));
	// fnmsubs f23,f19,f30,f23
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f30.f64 - ctx.f23.f64)));
	// fmadds f27,f22,f4,f26
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f4.f64 + ctx.f26.f64));
	// lfs f26,1628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1628);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f27,f20,f7,f27
	ctx.f27.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f27.f64)));
	// fadds f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// stfs f28,4604(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4604, temp.u32);
	// lfs f28,1200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1200);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f31
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// fmuls f27,f28,f29
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f29.f64));
	// lfs f28,4064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4064);
	ctx.f28.f64 = double(temp.f32);
	// fadds f25,f26,f28
	ctx.f25.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// lfs f28,3204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3204);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f24,f2,f28
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// lfs f26,1404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1404);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,3764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3764);
	ctx.f28.f64 = double(temp.f32);
	// fadds f22,f26,f28
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// lfs f26,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,3212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3212);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f21,f28,f26
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f26.f64));
	// lfs f28,1556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1556);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f20,f2,f28
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// lfs f28,1208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1208);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f31
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// stfs f28,488(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fmuls f25,f25,f2
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// fmuls f24,f24,f26
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f26.f64));
	// fmsubs f27,f28,f29,f27
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f29.f64 - ctx.f27.f64));
	// lfs f28,1388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1388);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f2,f28
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// lfs f28,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f22,f22,f28,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 + ctx.f21.f64));
	// fmuls f21,f20,f28
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f28.f64));
	// lfs f20,1700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1700);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f25,f25,f28,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f28.f64 - ctx.f24.f64));
	// lfs f24,3220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3220);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f2,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// fsubs f27,f27,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f20.f64));
	// lfs f20,4044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4044);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f2,f20
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f20.f64));
	// fmsubs f22,f22,f2,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f2.f64 - ctx.f21.f64));
	// lfs f21,3772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3772);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f29,f27
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f29.f64 + ctx.f27.f64));
	// lfs f27,1788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1788);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f27,f17
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f17.f64));
	// lfs f27,1792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1792);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f16,f16,f27
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f27.f64));
	// lfs f27,-29988(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29988);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f25,f18,f27,f25
	ctx.f25.f64 = double(float(-(ctx.f18.f64 * ctx.f27.f64 - ctx.f25.f64)));
	// lfs f18,4076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4076);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f22,f20,f28,f22
	ctx.f22.f64 = double(float(-(ctx.f20.f64 * ctx.f28.f64 - ctx.f22.f64)));
	// lfs f20,1436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1436);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f2,f18
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// stfs f27,1788(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1788, temp.u32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfs f20,1684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1684);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f2,f20
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f20.f64));
	// fnmsubs f15,f24,f28,f25
	ctx.f15.f64 = double(float(-(ctx.f24.f64 * ctx.f28.f64 - ctx.f25.f64)));
	// lfs f25,1420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1420);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f14,f25,f27
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f24,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,1148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1148);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f22,f18,f26,f22
	ctx.f22.f64 = double(float(-(ctx.f18.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// fmadds f17,f25,f24,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f24.f64 + ctx.f17.f64));
	// lfs f25,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f31
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// stfs f25,1020(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1020, temp.u32);
	// fmuls f16,f16,f24
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f24.f64));
	// lfs f24,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f21,f25,f29,f21
	ctx.f21.f64 = double(float(-(ctx.f25.f64 * ctx.f29.f64 - ctx.f21.f64)));
	// lfs f25,1548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1548);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f18,f2,f25
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfs f25,1192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1192);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f19,f24,f25
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// lfs f24,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f22,f18,f27,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f27.f64 + ctx.f22.f64));
	// fmuls f24,f24,f31
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// lfs f18,1396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1396);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f2,f18
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// fmadds f23,f19,f30,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f30.f64 + ctx.f23.f64));
	// stfs f23,4608(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4608, temp.u32);
	// lfs f23,4084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4084);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,4092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4092);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f24,f24,f29,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 + ctx.f21.f64));
	// fnmsubs f21,f20,f28,f15
	ctx.f21.f64 = double(float(-(ctx.f20.f64 * ctx.f28.f64 - ctx.f15.f64)));
	// lfs f28,3236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3236);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f26,f28,f26,f14
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f26.f64 + ctx.f14.f64));
	// lfs f28,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f20,f17,f28,f16
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f28.f64 - ctx.f16.f64));
	// lfs f17,3780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3780);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// lfs f17,3244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3244);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f24,f17,f29,f24
	ctx.f24.f64 = double(float(-(ctx.f17.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// lfs f17,1944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1944);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f2,f26,f2,f21
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 + ctx.f21.f64));
	// stfs f2,4612(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4612, temp.u32);
	// lfs f2,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f2,f28,f2,f20
	ctx.f2.f64 = double(float(-(ctx.f28.f64 * ctx.f2.f64 - ctx.f20.f64)));
	// stfs f2,4616(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4616, temp.u32);
	// fnmsubs f2,f18,f27,f22
	ctx.f2.f64 = double(float(-(ctx.f18.f64 * ctx.f27.f64 - ctx.f22.f64)));
	// stfs f2,4620(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4620, temp.u32);
	// lfs f2,4052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4052);
	ctx.f2.f64 = double(temp.f32);
	// lfs f28,1636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1636);
	ctx.f28.f64 = double(temp.f32);
	// lfs f26,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f26.f64 = double(temp.f32);
	// lfs f27,3252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3252);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f2,f2,f29,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f29.f64 + ctx.f24.f64));
	// lfs f22,3268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3268);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f27,f13,f27
	ctx.f27.f64 = double(float(ctx.f13.f64 * ctx.f27.f64));
	// lfs f24,3788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3788);
	ctx.f24.f64 = double(temp.f32);
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// lfs f22,3796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3796);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,3276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3276);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,3804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3804);
	ctx.f20.f64 = double(temp.f32);
	// fadds f28,f2,f28
	ctx.f28.f64 = double(float(ctx.f2.f64 + ctx.f28.f64));
	// lfs f2,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f27,f27,f7
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fnmsubs f28,f24,f29,f28
	ctx.f28.f64 = double(float(-(ctx.f24.f64 * ctx.f29.f64 - ctx.f28.f64)));
	// lfs f24,3260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3260);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// fmuls f24,f13,f24
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// fmsubs f22,f22,f7,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 - ctx.f2.f64));
	// lfs f2,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f28,f21,f2,f28
	ctx.f28.f64 = double(float(-(ctx.f21.f64 * ctx.f2.f64 - ctx.f28.f64)));
	// lfs f21,4060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4060);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f13,f21
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// fmsubs f27,f22,f13,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f27.f64));
	// lfs f22,3284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3284);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f20,f20,f2,f28
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f2.f64 + ctx.f28.f64));
	// lfs f28,3292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3292);
	ctx.f28.f64 = double(temp.f32);
	// fadds f19,f28,f19
	ctx.f19.f64 = double(float(ctx.f28.f64 + ctx.f19.f64));
	// lfs f28,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f25,f28
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f28.f64));
	// lfs f28,2184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2184);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f17,f28,f17
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// fmuls f22,f13,f22
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f22.f64));
	// fnmsubs f24,f24,f4,f27
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// lfs f27,1220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1220);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmadds f24,f23,f4,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f24.f64));
	// fmuls f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// lfs f26,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// lfs f25,3300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3300);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f25,f2,f20
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f2.f64 - ctx.f20.f64)));
	// lfs f20,3812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3812);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f19,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f28,f19
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f28,3308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3308);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f23,f13,f28
	ctx.f23.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f28,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f16,f28
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// lfs f15,4100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4100);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f27,f20,f7,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f27.f64));
	// fmadds f2,f15,f2,f25
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64 + ctx.f25.f64));
	// lfs f25,3316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3316);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f24,f21,f7,f24
	ctx.f24.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f24.f64)));
	// lfs f21,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f28
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f28.f64));
	// fmuls f28,f23,f4
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// fmuls f25,f13,f25
	ctx.f25.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// fnmsubs f23,f18,f30,f2
	ctx.f23.f64 = double(float(-(ctx.f18.f64 * ctx.f30.f64 - ctx.f2.f64)));
	// lfs f2,3820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3820);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f27,f2,f7,f27
	ctx.f27.f64 = double(float(-(ctx.f2.f64 * ctx.f7.f64 - ctx.f27.f64)));
	// lfs f2,3324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3324);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f20,f13,f2
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// lfs f2,1132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1132);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f24,f22,f7,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 + ctx.f24.f64));
	// lfs f18,4068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4068);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,3332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3332);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f2,f18
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// fmuls f22,f2,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// lfs f2,3828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3828);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f15,f13,f2
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmadds f2,f26,f30,f23
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f30.f64 + ctx.f23.f64));
	// fmsubs f27,f27,f13,f28
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 - ctx.f28.f64));
	// lfs f28,3340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3340);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f13,f28
	ctx.f26.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f28,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f24,f17,f28,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f28.f64 + ctx.f24.f64));
	// lfs f17,2408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2408);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f23,f16,f30,f2
	ctx.f23.f64 = double(float(-(ctx.f16.f64 * ctx.f30.f64 - ctx.f2.f64)));
	// lfs f2,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f27,f18,f2,f27
	ctx.f27.f64 = double(float(-(ctx.f18.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f18,1880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1880);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,2424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2424);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f28,f19,f28,f24
	ctx.f28.f64 = double(float(-(ctx.f19.f64 * ctx.f28.f64 - ctx.f24.f64)));
	// lfs f19,2192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2192);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f30,f21,f30,f23
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f30.f64 + ctx.f23.f64));
	// lfs f23,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f23.f64 = double(temp.f32);
	// lfs f21,2368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2368);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f27,f15,f4,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 * ctx.f4.f64 + ctx.f27.f64));
	// fnmsubs f28,f25,f7,f28
	ctx.f28.f64 = double(float(-(ctx.f25.f64 * ctx.f7.f64 - ctx.f28.f64)));
	// lfs f25,1572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1572);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// stfs f30,4624(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4624, temp.u32);
	// fnmsubs f27,f26,f7,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f7.f64 - ctx.f27.f64)));
	// lfs f26,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f30,f20,f4,f28
	ctx.f30.f64 = double(float(-(ctx.f20.f64 * ctx.f4.f64 - ctx.f28.f64)));
	// lfs f20,3836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3836);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// fmadds f28,f22,f2,f30
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f2.f64 + ctx.f30.f64));
	// lfs f30,1744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1744);
	ctx.f30.f64 = double(temp.f32);
	// lfs f2,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f2,f30
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// lfs f30,4232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4232);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f24,f6,f30
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f30,1916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1916);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f23,f30,f23
	ctx.f23.f64 = double(float(ctx.f30.f64 * ctx.f23.f64));
	// lfs f30,3348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3348);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f22,f6,f30
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f30,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f21,f21,f30
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// fmuls f2,f2,f18
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// lfs f18,2400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2400);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// fmadds f30,f19,f30,f25
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f30.f64 + ctx.f25.f64));
	// lfs f19,1476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1476);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f25,f24,f10
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// lfs f24,2388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2388);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f19,f19,f10
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// fmadds f30,f30,f0,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 + ctx.f25.f64));
	// lfs f25,2392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2392);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f19,f17,f1,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f1.f64 + ctx.f19.f64));
	// lfs f17,2416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2416);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f25,f13,f25
	ctx.f25.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fmsubs f30,f23,f26,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 - ctx.f30.f64));
	// lfs f26,2432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2432);
	ctx.f26.f64 = double(temp.f32);
	// lfs f23,2440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2440);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f26,f26,f1
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// lfs f16,2448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2448);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f27,f25,f4,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f4.f64 + ctx.f27.f64));
	// fmuls f16,f13,f16
	ctx.f16.f64 = double(float(ctx.f13.f64 * ctx.f16.f64));
	// lfs f14,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f30,f22,f10,f30
	ctx.f30.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 + ctx.f30.f64));
	// lfs f15,1736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1736);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f15.f64));
	// lfs f14,1676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1676);
	ctx.f14.f64 = double(temp.f32);
	// lfs f25,1492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1492);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f26,f17,f10,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f26.f64));
	// fadds f25,f14,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 + ctx.f25.f64));
	// lfs f22,2456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2456);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f23,f23,f10
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// lfs f17,1816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1816);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f22,f13,f22
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f22.f64));
	// lfs f14,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f17.f64));
	// fnmsubs f27,f16,f4,f27
	ctx.f27.f64 = double(float(-(ctx.f16.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// lfs f16,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f30,f21,f16,f30
	ctx.f30.f64 = double(float(-(ctx.f21.f64 * ctx.f16.f64 - ctx.f30.f64)));
	// lfs f16,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f16.f64 = double(temp.f32);
	// lfs f21,2464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2464);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f13,f21
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// fmuls f25,f25,f6
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// fmsubs f26,f26,f6,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f6.f64 - ctx.f23.f64));
	// lfs f23,940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 940);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// lfs f16,1484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1484);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f6,f16
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f16.f64));
	// fmadds f27,f22,f4,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f4.f64 + ctx.f27.f64));
	// lfs f22,1344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1344);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f30,f20,f10,f30
	ctx.f30.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 + ctx.f30.f64));
	// lfs f20,2480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2480);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// fmuls f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// fmadds f26,f25,f1,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f26.f64));
	// lfs f25,2472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2472);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f6,f25
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// fnmsubs f27,f21,f4,f27
	ctx.f27.f64 = double(float(-(ctx.f21.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// fnmsubs f30,f24,f1,f30
	ctx.f30.f64 = double(float(-(ctx.f24.f64 * ctx.f1.f64 - ctx.f30.f64)));
	// fnmsubs f26,f16,f1,f26
	ctx.f26.f64 = double(float(-(ctx.f16.f64 * ctx.f1.f64 - ctx.f26.f64)));
	// fadds f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// stfs f28,4628(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4628, temp.u32);
	// fmadds f30,f19,f6,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f6.f64 + ctx.f30.f64));
	// lfs f27,1508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1508);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f28,f25,f1,f26
	ctx.f28.f64 = double(float(-(ctx.f25.f64 * ctx.f1.f64 - ctx.f26.f64)));
	// fmadds f2,f2,f0,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f30.f64));
	// lfs f30,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f28,f20,f10,f28
	ctx.f28.f64 = double(float(-(ctx.f20.f64 * ctx.f10.f64 - ctx.f28.f64)));
	// lfs f20,2528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2528);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f2,f18,f10,f2
	ctx.f2.f64 = double(float(-(ctx.f18.f64 * ctx.f10.f64 - ctx.f2.f64)));
	// lfs f18,1536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1536);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// lfs f18,1596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1596);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f3,f18
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// fmadds f2,f15,f0,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 + ctx.f2.f64));
	// fnmsubs f2,f17,f0,f2
	ctx.f2.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// lfs f17,2536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2536);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f2,f23,f0,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f2.f64));
	// fnmsubs f23,f22,f1,f2
	ctx.f23.f64 = double(float(-(ctx.f22.f64 * ctx.f1.f64 - ctx.f2.f64)));
	// lfs f2,2488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2488);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,2496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2496);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// lfs f2,1368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1368);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f26,f2,f30
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// lfs f2,1132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1132);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f2,f27
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// lfs f27,1652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1652);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f2,f27
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// lfs f27,2504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2504);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f22,f2,f27
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// lfs f27,1516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1516);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f21,f6,f27
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f27,2512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2512);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f2,f27
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// lfs f27,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f1,f1,f27,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64 + ctx.f26.f64));
	// lfs f26,2520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2520);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f3,f26
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f26.f64));
	// fmuls f22,f22,f27
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f27.f64));
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// fnmsubs f28,f21,f10,f28
	ctx.f28.f64 = double(float(-(ctx.f21.f64 * ctx.f10.f64 - ctx.f28.f64)));
	// lfs f16,1500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1500);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f26,f26,f12,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f22.f64));
	// lfs f21,1340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1340);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f17,f3,f17
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// lfs f15,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f15.f64 = double(temp.f32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// lfs f16,1256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1256);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f25,f25,f30,f1
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f30.f64 - ctx.f1.f64));
	// lfs f1,2552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2552);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// lfs f15,1692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1692);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f1,f15
	ctx.f15.f64 = double(float(ctx.f1.f64 + ctx.f15.f64));
	// lfs f1,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f1.f64 = double(temp.f32);
	// lfs f22,2544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2544);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f3,f22
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// fmadds f20,f20,f0,f28
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f28.f64));
	// lfs f28,2560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2560);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f26,f17,f12,f26
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f12.f64 - ctx.f26.f64)));
	// fmuls f17,f28,f1
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f1.f64));
	// lfs f28,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f31
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// stfs f28,628(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// fmuls f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// fmadds f17,f15,f12,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f17.f64));
	// fmuls f14,f6,f28
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fnmsubs f28,f24,f30,f25
	ctx.f28.f64 = double(float(-(ctx.f24.f64 * ctx.f30.f64 - ctx.f25.f64)));
	// lfs f25,2568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2568);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f3,f25
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// stfs f25,324(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fmadds f21,f21,f1,f26
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 + ctx.f26.f64));
	// lfs f26,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f26,f31
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// lfs f26,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f31
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// stfs f26,1900(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1900, temp.u32);
	// fnmsubs f24,f16,f0,f20
	ctx.f24.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f20.f64)));
	// lfs f20,1604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1604);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f3,f20
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// stfs f25,328(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fmadds f19,f19,f27,f28
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f28.f64));
	// lfs f28,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f31
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// stfs f28,1224(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1224, temp.u32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfs f25,1360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1360);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f15,f2,f25
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfs f25,2576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2576);
	ctx.f25.f64 = double(temp.f32);
	// lfs f2,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f21,f20,f1,f21
	ctx.f21.f64 = double(float(-(ctx.f20.f64 * ctx.f1.f64 - ctx.f21.f64)));
	// fmadds f20,f25,f2,f17
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 + ctx.f17.f64));
	// lfs f25,2584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2584);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f19,f18,f12,f19
	ctx.f19.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f19.f64)));
	// fmuls f16,f6,f28
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f28,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f24,f14,f28,f24
	ctx.f24.f64 = double(float(-(ctx.f14.f64 * ctx.f28.f64 - ctx.f24.f64)));
	// fmuls f18,f3,f25
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f25,1612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1612);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f26,f26,f6
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// fmadds f21,f20,f3,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f3.f64 + ctx.f21.f64));
	// lfs f20,2592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2592);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f22,f22,f12,f19
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f19.f64)));
	// fnmsubs f17,f16,f28,f24
	ctx.f17.f64 = double(float(-(ctx.f16.f64 * ctx.f28.f64 - ctx.f24.f64)));
	// lfs f24,1128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1128);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f16,f3,f25
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f25,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f9,f25
	ctx.f25.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// fmuls f20,f24,f20
	ctx.f20.f64 = double(float(ctx.f24.f64 * ctx.f20.f64));
	// fmadds f28,f26,f28,f17
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f28.f64 + ctx.f17.f64));
	// fnmsubs f26,f16,f1,f21
	ctx.f26.f64 = double(float(-(ctx.f16.f64 * ctx.f1.f64 - ctx.f21.f64)));
	// lfs f21,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f22,f21,f2,f22
	ctx.f22.f64 = double(float(-(ctx.f21.f64 * ctx.f2.f64 - ctx.f22.f64)));
	// fadds f28,f23,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// stfs f28,4632(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4632, temp.u32);
	// fmadds f28,f15,f30,f22
	ctx.f28.f64 = double(float(ctx.f15.f64 * ctx.f30.f64 + ctx.f22.f64));
	// fnmsubs f28,f18,f1,f28
	ctx.f28.f64 = double(float(-(ctx.f18.f64 * ctx.f1.f64 - ctx.f28.f64)));
	// fadds f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// stfs f28,4636(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4636, temp.u32);
	// lfs f28,1352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1352);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f28,f9
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f9.f64));
	// lfs f28,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f28.f64 = double(temp.f32);
	// lfs f23,3248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3248);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f23,f28,f23
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmuls f28,f19,f28
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f28.f64));
	// lfs f18,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f26,f18
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f18.f64));
	// lfs f26,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f26.f64 = double(temp.f32);
	// lfs f21,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,2600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2600);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f22.f64));
	// lfs f21,1392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1392);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f9
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// lfs f15,2608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2608);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,1400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1400);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f9
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f9.f64));
	// lfs f14,1052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1052);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,1324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1324);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmuls f16,f28,f26
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f26.f64));
	// lfs f28,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f9,f28
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f22,f22,f26
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f26.f64));
	// fmuls f21,f21,f12
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmuls f15,f28,f15
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f15.f64));
	// lfs f28,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f20,f20,f28,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f28.f64 - ctx.f18.f64));
	// lfs f18,2616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2616);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f24,f24,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f18.f64));
	// lfs f18,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// lfs f14,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f27,f19,f27,f21
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 - ctx.f21.f64));
	// lfs f19,916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 916);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,2624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2624);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f19,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f19.f64 + ctx.f17.f64));
	// lfs f17,3608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3608);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,2632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2632);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f9,f19
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f19.f64));
	// fmadds f23,f23,f28,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f28.f64 + ctx.f20.f64));
	// lfs f20,3616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3616);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f17,2640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2640);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// lfs f14,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f27,f15,f14,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 * ctx.f14.f64 + ctx.f27.f64));
	// lfs f14,2656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2656);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// lfs f15,2648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2648);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f14,f9
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f9.f64));
	// fmuls f15,f15,f9
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f9.f64));
	// fnmsubs f23,f22,f28,f23
	ctx.f23.f64 = double(float(-(ctx.f22.f64 * ctx.f28.f64 - ctx.f23.f64)));
	// lfs f22,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f27,f24,f28,f27
	ctx.f27.f64 = double(float(-(ctx.f24.f64 * ctx.f28.f64 - ctx.f27.f64)));
	// lfs f24,1384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1384);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f22,f20,f22,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f22.f64 + ctx.f17.f64));
	// lfs f17,3696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3696);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,1376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1376);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f24,f9,f24
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f24.f64));
	// fmuls f20,f9,f20
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f20.f64));
	// fnmsubs f28,f16,f28,f23
	ctx.f28.f64 = double(float(-(ctx.f16.f64 * ctx.f28.f64 - ctx.f23.f64)));
	// lfs f23,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f25,f23
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f23.f64));
	// lfs f16,1796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1796);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f9
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// fnmsubs f27,f18,f12,f27
	ctx.f27.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f27.f64)));
	// lfs f18,3728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3728);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f22,f17,f30,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 + ctx.f22.f64));
	// lfs f17,2664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2664);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f9,f17
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f17.f64));
	// fmuls f18,f9,f18
	ctx.f18.f64 = double(float(ctx.f9.f64 * ctx.f18.f64));
	// fmadds f28,f21,f9,f28
	ctx.f28.f64 = double(float(ctx.f21.f64 * ctx.f9.f64 + ctx.f28.f64));
	// lfs f21,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f21.f64));
	// lfs f21,1408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1408);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f9
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// fnmsubs f27,f14,f2,f27
	ctx.f27.f64 = double(float(-(ctx.f14.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f14,3720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3720);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f9,f14
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f14.f64));
	// fnmsubs f28,f19,f2,f28
	ctx.f28.f64 = double(float(-(ctx.f19.f64 * ctx.f2.f64 - ctx.f28.f64)));
	// fmadds f27,f22,f9,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 + ctx.f27.f64));
	// fmadds f22,f15,f2,f28
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f2.f64 + ctx.f28.f64));
	// fnmsubs f27,f23,f1,f27
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f1.f64 - ctx.f27.f64)));
	// lfs f28,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f23,f20,f28,f22
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f28.f64 - ctx.f22.f64)));
	// lfs f22,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,2336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2336);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f27,f18,f22,f27
	ctx.f27.f64 = double(float(-(ctx.f18.f64 * ctx.f22.f64 - ctx.f27.f64)));
	// lfs f22,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f24,f24,f22,f23
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f22.f64 - ctx.f23.f64)));
	// lfs f22,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f1,f25,f1,f27
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f27.f64));
	// fmadds f27,f17,f2,f24
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 + ctx.f24.f64));
	// lfs f17,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f25,f14,f30,f1
	ctx.f25.f64 = double(float(-(ctx.f14.f64 * ctx.f30.f64 - ctx.f1.f64)));
	// lfs f1,1912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1912);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f2,f16,f2,f27
	ctx.f2.f64 = double(float(-(ctx.f16.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f30,1296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1296);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f18,f30,f18
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f18.f64));
	// lfs f16,1920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1920);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,2044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2044);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f27,f21,f28,f2
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f28.f64 + ctx.f2.f64));
	// lfs f2,2012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2012);
	ctx.f2.f64 = double(temp.f32);
	// fadds f28,f2,f1
	ctx.f28.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// lfs f1,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f31,f26
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f26.f64));
	// lfs f21,1536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1536);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f26,f30,f2
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f2.f64));
	// lfs f2,1884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1884);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f24,f1,f2
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f1,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 812);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f28,f28,f1
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f1.f64));
	// fmuls f23,f1,f2
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f2,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// lfs f30,1312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1312);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f1,f15
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f15.f64));
	// fmuls f22,f2,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// lfs f2,1372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1372);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f21,f21,f2
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f2.f64));
	// lfs f2,16816(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 16816);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f26,f26,f2,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 - ctx.f28.f64));
	// stfs f2,1256(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1256, temp.u32);
	// lfs f2,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f2.f64 = double(temp.f32);
	// lfs f28,1012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1012);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f2,f16
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// fmuls f20,f28,f2
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f2.f64));
	// lfs f28,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f19,f28,f19
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fmadds f30,f17,f30,f21
	ctx.f30.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 + ctx.f21.f64));
	// lfs f21,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f28,f21
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// lfs f28,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f2,f28,f26
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f28.f64 + ctx.f26.f64));
	// lfs f26,1512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1512);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f1,f26
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// lfs f1,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f1.f64 = double(temp.f32);
	// lfs f17,2028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2028);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f2,f17
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// fmadds f1,f24,f1,f28
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f1.f64 + ctx.f28.f64));
	// lfs f24,1076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1076);
	ctx.f24.f64 = double(temp.f32);
	// lfs f28,1308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1308);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f24,f28
	ctx.f28.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// lfs f24,2036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2036);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f2,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// fmsubs f2,f2,f14,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64 - ctx.f26.f64));
	// lfs f14,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f14.f64 = double(temp.f32);
	// lfs f26,3664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3664);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f9,f26
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// fnmsubs f1,f23,f14,f1
	ctx.f1.f64 = double(float(-(ctx.f23.f64 * ctx.f14.f64 - ctx.f1.f64)));
	// lfs f14,1220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1220);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f23,f28,f31
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// lfs f28,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f28,f14
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f14.f64));
	// lfs f28,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f2,f16,f28,f2
	ctx.f2.f64 = double(float(-(ctx.f16.f64 * ctx.f28.f64 - ctx.f2.f64)));
	// lfs f28,1296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1296);
	ctx.f28.f64 = double(temp.f32);
	// lfs f16,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f28,f16
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f16.f64));
	// lfs f28,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f26,f28,f25
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f28.f64 + ctx.f25.f64));
	// lfs f26,1076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1076);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,1956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1956);
	ctx.f25.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fnmsubs f1,f26,f25,f1
	ctx.f1.f64 = double(float(-(ctx.f26.f64 * ctx.f25.f64 - ctx.f1.f64)));
	// lfs f25,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,2268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2268);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// lfs f25,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f2,f24,f25,f2
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f25.f64 - ctx.f2.f64)));
	// lfs f25,1452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1452);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f25
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// lfs f25,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f25.f64 = double(temp.f32);
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// stfs f28,4640(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4640, temp.u32);
	// lfs f28,2052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2052);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f1,f22,f25,f1
	ctx.f1.f64 = double(float(-(ctx.f22.f64 * ctx.f25.f64 - ctx.f1.f64)));
	// lfs f27,1076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1076);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f2,f27,f28,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f28.f64 + ctx.f2.f64));
	// lfs f28,1520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1520);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f30,f30,f25,f1
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f25.f64 + ctx.f1.f64));
	// lfs f1,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f28,f1,f28,f2
	ctx.f28.f64 = double(float(-(ctx.f1.f64 * ctx.f28.f64 - ctx.f2.f64)));
	// lfs f2,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmadds f22,f27,f2,f30
	ctx.f22.f64 = double(float(ctx.f27.f64 * ctx.f2.f64 + ctx.f30.f64));
	// lfs f2,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f30,f26,f2,f28
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 + ctx.f28.f64));
	// lfs f28,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f28.f64 = double(temp.f32);
	// stfs f30,324(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fmr f30,f28
	ctx.f30.f64 = ctx.f28.f64;
	// fnmsubs f28,f20,f30,f22
	ctx.f28.f64 = double(float(-(ctx.f20.f64 * ctx.f30.f64 - ctx.f22.f64)));
	// fmadds f26,f19,f30,f28
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f30.f64 + ctx.f28.f64));
	// lfs f28,-29924(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29924);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f26,f18,f28,f26
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f28.f64 - ctx.f26.f64)));
	// fmadds f22,f21,f30,f26
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f30.f64 + ctx.f26.f64));
	// lfs f26,-29912(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -29912);
	ctx.f26.f64 = double(temp.f32);
	// lfs f21,1256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1256);
	ctx.f21.f64 = double(temp.f32);
	// stfs f26,1796(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1796, temp.u32);
	// fnmsubs f22,f17,f26,f22
	ctx.f22.f64 = double(float(-(ctx.f17.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// lfs f19,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f24,f24,f25,f19
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f25.f64 - ctx.f19.f64)));
	// lfs f25,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f25.f64 = double(temp.f32);
	// lfs f19,1108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f25,f19
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// lfs f25,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f31
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// lfs f17,2680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2680);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f22,f15,f30,f22
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f30.f64 - ctx.f22.f64)));
	// fnmsubs f23,f23,f21,f22
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f21.f64 - ctx.f22.f64)));
	// lfs f21,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f21,f25
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f25.f64));
	// fmadds f28,f14,f28,f23
	ctx.f28.f64 = double(float(ctx.f14.f64 * ctx.f28.f64 + ctx.f23.f64));
	// lfs f23,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f20,f16,f26,f28
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f26.f64 + ctx.f28.f64));
	// lfs f28,2060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2060);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f1,f28
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmuls f28,f31,f31
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fnmsubs f26,f26,f30,f24
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f30.f64 - ctx.f24.f64)));
	// lfs f24,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f28,f23,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// lfs f23,2068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2068);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f1,f23
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// lfs f23,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f23.f64));
	// fmuls f17,f24,f17
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f17.f64));
	// fmuls f28,f28,f30
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// fmadds f26,f22,f30,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f30.f64 + ctx.f26.f64));
	// fmsubs f16,f23,f2,f28
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 - ctx.f28.f64));
	// lfs f28,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f23,f28,f31
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// lfs f28,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f23
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// lfs f28,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f31
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// fmadds f18,f14,f28,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f28.f64 + ctx.f18.f64));
	// lfs f28,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f22,f19,f28,f16
	ctx.f22.f64 = double(float(-(ctx.f19.f64 * ctx.f28.f64 - ctx.f16.f64)));
	// lfs f19,1264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1264);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f26,f24,f19,f26
	ctx.f26.f64 = double(float(-(ctx.f24.f64 * ctx.f19.f64 - ctx.f26.f64)));
	// lfs f19,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f22,f18,f28,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 + ctx.f22.f64));
	// lfs f18,1804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1804);
	ctx.f18.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f16,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f26,f1,f19,f26
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f19.f64 + ctx.f26.f64));
	// lfs f19,1948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1948);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f22,f15,f28,f22
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f28.f64 - ctx.f22.f64)));
	// lfs f15,2092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2092);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f26,f17,f30,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 + ctx.f26.f64));
	// lfs f30,2688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2688);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f22,f30,f29,f22
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 + ctx.f22.f64));
	// lfs f30,1100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1100);
	ctx.f30.f64 = double(temp.f32);
	// lfs f17,2704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2704);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f19,f30,f26
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f30.f64 + ctx.f26.f64));
	// lfs f26,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f18,f18,f26,f22
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f26.f64 + ctx.f22.f64));
	// lfs f22,1976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1976);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f19,f27,f22,f19
	ctx.f19.f64 = double(float(-(ctx.f27.f64 * ctx.f22.f64 - ctx.f19.f64)));
	// lfs f22,-29856(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29856);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f18,f17,f22,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f22.f64 + ctx.f18.f64));
	// lfs f17,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f17.f64 = double(temp.f32);
	// stfs f22,1804(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1804, temp.u32);
	// fmadds f19,f1,f17,f19
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f17.f64 + ctx.f19.f64));
	// lfs f17,2712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2712);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f18,f17,f26,f18
	ctx.f18.f64 = double(float(-(ctx.f17.f64 * ctx.f26.f64 - ctx.f18.f64)));
	// lfs f17,660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 660);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f17,f30,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 + ctx.f19.f64));
	// lfs f17,2720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2720);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f18,f17,f29,f18
	ctx.f18.f64 = double(float(-(ctx.f17.f64 * ctx.f29.f64 - ctx.f18.f64)));
	// lfs f17,1332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1332);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f24,f24,f17,f19
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f17.f64 - ctx.f19.f64)));
	// lfs f19,2728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2728);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f19,f19,f29,f18
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f29.f64 - ctx.f18.f64)));
	// lfs f18,1240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1240);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f30,f18,f30,f24
	ctx.f30.f64 = double(float(-(ctx.f18.f64 * ctx.f30.f64 - ctx.f24.f64)));
	// lfs f24,2736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2736);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f24,f22,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f22.f64 + ctx.f19.f64));
	// lfs f22,940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 940);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,1440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1440);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,2800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2800);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f30,f27,f22,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f22.f64 + ctx.f30.f64));
	// lfs f27,2744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2744);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f24,f27,f29,f24
	ctx.f24.f64 = double(float(-(ctx.f27.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// lfs f22,1432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1432);
	ctx.f22.f64 = double(temp.f32);
	// fadds f30,f20,f30
	ctx.f30.f64 = double(float(ctx.f20.f64 + ctx.f30.f64));
	// stfs f30,4644(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4644, temp.u32);
	// lfs f30,2752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2752);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f27,f30,f2
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f2.f64));
	// lfs f30,-30112(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + -30112);
	ctx.f30.f64 = double(temp.f32);
	// lfs f20,2768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2768);
	ctx.f20.f64 = double(temp.f32);
	// stfs f30,1720(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1720, temp.u32);
	// fmsubs f27,f22,f30,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f30.f64 - ctx.f27.f64));
	// lfs f22,2760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2760);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// lfs f20,2776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2776);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f2,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f2.f64 + ctx.f27.f64));
	// lfs f27,2784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2784);
	ctx.f27.f64 = double(temp.f32);
	// fadds f22,f22,f27
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// lfs f27,2792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2792);
	ctx.f27.f64 = double(temp.f32);
	// fadds f19,f27,f19
	ctx.f19.f64 = double(float(ctx.f27.f64 + ctx.f19.f64));
	// lfs f27,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f23,f27,f23
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// fmuls f27,f27,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f16.f64));
	// lfs f16,2816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2816);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f20,f18,f26,f20
	ctx.f20.f64 = double(float(-(ctx.f18.f64 * ctx.f26.f64 - ctx.f20.f64)));
	// lfs f18,2808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2808);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f18,f18,f29,f24
	ctx.f18.f64 = double(float(-(ctx.f18.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// lfs f24,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fadds f17,f17,f24
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f24.f64));
	// fnmsubs f20,f16,f2,f20
	ctx.f20.f64 = double(float(-(ctx.f16.f64 * ctx.f2.f64 - ctx.f20.f64)));
	// lfs f16,1060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1060);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f19,f19,f29,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f29.f64 + ctx.f18.f64));
	// lfs f18,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f25
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// lfs f25,1288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1288);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f17,f17,f25,f27
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f25.f64 + ctx.f27.f64));
	// lfs f25,-29928(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + -29928);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// lfs f27,1036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1036);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// fnmsubs f20,f27,f25,f20
	ctx.f20.f64 = double(float(-(ctx.f27.f64 * ctx.f25.f64 - ctx.f20.f64)));
	// lfs f15,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f15.f64 = double(temp.f32);
	// lfs f27,1856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1856);
	ctx.f27.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f16,f15,f27,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f27.f64 + ctx.f16.f64));
	// lfs f27,2824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2824);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f19,f27,f26,f19
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f26.f64 + ctx.f19.f64));
	// lfs f27,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// lfs f26,-30276(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + -30276);
	ctx.f26.f64 = double(temp.f32);
	// lfs f14,1028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1028);
	ctx.f14.f64 = double(temp.f32);
	// stfs f26,412(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// stfs f27,1248(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1248, temp.u32);
	// stfs f25,376(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fnmsubs f26,f14,f26,f20
	ctx.f26.f64 = double(float(-(ctx.f14.f64 * ctx.f26.f64 - ctx.f20.f64)));
	// lfs f20,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f20.f64));
	// lfs f16,2832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2832);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f19,f16,f29,f19
	ctx.f19.f64 = double(float(-(ctx.f16.f64 * ctx.f29.f64 - ctx.f19.f64)));
	// fmuls f15,f27,f24
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f24.f64));
	// lfs f27,1304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1304);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// fmadds f26,f22,f2,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f2.f64 + ctx.f26.f64));
	// fmadds f22,f17,f0,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f20.f64));
	// lfs f20,2840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2840);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f29,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f29.f64 + ctx.f19.f64));
	// lfs f19,1424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1424);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f24,f24,f13
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// fmadds f26,f19,f25,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f25.f64 + ctx.f26.f64));
	// lfs f19,928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 928);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f25,f24,f0,f22
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// lfs f24,1416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1416);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f26,f24,f30,f26
	ctx.f26.f64 = double(float(-(ctx.f24.f64 * ctx.f30.f64 - ctx.f26.f64)));
	// lfs f24,2848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2848);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f26,f24,f2,f26
	ctx.f26.f64 = double(float(-(ctx.f24.f64 * ctx.f2.f64 - ctx.f26.f64)));
	// lfs f24,952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 952);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f26,f24,f30,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f30.f64 + ctx.f26.f64));
	// lfs f30,-16900(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -16900);
	ctx.f30.f64 = double(temp.f32);
	// lfs f24,3768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3768);
	ctx.f24.f64 = double(temp.f32);
	// stfs f30,300(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fnmsubs f30,f24,f30,f26
	ctx.f30.f64 = double(float(-(ctx.f24.f64 * ctx.f30.f64 - ctx.f26.f64)));
	// lfs f24,3776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3776);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f26,f23,f28,f30
	ctx.f26.f64 = double(float(-(ctx.f23.f64 * ctx.f28.f64 - ctx.f30.f64)));
	// lfs f30,-29812(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -29812);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,1264(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1264, temp.u32);
	// fmadds f30,f24,f30,f26
	ctx.f30.f64 = double(float(ctx.f24.f64 * ctx.f30.f64 + ctx.f26.f64));
	// fnmsubs f30,f18,f28,f30
	ctx.f30.f64 = double(float(-(ctx.f18.f64 * ctx.f28.f64 - ctx.f30.f64)));
	// fnmsubs f30,f15,f28,f30
	ctx.f30.f64 = double(float(-(ctx.f15.f64 * ctx.f28.f64 - ctx.f30.f64)));
	// lfs f28,3760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3760);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f28,f13
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,2856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2856);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f24,f28,f13
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,1000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1000);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f23,f28,f13
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 968);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f22,f28,f13
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 888);
	ctx.f28.f64 = double(temp.f32);
	// fadds f30,f20,f30
	ctx.f30.f64 = double(float(ctx.f20.f64 + ctx.f30.f64));
	// stfs f30,4648(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4648, temp.u32);
	// lfs f30,3744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3744);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f20,f28,f13
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// fmuls f30,f30,f13
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// lfs f28,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f25,f30,f28,f25
	ctx.f25.f64 = double(float(-(ctx.f30.f64 * ctx.f28.f64 - ctx.f25.f64)));
	// lfs f30,-29980(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29980);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,940(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 940, temp.u32);
	// fmuls f19,f19,f30
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// lfs f30,2864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2864);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f18,f30,f11
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// lfs f30,960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 960);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f17,f30,f13
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// lfs f30,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f25,f26,f28,f25
	ctx.f25.f64 = double(float(-(ctx.f26.f64 * ctx.f28.f64 - ctx.f25.f64)));
	// lfs f26,1928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1928);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f30
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// lfs f26,3752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3752);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f26,f13
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// lfs f26,-29976(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -29976);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,324(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f14,904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 904);
	ctx.f14.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f26,f14,f26,f19
	ctx.f26.f64 = double(float(ctx.f14.f64 * ctx.f26.f64 + ctx.f19.f64));
	// lfs f19,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// lfs f18,1192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1192);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f18.f64));
	// lfs f18,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f25,f24,f18,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f18.f64 - ctx.f25.f64)));
	// lfs f14,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,2880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2880);
	ctx.f18.f64 = double(temp.f32);
	// lfs f24,2872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2872);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f11
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// fmadds f18,f18,f14,f26
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f14.f64 + ctx.f26.f64));
	// lfs f26,-29968(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29968);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,996(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 996, temp.u32);
	// fmsubs f26,f16,f26,f19
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f26.f64 - ctx.f19.f64));
	// lfs f16,1192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1192);
	ctx.f16.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fnmsubs f25,f23,f28,f25
	ctx.f25.f64 = double(float(-(ctx.f23.f64 * ctx.f28.f64 - ctx.f25.f64)));
	// lfs f23,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// lfs f14,1788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1788);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 896);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfs f19,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f27
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f27.f64));
	// fmadds f18,f16,f14,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f14.f64 + ctx.f18.f64));
	// lfs f16,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f26,f24,f16,f26
	ctx.f26.f64 = double(float(-(ctx.f24.f64 * ctx.f16.f64 - ctx.f26.f64)));
	// lfs f16,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f25,f22,f16,f25
	ctx.f25.f64 = double(float(-(ctx.f22.f64 * ctx.f16.f64 - ctx.f25.f64)));
	// lfs f22,1272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1272);
	ctx.f22.f64 = double(temp.f32);
	// lfs f16,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f23,f22,f16,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f16.f64 + ctx.f23.f64));
	// lfs f22,3736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3736);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f13
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmuls f24,f19,f13
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// lfs f19,3784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3784);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f30
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// fmadds f18,f18,f11,f26
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 + ctx.f26.f64));
	// lfs f26,2888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2888);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f11
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f26,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f25,f20,f28,f25
	ctx.f25.f64 = double(float(-(ctx.f20.f64 * ctx.f28.f64 - ctx.f25.f64)));
	// lfs f20,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f23,f26,f20,f23
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 + ctx.f23.f64));
	// lfs f26,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f26.f64 = double(temp.f32);
	// lfs f20,1164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1164);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f26
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// lfs f26,2896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2896);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f26,f11
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f26,-29956(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29956);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,660(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 660, temp.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fnmsubs f19,f19,f26,f18
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f26.f64 - ctx.f18.f64)));
	// lfs f26,3864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3864);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f18,f26,f30
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// lfs f26,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f25,f17,f26,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 + ctx.f25.f64));
	// lfs f17,3856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3856);
	ctx.f17.f64 = double(temp.f32);
	// lfs f26,-30184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30184);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,1892(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1892, temp.u32);
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fmadds f26,f17,f26,f20
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 + ctx.f20.f64));
	// lfs f20,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f20,f16,f20,f19
	ctx.f20.f64 = double(float(-(ctx.f16.f64 * ctx.f20.f64 - ctx.f19.f64)));
	// lfs f19,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f25,f15,f4,f25
	ctx.f25.f64 = double(float(-(ctx.f15.f64 * ctx.f4.f64 - ctx.f25.f64)));
	// fmuls f26,f26,f30
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// fmadds f20,f14,f19,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f19.f64 + ctx.f20.f64));
	// stfs f20,4656(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4656, temp.u32);
	// fnmsubs f25,f21,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// fnmsubs f25,f24,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// fnmsubs f28,f22,f28,f25
	ctx.f28.f64 = double(float(-(ctx.f22.f64 * ctx.f28.f64 - ctx.f25.f64)));
	// lfs f25,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f28,f23,f0,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f28.f64));
	// stfs f28,4652(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4652, temp.u32);
	// lfs f28,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// lfs f25,3792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3792);
	ctx.f25.f64 = double(temp.f32);
	// lfs f21,940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 940);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f25,f25,f30
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f30.f64));
	// lfs f22,944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 944);
	ctx.f22.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f21.f64));
	// lfs f21,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f28,f27,f21,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f21.f64 + ctx.f28.f64));
	// lfs f24,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f24.f64 = double(temp.f32);
	// lfs f21,2904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2904);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// lfs f19,984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 984);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f21,f21,f11
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// lfs f17,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f17.f64 = double(temp.f32);
	// lfs f27,1252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1252);
	ctx.f27.f64 = double(temp.f32);
	// lfs f15,2920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2920);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,1788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1788);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f23,920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 920);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// lfs f25,1764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1764);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f22,f19,f17,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f22.f64));
	// lfs f20,2912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2912);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f28,f13
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 912);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f17,f28,f11
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// lfs f28,936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 936);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f28,f13
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f21,f21,f28
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f28.f64));
	// fmuls f24,f24,f13
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// fmadds f22,f15,f28,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f28.f64 + ctx.f22.f64));
	// lfs f28,1740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1740);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f27,f19,f0,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 + ctx.f27.f64));
	// lfs f19,2928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2928);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f28,f19
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f15,1904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1904);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f30
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f30.f64));
	// fmsubs f21,f17,f14,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f14.f64 - ctx.f21.f64));
	// lfs f17,2936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2936);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f22,f17,f14,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f14.f64 + ctx.f22.f64));
	// lfs f17,1156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1156);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f27,f24,f0,f27
	ctx.f27.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f27.f64)));
	// lfs f24,1320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1320);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f17,f7,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f24.f64));
	// lfs f14,3816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3816);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,3840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3840);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f19,f19,f30
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// fmuls f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// fmuls f14,f14,f30
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f30.f64));
	// lfs f30,1712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1712);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f28,f28,f30
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// lfs f30,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f22,f22,f11,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 + ctx.f21.f64));
	// lfs f21,2960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2960);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f27,f23,f30,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f30.f64 + ctx.f27.f64));
	// lfs f30,-30220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30220);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f26,f18,f30,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 - ctx.f26.f64));
	// stfs f30,1712(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1712, temp.u32);
	// lfs f30,1136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1136);
	ctx.f30.f64 = double(temp.f32);
	// lfs f23,2952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2952);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// lfs f30,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f21,f21,f30
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// lfs f18,2968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2968);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// lfs f28,660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 660);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f18,f11
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// fnmsubs f22,f15,f28,f22
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f28.f64 - ctx.f22.f64)));
	// lfs f28,2976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2976);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f7,f25,f7,f27
	ctx.f7.f64 = double(float(-(ctx.f25.f64 * ctx.f7.f64 - ctx.f27.f64)));
	// fmuls f25,f28,f11
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// lfs f11,1752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1752);
	ctx.f11.f64 = double(temp.f32);
	// lfs f28,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f27,f23,f11,f26
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f11.f64 + ctx.f26.f64));
	// lfs f26,3800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3800);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f11,f31,f31
	ctx.f11.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f26,f26,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmuls f11,f21,f11
	ctx.f11.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// fnmsubs f7,f20,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f20.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// lfs f23,996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 996);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f17,f23,f22
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f23.f64 + ctx.f22.f64));
	// lfs f22,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f11,f11,f22,f27
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f22.f64 - ctx.f27.f64)));
	// lfs f27,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f27.f64 = double(temp.f32);
	// stfs f11,4660(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4660, temp.u32);
	// lfs f11,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f11.f64 = double(temp.f32);
	// lfs f21,3808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3808);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f28
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f28.f64));
	// lfs f28,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f28.f64 = double(temp.f32);
	// lfs f20,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,1756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1756);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f7,f16,f27,f7
	ctx.f7.f64 = double(float(-(ctx.f16.f64 * ctx.f27.f64 - ctx.f7.f64)));
	// lfs f16,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f23,f18,f11,f23
	ctx.f23.f64 = double(float(-(ctx.f18.f64 * ctx.f11.f64 - ctx.f23.f64)));
	// fmadds f7,f24,f13,f7
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f7.f64));
	// fnmsubs f11,f25,f11,f23
	ctx.f11.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f23.f64)));
	// stfs f11,4664(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4664, temp.u32);
	// lfs f11,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f11.f64 = double(temp.f32);
	// lfs f25,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f7,f19,f11,f7
	ctx.f7.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 + ctx.f7.f64));
	// lfs f19,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f7,f14,f25,f7
	ctx.f7.f64 = double(float(-(ctx.f14.f64 * ctx.f25.f64 - ctx.f7.f64)));
	// lfs f14,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f11,f30,f11,f7
	ctx.f11.f64 = double(float(-(ctx.f30.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// lfs f7,1252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1252);
	ctx.f7.f64 = double(temp.f32);
	// lfs f30,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f26,f26,f7,f11
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f7.f64 - ctx.f11.f64)));
	// lfs f7,3824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3824);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f24,f7,f13
	ctx.f24.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f11,1288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1288);
	ctx.f11.f64 = double(temp.f32);
	// lfs f7,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f25,f11,f13
	ctx.f25.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmuls f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// lfs f7,3832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3832);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f23,f7,f13
	ctx.f23.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f7,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f25,f25,f28
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f28.f64));
	// lfs f28,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f20,f28,f20
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f20.f64));
	// lfs f28,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f31
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// fmuls f22,f30,f7
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f7.f64));
	// fmuls f18,f11,f13
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f11,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// fmuls f19,f28,f19
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmsubs f25,f24,f27,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f27.f64 - ctx.f25.f64));
	// lfs f24,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f7
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// lfs f7,1724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1724);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f22,f19,f11,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 - ctx.f22.f64));
	// lfs f19,1748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1748);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f17,f16,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f19.f64));
	// lfs f16,2992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2992);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f7,f13
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f7,2984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2984);
	ctx.f7.f64 = double(temp.f32);
	// fadds f16,f7,f16
	ctx.f16.f64 = double(float(ctx.f7.f64 + ctx.f16.f64));
	// lfs f7,3000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3000);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f15,f7,f13
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f7,976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 976);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f25,f18,f0,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f25.f64));
	// fmadds f22,f7,f14,f22
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f14.f64 + ctx.f22.f64));
	// lfs f7,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f14,f7,f30
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// lfs f7,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// lfs f30,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f30.f64 = double(temp.f32);
	// stfs f7,1272(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1272, temp.u32);
	// fmadds f7,f30,f7,f24
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f7.f64 + ctx.f24.f64));
	// lfs f30,3008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3008);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f24,f30,f13
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// lfs f30,3016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3016);
	ctx.f30.f64 = double(temp.f32);
	// fadds f18,f16,f30
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f30.f64));
	// lfs f16,3024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3024);
	ctx.f16.f64 = double(temp.f32);
	// lfs f30,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f22,f16,f30,f22
	ctx.f22.f64 = double(float(-(ctx.f16.f64 * ctx.f30.f64 - ctx.f22.f64)));
	// fnmsubs f27,f23,f27,f25
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f27.f64 - ctx.f25.f64)));
	// lfs f23,2092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2092);
	ctx.f23.f64 = double(temp.f32);
	// lfs f25,1064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1064);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f7,f7,f11,f22
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f11.f64 + ctx.f22.f64));
	// fmuls f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f25.f64));
	// lfs f23,3040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3040);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// lfs f18,1060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1060);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,3048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3048);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f18,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,3032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3032);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fmadds f27,f21,f18,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f18.f64 + ctx.f27.f64));
	// lfs f18,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f7,f14,f2,f7
	ctx.f7.f64 = double(float(-(ctx.f14.f64 * ctx.f2.f64 - ctx.f7.f64)));
	// fnmsubs f0,f20,f0,f27
	ctx.f0.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f27.f64)));
	// lfs f27,3064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3064);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f7,f23,f29,f7
	ctx.f7.f64 = double(float(ctx.f23.f64 * ctx.f29.f64 + ctx.f7.f64));
	// lfs f20,1240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1240);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f0,f19,f13,f0
	ctx.f0.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f0.f64));
	// lfs f13,3056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3056);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f13,f13,f29,f7
	ctx.f13.f64 = double(float(-(ctx.f13.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// lfs f7,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f7.f64 = double(temp.f32);
	// lfs f19,2108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2108);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f0,f17,f7,f0
	ctx.f0.f64 = double(float(-(ctx.f17.f64 * ctx.f7.f64 - ctx.f0.f64)));
	// lfs f7,1804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1804);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f13,f27,f7,f13
	ctx.f13.f64 = double(float(-(ctx.f27.f64 * ctx.f7.f64 - ctx.f13.f64)));
	// lfs f27,3072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3072);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f0,f15,f10,f0
	ctx.f0.f64 = double(float(-(ctx.f15.f64 * ctx.f10.f64 - ctx.f0.f64)));
	// fnmsubs f13,f27,f7,f13
	ctx.f13.f64 = double(float(-(ctx.f27.f64 * ctx.f7.f64 - ctx.f13.f64)));
	// lfs f27,3080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3080);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f0,f24,f10,f0
	ctx.f0.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f0.f64));
	// fnmsubs f27,f27,f30,f13
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f30.f64 - ctx.f13.f64)));
	// fnmsubs f13,f16,f10,f0
	ctx.f13.f64 = double(float(-(ctx.f16.f64 * ctx.f10.f64 - ctx.f0.f64)));
	// lfs f0,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f13,f25,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f25.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// lfs f25,1116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1116);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f0,f22,f0,f13
	ctx.f0.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f13,3096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3096);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f26,f0
	ctx.f0.f64 = double(float(ctx.f26.f64 + ctx.f0.f64));
	// stfs f0,4668(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4668, temp.u32);
	// lfs f0,3088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3088);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// lfs f26,1024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1024);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f13,f13,f2,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 - ctx.f0.f64));
	// lfs f0,1720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1720);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f26,f26,f0,f13
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// lfs f13,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f24,f25,f13
	ctx.f24.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// lfs f13,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// lfs f25,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f25,f13
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// lfs f13,3104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3104);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f2,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 + ctx.f26.f64));
	// lfs f26,3112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3112);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f27,f26,f29,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f29.f64 - ctx.f27.f64)));
	// lfs f26,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f26.f64));
	// lfs f26,868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 868);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,1308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1308);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f26,f26,f0,f13
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f13,f31,f31
	ctx.f13.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f22,f25,f13
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// lfs f13,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f13.f64 = double(temp.f32);
	// lfs f25,1280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1280);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f21,f25,f13
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// lfs f13,3120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3120);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f27,f13,f30,f27
	ctx.f27.f64 = double(float(ctx.f13.f64 * ctx.f30.f64 + ctx.f27.f64));
	// lfs f13,3128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3128);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f26,f13,f2,f26
	ctx.f26.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 + ctx.f26.f64));
	// lfs f13,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fmuls f21,f21,f2
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f2.f64));
	// fadds f13,f20,f13
	ctx.f13.f64 = double(float(ctx.f20.f64 + ctx.f13.f64));
	// lfs f20,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f20.f64));
	// lfs f19,3136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3136);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f27,f19,f29,f27
	ctx.f27.f64 = double(float(-(ctx.f19.f64 * ctx.f29.f64 - ctx.f27.f64)));
	// lfs f19,1296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1296);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,3144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3144);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f26,f18,f2,f26
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f2.f64 - ctx.f26.f64)));
	// lfs f18,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f21,f13,f1,f21
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 + ctx.f21.f64));
	// lfs f13,3152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3152);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f27,f13,f29,f27
	ctx.f27.f64 = double(float(-(ctx.f13.f64 * ctx.f29.f64 - ctx.f27.f64)));
	// lfs f13,992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 992);
	ctx.f13.f64 = double(temp.f32);
	// lfs f17,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,1176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1176);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f26,f13,f18,f26
	ctx.f26.f64 = double(float(-(ctx.f13.f64 * ctx.f18.f64 - ctx.f26.f64)));
	// lfs f13,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f21,f20,f13,f21
	ctx.f21.f64 = double(float(-(ctx.f20.f64 * ctx.f13.f64 - ctx.f21.f64)));
	// lfs f20,3160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3160);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f29,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f29.f64 + ctx.f27.f64));
	// lfs f18,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f18.f64 = double(temp.f32);
	// lfs f27,1008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1008);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f18,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f18.f64 + ctx.f26.f64));
	// lfs f26,3168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3168);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f27,f26,f2,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f26,1032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1032);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f0,f26,f0,f27
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f27.f64));
	// lfs f27,864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 864);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f26.f64));
	// fmadds f0,f27,f30,f0
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f30.f64 + ctx.f0.f64));
	// lfs f30,3176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3176);
	ctx.f30.f64 = double(temp.f32);
	// lfs f27,1264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1264);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f0,f30,f2,f0
	ctx.f0.f64 = double(float(-(ctx.f30.f64 * ctx.f2.f64 - ctx.f0.f64)));
	// lfs f30,1196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1196);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f0,f24,f11,f0
	ctx.f0.f64 = double(float(ctx.f24.f64 * ctx.f11.f64 + ctx.f0.f64));
	// lfs f24,1504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1504);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f16,f16,f24
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f24.f64));
	// fnmsubs f0,f23,f11,f0
	ctx.f0.f64 = double(float(-(ctx.f23.f64 * ctx.f11.f64 - ctx.f0.f64)));
	// fnmsubs f0,f30,f27,f0
	ctx.f0.f64 = double(float(-(ctx.f30.f64 * ctx.f27.f64 - ctx.f0.f64)));
	// lfs f27,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f27.f64 = double(temp.f32);
	// lfs f30,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f0,f28,f11,f0
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f11.f64 + ctx.f0.f64));
	// lfs f11,1204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1204);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f0,f22,f27,f0
	ctx.f0.f64 = double(float(ctx.f22.f64 * ctx.f27.f64 + ctx.f0.f64));
	// fmadds f0,f11,f30,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f30.f64 + ctx.f0.f64));
	// lfs f30,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f30.f64 = double(temp.f32);
	// lfs f11,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f22,f30,f26
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f26.f64));
	// fmuls f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fadds f0,f20,f0
	ctx.f0.f64 = double(float(ctx.f20.f64 + ctx.f0.f64));
	// stfs f0,4672(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4672, temp.u32);
	// lfs f0,1772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1772);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f28,f0,f30
	ctx.f28.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// lfs f0,2100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2100);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f23,f1,f0
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f0,1100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1100);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f20,f11,f0
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f11,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f18,f11,f24
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f24.f64));
	// lfs f11,1796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1796);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f21,f19,f11,f21
	ctx.f21.f64 = double(float(-(ctx.f19.f64 * ctx.f11.f64 - ctx.f21.f64)));
	// lfs f11,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 * ctx.f24.f64));
	// lfs f14,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f19,f28,f11
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// lfs f28,2260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2260);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f17,f28,f17
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// fmuls f25,f28,f25
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmadds f23,f23,f27,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f27.f64 + ctx.f19.f64));
	// lfs f19,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f19.f64));
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f21,f17,f11,f21
	ctx.f21.f64 = double(float(-(ctx.f17.f64 * ctx.f11.f64 - ctx.f21.f64)));
	// fmuls f17,f15,f11
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// fmuls f15,f28,f30
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// fmsubs f23,f22,f14,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f14.f64 - ctx.f23.f64));
	// lfs f22,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f22.f64));
	// lfs f19,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f26,f26,f19,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f19.f64 + ctx.f21.f64));
	// lfs f21,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f21,f30,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// fnmsubs f25,f25,f11,f26
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f26.f64)));
	// lfs f26,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f31,f26
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f26.f64));
	// lfs f14,1504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1504);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f19,f19,f0,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 - ctx.f17.f64));
	// lfs f17,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f23,f20,f27,f23
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f27.f64 - ctx.f23.f64)));
	// lfs f20,1160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1160);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f14.f64));
	// lfs f14,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f30,f14
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f14.f64));
	// fmuls f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// fmadds f20,f15,f11,f19
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 + ctx.f19.f64));
	// lfs f19,1104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f15,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,2252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2252);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f19.f64));
	// lfs f15,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f23,f18,f15,f23
	ctx.f23.f64 = double(float(-(ctx.f18.f64 * ctx.f15.f64 - ctx.f23.f64)));
	// lfs f18,1236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1236);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f25,f21,f18,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f18.f64 - ctx.f25.f64)));
	// lfs f18,1160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1160);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f18.f64));
	// lfs f18,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,1176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1176);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f20,f14,f18,f20
	ctx.f20.f64 = double(float(-(ctx.f14.f64 * ctx.f18.f64 - ctx.f20.f64)));
	// lfs f14,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f15,f14,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64 + ctx.f28.f64));
	// lfs f28,-30000(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -30000);
	ctx.f28.f64 = double(temp.f32);
	// lfs f14,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,3184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3184);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f23,f16,f28,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f28.f64 + ctx.f23.f64));
	// lfs f16,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f14.f64));
	// lfs f14,1256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1256);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f26,f26,f14,f25
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f14.f64 - ctx.f25.f64)));
	// lfs f14,1296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1296);
	ctx.f14.f64 = double(temp.f32);
	// lfs f25,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f18,f1,f18
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f18.f64));
	// fmuls f25,f14,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// lfs f14,1796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1796);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f21,f21,f14,f20
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f14.f64 - ctx.f20.f64)));
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f14.f64));
	// lfs f14,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f24,f24,f14,f23
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f14.f64 - ctx.f23.f64)));
	// lfs f23,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f26,f15,f11,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 + ctx.f26.f64));
	// fnmsubs f23,f16,f23,f21
	ctx.f23.f64 = double(float(-(ctx.f16.f64 * ctx.f23.f64 - ctx.f21.f64)));
	// lfs f21,1772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1772);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f11,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 + ctx.f20.f64));
	// lfs f20,1048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1048);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f24,f22,f11,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 + ctx.f24.f64));
	// lfs f22,1256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1256);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f23,f25,f22,f23
	ctx.f23.f64 = double(float(-(ctx.f25.f64 * ctx.f22.f64 - ctx.f23.f64)));
	// fmadds f28,f17,f28,f24
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f28.f64 + ctx.f24.f64));
	// lfs f24,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f24.f64 = double(temp.f32);
	// lfs f17,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f28,f19,f13,f28
	ctx.f28.f64 = double(float(-(ctx.f19.f64 * ctx.f13.f64 - ctx.f28.f64)));
	// lfs f19,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f19,828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 828);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f9
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f9.f64));
	// fmadds f28,f18,f27,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f27.f64 + ctx.f28.f64));
	// lfs f18,2244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2244);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// fadds f22,f26,f28
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// lfs f28,3192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3192);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f1,f28
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// lfs f28,1512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1512);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f25,f28,f0
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// lfs f28,1308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1308);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f24,f28,f24
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f24.f64));
	// fmsubs f26,f26,f2,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 - ctx.f25.f64));
	// lfs f25,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f24,f25
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// lfs f24,3200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3200);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f16,f9,f24
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f24.f64));
	// lfs f24,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f28,f9,f28
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f19,f19,f24
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f24.f64));
	// lfs f24,2108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2108);
	ctx.f24.f64 = double(temp.f32);
	// lfs f15,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f24
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f24.f64));
	// lfs f24,1072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1072);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f26,f1,f24,f26
	ctx.f26.f64 = double(float(-(ctx.f1.f64 * ctx.f24.f64 - ctx.f26.f64)));
	// lfs f24,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f20,f20,f24,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f24.f64 + ctx.f17.f64));
	// lfs f17,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f17,f28,f17
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// lfs f28,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f19,f16,f28,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f28.f64 - ctx.f19.f64));
	// lfs f28,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f18,f18,f13,f26
	ctx.f18.f64 = double(float(-(ctx.f18.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// lfs f26,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f20,f26,f28,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f28.f64 + ctx.f20.f64));
	// lfs f26,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f9,f26
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// lfs f28,3208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3208);
	ctx.f28.f64 = double(temp.f32);
	// stfs f26,760(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 760, temp.u32);
	// fnmsubs f19,f17,f25,f19
	ctx.f19.f64 = double(float(-(ctx.f17.f64 * ctx.f25.f64 - ctx.f19.f64)));
	// lfs f25,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f25.f64 = double(temp.f32);
	// lfs f17,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f18,f15,f13,f18
	ctx.f18.f64 = double(float(-(ctx.f15.f64 * ctx.f13.f64 - ctx.f18.f64)));
	// lfs f15,3216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3216);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f20,f25,f17,f20
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f17.f64 + ctx.f20.f64));
	// lfs f25,1280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1280);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f16,f28,f26
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f26.f64));
	// lfs f28,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f28,f14
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f14.f64));
	// lfs f17,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f23,f21,f25,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f25.f64 + ctx.f23.f64));
	// lfs f25,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// fmadds f20,f20,f9,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 + ctx.f19.f64));
	// lfs f19,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f30,f19
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f19.f64));
	// lfs f30,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f31
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// fmuls f21,f14,f25
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// lfs f14,3224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3224);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f18,f1,f14,f18
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f14.f64 + ctx.f18.f64));
	// lfs f25,1544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1544);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f17,f25
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// fmadds f23,f30,f0,f23
	ctx.f23.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 + ctx.f23.f64));
	// lfs f30,1144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1144);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f25,f30,f25
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lfs f30,3232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3232);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f26,f30,f26
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f26.f64));
	// lfs f30,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f18,f30,f0,f18
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 + ctx.f18.f64));
	// lfs f30,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f20,f16,f30,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f30.f64 + ctx.f20.f64));
	// lfs f16,3240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3240);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f28
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// fmadds f27,f19,f27,f23
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f23.f64));
	// lfs f23,3248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3248);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f28,f28,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// lfs f23,3256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3256);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f23,f1,f23,f18
	ctx.f23.f64 = double(float(-(ctx.f1.f64 * ctx.f23.f64 - ctx.f18.f64)));
	// fnmsubs f21,f21,f12,f20
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f12.f64 - ctx.f20.f64)));
	// fadds f27,f22,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// fmadds f23,f17,f13,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f23.f64));
	// fnmsubs f22,f15,f30,f21
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f30.f64 - ctx.f21.f64)));
	// fnmsubs f13,f25,f13,f23
	ctx.f13.f64 = double(float(-(ctx.f25.f64 * ctx.f13.f64 - ctx.f23.f64)));
	// lfs f25,1520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1520);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f26,f26,f30,f22
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f30.f64 - ctx.f22.f64)));
	// fnmsubs f0,f25,f0,f13
	ctx.f0.f64 = double(float(-(ctx.f25.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmadds f13,f16,f30,f26
	ctx.f13.f64 = double(float(ctx.f16.f64 * ctx.f30.f64 + ctx.f26.f64));
	// fadds f0,f27,f0
	ctx.f0.f64 = double(float(ctx.f27.f64 + ctx.f0.f64));
	// stfs f0,4676(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4676, temp.u32);
	// fnmsubs f28,f28,f30,f13
	ctx.f28.f64 = double(float(-(ctx.f28.f64 * ctx.f30.f64 - ctx.f13.f64)));
	// lfs f13,1552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,3264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3264);
	ctx.f0.f64 = double(temp.f32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// lfs f13,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f27,f13,f12
	ctx.f27.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f13,1632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1632);
	ctx.f13.f64 = double(temp.f32);
	// lfs f30,1640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1640);
	ctx.f30.f64 = double(temp.f32);
	// fadds f26,f13,f30
	ctx.f26.f64 = double(float(ctx.f13.f64 + ctx.f30.f64));
	// lfs f13,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f13.f64 = double(temp.f32);
	// lfs f30,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f25,1648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1648);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f30
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f30.f64));
	// lfs f23,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f27,f22,f23,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 + ctx.f27.f64));
	// lfs f20,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,3312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3312);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,3328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3328);
	ctx.f17.f64 = double(temp.f32);
	// lfs f23,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f9,f23
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,3272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3272);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f26,f26,f12,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f0.f64));
	// lfs f0,3280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3280);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f22,f22,f8
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// lfs f21,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// lfs f24,3288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3288);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f0,f24
	ctx.f24.f64 = double(float(ctx.f0.f64 + ctx.f24.f64));
	// lfs f0,1212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1212);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f27,f0,f20,f27
	ctx.f27.f64 = double(float(ctx.f0.f64 * ctx.f20.f64 + ctx.f27.f64));
	// lfs f0,3296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3296);
	ctx.f0.f64 = double(temp.f32);
	// lfs f20,916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 916);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f9,f21
	ctx.f21.f64 = double(float(ctx.f9.f64 * ctx.f21.f64));
	// fmuls f20,f0,f20
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f20.f64));
	// lfs f0,3304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3304);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f19,f0,f19
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// lfs f0,3320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3320);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f18,f9,f0
	ctx.f18.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f0,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f0.f64 = double(temp.f32);
	// lfs f14,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f26,f17,f0,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f26.f64));
	// lfs f15,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,3336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3336);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f8
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f8.f64));
	// fmuls f27,f27,f9
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// fmadds f24,f24,f16,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f16.f64 + ctx.f20.f64));
	// lfs f16,1656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1656);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// lfs f20,3344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3344);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f9,f20
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f20.f64));
	// fmsubs f26,f26,f8,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f8.f64 - ctx.f25.f64));
	// lfs f25,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f27,f23,f25,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f25.f64 - ctx.f27.f64));
	// lfs f25,1664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1664);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f30
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f30.f64));
	// lfs f30,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f12,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f12.f64 + ctx.f24.f64));
	// lfs f23,1672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1672);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,3352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3352);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f23,f8
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fmuls f24,f9,f24
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f24.f64));
	// fnmsubs f26,f22,f13,f26
	ctx.f26.f64 = double(float(-(ctx.f22.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// lfs f22,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f27,f21,f22,f27
	ctx.f27.f64 = double(float(-(ctx.f21.f64 * ctx.f22.f64 - ctx.f27.f64)));
	// lfs f22,1780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1780);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,3368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3368);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f30,f22
	ctx.f22.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// lfs f30,3360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3360);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f0
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f21.f64));
	// lfs f15,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f9,f15
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f15.f64));
	// fnmsubs f26,f19,f14,f26
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f14.f64 - ctx.f26.f64)));
	// lfs f19,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f27,f18,f19,f27
	ctx.f27.f64 = double(float(-(ctx.f18.f64 * ctx.f19.f64 - ctx.f27.f64)));
	// lfs f18,1680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1680);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,3376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3376);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f8
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// fmadds f18,f18,f13,f30
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f30.f64));
	// lfs f30,1688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1688);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f30,f8
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// lfs f30,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f21,f21,f30,f28
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f30.f64 + ctx.f28.f64));
	// lfs f30,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f26,f17,f13,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f26.f64));
	// fnmsubs f27,f20,f30,f27
	ctx.f27.f64 = double(float(-(ctx.f20.f64 * ctx.f30.f64 - ctx.f27.f64)));
	// lfs f28,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f26,f16,f28,f26
	ctx.f26.f64 = double(float(-(ctx.f16.f64 * ctx.f28.f64 - ctx.f26.f64)));
	// lfs f20,1704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1704);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,1336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1336);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f27,f22,f9,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 + ctx.f27.f64));
	// fnmsubs f26,f25,f28,f26
	ctx.f26.f64 = double(float(-(ctx.f25.f64 * ctx.f28.f64 - ctx.f26.f64)));
	// lfs f25,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f30,f24,f30,f27
	ctx.f30.f64 = double(float(-(ctx.f24.f64 * ctx.f30.f64 - ctx.f27.f64)));
	// fnmsubs f27,f23,f12,f26
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f26.f64)));
	// lfs f26,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f25,f26
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// lfs f26,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f30,f15,f13,f30
	ctx.f30.f64 = double(float(-(ctx.f15.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f27,f18,f8,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f8.f64 + ctx.f27.f64));
	// lfs f18,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f18.f64 = double(temp.f32);
	// fadds f30,f21,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// stfs f30,4680(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4680, temp.u32);
	// lfs f30,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f24,f19,f0,f27
	ctx.f24.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f27.f64)));
	// fmuls f27,f30,f31
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// lfs f30,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f22,f26,f30
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// lfs f26,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f26.f64 = double(temp.f32);
	// lfs f21,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,1480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1480);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f24,f14,f12,f24
	ctx.f24.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f24.f64)));
	// lfs f14,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmadds f22,f16,f15,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 + ctx.f22.f64));
	// lfs f15,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f27,f26,f25,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f25.f64 + ctx.f27.f64));
	// lfs f26,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f21,f21,f26
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f26.f64));
	// lfs f26,1696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1696);
	ctx.f26.f64 = double(temp.f32);
	// fadds f20,f26,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 + ctx.f20.f64));
	// lfs f26,1524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1524);
	ctx.f26.f64 = double(temp.f32);
	// fadds f19,f26,f19
	ctx.f19.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// lfs f26,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f18,f26,f18
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f18.f64));
	// fmadds f16,f15,f16,f27
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64 + ctx.f27.f64));
	// lfs f27,3384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3384);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f27,f30
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// lfs f27,1488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1488);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f20,f11
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// fadds f19,f19,f27
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f27.f64));
	// lfs f27,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f31,f27
	ctx.f27.f64 = double(float(ctx.f31.f64 * ctx.f27.f64));
	// fmsubs f20,f17,f29,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f29.f64 - ctx.f20.f64));
	// lfs f17,1496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1496);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// lfs f17,1528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1528);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// fmuls f25,f16,f29
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f29.f64));
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,1348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1348);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f14.f64));
	// lfs f14,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f20,f19,f11,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 + ctx.f20.f64));
	// lfs f19,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f25,f23,f29,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f29.f64 - ctx.f25.f64));
	// lfs f23,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f19,f14,f19,f17
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f19.f64 + ctx.f17.f64));
	// lfs f17,1080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1080);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f28,f16,f28,f24
	ctx.f28.f64 = double(float(-(ctx.f16.f64 * ctx.f28.f64 - ctx.f24.f64)));
	// lfs f24,1660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f26,f26,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,3392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3392);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f14.f64));
	// lfs f16,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f23,f23,f8
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fnmsubs f25,f24,f11,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f11.f64 - ctx.f25.f64)));
	// lfs f24,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f16.f64));
	// lfs f16,1356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1356);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f20,f16,f11,f20
	ctx.f20.f64 = double(float(-(ctx.f16.f64 * ctx.f11.f64 - ctx.f20.f64)));
	// lfs f11,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f11.f64 = double(temp.f32);
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f28,f23,f0,f28
	ctx.f28.f64 = double(float(-(ctx.f23.f64 * ctx.f0.f64 - ctx.f28.f64)));
	// fmuls f16,f11,f16
	ctx.f16.f64 = double(float(ctx.f11.f64 * ctx.f16.f64));
	// lfs f11,3400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3400);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f14,f11,f8
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f11,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f25,f22,f11,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 + ctx.f25.f64));
	// lfs f23,1536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1536);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// lfs f22,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f23,f19,f29,f20
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f29.f64 + ctx.f20.f64));
	// lfs f20,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// lfs f19,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f28,f14,f13,f28
	ctx.f28.f64 = double(float(-(ctx.f14.f64 * ctx.f13.f64 - ctx.f28.f64)));
	// stfs f28,4684(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4684, temp.u32);
	// fnmsubs f25,f21,f29,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f29.f64 - ctx.f25.f64)));
	// lfs f14,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f20,f20,f19,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64 + ctx.f16.f64));
	// fnmsubs f28,f24,f29,f23
	ctx.f28.f64 = double(float(-(ctx.f24.f64 * ctx.f29.f64 - ctx.f23.f64)));
	// fnmsubs f25,f18,f29,f25
	ctx.f25.f64 = double(float(-(ctx.f18.f64 * ctx.f29.f64 - ctx.f25.f64)));
	// fmadds f24,f20,f29,f28
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f29.f64 + ctx.f28.f64));
	// fmadds f28,f15,f29,f25
	ctx.f28.f64 = double(float(ctx.f15.f64 * ctx.f29.f64 + ctx.f25.f64));
	// fnmsubs f28,f27,f29,f28
	ctx.f28.f64 = double(float(-(ctx.f27.f64 * ctx.f29.f64 - ctx.f28.f64)));
	// lfs f27,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f28,f26,f29,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f29.f64 + ctx.f28.f64));
	// lfs f26,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f28,f17,f11,f28
	ctx.f28.f64 = double(float(-(ctx.f17.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// fnmsubs f23,f30,f11,f28
	ctx.f23.f64 = double(float(-(ctx.f30.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// lfs f11,3408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3408);
	ctx.f11.f64 = double(temp.f32);
	// lfs f30,1116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1116);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f11
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// lfs f11,3416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3416);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f25,f11,f1
	ctx.f25.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// lfs f28,1108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	ctx.f28.f64 = double(temp.f32);
	// lfs f11,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f21,f11,f28
	ctx.f21.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// lfs f11,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f11.f64 = double(temp.f32);
	// lfs f28,1296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1296);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f20,f11,f28
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// lfs f11,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f19,f27,f11
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// fmuls f18,f30,f26
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f26.f64));
	// lfs f30,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f28,f30,f31
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// lfs f30,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f21,f21,f26,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f26.f64 - ctx.f18.f64));
	// lfs f26,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f17,f28,f30,f25
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f30.f64 + ctx.f25.f64));
	// lfs f25,1280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1280);
	ctx.f25.f64 = double(temp.f32);
	// lfs f28,1272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1272);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f25,f11
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// fmuls f16,f27,f28
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// lfs f11,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f11.f64 = double(temp.f32);
	// lfs f28,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f20,f11,f28,f20
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f28.f64 + ctx.f20.f64));
	// lfs f11,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// lfs f28,1076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1076);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f28,f26
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f26.f64));
	// lfs f26,1084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1084);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// fmuls f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// lfs f25,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f21,f17,f7,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f21.f64));
	// lfs f17,924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 924);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f25,f20,f25,f19
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f25.f64 + ctx.f19.f64));
	// lfs f19,1532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1532);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f17,f14,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f14.f64 + ctx.f19.f64));
	// lfs f20,1460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1460);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f20,f1,f20
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f20.f64));
	// lfs f14,1108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f17.f64));
	// fnmsubs f21,f16,f7,f21
	ctx.f21.f64 = double(float(-(ctx.f16.f64 * ctx.f7.f64 - ctx.f21.f64)));
	// fnmsubs f25,f15,f11,f25
	ctx.f25.f64 = double(float(-(ctx.f15.f64 * ctx.f11.f64 - ctx.f25.f64)));
	// lfs f16,1208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1208);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f27,f27,f11,f25
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f11.f64 - ctx.f25.f64)));
	// fmuls f16,f28,f16
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f16.f64));
	// lfs f15,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f28,f19,f28,f26
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f28.f64 + ctx.f26.f64));
	// lfs f19,1248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1248);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f15,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f15.f64 + ctx.f17.f64));
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,1372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1372);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f25,f18,f11,f21
	ctx.f25.f64 = double(float(-(ctx.f18.f64 * ctx.f11.f64 - ctx.f21.f64)));
	// fmuls f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f15.f64));
	// lfs f21,3424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3424);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,3432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3432);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f21,f21,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64));
	// lfs f14,1644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1644);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f18,f18,f1
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// fmuls f14,f14,f1
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f1.f64));
	// lfs f1,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// lfs f26,1364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1364);
	ctx.f26.f64 = double(temp.f32);
	// lfs f17,1620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1620);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f26,f26,f30
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// fmuls f17,f30,f17
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f17.f64));
	// fmadds f28,f28,f11,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f11.f64 + ctx.f27.f64));
	// fnmsubs f27,f20,f7,f25
	ctx.f27.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f25.f64)));
	// lfs f25,1540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1540);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// fnmsubs f30,f22,f29,f24
	ctx.f30.f64 = double(float(-(ctx.f22.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// lfs f24,1380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1380);
	ctx.f24.f64 = double(temp.f32);
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// lfs f22,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f28,f16,f11,f28
	ctx.f28.f64 = double(float(-(ctx.f16.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// lfs f11,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f11.f64 = double(temp.f32);
	// lfs f24,1088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1088);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f27,f19,f11,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 + ctx.f27.f64));
	// lfs f19,1548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1548);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f24,f22,f24,f15
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f24.f64 + ctx.f15.f64));
	// lfs f22,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f22.f64 = double(temp.f32);
	// fadds f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// stfs f30,4688(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4688, temp.u32);
	// lfs f23,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f25,f25,f6
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// fnmsubs f30,f17,f7,f28
	ctx.f30.f64 = double(float(-(ctx.f17.f64 * ctx.f7.f64 - ctx.f28.f64)));
	// fmadds f28,f26,f7,f27
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 + ctx.f27.f64));
	// fnmsubs f30,f18,f7,f30
	ctx.f30.f64 = double(float(-(ctx.f18.f64 * ctx.f7.f64 - ctx.f30.f64)));
	// lfs f18,1396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1396);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f28,f21,f7,f28
	ctx.f28.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f28.f64)));
	// fmadds f11,f24,f11,f30
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f11.f64 + ctx.f30.f64));
	// fmadds f30,f14,f7,f28
	ctx.f30.f64 = double(float(ctx.f14.f64 * ctx.f7.f64 + ctx.f28.f64));
	// fnmsubs f7,f1,f7,f30
	ctx.f7.f64 = double(float(-(ctx.f1.f64 * ctx.f7.f64 - ctx.f30.f64)));
	// lfs f30,1684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1684);
	ctx.f30.f64 = double(temp.f32);
	// fadds f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f7.f64));
	// stfs f11,4692(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4692, temp.u32);
	// lfs f7,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f7.f64 = double(temp.f32);
	// lfs f11,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f11,f7
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// lfs f11,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f28,f11,f7
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// lfs f11,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f27,f11,f7
	ctx.f27.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// lfs f11,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f26,f11,f30
	ctx.f26.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfs f30,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f24,f30,f7
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f7.f64));
	// lfs f7,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f23,f23,f7,f1
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 + ctx.f1.f64));
	// lfs f1,1228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1228);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f1,f22
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f22.f64));
	// lfs f1,1152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1152);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f28,f1,f7,f28
	ctx.f28.f64 = double(float(ctx.f1.f64 * ctx.f7.f64 + ctx.f28.f64));
	// lfs f1,1096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1096);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f21,f7,f1
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f1.f64));
	// lfs f1,1388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1388);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f11,f1
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// lfs f1,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f26,f1
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// fmuls f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f18.f64));
	// lfs f18,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f7
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f7.f64));
	// lfs f7,1628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1628);
	ctx.f7.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f17,f11,f7
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// lfs f7,1404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1404);
	ctx.f7.f64 = double(temp.f32);
	// lfs f16,1556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1556);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f25,f25,f10,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 - ctx.f23.f64));
	// fadds f16,f7,f16
	ctx.f16.f64 = double(float(ctx.f7.f64 + ctx.f16.f64));
	// lfs f7,-29872(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -29872);
	ctx.f7.f64 = double(temp.f32);
	// lfs f15,940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 940);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f26,f22,f7,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 - ctx.f26.f64));
	// fmuls f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f15.f64));
	// lfs f15,-30096(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30096);
	ctx.f15.f64 = double(temp.f32);
	// stfs f7,660(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 660, temp.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f15,324(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f7,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f7.f64 = double(temp.f32);
	// lfs f22,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,1184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1184);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f22,f7,f22
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f22.f64));
	// fmuls f15,f7,f15
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f15.f64));
	// lfs f7,1412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1412);
	ctx.f7.f64 = double(temp.f32);
	// lfs f14,1668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1668);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f7,f14
	ctx.f14.f64 = double(float(ctx.f7.f64 + ctx.f14.f64));
	// lfs f7,940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 940);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f7,f20,f7,f26
	ctx.f7.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// lfs f20,1276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1276);
	ctx.f20.f64 = double(temp.f32);
	// lfs f26,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// lfs f23,3440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3440);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f20,f16,f1,f19
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f19.f64));
	// lfs f19,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f28,f28,f19,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64 + ctx.f25.f64));
	// lfs f19,1148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1148);
	ctx.f19.f64 = double(temp.f32);
	// lfs f25,1792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1792);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f11,f23
	ctx.f23.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// fadds f25,f25,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f19.f64));
	// lfs f16,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,3448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3448);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfs f16,3456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3456);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f11,f16
	ctx.f16.f64 = double(float(ctx.f11.f64 * ctx.f16.f64));
	// fnmsubs f1,f17,f1,f7
	ctx.f1.f64 = double(float(-(ctx.f17.f64 * ctx.f1.f64 - ctx.f7.f64)));
	// lfs f7,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f7.f64 = double(temp.f32);
	// lfs f17,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f14,f6
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f6.f64));
	// fmuls f20,f20,f11
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// fnmsubs f28,f27,f7,f28
	ctx.f28.f64 = double(float(-(ctx.f27.f64 * ctx.f7.f64 - ctx.f28.f64)));
	// lfs f7,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f7.f64 = double(temp.f32);
	// lfs f27,1276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1276);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f7,f27
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// lfs f7,1112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fadds f17,f7,f17
	ctx.f17.f64 = double(float(ctx.f7.f64 + ctx.f17.f64));
	// lfs f7,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f30,f30,f7
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f7.f64));
	// lfs f7,1420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1420);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// lfs f7,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f23,f23,f7,f1
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 + ctx.f1.f64));
	// lfs f1,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f25,f25,f1
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f1.f64));
	// lfs f1,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f1.f64 = double(temp.f32);
	// stfs f11,324(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fmr f11,f1
	ctx.f11.f64 = ctx.f1.f64;
	// lfs f1,-30240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30240);
	ctx.f1.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmsubs f20,f16,f7,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f7.f64 - ctx.f20.f64));
	// lfs f7,1092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1092);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f28,f24,f11,f28
	ctx.f28.f64 = double(float(-(ctx.f24.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// fmuls f24,f19,f1
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// lfs f1,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f27,f7,f1,f27
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f1.f64 + ctx.f27.f64));
	// lfs f7,-30236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30236);
	ctx.f7.f64 = double(temp.f32);
	// lfs f1,660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 660);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f17,f6
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// stfs f7,440(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fmadds f26,f26,f1,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 + ctx.f23.f64));
	// fmuls f30,f30,f11
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fnmsubs f28,f21,f11,f28
	ctx.f28.f64 = double(float(-(ctx.f21.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// fmsubs f7,f25,f7,f24
	ctx.f7.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 - ctx.f24.f64));
	// stfs f7,4704(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4704, temp.u32);
	// fmadds f7,f27,f1,f20
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f20.f64));
	// stfs f7,4708(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4708, temp.u32);
	// lfs f27,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f1,f19,f4,f30
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f4.f64 - ctx.f30.f64));
	// lfs f7,940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 940);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f7,f27,f7,f26
	ctx.f7.f64 = double(float(-(ctx.f27.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// stfs f7,4700(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4700, temp.u32);
	// fnmsubs f7,f18,f11,f28
	ctx.f7.f64 = double(float(-(ctx.f18.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// lfs f30,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f30.f64 = double(temp.f32);
	// lfs f24,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f24.f64 = double(temp.f32);
	// lfs f20,1160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1160);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f7,f22,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f22.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// fnmsubs f7,f15,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f15.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// fmadds f7,f14,f10,f7
	ctx.f7.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 + ctx.f7.f64));
	// stfs f7,4696(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4696, temp.u32);
	// lfs f7,3464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3464);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f28,f6,f7
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f7,1564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1564);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f27,f30,f7
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f7.f64));
	// lfs f30,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f30.f64 = double(temp.f32);
	// lfs f7,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f26,f7,f30
	ctx.f26.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// lfs f7,1468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1468);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f25,f6,f7
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f7,1428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1428);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f24,f24,f7
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// lfs f7,2236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2236);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f23,f6,f7
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// fnmsubs f7,f28,f4,f1
	ctx.f7.f64 = double(float(-(ctx.f28.f64 * ctx.f4.f64 - ctx.f1.f64)));
	// lfs f1,1636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1636);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f6,f1
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f28,1104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	ctx.f28.f64 = double(temp.f32);
	// lfs f1,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f21,f1,f28
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// lfs f1,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f1,f20
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f20.f64));
	// lfs f1,1020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1020);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f6,f1
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f27,f27,f11,f7
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f7.f64));
	// fmuls f7,f1,f31
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fnmsubs f26,f26,f11,f27
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f11.f64 - ctx.f27.f64)));
	// fmuls f18,f6,f7
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f7,1168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1168);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f17,f1,f7
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// lfs f1,1112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f21,f1,f7,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f7.f64 + ctx.f21.f64));
	// lfs f1,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f20,f1
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f1.f64));
	// lfs f1,1436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1436);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f6,f1
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f1,f28
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// lfs f1,1572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1572);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f14,f6,f1
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f28,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f28.f64 = double(temp.f32);
	// lfs f1,1444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1444);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f28,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 * ctx.f1.f64));
	// lfs f28,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f28.f64 = double(temp.f32);
	// stfs f1,324(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fmr f1,f28
	ctx.f1.f64 = ctx.f28.f64;
	// lfs f28,1200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1200);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f26,f25,f4,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f4.f64 + ctx.f26.f64));
	// fmuls f27,f28,f31
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// fmuls f28,f28,f7
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f7.f64));
	// lfs f7,1700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1700);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f25,f6,f7
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f7,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmadds f21,f21,f1,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 + ctx.f20.f64));
	// fmadds f11,f24,f11,f26
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f11.f64 + ctx.f26.f64));
	// fmuls f27,f6,f27
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f6,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f6,f7
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f6,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f7,f17,f1,f21
	ctx.f7.f64 = double(float(ctx.f17.f64 * ctx.f1.f64 - ctx.f21.f64));
	// fmuls f21,f6,f30
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f6,3472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3472);
	ctx.f6.f64 = double(temp.f32);
	// lfs f30,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f26,f6,f30
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f6,1732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1732);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f7,f15,f1,f7
	ctx.f7.f64 = double(float(ctx.f15.f64 * ctx.f1.f64 + ctx.f7.f64));
	// lfs f30,1100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1100);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f11,f23,f4,f11
	ctx.f11.f64 = double(float(-(ctx.f23.f64 * ctx.f4.f64 - ctx.f11.f64)));
	// fmuls f30,f6,f30
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f6,3480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3480);
	ctx.f6.f64 = double(temp.f32);
	// lfs f24,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// lfs f1,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f1.f64 = double(temp.f32);
	// lfs f6,3488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3488);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f6,f1
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f6,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f6.f64 = double(temp.f32);
	// lfs f1,3496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3496);
	ctx.f1.f64 = double(temp.f32);
	// lfs f15,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f11,f22,f10,f11
	ctx.f11.f64 = double(float(-(ctx.f22.f64 * ctx.f10.f64 - ctx.f11.f64)));
	// fmuls f17,f30,f6
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// lfs f30,924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 924);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f6,f1
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f6.f64 + ctx.f1.f64));
	// lfs f1,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f7,f15,f1,f7
	ctx.f7.f64 = double(float(-(ctx.f15.f64 * ctx.f1.f64 - ctx.f7.f64)));
	// lfs f1,1100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1100);
	ctx.f1.f64 = double(temp.f32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f11,f19,f4,f11
	ctx.f11.f64 = double(float(ctx.f19.f64 * ctx.f4.f64 + ctx.f11.f64));
	// lfs f19,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f23,f30,f1,f23
	ctx.f23.f64 = double(float(ctx.f30.f64 * ctx.f1.f64 + ctx.f23.f64));
	// lfs f30,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f28,f28,f30,f7
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f30.f64 + ctx.f7.f64));
	// lfs f7,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f22,f18,f4,f11
	ctx.f22.f64 = double(float(-(ctx.f18.f64 * ctx.f4.f64 - ctx.f11.f64)));
	// lfs f11,1804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1804);
	ctx.f11.f64 = double(temp.f32);
	// lfs f18,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f28,f20,f7,f28
	ctx.f28.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f28.f64)));
	// fnmsubs f28,f26,f11,f28
	ctx.f28.f64 = double(float(-(ctx.f26.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// fmadds f26,f16,f10,f22
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f22.f64));
	// lfs f16,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f22,f17,f11,f28
	ctx.f22.f64 = double(float(-(ctx.f17.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// lfs f17,1452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1452);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f28,f14,f10,f26
	ctx.f28.f64 = double(float(-(ctx.f14.f64 * ctx.f10.f64 - ctx.f26.f64)));
	// lfs f26,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// lfs f16,1580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1580);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// fnmsubs f4,f27,f4,f28
	ctx.f4.f64 = double(float(-(ctx.f27.f64 * ctx.f4.f64 - ctx.f28.f64)));
	// lfs f28,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f4,f25,f10,f4
	ctx.f4.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 + ctx.f4.f64));
	// lfs f10,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f4,f21,f10,f4
	ctx.f4.f64 = double(float(-(ctx.f21.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// fmadds f10,f24,f10,f4
	ctx.f10.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f4.f64));
	// stfs f10,4712(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4712, temp.u32);
	// lfs f4,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f4.f64 = double(temp.f32);
	// lfs f10,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f27,f4,f10
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f4,1108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f25,f4,f1
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// lfs f4,3504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3504);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f24,f4,f28
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// lfs f4,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// lfs f28,1116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1116);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f20,f28,f26
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f26.f64));
	// fmuls f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmuls f21,f4,f10
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f4,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f25,f25,f4
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// lfs f4,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f19,f19,f4
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// lfs f4,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f18,f4,f18
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f18.f64));
	// fmadds f24,f24,f11,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64 + ctx.f27.f64));
	// lfs f27,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f27,f28
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// lfs f27,1876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1876);
	ctx.f27.f64 = double(temp.f32);
	// lfs f28,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f14,f28,f31,f27
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f31.f64 + ctx.f27.f64));
	// lfs f31,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f31.f64 = double(temp.f32);
	// lfs f27,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f19,f31
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f31.f64));
	// lfs f31,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f18,f18,f29
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f29.f64));
	// fmuls f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmsubs f25,f25,f7,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 - ctx.f24.f64));
	// stfs f31,324(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fmadds f25,f21,f11,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 + ctx.f25.f64));
	// lfs f24,1120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1120);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f23,f23,f11,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f11.f64 + ctx.f22.f64));
	// fmuls f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f26.f64));
	// lfs f24,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f24.f64 = double(temp.f32);
	// fmr f31,f24
	ctx.f31.f64 = ctx.f24.f64;
	// lfs f21,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f25,f20,f7,f25
	ctx.f25.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f25.f64)));
	// fmadds f24,f14,f31,f19
	ctx.f24.f64 = double(float(ctx.f14.f64 * ctx.f31.f64 + ctx.f19.f64));
	// lfs f19,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f19,f16,f19,f18
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f19.f64 - ctx.f18.f64));
	// lfs f18,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f6
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f6.f64));
	// lfs f16,1460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1460);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f1
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f1.f64));
	// lfs f14,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f25,f17,f7,f25
	ctx.f25.f64 = double(float(-(ctx.f17.f64 * ctx.f7.f64 - ctx.f25.f64)));
	// lfs f17,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f10,f17,f10
	ctx.f10.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// lfs f17,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f17.f64));
	// fmadds f24,f21,f6,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 + ctx.f24.f64));
	// fnmsubs f25,f15,f7,f25
	ctx.f25.f64 = double(float(-(ctx.f15.f64 * ctx.f7.f64 - ctx.f25.f64)));
	// fnmsubs f7,f26,f7,f25
	ctx.f7.f64 = double(float(-(ctx.f26.f64 * ctx.f7.f64 - ctx.f25.f64)));
	// lfs f21,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f7,f16,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f16.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// fnmsubs f21,f21,f29,f19
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f29.f64 - ctx.f19.f64)));
	// lfs f19,1644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1644);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f1,f19,f1
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// lfs f19,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f4,f19,f18
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f19.f64 + ctx.f18.f64));
	// lfs f4,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f20,f27,f4
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// lfs f4,1468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1468);
	ctx.f4.f64 = double(temp.f32);
	// lfs f18,1168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1168);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f4,f18
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f18.f64));
	// lfs f4,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f24,f24,f4,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f21.f64));
	// lfs f4,1588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1588);
	ctx.f4.f64 = double(temp.f32);
	// lfs f21,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f1,f4,f21,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f21.f64 + ctx.f1.f64));
	// lfs f4,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f4.f64 = double(temp.f32);
	// lfs f21,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f4,f21
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// fmadds f24,f19,f29,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f29.f64 + ctx.f24.f64));
	// lfs f19,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f27,f27,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// lfs f19,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f11,f1,f11,f7
	ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 + ctx.f7.f64));
	// lfs f1,1676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1676);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f4,f19
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// fnmsubs f24,f20,f29,f24
	ctx.f24.f64 = double(float(-(ctx.f20.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// fnmsubs f11,f18,f30,f11
	ctx.f11.f64 = double(float(-(ctx.f18.f64 * ctx.f30.f64 - ctx.f11.f64)));
	// fnmsubs f26,f21,f29,f24
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// fmadds f11,f10,f30,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f30.f64 + ctx.f11.f64));
	// lfs f30,1484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1484);
	ctx.f30.f64 = double(temp.f32);
	// fadds f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// lfs f10,3512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3512);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// lfs f30,1596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1596);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f8,f30
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fnmsubs f26,f17,f29,f26
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f29.f64 - ctx.f26.f64)));
	// fadds f11,f23,f11
	ctx.f11.f64 = double(float(ctx.f23.f64 + ctx.f11.f64));
	// stfs f11,4716(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4716, temp.u32);
	// lfs f11,1476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1476);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f2
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f2.f64));
	// fmuls f10,f10,f13
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmadds f7,f27,f29,f26
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f29.f64 + ctx.f26.f64));
	// lfs f26,3528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3528);
	ctx.f26.f64 = double(temp.f32);
	// lfs f27,3520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3520);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f8,f27
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmsubs f11,f26,f2,f11
	ctx.f11.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 - ctx.f11.f64));
	// lfs f26,1492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1492);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f1,f26
	ctx.f26.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// lfs f1,3536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3536);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f25,f8,f1
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// lfs f1,3544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3544);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f24,f8,f1
	ctx.f24.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// lfs f1,3552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3552);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f23,f1,f2,f11
	ctx.f23.f64 = double(float(-(ctx.f1.f64 * ctx.f2.f64 - ctx.f11.f64)));
	// fmsubs f10,f30,f13,f10
	ctx.f10.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 - ctx.f10.f64));
	// lfs f1,1652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1652);
	ctx.f1.f64 = double(temp.f32);
	// lfs f11,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f7,f19,f29,f7
	ctx.f7.f64 = double(float(-(ctx.f19.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// fmuls f30,f11,f1
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// lfs f1,1500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1500);
	ctx.f1.f64 = double(temp.f32);
	// lfs f22,1604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1604);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f1,f22
	ctx.f22.f64 = double(float(ctx.f1.f64 + ctx.f22.f64));
	// lfs f1,3560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3560);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f21,f1,f13
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f1,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f26,f26,f1,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 + ctx.f23.f64));
	// lfs f19,1900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1900);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f10,f27,f13,f10
	ctx.f10.f64 = double(float(-(ctx.f27.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// lfs f27,1508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1508);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f11,f27
	ctx.f27.f64 = double(float(ctx.f11.f64 * ctx.f27.f64));
	// fmadds f23,f22,f12,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f21.f64));
	// lfs f22,3568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3568);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f26,f22,f2,f26
	ctx.f26.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f26.f64)));
	// lfs f22,1692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1692);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f25,f25,f0,f10
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f10,3576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3576);
	ctx.f10.f64 = double(temp.f32);
	// fadds f22,f10,f22
	ctx.f22.f64 = double(float(ctx.f10.f64 + ctx.f22.f64));
	// lfs f10,3584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3584);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f21,f10,f0
	ctx.f21.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f10,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f10,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f20,f10,f6
	ctx.f20.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// lfs f6,3592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3592);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f6,f6,f2,f26
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 + ctx.f26.f64));
	// fnmsubs f26,f24,f0,f25
	ctx.f26.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// lfs f24,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// fmadds f24,f22,f13,f21
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f21.f64));
	// lfs f21,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f4,f29,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 + ctx.f7.f64));
	// lfs f4,1516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1516);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f22.f64));
	// fnmsubs f4,f4,f2,f6
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f2.f64 - ctx.f6.f64)));
	// lfs f6,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f6.f64 = double(temp.f32);
	// lfs f21,1340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1340);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f8,f21
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f21.f64));
	// fnmsubs f2,f30,f6,f26
	ctx.f2.f64 = double(float(-(ctx.f30.f64 * ctx.f6.f64 - ctx.f26.f64)));
	// lfs f26,1224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1224);
	ctx.f26.f64 = double(temp.f32);
	// lfs f30,1612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1612);
	ctx.f30.f64 = double(temp.f32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfs f25,3600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3600);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f30,f8,f30
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fmuls f25,f8,f25
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// fnmsubs f22,f22,f29,f7
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// lfs f7,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f4,f19,f7,f4
	ctx.f4.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 + ctx.f4.f64));
	// fmadds f2,f23,f8,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f8.f64 + ctx.f2.f64));
	// lfs f23,1344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1344);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f4,f23,f1,f4
	ctx.f4.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f4.f64));
	// lfs f1,3616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3616);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f2,f27,f6,f2
	ctx.f2.f64 = double(float(-(ctx.f27.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// fnmsubs f4,f20,f29,f4
	ctx.f4.f64 = double(float(-(ctx.f20.f64 * ctx.f29.f64 - ctx.f4.f64)));
	// lfs f29,1784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1784);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f2,f24,f8,f2
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f8.f64 + ctx.f2.f64));
	// fmadds f7,f26,f7,f4
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 + ctx.f4.f64));
	// fnmsubs f4,f30,f12,f2
	ctx.f4.f64 = double(float(-(ctx.f30.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f2,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f2.f64 = double(temp.f32);
	// fadds f7,f22,f7
	ctx.f7.f64 = double(float(ctx.f22.f64 + ctx.f7.f64));
	// stfs f7,4720(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4720, temp.u32);
	// fnmsubs f7,f25,f0,f4
	ctx.f7.f64 = double(float(-(ctx.f25.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// lfs f4,1352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1352);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// lfs f2,3608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3608);
	ctx.f2.f64 = double(temp.f32);
	// fadds f30,f2,f1
	ctx.f30.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// lfs f1,3632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3632);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,3624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3624);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// lfs f1,3640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3640);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f4,f1,f29,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f4.f64));
	// lfs f1,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f1.f64 = double(temp.f32);
	// lfs f29,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f1,f8
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fmuls f29,f29,f31
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f31.f64));
	// lfs f27,3648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3648);
	ctx.f27.f64 = double(temp.f32);
	// lis r11,-32245
	ctx.r11.s64 = -2113208320;
	// fadds f27,f2,f27
	ctx.f27.f64 = double(float(ctx.f2.f64 + ctx.f27.f64));
	// lfs f2,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f7,f21,f12,f7
	ctx.f7.f64 = double(float(-(ctx.f21.f64 * ctx.f12.f64 - ctx.f7.f64)));
	// lfs f26,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f2
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// lfs f25,1324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1324);
	ctx.f25.f64 = double(temp.f32);
	// lfs f2,25992(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 25992);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f4,f25,f2,f4
	ctx.f4.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 + ctx.f4.f64));
	// lfs f25,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f1,f25
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// lfs f1,1236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1236);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f29,f10,f28,f29
	ctx.f29.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 + ctx.f29.f64));
	// lfs f10,3656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3656);
	ctx.f10.f64 = double(temp.f32);
	// fadds f10,f27,f10
	ctx.f10.f64 = double(float(ctx.f27.f64 + ctx.f10.f64));
	// fmuls f27,f26,f8
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// lfs f26,3664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3664);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f4,f26,f1,f4
	ctx.f4.f64 = double(float(-(ctx.f26.f64 * ctx.f1.f64 - ctx.f4.f64)));
	// fmuls f26,f25,f0
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// lfs f25,3672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3672);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f8
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// fmuls f24,f10,f12
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f10,1360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1360);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f23,f10,f11
	ctx.f23.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,1264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1264);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f4,f30,f10,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f10.f64 + ctx.f4.f64));
	// fmsubs f30,f27,f0,f26
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 - ctx.f26.f64));
	// lfs f26,3688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3688);
	ctx.f26.f64 = double(temp.f32);
	// lfs f27,3680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3680);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f8
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// fmadds f29,f29,f0,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f0.f64 + ctx.f24.f64));
	// lfs f24,1188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1188);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f26.f64));
	// lfs f24,3696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3696);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f7,f23,f6,f7
	ctx.f7.f64 = double(float(-(ctx.f23.f64 * ctx.f6.f64 - ctx.f7.f64)));
	// fnmsubs f24,f24,f1,f4
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f1.f64 - ctx.f4.f64)));
	// lfs f4,3704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3704);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f23,f4,f8
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// lfs f4,1368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1368);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f11,f11,f4
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// lfs f4,2220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2220);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f30,f29,f8,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 + ctx.f30.f64));
	// lfs f29,1376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1376);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f29,f29,f4,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 + ctx.f24.f64));
	// lfs f24,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f7,f26,f24,f7
	ctx.f7.f64 = double(float(-(ctx.f26.f64 * ctx.f24.f64 - ctx.f7.f64)));
	// lfs f24,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f8
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// lfs f26,3712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3712);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f8
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// fnmsubs f30,f25,f12,f30
	ctx.f30.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// lfs f25,3720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3720);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f29,f25,f1,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f29.f64));
	// fnmsubs f11,f11,f6,f7
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f7.f64)));
	// stfs f11,4724(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4724, temp.u32);
	// fmuls f7,f24,f31
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// lfs f31,3728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3728);
	ctx.f31.f64 = double(temp.f32);
	// fnmsubs f11,f27,f12,f30
	ctx.f11.f64 = double(float(-(ctx.f27.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// lfs f30,1440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1440);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f9
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// fmadds f10,f31,f10,f29
	ctx.f10.f64 = double(float(ctx.f31.f64 * ctx.f10.f64 + ctx.f29.f64));
	// lfs f31,1384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1384);
	ctx.f31.f64 = double(temp.f32);
	// lfs f29,1028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1028);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f29,f9
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f9.f64));
	// fnmsubs f11,f23,f12,f11
	ctx.f11.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f11.f64)));
	// fnmsubs f10,f31,f4,f10
	ctx.f10.f64 = double(float(-(ctx.f31.f64 * ctx.f4.f64 - ctx.f10.f64)));
	// fnmsubs f31,f26,f12,f11
	ctx.f31.f64 = double(float(-(ctx.f26.f64 * ctx.f12.f64 - ctx.f11.f64)));
	// lfs f11,1392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1392);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f11,f11,f2,f10
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f2.f64 - ctx.f10.f64)));
	// lfs f10,1400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1400);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f11,f10,f2,f11
	ctx.f11.f64 = double(float(-(ctx.f10.f64 * ctx.f2.f64 - ctx.f11.f64)));
	// lfs f10,1408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1408);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f11,f10,f4,f11
	ctx.f11.f64 = double(float(-(ctx.f10.f64 * ctx.f4.f64 - ctx.f11.f64)));
	// stfs f11,4728(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4728, temp.u32);
	// lfs f10,1424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1424);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,1416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1416);
	ctx.f11.f64 = double(temp.f32);
	// fadds f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// lfs f10,1432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1432);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// fmuls f25,f11,f9
	ctx.f25.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f11,884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f24,f10,f11
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,3736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3736);
	ctx.f10.f64 = double(temp.f32);
	// lfs f23,3744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3744);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f7,f7,f0,f31
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f31.f64)));
	// fadds f23,f10,f23
	ctx.f23.f64 = double(float(ctx.f10.f64 + ctx.f23.f64));
	// lfs f10,3752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3752);
	ctx.f10.f64 = double(temp.f32);
	// lfs f19,1044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1044);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f22,f3,f10
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// lfs f20,1016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1016);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// lfs f18,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,1052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1052);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f18.f64 = double(temp.f32);
	// lfs f10,1128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1128);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// fmsubs f25,f25,f11,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 - ctx.f24.f64));
	// lfs f21,872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 872);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f10,f21
	ctx.f21.f64 = double(float(ctx.f10.f64 * ctx.f21.f64));
	// lfs f27,1036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1036);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f23,f3
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f26,952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 952);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f22,f0
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// lfs f22,3760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3760);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f3,f22
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// fmuls f27,f27,f9
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// fmuls f26,f26,f9
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// fmadds f20,f20,f10,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 + ctx.f19.f64));
	// lfs f19,880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 880);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f10,f19
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f19.f64));
	// fmuls f31,f18,f8
	ctx.f31.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// fnmsubs f10,f30,f13,f25
	ctx.f10.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f25.f64)));
	// lfs f30,960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 960);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f3
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f3.f64));
	// fmsubs f25,f24,f0,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 - ctx.f23.f64));
	// lfs f24,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f24.f64));
	// lfs f23,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f23,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f7,f31,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f31.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fmadds f10,f29,f11,f10
	ctx.f10.f64 = double(float(ctx.f29.f64 * ctx.f11.f64 + ctx.f10.f64));
	// lfs f29,888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 888);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f29,f3
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// fmadds f25,f22,f0,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 + ctx.f25.f64));
	// lfs f22,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f31,f28,f8
	ctx.f31.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// lfs f28,3768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3768);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// fmuls f28,f9,f28
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fnmsubs f10,f27,f11,f10
	ctx.f10.f64 = double(float(-(ctx.f27.f64 * ctx.f11.f64 - ctx.f10.f64)));
	// lfs f27,1000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1000);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f3
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// fnmsubs f30,f30,f12,f25
	ctx.f30.f64 = double(float(-(ctx.f30.f64 * ctx.f12.f64 - ctx.f25.f64)));
	// lfs f25,896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 896);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f5
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f5.f64));
	// fnmsubs f7,f31,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f31.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// lfs f31,3776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3776);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f23,f23,f8
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fmuls f22,f9,f31
	ctx.f22.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fnmsubs f31,f26,f11,f10
	ctx.f31.f64 = double(float(-(ctx.f26.f64 * ctx.f11.f64 - ctx.f10.f64)));
	// lfs f10,968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 968);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f26,f10,f3
	ctx.f26.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f10,904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 904);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f18,f10,f5
	ctx.f18.f64 = double(float(ctx.f10.f64 * ctx.f5.f64));
	// fnmsubs f29,f29,f12,f30
	ctx.f29.f64 = double(float(-(ctx.f29.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// lfs f30,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f25,f25,f30
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f30.f64));
	// fmadds f10,f23,f0,f7
	ctx.f10.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f7.f64));
	// stfs f10,4732(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4732, temp.u32);
	// lfs f7,3784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3784);
	ctx.f7.f64 = double(temp.f32);
	// lfs f10,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f23,f7,f10
	ctx.f23.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// lfs f7,1216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1216);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f31,f21,f7,f31
	ctx.f31.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f31.f64)));
	// fnmsubs f29,f27,f12,f29
	ctx.f29.f64 = double(float(-(ctx.f27.f64 * ctx.f12.f64 - ctx.f29.f64)));
	// fmsubs f27,f18,f30,f25
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 - ctx.f25.f64));
	// fmadds f31,f20,f7,f31
	ctx.f31.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f31.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f29,f26,f12,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f29.f64));
	// stfs f29,4740(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4740, temp.u32);
	// lfs f17,1904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1904);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,3840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3840);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f17,912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 912);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f5
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f5.f64));
	// lfs f20,3832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3832);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f15,1156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1156);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,1764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1764);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// fnmsubs f29,f19,f7,f31
	ctx.f29.f64 = double(float(-(ctx.f19.f64 * ctx.f7.f64 - ctx.f31.f64)));
	// lfs f31,-29840(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29840);
	ctx.f31.f64 = double(temp.f32);
	// stfs f31,324(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f19,1032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1032);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f9
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f9.f64));
	// fmuls f18,f18,f10
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64));
	// fmuls f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// fmadds f20,f15,f13,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f20.f64));
	// lfs f15,920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 920);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f3
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// fnmsubs f29,f24,f31,f29
	ctx.f29.f64 = double(float(-(ctx.f24.f64 * ctx.f31.f64 - ctx.f29.f64)));
	// lfs f31,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// fmadds f29,f28,f31,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f31.f64 + ctx.f29.f64));
	// fnmsubs f29,f22,f31,f29
	ctx.f29.f64 = double(float(-(ctx.f22.f64 * ctx.f31.f64 - ctx.f29.f64)));
	// stfs f29,4736(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4736, temp.u32);
	// lfs f29,3792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3792);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f29,f10
	ctx.f28.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f29,3800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3800);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f26,f29,f10
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f29,3808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3808);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f25,f29,f10
	ctx.f25.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f29,3816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3816);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f24,f29,f10
	ctx.f24.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f29,3824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3824);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f22,f3,f29
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f29.f64));
	// lfs f29,1756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1756);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f21,f29,f3
	ctx.f21.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// lfs f29,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f28,f29
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f29.f64));
	// fmsubs f28,f26,f29,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f29.f64 - ctx.f28.f64));
	// lfs f26,976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 976);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f9
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// fnmsubs f25,f25,f29,f28
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f29.f64 - ctx.f28.f64)));
	// lfs f28,1008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1008);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f9,f28
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// lfs f28,1712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1712);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f26,f26,f11,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f11.f64 - ctx.f19.f64));
	// fmadds f27,f23,f28,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f28.f64 + ctx.f27.f64));
	// lfs f23,928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 928);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// fmsubs f28,f18,f28,f17
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 - ctx.f17.f64));
	// fmadds f25,f24,f29,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 + ctx.f25.f64));
	// lfs f29,-30160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30160);
	ctx.f29.f64 = double(temp.f32);
	// lfs f24,3856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3856);
	ctx.f24.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f24,f24,f29
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f29.f64));
	// lfs f29,3864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3864);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f19,f29,f10
	ctx.f19.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f29,984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 984);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f18,f29,f5
	ctx.f18.f64 = double(float(ctx.f29.f64 * ctx.f5.f64));
	// lfs f29,936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 936);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f17,f29,f3
	ctx.f17.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// lfs f29,1024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1024);
	ctx.f29.f64 = double(temp.f32);
	// fnmsubs f26,f14,f11,f26
	ctx.f26.f64 = double(float(-(ctx.f14.f64 * ctx.f11.f64 - ctx.f26.f64)));
	// fmuls f14,f29,f9
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f9.f64));
	// lfs f29,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f29.f64 = double(temp.f32);
	// fnmsubs f27,f23,f29,f27
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f29.f64 - ctx.f27.f64)));
	// lfs f29,1928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1928);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f23,f29,f10
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f29,-30188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -30188);
	ctx.f29.f64 = double(temp.f32);
	// fnmsubs f25,f22,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// lfs f22,1164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1164);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f29,f22,f29,f24
	ctx.f29.f64 = double(float(ctx.f22.f64 * ctx.f29.f64 - ctx.f24.f64));
	// lfs f24,1892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1892);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f24.f64));
	// fmadds f30,f18,f30,f28
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 + ctx.f28.f64));
	// lfs f28,944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 944);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f5,f28,f5
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f5.f64));
	// lfs f22,992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 992);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f28,f21,f13,f25
	ctx.f28.f64 = double(float(-(ctx.f21.f64 * ctx.f13.f64 - ctx.f25.f64)));
	// lfs f25,1724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1724);
	ctx.f25.f64 = double(temp.f32);
	// lfs f21,864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 864);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f26,f14,f11,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 + ctx.f26.f64));
	// fmuls f25,f25,f3
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// lfs f19,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f22,f22,f9
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f9.f64));
	// lfs f18,1180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1180);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmsubs f29,f29,f10,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f10.f64 - ctx.f24.f64));
	// stfs f29,4748(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4748, temp.u32);
	// lfs f29,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f29.f64 = double(temp.f32);
	// fnmsubs f5,f5,f29,f30
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f29.f64 - ctx.f30.f64)));
	// lfs f30,868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 868);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f3,f20,f3,f28
	ctx.f3.f64 = double(float(ctx.f20.f64 * ctx.f3.f64 + ctx.f28.f64));
	// stfs f5,4752(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4752, temp.u32);
	// lfs f28,1712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1712);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f23,f28,f27
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f28.f64 + ctx.f27.f64));
	// stfs f28,4744(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4744, temp.u32);
	// fnmsubs f5,f22,f11,f26
	ctx.f5.f64 = double(float(-(ctx.f22.f64 * ctx.f11.f64 - ctx.f26.f64)));
	// lfs f27,1592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1592);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f30,f30,f11,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f11.f64 + ctx.f21.f64));
	// lfs f29,1576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1576);
	ctx.f29.f64 = double(temp.f32);
	// lfs f28,1584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1584);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f29,f8,f29
	ctx.f29.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// fadds f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// lfs f22,876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	ctx.f22.f64 = double(temp.f32);
	// lfs f27,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f27.f64 = double(temp.f32);
	// lfs f21,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f27,f10,f27
	ctx.f27.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// lfs f26,1600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1600);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f11,f16,f13,f3
	ctx.f11.f64 = double(float(-(ctx.f16.f64 * ctx.f13.f64 - ctx.f3.f64)));
	// lfs f3,1568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1568);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f8,f3
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// lfs f20,1624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1624);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f26,f8,f26
	ctx.f26.f64 = double(float(ctx.f8.f64 * ctx.f26.f64));
	// fmuls f20,f8,f20
	ctx.f20.f64 = double(float(ctx.f8.f64 * ctx.f20.f64));
	// fmadds f30,f30,f9,f5
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 + ctx.f5.f64));
	// lfs f5,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f22,f5
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// fmuls f28,f28,f8
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// fmuls f19,f5,f19
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// fmadds f11,f15,f12,f11
	ctx.f11.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f11.f64));
	// fnmsubs f30,f22,f7,f30
	ctx.f30.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f30.f64)));
	// lfs f22,1172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1172);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f8,f22
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f22.f64));
	// fnmsubs f11,f17,f12,f11
	ctx.f11.f64 = double(float(-(ctx.f17.f64 * ctx.f12.f64 - ctx.f11.f64)));
	// lfs f17,1188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1188);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f18.f64));
	// lfs f17,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f10,f17
	ctx.f17.f64 = double(float(ctx.f10.f64 * ctx.f17.f64));
	// fmadds f30,f21,f7,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 + ctx.f30.f64));
	// fmadds f11,f25,f13,f11
	ctx.f11.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f11.f64));
	// stfs f11,4756(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4756, temp.u32);
	// lfs f11,1560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1560);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// fmuls f25,f11,f12
	ctx.f25.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f11,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f24,f10,f11
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f11,1608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1608);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f23,f8,f11
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// lfs f11,4792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4792);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f27,f27,f11
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// fmsubs f3,f3,f13,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 - ctx.f25.f64));
	// fmuls f25,f24,f11
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// lfs f24,1616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1616);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f8,f24
	ctx.f24.f64 = double(float(ctx.f8.f64 * ctx.f24.f64));
	// fnmsubs f3,f29,f13,f3
	ctx.f3.f64 = double(float(-(ctx.f29.f64 * ctx.f13.f64 - ctx.f3.f64)));
	// lfs f29,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f9,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// fmadds f3,f28,f13,f3
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 + ctx.f3.f64));
	// lfs f28,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f5,f28,f5
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f5.f64));
	// lfs f28,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f28.f64));
	// lfs f28,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f3,f27,f6,f3
	ctx.f3.f64 = double(float(-(ctx.f27.f64 * ctx.f6.f64 - ctx.f3.f64)));
	// lfs f21,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f30,f19,f7,f30
	ctx.f30.f64 = double(float(-(ctx.f19.f64 * ctx.f7.f64 - ctx.f30.f64)));
	// lfs f27,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f28,f10,f28
	ctx.f28.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// lfs f10,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// lfs f19,1196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1196);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f21,f21,f10
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// lfs f10,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f27,f10,f27
	ctx.f27.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// lwz r31,5124(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 5124);
	// fmuls f19,f19,f9
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f9.f64));
	// lwz r11,5148(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 5148);
	// addi r6,r31,100
	ctx.r6.s64 = ctx.r31.s64 + 100;
	// addi r5,r11,100
	ctx.r5.s64 = ctx.r11.s64 + 100;
	// addi r4,r1,4288
	ctx.r4.s64 = ctx.r1.s64 + 4288;
	// fmadds f3,f26,f12,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f3.f64));
	// li r3,11
	ctx.r3.s64 = 11;
	// fnmsubs f30,f29,f7,f30
	ctx.f30.f64 = double(float(-(ctx.f29.f64 * ctx.f7.f64 - ctx.f30.f64)));
	// fmuls f28,f28,f11
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// lfs f11,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f10,f11
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f11,1204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1204);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f9,f11,f9
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f11,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f29,f27,f8
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// lfs f27,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f11
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// fnmsubs f3,f25,f6,f3
	ctx.f3.f64 = double(float(-(ctx.f25.f64 * ctx.f6.f64 - ctx.f3.f64)));
	// fmadds f7,f5,f7,f30
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 + ctx.f30.f64));
	// fmuls f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// fmadds f5,f23,f12,f3
	ctx.f5.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 + ctx.f3.f64));
	// lfs f3,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f7,f21,f3,f7
	ctx.f7.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 + ctx.f7.f64));
	// fnmsubs f5,f24,f13,f5
	ctx.f5.f64 = double(float(-(ctx.f24.f64 * ctx.f13.f64 - ctx.f5.f64)));
	// fmadds f7,f19,f31,f7
	ctx.f7.f64 = double(float(ctx.f19.f64 * ctx.f31.f64 + ctx.f7.f64));
	// fmadds f13,f20,f13,f5
	ctx.f13.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f5.f64));
	// fnmsubs f9,f9,f31,f7
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f31.f64 - ctx.f7.f64)));
	// stfs f9,4760(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4760, temp.u32);
	// lfs f9,1212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1212);
	ctx.f9.f64 = double(temp.f32);
	// lfs f7,828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 828);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f13,f22,f12,f13
	ctx.f13.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f13.f64)));
	// lfs f12,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f13,f18,f12,f13
	ctx.f13.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f13.f64)));
	// lfs f12,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f13,f17,f6,f13
	ctx.f13.f64 = double(float(-(ctx.f17.f64 * ctx.f6.f64 - ctx.f13.f64)));
	// fnmsubs f13,f28,f6,f13
	ctx.f13.f64 = double(float(-(ctx.f28.f64 * ctx.f6.f64 - ctx.f13.f64)));
	// fmadds f13,f29,f0,f13
	ctx.f13.f64 = double(float(ctx.f29.f64 * ctx.f0.f64 + ctx.f13.f64));
	// fnmsubs f13,f10,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f10.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// lfs f10,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f10.f64 = double(temp.f32);
	// fadds f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// lfs f10,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// fmadds f12,f12,f2,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 + ctx.f10.f64));
	// fmuls f10,f27,f8
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// fmsubs f12,f9,f1,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f1.f64 - ctx.f12.f64));
	// lfs f9,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// lfs f9,1048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1048);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f13,f10,f0,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f10,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f10.f64 = double(temp.f32);
	// fadds f9,f9,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// fmadds f12,f10,f4,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 + ctx.f12.f64));
	// lfs f10,720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 720);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f8,1784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1784);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f12,f10,f8,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f8.f64 + ctx.f12.f64));
	// fnmsubs f0,f11,f0,f13
	ctx.f0.f64 = double(float(-(ctx.f11.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// stfs f0,4764(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4764, temp.u32);
	// lfs f0,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f13,f0,f4,f12
	ctx.f13.f64 = double(float(-(ctx.f0.f64 * ctx.f4.f64 - ctx.f12.f64)));
	// lfs f12,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,1264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1264);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f13,f12,f0,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f12,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f12,f2,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 + ctx.f13.f64));
	// lfs f12,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f12,f11,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f13.f64));
	// lfs f12,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f13,f12,f1,f13
	ctx.f13.f64 = double(float(-(ctx.f12.f64 * ctx.f1.f64 - ctx.f13.f64)));
	// fmadds f0,f9,f0,f13
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f13,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f0,f13,f1,f0
	ctx.f0.f64 = double(float(-(ctx.f13.f64 * ctx.f1.f64 - ctx.f0.f64)));
	// stfs f0,4768(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4768, temp.u32);
	// bl 0x82a64ab8
	ctx.lr = 0x82A76E10;
	sub_82A64AB8(ctx, base);
loc_82A76E10:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,5104
	ctx.r1.s64 = ctx.r1.s64 + 5104;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c58c
	ctx.lr = 0x82A76E20;
	__restfpr_14(ctx, base);
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A76E28"))) PPC_WEAK_FUNC(sub_82A76E28);
PPC_FUNC_IMPL(__imp__sub_82A76E28) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r5,8(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// b 0x82a7de78
	sub_82A7DE78(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A76E48"))) PPC_WEAK_FUNC(sub_82A76E48);
PPC_FUNC_IMPL(__imp__sub_82A76E48) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// cmplwi cr6,r11,118
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 118, ctx.xer);
	// bne cr6,0x82a76edc
	if (!ctx.cr6.eq) goto loc_82A76EDC;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A76E6C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82a76e6c
	if (!ctx.cr6.eq) goto loc_82A76E6C;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// subf r10,r3,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r3.s64;
	// cmpwi cr6,r10,3
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 3, ctx.xer);
	// ble cr6,0x82a76edc
	if (!ctx.cr6.gt) goto loc_82A76EDC;
	// addi r31,r11,-3
	ctx.r31.s64 = ctx.r11.s64 + -3;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r4,r11,-28736
	ctx.r4.s64 = ctx.r11.s64 + -28736;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d625b0
	ctx.lr = 0x82A76EB0;
	sub_82D625B0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a76ed4
	if (ctx.cr0.eq) goto loc_82A76ED4;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r4,r11,-28740
	ctx.r4.s64 = ctx.r11.s64 + -28740;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d625b0
	ctx.lr = 0x82A76ECC;
	sub_82D625B0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a76edc
	if (!ctx.cr0.eq) goto loc_82A76EDC;
loc_82A76ED4:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82a76ee0
	goto loc_82A76EE0;
loc_82A76EDC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A76EE0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A76EF8"))) PPC_WEAK_FUNC(sub_82A76EF8);
PPC_FUNC_IMPL(__imp__sub_82A76EF8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A76F00;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,118
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 118, ctx.xer);
	// bne cr6,0x82a76fa0
	if (!ctx.cr6.eq) goto loc_82A76FA0;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A76F20:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82a76f20
	if (!ctx.cr6.eq) goto loc_82A76F20;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// subf r10,r31,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r31.s64;
	// cmpwi cr6,r10,3
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 3, ctx.xer);
	// ble cr6,0x82a76fa0
	if (!ctx.cr6.gt) goto loc_82A76FA0;
	// addi r30,r11,-3
	ctx.r30.s64 = ctx.r11.s64 + -3;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r4,r11,-28736
	ctx.r4.s64 = ctx.r11.s64 + -28736;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82d625b0
	ctx.lr = 0x82A76F64;
	sub_82D625B0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a76f78
	if (!ctx.cr0.eq) goto loc_82A76F78;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r11,-29708
	ctx.r3.s64 = ctx.r11.s64 + -29708;
	// b 0x82a76fd8
	goto loc_82A76FD8;
loc_82A76F78:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r4,r11,-28740
	ctx.r4.s64 = ctx.r11.s64 + -28740;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82d625b0
	ctx.lr = 0x82A76F8C;
	sub_82D625B0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a76fa0
	if (!ctx.cr0.eq) goto loc_82A76FA0;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r11,-29720
	ctx.r3.s64 = ctx.r11.s64 + -29720;
	// b 0x82a76fd8
	goto loc_82A76FD8;
loc_82A76FA0:
	// rlwinm. r11,r29,0,11,11
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x100000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a76fd4
	if (!ctx.cr0.eq) goto loc_82A76FD4;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,118
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 118, ctx.xer);
	// bne cr6,0x82a76fc4
	if (!ctx.cr6.eq) goto loc_82A76FC4;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r31,r11,-16852
	ctx.r31.s64 = ctx.r11.s64 + -16852;
	// b 0x82a76fd4
	goto loc_82A76FD4;
loc_82A76FC4:
	// cmpwi cr6,r11,112
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 112, ctx.xer);
	// bne cr6,0x82a76fd4
	if (!ctx.cr6.eq) goto loc_82A76FD4;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r31,r11,-16860
	ctx.r31.s64 = ctx.r11.s64 + -16860;
loc_82A76FD4:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82A76FD8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A76FE0"))) PPC_WEAK_FUNC(sub_82A76FE0);
PPC_FUNC_IMPL(__imp__sub_82A76FE0) {
	PPC_FUNC_PROLOGUE();
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82a76ffc
	if (!ctx.cr6.eq) goto loc_82A76FFC;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82a77070
	goto loc_82A77070;
loc_82A76FFC:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r31,0
	ctx.r31.s64 = 0;
	// li r6,49
	ctx.r6.s64 = 49;
	// addi r30,r11,-29368
	ctx.r30.s64 = ctx.r11.s64 + -29368;
loc_82A7700C:
	// add r11,r6,r31
	ctx.r11.u64 = ctx.r6.u64 + ctx.r31.u64;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// rlwinm r9,r11,31,1,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// lwzx r11,r11,r30
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
loc_82A77020:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82a77044
	if (ctx.cr0.eq) goto loc_82A77044;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82a77020
	if (ctx.cr6.eq) goto loc_82A77020;
loc_82A77044:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq 0x82a7707c
	if (ctx.cr0.eq) goto loc_82A7707C;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// bge cr6,0x82a7705c
	if (!ctx.cr6.lt) goto loc_82A7705C;
	// addi r31,r9,1
	ctx.r31.s64 = ctx.r9.s64 + 1;
	// b 0x82a77060
	goto loc_82A77060;
loc_82A7705C:
	// mr r6,r9
	ctx.r6.u64 = ctx.r9.u64;
loc_82A77060:
	// cmplw cr6,r31,r6
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r6.u32, ctx.xer);
	// blt cr6,0x82a7700c
	if (ctx.cr6.lt) goto loc_82A7700C;
loc_82A77068:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_82A77070:
	// ld r30,-16(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
loc_82A7707C:
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// addi r10,r30,8
	ctx.r10.s64 = ctx.r30.s64 + 8;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// and r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 & ctx.r4.u64;
	// cmplw cr6,r10,r4
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, ctx.xer);
	// bne cr6,0x82a77068
	if (!ctx.cr6.eq) goto loc_82A77068;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82a770b8
	if (ctx.cr6.eq) goto loc_82A770B8;
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,4(r5)
	PPC_STORE_U32(ctx.r5.u32 + 4, ctx.r10.u32);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// stw r11,8(r5)
	PPC_STORE_U32(ctx.r5.u32 + 8, ctx.r11.u32);
loc_82A770B8:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82a77070
	goto loc_82A77070;
}

__attribute__((alias("__imp__sub_82A770C0"))) PPC_WEAK_FUNC(sub_82A770C0);
PPC_FUNC_IMPL(__imp__sub_82A770C0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r9,49
	ctx.r9.s64 = 49;
	// addi r10,r11,-29368
	ctx.r10.s64 = ctx.r11.s64 + -29368;
	// addi r11,r10,596
	ctx.r11.s64 = ctx.r10.s64 + 596;
loc_82A770D0:
	// addi r11,r11,-12
	ctx.r11.s64 = ctx.r11.s64 + -12;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// lwz r8,-4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	// cmplw cr6,r8,r3
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r3.u32, ctx.xer);
	// bne cr6,0x82a770f4
	if (!ctx.cr6.eq) goto loc_82A770F4;
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// and r8,r8,r4
	ctx.r8.u64 = ctx.r8.u64 & ctx.r4.u64;
	// cmplw cr6,r8,r4
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r4.u32, ctx.xer);
	// beq cr6,0x82a7710c
	if (ctx.cr6.eq) goto loc_82A7710C;
loc_82A770F4:
	// addi r8,r10,8
	ctx.r8.s64 = ctx.r10.s64 + 8;
	// cmplw cr6,r11,r8
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r8.u32, ctx.xer);
	// bgt cr6,0x82a770d0
	if (ctx.cr6.gt) goto loc_82A770D0;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// blr 
	return;
loc_82A7710C:
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82a77134
	if (ctx.cr6.eq) goto loc_82A77134;
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,4(r5)
	PPC_STORE_U32(ctx.r5.u32 + 4, ctx.r10.u32);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// stw r11,8(r5)
	PPC_STORE_U32(ctx.r5.u32 + 8, ctx.r11.u32);
loc_82A77134:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A77140"))) PPC_WEAK_FUNC(sub_82A77140);
PPC_FUNC_IMPL(__imp__sub_82A77140) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A77148;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r28,0
	ctx.r28.s64 = 0;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r29,r28
	ctx.r29.u64 = ctx.r28.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne cr6,0x82a7716c
	if (!ctx.cr6.eq) goto loc_82A7716C;
	// lis r29,-32761
	ctx.r29.s64 = -2147024896;
	// ori r29,r29,87
	ctx.r29.u64 = ctx.r29.u64 | 87;
	// b 0x82a771a0
	goto loc_82A771A0;
loc_82A7716C:
	// addi r31,r4,-1
	ctx.r31.s64 = ctx.r4.s64 + -1;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82d60820
	ctx.lr = 0x82A7717C;
	sub_82D60820(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a77194
	if (ctx.cr0.lt) goto loc_82A77194;
	// cmplw cr6,r3,r31
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r31.u32, ctx.xer);
	// bgt cr6,0x82a77194
	if (ctx.cr6.gt) goto loc_82A77194;
	// bne cr6,0x82a771a0
	if (!ctx.cr6.eq) goto loc_82A771A0;
	// b 0x82a7719c
	goto loc_82A7719C;
loc_82A77194:
	// lis r29,-32761
	ctx.r29.s64 = -2147024896;
	// ori r29,r29,122
	ctx.r29.u64 = ctx.r29.u64 | 122;
loc_82A7719C:
	// stbx r28,r31,r30
	PPC_STORE_U8(ctx.r31.u32 + ctx.r30.u32, ctx.r28.u8);
loc_82A771A0:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A771B0"))) PPC_WEAK_FUNC(sub_82A771B0);
PPC_FUNC_IMPL(__imp__sub_82A771B0) {
	PPC_FUNC_PROLOGUE();
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// b 0x8247f370
	sub_8247F370(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A771B8"))) PPC_WEAK_FUNC(sub_82A771B8);
PPC_FUNC_IMPL(__imp__sub_82A771B8) {
	PPC_FUNC_PROLOGUE();
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// b 0x8247f398
	sub_8247F398(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A771C0"))) PPC_WEAK_FUNC(sub_82A771C0);
PPC_FUNC_IMPL(__imp__sub_82A771C0) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lis r10,-32230
	ctx.r10.s64 = -2112225280;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// addi r4,r10,5983
	ctx.r4.s64 = ctx.r10.s64 + 5983;
	// lwz r8,16(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r6,8(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r5,4(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// b 0x82a7df78
	sub_82A7DF78(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A771E8"))) PPC_WEAK_FUNC(sub_82A771E8);
PPC_FUNC_IMPL(__imp__sub_82A771E8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A771F0;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r31,0
	ctx.r31.s64 = 0;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82a7720c
	if (ctx.cr6.eq) goto loc_82A7720C;
	// stw r31,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r31.u32);
loc_82A7720C:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82a77220
	if (!ctx.cr6.eq) goto loc_82A77220;
loc_82A77214:
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82a772c8
	goto loc_82A772C8;
loc_82A77220:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82a77214
	if (ctx.cr6.eq) goto loc_82A77214;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lis r10,4138
	ctx.r10.s64 = 271187968;
	// ori r10,r10,4352
	ctx.r10.u64 = ctx.r10.u64 | 4352;
	// rlwinm r9,r11,0,0,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF00;
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a7725c
	if (ctx.cr6.eq) goto loc_82A7725C;
	// rlwinm r11,r11,0,0,15
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFF0000;
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a7725c
	if (ctx.cr6.eq) goto loc_82A7725C;
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82a772c0
	if (!ctx.cr6.eq) goto loc_82A772C0;
loc_82A7725C:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x8247f370
	ctx.lr = 0x82A77268;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a77278
	if (ctx.cr0.eq) goto loc_82A77278;
	// bl 0x82a84658
	ctx.lr = 0x82A77274;
	sub_82A84658(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
loc_82A77278:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82a7728c
	if (!ctx.cr6.eq) goto loc_82A7728C;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82a772c8
	goto loc_82A772C8;
loc_82A7728C:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a84b80
	ctx.lr = 0x82A7729C;
	sub_82A84B80(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bge 0x82a772c0
	if (!ctx.cr0.lt) goto loc_82A772C0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a83840
	ctx.lr = 0x82A772AC;
	sub_82A83840(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A772B8;
	sub_8247F398(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// b 0x82a772c8
	goto loc_82A772C8;
loc_82A772C0:
	// stw r31,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A772C8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A772D0"))) PPC_WEAK_FUNC(sub_82A772D0);
PPC_FUNC_IMPL(__imp__sub_82A772D0) {
	PPC_FUNC_PROLOGUE();
	// b 0x82a771e8
	sub_82A771E8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A772D8"))) PPC_WEAK_FUNC(sub_82A772D8);
PPC_FUNC_IMPL(__imp__sub_82A772D8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,32767
	ctx.r11.s64 = 2147418112;
	// ori r11,r11,65535
	ctx.r11.u64 = ctx.r11.u64 | 65535;
	// cmplw cr6,r4,r11
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a77314
	if (!ctx.cr6.gt) goto loc_82A77314;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,87
	ctx.r3.u64 = ctx.r3.u64 | 87;
	// b 0x82a77328
	goto loc_82A77328;
loc_82A77314:
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,136
	ctx.r10.s64 = ctx.r1.s64 + 136;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82a77140
	ctx.lr = 0x82A77328;
	sub_82A77140(ctx, base);
loc_82A77328:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A77338"))) PPC_WEAK_FUNC(sub_82A77338);
PPC_FUNC_IMPL(__imp__sub_82A77338) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4a4
	ctx.lr = 0x82A77340;
	__savegprlr_19(ctx, base);
	// stwu r1,-1152(r1)
	ea = -1152 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r20,0
	ctx.r20.s64 = 0;
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// addi r3,r1,336
	ctx.r3.s64 = ctx.r1.s64 + 336;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// mr r24,r5
	ctx.r24.u64 = ctx.r5.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r20.u32);
	// mr r22,r7
	ctx.r22.u64 = ctx.r7.u64;
	// stw r20,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r20.u32);
	// mr r19,r8
	ctx.r19.u64 = ctx.r8.u64;
	// mr r21,r9
	ctx.r21.u64 = ctx.r9.u64;
	// mr r27,r10
	ctx.r27.u64 = ctx.r10.u64;
	// bl 0x82a7bd08
	ctx.lr = 0x82A77378;
	sub_82A7BD08(ctx, base);
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// beq cr6,0x82a77384
	if (ctx.cr6.eq) goto loc_82A77384;
	// stw r20,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r20.u32);
loc_82A77384:
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x82a77390
	if (ctx.cr6.eq) goto loc_82A77390;
	// stw r20,0(r21)
	PPC_STORE_U32(ctx.r21.u32 + 0, ctx.r20.u32);
loc_82A77390:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a773b0
	if (ctx.cr6.eq) goto loc_82A773B0;
	// lwz r11,20(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a773b0
	if (ctx.cr6.eq) goto loc_82A773B0;
	// lis r30,-30602
	ctx.r30.s64 = -2005532672;
	// ori r30,r30,2156
	ctx.r30.u64 = ctx.r30.u64 | 2156;
	// b 0x82a77980
	goto loc_82A77980;
loc_82A773B0:
	// lis r12,-863
	ctx.r12.s64 = -56557568;
	// ori r12,r12,57792
	ctx.r12.u64 = ctx.r12.u64 | 57792;
	// and. r11,r29,r12
	ctx.r11.u64 = ctx.r29.u64 & ctx.r12.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a773cc
	if (ctx.cr0.eq) goto loc_82A773CC;
loc_82A773C0:
	// lis r30,-30602
	ctx.r30.s64 = -2005532672;
	// ori r30,r30,2156
	ctx.r30.u64 = ctx.r30.u64 | 2156;
	// b 0x82a77964
	goto loc_82A77964;
loc_82A773CC:
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a773c0
	if (ctx.cr6.eq) goto loc_82A773C0;
	// mr r31,r20
	ctx.r31.u64 = ctx.r20.u64;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a77814
	if (ctx.cr6.eq) goto loc_82A77814;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// rlwinm. r11,r11,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a77814
	if (ctx.cr0.eq) goto loc_82A77814;
	// bl 0x82d89208
	ctx.lr = 0x82A773F4;
	sub_82D89208(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// stw r31,20(r27)
	PPC_STORE_U32(ctx.r27.u32 + 20, ctx.r31.u32);
	// bne 0x82a7740c
	if (!ctx.cr0.eq) goto loc_82A7740C;
	// lis r30,-32761
	ctx.r30.s64 = -2147024896;
	// ori r30,r30,14
	ctx.r30.u64 = ctx.r30.u64 | 14;
	// b 0x82a77964
	goto loc_82A77964;
loc_82A7740C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r11,-28452
	ctx.r4.s64 = ctx.r11.s64 + -28452;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d87458
	ctx.lr = 0x82A77420;
	sub_82D87458(ctx, base);
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77434;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a77474
	if (ctx.cr0.eq) goto loc_82A77474;
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77450;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// b 0x82a77468
	goto loc_82A77468;
loc_82A77458:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r5,4(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// bl 0x82d89b60
	ctx.lr = 0x82A77464;
	sub_82D89B60(ctx, base);
	// addi r30,r30,8
	ctx.r30.s64 = ctx.r30.s64 + 8;
loc_82A77468:
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi r4,0
	ctx.cr0.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne 0x82a77458
	if (!ctx.cr0.eq) goto loc_82A77458;
loc_82A77474:
	// clrlwi. r11,r29,31
	ctx.r11.u64 = ctx.r29.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// addi r28,r11,8328
	ctx.r28.s64 = ctx.r11.s64 + 8328;
	// lis r11,-32245
	ctx.r11.s64 = -2113208320;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// addi r26,r11,-25912
	ctx.r26.s64 = ctx.r11.s64 + -25912;
	// bne 0x82a77494
	if (!ctx.cr0.eq) goto loc_82A77494;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A77494:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28576
	ctx.r4.s64 = ctx.r11.s64 + -28576;
	// bl 0x82d89250
	ctx.lr = 0x82A774A4;
	sub_82D89250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a774b4
	if (!ctx.cr0.eq) goto loc_82A774B4;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A774B4:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28580
	ctx.r4.s64 = ctx.r11.s64 + -28580;
	// bl 0x82d89250
	ctx.lr = 0x82A774C4;
	sub_82D89250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,11,11
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x100000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a774d4
	if (!ctx.cr0.eq) goto loc_82A774D4;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A774D4:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28596
	ctx.r4.s64 = ctx.r11.s64 + -28596;
	// bl 0x82d89250
	ctx.lr = 0x82A774E4;
	sub_82D89250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,14,14
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x20000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a774f4
	if (!ctx.cr0.eq) goto loc_82A774F4;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A774F4:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28612
	ctx.r4.s64 = ctx.r11.s64 + -28612;
	// bl 0x82d89250
	ctx.lr = 0x82A77504;
	sub_82D89250(ctx, base);
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a77518
	if (!ctx.cr0.eq) goto loc_82A77518;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A77518:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28620
	ctx.r4.s64 = ctx.r11.s64 + -28620;
	// bl 0x82d89250
	ctx.lr = 0x82A77528;
	sub_82D89250(ctx, base);
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a7753c
	if (!ctx.cr0.eq) goto loc_82A7753C;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A7753C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28628
	ctx.r4.s64 = ctx.r11.s64 + -28628;
	// bl 0x82d89250
	ctx.lr = 0x82A7754C;
	sub_82D89250(ctx, base);
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// li r4,16
	ctx.r4.s64 = 16;
	// lwz r6,16(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// addi r30,r11,7996
	ctx.r30.s64 = ctx.r11.s64 + 7996;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82a772d8
	ctx.lr = 0x82A77568;
	sub_82A772D8(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r11,-28644
	ctx.r4.s64 = ctx.r11.s64 + -28644;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d89250
	ctx.lr = 0x82A7757C;
	sub_82D89250(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r6,32(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 32);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82a772d8
	ctx.lr = 0x82A77590;
	sub_82A772D8(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r11,-28656
	ctx.r4.s64 = ctx.r11.s64 + -28656;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d89250
	ctx.lr = 0x82A775A4;
	sub_82D89250(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r6,36(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 36);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82a772d8
	ctx.lr = 0x82A775B8;
	sub_82A772D8(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r11,-28668
	ctx.r4.s64 = ctx.r11.s64 + -28668;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d89250
	ctx.lr = 0x82A775CC;
	sub_82D89250(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r6,40(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 40);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82a772d8
	ctx.lr = 0x82A775E0;
	sub_82A772D8(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r11,-28680
	ctx.r4.s64 = ctx.r11.s64 + -28680;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d89250
	ctx.lr = 0x82A775F4;
	sub_82D89250(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r6,44(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 44);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82a772d8
	ctx.lr = 0x82A77608;
	sub_82A772D8(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r11,-28692
	ctx.r4.s64 = ctx.r11.s64 + -28692;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d89250
	ctx.lr = 0x82A7761C;
	sub_82D89250(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r6,52(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 52);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82a772d8
	ctx.lr = 0x82A77630;
	sub_82A772D8(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r11,-28704
	ctx.r4.s64 = ctx.r11.s64 + -28704;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d89250
	ctx.lr = 0x82A77644;
	sub_82D89250(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r6,48(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 48);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82a772d8
	ctx.lr = 0x82A77658;
	sub_82A772D8(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r11,-28716
	ctx.r4.s64 = ctx.r11.s64 + -28716;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d89250
	ctx.lr = 0x82A7766C;
	sub_82D89250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x4;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a7767c
	if (!ctx.cr0.eq) goto loc_82A7767C;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A7767C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28456
	ctx.r4.s64 = ctx.r11.s64 + -28456;
	// bl 0x82d89250
	ctx.lr = 0x82A7768C;
	sub_82D89250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x8;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a7769c
	if (!ctx.cr0.eq) goto loc_82A7769C;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A7769C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28464
	ctx.r4.s64 = ctx.r11.s64 + -28464;
	// bl 0x82d89250
	ctx.lr = 0x82A776AC;
	sub_82D89250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a776bc
	if (!ctx.cr0.eq) goto loc_82A776BC;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A776BC:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28472
	ctx.r4.s64 = ctx.r11.s64 + -28472;
	// bl 0x82d89250
	ctx.lr = 0x82A776CC;
	sub_82D89250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a776dc
	if (!ctx.cr0.eq) goto loc_82A776DC;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A776DC:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28480
	ctx.r4.s64 = ctx.r11.s64 + -28480;
	// bl 0x82d89250
	ctx.lr = 0x82A776EC;
	sub_82D89250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,23,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x100;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a776fc
	if (!ctx.cr0.eq) goto loc_82A776FC;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A776FC:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28484
	ctx.r4.s64 = ctx.r11.s64 + -28484;
	// bl 0x82d89250
	ctx.lr = 0x82A7770C;
	sub_82D89250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,22,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x200;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a7771c
	if (!ctx.cr0.eq) goto loc_82A7771C;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A7771C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28492
	ctx.r4.s64 = ctx.r11.s64 + -28492;
	// bl 0x82d89250
	ctx.lr = 0x82A7772C;
	sub_82D89250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,21,21
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x400;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a7773c
	if (!ctx.cr0.eq) goto loc_82A7773C;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A7773C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28500
	ctx.r4.s64 = ctx.r11.s64 + -28500;
	// bl 0x82d89250
	ctx.lr = 0x82A7774C;
	sub_82D89250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,13,13
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x40000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a7775c
	if (!ctx.cr0.eq) goto loc_82A7775C;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A7775C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28516
	ctx.r4.s64 = ctx.r11.s64 + -28516;
	// bl 0x82d89250
	ctx.lr = 0x82A7776C;
	sub_82D89250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,9,9
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x400000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a7777c
	if (!ctx.cr0.eq) goto loc_82A7777C;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A7777C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28524
	ctx.r4.s64 = ctx.r11.s64 + -28524;
	// bl 0x82d89250
	ctx.lr = 0x82A7778C;
	sub_82D89250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,6,6
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x2000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a7779c
	if (!ctx.cr0.eq) goto loc_82A7779C;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A7779C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28532
	ctx.r4.s64 = ctx.r11.s64 + -28532;
	// bl 0x82d89250
	ctx.lr = 0x82A777AC;
	sub_82D89250(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,7,7
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x1000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a777bc
	if (!ctx.cr0.eq) goto loc_82A777BC;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A777BC:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28540
	ctx.r4.s64 = ctx.r11.s64 + -28540;
	// bl 0x82d89250
	ctx.lr = 0x82A777CC;
	sub_82D89250(ctx, base);
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r11,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a777e0
	if (!ctx.cr0.eq) goto loc_82A777E0;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A777E0:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28560
	ctx.r4.s64 = ctx.r11.s64 + -28560;
	// bl 0x82d89250
	ctx.lr = 0x82A777F0;
	sub_82D89250(ctx, base);
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r11,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a77804
	if (!ctx.cr0.eq) goto loc_82A77804;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82A77804:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-28572
	ctx.r4.s64 = ctx.r11.s64 + -28572;
	// bl 0x82d89250
	ctx.lr = 0x82A77814;
	sub_82D89250(ctx, base);
loc_82A77814:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// bl 0x82a76ef8
	ctx.lr = 0x82A77820;
	sub_82A76EF8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// stw r27,1028(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1028, ctx.r27.u32);
	// addi r4,r1,336
	ctx.r4.s64 = ctx.r1.s64 + 336;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// stw r11,0(r24)
	PPC_STORE_U32(ctx.r24.u32 + 0, ctx.r11.u32);
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77844;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a77964
	if (ctx.cr0.lt) goto loc_82A77964;
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// bl 0x82a76e48
	ctx.lr = 0x82A77854;
	sub_82A76E48(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// addi r3,r1,336
	ctx.r3.s64 = ctx.r1.s64 + 336;
	// beq 0x82a7786c
	if (ctx.cr0.eq) goto loc_82A7786C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r4,r11,-28752
	ctx.r4.s64 = ctx.r11.s64 + -28752;
	// b 0x82a77874
	goto loc_82A77874;
loc_82A7786C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r4,r11,-28768
	ctx.r4.s64 = ctx.r11.s64 + -28768;
loc_82A77874:
	// bl 0x82a7cf00
	ctx.lr = 0x82A77878;
	sub_82A7CF00(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82a8d1d0
	ctx.lr = 0x82A77884;
	sub_82A8D1D0(ctx, base);
	// addi r11,r1,100
	ctx.r11.s64 = ctx.r1.s64 + 100;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwz r8,0(r24)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// ori r9,r29,256
	ctx.r9.u64 = ctx.r29.u64 | 256;
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r27.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r23
	ctx.r6.u64 = ctx.r23.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// addi r4,r1,336
	ctx.r4.s64 = ctx.r1.s64 + 336;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82aa3108
	ctx.lr = 0x82A778B4;
	sub_82AA3108(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bge 0x82a778c8
	if (!ctx.cr0.lt) goto loc_82A778C8;
	// bl 0x82a8f148
	ctx.lr = 0x82A778C4;
	sub_82A8F148(ctx, base);
	// b 0x82a77964
	goto loc_82A77964;
loc_82A778C8:
	// bl 0x82a8f148
	ctx.lr = 0x82A778CC;
	sub_82A8F148(ctx, base);
	// addi r3,r1,360
	ctx.r3.s64 = ctx.r1.s64 + 360;
	// bl 0x82a850a8
	ctx.lr = 0x82A778D4;
	sub_82A850A8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a778e8
	if (ctx.cr0.eq) goto loc_82A778E8;
	// lis r30,-30602
	ctx.r30.s64 = -2005532672;
	// ori r30,r30,2905
	ctx.r30.u64 = ctx.r30.u64 | 2905;
	// b 0x82a77964
	goto loc_82A77964;
loc_82A778E8:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82a7793c
	if (ctx.cr6.eq) goto loc_82A7793C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d89cd8
	ctx.lr = 0x82A778F8;
	sub_82D89CD8(ctx, base);
	// addi r28,r27,12
	ctx.r28.s64 = ctx.r27.s64 + 12;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82a7fd28
	ctx.lr = 0x82A77908;
	sub_82A7FD28(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7793c
	if (ctx.cr0.lt) goto loc_82A7793C;
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77924;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d89ce0
	ctx.lr = 0x82A77938;
	sub_82D89CE0(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
loc_82A7793C:
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// beq cr6,0x82a77950
	if (ctx.cr6.eq) goto loc_82A77950;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r20.u32);
	// stw r11,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r11.u32);
loc_82A77950:
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x82a77964
	if (ctx.cr6.eq) goto loc_82A77964;
	// lwz r11,100(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stw r20,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r20.u32);
	// stw r11,0(r21)
	PPC_STORE_U32(ctx.r21.u32 + 0, ctx.r11.u32);
loc_82A77964:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a77980
	if (ctx.cr6.eq) goto loc_82A77980;
	// lwz r3,20(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a77980
	if (ctx.cr0.eq) goto loc_82A77980;
	// bl 0x82274420
	ctx.lr = 0x82A7797C;
	sub_82274420(ctx, base);
	// stw r20,20(r27)
	PPC_STORE_U32(ctx.r27.u32 + 20, ctx.r20.u32);
loc_82A77980:
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// beq cr6,0x82a77994
	if (ctx.cr6.eq) goto loc_82A77994;
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// addi r3,r1,360
	ctx.r3.s64 = ctx.r1.s64 + 360;
	// bl 0x82a84fd0
	ctx.lr = 0x82A77994;
	sub_82A84FD0(ctx, base);
loc_82A77994:
	// lwz r3,100(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82a779b4
	if (ctx.cr6.eq) goto loc_82A779B4;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A779B0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r20,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r20.u32);
loc_82A779B4:
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82a779d4
	if (ctx.cr6.eq) goto loc_82A779D4;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A779D0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r20.u32);
loc_82A779D4:
	// addi r3,r1,336
	ctx.r3.s64 = ctx.r1.s64 + 336;
	// bl 0x82a7be18
	ctx.lr = 0x82A779DC;
	sub_82A7BE18(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r1,r1,1152
	ctx.r1.s64 = ctx.r1.s64 + 1152;
	// b 0x82d5c4f4
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A779E8"))) PPC_WEAK_FUNC(sub_82A779E8);
PPC_FUNC_IMPL(__imp__sub_82A779E8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c498
	ctx.lr = 0x82A779F0;
	__savegprlr_16(ctx, base);
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r30,-31980
	ctx.r30.s64 = -2095841280;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// lbz r11,27345(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 27345);
	// mr r24,r7
	ctx.r24.u64 = ctx.r7.u64;
	// mr r22,r8
	ctx.r22.u64 = ctx.r8.u64;
	// mr r21,r9
	ctx.r21.u64 = ctx.r9.u64;
	// mr r23,r10
	ctx.r23.u64 = ctx.r10.u64;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lis r29,-31980
	ctx.r29.s64 = -2095841280;
	// bne 0x82a77a58
	if (!ctx.cr0.eq) goto loc_82A77A58;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r11,-28216
	ctx.r3.s64 = ctx.r11.s64 + -28216;
	// bl 0x82a3b940
	ctx.lr = 0x82A77A34;
	sub_82A3B940(ctx, base);
	// cmpwi cr6,r3,-1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, -1, ctx.xer);
	// beq cr6,0x82a77a50
	if (ctx.cr6.eq) goto loc_82A77A50;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r11,-28304
	ctx.r3.s64 = ctx.r11.s64 + -28304;
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,27344(r29)
	PPC_STORE_U8(ctx.r29.u32 + 27344, ctx.r11.u8);
	// bl 0x82a39a40
	ctx.lr = 0x82A77A50;
	sub_82A39A40(ctx, base);
loc_82A77A50:
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,27345(r30)
	PPC_STORE_U8(ctx.r30.u32 + 27345, ctx.r11.u8);
loc_82A77A58:
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
	// mr r9,r21
	ctx.r9.u64 = ctx.r21.u64;
	// mr r8,r22
	ctx.r8.u64 = ctx.r22.u64;
	// mr r7,r24
	ctx.r7.u64 = ctx.r24.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82a77338
	ctx.lr = 0x82A77A7C;
	sub_82A77338(ctx, base);
	// mr. r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r20.s32, 0, ctx.xer);
	// blt 0x82a77ea8
	if (ctx.cr0.lt) goto loc_82A77EA8;
	// lbz r11,27344(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 27344);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a77ea8
	if (ctx.cr0.eq) goto loc_82A77EA8;
	// rlwinm. r11,r31,0,6,6
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0x2000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a77ea8
	if (!ctx.cr0.eq) goto loc_82A77EA8;
	// rlwinm. r11,r31,0,11,11
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0x100000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a77ea8
	if (!ctx.cr0.eq) goto loc_82A77EA8;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82a77ea8
	if (ctx.cr6.eq) goto loc_82A77EA8;
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a77ea8
	if (ctx.cr6.eq) goto loc_82A77EA8;
	// li r29,0
	ctx.r29.s64 = 0;
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// oris r6,r31,16
	ctx.r6.u64 = ctx.r31.u64 | 1048576;
	// oris r26,r31,512
	ctx.r26.u64 = ctx.r31.u64 | 33554432;
	// stw r29,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r29.u32);
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r29.u32);
	// lbz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// stw r29,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r29.u32);
	// stw r29,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r29.u32);
	// cmplwi cr6,r11,118
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 118, ctx.xer);
	// bne cr6,0x82a77aec
	if (!ctx.cr6.eq) goto loc_82A77AEC;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r11,r11,-16852
	ctx.r11.s64 = ctx.r11.s64 + -16852;
	// b 0x82a77af4
	goto loc_82A77AF4;
loc_82A77AEC:
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r11,r11,-16860
	ctx.r11.s64 = ctx.r11.s64 + -16860;
loc_82A77AF4:
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
	// stw r11,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r11.u32);
	// addi r9,r1,120
	ctx.r9.s64 = ctx.r1.s64 + 120;
	// addi r8,r1,116
	ctx.r8.s64 = ctx.r1.s64 + 116;
	// addi r7,r1,124
	ctx.r7.s64 = ctx.r1.s64 + 124;
	// addi r5,r1,132
	ctx.r5.s64 = ctx.r1.s64 + 132;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82a77338
	ctx.lr = 0x82A77B18;
	sub_82A77338(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a77b34
	if (!ctx.cr0.lt) goto loc_82A77B34;
	// lwz r3,116(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
loc_82A77B24:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82a77ea8
	if (ctx.cr6.eq) goto loc_82A77EA8;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// b 0x82a77e9c
	goto loc_82A77E9C;
loc_82A77B34:
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// lis r3,1
	ctx.r3.s64 = 65536;
	// bl 0x82a7fd28
	ctx.lr = 0x82A77B40;
	sub_82A7FD28(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a77b8c
	if (!ctx.cr0.lt) goto loc_82A77B8C;
	// lwz r3,116(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82a77b68
	if (ctx.cr6.eq) goto loc_82A77B68;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77B64;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r29.u32);
loc_82A77B68:
	// lwz r3,124(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82a77b84
	if (ctx.cr6.eq) goto loc_82A77B84;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77B84;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A77B84:
	// lwz r3,120(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// b 0x82a77b24
	goto loc_82A77B24;
loc_82A77B8C:
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r29,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r29.u32);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,16(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77BA4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r11,12(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77BC0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// bl 0x82d5cb60
	ctx.lr = 0x82A77BCC;
	sub_82D5CB60(ctx, base);
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82a77bdc
	if (ctx.cr6.eq) goto loc_82A77BDC;
	// lwz r30,16(r23)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r23.u32 + 16);
	// b 0x82a77be0
	goto loc_82A77BE0;
loc_82A77BDC:
	// mr r30,r29
	ctx.r30.u64 = ctx.r29.u64;
loc_82A77BE0:
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lis r11,-32047
	ctx.r11.s64 = -2100232192;
	// lwz r28,120(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// addi r19,r1,128
	ctx.r19.s64 = ctx.r1.s64 + 128;
	// addi r27,r11,-28136
	ctx.r27.s64 = ctx.r11.s64 + -28136;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,16(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77C04;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r18,r3
	ctx.r18.u64 = ctx.r3.u64;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r11,12(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77C20;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r31,124(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// mr r17,r3
	ctx.r17.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r11,16(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77C3C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r16,r3
	ctx.r16.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77C54;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r4,r16
	ctx.r4.u64 = ctx.r16.u64;
	// mr r5,r17
	ctx.r5.u64 = ctx.r17.u64;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// mr r6,r18
	ctx.r6.u64 = ctx.r18.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// mr r7,r19
	ctx.r7.u64 = ctx.r19.u64;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r29.u32);
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// bl 0x82d8df00
	ctx.lr = 0x82A77C80;
	sub_82D8DF00(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a77ce0
	if (!ctx.cr0.lt) goto loc_82A77CE0;
loc_82A77C88:
	// lwz r3,116(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82a77ca8
	if (ctx.cr6.eq) goto loc_82A77CA8;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77CA4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r29.u32);
loc_82A77CA8:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77CBC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82a77cd8
	if (ctx.cr6.eq) goto loc_82A77CD8;
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77CD8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A77CD8:
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// b 0x82a77b24
	goto loc_82A77B24;
loc_82A77CE0:
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lbz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r11,118
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 118, ctx.xer);
	// bne cr6,0x82a77d0c
	if (!ctx.cr6.eq) goto loc_82A77D0C;
	// bl 0x82212328
	ctx.lr = 0x82A77D08;
	sub_82212328(ctx, base);
	// b 0x82a77d10
	goto loc_82A77D10;
loc_82A77D0C:
	// bl 0x82212328
	ctx.lr = 0x82A77D10;
	sub_82212328(ctx, base);
loc_82A77D10:
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82a77e40
	if (!ctx.cr6.eq) goto loc_82A77E40;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r11,-28440
	ctx.r3.s64 = ctx.r11.s64 + -28440;
	// bl 0x82a39a40
	ctx.lr = 0x82A77D24;
	sub_82A39A40(ctx, base);
	// addi r4,r1,124
	ctx.r4.s64 = ctx.r1.s64 + 124;
	// lwz r3,128(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// stw r29,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r29.u32);
	// bl 0x82a7fd28
	ctx.lr = 0x82A77D34;
	sub_82A7FD28(ctx, base);
	// mr. r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r20.s32, 0, ctx.xer);
	// blt 0x82a77c88
	if (ctx.cr0.lt) goto loc_82A77C88;
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r30,128(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77D54;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r11,12(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77D70;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82d5c630
	ctx.lr = 0x82A77D7C;
	sub_82D5C630(ctx, base);
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82a77d98
	if (ctx.cr6.eq) goto loc_82A77D98;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77D98;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A77D98:
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77DB4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77DC8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r11,0(r24)
	PPC_STORE_U32(ctx.r24.u32 + 0, ctx.r11.u32);
	// lwz r3,0(r22)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a77dec
	if (ctx.cr0.eq) goto loc_82A77DEC;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77DEC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A77DEC:
	// lwz r11,116(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// stw r11,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r11.u32);
	// lwz r3,0(r21)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a77e10
	if (ctx.cr0.eq) goto loc_82A77E10;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77E10;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A77E10:
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// stw r28,0(r21)
	PPC_STORE_U32(ctx.r21.u32 + 0, ctx.r28.u32);
	// beq cr6,0x82a77ea8
	if (ctx.cr6.eq) goto loc_82A77EA8;
	// lwz r3,12(r23)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r23.u32 + 12);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a77ea8
	if (ctx.cr0.eq) goto loc_82A77EA8;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77E38;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r29,12(r23)
	PPC_STORE_U32(ctx.r23.u32 + 12, ctx.r29.u32);
	// b 0x82a77ea8
	goto loc_82A77EA8;
loc_82A77E40:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77E54;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82a77e70
	if (ctx.cr6.eq) goto loc_82A77E70;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77E70;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A77E70:
	// lwz r3,116(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82a77e8c
	if (ctx.cr6.eq) goto loc_82A77E8C;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77E8C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A77E8C:
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82a77ea8
	if (ctx.cr6.eq) goto loc_82A77EA8;
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
loc_82A77E9C:
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A77EA8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A77EA8:
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// b 0x82d5c4e8
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A77EB8"))) PPC_WEAK_FUNC(sub_82A77EB8);
PPC_FUNC_IMPL(__imp__sub_82A77EB8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b8
	ctx.lr = 0x82A77EC0;
	__savegprlr_24(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// mr r26,r8
	ctx.r26.u64 = ctx.r8.u64;
	// mr r25,r9
	ctx.r25.u64 = ctx.r9.u64;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
	// bl 0x82a779e8
	ctx.lr = 0x82A77EE8;
	sub_82A779E8(ctx, base);
	// lis r11,-30602
	ctx.r11.s64 = -2005532672;
	// ori r11,r11,2924
	ctx.r11.u64 = ctx.r11.u64 | 2924;
	// cmpw cr6,r3,r11
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82a77f24
	if (!ctx.cr6.eq) goto loc_82A77F24;
	// rlwinm. r11,r31,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0x4;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a77f24
	if (!ctx.cr0.eq) goto loc_82A77F24;
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// ori r6,r31,4
	ctx.r6.u64 = ctx.r31.u64 | 4;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82a779e8
	ctx.lr = 0x82A77F24;
	sub_82A779E8(ctx, base);
loc_82A77F24:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82d5c508
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A77F30"))) PPC_WEAK_FUNC(sub_82A77F30);
PPC_FUNC_IMPL(__imp__sub_82A77F30) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82A77F38;
	__savegprlr_26(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r31,0
	ctx.r31.s64 = 0;
	// stw r5,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r5.u32);
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// mr r26,r8
	ctx.r26.u64 = ctx.r8.u64;
	// mr r30,r9
	ctx.r30.u64 = ctx.r9.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// stw r31,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r31.u32);
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r31.u32);
	// bne cr6,0x82a77f84
	if (!ctx.cr6.eq) goto loc_82A77F84;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// mr r9,r31
	ctx.r9.u64 = ctx.r31.u64;
	// li r10,7
	ctx.r10.s64 = 7;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82A77F74:
	// std r9,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r9.u64);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// bdnz 0x82a77f74
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82A77F74;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
loc_82A77F84:
	// mr r9,r31
	ctx.r9.u64 = ctx.r31.u64;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82a77fb0
	if (ctx.cr6.eq) goto loc_82A77FB0;
	// lbz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,118
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 118, ctx.xer);
	// beq cr6,0x82a77fb0
	if (ctx.cr6.eq) goto loc_82A77FB0;
	// cmpwi cr6,r11,112
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 112, ctx.xer);
	// beq cr6,0x82a77fb0
	if (ctx.cr6.eq) goto loc_82A77FB0;
	// li r9,1
	ctx.r9.s64 = 1;
	// oris r6,r6,16
	ctx.r6.u64 = ctx.r6.u64 | 1048576;
loc_82A77FB0:
	// clrlwi. r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a78084
	if (!ctx.cr0.eq) goto loc_82A78084;
	// rlwinm. r11,r6,0,11,11
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x100000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a78084
	if (!ctx.cr0.eq) goto loc_82A78084;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// addi r8,r1,88
	ctx.r8.s64 = ctx.r1.s64 + 88;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// bl 0x82a77eb8
	ctx.lr = 0x82A77FD4;
	sub_82A77EB8(ctx, base);
	// mr. r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// blt 0x82a78010
	if (ctx.cr0.lt) goto loc_82A78010;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82a77ff4
	if (ctx.cr6.eq) goto loc_82A77FF4;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
	// stw r11,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r11.u32);
	// b 0x82a77ff8
	goto loc_82A77FF8;
loc_82A77FF4:
	// lwz r29,80(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82A77FF8:
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82a78014
	if (ctx.cr6.eq) goto loc_82A78014;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
	// b 0x82a78018
	goto loc_82A78018;
loc_82A78010:
	// lwz r29,80(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82A78014:
	// lwz r3,84(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82A78018:
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a7802c
	if (ctx.cr6.eq) goto loc_82A7802C;
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stw r31,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r31.u32);
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
loc_82A7802C:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82a78044
	if (ctx.cr6.eq) goto loc_82A78044;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A78044;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A78044:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82a78060
	if (ctx.cr6.eq) goto loc_82A78060;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A78060;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A78060:
	// lwz r3,88(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82a7807c
	if (ctx.cr6.eq) goto loc_82A7807C;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A7807C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A7807C:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// b 0x82a78098
	goto loc_82A78098;
loc_82A78084:
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// bl 0x82a77eb8
	ctx.lr = 0x82A78098;
	sub_82A77EB8(ctx, base);
loc_82A78098:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A780A0"))) PPC_WEAK_FUNC(sub_82A780A0);
PPC_FUNC_IMPL(__imp__sub_82A780A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A780A8;
	__savegprlr_28(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// stw r31,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r31.u32);
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// addi r28,r10,-28732
	ctx.r28.s64 = ctx.r10.s64 + -28732;
	// mr r5,r8
	ctx.r5.u64 = ctx.r8.u64;
	// lwz r8,228(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	// mr r6,r9
	ctx.r6.u64 = ctx.r9.u64;
	// lwz r9,236(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r30.u32);
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r29.u32);
	// bl 0x82a77f30
	ctx.lr = 0x82A780FC;
	sub_82A77F30(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A78108"))) PPC_WEAK_FUNC(sub_82A78108);
PPC_FUNC_IMPL(__imp__sub_82A78108) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A78110;
	__savegprlr_29(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// mr r6,r8
	ctx.r6.u64 = ctx.r8.u64;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r31.u32);
	// addi r29,r10,-28780
	ctx.r29.s64 = ctx.r10.s64 + -28780;
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// mr r7,r9
	ctx.r7.u64 = ctx.r9.u64;
	// lwz r9,228(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r29.u32);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// bl 0x82a77f30
	ctx.lr = 0x82A78164;
	sub_82A77F30(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A78170"))) PPC_WEAK_FUNC(sub_82A78170);
PPC_FUNC_IMPL(__imp__sub_82A78170) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// vspltisw v0,1
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_set1_epi32(int(0x1)));
	// vspltisw v10,-1
	_mm_store_si128((__m128i*)ctx.v10.u32, _mm_set1_epi32(int(0xFFFFFFFF)));
	// vmulfp128 v8,v1,v1
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v8.f32, _mm_mul_ps(_mm_load_ps(ctx.v1.f32), _mm_load_ps(ctx.v1.f32)));
	// addi r11,r11,-28176
	ctx.r11.s64 = ctx.r11.s64 + -28176;
	// vcfsx v11,v0,1
	_mm_store_ps(ctx.v11.f32, _mm_mul_ps(_mm_cvtepi32_ps(_mm_load_si128((__m128i*)ctx.v0.u32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x3F000000)))));
	// lvx128 v9,r0,r11
	_mm_store_si128((__m128i*)ctx.v9.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// addi r11,r11,5808
	ctx.r11.s64 = ctx.r11.s64 + 5808;
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// vspltw v7,v0,3
	_mm_store_si128((__m128i*)ctx.v7.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x0));
	// addi r11,r11,5792
	ctx.r11.s64 = ctx.r11.s64 + 5792;
	// vspltw v5,v0,2
	_mm_store_si128((__m128i*)ctx.v5.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x55));
	// vspltw v31,v0,1
	_mm_store_si128((__m128i*)ctx.v31.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xAA));
	// vspltw v29,v0,0
	_mm_store_si128((__m128i*)ctx.v29.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// vslw v0,v10,v10
	ctx.v0.u32[0] = ctx.v10.u32[0] << (ctx.v10.u8[0] & 0x1F);
	ctx.v0.u32[1] = ctx.v10.u32[1] << (ctx.v10.u8[4] & 0x1F);
	ctx.v0.u32[2] = ctx.v10.u32[2] << (ctx.v10.u8[8] & 0x1F);
	ctx.v0.u32[3] = ctx.v10.u32[3] << (ctx.v10.u8[12] & 0x1F);
	// lvx128 v13,r0,r11
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// vandc v0,v1,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)ctx.v1.u8)));
	// vspltw v6,v13,3
	_mm_store_si128((__m128i*)ctx.v6.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0x0));
	// addi r11,r11,5824
	ctx.r11.s64 = ctx.r11.s64 + 5824;
	// vspltw v4,v13,2
	_mm_store_si128((__m128i*)ctx.v4.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0x55));
	// vspltw v30,v13,1
	_mm_store_si128((__m128i*)ctx.v30.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xAA));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// vmulfp128 v10,v8,v0
	_mm_store_ps(ctx.v10.f32, _mm_mul_ps(_mm_load_ps(ctx.v8.f32), _mm_load_ps(ctx.v0.f32)));
	// vmaddfp v8,v4,v0,v5
	_mm_store_ps(ctx.v8.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v4.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v5.f32)));
	// lvx128 v12,r0,r11
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// vspltw v3,v12,3
	_mm_store_si128((__m128i*)ctx.v3.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v12.u32), 0x0));
	// vmaddfp v13,v13,v0,v29
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v29.f32)));
	// vspltw v2,v12,2
	_mm_store_si128((__m128i*)ctx.v2.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v12.u32), 0x55));
	// addi r11,r11,5856
	ctx.r11.s64 = ctx.r11.s64 + 5856;
	// vspltw v28,v12,1
	_mm_store_si128((__m128i*)ctx.v28.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v12.u32), 0xAA));
	// vspltw v27,v12,0
	_mm_store_si128((__m128i*)ctx.v27.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v12.u32), 0xFF));
	// vsubfp v12,v9,v0
	_mm_store_ps(ctx.v12.f32, _mm_sub_ps(_mm_load_ps(ctx.v9.f32), _mm_load_ps(ctx.v0.f32)));
	// vmaddfp v9,v6,v0,v7
	_mm_store_ps(ctx.v9.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v6.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v7.f32)));
	// vmaddfp v7,v30,v0,v31
	_mm_store_ps(ctx.v7.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v30.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v31.f32)));
	// vmaddfp v8,v8,v0,v2
	_mm_store_ps(ctx.v8.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v8.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v2.f32)));
	// vmaddfp v6,v13,v0,v27
	_mm_store_ps(ctx.v6.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v27.f32)));
	// vrsqrtefp v13,v12
	_mm_store_ps(ctx.v13.f32, _mm_div_ps(_mm_set1_ps(1), _mm_sqrt_ps(_mm_load_ps(ctx.v12.f32))));
	// vmaddfp v9,v9,v0,v3
	_mm_store_ps(ctx.v9.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v9.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v3.f32)));
	// vmulfp128 v12,v12,v11
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v11.f32)));
	// vmaddfp v7,v7,v0,v28
	_mm_store_ps(ctx.v7.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v7.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v28.f32)));
	// vmaddfp v9,v8,v10,v9
	_mm_store_ps(ctx.v9.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v8.f32), _mm_load_ps(ctx.v10.f32)), _mm_load_ps(ctx.v9.f32)));
	// vmulfp128 v8,v13,v13
	_mm_store_ps(ctx.v8.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v13.f32)));
	// vmulfp128 v9,v1,v9
	_mm_store_ps(ctx.v9.f32, _mm_mul_ps(_mm_load_ps(ctx.v1.f32), _mm_load_ps(ctx.v9.f32)));
	// vnmsubfp v12,v12,v8,v11
	_mm_store_ps(ctx.v12.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v8.f32)), _mm_load_ps(ctx.v11.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vor v8,v0,v0
	_mm_store_si128((__m128i*)ctx.v8.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// vmulfp128 v0,v0,v11
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v11.f32)));
	// vmaddfp v13,v13,v12,v13
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v12.f32)), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v12,v6,v10,v7
	_mm_store_ps(ctx.v12.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v6.f32), _mm_load_ps(ctx.v10.f32)), _mm_load_ps(ctx.v7.f32)));
	// vnmsubfp v10,v8,v1,v1
	_mm_store_ps(ctx.v10.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v8.f32), _mm_load_ps(ctx.v1.f32)), _mm_load_ps(ctx.v1.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vmulfp128 v12,v10,v12
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v12.f32)));
	// vmaddfp v13,v12,v13,v9
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v13.f32)), _mm_load_ps(ctx.v9.f32)));
	// vsubfp v1,v0,v13
	_mm_store_ps(ctx.v1.f32, _mm_sub_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A78260"))) PPC_WEAK_FUNC(sub_82A78260);
PPC_FUNC_IMPL(__imp__sub_82A78260) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82A78270:
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addi r9,r1,-12
	ctx.r9.s64 = ctx.r1.s64 + -12;
	// stfs f0,-12(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -12, temp.u32);
	// addi r8,r1,-12
	ctx.r8.s64 = ctx.r1.s64 + -12;
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// lvsl v7,r0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v7.u8, _mm_load_si128((__m128i*)&VectorShiftTableL[(temp.u32 & 0xF) * 16]));
	// lvx128 v0,r0,r8
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r8.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r8,r1,-16
	ctx.r8.s64 = ctx.r1.s64 + -16;
	// vperm v0,v0,v0,v7
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_perm_epi8_(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)ctx.v7.u8)));
	// vor v13,v0,v0
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// vpkd3d128 v13,v0,1,2,2
	ctx.fpscr.enableFlushModeUnconditional();
	__builtin_debugtrap();
	// vsplth v0,v13,0
	_mm_store_si128((__m128i*)ctx.v0.u16, _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u16), _mm_set1_epi16(short(0xF0E))));
	// stvehx v0,r0,r8
	ea = (ctx.r8.u32) & ~0x1;
	PPC_STORE_U16(ea, ctx.v0.u16[7 - ((ea & 0xF) >> 1)]);
	// lhz r9,-16(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + -16);
	// sth r9,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, ctx.r9.u16);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// bne 0x82a78270
	if (!ctx.cr0.eq) goto loc_82A78270;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A782C0"))) PPC_WEAK_FUNC(sub_82A782C0);
PPC_FUNC_IMPL(__imp__sub_82A782C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82A782D0:
	// lhz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// addi r9,r1,-16
	ctx.r9.s64 = ctx.r1.s64 + -16;
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// sth r8,-16(r1)
	PPC_STORE_U16(ctx.r1.u32 + -16, ctx.r8.u16);
	// addi r8,r1,-16
	ctx.r8.s64 = ctx.r1.s64 + -16;
	// lvsl v0,r0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)&VectorShiftTableL[(temp.u32 & 0xF) * 16]));
	// vsldoi v0,v0,v0,4
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_alignr_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)ctx.v0.u8), 12));
	// lvx128 v13,r0,r8
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r8.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r8,r1,-12
	ctx.r8.s64 = ctx.r1.s64 + -12;
	// vperm v0,v13,v13,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_perm_epi8_(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// vupkd3d128 v0,v0,12
	__builtin_debugtrap();
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// stvewx v0,r0,r8
	ea = (ctx.r8.u32) & ~0x3;
	PPC_STORE_U32(ea, ctx.v0.u32[3 - ((ea & 0xF) >> 2)]);
	// lfs f0,-12(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -12);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82a782d0
	if (!ctx.cr0.eq) goto loc_82A782D0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A78320"))) PPC_WEAK_FUNC(sub_82A78320);
PPC_FUNC_IMPL(__imp__sub_82A78320) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lis r9,-31988
	ctx.r9.s64 = -2096365568;
	// addi r10,r11,-28160
	ctx.r10.s64 = ctx.r11.s64 + -28160;
	// addi r8,r10,40
	ctx.r8.s64 = ctx.r10.s64 + 40;
	// addi r11,r10,40
	ctx.r11.s64 = ctx.r10.s64 + 40;
	// lwz r9,-26028(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + -26028);
	// cmplw cr6,r8,r9
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82a78358
	if (!ctx.cr6.lt) goto loc_82A78358;
loc_82A78340:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r3,r8
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r8.s32, ctx.xer);
	// beq cr6,0x82a78360
	if (ctx.cr6.eq) goto loc_82A78360;
	// addi r11,r11,36
	ctx.r11.s64 = ctx.r11.s64 + 36;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82a78340
	if (ctx.cr6.lt) goto loc_82A78340;
loc_82A78358:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// blr 
	return;
loc_82A78360:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A78368"))) PPC_WEAK_FUNC(sub_82A78368);
PPC_FUNC_IMPL(__imp__sub_82A78368) {
	PPC_FUNC_PROLOGUE();
	// addis r11,r3,-13873
	ctx.r11.s64 = ctx.r3.s64 + -909180928;
	// addic. r11,r11,-19521
	ctx.xer.ca = ctx.r11.u32 > 19520;
	ctx.r11.s64 = ctx.r11.s64 + -19521;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a78388
	if (ctx.cr0.eq) goto loc_82A78388;
	// cmplwi cr6,r11,1503
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1503, ctx.xer);
	// bnelr cr6
	if (!ctx.cr6.eq) return;
	// lis r3,10280
	ctx.r3.s64 = 673710080;
	// ori r3,r3,134
	ctx.r3.u64 = ctx.r3.u64 | 134;
	// blr 
	return;
loc_82A78388:
	// lis r3,2048
	ctx.r3.s64 = 134217728;
	// ori r3,r3,74
	ctx.r3.u64 = ctx.r3.u64 | 74;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A78398"))) PPC_WEAK_FUNC(sub_82A78398);
PPC_FUNC_IMPL(__imp__sub_82A78398) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r3,1
	ctx.r3.s64 = 1;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// bl 0x82d09218
	ctx.lr = 0x82A783B4;
	sub_82D09218(ctx, base);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82a783c4
	if (!ctx.cr6.eq) goto loc_82A783C4;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82a783e0
	goto loc_82A783E0;
loc_82A783C4:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// rlwinm r10,r11,0,26,22
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFE3F;
	// cmpwi cr6,r10,-449
	ctx.cr6.compare<int32_t>(ctx.r10.s32, -449, ctx.xer);
	// bne cr6,0x82a783dc
	if (!ctx.cr6.eq) goto loc_82A783DC;
	// lis r11,6184
	ctx.r11.s64 = 405274624;
	// ori r11,r11,390
	ctx.r11.u64 = ctx.r11.u64 | 390;
loc_82A783DC:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
loc_82A783E0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A783F8"))) PPC_WEAK_FUNC(sub_82A783F8);
PPC_FUNC_IMPL(__imp__sub_82A783F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82A78400;
	__savegprlr_14(ctx, base);
	// stwu r1,-736(r1)
	ea = -736 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// stw r9,804(r1)
	PPC_STORE_U32(ctx.r1.u32 + 804, ctx.r9.u32);
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r16,r6
	ctx.r16.u64 = ctx.r6.u64;
	// stw r25,772(r1)
	PPC_STORE_U32(ctx.r1.u32 + 772, ctx.r25.u32);
	// mr r18,r7
	ctx.r18.u64 = ctx.r7.u64;
	// mr r19,r8
	ctx.r19.u64 = ctx.r8.u64;
	// mr r21,r10
	ctx.r21.u64 = ctx.r10.u64;
	// bl 0x82aa72a8
	ctx.lr = 0x82A78430;
	sub_82AA72A8(ctx, base);
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82aaaaf0
	ctx.lr = 0x82A78438;
	sub_82AAAAF0(ctx, base);
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// mr r20,r28
	ctx.r20.u64 = ctx.r28.u64;
	// mr r26,r28
	ctx.r26.u64 = ctx.r28.u64;
	// mr r23,r28
	ctx.r23.u64 = ctx.r28.u64;
	// stw r28,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r28.u32);
	// mr r27,r28
	ctx.r27.u64 = ctx.r28.u64;
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r28.u32);
	// mr r31,r28
	ctx.r31.u64 = ctx.r28.u64;
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r28.u32);
	// mr r29,r28
	ctx.r29.u64 = ctx.r28.u64;
	// stw r28,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r28.u32);
	// mr r15,r28
	ctx.r15.u64 = ctx.r28.u64;
	// stw r28,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r28.u32);
	// mr r14,r28
	ctx.r14.u64 = ctx.r28.u64;
	// stw r28,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r28.u32);
	// bne cr6,0x82a7849c
	if (!ctx.cr6.eq) goto loc_82A7849C;
loc_82A7847C:
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82aaad60
	ctx.lr = 0x82A78484;
	sub_82AAAD60(ctx, base);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82aa7c78
	ctx.lr = 0x82A7848C;
	sub_82AA7C78(ctx, base);
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
loc_82A78494:
	// addi r1,r1,736
	ctx.r1.s64 = ctx.r1.s64 + 736;
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
loc_82A7849C:
	// cmplwi cr6,r16,0
	ctx.cr6.compare<uint32_t>(ctx.r16.u32, 0, ctx.xer);
	// beq cr6,0x82a7847c
	if (ctx.cr6.eq) goto loc_82A7847C;
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// bne cr6,0x82a784cc
	if (!ctx.cr6.eq) goto loc_82A784CC;
loc_82A784AC:
	// lis r31,-30602
	ctx.r31.s64 = -2005532672;
	// ori r31,r31,2156
	ctx.r31.u64 = ctx.r31.u64 | 2156;
loc_82A784B4:
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82aaad60
	ctx.lr = 0x82A784BC;
	sub_82AAAD60(ctx, base);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82aa7c78
	ctx.lr = 0x82A784C4;
	sub_82AA7C78(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// b 0x82a78494
	goto loc_82A78494;
loc_82A784CC:
	// lwz r11,844(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// bne cr6,0x82a784e4
	if (!ctx.cr6.eq) goto loc_82A784E4;
	// lis r11,8
	ctx.r11.s64 = 524288;
	// ori r11,r11,4
	ctx.r11.u64 = ctx.r11.u64 | 4;
	// stw r11,844(r1)
	PPC_STORE_U32(ctx.r1.u32 + 844, ctx.r11.u32);
loc_82A784E4:
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// addi r4,r1,352
	ctx.r4.s64 = ctx.r1.s64 + 352;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82aaad68
	ctx.lr = 0x82A78504;
	sub_82AAAD68(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a78514
	if (!ctx.cr0.lt) goto loc_82A78514;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// b 0x82a784b4
	goto loc_82A784B4;
loc_82A78514:
	// addi r5,r1,288
	ctx.r5.s64 = ctx.r1.s64 + 288;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82a37b48
	ctx.lr = 0x82A78524;
	sub_82A37B48(ctx, base);
	// lwz r11,340(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// rlwinm r22,r18,24,31,31
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r18.u32 | (ctx.r18.u64 << 32), 24) & 0x1;
	// clrlwi r30,r11,31
	ctx.r30.u64 = ctx.r11.u32 & 0x1;
	// rlwinm r11,r11,31,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x1;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r30.u32);
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// lwz r11,820(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a78568
	if (ctx.cr6.eq) goto loc_82A78568;
	// lwz r11,8(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 8);
	// cmpwi cr6,r11,16
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 16, ctx.xer);
	// ble cr6,0x82a78560
	if (!ctx.cr6.gt) goto loc_82A78560;
	// lwz r11,12(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 12);
	// cmpwi cr6,r11,16
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 16, ctx.xer);
	// bgt cr6,0x82a78568
	if (ctx.cr6.gt) goto loc_82A78568;
loc_82A78560:
	// li r17,1
	ctx.r17.s64 = 1;
	// b 0x82a7856c
	goto loc_82A7856C;
loc_82A78568:
	// mr r17,r28
	ctx.r17.u64 = ctx.r28.u64;
loc_82A7856C:
	// cmpwi cr6,r22,0
	ctx.cr6.compare<int32_t>(ctx.r22.s32, 0, ctx.xer);
	// beq cr6,0x82a786c4
	if (ctx.cr6.eq) goto loc_82A786C4;
	// clrlwi r25,r18,26
	ctx.r25.u64 = ctx.r18.u32 & 0x3F;
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// addi r4,r1,100
	ctx.r4.s64 = ctx.r1.s64 + 100;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82a38070
	ctx.lr = 0x82A78588;
	sub_82A38070(ctx, base);
	// cmpwi cr6,r17,0
	ctx.cr6.compare<int32_t>(ctx.r17.s32, 0, ctx.xer);
	// bne cr6,0x82a785a0
	if (!ctx.cr6.eq) goto loc_82A785A0;
	// lwz r27,8(r21)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r21.u32 + 8);
	// mr r29,r28
	ctx.r29.u64 = ctx.r28.u64;
	// lwz r31,12(r21)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r21.u32 + 12);
	// b 0x82a786a0
	goto loc_82A786A0;
loc_82A785A0:
	// lwz r26,828(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 828);
	// addi r11,r26,-1
	ctx.r11.s64 = ctx.r26.s64 + -1;
	// cmplwi cr6,r11,8191
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 8191, ctx.xer);
	// bgt cr6,0x82a784ac
	if (ctx.cr6.gt) goto loc_82A784AC;
	// lwz r29,836(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	// addi r11,r29,-1
	ctx.r11.s64 = ctx.r29.s64 + -1;
	// cmplwi cr6,r11,8191
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 8191, ctx.xer);
	// bgt cr6,0x82a784ac
	if (ctx.cr6.gt) goto loc_82A784AC;
	// lwz r11,8(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 8);
	// lwz r10,12(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 12);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// ble cr6,0x82a785d4
	if (!ctx.cr6.gt) goto loc_82A785D4;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A785D4:
	// cmplw cr6,r26,r29
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r29.u32, ctx.xer);
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// bgt cr6,0x82a785e4
	if (ctx.cr6.gt) goto loc_82A785E4;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
loc_82A785E4:
	// mr r27,r28
	ctx.r27.u64 = ctx.r28.u64;
	// b 0x82a785f4
	goto loc_82A785F4;
loc_82A785EC:
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
loc_82A785F4:
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bgt cr6,0x82a785ec
	if (ctx.cr6.gt) goto loc_82A785EC;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82a37e40
	ctx.lr = 0x82A7860C;
	sub_82A37E40(ctx, base);
	// addi r11,r26,-1
	ctx.r11.s64 = ctx.r26.s64 + -1;
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// subfic r11,r3,32
	ctx.xer.ca = ctx.r3.u32 <= 32;
	ctx.r11.s64 = 32 - ctx.r3.s64;
	// subf. r10,r10,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r10.s64;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge 0x82a78624
	if (!ctx.cr0.lt) goto loc_82A78624;
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
loc_82A78624:
	// addi r9,r29,-1
	ctx.r9.s64 = ctx.r29.s64 + -1;
	// cntlzw r9,r9
	ctx.r9.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
	// subf. r31,r9,r11
	ctx.r31.s64 = ctx.r11.s64 - ctx.r9.s64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// slw r30,r11,r10
	ctx.r30.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r11.u32 << (ctx.r10.u8 & 0x3F));
	// bge 0x82a78640
	if (!ctx.cr0.lt) goto loc_82A78640;
	// mr r31,r28
	ctx.r31.u64 = ctx.r28.u64;
loc_82A78640:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r11,100(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// li r29,1
	ctx.r29.s64 = 1;
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r11,r11,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// add r30,r11,r30
	ctx.r30.u64 = ctx.r11.u64 + ctx.r30.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r22
	ctx.r8.u64 = ctx.r22.u64;
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// andc r27,r30,r11
	ctx.r27.u64 = ctx.r30.u64 & ~ctx.r11.u64;
	// slw r31,r29,r31
	ctx.r31.u64 = ctx.r31.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r31.u8 & 0x3F));
	// add r31,r31,r10
	ctx.r31.u64 = ctx.r31.u64 + ctx.r10.u64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r31,r31,-1
	ctx.r31.s64 = ctx.r31.s64 + -1;
	// andc r31,r31,r10
	ctx.r31.u64 = ctx.r31.u64 & ~ctx.r10.u64;
	// bl 0x82a38048
	ctx.lr = 0x82A78698;
	sub_82A38048(ctx, base);
	// lwz r30,80(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
loc_82A786A0:
	// addi r11,r31,31
	ctx.r11.s64 = ctx.r31.s64 + 31;
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r25,772(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	// rlwinm r11,r11,0,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFE0;
	// twllei r10,0
	// divwu r11,r11,r10
	ctx.r11.u32 = ctx.r11.u32 / ctx.r10.u32;
	// mullw r11,r11,r19
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r19.s32);
	// addi r11,r11,4095
	ctx.r11.s64 = ctx.r11.s64 + 4095;
	// rlwinm r26,r11,0,0,19
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFF000;
loc_82A786C4:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq cr6,0x82a78794
	if (ctx.cr6.eq) goto loc_82A78794;
	// lwz r11,108(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a786e8
	if (!ctx.cr6.eq) goto loc_82A786E8;
	// lwz r15,292(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// lwz r14,296(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	// stw r28,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r28.u32);
	// b 0x82a78738
	goto loc_82A78738;
loc_82A786E8:
	// addi r5,r1,448
	ctx.r5.s64 = ctx.r1.s64 + 448;
	// lwz r3,24(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82a37b48
	ctx.lr = 0x82A786F8;
	sub_82A37B48(ctx, base);
	// addi r4,r1,512
	ctx.r4.s64 = ctx.r1.s64 + 512;
	// lwz r3,24(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 24);
	// bl 0x82a37b50
	ctx.lr = 0x82A78704;
	sub_82A37B50(ctx, base);
	// lwz r11,28(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 28);
	// lwz r10,304(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// lwz r5,460(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	// clrlwi r7,r10,26
	ctx.r7.u64 = ctx.r10.u32 & 0x3F;
	// lwz r4,456(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	// rlwinm r6,r11,4,28,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xF;
	// lwz r3,452(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	// lwz r15,516(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// lwz r14,520(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	// bl 0x82a38048
	ctx.lr = 0x82A78734;
	sub_82A38048(ctx, base);
	// stw r3,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r3.u32);
loc_82A78738:
	// lwz r11,304(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// clrlwi r3,r11,26
	ctx.r3.u64 = ctx.r11.u32 & 0x3F;
	// bl 0x82a38070
	ctx.lr = 0x82A7874C;
	sub_82A38070(ctx, base);
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// add r11,r15,r10
	ctx.r11.u64 = ctx.r15.u64 + ctx.r10.u64;
	// lwz r7,316(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r8,r11,-1
	ctx.r8.s64 = ctx.r11.s64 + -1;
	// add r11,r14,r9
	ctx.r11.u64 = ctx.r14.u64 + ctx.r9.u64;
	// andc r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 & ~ctx.r10.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r8,r9,-1
	ctx.r8.s64 = ctx.r9.s64 + -1;
	// mullw r10,r10,r7
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r7.s32);
	// andc r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 & ~ctx.r8.u64;
	// rlwinm r11,r10,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// mullw r10,r8,r11
	ctx.r10.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r11.s32);
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// stw r11,360(r1)
	PPC_STORE_U32(ctx.r1.u32 + 360, ctx.r11.u32);
	// addi r10,r10,4095
	ctx.r10.s64 = ctx.r10.s64 + 4095;
	// rlwinm r23,r10,0,0,19
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFF000;
loc_82A78794:
	// add. r3,r23,r26
	ctx.r3.u64 = ctx.r23.u64 + ctx.r26.u64;
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a787b8
	if (ctx.cr0.eq) goto loc_82A787B8;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// bl 0x8247f370
	ctx.lr = 0x82A787A4;
	sub_8247F370(ctx, base);
	// mr. r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r20.s32, 0, ctx.xer);
	// bne 0x82a787b8
	if (!ctx.cr0.eq) goto loc_82A787B8;
	// lis r31,-32761
	ctx.r31.s64 = -2147024896;
	// ori r31,r31,14
	ctx.r31.u64 = ctx.r31.u64 | 14;
	// b 0x82a784b4
	goto loc_82A784B4;
loc_82A787B8:
	// cmpwi cr6,r22,0
	ctx.cr6.compare<int32_t>(ctx.r22.s32, 0, ctx.xer);
	// beq cr6,0x82a78884
	if (ctx.cr6.eq) goto loc_82A78884;
	// lwz r11,100(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmpwi cr6,r17,0
	ctx.cr6.compare<int32_t>(ctx.r17.s32, 0, ctx.xer);
	// lwz r8,92(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// beq cr6,0x82a787dc
	if (ctx.cr6.eq) goto loc_82A787DC;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// b 0x82a787f4
	goto loc_82A787F4;
loc_82A787DC:
	// lwz r10,0(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// twllei r11,0
	// lwz r9,4(r21)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r21.u32 + 4);
	// twllei r8,0
	// divwu r4,r10,r11
	ctx.r4.u32 = ctx.r10.u32 / ctx.r11.u32;
	// divwu r5,r9,r8
	ctx.r5.u32 = ctx.r9.u32 / ctx.r8.u32;
loc_82A787F4:
	// add r9,r31,r8
	ctx.r9.u64 = ctx.r31.u64 + ctx.r8.u64;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// add r10,r27,r11
	ctx.r10.u64 = ctx.r27.u64 + ctx.r11.u64;
	// stw r4,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r4.u32);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// divwu r7,r9,r8
	ctx.r7.u32 = ctx.r9.u32 / ctx.r8.u32;
	// divwu r6,r10,r11
	ctx.r6.u32 = ctx.r10.u32 / ctx.r11.u32;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// twllei r8,0
	// twllei r11,0
	// bl 0x82a3bdb0
	ctx.lr = 0x82A78824;
	sub_82A3BDB0(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// clrlwi r7,r18,26
	ctx.r7.u64 = ctx.r18.u32 & 0x3F;
	// addi r10,r11,-29320
	ctx.r10.s64 = ctx.r11.s64 + -29320;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// add r8,r31,r11
	ctx.r8.u64 = ctx.r31.u64 + ctx.r11.u64;
	// twllei r11,0
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// lbzx r10,r7,r10
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r7.u32 + ctx.r10.u32);
	// subf r6,r29,r16
	ctx.r6.s64 = ctx.r16.s64 - ctx.r29.s64;
	// divwu r8,r8,r11
	ctx.r8.u32 = ctx.r8.u32 / ctx.r11.u32;
	// mullw r11,r10,r11
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r10,r11,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// divwu r7,r19,r10
	ctx.r7.u32 = ctx.r19.u32 / ctx.r10.u32;
	// twllei r10,0
	// bl 0x82a38ad0
	ctx.lr = 0x82A78878;
	sub_82A38AD0(ctx, base);
	// add r11,r29,r20
	ctx.r11.u64 = ctx.r29.u64 + ctx.r20.u64;
	// stw r11,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r11.u32);
	// b 0x82a78888
	goto loc_82A78888;
loc_82A78884:
	// stw r16,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r16.u32);
loc_82A78888:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq cr6,0x82a78904
	if (ctx.cr6.eq) goto loc_82A78904;
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r9,352(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	// add r11,r10,r26
	ctx.r11.u64 = ctx.r10.u64 + ctx.r26.u64;
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// add r11,r11,r20
	ctx.r11.u64 = ctx.r11.u64 + ctx.r20.u64;
	// stw r10,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r10.u32);
	// stw r11,352(r1)
	PPC_STORE_U32(ctx.r1.u32 + 352, ctx.r11.u32);
	// lwz r11,108(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a78904
	if (ctx.cr6.eq) goto loc_82A78904;
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r10,332(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// divwu r7,r15,r11
	ctx.r7.u32 = ctx.r15.u32 / ctx.r11.u32;
	// lwz r6,112(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// twllei r11,0
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// add r3,r26,r20
	ctx.r3.u64 = ctx.r26.u64 + ctx.r20.u64;
	// lwz r4,360(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	// divwu r8,r14,r11
	ctx.r8.u32 = ctx.r14.u32 / ctx.r11.u32;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// twllei r11,0
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// stw r28,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r28.u32);
	// stw r28,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r28.u32);
	// stw r7,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r7.u32);
	// stw r8,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r8.u32);
	// bl 0x82a38ad0
	ctx.lr = 0x82A78904;
	sub_82A38AD0(ctx, base);
loc_82A78904:
	// rlwinm r10,r18,0,24,22
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r18.u32 | (ctx.r18.u64 << 32), 0) & 0xFFFFFFFFFFFFFEFF;
	// lwz r9,4(r21)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r21.u32 + 4);
	// addi r11,r1,208
	ctx.r11.s64 = ctx.r1.s64 + 208;
	// lwz r8,8(r21)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r21.u32 + 8);
	// lwz r7,12(r21)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r21.u32 + 12);
	// addi r3,r1,232
	ctx.r3.s64 = ctx.r1.s64 + 232;
	// stw r19,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, ctx.r19.u32);
	// addi r4,r1,208
	ctx.r4.s64 = ctx.r1.s64 + 208;
	// stw r28,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r28.u32);
	// li r5,24
	ctx.r5.s64 = 24;
	// stw r10,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r10.u32);
	// lwz r10,0(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// stw r8,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r8.u32);
	// stw r7,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r7.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r28,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, ctx.r28.u32);
	// stw r11,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, ctx.r11.u32);
	// bl 0x82d5c630
	ctx.lr = 0x82A78954;
	sub_82D5C630(ctx, base);
	// lwz r11,424(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	// addi r5,r1,192
	ctx.r5.s64 = ctx.r1.s64 + 192;
	// addi r4,r1,352
	ctx.r4.s64 = ctx.r1.s64 + 352;
	// lwz r6,844(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// stw r11,264(r1)
	PPC_STORE_U32(ctx.r1.u32 + 264, ctx.r11.u32);
	// lwz r11,852(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	// stw r11,268(r1)
	PPC_STORE_U32(ctx.r1.u32 + 268, ctx.r11.u32);
	// lwz r11,804(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	// stw r11,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, ctx.r11.u32);
	// lwz r11,356(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// rlwinm r11,r11,0,24,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFEFF;
	// stw r11,356(r1)
	PPC_STORE_U32(ctx.r1.u32 + 356, ctx.r11.u32);
	// bl 0x82aaa948
	ctx.lr = 0x82A7898C;
	sub_82AAA948(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq cr6,0x82a78a6c
	if (ctx.cr6.eq) goto loc_82A78A6C;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x82a789e8
	if (ctx.cr6.eq) goto loc_82A789E8;
	// lwz r11,108(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a789e8
	if (!ctx.cr6.eq) goto loc_82A789E8;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,12(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	// lwz r7,0(r25)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// twllei r11,0
	// add r8,r10,r11
	ctx.r8.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r6,4(r25)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	// divwu r4,r7,r10
	ctx.r4.u32 = ctx.r7.u32 / ctx.r10.u32;
	// lwz r9,8(r25)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r25.u32 + 8);
	// divwu r5,r6,r11
	ctx.r5.u32 = ctx.r6.u32 / ctx.r11.u32;
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// twllei r10,0
	// stw r4,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r4.u32);
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// b 0x82a78a08
	goto loc_82A78A08;
loc_82A789E8:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// li r4,0
	ctx.r4.s64 = 0;
	// add r8,r14,r11
	ctx.r8.u64 = ctx.r14.u64 + ctx.r11.u64;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// add r9,r15,r10
	ctx.r9.u64 = ctx.r15.u64 + ctx.r10.u64;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
loc_82A78A08:
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// divwu r7,r8,r11
	ctx.r7.u32 = ctx.r8.u32 / ctx.r11.u32;
	// divwu r6,r9,r10
	ctx.r6.u32 = ctx.r9.u32 / ctx.r10.u32;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// twllei r11,0
	// twllei r10,0
	// bl 0x82a3bdb0
	ctx.lr = 0x82A78A28;
	sub_82A3BDB0(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// add r7,r26,r20
	ctx.r7.u64 = ctx.r26.u64 + ctx.r20.u64;
	// lwz r4,88(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// add r9,r14,r11
	ctx.r9.u64 = ctx.r14.u64 + ctx.r11.u64;
	// lwz r8,360(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	// add r10,r15,r4
	ctx.r10.u64 = ctx.r15.u64 + ctx.r4.u64;
	// addi r5,r9,-1
	ctx.r5.s64 = ctx.r9.s64 + -1;
	// addi r3,r10,-1
	ctx.r3.s64 = ctx.r10.s64 + -1;
	// lwz r10,332(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// twllei r4,0
	// divwu r4,r3,r4
	ctx.r4.u32 = ctx.r3.u32 / ctx.r4.u32;
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// divwu r5,r5,r11
	ctx.r5.u32 = ctx.r5.u32 / ctx.r11.u32;
	// twllei r11,0
	// bl 0x82a38ac8
	ctx.lr = 0x82A78A6C;
	sub_82A38AC8(ctx, base);
loc_82A78A6C:
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// beq cr6,0x82a784b4
	if (ctx.cr6.eq) goto loc_82A784B4;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A78A80;
	sub_8247F398(ctx, base);
	// b 0x82a784b4
	goto loc_82A784B4;
}

__attribute__((alias("__imp__sub_82A78A88"))) PPC_WEAK_FUNC(sub_82A78A88);
PPC_FUNC_IMPL(__imp__sub_82A78A88) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82A78A90;
	__savegprlr_14(ctx, base);
	// stwu r1,-752(r1)
	ea = -752 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// stw r10,828(r1)
	PPC_STORE_U32(ctx.r1.u32 + 828, ctx.r10.u32);
	// mr r22,r7
	ctx.r22.u64 = ctx.r7.u64;
	// mr r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r14,r5
	ctx.r14.u64 = ctx.r5.u64;
	// stw r27,796(r1)
	PPC_STORE_U32(ctx.r1.u32 + 796, ctx.r27.u32);
	// stw r22,804(r1)
	PPC_STORE_U32(ctx.r1.u32 + 804, ctx.r22.u32);
	// mr r21,r8
	ctx.r21.u64 = ctx.r8.u64;
	// mr r18,r9
	ctx.r18.u64 = ctx.r9.u64;
	// bl 0x82aa72a8
	ctx.lr = 0x82A78AC4;
	sub_82AA72A8(ctx, base);
	// addi r3,r1,132
	ctx.r3.s64 = ctx.r1.s64 + 132;
	// bl 0x82aaab10
	ctx.lr = 0x82A78ACC;
	sub_82AAAB10(ctx, base);
	// li r26,0
	ctx.r26.s64 = 0;
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// mr r17,r26
	ctx.r17.u64 = ctx.r26.u64;
	// mr r24,r26
	ctx.r24.u64 = ctx.r26.u64;
	// mr r19,r26
	ctx.r19.u64 = ctx.r26.u64;
	// stw r26,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r26.u32);
	// mr r28,r26
	ctx.r28.u64 = ctx.r26.u64;
	// stw r26,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r26.u32);
	// mr r31,r26
	ctx.r31.u64 = ctx.r26.u64;
	// stw r26,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r26.u32);
	// mr r30,r26
	ctx.r30.u64 = ctx.r26.u64;
	// stw r26,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r26.u32);
	// mr r25,r26
	ctx.r25.u64 = ctx.r26.u64;
	// stw r26,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r26.u32);
	// mr r15,r26
	ctx.r15.u64 = ctx.r26.u64;
	// stw r26,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r26.u32);
	// stw r26,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r26.u32);
	// stw r26,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r26.u32);
	// bne cr6,0x82a78b38
	if (!ctx.cr6.eq) goto loc_82A78B38;
loc_82A78B18:
	// addi r3,r1,132
	ctx.r3.s64 = ctx.r1.s64 + 132;
	// bl 0x82aab258
	ctx.lr = 0x82A78B20;
	sub_82AAB258(ctx, base);
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x82aa7c78
	ctx.lr = 0x82A78B28;
	sub_82AA7C78(ctx, base);
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
loc_82A78B30:
	// addi r1,r1,752
	ctx.r1.s64 = ctx.r1.s64 + 752;
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
loc_82A78B38:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a78b18
	if (ctx.cr6.eq) goto loc_82A78B18;
	// lwz r27,836(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// bne cr6,0x82a78b6c
	if (!ctx.cr6.eq) goto loc_82A78B6C;
loc_82A78B4C:
	// lis r31,-30602
	ctx.r31.s64 = -2005532672;
	// ori r31,r31,2156
	ctx.r31.u64 = ctx.r31.u64 | 2156;
loc_82A78B54:
	// addi r3,r1,132
	ctx.r3.s64 = ctx.r1.s64 + 132;
	// bl 0x82aab258
	ctx.lr = 0x82A78B5C;
	sub_82AAB258(ctx, base);
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x82aa7c78
	ctx.lr = 0x82A78B64;
	sub_82AA7C78(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// b 0x82a78b30
	goto loc_82A78B30;
loc_82A78B6C:
	// lwz r11,876(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// bne cr6,0x82a78b84
	if (!ctx.cr6.eq) goto loc_82A78B84;
	// lis r11,8
	ctx.r11.s64 = 524288;
	// ori r11,r11,4
	ctx.r11.u64 = ctx.r11.u64 | 4;
	// stw r11,876(r1)
	PPC_STORE_U32(ctx.r1.u32 + 876, ctx.r11.u32);
loc_82A78B84:
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r14
	ctx.r7.u64 = ctx.r14.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// addi r4,r1,272
	ctx.r4.s64 = ctx.r1.s64 + 272;
	// addi r3,r1,132
	ctx.r3.s64 = ctx.r1.s64 + 132;
	// bl 0x82aab260
	ctx.lr = 0x82A78BA4;
	sub_82AAB260(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a78bb4
	if (!ctx.cr0.lt) goto loc_82A78BB4;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// b 0x82a78b54
	goto loc_82A78B54;
loc_82A78BB4:
	// addi r5,r1,208
	ctx.r5.s64 = ctx.r1.s64 + 208;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x82a37b48
	ctx.lr = 0x82A78BC4;
	sub_82A37B48(ctx, base);
	// lwz r11,260(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// rlwinm r16,r22,24,31,31
	ctx.r16.u64 = __builtin_rotateleft64(ctx.r22.u32 | (ctx.r22.u64 << 32), 24) & 0x1;
	// clrlwi r29,r11,31
	ctx.r29.u64 = ctx.r11.u32 & 0x1;
	// rlwinm r11,r11,31,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x1;
	// li r23,1
	ctx.r23.s64 = 1;
	// stw r29,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, ctx.r29.u32);
	// stw r11,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r11.u32);
	// lwz r11,844(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a78c0c
	if (ctx.cr6.eq) goto loc_82A78C0C;
	// lwz r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// cmplwi cr6,r11,16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 16, ctx.xer);
	// ble cr6,0x82a78c04
	if (!ctx.cr6.gt) goto loc_82A78C04;
	// lwz r11,12(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// cmplwi cr6,r11,16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 16, ctx.xer);
	// bgt cr6,0x82a78c0c
	if (ctx.cr6.gt) goto loc_82A78C0C;
loc_82A78C04:
	// stw r23,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r23.u32);
	// b 0x82a78c10
	goto loc_82A78C10;
loc_82A78C0C:
	// stw r26,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r26.u32);
loc_82A78C10:
	// cmpwi cr6,r16,0
	ctx.cr6.compare<int32_t>(ctx.r16.s32, 0, ctx.xer);
	// beq cr6,0x82a78db4
	if (ctx.cr6.eq) goto loc_82A78DB4;
	// clrlwi r22,r22,26
	ctx.r22.u64 = ctx.r22.u32 & 0x3F;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// addi r4,r1,180
	ctx.r4.s64 = ctx.r1.s64 + 180;
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82a38070
	ctx.lr = 0x82A78C2C;
	sub_82A38070(ctx, base);
	// lwz r11,176(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a78c58
	if (!ctx.cr6.eq) goto loc_82A78C58;
	// lwz r11,20(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// mr r25,r26
	ctx.r25.u64 = ctx.r26.u64;
	// lwz r28,8(r27)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// lwz r31,12(r27)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// rlwinm r30,r11,0,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// mullw r11,r30,r18
	ctx.r11.s64 = int64_t(ctx.r30.s32) * int64_t(ctx.r18.s32);
	// b 0x82a78da8
	goto loc_82A78DA8;
loc_82A78C58:
	// lwz r25,852(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	// addi r11,r25,-1
	ctx.r11.s64 = ctx.r25.s64 + -1;
	// cmplwi cr6,r11,8191
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 8191, ctx.xer);
	// bgt cr6,0x82a78b4c
	if (ctx.cr6.gt) goto loc_82A78B4C;
	// lwz r27,860(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	// addi r11,r27,-1
	ctx.r11.s64 = ctx.r27.s64 + -1;
	// cmplwi cr6,r11,8191
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 8191, ctx.xer);
	// bgt cr6,0x82a78b4c
	if (ctx.cr6.gt) goto loc_82A78B4C;
	// lwz r24,868(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 868);
	// addi r11,r24,-1
	ctx.r11.s64 = ctx.r24.s64 + -1;
	// cmplwi cr6,r11,1023
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1023, ctx.xer);
	// bgt cr6,0x82a78b4c
	if (ctx.cr6.gt) goto loc_82A78B4C;
	// lwz r10,836(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	// lwz r11,8(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a78ca0
	if (!ctx.cr6.gt) goto loc_82A78CA0;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A78CA0:
	// cmplw cr6,r25,r27
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, ctx.r27.u32, ctx.xer);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// bgt cr6,0x82a78cb0
	if (ctx.cr6.gt) goto loc_82A78CB0;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
loc_82A78CB0:
	// mr r30,r26
	ctx.r30.u64 = ctx.r26.u64;
	// b 0x82a78cc0
	goto loc_82A78CC0;
loc_82A78CB8:
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
loc_82A78CC0:
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bgt cr6,0x82a78cb8
	if (ctx.cr6.gt) goto loc_82A78CB8;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82a37e40
	ctx.lr = 0x82A78CD8;
	sub_82A37E40(ctx, base);
	// addi r11,r25,-1
	ctx.r11.s64 = ctx.r25.s64 + -1;
	// subfic r10,r3,32
	ctx.xer.ca = ctx.r3.u32 <= 32;
	ctx.r10.s64 = 32 - ctx.r3.s64;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// mr r9,r26
	ctx.r9.u64 = ctx.r26.u64;
	// subf. r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt 0x82a78cf4
	if (ctx.cr0.lt) goto loc_82A78CF4;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
loc_82A78CF4:
	// addi r11,r27,-1
	ctx.r11.s64 = ctx.r27.s64 + -1;
	// slw r29,r23,r9
	ctx.r29.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r23.u32 << (ctx.r9.u8 & 0x3F));
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// subf. r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge 0x82a78d0c
	if (!ctx.cr0.lt) goto loc_82A78D0C;
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
loc_82A78D0C:
	// addi r9,r24,-1
	ctx.r9.s64 = ctx.r24.s64 + -1;
	// slw r28,r23,r11
	ctx.r28.u64 = ctx.r11.u8 & 0x20 ? 0 : (ctx.r23.u32 << (ctx.r11.u8 & 0x3F));
	// cntlzw r9,r9
	ctx.r9.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
	// subf. r31,r9,r10
	ctx.r31.s64 = ctx.r10.s64 - ctx.r9.s64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// bge 0x82a78d24
	if (!ctx.cr0.lt) goto loc_82A78D24;
	// mr r31,r26
	ctx.r31.u64 = ctx.r26.u64;
loc_82A78D24:
	// slw r31,r23,r31
	ctx.r31.u64 = ctx.r31.u8 & 0x20 ? 0 : (ctx.r23.u32 << (ctx.r31.u8 & 0x3F));
	// lwz r11,180(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// rlwinm r11,r11,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r30,r31,0,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFFC;
	// add r31,r10,r28
	ctx.r31.u64 = ctx.r10.u64 + ctx.r28.u64;
	// add r29,r11,r29
	ctx.r29.u64 = ctx.r11.u64 + ctx.r29.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r29,r29,-1
	ctx.r29.s64 = ctx.r29.s64 + -1;
	// addi r31,r31,-1
	ctx.r31.s64 = ctx.r31.s64 + -1;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r16
	ctx.r8.u64 = ctx.r16.u64;
	// mr r7,r22
	ctx.r7.u64 = ctx.r22.u64;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// andc r28,r29,r11
	ctx.r28.u64 = ctx.r29.u64 & ~ctx.r11.u64;
	// andc r31,r31,r10
	ctx.r31.u64 = ctx.r31.u64 & ~ctx.r10.u64;
	// bl 0x82a38048
	ctx.lr = 0x82A78D80;
	sub_82A38048(ctx, base);
	// addi r11,r31,31
	ctx.r11.s64 = ctx.r31.s64 + 31;
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r27,836(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// rlwinm r11,r11,0,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFE0;
	// lwz r29,188(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// twllei r10,0
	// divwu r11,r11,r10
	ctx.r11.u32 = ctx.r11.u32 / ctx.r10.u32;
	// mullw r11,r11,r30
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r30.s32);
	// mullw r11,r11,r21
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r21.s32);
loc_82A78DA8:
	// addi r11,r11,4095
	ctx.r11.s64 = ctx.r11.s64 + 4095;
	// lwz r22,804(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	// rlwinm r24,r11,0,0,19
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFF000;
loc_82A78DB4:
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq cr6,0x82a78eac
	if (ctx.cr6.eq) goto loc_82A78EAC;
	// lwz r11,168(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a78de4
	if (!ctx.cr6.eq) goto loc_82A78DE4;
	// lwz r11,212(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// lwz r15,220(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// stw r26,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r26.u32);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
	// lwz r11,216(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// b 0x82a78e40
	goto loc_82A78E40;
loc_82A78DE4:
	// addi r5,r1,464
	ctx.r5.s64 = ctx.r1.s64 + 464;
	// lwz r3,24(r20)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r20.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82a37b48
	ctx.lr = 0x82A78DF4;
	sub_82A37B48(ctx, base);
	// addi r4,r1,528
	ctx.r4.s64 = ctx.r1.s64 + 528;
	// lwz r3,24(r20)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r20.u32 + 24);
	// bl 0x82a37b50
	ctx.lr = 0x82A78E00;
	sub_82A37B50(ctx, base);
	// lwz r11,28(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 28);
	// lwz r10,224(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwinm r6,r11,4,28,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xF;
	// lwz r11,532(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// lwz r5,476(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	// clrlwi r7,r10,26
	ctx.r7.u64 = ctx.r10.u32 & 0x3F;
	// lwz r4,472(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	// lwz r3,468(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	// lwz r15,540(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
	// lwz r11,536(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// bl 0x82a38048
	ctx.lr = 0x82A78E3C;
	sub_82A38048(ctx, base);
	// stw r3,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r3.u32);
loc_82A78E40:
	// lwz r11,224(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// addi r4,r1,124
	ctx.r4.s64 = ctx.r1.s64 + 124;
	// clrlwi r3,r11,26
	ctx.r3.u64 = ctx.r11.u32 & 0x3F;
	// bl 0x82a38070
	ctx.lr = 0x82A78E54;
	sub_82A38070(ctx, base);
	// lwz r9,104(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r8,124(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// addi r10,r9,-1
	ctx.r10.s64 = ctx.r9.s64 + -1;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// addi r7,r11,-1
	ctx.r7.s64 = ctx.r11.s64 + -1;
	// lwz r11,100(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// andc r10,r7,r10
	ctx.r10.u64 = ctx.r7.u64 & ~ctx.r10.u64;
	// andc r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 & ~ctx.r8.u64;
	// lwz r8,236(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// mullw r11,r11,r8
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r8.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// mullw r10,r11,r10
	ctx.r10.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// stw r10,284(r1)
	PPC_STORE_U32(ctx.r1.u32 + 284, ctx.r10.u32);
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// stw r11,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, ctx.r11.u32);
	// mullw r11,r10,r15
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r15.s32);
	// addi r11,r11,4095
	ctx.r11.s64 = ctx.r11.s64 + 4095;
	// rlwinm r19,r11,0,0,19
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFF000;
loc_82A78EAC:
	// add. r3,r19,r24
	ctx.r3.u64 = ctx.r19.u64 + ctx.r24.u64;
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a78ed0
	if (ctx.cr0.eq) goto loc_82A78ED0;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// bl 0x8247f370
	ctx.lr = 0x82A78EBC;
	sub_8247F370(ctx, base);
	// mr. r17,r3
	ctx.r17.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r17.s32, 0, ctx.xer);
	// bne 0x82a78ed0
	if (!ctx.cr0.eq) goto loc_82A78ED0;
	// lis r31,-32761
	ctx.r31.s64 = -2147024896;
	// ori r31,r31,14
	ctx.r31.u64 = ctx.r31.u64 | 14;
	// b 0x82a78b54
	goto loc_82A78B54;
loc_82A78ED0:
	// cmpwi cr6,r16,0
	ctx.cr6.compare<int32_t>(ctx.r16.s32, 0, ctx.xer);
	// beq cr6,0x82a78fcc
	if (ctx.cr6.eq) goto loc_82A78FCC;
	// lwz r11,176(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a78ef4
	if (ctx.cr6.eq) goto loc_82A78EF4;
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r27,r26
	ctx.r27.u64 = ctx.r26.u64;
	// b 0x82a78f00
	goto loc_82A78F00;
loc_82A78EF4:
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// lwz r8,4(r27)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// lwz r27,16(r27)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
loc_82A78F00:
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lwz r5,128(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// subf r6,r11,r28
	ctx.r6.s64 = ctx.r28.s64 - ctx.r11.s64;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
	// addi r9,r10,-29320
	ctx.r9.s64 = ctx.r10.s64 + -29320;
	// lwz r10,804(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	// subf r7,r8,r31
	ctx.r7.s64 = ctx.r31.s64 - ctx.r8.s64;
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r11.u32);
	// clrlwi r4,r10,26
	ctx.r4.u64 = ctx.r10.u32 & 0x3F;
	// lwz r10,180(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// add r7,r7,r5
	ctx.r7.u64 = ctx.r7.u64 + ctx.r5.u64;
	// stw r8,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r8.u32);
	// add r6,r6,r10
	ctx.r6.u64 = ctx.r6.u64 + ctx.r10.u64;
	// stw r8,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r8.u32);
	// addi r7,r7,-1
	ctx.r7.s64 = ctx.r7.s64 + -1;
	// stw r27,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r27.u32);
	// addi r6,r6,-1
	ctx.r6.s64 = ctx.r6.s64 + -1;
	// stw r27,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r27.u32);
	// lbzx r9,r4,r9
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r4.u32 + ctx.r9.u32);
	// divwu r29,r7,r5
	ctx.r29.u32 = ctx.r7.u32 / ctx.r5.u32;
	// divwu r28,r6,r10
	ctx.r28.u32 = ctx.r6.u32 / ctx.r10.u32;
	// lwz r7,796(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	// mullw r9,r9,r5
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r5.s32);
	// stw r30,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r30.u32);
	// add r11,r28,r11
	ctx.r11.u64 = ctx.r28.u64 + ctx.r11.u64;
	// mullw r9,r9,r10
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// stw r11,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r11.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// rlwinm r31,r9,29,3,31
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x1FFFFFFF;
	// add r11,r29,r8
	ctx.r11.u64 = ctx.r29.u64 + ctx.r8.u64;
	// twllei r10,0
	// twllei r5,0
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r4,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r4.u32);
	// divwu r9,r18,r21
	ctx.r9.u32 = ctx.r18.u32 / ctx.r21.u32;
	// subf r7,r25,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r25.s64;
	// stw r11,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r11.u32);
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r31.u32);
	// mr r5,r18
	ctx.r5.u64 = ctx.r18.u64;
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// divwu r8,r21,r31
	ctx.r8.u32 = ctx.r21.u32 / ctx.r31.u32;
	// twllei r21,0
	// twllei r31,0
	// bl 0x82a39428
	ctx.lr = 0x82A78FB8;
	sub_82A39428(ctx, base);
	// lwz r27,836(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	// add r11,r25,r17
	ctx.r11.u64 = ctx.r25.u64 + ctx.r17.u64;
	// lwz r29,188(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lwz r22,804(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	// b 0x82a78fd0
	goto loc_82A78FD0;
loc_82A78FCC:
	// lwz r11,796(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 796);
loc_82A78FD0:
	// stw r11,368(r1)
	PPC_STORE_U32(ctx.r1.u32 + 368, ctx.r11.u32);
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq cr6,0x82a79074
	if (ctx.cr6.eq) goto loc_82A79074;
	// lwz r10,172(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// lwz r9,272(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	// add r11,r10,r24
	ctx.r11.u64 = ctx.r10.u64 + ctx.r24.u64;
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// add r11,r11,r17
	ctx.r11.u64 = ctx.r11.u64 + ctx.r17.u64;
	// stw r10,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r10.u32);
	// stw r11,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, ctx.r11.u32);
	// lwz r11,168(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a79074
	if (ctx.cr6.eq) goto loc_82A79074;
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// add r3,r24,r17
	ctx.r3.u64 = ctx.r24.u64 + ctx.r17.u64;
	// twllei r11,0
	// lwz r7,184(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// divwu r8,r10,r11
	ctx.r8.u32 = ctx.r10.u32 / ctx.r11.u32;
	// lwz r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// twllei r11,0
	// lwz r5,284(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// divwu r9,r10,r11
	ctx.r9.u32 = ctx.r10.u32 / ctx.r11.u32;
	// lwz r11,252(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// mr r10,r15
	ctx.r10.u64 = ctx.r15.u64;
	// lwz r4,280(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// stw r26,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r26.u32);
	// stw r26,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r26.u32);
	// stw r26,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r26.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// addi r11,r1,144
	ctx.r11.s64 = ctx.r1.s64 + 144;
	// stw r26,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r26.u32);
	// stw r26,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r26.u32);
	// stw r26,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r26.u32);
	// stw r15,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r15.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// stw r8,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r8.u32);
	// stw r9,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r9.u32);
	// bl 0x82a39428
	ctx.lr = 0x82A79074;
	sub_82A39428(ctx, base);
loc_82A79074:
	// rlwinm r11,r22,0,24,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r22.u32 | (ctx.r22.u64 << 32), 0) & 0xFFFFFFFFFFFFFEFF;
	// stw r21,376(r1)
	PPC_STORE_U32(ctx.r1.u32 + 376, ctx.r21.u32);
	// addi r3,r1,384
	ctx.r3.s64 = ctx.r1.s64 + 384;
	// stw r18,380(r1)
	PPC_STORE_U32(ctx.r1.u32 + 380, ctx.r18.u32);
	// li r5,24
	ctx.r5.s64 = 24;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// stw r11,372(r1)
	PPC_STORE_U32(ctx.r1.u32 + 372, ctx.r11.u32);
	// bl 0x82d5c630
	ctx.lr = 0x82A79094;
	sub_82D5C630(ctx, base);
	// addi r3,r1,408
	ctx.r3.s64 = ctx.r1.s64 + 408;
	// li r5,24
	ctx.r5.s64 = 24;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// bl 0x82d5c630
	ctx.lr = 0x82A790A4;
	sub_82D5C630(ctx, base);
	// lwz r11,344(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	// addi r5,r1,368
	ctx.r5.s64 = ctx.r1.s64 + 368;
	// lwz r6,876(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	// addi r4,r1,272
	ctx.r4.s64 = ctx.r1.s64 + 272;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// stw r11,440(r1)
	PPC_STORE_U32(ctx.r1.u32 + 440, ctx.r11.u32);
	// lwz r11,884(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	// stw r11,444(r1)
	PPC_STORE_U32(ctx.r1.u32 + 444, ctx.r11.u32);
	// lwz r11,828(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 828);
	// stw r11,448(r1)
	PPC_STORE_U32(ctx.r1.u32 + 448, ctx.r11.u32);
	// lwz r11,276(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// rlwinm r11,r11,0,24,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFEFF;
	// stw r11,276(r1)
	PPC_STORE_U32(ctx.r1.u32 + 276, ctx.r11.u32);
	// bl 0x82aaa948
	ctx.lr = 0x82A790DC;
	sub_82AAA948(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq cr6,0x82a79214
	if (ctx.cr6.eq) goto loc_82A79214;
	// cmplwi cr6,r14,0
	ctx.cr6.compare<uint32_t>(ctx.r14.u32, 0, ctx.xer);
	// beq cr6,0x82a7916c
	if (ctx.cr6.eq) goto loc_82A7916C;
	// lwz r11,168(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a7916c
	if (!ctx.cr6.eq) goto loc_82A7916C;
	// lwz r9,4(r14)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r14.u32 + 4);
	// lwz r10,0(r14)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	// extsw r6,r9
	ctx.r6.s64 = ctx.r9.s32;
	// lwz r11,8(r14)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r14.u32 + 8);
	// lwz r7,12(r14)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r14.u32 + 12);
	// lwz r5,104(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// subf r7,r9,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r9.s64;
	// lwz r8,16(r14)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r14.u32 + 16);
	// stw r10,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r10.u32);
	// stw r6,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r6.u32);
	// add r7,r7,r5
	ctx.r7.u64 = ctx.r7.u64 + ctx.r5.u64;
	// lwz r6,20(r14)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r14.u32 + 20);
	// stw r10,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r10.u32);
	// addi r7,r7,-1
	ctx.r7.s64 = ctx.r7.s64 + -1;
	// stw r8,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r8.u32);
	// divwu r7,r7,r5
	ctx.r7.u32 = ctx.r7.u32 / ctx.r5.u32;
	// stw r9,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r9.u32);
	// stw r8,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r8.u32);
	// stw r6,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r6.u32);
	// subf r6,r10,r11
	ctx.r6.s64 = ctx.r11.s64 - ctx.r10.s64;
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// add r6,r6,r11
	ctx.r6.u64 = ctx.r6.u64 + ctx.r11.u64;
	// addi r6,r6,-1
	ctx.r6.s64 = ctx.r6.s64 + -1;
	// divwu r6,r6,r11
	ctx.r6.u32 = ctx.r6.u32 / ctx.r11.u32;
	// add r10,r6,r10
	ctx.r10.u64 = ctx.r6.u64 + ctx.r10.u64;
	// stw r10,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r10.u32);
	// add r10,r7,r9
	ctx.r10.u64 = ctx.r7.u64 + ctx.r9.u64;
	// b 0x82a791b4
	goto loc_82A791B4;
loc_82A7916C:
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lwz r5,104(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r26,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r26.u32);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// stw r26,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r26.u32);
	// add r10,r10,r5
	ctx.r10.u64 = ctx.r10.u64 + ctx.r5.u64;
	// stw r26,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r26.u32);
	// divwu r9,r9,r11
	ctx.r9.u32 = ctx.r9.u32 / ctx.r11.u32;
	// stw r26,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r26.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r26,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r26.u32);
	// stw r26,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r26.u32);
	// divwu r10,r10,r5
	ctx.r10.u32 = ctx.r10.u32 / ctx.r5.u32;
	// stw r15,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r15.u32);
	// stw r9,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r9.u32);
loc_82A791B4:
	// stw r10,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r10.u32);
	// addi r7,r1,144
	ctx.r7.s64 = ctx.r1.s64 + 144;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// twllei r5,0
	// twllei r5,0
	// add r9,r10,r5
	ctx.r9.u64 = ctx.r10.u64 + ctx.r5.u64;
	// lwz r10,252(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// add r8,r24,r17
	ctx.r8.u64 = ctx.r24.u64 + ctx.r17.u64;
	// addi r4,r9,-1
	ctx.r4.s64 = ctx.r9.s64 + -1;
	// stw r7,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r7.u32);
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// lwz r9,280(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// divwu r5,r4,r5
	ctx.r5.u32 = ctx.r4.u32 / ctx.r5.u32;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// mr r6,r15
	ctx.r6.u64 = ctx.r15.u64;
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// twllei r11,0
	// twllei r11,0
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// addi r3,r10,-1
	ctx.r3.s64 = ctx.r10.s64 + -1;
	// lwz r10,284(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// divwu r4,r3,r11
	ctx.r4.u32 = ctx.r3.u32 / ctx.r11.u32;
	// lwz r3,184(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// bl 0x82a393f8
	ctx.lr = 0x82A79214;
	sub_82A393F8(ctx, base);
loc_82A79214:
	// cmplwi cr6,r17,0
	ctx.cr6.compare<uint32_t>(ctx.r17.u32, 0, ctx.xer);
	// beq cr6,0x82a78b54
	if (ctx.cr6.eq) goto loc_82A78B54;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A79228;
	sub_8247F398(ctx, base);
	// b 0x82a78b54
	goto loc_82A78B54;
}

__attribute__((alias("__imp__sub_82A79230"))) PPC_WEAK_FUNC(sub_82A79230);
PPC_FUNC_IMPL(__imp__sub_82A79230) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4a4
	ctx.lr = 0x82A79238;
	__savegprlr_19(ctx, base);
	// stwu r1,-496(r1)
	ea = -496 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// mr r22,r5
	ctx.r22.u64 = ctx.r5.u64;
	// li r5,304
	ctx.r5.s64 = 304;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r21,r6
	ctx.r21.u64 = ctx.r6.u64;
	// mr r20,r7
	ctx.r20.u64 = ctx.r7.u64;
	// mr r31,r8
	ctx.r31.u64 = ctx.r8.u64;
	// mr r19,r9
	ctx.r19.u64 = ctx.r9.u64;
	// bl 0x82d5cb60
	ctx.lr = 0x82A79268;
	sub_82D5CB60(ctx, base);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82a7927c
	if (!ctx.cr6.eq) goto loc_82A7927C;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82a79650
	goto loc_82A79650;
loc_82A7927C:
	// cmpwi cr6,r31,-1
	ctx.cr6.compare<int32_t>(ctx.r31.s32, -1, ctx.xer);
	// bne cr6,0x82a79288
	if (!ctx.cr6.eq) goto loc_82A79288;
	// li r31,0
	ctx.r31.s64 = 0;
loc_82A79288:
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// beq cr6,0x82a79298
	if (ctx.cr6.eq) goto loc_82A79298;
	// lwz r3,0(r19)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	// b 0x82a7929c
	goto loc_82A7929C;
loc_82A79298:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82A7929C:
	// bl 0x82a78320
	ctx.lr = 0x82A792A0;
	sub_82A78320(ctx, base);
	// lwz r26,580(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82a78398
	ctx.lr = 0x82A792B8;
	sub_82A78398(ctx, base);
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// rlwinm r28,r24,0,26,22
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0xFFFFFFFFFFFFFE3F;
	// cmpwi cr6,r28,-449
	ctx.cr6.compare<int32_t>(ctx.r28.s32, -449, ctx.xer);
	// bne cr6,0x82a792d4
	if (!ctx.cr6.eq) goto loc_82A792D4;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2154
	ctx.r3.u64 = ctx.r3.u64 | 2154;
	// b 0x82a79650
	goto loc_82A79650;
loc_82A792D4:
	// li r11,-1
	ctx.r11.s64 = -1;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82a792e8
	if (ctx.cr6.eq) goto loc_82A792E8;
	// lwz r31,0(r23)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	// b 0x82a792ec
	goto loc_82A792EC;
loc_82A792E8:
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
loc_82A792EC:
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// beq cr6,0x82a792fc
	if (ctx.cr6.eq) goto loc_82A792FC;
	// lwz r29,0(r22)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// b 0x82a79300
	goto loc_82A79300;
loc_82A792FC:
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
loc_82A79300:
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x82a79310
	if (ctx.cr6.eq) goto loc_82A79310;
	// lwz r27,0(r21)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// b 0x82a79314
	goto loc_82A79314;
loc_82A79310:
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
loc_82A79314:
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// beq cr6,0x82a79324
	if (ctx.cr6.eq) goto loc_82A79324;
	// lwz r25,0(r20)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	// b 0x82a79328
	goto loc_82A79328;
loc_82A79324:
	// mr r25,r11
	ctx.r25.u64 = ctx.r11.u64;
loc_82A79328:
	// cmpwi cr6,r31,-1
	ctx.cr6.compare<int32_t>(ctx.r31.s32, -1, ctx.xer);
	// bne cr6,0x82a7934c
	if (!ctx.cr6.eq) goto loc_82A7934C;
	// cmpwi cr6,r29,-1
	ctx.cr6.compare<int32_t>(ctx.r29.s32, -1, ctx.xer);
	// bne cr6,0x82a79344
	if (!ctx.cr6.eq) goto loc_82A79344;
	// li r29,256
	ctx.r29.s64 = 256;
	// li r31,256
	ctx.r31.s64 = 256;
	// b 0x82a79370
	goto loc_82A79370;
loc_82A79344:
	// mr r31,r29
	ctx.r31.u64 = ctx.r29.u64;
	// b 0x82a79358
	goto loc_82A79358;
loc_82A7934C:
	// cmpwi cr6,r29,-1
	ctx.cr6.compare<int32_t>(ctx.r29.s32, -1, ctx.xer);
	// bne cr6,0x82a79358
	if (!ctx.cr6.eq) goto loc_82A79358;
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82A79358:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82a79364
	if (!ctx.cr6.eq) goto loc_82A79364;
	// li r31,1
	ctx.r31.s64 = 1;
loc_82A79364:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82a79370
	if (!ctx.cr6.eq) goto loc_82A79370;
	// li r29,1
	ctx.r29.s64 = 1;
loc_82A79370:
	// cmpwi cr6,r26,18
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 18, ctx.xer);
	// bne cr6,0x82a79388
	if (!ctx.cr6.eq) goto loc_82A79388;
	// cmplw cr6,r31,r29
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r29.u32, ctx.xer);
	// ble cr6,0x82a79384
	if (!ctx.cr6.gt) goto loc_82A79384;
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82A79384:
	// mr r31,r29
	ctx.r31.u64 = ctx.r29.u64;
loc_82A79388:
	// cmpwi cr6,r27,-1
	ctx.cr6.compare<int32_t>(ctx.r27.s32, -1, ctx.xer);
	// beq cr6,0x82a79398
	if (ctx.cr6.eq) goto loc_82A79398;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// bne cr6,0x82a7939c
	if (!ctx.cr6.eq) goto loc_82A7939C;
loc_82A79398:
	// li r27,1
	ctx.r27.s64 = 1;
loc_82A7939C:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82a42d78
	ctx.lr = 0x82A793A8;
	sub_82A42D78(ctx, base);
	// lwz r9,140(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// cmpwi cr6,r26,17
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 17, ctx.xer);
	// bne cr6,0x82a793dc
	if (!ctx.cr6.eq) goto loc_82A793DC;
	// cmplwi cr6,r27,1024
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 1024, ctx.xer);
	// ble cr6,0x82a793c0
	if (!ctx.cr6.gt) goto loc_82A793C0;
	// li r27,1024
	ctx.r27.s64 = 1024;
loc_82A793C0:
	// cmplwi cr6,r31,2048
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 2048, ctx.xer);
	// ble cr6,0x82a793cc
	if (!ctx.cr6.gt) goto loc_82A793CC;
	// li r31,2048
	ctx.r31.s64 = 2048;
loc_82A793CC:
	// cmplwi cr6,r29,2048
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 2048, ctx.xer);
	// ble cr6,0x82a7943c
	if (!ctx.cr6.gt) goto loc_82A7943C;
	// li r29,2048
	ctx.r29.s64 = 2048;
	// b 0x82a7943c
	goto loc_82A7943C;
loc_82A793DC:
	// lwz r11,168(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a793ec
	if (!ctx.cr6.gt) goto loc_82A793EC;
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
loc_82A793EC:
	// lwz r11,172(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a793fc
	if (!ctx.cr6.gt) goto loc_82A793FC;
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
loc_82A793FC:
	// cmpwi cr6,r26,3
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 3, ctx.xer);
	// bne cr6,0x82a7943c
	if (!ctx.cr6.eq) goto loc_82A7943C;
	// rlwinm. r11,r9,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// li r10,1
	ctx.r10.s64 = 1;
	// bne 0x82a79414
	if (!ctx.cr0.eq) goto loc_82A79414;
	// lwz r10,184(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
loc_82A79414:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a7943c
	if (ctx.cr6.eq) goto loc_82A7943C;
	// mullw r11,r10,r29
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r29.s32);
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a7942c
	if (!ctx.cr6.gt) goto loc_82A7942C;
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
loc_82A7942C:
	// mullw r11,r10,r31
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r31.s32);
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a7943c
	if (!ctx.cr6.gt) goto loc_82A7943C;
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
loc_82A7943C:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmpwi cr6,r26,3
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 3, ctx.xer);
	// beq cr6,0x82a79468
	if (ctx.cr6.eq) goto loc_82A79468;
	// cmpwi cr6,r26,17
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 17, ctx.xer);
	// beq cr6,0x82a79460
	if (ctx.cr6.eq) goto loc_82A79460;
	// cmpwi cr6,r26,18
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 18, ctx.xer);
	// bne cr6,0x82a7946c
	if (!ctx.cr6.eq) goto loc_82A7946C;
	// lis r11,2
	ctx.r11.s64 = 131072;
	// b 0x82a7946c
	goto loc_82A7946C;
loc_82A79460:
	// lis r11,4
	ctx.r11.s64 = 262144;
	// b 0x82a7946c
	goto loc_82A7946C;
loc_82A79468:
	// li r11,2
	ctx.r11.s64 = 2;
loc_82A7946C:
	// lis r10,6688
	ctx.r10.s64 = 438304768;
	// cmplwi cr6,r25,1
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 1, ctx.xer);
	// ori r10,r10,18
	ctx.r10.u64 = ctx.r10.u64 | 18;
	// bne cr6,0x82a794a0
	if (!ctx.cr6.eq) goto loc_82A794A0;
	// rlwinm. r8,r9,0,23,23
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x100;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a794a0
	if (ctx.cr0.eq) goto loc_82A794A0;
	// cmpw cr6,r28,r10
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82a7949c
	if (ctx.cr6.lt) goto loc_82A7949C;
	// lis r8,6688
	ctx.r8.s64 = 438304768;
	// ori r8,r8,20
	ctx.r8.u64 = ctx.r8.u64 | 20;
	// cmpw cr6,r28,r8
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r8.s32, ctx.xer);
	// ble cr6,0x82a794a0
	if (!ctx.cr6.gt) goto loc_82A794A0;
loc_82A7949C:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82A794A0:
	// and. r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 & ctx.r9.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a794fc
	if (ctx.cr0.eq) goto loc_82A794FC;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// li r31,1
	ctx.r31.s64 = 1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// ble cr6,0x82a794c4
	if (!ctx.cr6.gt) goto loc_82A794C4;
loc_82A794B8:
	// rlwinm r31,r31,1,0,30
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a794b8
	if (ctx.cr6.lt) goto loc_82A794B8;
loc_82A794C4:
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// li r29,1
	ctx.r29.s64 = 1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// ble cr6,0x82a794e0
	if (!ctx.cr6.gt) goto loc_82A794E0;
loc_82A794D4:
	// rlwinm r29,r29,1,0,30
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a794d4
	if (ctx.cr6.lt) goto loc_82A794D4;
loc_82A794E0:
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// li r27,1
	ctx.r27.s64 = 1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// ble cr6,0x82a794fc
	if (!ctx.cr6.gt) goto loc_82A794FC;
loc_82A794F0:
	// rlwinm r27,r27,1,0,30
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a794f0
	if (ctx.cr6.lt) goto loc_82A794F0;
loc_82A794FC:
	// subf r11,r10,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r10.s64;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// bgt cr6,0x82a79518
	if (ctx.cr6.gt) goto loc_82A79518;
	// addi r11,r31,3
	ctx.r11.s64 = ctx.r31.s64 + 3;
	// addi r10,r29,3
	ctx.r10.s64 = ctx.r29.s64 + 3;
	// rlwinm r31,r11,0,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// rlwinm r29,r10,0,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
loc_82A79518:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmpwi cr6,r26,3
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 3, ctx.xer);
	// beq cr6,0x82a79548
	if (ctx.cr6.eq) goto loc_82A79548;
	// cmpwi cr6,r26,17
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 17, ctx.xer);
	// beq cr6,0x82a7953c
	if (ctx.cr6.eq) goto loc_82A7953C;
	// cmpwi cr6,r26,18
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 18, ctx.xer);
	// bne cr6,0x82a7954c
	if (!ctx.cr6.eq) goto loc_82A7954C;
	// lis r11,1
	ctx.r11.s64 = 65536;
	// b 0x82a7954c
	goto loc_82A7954C;
loc_82A7953C:
	// lis r11,0
	ctx.r11.s64 = 0;
	// ori r11,r11,32768
	ctx.r11.u64 = ctx.r11.u64 | 32768;
	// b 0x82a7954c
	goto loc_82A7954C;
loc_82A79548:
	// li r11,16384
	ctx.r11.s64 = 16384;
loc_82A7954C:
	// and. r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 & ctx.r9.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a79580
	if (ctx.cr0.eq) goto loc_82A79580;
	// rlwinm. r11,r9,0,23,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x100;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a79588
	if (ctx.cr0.eq) goto loc_82A79588;
	// addi r11,r31,-1
	ctx.r11.s64 = ctx.r31.s64 + -1;
	// and. r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 & ctx.r31.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a79580
	if (!ctx.cr0.eq) goto loc_82A79580;
	// addi r11,r29,-1
	ctx.r11.s64 = ctx.r29.s64 + -1;
	// and. r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 & ctx.r29.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a79580
	if (!ctx.cr0.eq) goto loc_82A79580;
	// addi r11,r27,-1
	ctx.r11.s64 = ctx.r27.s64 + -1;
	// and. r11,r11,r27
	ctx.r11.u64 = ctx.r11.u64 & ctx.r27.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a79588
	if (ctx.cr0.eq) goto loc_82A79588;
loc_82A79580:
	// li r25,1
	ctx.r25.s64 = 1;
	// b 0x82a79610
	goto loc_82A79610;
loc_82A79588:
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82a795a4
	if (ctx.cr6.eq) goto loc_82A795A4;
loc_82A79598:
	// rlwinm. r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// bne 0x82a79598
	if (!ctx.cr0.eq) goto loc_82A79598;
loc_82A795A4:
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82a795c0
	if (ctx.cr6.eq) goto loc_82A795C0;
loc_82A795B4:
	// rlwinm. r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// bne 0x82a795b4
	if (!ctx.cr0.eq) goto loc_82A795B4;
loc_82A795C0:
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a795dc
	if (ctx.cr6.eq) goto loc_82A795DC;
loc_82A795D0:
	// rlwinm. r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// bne 0x82a795d0
	if (!ctx.cr0.eq) goto loc_82A795D0;
loc_82A795DC:
	// cmplw cr6,r8,r11
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a795e8
	if (!ctx.cr6.gt) goto loc_82A795E8;
	// mr r11,r8
	ctx.r11.u64 = ctx.r8.u64;
loc_82A795E8:
	// cmpwi cr6,r26,17
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 17, ctx.xer);
	// bne cr6,0x82a795fc
	if (!ctx.cr6.eq) goto loc_82A795FC;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a795fc
	if (!ctx.cr6.gt) goto loc_82A795FC;
	// mr r11,r9
	ctx.r11.u64 = ctx.r9.u64;
loc_82A795FC:
	// cmplw cr6,r25,r11
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, ctx.r11.u32, ctx.xer);
	// bgt cr6,0x82a7960c
	if (ctx.cr6.gt) goto loc_82A7960C;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// bne cr6,0x82a79610
	if (!ctx.cr6.eq) goto loc_82A79610;
loc_82A7960C:
	// mr r25,r11
	ctx.r25.u64 = ctx.r11.u64;
loc_82A79610:
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82a7961c
	if (ctx.cr6.eq) goto loc_82A7961C;
	// stw r31,0(r23)
	PPC_STORE_U32(ctx.r23.u32 + 0, ctx.r31.u32);
loc_82A7961C:
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// beq cr6,0x82a79628
	if (ctx.cr6.eq) goto loc_82A79628;
	// stw r29,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r29.u32);
loc_82A79628:
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x82a79634
	if (ctx.cr6.eq) goto loc_82A79634;
	// stw r27,0(r21)
	PPC_STORE_U32(ctx.r21.u32 + 0, ctx.r27.u32);
loc_82A79634:
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// beq cr6,0x82a79640
	if (ctx.cr6.eq) goto loc_82A79640;
	// stw r25,0(r20)
	PPC_STORE_U32(ctx.r20.u32 + 0, ctx.r25.u32);
loc_82A79640:
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// beq cr6,0x82a7964c
	if (ctx.cr6.eq) goto loc_82A7964C;
	// stw r24,0(r19)
	PPC_STORE_U32(ctx.r19.u32 + 0, ctx.r24.u32);
loc_82A7964C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A79650:
	// addi r1,r1,496
	ctx.r1.s64 = ctx.r1.s64 + 496;
	// b 0x82d5c4f4
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A79658"))) PPC_WEAK_FUNC(sub_82A79658);
PPC_FUNC_IMPL(__imp__sub_82A79658) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b8
	ctx.lr = 0x82A79660;
	__savegprlr_24(ctx, base);
	// stwu r1,-400(r1)
	ea = -400 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// mr r28,r8
	ctx.r28.u64 = ctx.r8.u64;
	// mr r25,r9
	ctx.r25.u64 = ctx.r9.u64;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
	// bl 0x82aaaaf0
	ctx.lr = 0x82A7968C;
	sub_82AAAAF0(ctx, base);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82a796ac
	if (!ctx.cr6.eq) goto loc_82A796AC;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82aaad60
	ctx.lr = 0x82A7969C;
	sub_82AAAD60(ctx, base);
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
loc_82A796A4:
	// addi r1,r1,400
	ctx.r1.s64 = ctx.r1.s64 + 400;
	// b 0x82d5c508
	__restgprlr_24(ctx, base);
	return;
loc_82A796AC:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82a796cc
	if (!ctx.cr6.eq) goto loc_82A796CC;
	// lis r31,-30602
	ctx.r31.s64 = -2005532672;
	// ori r31,r31,2156
	ctx.r31.u64 = ctx.r31.u64 | 2156;
loc_82A796BC:
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82aaad60
	ctx.lr = 0x82A796C4;
	sub_82AAAD60(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// b 0x82a796a4
	goto loc_82A796A4;
loc_82A796CC:
	// li r9,1
	ctx.r9.s64 = 1;
	// cmplw cr6,r30,r31
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82a796e0
	if (!ctx.cr6.eq) goto loc_82A796E0;
	// lis r9,1
	ctx.r9.s64 = 65536;
	// ori r9,r9,1
	ctx.r9.u64 = ctx.r9.u64 | 1;
loc_82A796E0:
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82aaad68
	ctx.lr = 0x82A796FC;
	sub_82AAAD68(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a7970c
	if (!ctx.cr0.lt) goto loc_82A7970C;
loc_82A79704:
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// b 0x82a796bc
	goto loc_82A796BC;
loc_82A7970C:
	// addi r5,r1,256
	ctx.r5.s64 = ctx.r1.s64 + 256;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82a37b48
	ctx.lr = 0x82A7971C;
	sub_82A37B48(ctx, base);
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r7,264(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	// addi r10,r1,200
	ctx.r10.s64 = ctx.r1.s64 + 200;
	// lwz r6,260(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// lwz r8,168(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// stw r24,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r24.u32);
	// lwz r11,48(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r7,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r7.u32);
	// rlwinm r11,r11,21,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 21) & 0x1;
	// stw r6,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r6.u32);
	// lwz r7,164(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// lwz r6,160(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// stw r25,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r25.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82a783f8
	ctx.lr = 0x82A79768;
	sub_82A783F8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a79704
	if (ctx.cr0.lt) goto loc_82A79704;
	// li r31,0
	ctx.r31.s64 = 0;
	// b 0x82a796bc
	goto loc_82A796BC;
}

__attribute__((alias("__imp__sub_82A79778"))) PPC_WEAK_FUNC(sub_82A79778);
PPC_FUNC_IMPL(__imp__sub_82A79778) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b8
	ctx.lr = 0x82A79780;
	__savegprlr_24(ctx, base);
	// stwu r1,-400(r1)
	ea = -400 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// mr r28,r8
	ctx.r28.u64 = ctx.r8.u64;
	// mr r25,r9
	ctx.r25.u64 = ctx.r9.u64;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
	// bl 0x82aaab10
	ctx.lr = 0x82A797AC;
	sub_82AAAB10(ctx, base);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82a797cc
	if (!ctx.cr6.eq) goto loc_82A797CC;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82aab258
	ctx.lr = 0x82A797BC;
	sub_82AAB258(ctx, base);
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
loc_82A797C4:
	// addi r1,r1,400
	ctx.r1.s64 = ctx.r1.s64 + 400;
	// b 0x82d5c508
	__restgprlr_24(ctx, base);
	return;
loc_82A797CC:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82a797ec
	if (!ctx.cr6.eq) goto loc_82A797EC;
	// lis r31,-30602
	ctx.r31.s64 = -2005532672;
	// ori r31,r31,2156
	ctx.r31.u64 = ctx.r31.u64 | 2156;
loc_82A797DC:
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82aab258
	ctx.lr = 0x82A797E4;
	sub_82AAB258(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// b 0x82a797c4
	goto loc_82A797C4;
loc_82A797EC:
	// li r9,1
	ctx.r9.s64 = 1;
	// cmplw cr6,r30,r31
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82a79800
	if (!ctx.cr6.eq) goto loc_82A79800;
	// lis r9,1
	ctx.r9.s64 = 65536;
	// ori r9,r9,1
	ctx.r9.u64 = ctx.r9.u64 | 1;
loc_82A79800:
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82aab260
	ctx.lr = 0x82A7981C;
	sub_82AAB260(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a7982c
	if (!ctx.cr0.lt) goto loc_82A7982C;
loc_82A79824:
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// b 0x82a797dc
	goto loc_82A797DC;
loc_82A7982C:
	// addi r5,r1,256
	ctx.r5.s64 = ctx.r1.s64 + 256;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82a37b48
	ctx.lr = 0x82A7983C;
	sub_82A37B48(ctx, base);
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r4,260(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// addi r5,r1,200
	ctx.r5.s64 = ctx.r1.s64 + 200;
	// lwz r8,268(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
	// lwz r7,264(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r9,172(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// lwz r11,48(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	// stw r4,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r4.u32);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// rlwinm r11,r11,21,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 21) & 0x1;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// stw r8,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r8.u32);
	// stw r7,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r7.u32);
	// lwz r8,168(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// lwz r7,164(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// lwz r6,160(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// stw r24,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r24.u32);
	// stw r25,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r25.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// bl 0x82a78a88
	ctx.lr = 0x82A79898;
	sub_82A78A88(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a79824
	if (ctx.cr0.lt) goto loc_82A79824;
	// li r31,0
	ctx.r31.s64 = 0;
	// b 0x82a797dc
	goto loc_82A797DC;
}

__attribute__((alias("__imp__sub_82A798A8"))) PPC_WEAK_FUNC(sub_82A798A8);
PPC_FUNC_IMPL(__imp__sub_82A798A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82A798B0;
	__savegprlr_14(ctx, base);
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r14,r4
	ctx.r14.u64 = ctx.r4.u64;
	// mr r18,r5
	ctx.r18.u64 = ctx.r5.u64;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82a798d8
	if (!ctx.cr6.eq) goto loc_82A798D8;
loc_82A798CC:
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82a79cc4
	goto loc_82A79CC4;
loc_82A798D8:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82a41f08
	ctx.lr = 0x82A798E0;
	sub_82A41F08(ctx, base);
	// mr r19,r3
	ctx.r19.u64 = ctx.r3.u64;
	// cmpwi cr6,r19,3
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 3, ctx.xer);
	// beq cr6,0x82a79918
	if (ctx.cr6.eq) goto loc_82A79918;
	// cmpwi cr6,r19,17
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 17, ctx.xer);
	// beq cr6,0x82a79908
	if (ctx.cr6.eq) goto loc_82A79908;
	// cmpwi cr6,r19,18
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 18, ctx.xer);
	// bne cr6,0x82a798cc
	if (!ctx.cr6.eq) goto loc_82A798CC;
	// lwz r16,80(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r17,r30
	ctx.r17.u64 = ctx.r30.u64;
	// b 0x82a79920
	goto loc_82A79920;
loc_82A79908:
	// lwz r16,80(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r15,r30
	ctx.r15.u64 = ctx.r30.u64;
	// lwz r17,80(r1)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// b 0x82a79924
	goto loc_82A79924;
loc_82A79918:
	// lwz r17,80(r1)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r16,r30
	ctx.r16.u64 = ctx.r30.u64;
loc_82A79920:
	// lwz r15,80(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82A79924:
	// cmpwi cr6,r31,-1
	ctx.cr6.compare<int32_t>(ctx.r31.s32, -1, ctx.xer);
	// bne cr6,0x82a7997c
	if (!ctx.cr6.eq) goto loc_82A7997C;
	// cmpwi cr6,r19,3
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 3, ctx.xer);
	// beq cr6,0x82a79a7c
	if (ctx.cr6.eq) goto loc_82A79A7C;
	// cmpwi cr6,r19,17
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 17, ctx.xer);
	// beq cr6,0x82a79a44
	if (ctx.cr6.eq) goto loc_82A79A44;
	// cmpwi cr6,r19,18
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 18, ctx.xer);
	// bne cr6,0x82a79ab4
	if (!ctx.cr6.eq) goto loc_82A79AB4;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82a47128
	ctx.lr = 0x82A79954;
	sub_82A47128(ctx, base);
	// lwz r11,152(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// and. r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a79974
	if (!ctx.cr0.eq) goto loc_82A79974;
	// lwz r11,156(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
loc_82A79968:
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// and. r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a79ac0
	if (ctx.cr0.eq) goto loc_82A79AC0;
loc_82A79974:
	// lis r31,8
	ctx.r31.s64 = 524288;
	// ori r31,r31,4
	ctx.r31.u64 = ctx.r31.u64 | 4;
loc_82A7997C:
	// cmpwi cr6,r19,18
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 18, ctx.xer);
	// bne cr6,0x82a79988
	if (!ctx.cr6.eq) goto loc_82A79988;
	// oris r31,r31,7
	ctx.r31.u64 = ctx.r31.u64 | 458752;
loc_82A79988:
	// rlwinm. r11,r31,0,9,9
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0x400000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// oris r21,r31,96
	ctx.r21.u64 = ctx.r31.u64 | 6291456;
	// bne 0x82a79998
	if (!ctx.cr0.eq) goto loc_82A79998;
	// rlwinm r21,r31,0,11,8
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFFFFF9FFFFF;
loc_82A79998:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82a47058
	ctx.lr = 0x82A799A0;
	sub_82A47058(ctx, base);
	// mr r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	// cmpwi cr6,r18,-1
	ctx.cr6.compare<int32_t>(ctx.r18.s32, -1, ctx.xer);
	// bne cr6,0x82a799b0
	if (!ctx.cr6.eq) goto loc_82A799B0;
	// li r18,0
	ctx.r18.s64 = 0;
loc_82A799B0:
	// cmplw cr6,r18,r20
	ctx.cr6.compare<uint32_t>(ctx.r18.u32, ctx.r20.u32, ctx.xer);
	// bge cr6,0x82a798cc
	if (!ctx.cr6.lt) goto loc_82A798CC;
	// li r29,0
	ctx.r29.s64 = 0;
	// li r26,0
	ctx.r26.s64 = 0;
	// li r28,0
	ctx.r28.s64 = 0;
	// li r25,0
	ctx.r25.s64 = 0;
	// cmpwi cr6,r19,18
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 18, ctx.xer);
	// li r22,6
	ctx.r22.s64 = 6;
	// beq cr6,0x82a799d8
	if (ctx.cr6.eq) goto loc_82A799D8;
	// li r22,1
	ctx.r22.s64 = 1;
loc_82A799D8:
	// clrlwi r11,r21,24
	ctx.r11.u64 = ctx.r21.u32 & 0xFF;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82a799f0
	if (ctx.cr6.eq) goto loc_82A799F0;
	// cmplwi cr6,r11,5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 5, ctx.xer);
	// li r23,0
	ctx.r23.s64 = 0;
	// bne cr6,0x82a799f4
	if (!ctx.cr6.eq) goto loc_82A799F4;
loc_82A799F0:
	// li r23,1
	ctx.r23.s64 = 1;
loc_82A799F4:
	// li r27,0
	ctx.r27.s64 = 0;
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// beq cr6,0x82a79c7c
	if (ctx.cr6.eq) goto loc_82A79C7C;
	// lis r11,-32761
	ctx.r11.s64 = -2147024896;
	// lwz r31,80(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// ori r24,r11,14
	ctx.r24.u64 = ctx.r11.u64 | 14;
loc_82A79A0C:
	// cmpwi cr6,r19,3
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 3, ctx.xer);
	// beq cr6,0x82a79adc
	if (ctx.cr6.eq) goto loc_82A79ADC;
	// cmpwi cr6,r19,17
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 17, ctx.xer);
	// beq cr6,0x82a79ac8
	if (ctx.cr6.eq) goto loc_82A79AC8;
	// cmpwi cr6,r19,18
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 18, ctx.xer);
	// bne cr6,0x82a79af4
	if (!ctx.cr6.eq) goto loc_82A79AF4;
	// mr r5,r18
	ctx.r5.u64 = ctx.r18.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82a47200
	ctx.lr = 0x82A79A34;
	sub_82A47200(ctx, base);
	// mr. r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
loc_82A79A38:
	// beq 0x82a79ccc
	if (ctx.cr0.eq) goto loc_82A79CCC;
loc_82A79A3C:
	// li r31,0
	ctx.r31.s64 = 0;
	// b 0x82a79afc
	goto loc_82A79AFC;
loc_82A79A44:
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r15
	ctx.r3.u64 = ctx.r15.u64;
	// bl 0x82a472c0
	ctx.lr = 0x82A79A54;
	sub_82A472C0(ctx, base);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// and. r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a79974
	if (!ctx.cr0.eq) goto loc_82A79974;
	// lwz r11,116(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// and. r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a79974
	if (!ctx.cr0.eq) goto loc_82A79974;
	// lwz r11,120(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// b 0x82a79968
	goto loc_82A79968;
loc_82A79A7C:
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
	// bl 0x82a47128
	ctx.lr = 0x82A79A8C;
	sub_82A47128(ctx, base);
	// lwz r11,152(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// and. r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a79aac
	if (!ctx.cr0.eq) goto loc_82A79AAC;
	// lwz r11,156(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// and. r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a79ac0
	if (ctx.cr0.eq) goto loc_82A79AC0;
loc_82A79AAC:
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82a79ab8
	goto loc_82A79AB8;
loc_82A79AB4:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82A79AB8:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a79974
	if (ctx.cr6.eq) goto loc_82A79974;
loc_82A79AC0:
	// li r31,5
	ctx.r31.s64 = 5;
	// b 0x82a7997c
	goto loc_82A7997C;
loc_82A79AC8:
	// mr r4,r18
	ctx.r4.u64 = ctx.r18.u64;
	// mr r3,r15
	ctx.r3.u64 = ctx.r15.u64;
	// bl 0x82a472c8
	ctx.lr = 0x82A79AD4;
	sub_82A472C8(ctx, base);
	// mr. r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// b 0x82a79a38
	goto loc_82A79A38;
loc_82A79ADC:
	// mr r4,r18
	ctx.r4.u64 = ctx.r18.u64;
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
	// bl 0x82a47130
	ctx.lr = 0x82A79AE8;
	sub_82A47130(ctx, base);
	// mr. r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// bne 0x82a79a3c
	if (!ctx.cr0.eq) goto loc_82A79A3C;
	// mr r31,r24
	ctx.r31.u64 = ctx.r24.u64;
loc_82A79AF4:
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt cr6,0x82a79c80
	if (ctx.cr6.lt) goto loc_82A79C80;
loc_82A79AFC:
	// addi r30,r18,1
	ctx.r30.s64 = ctx.r18.s64 + 1;
	// b 0x82a79c40
	goto loc_82A79C40;
loc_82A79B04:
	// cmpwi cr6,r19,3
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 3, ctx.xer);
	// beq cr6,0x82a79bd8
	if (ctx.cr6.eq) goto loc_82A79BD8;
	// cmpwi cr6,r19,17
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 17, ctx.xer);
	// beq cr6,0x82a79b9c
	if (ctx.cr6.eq) goto loc_82A79B9C;
	// cmpwi cr6,r19,18
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 18, ctx.xer);
	// bne cr6,0x82a79bf0
	if (!ctx.cr6.eq) goto loc_82A79BF0;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82a47200
	ctx.lr = 0x82A79B2C;
	sub_82A47200(ctx, base);
	// mr. r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// beq 0x82a79ccc
	if (ctx.cr0.eq) goto loc_82A79CCC;
loc_82A79B34:
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r21
	ctx.r9.u64 = ctx.r21.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r14
	ctx.r7.u64 = ctx.r14.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r14
	ctx.r4.u64 = ctx.r14.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82a79658
	ctx.lr = 0x82A79B58;
	sub_82A79658(ctx, base);
loc_82A79B58:
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
loc_82A79B5C:
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt cr6,0x82a79c80
	if (ctx.cr6.lt) goto loc_82A79C80;
	// cmpwi cr6,r23,0
	ctx.cr6.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// beq cr6,0x82a79c14
	if (ctx.cr6.eq) goto loc_82A79C14;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82a79b7c
	if (ctx.cr6.eq) goto loc_82A79B7C;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82a42570
	ctx.lr = 0x82A79B7C;
	sub_82A42570(ctx, base);
loc_82A79B7C:
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a79b8c
	if (ctx.cr6.eq) goto loc_82A79B8C;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82a42570
	ctx.lr = 0x82A79B8C;
	sub_82A42570(ctx, base);
loc_82A79B8C:
	// mr r29,r28
	ctx.r29.u64 = ctx.r28.u64;
	// mr r26,r25
	ctx.r26.u64 = ctx.r25.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// b 0x82a79c38
	goto loc_82A79C38;
loc_82A79B9C:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r15
	ctx.r3.u64 = ctx.r15.u64;
	// bl 0x82a472c8
	ctx.lr = 0x82A79BA8;
	sub_82A472C8(ctx, base);
	// mr. r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// beq 0x82a79ccc
	if (ctx.cr0.eq) goto loc_82A79CCC;
loc_82A79BB0:
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r21
	ctx.r9.u64 = ctx.r21.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r14
	ctx.r7.u64 = ctx.r14.u64;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r14
	ctx.r4.u64 = ctx.r14.u64;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82a79778
	ctx.lr = 0x82A79BD4;
	sub_82A79778(ctx, base);
	// b 0x82a79b58
	goto loc_82A79B58;
loc_82A79BD8:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
	// bl 0x82a47130
	ctx.lr = 0x82A79BE4;
	sub_82A47130(ctx, base);
	// mr. r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// bne 0x82a79b34
	if (!ctx.cr0.eq) goto loc_82A79B34;
	// mr r31,r24
	ctx.r31.u64 = ctx.r24.u64;
loc_82A79BF0:
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt cr6,0x82a79c80
	if (ctx.cr6.lt) goto loc_82A79C80;
	// cmpwi cr6,r19,3
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 3, ctx.xer);
	// beq cr6,0x82a79b34
	if (ctx.cr6.eq) goto loc_82A79B34;
	// cmpwi cr6,r19,17
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 17, ctx.xer);
	// beq cr6,0x82a79bb0
	if (ctx.cr6.eq) goto loc_82A79BB0;
	// cmpwi cr6,r19,18
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 18, ctx.xer);
	// beq cr6,0x82a79b34
	if (ctx.cr6.eq) goto loc_82A79B34;
	// b 0x82a79b5c
	goto loc_82A79B5C;
loc_82A79C14:
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82a79c28
	if (ctx.cr6.eq) goto loc_82A79C28;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82a42570
	ctx.lr = 0x82A79C24;
	sub_82A42570(ctx, base);
	// li r28,0
	ctx.r28.s64 = 0;
loc_82A79C28:
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x82a79c3c
	if (ctx.cr6.eq) goto loc_82A79C3C;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82a42570
	ctx.lr = 0x82A79C38;
	sub_82A42570(ctx, base);
loc_82A79C38:
	// li r25,0
	ctx.r25.s64 = 0;
loc_82A79C3C:
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
loc_82A79C40:
	// cmplw cr6,r30,r20
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r20.u32, ctx.xer);
	// blt cr6,0x82a79b04
	if (ctx.cr6.lt) goto loc_82A79B04;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82a79c5c
	if (ctx.cr6.eq) goto loc_82A79C5C;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82a42570
	ctx.lr = 0x82A79C58;
	sub_82A42570(ctx, base);
	// li r29,0
	ctx.r29.s64 = 0;
loc_82A79C5C:
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a79c70
	if (ctx.cr6.eq) goto loc_82A79C70;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82a42570
	ctx.lr = 0x82A79C6C;
	sub_82A42570(ctx, base);
	// li r26,0
	ctx.r26.s64 = 0;
loc_82A79C70:
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// cmplw cr6,r27,r22
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r22.u32, ctx.xer);
	// blt cr6,0x82a79a0c
	if (ctx.cr6.lt) goto loc_82A79A0C;
loc_82A79C7C:
	// li r31,0
	ctx.r31.s64 = 0;
loc_82A79C80:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82a79c90
	if (ctx.cr6.eq) goto loc_82A79C90;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82a42570
	ctx.lr = 0x82A79C90;
	sub_82A42570(ctx, base);
loc_82A79C90:
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a79ca0
	if (ctx.cr6.eq) goto loc_82A79CA0;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82a42570
	ctx.lr = 0x82A79CA0;
	sub_82A42570(ctx, base);
loc_82A79CA0:
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82a79cb0
	if (ctx.cr6.eq) goto loc_82A79CB0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82a42570
	ctx.lr = 0x82A79CB0;
	sub_82A42570(ctx, base);
loc_82A79CB0:
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x82a79cc0
	if (ctx.cr6.eq) goto loc_82A79CC0;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82a42570
	ctx.lr = 0x82A79CC0;
	sub_82A42570(ctx, base);
loc_82A79CC0:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82A79CC4:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
loc_82A79CCC:
	// mr r31,r24
	ctx.r31.u64 = ctx.r24.u64;
	// b 0x82a79c80
	goto loc_82A79C80;
}

__attribute__((alias("__imp__sub_82A79CD8"))) PPC_WEAK_FUNC(sub_82A79CD8);
PPC_FUNC_IMPL(__imp__sub_82A79CD8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82A79CE0;
	__savegprlr_14(ctx, base);
	// stwu r1,-1520(r1)
	ea = -1520 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// stw r9,1588(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1588, ctx.r9.u32);
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// mr r26,r8
	ctx.r26.u64 = ctx.r8.u64;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// stw r28,1564(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1564, ctx.r28.u32);
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// stw r27,1572(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1572, ctx.r27.u32);
	// stw r26,1580(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1580, ctx.r26.u32);
	// mr r25,r10
	ctx.r25.u64 = ctx.r10.u64;
	// bl 0x82aa3238
	ctx.lr = 0x82A79D18;
	sub_82AA3238(ctx, base);
	// li r16,0
	ctx.r16.s64 = 0;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// mr r17,r16
	ctx.r17.u64 = ctx.r16.u64;
	// stw r16,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r16.u32);
	// bne cr6,0x82a79d44
	if (!ctx.cr6.eq) goto loc_82A79D44;
loc_82A79D2C:
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82aa3550
	ctx.lr = 0x82A79D34;
	sub_82AA3550(ctx, base);
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
loc_82A79D3C:
	// addi r1,r1,1520
	ctx.r1.s64 = ctx.r1.s64 + 1520;
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
loc_82A79D44:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82a79d2c
	if (ctx.cr6.eq) goto loc_82A79D2C;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82a79d2c
	if (ctx.cr6.eq) goto loc_82A79D2C;
	// lwz r11,1668(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1668);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a79d78
	if (!ctx.cr6.eq) goto loc_82A79D78;
	// lis r30,-30602
	ctx.r30.s64 = -2005532672;
	// ori r30,r30,2156
	ctx.r30.u64 = ctx.r30.u64 | 2156;
loc_82A79D68:
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82aa3550
	ctx.lr = 0x82A79D70;
	sub_82AA3550(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// b 0x82a79d3c
	goto loc_82A79D3C;
loc_82A79D78:
	// lwz r29,1644(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1644);
	// lwz r22,1660(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82a79d94
	if (!ctx.cr6.eq) goto loc_82A79D94;
	// cmpwi cr6,r22,-1
	ctx.cr6.compare<int32_t>(ctx.r22.s32, -1, ctx.xer);
	// bne cr6,0x82a79d94
	if (!ctx.cr6.eq) goto loc_82A79D94;
	// addi r29,r1,304
	ctx.r29.s64 = ctx.r1.s64 + 304;
loc_82A79D94:
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82aa6c40
	ctx.lr = 0x82A79DAC;
	sub_82AA6C40(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a79dbc
	if (!ctx.cr0.lt) goto loc_82A79DBC;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// b 0x82a79d68
	goto loc_82A79D68;
loc_82A79DBC:
	// cmpwi cr6,r22,-1
	ctx.cr6.compare<int32_t>(ctx.r22.s32, -1, ctx.xer);
	// bne cr6,0x82a79dcc
	if (!ctx.cr6.eq) goto loc_82A79DCC;
	// lwz r22,20(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// stw r22,1660(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1660, ctx.r22.u32);
loc_82A79DCC:
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,236(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r10,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r10.u32);
	// beq cr6,0x82a79df4
	if (ctx.cr6.eq) goto loc_82A79DF4;
loc_82A79DE0:
	// lwz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82a79de0
	if (!ctx.cr0.eq) goto loc_82A79DE0;
	// stw r10,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r10.u32);
loc_82A79DF4:
	// li r10,1
	ctx.r10.s64 = 1;
	// cmpwi cr6,r22,18
	ctx.cr6.compare<int32_t>(ctx.r22.s32, 18, ctx.xer);
	// stw r10,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r10.u32);
	// bne cr6,0x82a79e38
	if (!ctx.cr6.eq) goto loc_82A79E38;
	// lwz r11,240(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a79e2c
	if (ctx.cr6.eq) goto loc_82A79E2C;
loc_82A79E10:
	// lwz r11,80(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82a79e10
	if (!ctx.cr0.eq) goto loc_82A79E10;
	// stw r10,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r10.u32);
	// cmplwi cr6,r10,6
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 6, ctx.xer);
	// beq cr6,0x82a79e38
	if (ctx.cr6.eq) goto loc_82A79E38;
loc_82A79E2C:
	// lis r30,-32768
	ctx.r30.s64 = -2147483648;
	// ori r30,r30,16389
	ctx.r30.u64 = ctx.r30.u64 | 16389;
	// b 0x82a79d68
	goto loc_82A79D68;
loc_82A79E38:
	// lwz r10,172(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// cmpwi cr6,r28,-2
	ctx.cr6.compare<int32_t>(ctx.r28.s32, -2, ctx.xer);
	// beq cr6,0x82a79e80
	if (ctx.cr6.eq) goto loc_82A79E80;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// blt cr6,0x82a79e80
	if (ctx.cr6.lt) goto loc_82A79E80;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82a79e5c
	if (ctx.cr6.eq) goto loc_82A79E5C;
	// cmpwi cr6,r28,-1
	ctx.cr6.compare<int32_t>(ctx.r28.s32, -1, ctx.xer);
	// bne cr6,0x82a79e84
	if (!ctx.cr6.eq) goto loc_82A79E84;
loc_82A79E5C:
	// li r11,1
	ctx.r11.s64 = 1;
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// stw r11,1564(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1564, ctx.r11.u32);
	// ble cr6,0x82a79e84
	if (!ctx.cr6.gt) goto loc_82A79E84;
loc_82A79E6C:
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a79e6c
	if (ctx.cr6.lt) goto loc_82A79E6C;
	// stw r11,1564(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1564, ctx.r11.u32);
	// b 0x82a79e84
	goto loc_82A79E84;
loc_82A79E80:
	// stw r10,1564(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1564, ctx.r10.u32);
loc_82A79E84:
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmpwi cr6,r27,-2
	ctx.cr6.compare<int32_t>(ctx.r27.s32, -2, ctx.xer);
	// beq cr6,0x82a79ecc
	if (ctx.cr6.eq) goto loc_82A79ECC;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// blt cr6,0x82a79ecc
	if (ctx.cr6.lt) goto loc_82A79ECC;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a79ea8
	if (ctx.cr6.eq) goto loc_82A79EA8;
	// cmpwi cr6,r27,-1
	ctx.cr6.compare<int32_t>(ctx.r27.s32, -1, ctx.xer);
	// bne cr6,0x82a79ed0
	if (!ctx.cr6.eq) goto loc_82A79ED0;
loc_82A79EA8:
	// li r11,1
	ctx.r11.s64 = 1;
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// stw r11,1572(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1572, ctx.r11.u32);
	// ble cr6,0x82a79ed0
	if (!ctx.cr6.gt) goto loc_82A79ED0;
loc_82A79EB8:
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a79eb8
	if (ctx.cr6.lt) goto loc_82A79EB8;
	// stw r11,1572(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1572, ctx.r11.u32);
	// b 0x82a79ed0
	goto loc_82A79ED0;
loc_82A79ECC:
	// stw r10,1572(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1572, ctx.r10.u32);
loc_82A79ED0:
	// lwz r10,180(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// cmpwi cr6,r26,-2
	ctx.cr6.compare<int32_t>(ctx.r26.s32, -2, ctx.xer);
	// beq cr6,0x82a79f18
	if (ctx.cr6.eq) goto loc_82A79F18;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// blt cr6,0x82a79f18
	if (ctx.cr6.lt) goto loc_82A79F18;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a79ef4
	if (ctx.cr6.eq) goto loc_82A79EF4;
	// cmpwi cr6,r26,-1
	ctx.cr6.compare<int32_t>(ctx.r26.s32, -1, ctx.xer);
	// bne cr6,0x82a79f1c
	if (!ctx.cr6.eq) goto loc_82A79F1C;
loc_82A79EF4:
	// li r11,1
	ctx.r11.s64 = 1;
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// stw r11,1580(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1580, ctx.r11.u32);
	// ble cr6,0x82a79f1c
	if (!ctx.cr6.gt) goto loc_82A79F1C;
loc_82A79F04:
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a79f04
	if (ctx.cr6.lt) goto loc_82A79F04;
	// stw r11,1580(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1580, ctx.r11.u32);
	// b 0x82a79f1c
	goto loc_82A79F1C;
loc_82A79F18:
	// stw r10,1580(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1580, ctx.r10.u32);
loc_82A79F1C:
	// lwz r19,1620(r1)
	ctx.r19.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1620);
	// cmpwi cr6,r19,-1
	ctx.cr6.compare<int32_t>(ctx.r19.s32, -1, ctx.xer);
	// bne cr6,0x82a79f30
	if (!ctx.cr6.eq) goto loc_82A79F30;
	// lis r19,8
	ctx.r19.s64 = 524288;
	// ori r19,r19,4
	ctx.r19.u64 = ctx.r19.u64 | 4;
loc_82A79F30:
	// lwz r14,1628(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1628);
	// cmpwi cr6,r14,-1
	ctx.cr6.compare<int32_t>(ctx.r14.s32, -1, ctx.xer);
	// bne cr6,0x82a79f40
	if (!ctx.cr6.eq) goto loc_82A79F40;
	// li r14,5
	ctx.r14.s64 = 5;
loc_82A79F40:
	// cmpwi cr6,r22,18
	ctx.cr6.compare<int32_t>(ctx.r22.s32, 18, ctx.xer);
	// bne cr6,0x82a79f50
	if (!ctx.cr6.eq) goto loc_82A79F50;
	// oris r19,r19,7
	ctx.r19.u64 = ctx.r19.u64 | 458752;
	// oris r14,r14,7
	ctx.r14.u64 = ctx.r14.u64 | 458752;
loc_82A79F50:
	// clrlwi r11,r19,24
	ctx.r11.u64 = ctx.r19.u32 & 0xFF;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82a79f74
	if (ctx.cr6.eq) goto loc_82A79F74;
	// clrlwi r11,r14,24
	ctx.r11.u64 = ctx.r14.u32 & 0xFF;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82a79f74
	if (ctx.cr6.eq) goto loc_82A79F74;
	// cmplwi cr6,r11,5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 5, ctx.xer);
	// mr r15,r16
	ctx.r15.u64 = ctx.r16.u64;
	// bne cr6,0x82a79f78
	if (!ctx.cr6.eq) goto loc_82A79F78;
loc_82A79F74:
	// li r15,1
	ctx.r15.s64 = 1;
loc_82A79F78:
	// lwz r11,168(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a79f90
	if (ctx.cr6.eq) goto loc_82A79F90;
	// lis r30,-32768
	ctx.r30.s64 = -2147483648;
	// ori r30,r30,16385
	ctx.r30.u64 = ctx.r30.u64 | 16385;
	// b 0x82a79d68
	goto loc_82A79D68;
loc_82A79F90:
	// li r5,1024
	ctx.r5.s64 = 1024;
	// li r4,255
	ctx.r4.s64 = 255;
	// addi r3,r1,336
	ctx.r3.s64 = ctx.r1.s64 + 336;
	// bl 0x82d5cb60
	ctx.lr = 0x82A79FA0;
	sub_82D5CB60(ctx, base);
	// lwz r11,1604(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1604);
	// lwz r21,1636(r1)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1636);
	// rlwinm r11,r11,0,26,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFE3F;
	// cmpwi cr6,r11,-449
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -449, ctx.xer);
	// bne cr6,0x82a7a064
	if (!ctx.cr6.eq) goto loc_82A7A064;
	// lwz r7,160(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x82a7a038
	if (ctx.cr6.eq) goto loc_82A7A038;
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82a78320
	ctx.lr = 0x82A79FC8;
	sub_82A78320(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a79fe8
	if (ctx.cr0.eq) goto loc_82A79FE8;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x82a79fe8
	if (ctx.cr6.eq) goto loc_82A79FE8;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82a7a038
	if (!ctx.cr6.eq) goto loc_82A7A038;
loc_82A79FE8:
	// lwz r11,16(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a7a038
	if (!ctx.cr6.eq) goto loc_82A7A038;
	// addi r3,r1,256
	ctx.r3.s64 = ctx.r1.s64 + 256;
	// li r5,36
	ctx.r5.s64 = 36;
	// bl 0x82d5c630
	ctx.lr = 0x82A7A000;
	sub_82D5C630(ctx, base);
	// li r11,-1
	ctx.r11.s64 = -1;
	// addi r6,r1,256
	ctx.r6.s64 = ctx.r1.s64 + 256;
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,256(r1)
	PPC_STORE_U32(ctx.r1.u32 + 256, ctx.r11.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, ctx.r11.u32);
	// bl 0x82a78398
	ctx.lr = 0x82A7A024;
	sub_82A78398(ctx, base);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// rlwinm r11,r7,0,26,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFFFFFFFE3F;
	// cmpwi cr6,r11,-449
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -449, ctx.xer);
	// bne cr6,0x82a7a038
	if (!ctx.cr6.eq) goto loc_82A7A038;
	// lwz r7,160(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
loc_82A7A038:
	// addis r11,r7,-13873
	ctx.r11.s64 = ctx.r7.s64 + -909180928;
	// addic. r11,r11,-19521
	ctx.xer.ca = ctx.r11.u32 > 19520;
	ctx.r11.s64 = ctx.r11.s64 + -19521;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a7a058
	if (ctx.cr0.eq) goto loc_82A7A058;
	// cmplwi cr6,r11,1503
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1503, ctx.xer);
	// bne cr6,0x82a7a060
	if (!ctx.cr6.eq) goto loc_82A7A060;
	// lis r7,10280
	ctx.r7.s64 = 673710080;
	// ori r7,r7,134
	ctx.r7.u64 = ctx.r7.u64 | 134;
	// b 0x82a7a060
	goto loc_82A7A060;
loc_82A7A058:
	// lis r7,2048
	ctx.r7.s64 = 134217728;
	// ori r7,r7,74
	ctx.r7.u64 = ctx.r7.u64 | 74;
loc_82A7A060:
	// stw r7,1604(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1604, ctx.r7.u32);
loc_82A7A064:
	// lwz r23,1652(r1)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1652);
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82a7a080
	if (ctx.cr6.eq) goto loc_82A7A080;
	// addi r4,r1,336
	ctx.r4.s64 = ctx.r1.s64 + 336;
	// li r5,1024
	ctx.r5.s64 = 1024;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82d5c630
	ctx.lr = 0x82A7A080;
	sub_82D5C630(ctx, base);
loc_82A7A080:
	// lwz r31,1612(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1612);
	// addi r9,r1,1604
	ctx.r9.s64 = ctx.r1.s64 + 1604;
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// addi r7,r1,1588
	ctx.r7.s64 = ctx.r1.s64 + 1588;
	// addi r6,r1,1580
	ctx.r6.s64 = ctx.r1.s64 + 1580;
	// addi r5,r1,1572
	ctx.r5.s64 = ctx.r1.s64 + 1572;
	// addi r4,r1,1564
	ctx.r4.s64 = ctx.r1.s64 + 1564;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82a79230
	ctx.lr = 0x82A7A0AC;
	sub_82A79230(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a79d68
	if (ctx.cr0.lt) goto loc_82A79D68;
	// lis r11,-32761
	ctx.r11.s64 = -2147024896;
	// lwz r20,1588(r1)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1588);
	// cmpwi cr6,r22,3
	ctx.cr6.compare<int32_t>(ctx.r22.s32, 3, ctx.xer);
	// ori r18,r11,14
	ctx.r18.u64 = ctx.r11.u64 | 14;
	// beq cr6,0x82a7a130
	if (ctx.cr6.eq) goto loc_82A7A130;
	// cmpwi cr6,r22,17
	ctx.cr6.compare<int32_t>(ctx.r22.s32, 17, ctx.xer);
	// beq cr6,0x82a7a11c
	if (ctx.cr6.eq) goto loc_82A7A11C;
	// cmpwi cr6,r22,18
	ctx.cr6.compare<int32_t>(ctx.r22.s32, 18, ctx.xer);
	// bne cr6,0x82a7a160
	if (!ctx.cr6.eq) goto loc_82A7A160;
	// lwz r4,1564(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1564);
	// li r10,18
	ctx.r10.s64 = 18;
	// li r5,6
	ctx.r5.s64 = 6;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
loc_82A7A0E8:
	// lwz r20,1588(r1)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1588);
	// mr r9,r31
	ctx.r9.u64 = ctx.r31.u64;
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// lwz r8,1604(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1604);
	// mr r6,r20
	ctx.r6.u64 = ctx.r20.u64;
	// bl 0x82a47380
	ctx.lr = 0x82A7A100;
	sub_82A47380(ctx, base);
	// mr. r17,r3
	ctx.r17.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r17.s32, 0, ctx.xer);
	// beq 0x82a7a110
	if (ctx.cr0.eq) goto loc_82A7A110;
loc_82A7A108:
	// mr r30,r16
	ctx.r30.u64 = ctx.r16.u64;
	// b 0x82a7a168
	goto loc_82A7A168;
loc_82A7A110:
	// lis r30,-32761
	ctx.r30.s64 = -2147024896;
	// ori r30,r30,14
	ctx.r30.u64 = ctx.r30.u64 | 14;
	// b 0x82a7a444
	goto loc_82A7A444;
loc_82A7A11C:
	// lwz r5,1580(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1580);
	// li r10,17
	ctx.r10.s64 = 17;
	// lwz r4,1572(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1572);
	// lwz r3,1564(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1564);
	// b 0x82a7a0e8
	goto loc_82A7A0E8;
loc_82A7A130:
	// li r10,3
	ctx.r10.s64 = 3;
	// lwz r8,1604(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1604);
	// mr r9,r31
	ctx.r9.u64 = ctx.r31.u64;
	// lwz r4,1572(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1572);
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// lwz r3,1564(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1564);
	// mr r6,r20
	ctx.r6.u64 = ctx.r20.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// bl 0x82a47380
	ctx.lr = 0x82A7A154;
	sub_82A47380(ctx, base);
	// mr. r17,r3
	ctx.r17.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r17.s32, 0, ctx.xer);
	// bne 0x82a7a108
	if (!ctx.cr0.eq) goto loc_82A7A108;
	// mr r30,r18
	ctx.r30.u64 = ctx.r18.u64;
loc_82A7A160:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt cr6,0x82a79d68
	if (ctx.cr6.lt) goto loc_82A79D68;
loc_82A7A168:
	// lwz r11,48(r17)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r17.u32 + 48);
	// addi r22,r1,160
	ctx.r22.s64 = ctx.r1.s64 + 160;
	// lwz r29,192(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// li r24,0
	ctx.r24.s64 = 0;
	// rlwinm r27,r11,21,31,31
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 21) & 0x1;
	// lwz r11,152(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// lwz r28,196(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// lwz r25,204(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7a3e0
	if (ctx.cr6.eq) goto loc_82A7A3E0;
loc_82A7A190:
	// lwz r11,148(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r26,0
	ctx.r26.s64 = 0;
	// mr r31,r22
	ctx.r31.u64 = ctx.r22.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7a30c
	if (ctx.cr6.eq) goto loc_82A7A30C;
loc_82A7A1A4:
	// cmplw cr6,r26,r20
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r20.u32, ctx.xer);
	// bge cr6,0x82a7a30c
	if (!ctx.cr6.lt) goto loc_82A7A30C;
	// lwz r11,1660(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82a7a2cc
	if (ctx.cr6.eq) goto loc_82A7A2CC;
	// cmpwi cr6,r11,17
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 17, ctx.xer);
	// beq cr6,0x82a7a26c
	if (ctx.cr6.eq) goto loc_82A7A26C;
	// cmpwi cr6,r11,18
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 18, ctx.xer);
	// bne cr6,0x82a7a2e4
	if (!ctx.cr6.eq) goto loc_82A7A2E4;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82a47200
	ctx.lr = 0x82A7A1D8;
	sub_82A47200(ctx, base);
	// mr. r16,r3
	ctx.r16.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r16.s32, 0, ctx.xer);
	// beq 0x82a7a4f8
	if (ctx.cr0.eq) goto loc_82A7A4F8;
loc_82A7A1E0:
	// addi r10,r31,24
	ctx.r10.s64 = ctx.r31.s64 + 24;
	// lwz r8,48(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r9,r1,336
	ctx.r9.s64 = ctx.r1.s64 + 336;
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// stw r21,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r21.u32);
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
	// stw r19,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r19.u32);
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r28.u32);
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r29.u32);
	// stw r27,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r27.u32);
	// bl 0x82a783f8
	ctx.lr = 0x82A7A218;
	sub_82A783F8(ctx, base);
loc_82A7A218:
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
loc_82A7A21C:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt cr6,0x82a7a424
	if (ctx.cr6.lt) goto loc_82A7A424;
	// lwz r11,144(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7a240
	if (ctx.cr6.eq) goto loc_82A7A240;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// bl 0x82a42570
	ctx.lr = 0x82A7A238;
	sub_82A42570(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r11.u32);
loc_82A7A240:
	// cmplwi cr6,r16,0
	ctx.cr6.compare<uint32_t>(ctx.r16.u32, 0, ctx.xer);
	// beq cr6,0x82a7a254
	if (ctx.cr6.eq) goto loc_82A7A254;
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
	// bl 0x82a42570
	ctx.lr = 0x82A7A250;
	sub_82A42570(ctx, base);
	// li r16,0
	ctx.r16.s64 = 0;
loc_82A7A254:
	// lwz r11,148(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// cmplw cr6,r26,r11
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82a7a30c
	if (!ctx.cr6.lt) goto loc_82A7A30C;
	// lwz r31,76(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// b 0x82a7a1a4
	goto loc_82A7A1A4;
loc_82A7A26C:
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82a472c8
	ctx.lr = 0x82A7A278;
	sub_82A472C8(ctx, base);
	// stw r3,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r3.u32);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7a4f8
	if (ctx.cr0.eq) goto loc_82A7A4F8;
loc_82A7A284:
	// addi r11,r31,24
	ctx.r11.s64 = ctx.r31.s64 + 24;
	// lwz r9,52(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// addi r10,r1,336
	ctx.r10.s64 = ctx.r1.s64 + 336;
	// lwz r8,48(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r3,144(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// stw r21,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r21.u32);
	// stw r19,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r19.u32);
	// stw r25,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r25.u32);
	// stw r28,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r28.u32);
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r29.u32);
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r27.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82a78a88
	ctx.lr = 0x82A7A2C8;
	sub_82A78A88(ctx, base);
	// b 0x82a7a218
	goto loc_82A7A218;
loc_82A7A2CC:
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82a47130
	ctx.lr = 0x82A7A2D8;
	sub_82A47130(ctx, base);
	// mr. r16,r3
	ctx.r16.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r16.s32, 0, ctx.xer);
	// bne 0x82a7a1e0
	if (!ctx.cr0.eq) goto loc_82A7A1E0;
	// mr r30,r18
	ctx.r30.u64 = ctx.r18.u64;
loc_82A7A2E4:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt cr6,0x82a7a424
	if (ctx.cr6.lt) goto loc_82A7A424;
	// lwz r11,1660(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82a7a1e0
	if (ctx.cr6.eq) goto loc_82A7A1E0;
	// cmpwi cr6,r11,17
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 17, ctx.xer);
	// beq cr6,0x82a7a284
	if (ctx.cr6.eq) goto loc_82A7A284;
	// cmpwi cr6,r11,18
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 18, ctx.xer);
	// beq cr6,0x82a7a1e0
	if (ctx.cr6.eq) goto loc_82A7A1E0;
	// b 0x82a7a21c
	goto loc_82A7A21C;
loc_82A7A30C:
	// cmpwi cr6,r15,0
	ctx.cr6.compare<int32_t>(ctx.r15.s32, 0, ctx.xer);
	// bne cr6,0x82a7a3cc
	if (!ctx.cr6.eq) goto loc_82A7A3CC;
	// b 0x82a7a3c4
	goto loc_82A7A3C4;
loc_82A7A318:
	// lwz r11,1660(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82a7a4b8
	if (ctx.cr6.eq) goto loc_82A7A4B8;
	// cmpwi cr6,r11,17
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 17, ctx.xer);
	// beq cr6,0x82a7a458
	if (ctx.cr6.eq) goto loc_82A7A458;
	// cmpwi cr6,r11,18
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 18, ctx.xer);
	// bne cr6,0x82a7a4d0
	if (!ctx.cr6.eq) goto loc_82A7A4D0;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82a47200
	ctx.lr = 0x82A7A344;
	sub_82A47200(ctx, base);
	// mr. r16,r3
	ctx.r16.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r16.s32, 0, ctx.xer);
	// beq 0x82a7a4f8
	if (ctx.cr0.eq) goto loc_82A7A4F8;
loc_82A7A34C:
	// addi r10,r31,24
	ctx.r10.s64 = ctx.r31.s64 + 24;
	// lwz r8,48(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r9,r1,336
	ctx.r9.s64 = ctx.r1.s64 + 336;
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// stw r21,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r21.u32);
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
	// stw r19,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r19.u32);
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r28.u32);
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r29.u32);
	// stw r27,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r27.u32);
	// bl 0x82a783f8
	ctx.lr = 0x82A7A384;
	sub_82A783F8(ctx, base);
loc_82A7A384:
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
loc_82A7A388:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt cr6,0x82a7a424
	if (ctx.cr6.lt) goto loc_82A7A424;
	// lwz r11,144(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7a3ac
	if (ctx.cr6.eq) goto loc_82A7A3AC;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// bl 0x82a42570
	ctx.lr = 0x82A7A3A4;
	sub_82A42570(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r11.u32);
loc_82A7A3AC:
	// cmplwi cr6,r16,0
	ctx.cr6.compare<uint32_t>(ctx.r16.u32, 0, ctx.xer);
	// beq cr6,0x82a7a3c0
	if (ctx.cr6.eq) goto loc_82A7A3C0;
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
	// bl 0x82a42570
	ctx.lr = 0x82A7A3BC;
	sub_82A42570(ctx, base);
	// li r16,0
	ctx.r16.s64 = 0;
loc_82A7A3C0:
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
loc_82A7A3C4:
	// cmplw cr6,r26,r20
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r20.u32, ctx.xer);
	// blt cr6,0x82a7a318
	if (ctx.cr6.lt) goto loc_82A7A318;
loc_82A7A3CC:
	// lwz r11,152(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// addi r24,r24,1
	ctx.r24.s64 = ctx.r24.s64 + 1;
	// lwz r22,80(r22)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r22.u32 + 80);
	// cmplw cr6,r24,r11
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a7a190
	if (ctx.cr6.lt) goto loc_82A7A190;
loc_82A7A3E0:
	// cmpwi cr6,r15,0
	ctx.cr6.compare<int32_t>(ctx.r15.s32, 0, ctx.xer);
	// beq cr6,0x82a7a414
	if (ctx.cr6.eq) goto loc_82A7A414;
	// lwz r11,148(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// cmplw cr6,r11,r20
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r20.u32, ctx.xer);
	// bge cr6,0x82a7a414
	if (!ctx.cr6.lt) goto loc_82A7A414;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// mr r6,r14
	ctx.r6.u64 = ctx.r14.u64;
	// addi r5,r11,-1
	ctx.r5.s64 = ctx.r11.s64 + -1;
	// addi r4,r1,336
	ctx.r4.s64 = ctx.r1.s64 + 336;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82a798a8
	ctx.lr = 0x82A7A40C;
	sub_82A798A8(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7a424
	if (ctx.cr0.lt) goto loc_82A7A424;
loc_82A7A414:
	// lwz r11,1668(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1668);
	// li r30,0
	ctx.r30.s64 = 0;
	// stw r17,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r17.u32);
	// li r17,0
	ctx.r17.s64 = 0;
loc_82A7A424:
	// lwz r3,144(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82a7a434
	if (ctx.cr6.eq) goto loc_82A7A434;
	// bl 0x82a42570
	ctx.lr = 0x82A7A434;
	sub_82A42570(ctx, base);
loc_82A7A434:
	// cmplwi cr6,r16,0
	ctx.cr6.compare<uint32_t>(ctx.r16.u32, 0, ctx.xer);
	// beq cr6,0x82a7a444
	if (ctx.cr6.eq) goto loc_82A7A444;
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
	// bl 0x82a42570
	ctx.lr = 0x82A7A444;
	sub_82A42570(ctx, base);
loc_82A7A444:
	// cmplwi cr6,r17,0
	ctx.cr6.compare<uint32_t>(ctx.r17.u32, 0, ctx.xer);
	// beq cr6,0x82a79d68
	if (ctx.cr6.eq) goto loc_82A79D68;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82a42570
	ctx.lr = 0x82A7A454;
	sub_82A42570(ctx, base);
	// b 0x82a79d68
	goto loc_82A79D68;
loc_82A7A458:
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82a472c8
	ctx.lr = 0x82A7A464;
	sub_82A472C8(ctx, base);
	// stw r3,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r3.u32);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7a4f8
	if (ctx.cr0.eq) goto loc_82A7A4F8;
loc_82A7A470:
	// addi r11,r31,24
	ctx.r11.s64 = ctx.r31.s64 + 24;
	// lwz r9,52(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// addi r10,r1,336
	ctx.r10.s64 = ctx.r1.s64 + 336;
	// lwz r8,48(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r3,144(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// stw r21,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r21.u32);
	// stw r19,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r19.u32);
	// stw r25,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r25.u32);
	// stw r28,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r28.u32);
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r29.u32);
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r27.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82a78a88
	ctx.lr = 0x82A7A4B4;
	sub_82A78A88(ctx, base);
	// b 0x82a7a384
	goto loc_82A7A384;
loc_82A7A4B8:
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82a47130
	ctx.lr = 0x82A7A4C4;
	sub_82A47130(ctx, base);
	// mr. r16,r3
	ctx.r16.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r16.s32, 0, ctx.xer);
	// bne 0x82a7a34c
	if (!ctx.cr0.eq) goto loc_82A7A34C;
	// mr r30,r18
	ctx.r30.u64 = ctx.r18.u64;
loc_82A7A4D0:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt cr6,0x82a7a424
	if (ctx.cr6.lt) goto loc_82A7A424;
	// lwz r11,1660(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82a7a34c
	if (ctx.cr6.eq) goto loc_82A7A34C;
	// cmpwi cr6,r11,17
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 17, ctx.xer);
	// beq cr6,0x82a7a470
	if (ctx.cr6.eq) goto loc_82A7A470;
	// cmpwi cr6,r11,18
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 18, ctx.xer);
	// beq cr6,0x82a7a34c
	if (ctx.cr6.eq) goto loc_82A7A34C;
	// b 0x82a7a388
	goto loc_82A7A388;
loc_82A7A4F8:
	// mr r30,r18
	ctx.r30.u64 = ctx.r18.u64;
	// b 0x82a7a424
	goto loc_82A7A424;
}

__attribute__((alias("__imp__sub_82A7A500"))) PPC_WEAK_FUNC(sub_82A7A500);
PPC_FUNC_IMPL(__imp__sub_82A7A500) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// lwz r10,308(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// li r31,3
	ctx.r31.s64 = 3;
	// lwz r30,284(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// stw r10,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r10.u32);
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// lwz r9,300(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	// stw r31,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r31.u32);
	// lwz r31,268(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	// stw r30,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r30.u32);
	// lwz r30,276(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// stw r9,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r9.u32);
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
	// lwz r8,292(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r31.u32);
	// lwz r31,260(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// stw r8,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r8.u32);
	// li r8,1
	ctx.r8.s64 = 1;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r31.u32);
	// bl 0x82a79cd8
	ctx.lr = 0x82A7A56C;
	sub_82A79CD8(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7A588"))) PPC_WEAK_FUNC(sub_82A7A588);
PPC_FUNC_IMPL(__imp__sub_82A7A588) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r8,-1
	ctx.r8.s64 = -1;
	// stw r6,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r6.u32);
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r7,r8
	ctx.r7.u64 = ctx.r8.u64;
	// mr r6,r8
	ctx.r6.u64 = ctx.r8.u64;
	// li r31,1
	ctx.r31.s64 = 1;
	// li r10,-1
	ctx.r10.s64 = -1;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r11.u32);
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// stw r7,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r7.u32);
	// stw r6,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r6.u32);
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// bl 0x82a7a500
	ctx.lr = 0x82A7A5D4;
	sub_82A7A500(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7A5E8"))) PPC_WEAK_FUNC(sub_82A7A5E8);
PPC_FUNC_IMPL(__imp__sub_82A7A5E8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82a850b0
	ctx.lr = 0x82A7A600;
	sub_82A850B0(ctx, base);
	// addi r3,r31,60
	ctx.r3.s64 = ctx.r31.s64 + 60;
	// bl 0x82aa7118
	ctx.lr = 0x82A7A608;
	sub_82AA7118(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,56(r31)
	PPC_STORE_U32(ctx.r31.u32 + 56, ctx.r11.u32);
	// stw r11,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r11.u32);
	// stw r11,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r11.u32);
	// stw r11,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r11.u32);
	// stw r11,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r11.u32);
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// stw r11,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7A640"))) PPC_WEAK_FUNC(sub_82A7A640);
PPC_FUNC_IMPL(__imp__sub_82A7A640) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82A7A648;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// li r26,0
	ctx.r26.s64 = 0;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A7A664:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82a7a664
	if (!ctx.cr6.eq) goto loc_82A7A664;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// rotlwi r28,r11,0
	ctx.r28.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// addi r30,r28,1
	ctx.r30.s64 = ctx.r28.s64 + 1;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82ab7070
	ctx.lr = 0x82A7A694;
	sub_82AB7070(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r3.u32);
	// beq 0x82a7a6bc
	if (ctx.cr0.eq) goto loc_82A7A6BC;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82ab7070
	ctx.lr = 0x82A7A6B0;
	sub_82AB7070(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r3.u32);
	// bne 0x82a7a6c8
	if (!ctx.cr0.eq) goto loc_82A7A6C8;
loc_82A7A6BC:
	// lis r26,-32761
	ctx.r26.s64 = -2147024896;
	// ori r26,r26,14
	ctx.r26.u64 = ctx.r26.u64 | 14;
	// b 0x82a7a714
	goto loc_82A7A714;
loc_82A7A6C8:
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// bl 0x82d5e188
	ctx.lr = 0x82A7A6D8;
	sub_82D5E188(ctx, base);
	// li r4,92
	ctx.r4.s64 = 92;
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// bl 0x82d62840
	ctx.lr = 0x82A7A6E4;
	sub_82D62840(ctx, base);
	// mr. r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq 0x82a7a6f0
	if (ctx.cr0.eq) goto loc_82A7A6F0;
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
loc_82A7A6F0:
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// stbx r26,r11,r28
	PPC_STORE_U8(ctx.r11.u32 + ctx.r28.u32, ctx.r26.u8);
	// lwz r4,80(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// lwz r3,76(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// bl 0x82d5c630
	ctx.lr = 0x82A7A708;
	sub_82D5C630(ctx, base);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82a7a714
	if (ctx.cr6.eq) goto loc_82A7A714;
	// stb r26,0(r29)
	PPC_STORE_U8(ctx.r29.u32 + 0, ctx.r26.u8);
loc_82A7A714:
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7A720"))) PPC_WEAK_FUNC(sub_82A7A720);
PPC_FUNC_IMPL(__imp__sub_82A7A720) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b0
	ctx.lr = 0x82A7A728;
	__savegprlr_22(ctx, base);
	// stwu r1,-704(r1)
	ea = -704 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r25,r6
	ctx.r25.u64 = ctx.r6.u64;
	// mr r23,r7
	ctx.r23.u64 = ctx.r7.u64;
	// mr r22,r8
	ctx.r22.u64 = ctx.r8.u64;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
	// stw r9,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r9.u32);
	// cmpwi cr6,r5,0
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// beq cr6,0x82a7a77c
	if (ctx.cr6.eq) goto loc_82A7A77C;
	// lis r3,0
	ctx.r3.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,260
	ctx.r8.s64 = 260;
	// addi r7,r1,352
	ctx.r7.s64 = ctx.r1.s64 + 352;
	// li r6,-1
	ctx.r6.s64 = -1;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// ori r3,r3,65001
	ctx.r3.u64 = ctx.r3.u64 | 65001;
	// bl 0x82a39bf8
	ctx.lr = 0x82A7A778;
	sub_82A39BF8(ctx, base);
	// addi r29,r1,352
	ctx.r29.s64 = ctx.r1.s64 + 352;
loc_82A7A77C:
	// lwz r11,72(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7a8b4
	if (ctx.cr6.eq) goto loc_82A7A8B4;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A7A790:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82a7a790
	if (!ctx.cr6.eq) goto loc_82A7A790;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// addi r30,r11,1
	ctx.r30.s64 = ctx.r11.s64 + 1;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82ab7070
	ctx.lr = 0x82A7A7C0;
	sub_82AB7070(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r3.u32);
	// bne 0x82a7a7d8
	if (!ctx.cr0.eq) goto loc_82A7A7D8;
loc_82A7A7CC:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82a7a924
	goto loc_82A7A924;
loc_82A7A7D8:
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82d5c630
	ctx.lr = 0x82A7A7E4;
	sub_82D5C630(ctx, base);
	// li r26,0
	ctx.r26.s64 = 0;
	// lwz r3,72(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// addi r27,r31,88
	ctx.r27.s64 = ctx.r31.s64 + 88;
	// addi r28,r31,84
	ctx.r28.s64 = ctx.r31.s64 + 84;
	// lwz r5,76(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r6,788(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	// li r10,260
	ctx.r10.s64 = 260;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// stb r26,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r26.u8);
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A7A824;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bge 0x82a7a84c
	if (!ctx.cr0.lt) goto loc_82A7A84C;
loc_82A7A82C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// addi r6,r11,-22480
	ctx.r6.s64 = ctx.r11.s64 + -22480;
	// li r5,1507
	ctx.r5.s64 = 1507;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82a85c20
	ctx.lr = 0x82A7A848;
	sub_82A85C20(ctx, base);
	// b 0x82a7a920
	goto loc_82A7A920;
loc_82A7A84C:
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a7a8fc
	if (ctx.cr0.eq) goto loc_82A7A8FC;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// stb r26,339(r1)
	PPC_STORE_U8(ctx.r1.u32 + 339, ctx.r26.u8);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A7A864:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82a7a864
	if (!ctx.cr6.eq) goto loc_82A7A864;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// addi r29,r11,1
	ctx.r29.s64 = ctx.r11.s64 + 1;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82ab7070
	ctx.lr = 0x82A7A894;
	sub_82AB7070(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq 0x82a7a7cc
	if (ctx.cr0.eq) goto loc_82A7A7CC;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82d5c630
	ctx.lr = 0x82A7A8AC;
	sub_82D5C630(ctx, base);
	// stw r30,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r30.u32);
	// b 0x82a7a8fc
	goto loc_82A7A8FC;
loc_82A7A8B4:
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7a640
	ctx.lr = 0x82A7A8C4;
	sub_82A7A640(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7a920
	if (ctx.cr0.lt) goto loc_82A7A920;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,76(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// addi r3,r31,60
	ctx.r3.s64 = ctx.r31.s64 + 60;
	// bl 0x82aa7130
	ctx.lr = 0x82A7A8DC;
	sub_82AA7130(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7a82c
	if (ctx.cr0.lt) goto loc_82A7A82C;
	// lwz r11,64(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// addi r28,r31,84
	ctx.r28.s64 = ctx.r31.s64 + 84;
	// lwz r10,68(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// addi r27,r31,88
	ctx.r27.s64 = ctx.r31.s64 + 88;
	// stw r11,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r11.u32);
	// stw r10,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r10.u32);
loc_82A7A8FC:
	// mr r9,r22
	ctx.r9.u64 = ctx.r22.u64;
	// lwz r6,76(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// lwz r5,0(r27)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r4,0(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a850d8
	ctx.lr = 0x82A7A91C;
	sub_82A850D8(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
loc_82A7A920:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
loc_82A7A924:
	// addi r1,r1,704
	ctx.r1.s64 = ctx.r1.s64 + 704;
	// b 0x82d5c500
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7A930"))) PPC_WEAK_FUNC(sub_82A7A930);
PPC_FUNC_IMPL(__imp__sub_82A7A930) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A7A938;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// mr r28,r8
	ctx.r28.u64 = ctx.r8.u64;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82a7a96c
	if (ctx.cr6.eq) goto loc_82A7A96C;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a7a96c
	if (!ctx.cr6.eq) goto loc_82A7A96C;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82a7a9ac
	goto loc_82A7A9AC;
loc_82A7A96C:
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// stw r11,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r11.u32);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// stw r6,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r6.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7a640
	ctx.lr = 0x82A7A984;
	sub_82A7A640(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7a9ac
	if (ctx.cr0.lt) goto loc_82A7A9AC;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// lwz r5,88(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// lwz r4,84(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a850d8
	ctx.lr = 0x82A7A9AC;
	sub_82A850D8(ctx, base);
loc_82A7A9AC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7A9B8"))) PPC_WEAK_FUNC(sub_82A7A9B8);
PPC_FUNC_IMPL(__imp__sub_82A7A9B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82abaf58
	ctx.lr = 0x82A7A9D4;
	sub_82ABAF58(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7a9f0
	if (ctx.cr0.lt) goto loc_82A7A9F0;
	// li r11,1
	ctx.r11.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,684(r31)
	PPC_STORE_U32(ctx.r31.u32 + 684, ctx.r11.u32);
	// bl 0x82ab7138
	ctx.lr = 0x82A7A9EC;
	sub_82AB7138(ctx, base);
	// stw r3,688(r31)
	PPC_STORE_U32(ctx.r31.u32 + 688, ctx.r3.u32);
loc_82A7A9F0:
	// stw r30,680(r31)
	PPC_STORE_U32(ctx.r31.u32 + 680, ctx.r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7AA10"))) PPC_WEAK_FUNC(sub_82A7AA10);
PPC_FUNC_IMPL(__imp__sub_82A7AA10) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,684(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 684);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a7aa44
	if (ctx.cr6.eq) goto loc_82A7AA44;
	// lwz r3,688(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 688);
	// bl 0x82ab7138
	ctx.lr = 0x82A7AA38;
	sub_82AB7138(ctx, base);
	// bl 0x82abb0a0
	ctx.lr = 0x82A7AA3C;
	sub_82ABB0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,684(r31)
	PPC_STORE_U32(ctx.r31.u32 + 684, ctx.r11.u32);
loc_82A7AA44:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7AA58"))) PPC_WEAK_FUNC(sub_82A7AA58);
PPC_FUNC_IMPL(__imp__sub_82A7AA58) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82a7aa6c
	if (ctx.cr6.eq) goto loc_82A7AA6C;
	// lwz r11,632(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 632);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
loc_82A7AA6C:
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82a7aa80
	if (ctx.cr6.eq) goto loc_82A7AA80;
	// lwz r11,632(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 632);
	// lwz r11,28(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r11.u32);
loc_82A7AA80:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7AA88"))) PPC_WEAK_FUNC(sub_82A7AA88);
PPC_FUNC_IMPL(__imp__sub_82A7AA88) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,628(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 628);
	// b 0x82a7aa94
	goto loc_82A7AA94;
loc_82A7AA90:
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
loc_82A7AA94:
	// lwz r10,92(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne 0x82a7aa90
	if (!ctx.cr0.eq) goto loc_82A7AA90;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82a7aab0
	if (ctx.cr6.eq) goto loc_82A7AAB0;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
loc_82A7AAB0:
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82a7aad4
	if (ctx.cr6.eq) goto loc_82A7AAD4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// bge cr6,0x82a7aad0
	if (!ctx.cr6.lt) goto loc_82A7AAD0;
	// li r11,0
	ctx.r11.s64 = 0;
loc_82A7AAD0:
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r11.u32);
loc_82A7AAD4:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7AAE0"))) PPC_WEAK_FUNC(sub_82A7AAE0);
PPC_FUNC_IMPL(__imp__sub_82A7AAE0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-368(r1)
	ea = -368 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,632(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 632);
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// bl 0x82a862c0
	ctx.lr = 0x82A7AB08;
	sub_82A862C0(ctx, base);
	// lwz r11,92(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 92);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a7ac2c
	if (ctx.cr6.eq) goto loc_82A7AC2C;
	// lwz r5,632(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 632);
	// lwz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// b 0x82a7ab44
	goto loc_82A7AB44;
loc_82A7AB20:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,32
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 32, ctx.xer);
	// beq cr6,0x82a7ab38
	if (ctx.cr6.eq) goto loc_82A7AB38;
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82a7ab4c
	if (!ctx.cr6.eq) goto loc_82A7AB4C;
loc_82A7AB38:
	// lwz r11,632(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 632);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
loc_82A7AB44:
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a7ab20
	if (ctx.cr6.lt) goto loc_82A7AB20;
loc_82A7AB4C:
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r10,r31,2
	ctx.r10.s64 = ctx.r31.s64 + 2;
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
loc_82A7AB58:
	// lwz r9,0(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmplw cr6,r31,r9
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82a7abf8
	if (!ctx.cr6.lt) goto loc_82A7ABF8;
	// lbz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// extsb r6,r7
	ctx.r6.s64 = ctx.r7.s8;
	// cmpwi cr6,r6,92
	ctx.cr6.compare<int32_t>(ctx.r6.s32, 92, ctx.xer);
	// bne cr6,0x82a7abd0
	if (!ctx.cr6.eq) goto loc_82A7ABD0;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82a7ab98
	if (!ctx.cr6.lt) goto loc_82A7AB98;
	// lbz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r4,10
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 10, ctx.xer);
	// bne cr6,0x82a7ab98
	if (!ctx.cr6.eq) goto loc_82A7AB98;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82a7abf0
	goto loc_82A7ABF0;
loc_82A7AB98:
	// cmpwi cr6,r6,92
	ctx.cr6.compare<int32_t>(ctx.r6.s32, 92, ctx.xer);
	// bne cr6,0x82a7abd0
	if (!ctx.cr6.eq) goto loc_82A7ABD0;
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82a7abd0
	if (!ctx.cr6.lt) goto loc_82A7ABD0;
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r9,13
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 13, ctx.xer);
	// bne cr6,0x82a7abd0
	if (!ctx.cr6.eq) goto loc_82A7ABD0;
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 10, ctx.xer);
	// bne cr6,0x82a7abd0
	if (!ctx.cr6.eq) goto loc_82A7ABD0;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82a7abf0
	goto loc_82A7ABF0;
loc_82A7ABD0:
	// cmpwi cr6,r6,13
	ctx.cr6.compare<int32_t>(ctx.r6.s32, 13, ctx.xer);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// beq cr6,0x82a7abf0
	if (ctx.cr6.eq) goto loc_82A7ABF0;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// stbx r7,r8,r9
	PPC_STORE_U8(ctx.r8.u32 + ctx.r9.u32, ctx.r7.u8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
loc_82A7ABF0:
	// cmplwi cr6,r8,255
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 255, ctx.xer);
	// blt cr6,0x82a7ab58
	if (ctx.cr6.lt) goto loc_82A7AB58;
loc_82A7ABF8:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r6,r11,-22444
	ctx.r6.s64 = ctx.r11.s64 + -22444;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r30,640
	ctx.r4.s64 = ctx.r30.s64 + 640;
	// addi r3,r30,24
	ctx.r3.s64 = ctx.r30.s64 + 24;
	// stbx r11,r8,r10
	PPC_STORE_U8(ctx.r8.u32 + ctx.r10.u32, ctx.r11.u8);
	// bl 0x82a85c20
	ctx.lr = 0x82A7AC20;
	sub_82A85C20(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,84(r30)
	PPC_STORE_U32(ctx.r30.u32 + 84, ctx.r11.u32);
	// stw r11,80(r30)
	PPC_STORE_U32(ctx.r30.u32 + 80, ctx.r11.u32);
loc_82A7AC2C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7AC48"))) PPC_WEAK_FUNC(sub_82A7AC48);
PPC_FUNC_IMPL(__imp__sub_82A7AC48) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne 0x82a7ac98
	if (!ctx.cr0.eq) goto loc_82A7AC98;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1508
	ctx.r5.s64 = 1508;
	// addi r6,r11,-22396
	ctx.r6.s64 = ctx.r11.s64 + -22396;
loc_82A7AC78:
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82a85c20
	ctx.lr = 0x82A7AC84;
	sub_82A85C20(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// b 0x82a7acf4
	goto loc_82A7ACF4;
loc_82A7AC98:
	// lwz r11,8(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a7acb4
	if (ctx.cr6.eq) goto loc_82A7ACB4;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1513
	ctx.r5.s64 = 1513;
	// addi r6,r11,-22432
	ctx.r6.s64 = ctx.r11.s64 + -22432;
	// b 0x82a7ac78
	goto loc_82A7AC78;
loc_82A7ACB4:
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beq cr6,0x82a7acd8
	if (ctx.cr6.eq) goto loc_82A7ACD8;
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a7acd8
	if (!ctx.cr6.eq) goto loc_82A7ACD8;
	// lwz r11,4(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// bne cr6,0x82a7acdc
	if (!ctx.cr6.eq) goto loc_82A7ACDC;
loc_82A7ACD8:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82A7ACDC:
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// stw r11,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r11.u32);
	// beq cr6,0x82a7acf0
	if (ctx.cr6.eq) goto loc_82A7ACF0;
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r11.u32);
loc_82A7ACF0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A7ACF4:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7AD08"))) PPC_WEAK_FUNC(sub_82A7AD08);
PPC_FUNC_IMPL(__imp__sub_82A7AD08) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r11,56(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82a7ad58
	if (!ctx.cr0.eq) goto loc_82A7AD58;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1509
	ctx.r5.s64 = 1509;
	// addi r6,r11,-22340
	ctx.r6.s64 = ctx.r11.s64 + -22340;
loc_82A7AD38:
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82a85c20
	ctx.lr = 0x82A7AD44;
	sub_82A85C20(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// b 0x82a7ada8
	goto loc_82A7ADA8;
loc_82A7AD58:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82a7ad74
	if (ctx.cr6.eq) goto loc_82A7AD74;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1514
	ctx.r5.s64 = 1514;
	// addi r6,r11,-22376
	ctx.r6.s64 = ctx.r11.s64 + -22376;
	// b 0x82a7ad38
	goto loc_82A7AD38;
loc_82A7AD74:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// li r9,1
	ctx.r9.s64 = 1;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82a7ad94
	if (!ctx.cr6.eq) goto loc_82A7AD94;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// bne cr6,0x82a7ad98
	if (!ctx.cr6.eq) goto loc_82A7AD98;
loc_82A7AD94:
	// li r10,0
	ctx.r10.s64 = 0;
loc_82A7AD98:
	// stw r10,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
loc_82A7ADA8:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7ADC0"))) PPC_WEAK_FUNC(sub_82A7ADC0);
PPC_FUNC_IMPL(__imp__sub_82A7ADC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c4
	ctx.lr = 0x82A7ADC8;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// addi r30,r28,640
	ctx.r30.s64 = ctx.r28.s64 + 640;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r4,672(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 672);
	// lwz r3,632(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7ADE4;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7afa8
	if (ctx.cr0.lt) goto loc_82A7AFA8;
	// lwz r7,0(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r27,0
	ctx.r27.s64 = 0;
	// cmpwi cr6,r7,1
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 1, ctx.xer);
	// bne cr6,0x82a7af84
	if (!ctx.cr6.eq) goto loc_82A7AF84;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r31,r28,648
	ctx.r31.s64 = ctx.r28.s64 + 648;
	// addi r10,r11,23068
	ctx.r10.s64 = ctx.r11.s64 + 23068;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82A7AE0C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7ae30
	if (ctx.cr0.eq) goto loc_82A7AE30;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7ae0c
	if (ctx.cr6.eq) goto loc_82A7AE0C;
loc_82A7AE30:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7af84
	if (!ctx.cr0.eq) goto loc_82A7AF84;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r4,672(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 672);
	// lwz r3,632(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7AE48;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7afa8
	if (ctx.cr0.lt) goto loc_82A7AFA8;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82a7ae7c
	if (!ctx.cr6.eq) goto loc_82A7AE7C;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r29,0(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r4,672(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 672);
	// lwz r3,632(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7AE70;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7afa8
	if (ctx.cr0.lt) goto loc_82A7AFA8;
	// b 0x82a7ae80
	goto loc_82A7AE80;
loc_82A7AE7C:
	// mr r29,r27
	ctx.r29.u64 = ctx.r27.u64;
loc_82A7AE80:
	// lwz r7,0(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpwi cr6,r7,1
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 1, ctx.xer);
	// bne cr6,0x82a7af84
	if (!ctx.cr6.eq) goto loc_82A7AF84;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r10,r11,17360
	ctx.r10.s64 = ctx.r11.s64 + 17360;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82A7AE98:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7aebc
	if (ctx.cr0.eq) goto loc_82A7AEBC;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7ae98
	if (ctx.cr6.eq) goto loc_82A7AE98;
loc_82A7AEBC:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7af84
	if (!ctx.cr0.eq) goto loc_82A7AF84;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r4,672(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 672);
	// lwz r3,632(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7AED4;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7afa8
	if (ctx.cr0.lt) goto loc_82A7AFA8;
	// lwz r7,0(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpwi cr6,r7,12
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 12, ctx.xer);
	// beq cr6,0x82a7aef0
	if (ctx.cr6.eq) goto loc_82A7AEF0;
	// cmpwi cr6,r7,13
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 13, ctx.xer);
	// bne cr6,0x82a7af84
	if (!ctx.cr6.eq) goto loc_82A7AF84;
loc_82A7AEF0:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82a7af00
	if (!ctx.cr6.eq) goto loc_82A7AF00;
	// stw r27,60(r28)
	PPC_STORE_U32(ctx.r28.u32 + 60, ctx.r27.u32);
	// b 0x82a7afa4
	goto loc_82A7AFA4;
loc_82A7AF00:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r11,-22304
	ctx.r10.s64 = ctx.r11.s64 + -22304;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
loc_82A7AF0C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7af30
	if (ctx.cr0.eq) goto loc_82A7AF30;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7af0c
	if (ctx.cr6.eq) goto loc_82A7AF0C;
loc_82A7AF30:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7af40
	if (!ctx.cr0.eq) goto loc_82A7AF40;
	// li r11,1024
	ctx.r11.s64 = 1024;
	// b 0x82a7af7c
	goto loc_82A7AF7C;
loc_82A7AF40:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r11,-22320
	ctx.r10.s64 = ctx.r11.s64 + -22320;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
loc_82A7AF4C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7af70
	if (ctx.cr0.eq) goto loc_82A7AF70;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7af4c
	if (ctx.cr6.eq) goto loc_82A7AF4C;
loc_82A7AF70:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7af84
	if (!ctx.cr0.eq) goto loc_82A7AF84;
	// li r11,2048
	ctx.r11.s64 = 2048;
loc_82A7AF7C:
	// stw r11,60(r28)
	PPC_STORE_U32(ctx.r28.u32 + 60, ctx.r11.u32);
	// b 0x82a7afa4
	goto loc_82A7AFA4;
loc_82A7AF84:
	// cmpwi cr6,r7,12
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 12, ctx.xer);
	// beq cr6,0x82a7afa0
	if (ctx.cr6.eq) goto loc_82A7AFA0;
	// cmpwi cr6,r7,13
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 13, ctx.xer);
	// beq cr6,0x82a7afa0
	if (ctx.cr6.eq) goto loc_82A7AFA0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,632(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 632);
	// bl 0x82a862c0
	ctx.lr = 0x82A7AFA0;
	sub_82A862C0(ctx, base);
loc_82A7AFA0:
	// stw r27,668(r28)
	PPC_STORE_U32(ctx.r28.u32 + 668, ctx.r27.u32);
loc_82A7AFA4:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
loc_82A7AFA8:
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,76(r28)
	PPC_STORE_U32(ctx.r28.u32 + 76, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c514
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7AFB8"))) PPC_WEAK_FUNC(sub_82A7AFB8);
PPC_FUNC_IMPL(__imp__sub_82A7AFB8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82A7AFC0;
	__savegprlr_14(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// li r25,0
	ctx.r25.s64 = 0;
	// addi r24,r26,640
	ctx.r24.s64 = ctx.r26.s64 + 640;
	// mr r14,r25
	ctx.r14.u64 = ctx.r25.u64;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// lwz r4,672(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 672);
	// lwz r3,632(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 632);
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r25.u32);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7AFE8;
	sub_82A86ED8(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt 0x82a7b48c
	if (ctx.cr0.lt) goto loc_82A7B48C;
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82a7b464
	if (!ctx.cr6.eq) goto loc_82A7B464;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r27,r26,648
	ctx.r27.s64 = ctx.r26.s64 + 648;
	// addi r10,r11,23068
	ctx.r10.s64 = ctx.r11.s64 + 23068;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
loc_82A7B00C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7b030
	if (ctx.cr0.eq) goto loc_82A7B030;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b00c
	if (ctx.cr6.eq) goto loc_82A7B00C;
loc_82A7B030:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7b464
	if (!ctx.cr0.eq) goto loc_82A7B464;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// lwz r4,672(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 672);
	// lwz r3,632(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7B048;
	sub_82A86ED8(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt 0x82a7b48c
	if (ctx.cr0.lt) goto loc_82A7B48C;
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// li r15,-1
	ctx.r15.s64 = -1;
	// addi r22,r11,9236
	ctx.r22.s64 = ctx.r11.s64 + 9236;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r20,r11,344
	ctx.r20.s64 = ctx.r11.s64 + 344;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r19,r11,-22268
	ctx.r19.s64 = ctx.r11.s64 + -22268;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r18,r11,-22276
	ctx.r18.s64 = ctx.r11.s64 + -22276;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r17,r11,-22284
	ctx.r17.s64 = ctx.r11.s64 + -22284;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r21,r11,-22292
	ctx.r21.s64 = ctx.r11.s64 + -22292;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r23,r11,17360
	ctx.r23.s64 = ctx.r11.s64 + 17360;
	// lis r11,16383
	ctx.r11.s64 = 1073676288;
	// ori r16,r11,65535
	ctx.r16.u64 = ctx.r11.u64 | 65535;
loc_82A7B094:
	// lwz r7,0(r24)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmpwi cr6,r7,1
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 1, ctx.xer);
	// bne cr6,0x82a7b0d4
	if (!ctx.cr6.eq) goto loc_82A7B0D4;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
loc_82A7B0A8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7b0cc
	if (ctx.cr0.eq) goto loc_82A7B0CC;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b0a8
	if (ctx.cr6.eq) goto loc_82A7B0A8;
loc_82A7B0CC:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a7b4b8
	if (ctx.cr0.eq) goto loc_82A7B4B8;
loc_82A7B0D4:
	// cmpwi cr6,r7,9
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 9, ctx.xer);
	// bne cr6,0x82a7b1d0
	if (!ctx.cr6.eq) goto loc_82A7B1D0;
	// lwz r7,0(r27)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// mr r10,r21
	ctx.r10.u64 = ctx.r21.u64;
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_82A7B0E8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7b10c
	if (ctx.cr0.eq) goto loc_82A7B10C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b0e8
	if (ctx.cr6.eq) goto loc_82A7B0E8;
loc_82A7B10C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7b11c
	if (!ctx.cr0.eq) goto loc_82A7B11C;
	// li r28,16
	ctx.r28.s64 = 16;
	// b 0x82a7b200
	goto loc_82A7B200;
loc_82A7B11C:
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
	// mr r10,r17
	ctx.r10.u64 = ctx.r17.u64;
loc_82A7B124:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7b148
	if (ctx.cr0.eq) goto loc_82A7B148;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b124
	if (ctx.cr6.eq) goto loc_82A7B124;
loc_82A7B148:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7b158
	if (!ctx.cr0.eq) goto loc_82A7B158;
	// li r28,15
	ctx.r28.s64 = 15;
	// b 0x82a7b200
	goto loc_82A7B200;
loc_82A7B158:
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
	// mr r10,r18
	ctx.r10.u64 = ctx.r18.u64;
loc_82A7B160:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7b184
	if (ctx.cr0.eq) goto loc_82A7B184;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b160
	if (ctx.cr6.eq) goto loc_82A7B160;
loc_82A7B184:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7b194
	if (!ctx.cr0.eq) goto loc_82A7B194;
	// li r28,0
	ctx.r28.s64 = 0;
	// b 0x82a7b200
	goto loc_82A7B200;
loc_82A7B194:
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
	// mr r10,r19
	ctx.r10.u64 = ctx.r19.u64;
loc_82A7B19C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7b1c0
	if (ctx.cr0.eq) goto loc_82A7B1C0;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b19c
	if (ctx.cr6.eq) goto loc_82A7B19C;
loc_82A7B1C0:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7b464
	if (!ctx.cr0.eq) goto loc_82A7B464;
	// li r28,255
	ctx.r28.s64 = 255;
	// b 0x82a7b200
	goto loc_82A7B200;
loc_82A7B1D0:
	// cmpwi cr6,r7,2
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 2, ctx.xer);
	// beq cr6,0x82a7b1e8
	if (ctx.cr6.eq) goto loc_82A7B1E8;
	// cmpwi cr6,r7,3
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 3, ctx.xer);
	// beq cr6,0x82a7b1e8
	if (ctx.cr6.eq) goto loc_82A7B1E8;
	// cmpwi cr6,r7,4
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 4, ctx.xer);
	// bne cr6,0x82a7b464
	if (!ctx.cr6.eq) goto loc_82A7B464;
loc_82A7B1E8:
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82a7b464
	if (ctx.cr6.lt) goto loc_82A7B464;
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// bgt cr6,0x82a7b464
	if (ctx.cr6.gt) goto loc_82A7B464;
	// mr r28,r11
	ctx.r28.u64 = ctx.r11.u64;
loc_82A7B200:
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// lwz r4,672(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 672);
	// lwz r3,632(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7B210;
	sub_82A86ED8(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt 0x82a7b48c
	if (ctx.cr0.lt) goto loc_82A7B48C;
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82a7b464
	if (!ctx.cr6.eq) goto loc_82A7B464;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// mr r10,r20
	ctx.r10.u64 = ctx.r20.u64;
loc_82A7B22C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7b250
	if (ctx.cr0.eq) goto loc_82A7B250;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b22c
	if (ctx.cr6.eq) goto loc_82A7B22C;
loc_82A7B250:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7b464
	if (!ctx.cr0.eq) goto loc_82A7B464;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// lwz r4,672(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 672);
	// lwz r3,632(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7B268;
	sub_82A86ED8(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt 0x82a7b48c
	if (ctx.cr0.lt) goto loc_82A7B48C;
loc_82A7B270:
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82a7b28c
	if (ctx.cr6.eq) goto loc_82A7B28C;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82a7b28c
	if (ctx.cr6.eq) goto loc_82A7B28C;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bne cr6,0x82a7b464
	if (!ctx.cr6.eq) goto loc_82A7B464;
loc_82A7B28C:
	// not r11,r25
	ctx.r11.u64 = ~ctx.r25.u64;
	// lwz r29,0(r27)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// and r11,r11,r25
	ctx.r11.u64 = ctx.r11.u64 & ctx.r25.u64;
	// cmplw cr6,r25,r11
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82a7b338
	if (!ctx.cr6.eq) goto loc_82A7B338;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// rlwinm r11,r25,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r25.u32 | (ctx.r25.u64 << 32), 1) & 0xFFFFFFFE;
	// bne cr6,0x82a7b2b4
	if (!ctx.cr6.eq) goto loc_82A7B2B4;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82A7B2B4:
	// cmplw cr6,r11,r16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r16.u32, ctx.xer);
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// ble cr6,0x82a7b2c4
	if (!ctx.cr6.gt) goto loc_82A7B2C4;
	// mr r3,r15
	ctx.r3.u64 = ctx.r15.u64;
loc_82A7B2C4:
	// bl 0x8247d8e0
	ctx.lr = 0x82A7B2C8;
	sub_8247D8E0(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// beq 0x82a7b530
	if (ctx.cr0.eq) goto loc_82A7B530;
	// rlwinm r30,r25,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r25.u32 | (ctx.r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82d5c630
	ctx.lr = 0x82A7B2E4;
	sub_82D5C630(ctx, base);
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x8247d948
	ctx.lr = 0x82A7B2EC;
	sub_8247D948(ctx, base);
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r31.u32);
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// rlwinm r11,r25,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r25.u32 | (ctx.r25.u64 << 32), 1) & 0xFFFFFFFE;
	// bne cr6,0x82a7b300
	if (!ctx.cr6.eq) goto loc_82A7B300;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82A7B300:
	// cmplw cr6,r11,r16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r16.u32, ctx.xer);
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// ble cr6,0x82a7b310
	if (!ctx.cr6.gt) goto loc_82A7B310;
	// mr r3,r15
	ctx.r3.u64 = ctx.r15.u64;
loc_82A7B310:
	// bl 0x8247d8e0
	ctx.lr = 0x82A7B314;
	sub_8247D8E0(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// beq 0x82a7b530
	if (ctx.cr0.eq) goto loc_82A7B530;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r14
	ctx.r4.u64 = ctx.r14.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d5c630
	ctx.lr = 0x82A7B32C;
	sub_82D5C630(ctx, base);
	// mr r3,r14
	ctx.r3.u64 = ctx.r14.u64;
	// bl 0x8247d948
	ctx.lr = 0x82A7B334;
	sub_8247D948(ctx, base);
	// mr r14,r31
	ctx.r14.u64 = ctx.r31.u64;
loc_82A7B338:
	// rlwinm r11,r25,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r25.u32 | (ctx.r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// stwx r29,r11,r14
	PPC_STORE_U32(ctx.r11.u32 + ctx.r14.u32, ctx.r29.u32);
	// stwx r28,r11,r10
	PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, ctx.r28.u32);
	// lwz r4,672(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 672);
	// lwz r3,632(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7B35C;
	sub_82A86ED8(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt 0x82a7b48c
	if (ctx.cr0.lt) goto loc_82A7B48C;
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82a7b270
	if (!ctx.cr6.eq) goto loc_82A7B270;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// mr r10,r22
	ctx.r10.u64 = ctx.r22.u64;
loc_82A7B378:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7b39c
	if (ctx.cr0.eq) goto loc_82A7B39C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b378
	if (ctx.cr6.eq) goto loc_82A7B378;
loc_82A7B39C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a7b3d8
	if (ctx.cr0.eq) goto loc_82A7B3D8;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
loc_82A7B3AC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7b3d0
	if (ctx.cr0.eq) goto loc_82A7B3D0;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b3ac
	if (ctx.cr6.eq) goto loc_82A7B3AC;
loc_82A7B3D0:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7b270
	if (!ctx.cr0.eq) goto loc_82A7B270;
loc_82A7B3D8:
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// mr r10,r22
	ctx.r10.u64 = ctx.r22.u64;
loc_82A7B3E0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7b404
	if (ctx.cr0.eq) goto loc_82A7B404;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b3e0
	if (ctx.cr6.eq) goto loc_82A7B3E0;
loc_82A7B404:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7b094
	if (!ctx.cr0.eq) goto loc_82A7B094;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// lwz r4,672(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 672);
	// lwz r3,632(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7B41C;
	sub_82A86ED8(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt 0x82a7b48c
	if (ctx.cr0.lt) goto loc_82A7B48C;
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82a7b094
	if (!ctx.cr6.eq) goto loc_82A7B094;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
loc_82A7B438:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7b45c
	if (ctx.cr0.eq) goto loc_82A7B45C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b438
	if (ctx.cr6.eq) goto loc_82A7B438;
loc_82A7B45C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7b094
	if (!ctx.cr0.eq) goto loc_82A7B094;
loc_82A7B464:
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82a7b484
	if (ctx.cr6.eq) goto loc_82A7B484;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82a7b484
	if (ctx.cr6.eq) goto loc_82A7B484;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,632(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 632);
	// bl 0x82a862c0
	ctx.lr = 0x82A7B484;
	sub_82A862C0(ctx, base);
loc_82A7B484:
	// li r31,0
	ctx.r31.s64 = 0;
	// stw r31,668(r26)
	PPC_STORE_U32(ctx.r26.u32 + 668, ctx.r31.u32);
loc_82A7B48C:
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x8247d948
	ctx.lr = 0x82A7B494;
	sub_8247D948(ctx, base);
	// mr r3,r14
	ctx.r3.u64 = ctx.r14.u64;
	// bl 0x8247d948
	ctx.lr = 0x82A7B49C;
	sub_8247D948(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8247d948
	ctx.lr = 0x82A7B4A4;
	sub_8247D948(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,76(r26)
	PPC_STORE_U32(ctx.r26.u32 + 76, ctx.r11.u32);
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
loc_82A7B4B8:
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// lwz r4,672(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 672);
	// lwz r3,632(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7B4C8;
	sub_82A86ED8(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt 0x82a7b48c
	if (ctx.cr0.lt) goto loc_82A7B48C;
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82a7b4e4
	if (ctx.cr6.eq) goto loc_82A7B4E4;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// bne cr6,0x82a7b464
	if (!ctx.cr6.eq) goto loc_82A7B464;
loc_82A7B4E4:
	// li r27,0
	ctx.r27.s64 = 0;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x82a7b528
	if (ctx.cr6.eq) goto loc_82A7B528;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r29,r26,24
	ctx.r29.s64 = ctx.r26.s64 + 24;
	// mr r30,r14
	ctx.r30.u64 = ctx.r14.u64;
	// subf r28,r14,r11
	ctx.r28.s64 = ctx.r11.s64 - ctx.r14.s64;
loc_82A7B500:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwzx r5,r28,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r30.u32);
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82a85b70
	ctx.lr = 0x82A7B510;
	sub_82A85B70(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt 0x82a7b48c
	if (ctx.cr0.lt) goto loc_82A7B48C;
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplw cr6,r27,r25
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r25.u32, ctx.xer);
	// blt cr6,0x82a7b500
	if (ctx.cr6.lt) goto loc_82A7B500;
loc_82A7B528:
	// li r31,0
	ctx.r31.s64 = 0;
	// b 0x82a7b48c
	goto loc_82A7B48C;
loc_82A7B530:
	// lis r31,-32761
	ctx.r31.s64 = -2147024896;
	// ori r31,r31,14
	ctx.r31.u64 = ctx.r31.u64 | 14;
	// b 0x82a7b48c
	goto loc_82A7B48C;
}

__attribute__((alias("__imp__sub_82A7B540"))) PPC_WEAK_FUNC(sub_82A7B540);
PPC_FUNC_IMPL(__imp__sub_82A7B540) {
	PPC_FUNC_PROLOGUE();
	// lis r10,1586
	ctx.r10.s64 = 103940096;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// ori r10,r10,55311
	ctx.r10.u64 = ctx.r10.u64 | 55311;
	// beq cr6,0x82a7b588
	if (ctx.cr6.eq) goto loc_82A7B588;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb. r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a7b588
	if (ctx.cr0.eq) goto loc_82A7B588;
loc_82A7B55C:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// mulli r10,r10,19
	ctx.r10.s64 = ctx.r10.s64 * 19;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb. r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a7b55c
	if (!ctx.cr0.eq) goto loc_82A7B55C;
	// li r11,127
	ctx.r11.s64 = 127;
	// divwu r11,r10,r11
	ctx.r11.u32 = ctx.r10.u32 / ctx.r11.u32;
	// mulli r11,r11,127
	ctx.r11.s64 = ctx.r11.s64 * 127;
	// subf r3,r11,r10
	ctx.r3.s64 = ctx.r10.s64 - ctx.r11.s64;
	// blr 
	return;
loc_82A7B588:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7B590"))) PPC_WEAK_FUNC(sub_82A7B590);
PPC_FUNC_IMPL(__imp__sub_82A7B590) {
	PPC_FUNC_PROLOGUE();
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A7B598;
	__savegprlr_29(ctx, base);
	// lwz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
loc_82A7B5A0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7b5c4
	if (ctx.cr0.eq) goto loc_82A7B5C4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b5a0
	if (ctx.cr6.eq) goto loc_82A7B5A0;
loc_82A7B5C4:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7b6c8
	if (!ctx.cr0.eq) goto loc_82A7B6C8;
	// lwz r30,4(r4)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// lwz r29,4(r5)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
	// mr. r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a7b600
	if (ctx.cr0.eq) goto loc_82A7B600;
loc_82A7B5E0:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a7b5f8
	if (ctx.cr6.eq) goto loc_82A7B5F8;
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82a7b5e0
	if (!ctx.cr0.eq) goto loc_82A7B5E0;
loc_82A7B5F8:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a7b6c8
	if (!ctx.cr6.eq) goto loc_82A7B6C8;
loc_82A7B600:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82a7b6c8
	if (!ctx.cr6.eq) goto loc_82A7B6C8;
	// lwz r3,8(r4)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r31,8(r5)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// b 0x82a7b824
	goto loc_82A7B824;
loc_82A7B614:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82a7b6b4
	if (ctx.cr6.eq) goto loc_82A7B6B4;
	// lwz r11,16(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82a7b6b4
	if (!ctx.cr6.eq) goto loc_82A7B6B4;
	// cmplwi cr6,r11,11
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 11, ctx.xer);
	// bgt cr6,0x82a7b810
	if (ctx.cr6.gt) goto loc_82A7B810;
	// lis r12,-32239
	ctx.r12.s64 = -2112815104;
	// addi r12,r12,-22640
	ctx.r12.s64 = ctx.r12.s64 + -22640;
	// lbzx r0,r12,r11
	ctx.r0.u64 = PPC_LOAD_U8(ctx.r12.u32 + ctx.r11.u32);
	// rlwinm r0,r0,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r0.u32 | (ctx.r0.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r12,-32088
	ctx.r12.s64 = -2102919168;
	// addi r12,r12,-18852
	ctx.r12.s64 = ctx.r12.s64 + -18852;
	// add r12,r12,r0
	ctx.r12.u64 = ctx.r12.u64 + ctx.r0.u64;
	// mtctr r12
	ctx.ctr.u64 = ctx.r12.u64;
	// nop 
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82A7B65C;
	case 1:
		goto loc_82A7B674;
	case 2:
		goto loc_82A7B65C;
	case 3:
		goto loc_82A7B65C;
	case 4:
		goto loc_82A7B65C;
	case 5:
		goto loc_82A7B6D0;
	case 6:
		goto loc_82A7B6D0;
	case 7:
		goto loc_82A7B6D0;
	case 8:
		goto loc_82A7B6D0;
	case 9:
		goto loc_82A7B6E0;
	case 10:
		goto loc_82A7B7E0;
	case 11:
		goto loc_82A7B7E0;
	default:
		__builtin_unreachable();
	}
loc_82A7B65C:
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
loc_82A7B668:
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
loc_82A7B66C:
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// b 0x82a7b814
	goto loc_82A7B814;
loc_82A7B674:
	// lbz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 24);
	// lbz r10,24(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 24);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82a7b6b4
	if (!ctx.cr6.eq) goto loc_82A7B6B4;
	// lbz r11,25(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 25);
	// lbz r10,25(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 25);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82a7b6b4
	if (!ctx.cr6.eq) goto loc_82A7B6B4;
	// lbz r11,26(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 26);
	// lbz r10,26(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 26);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82a7b6b4
	if (!ctx.cr6.eq) goto loc_82A7B6B4;
	// lbz r11,27(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 27);
	// lbz r10,27(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 27);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
loc_82A7B6B0:
	// beq cr6,0x82a7b81c
	if (ctx.cr6.eq) goto loc_82A7B81C;
loc_82A7B6B4:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82a7b6c8
	if (!ctx.cr6.eq) goto loc_82A7B6C8;
loc_82A7B6BC:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// beq cr6,0x82a7b6cc
	if (ctx.cr6.eq) goto loc_82A7B6CC;
loc_82A7B6C8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A7B6CC:
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
loc_82A7B6D0:
	// lfd f0,24(r3)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r3.u32 + 24);
	// lfd f13,24(r31)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r31.u32 + 24);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// b 0x82a7b6b0
	goto loc_82A7B6B0;
loc_82A7B6E0:
	// mr. r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// beq 0x82a7b740
	if (ctx.cr0.eq) goto loc_82A7B740;
	// lwz r5,24(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
loc_82A7B6F4:
	// lwz r10,24(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
loc_82A7B6FC:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82a7b720
	if (ctx.cr0.eq) goto loc_82A7B720;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82a7b6fc
	if (ctx.cr6.eq) goto loc_82A7B6FC;
loc_82A7B720:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq 0x82a7b73c
	if (ctx.cr0.eq) goto loc_82A7B73C;
	// lwz r9,12(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// cmplwi r9,0
	ctx.cr0.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne 0x82a7b6f4
	if (!ctx.cr0.eq) goto loc_82A7B6F4;
	// b 0x82a7b740
	goto loc_82A7B740;
loc_82A7B73C:
	// li r4,1
	ctx.r4.s64 = 1;
loc_82A7B740:
	// mr. r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// addi r5,r6,-1
	ctx.r5.s64 = ctx.r6.s64 + -1;
	// beq 0x82a7b79c
	if (ctx.cr0.eq) goto loc_82A7B79C;
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
loc_82A7B750:
	// lwz r10,24(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 24);
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
loc_82A7B758:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r7,r7,r9
	ctx.r7.s64 = ctx.r9.s64 - ctx.r7.s64;
	// beq 0x82a7b77c
	if (ctx.cr0.eq) goto loc_82A7B77C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82a7b758
	if (ctx.cr6.eq) goto loc_82A7B758;
loc_82A7B77C:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq 0x82a7b798
	if (ctx.cr0.eq) goto loc_82A7B798;
	// lwz r8,12(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// addi r5,r5,-1
	ctx.r5.s64 = ctx.r5.s64 + -1;
	// cmplwi r8,0
	ctx.cr0.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne 0x82a7b750
	if (!ctx.cr0.eq) goto loc_82A7B750;
	// b 0x82a7b79c
	goto loc_82A7B79C;
loc_82A7B798:
	// li r4,1
	ctx.r4.s64 = 1;
loc_82A7B79C:
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beq cr6,0x82a7b7ac
	if (ctx.cr6.eq) goto loc_82A7B7AC;
	// addi r11,r5,0
	ctx.r11.s64 = ctx.r5.s64 + 0;
	// b 0x82a7b668
	goto loc_82A7B668;
loc_82A7B7AC:
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
loc_82A7B7B4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7b7d8
	if (ctx.cr0.eq) goto loc_82A7B7D8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b7b4
	if (ctx.cr6.eq) goto loc_82A7B7B4;
loc_82A7B7D8:
	// cntlzw r11,r8
	ctx.r11.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// b 0x82a7b66c
	goto loc_82A7B66C;
loc_82A7B7E0:
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
loc_82A7B7E8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7b7d8
	if (ctx.cr0.eq) goto loc_82A7B7D8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b7e8
	if (ctx.cr6.eq) goto loc_82A7B7E8;
	// b 0x82a7b7d8
	goto loc_82A7B7D8;
loc_82A7B810:
	// li r11,1
	ctx.r11.s64 = 1;
loc_82A7B814:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a7b6b4
	if (ctx.cr6.eq) goto loc_82A7B6B4;
loc_82A7B81C:
	// lwz r3,12(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r31,12(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
loc_82A7B824:
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne 0x82a7b614
	if (!ctx.cr0.eq) goto loc_82A7B614;
	// b 0x82a7b6bc
	goto loc_82A7B6BC;
}

__attribute__((alias("__imp__sub_82A7B830"))) PPC_WEAK_FUNC(sub_82A7B830);
PPC_FUNC_IMPL(__imp__sub_82A7B830) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,632(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 632);
	// b 0x82a85170
	sub_82A85170(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7B838"))) PPC_WEAK_FUNC(sub_82A7B838);
PPC_FUNC_IMPL(__imp__sub_82A7B838) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A7B840;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r7,r4
	ctx.r7.u64 = ctx.r4.u64;
	// bl 0x82a7b540
	ctx.lr = 0x82A7B850;
	sub_82A7B540(ctx, base);
	// addi r11,r3,30
	ctx.r11.s64 = ctx.r3.s64 + 30;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r29
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r29.u32);
	// b 0x82a7b8a0
	goto loc_82A7B8A0;
loc_82A7B860:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_82A7B868:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7b88c
	if (ctx.cr0.eq) goto loc_82A7B88C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b868
	if (ctx.cr6.eq) goto loc_82A7B868;
loc_82A7B88C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// blt 0x82a7b8a8
	if (ctx.cr0.lt) goto loc_82A7B8A8;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b8b0
	if (ctx.cr6.eq) goto loc_82A7B8B0;
	// lwz r30,12(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
loc_82A7B8A0:
	// cmplwi r30,0
	ctx.cr0.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne 0x82a7b860
	if (!ctx.cr0.eq) goto loc_82A7B860;
loc_82A7B8A8:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82a7b918
	goto loc_82A7B918;
loc_82A7B8B0:
	// lwz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a7b8c4
	if (ctx.cr6.eq) goto loc_82A7B8C4;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82a7b918
	goto loc_82A7B918;
loc_82A7B8C4:
	// li r11,1
	ctx.r11.s64 = 1;
	// lwz r31,8(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stw r11,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r11.u32);
	// b 0x82a7b8f8
	goto loc_82A7B8F8;
loc_82A7B8D4:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82a7b8f4
	if (!ctx.cr6.eq) goto loc_82A7B8F4;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// bl 0x82a7b838
	ctx.lr = 0x82A7B8EC;
	sub_82A7B838(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a7b900
	if (!ctx.cr0.eq) goto loc_82A7B900;
loc_82A7B8F4:
	// lwz r31,12(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
loc_82A7B8F8:
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne 0x82a7b8d4
	if (!ctx.cr0.eq) goto loc_82A7B8D4;
loc_82A7B900:
	// li r11,0
	ctx.r11.s64 = 0;
	// subf r10,r11,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r11.s64;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// stw r11,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r11.u32);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r3,r10,1
	ctx.r3.u64 = ctx.r10.u64 ^ 1;
loc_82A7B918:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7B920"))) PPC_WEAK_FUNC(sub_82A7B920);
PPC_FUNC_IMPL(__imp__sub_82A7B920) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82a7b838
	ctx.lr = 0x82A7B940;
	sub_82A7B838(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a7b9ac
	if (!ctx.cr0.eq) goto loc_82A7B9AC;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7b540
	ctx.lr = 0x82A7B954;
	sub_82A7B540(ctx, base);
	// addi r11,r3,30
	ctx.r11.s64 = ctx.r3.s64 + 30;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r11,r31
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r31.u32);
	// b 0x82a7b9a4
	goto loc_82A7B9A4;
loc_82A7B964:
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
loc_82A7B96C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7b990
	if (ctx.cr0.eq) goto loc_82A7B990;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b96c
	if (ctx.cr6.eq) goto loc_82A7B96C;
loc_82A7B990:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// blt 0x82a7b9ac
	if (ctx.cr0.lt) goto loc_82A7B9AC;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7b9c8
	if (ctx.cr6.eq) goto loc_82A7B9C8;
	// lwz r7,12(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
loc_82A7B9A4:
	// cmplwi r7,0
	ctx.cr0.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne 0x82a7b964
	if (!ctx.cr0.eq) goto loc_82A7B964;
loc_82A7B9AC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A7B9B0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82A7B9C8:
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82a7b9d8
	if (ctx.cr6.eq) goto loc_82A7B9D8;
	// lwz r11,4(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r11.u32);
loc_82A7B9D8:
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82a7b9e8
	if (ctx.cr6.eq) goto loc_82A7B9E8;
	// lwz r11,8(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82A7B9E8:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82a7b9b0
	goto loc_82A7B9B0;
}

__attribute__((alias("__imp__sub_82A7B9F0"))) PPC_WEAK_FUNC(sub_82A7B9F0);
PPC_FUNC_IMPL(__imp__sub_82A7B9F0) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// li r11,0
	ctx.r11.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// li r9,92
	ctx.r9.s64 = 92;
loc_82A7BA08:
	// lbz r8,0(r4)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r8,34
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 34, ctx.xer);
	// bne cr6,0x82a7ba3c
	if (!ctx.cr6.eq) goto loc_82A7BA3C;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82a7ba28
	if (ctx.cr6.eq) goto loc_82A7BA28;
	// cmplw cr6,r3,r7
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r7.u32, ctx.xer);
	// bge cr6,0x82a7ba28
	if (!ctx.cr6.lt) goto loc_82A7BA28;
	// stbx r9,r3,r6
	PPC_STORE_U8(ctx.r3.u32 + ctx.r6.u32, ctx.r9.u8);
loc_82A7BA28:
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a7ba3c
	if (!ctx.cr6.eq) goto loc_82A7BA3C;
	// cntlzw r11,r10
	ctx.r11.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r10,r11,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
loc_82A7BA3C:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82a7ba70
	if (ctx.cr6.eq) goto loc_82A7BA70;
	// lbz r8,0(r4)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r8,92
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 92, ctx.xer);
	// bne cr6,0x82a7ba70
	if (!ctx.cr6.eq) goto loc_82A7BA70;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82a7ba68
	if (ctx.cr6.eq) goto loc_82A7BA68;
	// cmplw cr6,r3,r7
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r7.u32, ctx.xer);
	// bge cr6,0x82a7ba68
	if (!ctx.cr6.lt) goto loc_82A7BA68;
	// stbx r9,r3,r6
	PPC_STORE_U8(ctx.r3.u32 + ctx.r6.u32, ctx.r9.u8);
loc_82A7BA68:
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82A7BA70:
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82a7ba88
	if (ctx.cr6.eq) goto loc_82A7BA88;
	// cmplw cr6,r3,r7
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r7.u32, ctx.xer);
	// bge cr6,0x82a7ba88
	if (!ctx.cr6.lt) goto loc_82A7BA88;
	// lbz r8,0(r4)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// stbx r8,r3,r6
	PPC_STORE_U8(ctx.r3.u32 + ctx.r6.u32, ctx.r8.u8);
loc_82A7BA88:
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// bne 0x82a7ba08
	if (!ctx.cr0.eq) goto loc_82A7BA08;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7BAA0"))) PPC_WEAK_FUNC(sub_82A7BAA0);
PPC_FUNC_IMPL(__imp__sub_82A7BAA0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82a7bac4
	if (ctx.cr6.eq) goto loc_82A7BAC4;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// b 0x82a7baf4
	goto loc_82A7BAF4;
loc_82A7BAC4:
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a7baf0
	if (!ctx.cr6.eq) goto loc_82A7BAF0;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-22260
	ctx.r6.s64 = ctx.r11.s64 + -22260;
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82a85c20
	ctx.lr = 0x82A7BAE8;
	sub_82A85C20(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
loc_82A7BAF0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A7BAF4:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7BB08"))) PPC_WEAK_FUNC(sub_82A7BB08);
PPC_FUNC_IMPL(__imp__sub_82A7BB08) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7bb38
	if (ctx.cr0.eq) goto loc_82A7BB38;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82a7bb08
	ctx.lr = 0x82A7BB38;
	sub_82A7BB08(ctx, base);
loc_82A7BB38:
	// clrlwi. r11,r30,31
	ctx.r11.u64 = ctx.r30.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a7bb4c
	if (ctx.cr0.eq) goto loc_82A7BB4C;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A7BB4C;
	sub_8247F398(ctx, base);
loc_82A7BB4C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7BB68"))) PPC_WEAK_FUNC(sub_82A7BB68);
PPC_FUNC_IMPL(__imp__sub_82A7BB68) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r3,56(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7bb90
	if (ctx.cr0.eq) goto loc_82A7BB90;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82a7bb08
	ctx.lr = 0x82A7BB90;
	sub_82A7BB08(ctx, base);
loc_82A7BB90:
	// lwz r3,92(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7bba4
	if (ctx.cr0.eq) goto loc_82A7BBA4;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82a7bbf8
	ctx.lr = 0x82A7BBA4;
	sub_82A7BBF8(ctx, base);
loc_82A7BBA4:
	// lwz r11,72(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7bbd0
	if (ctx.cr6.eq) goto loc_82A7BBD0;
	// lwz r4,84(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// cmplwi r4,0
	ctx.cr0.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq 0x82a7bbd0
	if (ctx.cr0.eq) goto loc_82A7BBD0;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A7BBD0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A7BBD0:
	// addi r3,r31,60
	ctx.r3.s64 = ctx.r31.s64 + 60;
	// bl 0x82aa7290
	ctx.lr = 0x82A7BBD8;
	sub_82AA7290(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d09218
	ctx.lr = 0x82A7BBE0;
	sub_82D09218(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7BBF8"))) PPC_WEAK_FUNC(sub_82A7BBF8);
PPC_FUNC_IMPL(__imp__sub_82A7BBF8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82a7bb68
	ctx.lr = 0x82A7BC18;
	sub_82A7BB68(ctx, base);
	// clrlwi. r11,r30,31
	ctx.r11.u64 = ctx.r30.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a7bc2c
	if (ctx.cr0.eq) goto loc_82A7BC2C;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A7BC2C;
	sub_8247F398(ctx, base);
loc_82A7BC2C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7BC48"))) PPC_WEAK_FUNC(sub_82A7BC48);
PPC_FUNC_IMPL(__imp__sub_82A7BC48) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r3,40(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7bc78
	if (ctx.cr0.eq) goto loc_82A7BC78;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82a7bc48
	ctx.lr = 0x82A7BC78;
	sub_82A7BC48(ctx, base);
loc_82A7BC78:
	// clrlwi. r11,r30,31
	ctx.r11.u64 = ctx.r30.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a7bc8c
	if (ctx.cr0.eq) goto loc_82A7BC8C;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A7BC8C;
	sub_8247F398(ctx, base);
loc_82A7BC8C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7BCA8"))) PPC_WEAK_FUNC(sub_82A7BCA8);
PPC_FUNC_IMPL(__imp__sub_82A7BCA8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7bcd8
	if (ctx.cr0.eq) goto loc_82A7BCD8;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82a7bca8
	ctx.lr = 0x82A7BCD8;
	sub_82A7BCA8(ctx, base);
loc_82A7BCD8:
	// clrlwi. r11,r30,31
	ctx.r11.u64 = ctx.r30.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a7bcec
	if (ctx.cr0.eq) goto loc_82A7BCEC;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A7BCEC;
	sub_8247F398(ctx, base);
loc_82A7BCEC:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7BD08"))) PPC_WEAK_FUNC(sub_82A7BD08);
PPC_FUNC_IMPL(__imp__sub_82A7BD08) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A7BD10;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r5,1
	ctx.r5.s64 = 65536;
	// lis r4,16
	ctx.r4.s64 = 1048576;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82ab6fd8
	ctx.lr = 0x82A7BD24;
	sub_82AB6FD8(ctx, base);
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82a84fa0
	ctx.lr = 0x82A7BD2C;
	sub_82A84FA0(ctx, base);
	// li r30,0
	ctx.r30.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r30,684(r31)
	PPC_STORE_U32(ctx.r31.u32 + 684, ctx.r30.u32);
	// bl 0x82a7a9b8
	ctx.lr = 0x82A7BD3C;
	sub_82A7A9B8(ctx, base);
	// li r29,1
	ctx.r29.s64 = 1;
	// stw r30,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r30.u32);
	// li r5,508
	ctx.r5.s64 = 508;
	// stw r30,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r30.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r30,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r30.u32);
	// addi r3,r31,120
	ctx.r3.s64 = ctx.r31.s64 + 120;
	// stw r30,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r30.u32);
	// stw r30,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r30.u32);
	// stw r29,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r29.u32);
	// stw r29,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r29.u32);
	// stw r29,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r29.u32);
	// stw r29,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r29.u32);
	// stw r30,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r30.u32);
	// stw r30,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r30.u32);
	// stw r30,108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 108, ctx.r30.u32);
	// stw r30,112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 112, ctx.r30.u32);
	// stw r30,116(r31)
	PPC_STORE_U32(ctx.r31.u32 + 116, ctx.r30.u32);
	// stw r30,628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 628, ctx.r30.u32);
	// stw r30,632(r31)
	PPC_STORE_U32(ctx.r31.u32 + 632, ctx.r30.u32);
	// stw r30,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r30.u32);
	// bl 0x82d5cb60
	ctx.lr = 0x82A7BD94;
	sub_82D5CB60(ctx, base);
	// std r30,640(r31)
	PPC_STORE_U64(ctx.r31.u32 + 640, ctx.r30.u64);
	// li r4,0
	ctx.r4.s64 = 0;
	// std r30,648(r31)
	PPC_STORE_U64(ctx.r31.u32 + 648, ctx.r30.u64);
	// li r3,4
	ctx.r3.s64 = 4;
	// std r30,656(r31)
	PPC_STORE_U64(ctx.r31.u32 + 656, ctx.r30.u64);
	// std r30,664(r31)
	PPC_STORE_U64(ctx.r31.u32 + 664, ctx.r30.u64);
	// stw r29,672(r31)
	PPC_STORE_U32(ctx.r31.u32 + 672, ctx.r29.u32);
	// bl 0x82d62930
	ctx.lr = 0x82A7BDB4;
	sub_82D62930(ctx, base);
	// bl 0x82d62898
	ctx.lr = 0x82A7BDB8;
	sub_82D62898(ctx, base);
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,676(r31)
	PPC_STORE_U32(ctx.r31.u32 + 676, ctx.r3.u32);
	// addi r4,r11,8144
	ctx.r4.s64 = ctx.r11.s64 + 8144;
	// beq 0x82a7bdfc
	if (ctx.cr0.eq) goto loc_82A7BDFC;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
loc_82A7BDD0:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmpwi r10,0
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// subf r9,r9,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r9.s64;
	// beq 0x82a7bdf4
	if (ctx.cr0.eq) goto loc_82A7BDF4;
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82a7bdd0
	if (ctx.cr6.eq) goto loc_82A7BDD0;
loc_82A7BDF4:
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq 0x82a7be04
	if (ctx.cr0.eq) goto loc_82A7BE04;
loc_82A7BDFC:
	// li r3,4
	ctx.r3.s64 = 4;
	// bl 0x82d62930
	ctx.lr = 0x82A7BE04;
	sub_82D62930(ctx, base);
loc_82A7BE04:
	// stw r30,692(r31)
	PPC_STORE_U32(ctx.r31.u32 + 692, ctx.r30.u32);
	// bl 0x82aa7038
	ctx.lr = 0x82A7BE0C;
	sub_82AA7038(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7BE18"))) PPC_WEAK_FUNC(sub_82A7BE18);
PPC_FUNC_IMPL(__imp__sub_82A7BE18) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A7BE20;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r3,64(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 64);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7be3c
	if (ctx.cr0.eq) goto loc_82A7BE3C;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82a7bc48
	ctx.lr = 0x82A7BE3C;
	sub_82A7BC48(ctx, base);
loc_82A7BE3C:
	// lwz r3,116(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 116);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7be50
	if (ctx.cr0.eq) goto loc_82A7BE50;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82a7bca8
	ctx.lr = 0x82A7BE50;
	sub_82A7BCA8(ctx, base);
loc_82A7BE50:
	// lwz r31,628(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 628);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a7be70
	if (ctx.cr0.eq) goto loc_82A7BE70;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7bb68
	ctx.lr = 0x82A7BE64;
	sub_82A7BB68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A7BE70;
	sub_8247F398(ctx, base);
loc_82A7BE70:
	// lwz r3,68(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 68);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7be84
	if (ctx.cr0.eq) goto loc_82A7BE84;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82a7bca8
	ctx.lr = 0x82A7BE84;
	sub_82A7BCA8(ctx, base);
loc_82A7BE84:
	// addi r31,r30,120
	ctx.r31.s64 = ctx.r30.s64 + 120;
	// li r29,127
	ctx.r29.s64 = 127;
loc_82A7BE8C:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7bea0
	if (ctx.cr0.eq) goto loc_82A7BEA0;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82a7bb08
	ctx.lr = 0x82A7BEA0;
	sub_82A7BB08(ctx, base);
loc_82A7BEA0:
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// bne 0x82a7be8c
	if (!ctx.cr0.eq) goto loc_82A7BE8C;
	// lwz r11,684(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 684);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a7bec0
	if (ctx.cr6.eq) goto loc_82A7BEC0;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82a7aa10
	ctx.lr = 0x82A7BEC0;
	sub_82A7AA10(ctx, base);
loc_82A7BEC0:
	// addi r3,r30,24
	ctx.r3.s64 = ctx.r30.s64 + 24;
	// bl 0x82a85828
	ctx.lr = 0x82A7BEC8;
	sub_82A85828(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82ab7020
	ctx.lr = 0x82A7BED0;
	sub_82AB7020(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7BED8"))) PPC_WEAK_FUNC(sub_82A7BED8);
PPC_FUNC_IMPL(__imp__sub_82A7BED8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,12
	ctx.r3.s64 = 12;
	// bl 0x8247f370
	ctx.lr = 0x82A7BF00;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7bf24
	if (ctx.cr0.eq) goto loc_82A7BF24;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r30.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// b 0x82a7bf28
	goto loc_82A7BF28;
loc_82A7BF24:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82A7BF28:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a7bf3c
	if (!ctx.cr6.eq) goto loc_82A7BF3C;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82a7bf50
	goto loc_82A7BF50;
loc_82A7BF3C:
	// lwz r10,116(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
	// stw r11,116(r31)
	PPC_STORE_U32(ctx.r31.u32 + 116, ctx.r11.u32);
	// stw r30,672(r31)
	PPC_STORE_U32(ctx.r31.u32 + 672, ctx.r30.u32);
loc_82A7BF50:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7BF68"))) PPC_WEAK_FUNC(sub_82A7BF68);
PPC_FUNC_IMPL(__imp__sub_82A7BF68) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A7BF70;
	__savegprlr_28(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// lwz r11,76(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 76);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a7c728
	if (!ctx.cr6.eq) goto loc_82A7C728;
	// lwz r11,84(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 84);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a7c728
	if (!ctx.cr6.eq) goto loc_82A7C728;
	// lwz r10,112(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 112);
	// li r30,0
	ctx.r30.s64 = 0;
	// addi r31,r28,640
	ctx.r31.s64 = ctx.r28.s64 + 640;
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq 0x82a7bfd8
	if (ctx.cr0.eq) goto loc_82A7BFD8;
	// addi r11,r10,16
	ctx.r11.s64 = ctx.r10.s64 + 16;
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// std r9,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r9.u64);
	// ld r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// std r9,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r9.u64);
	// ld r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// std r9,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r9.u64);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// std r11,24(r31)
	PPC_STORE_U64(ctx.r31.u32 + 24, ctx.r11.u64);
	// lwz r11,12(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// stw r11,112(r28)
	PPC_STORE_U32(ctx.r28.u32 + 112, ctx.r11.u32);
	// stw r30,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r30.u32);
	// b 0x82a7bff4
	goto loc_82A7BFF4;
loc_82A7BFD8:
	// lwz r11,672(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 672);
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// lwz r3,632(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 632);
	// ori r4,r11,4
	ctx.r4.u64 = ctx.r11.u64 | 4;
	// bl 0x82a86ed8
	ctx.lr = 0x82A7BFEC;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7c730
	if (ctx.cr0.lt) goto loc_82A7C730;
loc_82A7BFF4:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x82a7c684
	if (ctx.cr6.eq) goto loc_82A7C684;
	// ble cr6,0x82a7c720
	if (!ctx.cr6.gt) goto loc_82A7C720;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// ble cr6,0x82a7c67c
	if (!ctx.cr6.gt) goto loc_82A7C67C;
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// beq cr6,0x82a7c040
	if (ctx.cr6.eq) goto loc_82A7C040;
	// cmpwi cr6,r11,10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 10, ctx.xer);
	// beq cr6,0x82a7c038
	if (ctx.cr6.eq) goto loc_82A7C038;
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82a7c02c
	if (ctx.cr6.eq) goto loc_82A7C02C;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// bne cr6,0x82a7c720
	if (!ctx.cr6.eq) goto loc_82A7C720;
loc_82A7C02C:
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,76(r28)
	PPC_STORE_U32(ctx.r28.u32 + 76, ctx.r11.u32);
	// b 0x82a7c730
	goto loc_82A7C730;
loc_82A7C038:
	// li r3,280
	ctx.r3.s64 = 280;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C040:
	// lwz r11,88(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 88);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a7c538
	if (ctx.cr6.eq) goto loc_82A7C538;
	// lwz r11,92(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 92);
	// li r29,1
	ctx.r29.s64 = 1;
	// stw r30,88(r28)
	PPC_STORE_U32(ctx.r28.u32 + 88, ctx.r30.u32);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lwz r11,648(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 648);
	// stw r30,100(r28)
	PPC_STORE_U32(ctx.r28.u32 + 100, ctx.r30.u32);
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// beq cr6,0x82a7c38c
	if (ctx.cr6.eq) goto loc_82A7C38C;
	// cmpwi cr6,r10,100
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 100, ctx.xer);
	// beq cr6,0x82a7c350
	if (ctx.cr6.eq) goto loc_82A7C350;
	// cmpwi cr6,r10,101
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 101, ctx.xer);
	// beq cr6,0x82a7c250
	if (ctx.cr6.eq) goto loc_82A7C250;
	// cmpwi cr6,r10,105
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 105, ctx.xer);
	// beq cr6,0x82a7c154
	if (ctx.cr6.eq) goto loc_82A7C154;
	// cmpwi cr6,r10,108
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 108, ctx.xer);
	// beq cr6,0x82a7c118
	if (ctx.cr6.eq) goto loc_82A7C118;
	// cmpwi cr6,r10,112
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 112, ctx.xer);
	// beq cr6,0x82a7c0dc
	if (ctx.cr6.eq) goto loc_82A7C0DC;
	// cmpwi cr6,r10,117
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 117, ctx.xer);
	// bne cr6,0x82a7c448
	if (!ctx.cr6.eq) goto loc_82A7C448;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,-22088
	ctx.r10.s64 = ctx.r10.s64 + -22088;
loc_82A7C0A8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7c0cc
	if (ctx.cr0.eq) goto loc_82A7C0CC;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7c0a8
	if (ctx.cr6.eq) goto loc_82A7C0A8;
loc_82A7C0CC:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7c448
	if (!ctx.cr0.eq) goto loc_82A7C448;
	// li r3,258
	ctx.r3.s64 = 258;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C0DC:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,-22096
	ctx.r10.s64 = ctx.r10.s64 + -22096;
loc_82A7C0E4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7c108
	if (ctx.cr0.eq) goto loc_82A7C108;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7c0e4
	if (ctx.cr6.eq) goto loc_82A7C0E4;
loc_82A7C108:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7c448
	if (!ctx.cr0.eq) goto loc_82A7C448;
	// li r3,270
	ctx.r3.s64 = 270;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C118:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,-22104
	ctx.r10.s64 = ctx.r10.s64 + -22104;
loc_82A7C120:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7c144
	if (ctx.cr0.eq) goto loc_82A7C144;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7c120
	if (ctx.cr6.eq) goto loc_82A7C120;
loc_82A7C144:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7c448
	if (!ctx.cr0.eq) goto loc_82A7C448;
	// li r3,259
	ctx.r3.s64 = 259;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C154:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,-22108
	ctx.r9.s64 = ctx.r10.s64 + -22108;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A7C160:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82a7c184
	if (ctx.cr0.eq) goto loc_82A7C184;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82a7c160
	if (ctx.cr6.eq) goto loc_82A7C160;
loc_82A7C184:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// bne 0x82a7c194
	if (!ctx.cr0.eq) goto loc_82A7C194;
	// li r3,262
	ctx.r3.s64 = 262;
	// b 0x82a7c28c
	goto loc_82A7C28C;
loc_82A7C194:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,-22116
	ctx.r9.s64 = ctx.r10.s64 + -22116;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A7C1A0:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82a7c1c4
	if (ctx.cr0.eq) goto loc_82A7C1C4;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82a7c1a0
	if (ctx.cr6.eq) goto loc_82A7C1A0;
loc_82A7C1C4:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// bne 0x82a7c1d4
	if (!ctx.cr0.eq) goto loc_82A7C1D4;
	// li r3,263
	ctx.r3.s64 = 263;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C1D4:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,-22124
	ctx.r9.s64 = ctx.r10.s64 + -22124;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A7C1E0:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82a7c204
	if (ctx.cr0.eq) goto loc_82A7C204;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82a7c1e0
	if (ctx.cr6.eq) goto loc_82A7C1E0;
loc_82A7C204:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// bne 0x82a7c214
	if (!ctx.cr0.eq) goto loc_82A7C214;
	// li r3,264
	ctx.r3.s64 = 264;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C214:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,-22132
	ctx.r10.s64 = ctx.r10.s64 + -22132;
loc_82A7C21C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7c240
	if (ctx.cr0.eq) goto loc_82A7C240;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7c21c
	if (ctx.cr6.eq) goto loc_82A7C21C;
loc_82A7C240:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7c448
	if (!ctx.cr0.eq) goto loc_82A7C448;
	// li r3,260
	ctx.r3.s64 = 260;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C250:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,-22140
	ctx.r9.s64 = ctx.r10.s64 + -22140;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A7C25C:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82a7c280
	if (ctx.cr0.eq) goto loc_82A7C280;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82a7c25c
	if (ctx.cr6.eq) goto loc_82A7C25C;
loc_82A7C280:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// bne 0x82a7c294
	if (!ctx.cr0.eq) goto loc_82A7C294;
loc_82A7C288:
	// li r3,265
	ctx.r3.s64 = 265;
loc_82A7C28C:
	// stw r29,100(r28)
	PPC_STORE_U32(ctx.r28.u32 + 100, ctx.r29.u32);
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C294:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,-22148
	ctx.r9.s64 = ctx.r10.s64 + -22148;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A7C2A0:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82a7c2c4
	if (ctx.cr0.eq) goto loc_82A7C2C4;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82a7c2a0
	if (ctx.cr6.eq) goto loc_82A7C2A0;
loc_82A7C2C4:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// bne 0x82a7c2d4
	if (!ctx.cr0.eq) goto loc_82A7C2D4;
loc_82A7C2CC:
	// li r3,266
	ctx.r3.s64 = 266;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C2D4:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,-22156
	ctx.r9.s64 = ctx.r10.s64 + -22156;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A7C2E0:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82a7c304
	if (ctx.cr0.eq) goto loc_82A7C304;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82a7c2e0
	if (ctx.cr6.eq) goto loc_82A7C2E0;
loc_82A7C304:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// bne 0x82a7c314
	if (!ctx.cr0.eq) goto loc_82A7C314;
loc_82A7C30C:
	// li r3,267
	ctx.r3.s64 = 267;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C314:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,-22284
	ctx.r10.s64 = ctx.r10.s64 + -22284;
loc_82A7C31C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7c340
	if (ctx.cr0.eq) goto loc_82A7C340;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7c31c
	if (ctx.cr6.eq) goto loc_82A7C31C;
loc_82A7C340:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7c448
	if (!ctx.cr0.eq) goto loc_82A7C448;
	// li r3,261
	ctx.r3.s64 = 261;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C350:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,-22164
	ctx.r10.s64 = ctx.r10.s64 + -22164;
loc_82A7C358:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7c37c
	if (ctx.cr0.eq) goto loc_82A7C37C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7c358
	if (ctx.cr6.eq) goto loc_82A7C358;
loc_82A7C37C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7c448
	if (!ctx.cr0.eq) goto loc_82A7C448;
	// li r3,257
	ctx.r3.s64 = 257;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C38C:
	// cmpwi cr6,r10,101
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 101, ctx.xer);
	// beq cr6,0x82a7c454
	if (ctx.cr6.eq) goto loc_82A7C454;
	// cmpwi cr6,r10,105
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 105, ctx.xer);
	// bne cr6,0x82a7c448
	if (!ctx.cr6.eq) goto loc_82A7C448;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,-22108
	ctx.r9.s64 = ctx.r10.s64 + -22108;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A7C3A8:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82a7c3cc
	if (ctx.cr0.eq) goto loc_82A7C3CC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82a7c3a8
	if (ctx.cr6.eq) goto loc_82A7C3A8;
loc_82A7C3CC:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// bne 0x82a7c3dc
	if (!ctx.cr0.eq) goto loc_82A7C3DC;
loc_82A7C3D4:
	// li r3,268
	ctx.r3.s64 = 268;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C3DC:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,-22116
	ctx.r9.s64 = ctx.r10.s64 + -22116;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A7C3E8:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82a7c40c
	if (ctx.cr0.eq) goto loc_82A7C40C;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82a7c3e8
	if (ctx.cr6.eq) goto loc_82A7C3E8;
loc_82A7C40C:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq 0x82a7c3d4
	if (ctx.cr0.eq) goto loc_82A7C3D4;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,-22124
	ctx.r10.s64 = ctx.r10.s64 + -22124;
loc_82A7C41C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7c440
	if (ctx.cr0.eq) goto loc_82A7C440;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7c41c
	if (ctx.cr6.eq) goto loc_82A7C41C;
loc_82A7C440:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a7c3d4
	if (ctx.cr0.eq) goto loc_82A7C3D4;
loc_82A7C448:
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,88(r28)
	PPC_STORE_U32(ctx.r28.u32 + 88, ctx.r11.u32);
	// b 0x82a7c674
	goto loc_82A7C674;
loc_82A7C454:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,-22148
	ctx.r9.s64 = ctx.r10.s64 + -22148;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A7C460:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82a7c484
	if (ctx.cr0.eq) goto loc_82A7C484;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82a7c460
	if (ctx.cr6.eq) goto loc_82A7C460;
loc_82A7C484:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq 0x82a7c2cc
	if (ctx.cr0.eq) goto loc_82A7C2CC;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,-22156
	ctx.r9.s64 = ctx.r10.s64 + -22156;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A7C498:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82a7c4bc
	if (ctx.cr0.eq) goto loc_82A7C4BC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82a7c498
	if (ctx.cr6.eq) goto loc_82A7C498;
loc_82A7C4BC:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq 0x82a7c30c
	if (ctx.cr0.eq) goto loc_82A7C30C;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,-22140
	ctx.r10.s64 = ctx.r10.s64 + -22140;
loc_82A7C4CC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7c4f0
	if (ctx.cr0.eq) goto loc_82A7C4F0;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7c4cc
	if (ctx.cr6.eq) goto loc_82A7C4CC;
loc_82A7C4F0:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7c448
	if (!ctx.cr0.eq) goto loc_82A7C448;
	// lwz r11,628(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 628);
	// lwz r11,56(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82a7c510
	if (!ctx.cr0.eq) goto loc_82A7C510;
	// stw r29,92(r28)
	PPC_STORE_U32(ctx.r28.u32 + 92, ctx.r29.u32);
	// b 0x82a7c288
	goto loc_82A7C288;
loc_82A7C510:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmpwi r10,0
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82a7c530
	if (ctx.cr0.eq) goto loc_82A7C530;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a7c530
	if (!ctx.cr6.eq) goto loc_82A7C530;
	// stw r10,92(r28)
	PPC_STORE_U32(ctx.r28.u32 + 92, ctx.r10.u32);
	// b 0x82a7c288
	goto loc_82A7C288;
loc_82A7C530:
	// li r3,269
	ctx.r3.s64 = 269;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C538:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lwz r4,648(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 648);
	// addi r10,r11,-22172
	ctx.r10.s64 = ctx.r11.s64 + -22172;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
loc_82A7C548:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7c56c
	if (ctx.cr0.eq) goto loc_82A7C56C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7c548
	if (ctx.cr6.eq) goto loc_82A7C548;
loc_82A7C56C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7c580
	if (!ctx.cr0.eq) goto loc_82A7C580;
	// li r3,271
	ctx.r3.s64 = 271;
	// stw r30,100(r28)
	PPC_STORE_U32(ctx.r28.u32 + 100, ctx.r30.u32);
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C580:
	// lwz r11,100(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 100);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a7c674
	if (ctx.cr6.eq) goto loc_82A7C674;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82a7b920
	ctx.lr = 0x82A7C59C;
	sub_82A7B920(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a7c674
	if (ctx.cr0.eq) goto loc_82A7C674;
	// lwz r10,80(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 80);
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// ld r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// li r29,1
	ctx.r29.s64 = 1;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ld r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// ld r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ld r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r31.u32 + 24);
	// std r10,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r10.u64);
	// std r9,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r9.u64);
	// std r8,16(r11)
	PPC_STORE_U64(ctx.r11.u32 + 16, ctx.r8.u64);
	// std r7,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r7.u64);
	// bne cr6,0x82a7c5f8
	if (!ctx.cr6.eq) goto loc_82A7C5F8;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x82a7f130
	ctx.lr = 0x82A7C5EC;
	sub_82A7F130(ctx, base);
	// cmpwi cr6,r3,1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 1, ctx.xer);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// beq cr6,0x82a7c5fc
	if (ctx.cr6.eq) goto loc_82A7C5FC;
loc_82A7C5F8:
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
loc_82A7C5FC:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r11,80(r28)
	PPC_STORE_U32(ctx.r28.u32 + 80, ctx.r11.u32);
	// bne cr6,0x82a7c620
	if (!ctx.cr6.eq) goto loc_82A7C620;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82a7bf68
	ctx.lr = 0x82A7C610;
	sub_82A7BF68(ctx, base);
	// cmpwi cr6,r3,-1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, -1, ctx.xer);
	// beq cr6,0x82a7c624
	if (ctx.cr6.eq) goto loc_82A7C624;
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// b 0x82a7c628
	goto loc_82A7C628;
loc_82A7C620:
	// lwz r3,84(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82A7C624:
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
loc_82A7C628:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r11,80(r28)
	PPC_STORE_U32(ctx.r28.u32 + 80, ctx.r11.u32);
	// beq cr6,0x82a7c734
	if (ctx.cr6.eq) goto loc_82A7C734;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// stw r29,84(r28)
	PPC_STORE_U32(ctx.r28.u32 + 84, ctx.r29.u32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// li r5,1518
	ctx.r5.s64 = 1518;
	// addi r6,r10,-22224
	ctx.r6.s64 = ctx.r10.s64 + -22224;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// ld r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// addi r3,r28,24
	ctx.r3.s64 = ctx.r28.s64 + 24;
	// ld r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// ld r8,16(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// std r10,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r10.u64);
	// std r9,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r9.u64);
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// std r11,24(r31)
	PPC_STORE_U64(ctx.r31.u32 + 24, ctx.r11.u64);
	// bl 0x82a85c20
	ctx.lr = 0x82A7C674;
	sub_82A85C20(ctx, base);
loc_82A7C674:
	// li r3,278
	ctx.r3.s64 = 278;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C67C:
	// li r3,279
	ctx.r3.s64 = 279;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C684:
	// lbz r11,649(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 649);
	// extsb. r10,r11
	ctx.r10.s64 = ctx.r11.s8;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82a7c69c
	if (!ctx.cr0.eq) goto loc_82A7C69C;
	// lbz r11,648(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 648);
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C69C:
	// lbz r11,650(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 650);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a7c720
	if (!ctx.cr6.eq) goto loc_82A7C720;
	// lbz r11,648(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 648);
	// cmpwi cr6,r10,61
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 61, ctx.xer);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// bne cr6,0x82a7c6f8
	if (!ctx.cr6.eq) goto loc_82A7C6F8;
	// cmpwi cr6,r11,33
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 33, ctx.xer);
	// beq cr6,0x82a7c6f0
	if (ctx.cr6.eq) goto loc_82A7C6F0;
	// cmpwi cr6,r11,60
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 60, ctx.xer);
	// beq cr6,0x82a7c6e8
	if (ctx.cr6.eq) goto loc_82A7C6E8;
	// cmpwi cr6,r11,61
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 61, ctx.xer);
	// beq cr6,0x82a7c6e0
	if (ctx.cr6.eq) goto loc_82A7C6E0;
	// cmpwi cr6,r11,62
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 62, ctx.xer);
	// bne cr6,0x82a7c720
	if (!ctx.cr6.eq) goto loc_82A7C720;
	// li r3,273
	ctx.r3.s64 = 273;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C6E0:
	// li r3,274
	ctx.r3.s64 = 274;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C6E8:
	// li r3,272
	ctx.r3.s64 = 272;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C6F0:
	// li r3,275
	ctx.r3.s64 = 275;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C6F8:
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82a7c720
	if (!ctx.cr6.eq) goto loc_82A7C720;
	// cmpwi cr6,r11,38
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 38, ctx.xer);
	// beq cr6,0x82a7c718
	if (ctx.cr6.eq) goto loc_82A7C718;
	// cmpwi cr6,r11,124
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 124, ctx.xer);
	// bne cr6,0x82a7c720
	if (!ctx.cr6.eq) goto loc_82A7C720;
	// li r3,277
	ctx.r3.s64 = 277;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C718:
	// li r3,276
	ctx.r3.s64 = 276;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C720:
	// li r3,281
	ctx.r3.s64 = 281;
	// b 0x82a7c734
	goto loc_82A7C734;
loc_82A7C728:
	// li r11,12
	ctx.r11.s64 = 12;
	// stw r11,640(r28)
	PPC_STORE_U32(ctx.r28.u32 + 640, ctx.r11.u32);
loc_82A7C730:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82A7C734:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7C740"))) PPC_WEAK_FUNC(sub_82A7C740);
PPC_FUNC_IMPL(__imp__sub_82A7C740) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// bl 0x82a7b540
	ctx.lr = 0x82A7C758;
	sub_82A7B540(ctx, base);
	// addi r11,r3,30
	ctx.r11.s64 = ctx.r3.s64 + 30;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// b 0x82a7c7ac
	goto loc_82A7C7AC;
loc_82A7C768:
	// lwz r6,0(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
loc_82A7C774:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82a7c798
	if (ctx.cr0.eq) goto loc_82A7C798;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82a7c774
	if (ctx.cr6.eq) goto loc_82A7C774;
loc_82A7C798:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// blt 0x82a7c7d8
	if (ctx.cr0.lt) goto loc_82A7C7D8;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82a7c7bc
	if (ctx.cr6.eq) goto loc_82A7C7BC;
	// addi r9,r6,12
	ctx.r9.s64 = ctx.r6.s64 + 12;
loc_82A7C7AC:
	// lwz r11,0(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a7c768
	if (!ctx.cr6.eq) goto loc_82A7C768;
	// b 0x82a7c7d8
	goto loc_82A7C7D8;
loc_82A7C7BC:
	// lwz r3,0(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// li r11,0
	ctx.r11.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r11.u32);
	// bl 0x82a7bb08
	ctx.lr = 0x82A7C7D8;
	sub_82A7BB08(ctx, base);
loc_82A7C7D8:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7C7F0"))) PPC_WEAK_FUNC(sub_82A7C7F0);
PPC_FUNC_IMPL(__imp__sub_82A7C7F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,16
	ctx.r3.s64 = 16;
	// bl 0x8247f370
	ctx.lr = 0x82A7C818;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7c840
	if (ctx.cr0.eq) goto loc_82A7C840;
	// lwz r10,92(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r30.u32);
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stw r9,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r9.u32);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// b 0x82a7c844
	goto loc_82A7C844;
loc_82A7C840:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82A7C844:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a7c858
	if (!ctx.cr6.eq) goto loc_82A7C858;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82a7c890
	goto loc_82A7C890;
loc_82A7C858:
	// lwz r10,628(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// stw r10,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r10.u32);
	// lwz r10,628(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// stw r11,56(r10)
	PPC_STORE_U32(ctx.r10.u32 + 56, ctx.r11.u32);
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a7c884
	if (ctx.cr6.eq) goto loc_82A7C884;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// bne cr6,0x82a7c888
	if (!ctx.cr6.eq) goto loc_82A7C888;
loc_82A7C884:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82A7C888:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r11.u32);
loc_82A7C890:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7C8A8"))) PPC_WEAK_FUNC(sub_82A7C8A8);
PPC_FUNC_IMPL(__imp__sub_82A7C8A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r3,56(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne 0x82a7c8f8
	if (!ctx.cr0.eq) goto loc_82A7C8F8;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1510
	ctx.r5.s64 = 1510;
	// addi r6,r11,-22080
	ctx.r6.s64 = ctx.r11.s64 + -22080;
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82a85c20
	ctx.lr = 0x82A7C8E4;
	sub_82A85C20(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// b 0x82a7c91c
	goto loc_82A7C91C;
loc_82A7C8F8:
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r10,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r10.u32);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// stw r10,56(r11)
	PPC_STORE_U32(ctx.r11.u32 + 56, ctx.r10.u32);
	// stw r9,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r9.u32);
	// bl 0x82a7bb08
	ctx.lr = 0x82A7C918;
	sub_82A7BB08(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A7C91C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7C930"))) PPC_WEAK_FUNC(sub_82A7C930);
PPC_FUNC_IMPL(__imp__sub_82A7C930) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r30,r31,640
	ctx.r30.s64 = ctx.r31.s64 + 640;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7C95C;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7ca0c
	if (ctx.cr0.lt) goto loc_82A7CA0C;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82a7c978
	if (ctx.cr6.eq) goto loc_82A7C978;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bne cr6,0x82a7c9ec
	if (!ctx.cr6.eq) goto loc_82A7C9EC;
loc_82A7C978:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,8
	ctx.r3.s64 = 8;
	// bl 0x8247f370
	ctx.lr = 0x82A7C984;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7c9a4
	if (ctx.cr0.eq) goto loc_82A7C9A4;
	// lwz r10,68(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lwz r9,648(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 648);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r9,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r9.u32);
	// b 0x82a7c9a8
	goto loc_82A7C9A8;
loc_82A7C9A4:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82A7C9A8:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r11,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r11.u32);
	// bne cr6,0x82a7c9c0
	if (!ctx.cr6.eq) goto loc_82A7C9C0;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82a7ca0c
	goto loc_82A7CA0C;
loc_82A7C9C0:
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7C9D0;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7ca0c
	if (ctx.cr0.lt) goto loc_82A7CA0C;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82a7ca08
	if (ctx.cr6.eq) goto loc_82A7CA08;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82a7ca08
	if (ctx.cr6.eq) goto loc_82A7CA08;
loc_82A7C9EC:
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82a7ca08
	if (ctx.cr6.eq) goto loc_82A7CA08;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82a7ca08
	if (ctx.cr6.eq) goto loc_82A7CA08;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82a862c0
	ctx.lr = 0x82A7CA08;
	sub_82A862C0(ctx, base);
loc_82A7CA08:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A7CA0C:
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7CA30"))) PPC_WEAK_FUNC(sub_82A7CA30);
PPC_FUNC_IMPL(__imp__sub_82A7CA30) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b0
	ctx.lr = 0x82A7CA38;
	__savegprlr_22(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// addi r27,r29,640
	ctx.r27.s64 = ctx.r29.s64 + 640;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7CA54;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7cdfc
	if (ctx.cr0.lt) goto loc_82A7CDFC;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82a7cdd8
	if (!ctx.cr6.eq) goto loc_82A7CDD8;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r31,r29,648
	ctx.r31.s64 = ctx.r29.s64 + 648;
	// addi r10,r11,23068
	ctx.r10.s64 = ctx.r11.s64 + 23068;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82A7CA78:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7ca9c
	if (ctx.cr0.eq) goto loc_82A7CA9C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7ca78
	if (ctx.cr6.eq) goto loc_82A7CA78;
loc_82A7CA9C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7cdd8
	if (!ctx.cr0.eq) goto loc_82A7CDD8;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7CAB4;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7cdfc
	if (ctx.cr0.lt) goto loc_82A7CDFC;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82a7cdd8
	if (!ctx.cr6.eq) goto loc_82A7CDD8;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r22,0(r31)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7CADC;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7cdfc
	if (ctx.cr0.lt) goto loc_82A7CDFC;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82a7cdd8
	if (!ctx.cr6.eq) goto loc_82A7CDD8;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// addi r24,r11,14828
	ctx.r24.s64 = ctx.r11.s64 + 14828;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
loc_82A7CB00:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7cb24
	if (ctx.cr0.eq) goto loc_82A7CB24;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7cb00
	if (ctx.cr6.eq) goto loc_82A7CB00;
loc_82A7CB24:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7cdd8
	if (!ctx.cr0.eq) goto loc_82A7CDD8;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7CB3C;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7cdfc
	if (ctx.cr0.lt) goto loc_82A7CDFC;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82a7cdd8
	if (!ctx.cr6.eq) goto loc_82A7CDD8;
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lwz r23,0(r31)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r26,0
	ctx.r26.s64 = 0;
	// addi r28,r1,96
	ctx.r28.s64 = ctx.r1.s64 + 96;
	// addi r25,r11,9232
	ctx.r25.s64 = ctx.r11.s64 + 9232;
loc_82A7CB64:
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// li r30,0
	ctx.r30.s64 = 0;
	// bl 0x82a86ed8
	ctx.lr = 0x82A7CB78;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7cdfc
	if (ctx.cr0.lt) goto loc_82A7CDFC;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82a7cdd8
	if (!ctx.cr6.eq) goto loc_82A7CDD8;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
loc_82A7CB94:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7cbb8
	if (ctx.cr0.eq) goto loc_82A7CBB8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7cb94
	if (ctx.cr6.eq) goto loc_82A7CB94;
loc_82A7CBB8:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7cdd8
	if (!ctx.cr0.eq) goto loc_82A7CDD8;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7CBD0;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7cdfc
	if (ctx.cr0.lt) goto loc_82A7CDFC;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82a7cc34
	if (!ctx.cr6.eq) goto loc_82A7CC34;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
loc_82A7CBEC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7cc10
	if (ctx.cr0.eq) goto loc_82A7CC10;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7cbec
	if (ctx.cr6.eq) goto loc_82A7CBEC;
loc_82A7CC10:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7cc34
	if (!ctx.cr0.eq) goto loc_82A7CC34;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// li r30,1
	ctx.r30.s64 = 1;
	// bl 0x82a86ed8
	ctx.lr = 0x82A7CC2C;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7cdfc
	if (ctx.cr0.lt) goto loc_82A7CDFC;
loc_82A7CC34:
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82a7cc74
	if (ctx.cr6.eq) goto loc_82A7CC74;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82a7cc64
	if (ctx.cr6.eq) goto loc_82A7CC64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// beq cr6,0x82a7cc74
	if (ctx.cr6.eq) goto loc_82A7CC74;
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// bgt cr6,0x82a7cdd8
	if (ctx.cr6.gt) goto loc_82A7CDD8;
	// lfd f0,0(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// b 0x82a7cc84
	goto loc_82A7CC84;
loc_82A7CC64:
	// lwa r11,0(r31)
	ctx.r11.s64 = int32_t(PPC_LOAD_U32(ctx.r31.u32 + 0));
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// b 0x82a7cc80
	goto loc_82A7CC80;
loc_82A7CC74:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
loc_82A7CC80:
	// fcfid f0,f0
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(ctx.f0.s64);
loc_82A7CC84:
	// stfd f0,0(r28)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r28.u32 + 0, ctx.f0.u64);
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq cr6,0x82a7cc98
	if (ctx.cr6.eq) goto loc_82A7CC98;
	// fneg f0,f0
	ctx.f0.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// stfd f0,0(r28)
	PPC_STORE_U64(ctx.r28.u32 + 0, ctx.f0.u64);
loc_82A7CC98:
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// addi r28,r28,8
	ctx.r28.s64 = ctx.r28.s64 + 8;
	// cmplwi cr6,r26,4
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 4, ctx.xer);
	// blt cr6,0x82a7cb64
	if (ctx.cr6.lt) goto loc_82A7CB64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7CCB8;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7cdfc
	if (ctx.cr0.lt) goto loc_82A7CDFC;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82a7cdd8
	if (!ctx.cr6.eq) goto loc_82A7CDD8;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r10,r11,17360
	ctx.r10.s64 = ctx.r11.s64 + 17360;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82A7CCD8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7ccfc
	if (ctx.cr0.eq) goto loc_82A7CCFC;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7ccd8
	if (ctx.cr6.eq) goto loc_82A7CCD8;
loc_82A7CCFC:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7cdd8
	if (!ctx.cr0.eq) goto loc_82A7CDD8;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7CD14;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7cdfc
	if (ctx.cr0.lt) goto loc_82A7CDFC;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82a7cd30
	if (ctx.cr6.eq) goto loc_82A7CD30;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// bne cr6,0x82a7cdd8
	if (!ctx.cr6.eq) goto loc_82A7CDD8;
loc_82A7CD30:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x8247f370
	ctx.lr = 0x82A7CD3C;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7cd54
	if (ctx.cr0.eq) goto loc_82A7CD54;
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stw r11,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r11.u32);
	// b 0x82a7cd58
	goto loc_82A7CD58;
loc_82A7CD54:
	// li r31,0
	ctx.r31.s64 = 0;
loc_82A7CD58:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82a7cd6c
	if (!ctx.cr6.eq) goto loc_82A7CD6C;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82a7cdfc
	goto loc_82A7CDFC;
loc_82A7CD6C:
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// stw r22,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r22.u32);
	// addi r30,r29,64
	ctx.r30.s64 = ctx.r29.s64 + 64;
	// stw r23,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r23.u32);
	// ld r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// ld r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// ld r8,16(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// std r10,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r10.u64);
	// std r9,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r9.u64);
	// std r8,24(r31)
	PPC_STORE_U64(ctx.r31.u32 + 24, ctx.r8.u64);
	// std r11,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r11.u64);
	// b 0x82a7cdbc
	goto loc_82A7CDBC;
loc_82A7CDA0:
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82d61e20
	ctx.lr = 0x82A7CDAC;
	sub_82D61E20(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a7cdc8
	if (!ctx.cr0.lt) goto loc_82A7CDC8;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r30,r11,40
	ctx.r30.s64 = ctx.r11.s64 + 40;
loc_82A7CDBC:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82a7cda0
	if (!ctx.cr0.eq) goto loc_82A7CDA0;
loc_82A7CDC8:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// stw r11,40(r31)
	PPC_STORE_U32(ctx.r31.u32 + 40, ctx.r11.u32);
	// stw r31,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r31.u32);
	// b 0x82a7cdf8
	goto loc_82A7CDF8;
loc_82A7CDD8:
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82a7cdf8
	if (ctx.cr6.eq) goto loc_82A7CDF8;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82a7cdf8
	if (ctx.cr6.eq) goto loc_82A7CDF8;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// bl 0x82a862c0
	ctx.lr = 0x82A7CDF8;
	sub_82A862C0(ctx, base);
loc_82A7CDF8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A7CDFC:
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,76(r29)
	PPC_STORE_U32(ctx.r29.u32 + 76, ctx.r11.u32);
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82d5c500
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7CE10"))) PPC_WEAK_FUNC(sub_82A7CE10);
PPC_FUNC_IMPL(__imp__sub_82A7CE10) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A7CE18;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r29,0(r28)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82a7b540
	ctx.lr = 0x82A7CE30;
	sub_82A7B540(ctx, base);
	// addi r11,r3,30
	ctx.r11.s64 = ctx.r3.s64 + 30;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r31,r11,r30
	ctx.r31.u64 = ctx.r11.u64 + ctx.r30.u64;
	// b 0x82a7ce84
	goto loc_82A7CE84;
loc_82A7CE40:
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
loc_82A7CE4C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7ce70
	if (ctx.cr0.eq) goto loc_82A7CE70;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7ce4c
	if (ctx.cr6.eq) goto loc_82A7CE4C;
loc_82A7CE70:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// blt 0x82a7cee4
	if (ctx.cr0.lt) goto loc_82A7CEE4;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7ce94
	if (ctx.cr6.eq) goto loc_82A7CE94;
	// addi r31,r7,12
	ctx.r31.s64 = ctx.r7.s64 + 12;
loc_82A7CE84:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a7ce40
	if (!ctx.cr6.eq) goto loc_82A7CE40;
	// b 0x82a7cee4
	goto loc_82A7CEE4;
loc_82A7CE94:
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82a7b590
	ctx.lr = 0x82A7CEA4;
	sub_82A7B590(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a7cec8
	if (!ctx.cr0.eq) goto loc_82A7CEC8;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// addi r6,r11,-22060
	ctx.r6.s64 = ctx.r11.s64 + -22060;
	// li r5,1519
	ctx.r5.s64 = 1519;
	// addi r4,r30,640
	ctx.r4.s64 = ctx.r30.s64 + 640;
	// addi r3,r30,24
	ctx.r3.s64 = ctx.r30.s64 + 24;
	// bl 0x82a85e58
	ctx.lr = 0x82A7CEC8;
	sub_82A85E58(ctx, base);
loc_82A7CEC8:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r11,0
	ctx.r11.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r11.u32);
	// bl 0x82a7bb08
	ctx.lr = 0x82A7CEE4;
	sub_82A7BB08(ctx, base);
loc_82A7CEE4:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,12(r28)
	PPC_STORE_U32(ctx.r28.u32 + 12, ctx.r11.u32);
	// stw r28,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r28.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7CF00"))) PPC_WEAK_FUNC(sub_82A7CF00);
PPC_FUNC_IMPL(__imp__sub_82A7CF00) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x8247f370
	ctx.lr = 0x82A7CF28;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7cf50
	if (ctx.cr0.eq) goto loc_82A7CF50;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r31.u32);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r11.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r11.u32);
	// b 0x82a7cf54
	goto loc_82A7CF54;
loc_82A7CF50:
	// li r4,0
	ctx.r4.s64 = 0;
loc_82A7CF54:
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne cr6,0x82a7cf68
	if (!ctx.cr6.eq) goto loc_82A7CF68;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82a7cf70
	goto loc_82A7CF70;
loc_82A7CF68:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82a7ce10
	ctx.lr = 0x82A7CF70;
	sub_82A7CE10(ctx, base);
loc_82A7CF70:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7CF88"))) PPC_WEAK_FUNC(sub_82A7CF88);
PPC_FUNC_IMPL(__imp__sub_82A7CF88) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A7CF90;
	__savegprlr_28(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x8247f370
	ctx.lr = 0x82A7CFAC;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// li r31,0
	ctx.r31.s64 = 0;
	// beq 0x82a7cfd4
	if (ctx.cr0.eq) goto loc_82A7CFD4;
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r30.u32);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r31.u32);
	// b 0x82a7cfd8
	goto loc_82A7CFD8;
loc_82A7CFD4:
	// mr r30,r31
	ctx.r30.u64 = ctx.r31.u64;
loc_82A7CFD8:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82a7cfec
	if (!ctx.cr6.eq) goto loc_82A7CFEC;
loc_82A7CFE0:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82a7d040
	goto loc_82A7D040;
loc_82A7CFEC:
	// li r11,2
	ctx.r11.s64 = 2;
	// stw r29,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r29.u32);
	// li r3,48
	ctx.r3.s64 = 48;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// bl 0x82ab71b8
	ctx.lr = 0x82A7D000;
	sub_82AB71B8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7d014
	if (ctx.cr0.eq) goto loc_82A7D014;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82ab77d8
	ctx.lr = 0x82A7D010;
	sub_82AB77D8(ctx, base);
	// b 0x82a7d018
	goto loc_82A7D018;
loc_82A7D014:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82A7D018:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r3.u32);
	// bne cr6,0x82a7d034
	if (!ctx.cr6.eq) goto loc_82A7D034;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82a7bb08
	ctx.lr = 0x82A7D030;
	sub_82A7BB08(ctx, base);
	// b 0x82a7cfe0
	goto loc_82A7CFE0;
loc_82A7D034:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82a7ce10
	ctx.lr = 0x82A7D040;
	sub_82A7CE10(ctx, base);
loc_82A7D040:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7D048"))) PPC_WEAK_FUNC(sub_82A7D048);
PPC_FUNC_IMPL(__imp__sub_82A7D048) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r11,r11,-21964
	ctx.r11.s64 = ctx.r11.s64 + -21964;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82A7D068:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7d08c
	if (ctx.cr0.eq) goto loc_82A7D08C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7d068
	if (ctx.cr6.eq) goto loc_82A7D068;
loc_82A7D08C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7d09c
	if (!ctx.cr0.eq) goto loc_82A7D09C;
	// lwz r3,660(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 660);
	// b 0x82a7d12c
	goto loc_82A7D12C;
loc_82A7D09C:
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7b920
	ctx.lr = 0x82A7D0AC;
	sub_82A7B920(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a7d128
	if (ctx.cr0.eq) goto loc_82A7D128;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7d0e0
	if (ctx.cr6.eq) goto loc_82A7D0E0;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1517
	ctx.r5.s64 = 1517;
	// addi r6,r11,-22032
	ctx.r6.s64 = ctx.r11.s64 + -22032;
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82a85c20
	ctx.lr = 0x82A7D0D8;
	sub_82A85C20(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82a7d12c
	goto loc_82A7D12C;
loc_82A7D0E0:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7d110
	if (ctx.cr6.eq) goto loc_82A7D110;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82a7d110
	if (!ctx.cr6.eq) goto loc_82A7D110;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// cmplwi cr6,r10,2
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 2, ctx.xer);
	// bgt cr6,0x82a7d110
	if (ctx.cr6.gt) goto loc_82A7D110;
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// b 0x82a7d12c
	goto loc_82A7D12C;
loc_82A7D110:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1518
	ctx.r5.s64 = 1518;
	// addi r6,r11,-22224
	ctx.r6.s64 = ctx.r11.s64 + -22224;
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82a85c20
	ctx.lr = 0x82A7D128;
	sub_82A85C20(ctx, base);
loc_82A7D128:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A7D12C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7D140"))) PPC_WEAK_FUNC(sub_82A7D140);
PPC_FUNC_IMPL(__imp__sub_82A7D140) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r11,1
	ctx.r11.s64 = 1;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// lwz r10,92(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82a7d214
	if (ctx.cr6.eq) goto loc_82A7D214;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r11,-21916
	ctx.r10.s64 = ctx.r11.s64 + -21916;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
loc_82A7D178:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7d19c
	if (ctx.cr0.eq) goto loc_82A7D19C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7d178
	if (ctx.cr6.eq) goto loc_82A7D178;
loc_82A7D19C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7d1e8
	if (!ctx.cr0.eq) goto loc_82A7D1E8;
	// lwz r11,88(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a7d1d4
	if (ctx.cr6.eq) goto loc_82A7D1D4;
	// lwz r11,640(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82a7d1d4
	if (!ctx.cr6.eq) goto loc_82A7D1D4;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lwz r7,648(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 648);
	// li r5,1504
	ctx.r5.s64 = 1504;
	// addi r6,r11,-21952
	ctx.r6.s64 = ctx.r11.s64 + -21952;
	// b 0x82a7d20c
	goto loc_82A7D20C;
loc_82A7D1D4:
	// addi r5,r31,640
	ctx.r5.s64 = ctx.r31.s64 + 640;
	// li r4,1500
	ctx.r4.s64 = 1500;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82a86128
	ctx.lr = 0x82A7D1E4;
	sub_82A86128(ctx, base);
	// b 0x82a7d214
	goto loc_82A7D214;
loc_82A7D1E8:
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r4,256
	ctx.r4.s64 = 256;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82a77140
	ctx.lr = 0x82A7D1F8;
	sub_82A77140(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// addi r6,r11,-5096
	ctx.r6.s64 = ctx.r11.s64 + -5096;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
loc_82A7D20C:
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82a85c20
	ctx.lr = 0x82A7D214;
	sub_82A85C20(ctx, base);
loc_82A7D214:
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7D228"))) PPC_WEAK_FUNC(sub_82A7D228);
PPC_FUNC_IMPL(__imp__sub_82A7D228) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b4
	ctx.lr = 0x82A7D230;
	__savegprlr_23(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x8247f370
	ctx.lr = 0x82A7D24C;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// li r24,0
	ctx.r24.s64 = 0;
	// beq 0x82a7d274
	if (ctx.cr0.eq) goto loc_82A7D274;
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r30.u32);
	// mr r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	// stw r24,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r24.u32);
	// stw r24,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r24.u32);
	// stw r24,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r24.u32);
	// stw r24,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r24.u32);
	// b 0x82a7d278
	goto loc_82A7D278;
loc_82A7D274:
	// mr r23,r24
	ctx.r23.u64 = ctx.r24.u64;
loc_82A7D278:
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82a7d550
	if (ctx.cr6.eq) goto loc_82A7D550;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq cr6,0x82a7d464
	if (ctx.cr6.eq) goto loc_82A7D464;
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82a7d464
	if (!ctx.cr6.lt) goto loc_82A7D464;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// lbz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r11,40
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 40, ctx.xer);
	// bne cr6,0x82a7d464
	if (!ctx.cr6.eq) goto loc_82A7D464;
	// addi r28,r31,640
	ctx.r28.s64 = ctx.r31.s64 + 640;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// addi r27,r23,4
	ctx.r27.s64 = ctx.r23.s64 + 4;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r29,r27
	ctx.r29.u64 = ctx.r27.u64;
	// bl 0x82a86ed8
	ctx.lr = 0x82A7D2C4;
	sub_82A86ED8(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7d580
	if (ctx.cr0.lt) goto loc_82A7D580;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// addi r26,r11,14828
	ctx.r26.s64 = ctx.r11.s64 + 14828;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r25,r11,-21900
	ctx.r25.s64 = ctx.r11.s64 + -21900;
loc_82A7D2DC:
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7D2EC;
	sub_82A86ED8(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7d580
	if (ctx.cr0.lt) goto loc_82A7D580;
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82a7d428
	if (!ctx.cr6.eq) goto loc_82A7D428;
	// lwz r6,0(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmplwi r6,0
	ctx.cr0.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq 0x82a7d368
	if (ctx.cr0.eq) goto loc_82A7D368;
	// lwz r7,648(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 648);
loc_82A7D310:
	// lwz r10,24(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 24);
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_82A7D318:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7d33c
	if (ctx.cr0.eq) goto loc_82A7D33C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7d318
	if (ctx.cr6.eq) goto loc_82A7D318;
loc_82A7D33C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a7d354
	if (ctx.cr0.eq) goto loc_82A7D354;
	// lwz r6,12(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 12);
	// cmplwi r6,0
	ctx.cr0.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// bne 0x82a7d310
	if (!ctx.cr0.eq) goto loc_82A7D310;
	// b 0x82a7d368
	goto loc_82A7D368;
loc_82A7D354:
	// mr r6,r25
	ctx.r6.u64 = ctx.r25.u64;
	// li r5,1511
	ctx.r5.s64 = 1511;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82a85c20
	ctx.lr = 0x82A7D368;
	sub_82A85C20(ctx, base);
loc_82A7D368:
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82ab71b8
	ctx.lr = 0x82A7D370;
	sub_82AB71B8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7d384
	if (ctx.cr0.eq) goto loc_82A7D384;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82ab77d8
	ctx.lr = 0x82A7D380;
	sub_82AB77D8(ctx, base);
	// b 0x82a7d388
	goto loc_82A7D388;
loc_82A7D384:
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
loc_82A7D388:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82a7d550
	if (ctx.cr6.eq) goto loc_82A7D550;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// addi r29,r3,12
	ctx.r29.s64 = ctx.r3.s64 + 12;
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7D3A8;
	sub_82A86ED8(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7d580
	if (ctx.cr0.lt) goto loc_82A7D580;
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82a7d428
	if (!ctx.cr6.eq) goto loc_82A7D428;
	// addi r10,r31,648
	ctx.r10.s64 = ctx.r31.s64 + 648;
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
loc_82A7D3C4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7d3e8
	if (ctx.cr0.eq) goto loc_82A7D3E8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7d3c4
	if (ctx.cr6.eq) goto loc_82A7D3C4;
loc_82A7D3E8:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a7d2dc
	if (ctx.cr0.eq) goto loc_82A7D2DC;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r10,r31,648
	ctx.r10.s64 = ctx.r31.s64 + 648;
	// addi r11,r11,17360
	ctx.r11.s64 = ctx.r11.s64 + 17360;
loc_82A7D3FC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7d420
	if (ctx.cr0.eq) goto loc_82A7D420;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7d3fc
	if (ctx.cr6.eq) goto loc_82A7D3FC;
loc_82A7D420:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a7d464
	if (ctx.cr0.eq) goto loc_82A7D464;
loc_82A7D428:
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// li r29,1
	ctx.r29.s64 = 1;
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82a7d440
	if (ctx.cr6.eq) goto loc_82A7D440;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// bne cr6,0x82a7d444
	if (!ctx.cr6.eq) goto loc_82A7D444;
loc_82A7D440:
	// stw r29,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r29.u32);
loc_82A7D444:
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,1500
	ctx.r4.s64 = 1500;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82a86128
	ctx.lr = 0x82A7D454;
	sub_82A86128(ctx, base);
	// lis r30,-32768
	ctx.r30.s64 = -2147483648;
	// stw r29,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r29.u32);
	// ori r30,r30,16389
	ctx.r30.u64 = ctx.r30.u64 | 16389;
	// b 0x82a7d580
	goto loc_82A7D580;
loc_82A7D464:
	// addi r28,r23,8
	ctx.r28.s64 = ctx.r23.s64 + 8;
loc_82A7D468:
	// lwz r10,112(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// addi r29,r31,640
	ctx.r29.s64 = ctx.r31.s64 + 640;
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq 0x82a7d4c0
	if (ctx.cr0.eq) goto loc_82A7D4C0;
	// addi r11,r10,16
	ctx.r11.s64 = ctx.r10.s64 + 16;
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// std r9,0(r29)
	PPC_STORE_U64(ctx.r29.u32 + 0, ctx.r9.u64);
	// ld r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// std r9,8(r29)
	PPC_STORE_U64(ctx.r29.u32 + 8, ctx.r9.u64);
	// ld r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// std r9,16(r29)
	PPC_STORE_U64(ctx.r29.u32 + 16, ctx.r9.u64);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// std r11,24(r29)
	PPC_STORE_U64(ctx.r29.u32 + 24, ctx.r11.u64);
	// lwz r11,12(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// stw r11,112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 112, ctx.r11.u32);
	// stw r24,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r24.u32);
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// stw r10,656(r31)
	PPC_STORE_U32(ctx.r31.u32 + 656, ctx.r10.u32);
	// lwz r11,28(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// stw r11,660(r31)
	PPC_STORE_U32(ctx.r31.u32 + 660, ctx.r11.u32);
	// b 0x82a7d4d8
	goto loc_82A7D4D8;
loc_82A7D4C0:
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7D4D0;
	sub_82A86ED8(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7d580
	if (ctx.cr0.lt) goto loc_82A7D580;
loc_82A7D4D8:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82a7d55c
	if (ctx.cr6.eq) goto loc_82A7D55C;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82a7d55c
	if (ctx.cr6.eq) goto loc_82A7D55C;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82ab71b8
	ctx.lr = 0x82A7D4F4;
	sub_82AB71B8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7d50c
	if (ctx.cr0.eq) goto loc_82A7D50C;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82ab77d8
	ctx.lr = 0x82A7D504;
	sub_82AB77D8(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// b 0x82a7d510
	goto loc_82A7D510;
loc_82A7D50C:
	// mr r30,r24
	ctx.r30.u64 = ctx.r24.u64;
loc_82A7D510:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82a7d550
	if (ctx.cr6.eq) goto loc_82A7D550;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,668(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 668);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82ab7070
	ctx.lr = 0x82A7D528;
	sub_82AB7070(ctx, base);
	// mr. r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq 0x82a7d550
	if (ctx.cr0.eq) goto loc_82A7D550;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r5,668(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 668);
	// lwz r4,664(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 664);
	// bl 0x82d5c630
	ctx.lr = 0x82A7D540;
	sub_82D5C630(ctx, base);
	// stw r29,40(r30)
	PPC_STORE_U32(ctx.r30.u32 + 40, ctx.r29.u32);
	// stw r30,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r30.u32);
	// addi r28,r30,12
	ctx.r28.s64 = ctx.r30.s64 + 12;
	// b 0x82a7d468
	goto loc_82A7D468;
loc_82A7D550:
	// lis r30,-32761
	ctx.r30.s64 = -2147024896;
	// ori r30,r30,14
	ctx.r30.u64 = ctx.r30.u64 | 14;
	// b 0x82a7d580
	goto loc_82A7D580;
loc_82A7D55C:
	// li r11,1
	ctx.r11.s64 = 1;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r11.u32);
	// bl 0x82a7ce10
	ctx.lr = 0x82A7D570;
	sub_82A7CE10(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7d580
	if (ctx.cr0.lt) goto loc_82A7D580;
	// mr r23,r24
	ctx.r23.u64 = ctx.r24.u64;
	// mr r30,r24
	ctx.r30.u64 = ctx.r24.u64;
loc_82A7D580:
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82a7d594
	if (ctx.cr6.eq) goto loc_82A7D594;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82a7bb08
	ctx.lr = 0x82A7D594;
	sub_82A7BB08(ctx, base);
loc_82A7D594:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82d5c504
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7D5A0"))) PPC_WEAK_FUNC(sub_82A7D5A0);
PPC_FUNC_IMPL(__imp__sub_82A7D5A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A7D5A8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r30,r31,640
	ctx.r30.s64 = ctx.r31.s64 + 640;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7D5C4;
	sub_82A86ED8(ctx, base);
	// li r29,1
	ctx.r29.s64 = 1;
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7d738
	if (ctx.cr0.lt) goto loc_82A7D738;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82a7d714
	if (!ctx.cr6.eq) goto loc_82A7D714;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lwz r7,648(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 648);
	// stw r29,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r29.u32);
	// addi r10,r11,-21812
	ctx.r10.s64 = ctx.r11.s64 + -21812;
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_82A7D5F0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7d614
	if (ctx.cr0.eq) goto loc_82A7D614;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7d5f0
	if (ctx.cr6.eq) goto loc_82A7D5F0;
loc_82A7D614:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7d628
	if (!ctx.cr0.eq) goto loc_82A7D628;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7adc0
	ctx.lr = 0x82A7D624;
	sub_82A7ADC0(ctx, base);
	// b 0x82a7d73c
	goto loc_82A7D73C;
loc_82A7D628:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r11,-21820
	ctx.r10.s64 = ctx.r11.s64 + -21820;
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_82A7D634:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7d658
	if (ctx.cr0.eq) goto loc_82A7D658;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7d634
	if (ctx.cr6.eq) goto loc_82A7D634;
loc_82A7D658:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7d66c
	if (!ctx.cr0.eq) goto loc_82A7D66C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7afb8
	ctx.lr = 0x82A7D668;
	sub_82A7AFB8(ctx, base);
	// b 0x82a7d73c
	goto loc_82A7D73C;
loc_82A7D66C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r11,-21824
	ctx.r10.s64 = ctx.r11.s64 + -21824;
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_82A7D678:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7d69c
	if (ctx.cr0.eq) goto loc_82A7D69C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7d678
	if (ctx.cr6.eq) goto loc_82A7D678;
loc_82A7D69C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7d6b0
	if (!ctx.cr0.eq) goto loc_82A7D6B0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7ca30
	ctx.lr = 0x82A7D6AC;
	sub_82A7CA30(ctx, base);
	// b 0x82a7d73c
	goto loc_82A7D73C;
loc_82A7D6B0:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r11,-21836
	ctx.r10.s64 = ctx.r11.s64 + -21836;
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_82A7D6BC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7d6e0
	if (ctx.cr0.eq) goto loc_82A7D6E0;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7d6bc
	if (ctx.cr6.eq) goto loc_82A7D6BC;
loc_82A7D6E0:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7d6f4
	if (!ctx.cr0.eq) goto loc_82A7D6F4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7c930
	ctx.lr = 0x82A7D6F0;
	sub_82A7C930(ctx, base);
	// b 0x82a7d73c
	goto loc_82A7D73C;
loc_82A7D6F4:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,3568
	ctx.r5.s64 = 3568;
	// addi r6,r11,-21868
	ctx.r6.s64 = ctx.r11.s64 + -21868;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82a85e58
	ctx.lr = 0x82A7D70C;
	sub_82A85E58(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,668(r31)
	PPC_STORE_U32(ctx.r31.u32 + 668, ctx.r11.u32);
loc_82A7D714:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82a7d734
	if (ctx.cr6.eq) goto loc_82A7D734;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82a7d734
	if (ctx.cr6.eq) goto loc_82A7D734;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82a862c0
	ctx.lr = 0x82A7D734;
	sub_82A862C0(ctx, base);
loc_82A7D734:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A7D738:
	// stw r29,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r29.u32);
loc_82A7D73C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7D748"))) PPC_WEAK_FUNC(sub_82A7D748);
PPC_FUNC_IMPL(__imp__sub_82A7D748) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// lwz r3,3032(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 3032);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82a7d140
	ctx.lr = 0x82A7D784;
	sub_82A7D140(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7D798"))) PPC_WEAK_FUNC(sub_82A7D798);
PPC_FUNC_IMPL(__imp__sub_82A7D798) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4bc
	ctx.lr = 0x82A7D7A0;
	__savegprlr_25(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// li r31,0
	ctx.r31.s64 = 0;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// std r31,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r31.u64);
	// std r31,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r31.u64);
	// std r31,16(r11)
	PPC_STORE_U64(ctx.r11.u32 + 16, ctx.r31.u64);
	// std r31,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r31.u64);
	// lwz r25,632(r27)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r27.u32 + 632);
	// bl 0x8247f370
	ctx.lr = 0x82A7D7D4;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7d800
	if (ctx.cr0.eq) goto loc_82A7D800;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// addi r11,r11,-21696
	ctx.r11.s64 = ctx.r11.s64 + -21696;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r31.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// b 0x82a7d804
	goto loc_82A7D804;
loc_82A7D800:
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82A7D804:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82a7dac4
	if (ctx.cr6.eq) goto loc_82A7DAC4;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82a7ce10
	ctx.lr = 0x82A7D818;
	sub_82A7CE10(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7dbd0
	if (ctx.cr0.lt) goto loc_82A7DBD0;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x8247f370
	ctx.lr = 0x82A7D82C;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7d858
	if (ctx.cr0.eq) goto loc_82A7D858;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// addi r11,r11,-21704
	ctx.r11.s64 = ctx.r11.s64 + -21704;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r31.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// b 0x82a7d85c
	goto loc_82A7D85C;
loc_82A7D858:
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82A7D85C:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82a7dac4
	if (ctx.cr6.eq) goto loc_82A7DAC4;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82a7ce10
	ctx.lr = 0x82A7D870;
	sub_82A7CE10(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7dbd0
	if (ctx.cr0.lt) goto loc_82A7DBD0;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x8247f370
	ctx.lr = 0x82A7D884;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7d8b0
	if (ctx.cr0.eq) goto loc_82A7D8B0;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// addi r11,r11,-21720
	ctx.r11.s64 = ctx.r11.s64 + -21720;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r31.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// b 0x82a7d8b4
	goto loc_82A7D8B4;
loc_82A7D8B0:
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82A7D8B4:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82a7dac4
	if (ctx.cr6.eq) goto loc_82A7DAC4;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82a7ce10
	ctx.lr = 0x82A7D8C8;
	sub_82A7CE10(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7dbd0
	if (ctx.cr0.lt) goto loc_82A7DBD0;
	// li r28,2
	ctx.r28.s64 = 2;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// stw r28,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r28.u32);
	// bl 0x8247f370
	ctx.lr = 0x82A7D8E8;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7d914
	if (ctx.cr0.eq) goto loc_82A7D914;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// addi r11,r11,-21736
	ctx.r11.s64 = ctx.r11.s64 + -21736;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r31.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// b 0x82a7d918
	goto loc_82A7D918;
loc_82A7D914:
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82A7D918:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82a7dac4
	if (ctx.cr6.eq) goto loc_82A7DAC4;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82ab71b8
	ctx.lr = 0x82A7D928;
	sub_82AB71B8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7d93c
	if (ctx.cr0.eq) goto loc_82A7D93C;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82ab77d8
	ctx.lr = 0x82A7D938;
	sub_82AB77D8(ctx, base);
	// b 0x82a7d940
	goto loc_82A7D940;
loc_82A7D93C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82A7D940:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r3.u32);
	// beq cr6,0x82a7dac4
	if (ctx.cr6.eq) goto loc_82A7DAC4;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82a7ce10
	ctx.lr = 0x82A7D958;
	sub_82A7CE10(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7dbd0
	if (ctx.cr0.lt) goto loc_82A7DBD0;
	// li r11,2560
	ctx.r11.s64 = 2560;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// bl 0x8247f370
	ctx.lr = 0x82A7D978;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7d9a4
	if (ctx.cr0.eq) goto loc_82A7D9A4;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// addi r11,r11,-21756
	ctx.r11.s64 = ctx.r11.s64 + -21756;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r31.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// b 0x82a7d9a8
	goto loc_82A7D9A8;
loc_82A7D9A4:
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82A7D9A8:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82a7dac4
	if (ctx.cr6.eq) goto loc_82A7DAC4;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82ab71b8
	ctx.lr = 0x82A7D9B8;
	sub_82AB71B8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7d9cc
	if (ctx.cr0.eq) goto loc_82A7D9CC;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82ab77d8
	ctx.lr = 0x82A7D9C8;
	sub_82AB77D8(ctx, base);
	// b 0x82a7d9d0
	goto loc_82A7D9D0;
loc_82A7D9CC:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82A7D9D0:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r3.u32);
	// beq cr6,0x82a7dac4
	if (ctx.cr6.eq) goto loc_82A7DAC4;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82a7ce10
	ctx.lr = 0x82A7D9E8;
	sub_82A7CE10(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7dbd0
	if (ctx.cr0.lt) goto loc_82A7DBD0;
	// li r11,2589
	ctx.r11.s64 = 2589;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// bl 0x8247f370
	ctx.lr = 0x82A7DA08;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7da34
	if (ctx.cr0.eq) goto loc_82A7DA34;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// addi r11,r11,-21772
	ctx.r11.s64 = ctx.r11.s64 + -21772;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r31.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// b 0x82a7da38
	goto loc_82A7DA38;
loc_82A7DA34:
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82A7DA38:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82a7dac4
	if (ctx.cr6.eq) goto loc_82A7DAC4;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82ab71b8
	ctx.lr = 0x82A7DA48;
	sub_82AB71B8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7da5c
	if (ctx.cr0.eq) goto loc_82A7DA5C;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82ab77d8
	ctx.lr = 0x82A7DA58;
	sub_82AB77D8(ctx, base);
	// b 0x82a7da60
	goto loc_82A7DA60;
loc_82A7DA5C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82A7DA60:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r3.u32);
	// beq cr6,0x82a7dac4
	if (ctx.cr6.eq) goto loc_82A7DAC4;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82a7ce10
	ctx.lr = 0x82A7DA78;
	sub_82A7CE10(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7dbd0
	if (ctx.cr0.lt) goto loc_82A7DBD0;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x8247f370
	ctx.lr = 0x82A7DA8C;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7dab8
	if (ctx.cr0.eq) goto loc_82A7DAB8;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// addi r11,r11,-21780
	ctx.r11.s64 = ctx.r11.s64 + -21780;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r31.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// b 0x82a7dabc
	goto loc_82A7DABC;
loc_82A7DAB8:
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82A7DABC:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82a7dad0
	if (!ctx.cr6.eq) goto loc_82A7DAD0;
loc_82A7DAC4:
	// lis r30,-32761
	ctx.r30.s64 = -2147024896;
	// ori r30,r30,14
	ctx.r30.u64 = ctx.r30.u64 | 14;
	// b 0x82a7dbd0
	goto loc_82A7DBD0;
loc_82A7DAD0:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82a7ce10
	ctx.lr = 0x82A7DADC;
	sub_82A7CE10(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7dbd0
	if (ctx.cr0.lt) goto loc_82A7DBD0;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// addi r4,r11,-21788
	ctx.r4.s64 = ctx.r11.s64 + -21788;
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
	// bl 0x82a7cf00
	ctx.lr = 0x82A7DAF8;
	sub_82A7CF00(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7dbd0
	if (ctx.cr0.lt) goto loc_82A7DBD0;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,200
	ctx.r5.s64 = 200;
	// addi r4,r11,-21800
	ctx.r4.s64 = ctx.r11.s64 + -21800;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82a7cf88
	ctx.lr = 0x82A7DB14;
	sub_82A7CF88(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7dbd0
	if (ctx.cr0.lt) goto loc_82A7DBD0;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a7dbcc
	if (ctx.cr6.eq) goto loc_82A7DBCC;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82a850b0
	ctx.lr = 0x82A7DB2C;
	sub_82A850B0(ctx, base);
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// stw r11,632(r27)
	PPC_STORE_U32(ctx.r27.u32 + 632, ctx.r11.u32);
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7dbc4
	if (ctx.cr6.eq) goto loc_82A7DBC4;
	// addi r28,r27,24
	ctx.r28.s64 = ctx.r27.s64 + 24;
loc_82A7DB44:
	// lwz r4,4(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// cmplwi r4,0
	ctx.cr0.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq 0x82a7db78
	if (ctx.cr0.eq) goto loc_82A7DB78;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A7DB58:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82a7db58
	if (!ctx.cr6.eq) goto loc_82A7DB58;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r5,r11,0
	ctx.r5.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// b 0x82a7db7c
	goto loc_82A7DB7C;
loc_82A7DB78:
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
loc_82A7DB7C:
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82a850d8
	ctx.lr = 0x82A7DB94;
	sub_82A850D8(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7dbf4
	if (ctx.cr0.lt) goto loc_82A7DBF4;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,0(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82a7d228
	ctx.lr = 0x82A7DBAC;
	sub_82A7D228(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82a7dbf4
	if (ctx.cr0.lt) goto loc_82A7DBF4;
	// addi r26,r26,8
	ctx.r26.s64 = ctx.r26.s64 + 8;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a7db44
	if (!ctx.cr6.eq) goto loc_82A7DB44;
loc_82A7DBC4:
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82d09218
	ctx.lr = 0x82A7DBCC;
	sub_82D09218(ctx, base);
loc_82A7DBCC:
	// mr r30,r31
	ctx.r30.u64 = ctx.r31.u64;
loc_82A7DBD0:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// stw r25,632(r27)
	PPC_STORE_U32(ctx.r27.u32 + 632, ctx.r25.u32);
	// beq cr6,0x82a7dbe8
	if (ctx.cr6.eq) goto loc_82A7DBE8;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82a7bb08
	ctx.lr = 0x82A7DBE8;
	sub_82A7BB08(ctx, base);
loc_82A7DBE8:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82d5c50c
	__restgprlr_25(ctx, base);
	return;
loc_82A7DBF4:
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82d09218
	ctx.lr = 0x82A7DBFC;
	sub_82D09218(ctx, base);
	// b 0x82a7dbd0
	goto loc_82A7DBD0;
}

__attribute__((alias("__imp__sub_82A7DC00"))) PPC_WEAK_FUNC(sub_82A7DC00);
PPC_FUNC_IMPL(__imp__sub_82A7DC00) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82a7d140
	ctx.lr = 0x82A7DC38;
	sub_82A7D140(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7DC48"))) PPC_WEAK_FUNC(sub_82A7DC48);
PPC_FUNC_IMPL(__imp__sub_82A7DC48) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4bc
	ctx.lr = 0x82A7DC50;
	__savegprlr_25(ctx, base);
	// stwu r1,-432(r1)
	ea = -432 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r27,r31,640
	ctx.r27.s64 = ctx.r31.s64 + 640;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r11,672(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// ori r4,r11,12
	ctx.r4.u64 = ctx.r11.u64 | 12;
	// bl 0x82a86ed8
	ctx.lr = 0x82A7DC70;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7de6c
	if (ctx.cr0.lt) goto loc_82A7DE6C;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// li r26,1
	ctx.r26.s64 = 1;
	// cmpwi cr6,r11,10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 10, ctx.xer);
	// beq cr6,0x82a7dcb4
	if (ctx.cr6.eq) goto loc_82A7DCB4;
	// cmpwi cr6,r11,11
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 11, ctx.xer);
	// beq cr6,0x82a7dcac
	if (ctx.cr6.eq) goto loc_82A7DCAC;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-21916
	ctx.r4.s64 = ctx.r11.s64 + -21916;
	// bl 0x82a7dc00
	ctx.lr = 0x82A7DCA0;
	sub_82A7DC00(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82a7de6c
	goto loc_82A7DE6C;
loc_82A7DCAC:
	// mr r25,r26
	ctx.r25.u64 = ctx.r26.u64;
	// b 0x82a7dcb8
	goto loc_82A7DCB8;
loc_82A7DCB4:
	// li r25,0
	ctx.r25.s64 = 0;
loc_82A7DCB8:
	// lwz r9,636(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 636);
	// lwz r28,648(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 648);
	// cmplwi r9,0
	ctx.cr0.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne 0x82a7dd04
	if (!ctx.cr0.eq) goto loc_82A7DD04;
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a7dd04
	if (!ctx.cr6.eq) goto loc_82A7DD04;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1505
	ctx.r5.s64 = 1505;
	// addi r6,r11,-21656
	ctx.r6.s64 = ctx.r11.s64 + -21656;
loc_82A7DCE4:
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82a85c20
	ctx.lr = 0x82A7DCF0;
	sub_82A85C20(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// stw r26,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r26.u32);
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// stw r26,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r26.u32);
	// b 0x82a7de6c
	goto loc_82A7DE6C;
loc_82A7DD04:
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a7dd3c
	if (ctx.cr0.eq) goto loc_82A7DD3C;
loc_82A7DD14:
	// lwz r11,92(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82a7dd14
	if (!ctx.cr0.eq) goto loc_82A7DD14;
	// cmplwi cr6,r10,32
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 32, ctx.xer);
	// blt cr6,0x82a7dd3c
	if (ctx.cr6.lt) goto loc_82A7DD3C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1506
	ctx.r5.s64 = 1506;
	// addi r6,r11,-21684
	ctx.r6.s64 = ctx.r11.s64 + -21684;
	// b 0x82a7dce4
	goto loc_82A7DCE4;
loc_82A7DD3C:
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82a7dd80
	if (!ctx.cr6.eq) goto loc_82A7DD80;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82a3b940
	ctx.lr = 0x82A7DD4C;
	sub_82A3B940(ctx, base);
	// cmpwi cr6,r3,-1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, -1, ctx.xer);
	// beq cr6,0x82a7dd5c
	if (ctx.cr6.eq) goto loc_82A7DD5C;
	// rlwinm. r11,r3,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a7dd80
	if (ctx.cr0.eq) goto loc_82A7DD80;
loc_82A7DD5C:
	// lwz r10,628(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// addi r5,r11,15008
	ctx.r5.s64 = ctx.r11.s64 + 15008;
	// li r4,260
	ctx.r4.s64 = 260;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r6,80(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	// bl 0x82a772d8
	ctx.lr = 0x82A7DD7C;
	sub_82A772D8(ctx, base);
	// addi r28,r1,96
	ctx.r28.s64 = ctx.r1.s64 + 96;
loc_82A7DD80:
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a7dda0
	if (ctx.cr0.eq) goto loc_82A7DDA0;
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a7dda0
	if (ctx.cr6.eq) goto loc_82A7DDA0;
	// lwz r29,84(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	// b 0x82a7dda4
	goto loc_82A7DDA4;
loc_82A7DDA0:
	// li r29,0
	ctx.r29.s64 = 0;
loc_82A7DDA4:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x8247f370
	ctx.lr = 0x82A7DDB0;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7ddc4
	if (ctx.cr0.eq) goto loc_82A7DDC4;
	// bl 0x82a7a5e8
	ctx.lr = 0x82A7DDBC;
	sub_82A7A5E8(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// b 0x82a7ddc8
	goto loc_82A7DDC8;
loc_82A7DDC4:
	// li r30,0
	ctx.r30.s64 = 0;
loc_82A7DDC8:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82a7dddc
	if (!ctx.cr6.eq) goto loc_82A7DDDC;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82a7de6c
	goto loc_82A7DE6C;
loc_82A7DDDC:
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
	// lwz r9,636(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 636);
	// addi r8,r31,24
	ctx.r8.s64 = ctx.r31.s64 + 24;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82a7a720
	ctx.lr = 0x82A7DE04;
	sub_82A7A720(ctx, base);
	// mr. r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// bge 0x82a7de30
	if (!ctx.cr0.lt) goto loc_82A7DE30;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r26,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r26.u32);
	// stw r26,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r26.u32);
	// bl 0x82a7bb68
	ctx.lr = 0x82A7DE1C;
	sub_82A7BB68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A7DE28;
	sub_8247F398(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// b 0x82a7de6c
	goto loc_82A7DE6C;
loc_82A7DE30:
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// stw r11,92(r30)
	PPC_STORE_U32(ctx.r30.u32 + 92, ctx.r11.u32);
	// lwz r11,692(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 692);
	// stw r30,628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 628, ctx.r30.u32);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a7de68
	if (ctx.cr0.eq) goto loc_82A7DE68;
	// lwz r3,20(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7de68
	if (ctx.cr0.eq) goto loc_82A7DE68;
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// lwz r4,76(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 76);
	// subf r6,r5,r11
	ctx.r6.s64 = ctx.r11.s64 - ctx.r5.s64;
	// bl 0x82d89b58
	ctx.lr = 0x82A7DE68;
	sub_82D89B58(ctx, base);
loc_82A7DE68:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A7DE6C:
	// addi r1,r1,432
	ctx.r1.s64 = ctx.r1.s64 + 432;
	// b 0x82d5c50c
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7DE78"))) PPC_WEAK_FUNC(sub_82A7DE78);
PPC_FUNC_IMPL(__imp__sub_82A7DE78) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c4
	ctx.lr = 0x82A7DE80;
	__savegprlr_27(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// lwz r3,680(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 680);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7df6c
	if (ctx.cr0.lt) goto loc_82A7DF6C;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x8247f370
	ctx.lr = 0x82A7DEB0;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7dec0
	if (ctx.cr0.eq) goto loc_82A7DEC0;
	// bl 0x82a7a5e8
	ctx.lr = 0x82A7DEBC;
	sub_82A7A5E8(ctx, base);
	// b 0x82a7dec4
	goto loc_82A7DEC4;
loc_82A7DEC0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A7DEC4:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 628, ctx.r3.u32);
	// bne cr6,0x82a7dedc
	if (!ctx.cr6.eq) goto loc_82A7DEDC;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82a7df6c
	goto loc_82A7DF6C;
loc_82A7DEDC:
	// li r11,0
	ctx.r11.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// addi r8,r31,24
	ctx.r8.s64 = ctx.r31.s64 + 24;
	// addi r7,r31,640
	ctx.r7.s64 = ctx.r31.s64 + 640;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82a7a720
	ctx.lr = 0x82A7DF04;
	sub_82A7A720(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7df6c
	if (ctx.cr0.lt) goto loc_82A7DF6C;
	// lwz r11,692(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 692);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a7df48
	if (ctx.cr0.eq) goto loc_82A7DF48;
	// lwz r3,20(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7df48
	if (ctx.cr0.eq) goto loc_82A7DF48;
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// extsw r5,r9
	ctx.r5.s64 = ctx.r9.s32;
	// lwz r4,76(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	// subf r6,r9,r10
	ctx.r6.s64 = ctx.r10.s64 - ctx.r9.s64;
	// bl 0x82d89b58
	ctx.lr = 0x82A7DF40;
	sub_82D89B58(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7df6c
	if (ctx.cr0.lt) goto loc_82A7DF6C;
loc_82A7DF48:
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7d798
	ctx.lr = 0x82A7DF54;
	sub_82A7D798(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7df6c
	if (ctx.cr0.lt) goto loc_82A7DF6C;
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r28,636(r31)
	PPC_STORE_U32(ctx.r31.u32 + 636, ctx.r28.u32);
	// stw r11,632(r31)
	PPC_STORE_U32(ctx.r31.u32 + 632, ctx.r11.u32);
loc_82A7DF6C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82d5c514
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7DF78"))) PPC_WEAK_FUNC(sub_82A7DF78);
PPC_FUNC_IMPL(__imp__sub_82A7DF78) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82A7DF80;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// lwz r3,680(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 680);
	// mr r26,r8
	ctx.r26.u64 = ctx.r8.u64;
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7e070
	if (ctx.cr0.lt) goto loc_82A7E070;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82a7dfb8
	if (!ctx.cr6.eq) goto loc_82A7DFB8;
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// addi r30,r11,5983
	ctx.r30.s64 = ctx.r11.s64 + 5983;
loc_82A7DFB8:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x8247f370
	ctx.lr = 0x82A7DFC4;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7dfd4
	if (ctx.cr0.eq) goto loc_82A7DFD4;
	// bl 0x82a7a5e8
	ctx.lr = 0x82A7DFD0;
	sub_82A7A5E8(ctx, base);
	// b 0x82a7dfd8
	goto loc_82A7DFD8;
loc_82A7DFD4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A7DFD8:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 628, ctx.r3.u32);
	// bne cr6,0x82a7dff0
	if (!ctx.cr6.eq) goto loc_82A7DFF0;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82a7e070
	goto loc_82A7E070;
loc_82A7DFF0:
	// addi r8,r31,24
	ctx.r8.s64 = ctx.r31.s64 + 24;
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82a7a930
	ctx.lr = 0x82A7E008;
	sub_82A7A930(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7e070
	if (ctx.cr0.lt) goto loc_82A7E070;
	// lwz r11,692(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 692);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a7e04c
	if (ctx.cr0.eq) goto loc_82A7E04C;
	// lwz r3,20(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7e04c
	if (ctx.cr0.eq) goto loc_82A7E04C;
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// extsw r5,r9
	ctx.r5.s64 = ctx.r9.s32;
	// lwz r4,76(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	// subf r6,r9,r10
	ctx.r6.s64 = ctx.r10.s64 - ctx.r9.s64;
	// bl 0x82d89b58
	ctx.lr = 0x82A7E044;
	sub_82D89B58(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7e070
	if (ctx.cr0.lt) goto loc_82A7E070;
loc_82A7E04C:
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7d798
	ctx.lr = 0x82A7E058;
	sub_82A7D798(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7e070
	if (ctx.cr0.lt) goto loc_82A7E070;
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r26,636(r31)
	PPC_STORE_U32(ctx.r31.u32 + 636, ctx.r26.u32);
	// stw r11,632(r31)
	PPC_STORE_U32(ctx.r31.u32 + 632, ctx.r11.u32);
loc_82A7E070:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7E078"))) PPC_WEAK_FUNC(sub_82A7E078);
PPC_FUNC_IMPL(__imp__sub_82A7E078) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82A7E080;
	__savegprlr_26(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// li r26,1
	ctx.r26.s64 = 1;
	// cmplwi cr6,r30,16
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 16, ctx.xer);
	// ble cr6,0x82a7e0a4
	if (!ctx.cr6.gt) goto loc_82A7E0A4;
	// stw r26,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r26.u32);
loc_82A7E0A4:
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a7e580
	if (!ctx.cr6.eq) goto loc_82A7E580;
	// rlwinm r11,r30,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// subfic r9,r30,16
	ctx.xer.ca = ctx.r30.u32 <= 16;
	ctx.r9.s64 = 16 - ctx.r30.s64;
	// add r29,r11,r10
	ctx.r29.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r5,r9,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82d5cb60
	ctx.lr = 0x82A7E0D0;
	sub_82D5CB60(ctx, base);
	// mtctr r30
	ctx.ctr.u64 = ctx.r30.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82a7e118
	if (ctx.cr6.eq) goto loc_82A7E118;
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
loc_82A7E0E0:
	// lwz r11,104(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a7e148
	if (ctx.cr0.eq) goto loc_82A7E148;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// stw r9,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r9.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// lwz r9,108(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// stw r11,108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 108, ctx.r11.u32);
	// bdnz 0x82a7e0e0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82A7E0E0;
loc_82A7E118:
	// cmplwi cr6,r27,46
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 46, ctx.xer);
	// bgt cr6,0x82a7e550
	if (ctx.cr6.gt) goto loc_82A7E550;
	// lis r12,-32239
	ctx.r12.s64 = -2112815104;
	// addi r12,r12,-22624
	ctx.r12.s64 = ctx.r12.s64 + -22624;
	// rlwinm r0,r27,1,0,30
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U16(ctx.r12.u32 + ctx.r0.u32);
	// lis r12,-32088
	ctx.r12.s64 = -2102919168;
	// addi r12,r12,-7864
	ctx.r12.s64 = ctx.r12.s64 + -7864;
	// add r12,r12,r0
	ctx.r12.u64 = ctx.r12.u64 + ctx.r0.u64;
	// mtctr r12
	ctx.ctr.u64 = ctx.r12.u64;
	// nop 
	// bctr 
	switch (ctx.r27.u64) {
	case 0:
		goto loc_82A7E168;
	case 1:
		goto loc_82A7E180;
	case 2:
		goto loc_82A7E194;
	case 3:
		goto loc_82A7E1C4;
	case 4:
		goto loc_82A7E20C;
	case 5:
		goto loc_82A7E218;
	case 6:
		goto loc_82A7E224;
	case 7:
		goto loc_82A7E238;
	case 8:
		goto loc_82A7E258;
	case 9:
		goto loc_82A7E280;
	case 10:
		goto loc_82A7E294;
	case 11:
		goto loc_82A7E2A0;
	case 12:
		goto loc_82A7E2AC;
	case 13:
		goto loc_82A7E2C8;
	case 14:
		goto loc_82A7E2D8;
	case 15:
		goto loc_82A7E2E4;
	case 16:
		goto loc_82A7E2E4;
	case 17:
		goto loc_82A7E2EC;
	case 18:
		goto loc_82A7E310;
	case 19:
		goto loc_82A7E2E4;
	case 20:
		goto loc_82A7E340;
	case 21:
		goto loc_82A7E358;
	case 22:
		goto loc_82A7E2E4;
	case 23:
		goto loc_82A7E2E4;
	case 24:
		goto loc_82A7E368;
	case 25:
		goto loc_82A7E380;
	case 26:
		goto loc_82A7E2E4;
	case 27:
		goto loc_82A7E3C4;
	case 28:
		goto loc_82A7E3E4;
	case 29:
		goto loc_82A7E2E4;
	case 30:
		goto loc_82A7E3FC;
	case 31:
		goto loc_82A7E41C;
	case 32:
		goto loc_82A7E434;
	case 33:
		goto loc_82A7E454;
	case 34:
		goto loc_82A7E2E4;
	case 35:
		goto loc_82A7E46C;
	case 36:
		goto loc_82A7E484;
	case 37:
		goto loc_82A7E2E4;
	case 38:
		goto loc_82A7E4A8;
	case 39:
		goto loc_82A7E2E4;
	case 40:
		goto loc_82A7E4D4;
	case 41:
		goto loc_82A7E2E4;
	case 42:
		goto loc_82A7E500;
	case 43:
		goto loc_82A7E2E4;
	case 44:
		goto loc_82A7E520;
	case 45:
		goto loc_82A7E520;
	case 46:
		goto loc_82A7E520;
	default:
		__builtin_unreachable();
	}
loc_82A7E148:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r6,r11,-21500
	ctx.r6.s64 = ctx.r11.s64 + -21500;
loc_82A7E150:
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82a85c20
	ctx.lr = 0x82A7E160;
	sub_82A85C20(ctx, base);
	// stw r26,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r26.u32);
	// b 0x82a7e580
	goto loc_82A7E580;
loc_82A7E168:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,24(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// bl 0x82a7d228
	ctx.lr = 0x82A7E17C;
	sub_82A7D228(ctx, base);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E180:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,24(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// bl 0x82a7c740
	ctx.lr = 0x82A7E190;
	sub_82A7C740(ctx, base);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E194:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// stw r10,28(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28, ctx.r10.u32);
	// lwz r11,640(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82a7e550
	if (ctx.cr6.eq) goto loc_82A7E550;
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r10,28(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28, ctx.r10.u32);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E1C4:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwz r9,24(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// stw r10,28(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28, ctx.r10.u32);
	// lwz r11,640(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82a7e1f8
	if (ctx.cr6.eq) goto loc_82A7E1F8;
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r10,28(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28, ctx.r10.u32);
loc_82A7E1F8:
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82a7e550
	if (ctx.cr6.eq) goto loc_82A7E550;
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// stw r9,24(r11)
	PPC_STORE_U32(ctx.r11.u32 + 24, ctx.r9.u32);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E20C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7dc48
	ctx.lr = 0x82A7E214;
	sub_82A7DC48(ctx, base);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E218:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7aae0
	ctx.lr = 0x82A7E220;
	sub_82A7AAE0(ctx, base);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E224:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r4,24(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
loc_82A7E22C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7c7f0
	ctx.lr = 0x82A7E234;
	sub_82A7C7F0(ctx, base);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E238:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,24(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// bl 0x82a7b920
	ctx.lr = 0x82A7E250;
	sub_82A7B920(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x82a7e22c
	goto loc_82A7E22C;
loc_82A7E258:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,24(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// bl 0x82a7b920
	ctx.lr = 0x82A7E270;
	sub_82A7B920(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r4,r11,27,31,31
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// b 0x82a7e22c
	goto loc_82A7E22C;
loc_82A7E280:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,24(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// bl 0x82a7ac48
	ctx.lr = 0x82A7E290;
	sub_82A7AC48(ctx, base);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E294:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7ad08
	ctx.lr = 0x82A7E29C;
	sub_82A7AD08(ctx, base);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E2A0:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7c8a8
	ctx.lr = 0x82A7E2A8;
	sub_82A7C8A8(ctx, base);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E2AC:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7c7f0
	ctx.lr = 0x82A7E2B8;
	sub_82A7C7F0(ctx, base);
loc_82A7E2B8:
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82a862c0
	ctx.lr = 0x82A7E2C4;
	sub_82A862C0(ctx, base);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E2C8:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7ac48
	ctx.lr = 0x82A7E2D4;
	sub_82A7AC48(ctx, base);
	// b 0x82a7e2b8
	goto loc_82A7E2B8;
loc_82A7E2D8:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7d5a0
	ctx.lr = 0x82A7E2E0;
	sub_82A7D5A0(ctx, base);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E2E4:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E2EC:
	// lwz r30,80(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,2
	ctx.r11.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r28,r30
	ctx.r28.u64 = ctx.r30.u64;
	// lwz r4,24(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// stw r11,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r11.u32);
	// bl 0x82a7d048
	ctx.lr = 0x82A7E308;
	sub_82A7D048(ctx, base);
	// stw r3,24(r30)
	PPC_STORE_U32(ctx.r30.u32 + 24, ctx.r3.u32);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E310:
	// lwz r30,80(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,2
	ctx.r11.s64 = 2;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r28,r30
	ctx.r28.u64 = ctx.r30.u64;
	// lwz r4,24(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// stw r11,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r11.u32);
	// bl 0x82a7b920
	ctx.lr = 0x82A7E334;
	sub_82A7B920(ctx, base);
	// stw r3,24(r30)
	PPC_STORE_U32(ctx.r30.u32 + 24, ctx.r3.u32);
	// stw r26,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r26.u32);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E340:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
loc_82A7E348:
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
loc_82A7E350:
	// stw r11,24(r28)
	PPC_STORE_U32(ctx.r28.u32 + 24, ctx.r11.u32);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E358:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// neg r11,r11
	ctx.r11.s64 = -ctx.r11.s64;
	// b 0x82a7e350
	goto loc_82A7E350;
loc_82A7E368:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r10,24(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// b 0x82a7e350
	goto loc_82A7E350;
loc_82A7E380:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a7e3a4
	if (ctx.cr0.eq) goto loc_82A7E3A4;
	// lwz r10,24(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// twllei r11,0
	// divwu r11,r10,r11
	ctx.r11.u32 = ctx.r10.u32 / ctx.r11.u32;
	// b 0x82a7e350
	goto loc_82A7E350;
loc_82A7E3A4:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1503
	ctx.r5.s64 = 1503;
	// addi r6,r11,-21544
	ctx.r6.s64 = ctx.r11.s64 + -21544;
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82a85c20
	ctx.lr = 0x82A7E3BC;
	sub_82A85C20(ctx, base);
	// stw r26,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r26.u32);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E3C4:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,24(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
loc_82A7E3D8:
	// mr r28,r11
	ctx.r28.u64 = ctx.r11.u64;
	// stw r10,24(r11)
	PPC_STORE_U32(ctx.r11.u32 + 24, ctx.r10.u32);
	// b 0x82a7e550
	goto loc_82A7E550;
loc_82A7E3E4:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// b 0x82a7e350
	goto loc_82A7E350;
loc_82A7E3FC:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// subfc r11,r10,r11
	ctx.xer.ca = ctx.r11.u32 >= ctx.r10.u32;
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
loc_82A7E410:
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// b 0x82a7e350
	goto loc_82A7E350;
loc_82A7E41C:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// subfc r11,r11,r10
	ctx.xer.ca = ctx.r10.u32 >= ctx.r11.u32;
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// b 0x82a7e410
	goto loc_82A7E410;
loc_82A7E434:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r9,24(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// subfc r10,r10,r9
	ctx.xer.ca = ctx.r9.u32 >= ctx.r10.u32;
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
loc_82A7E448:
	// subfe r10,r10,r10
	temp.u8 = (~ctx.r10.u32 + ctx.r10.u32 < ~ctx.r10.u32) | (~ctx.r10.u32 + ctx.r10.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r10.u64 = ~ctx.r10.u64 + ctx.r10.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// b 0x82a7e3d8
	goto loc_82A7E3D8;
loc_82A7E454:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r9,24(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// subfc r10,r9,r10
	ctx.xer.ca = ctx.r10.u32 >= ctx.r9.u32;
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// b 0x82a7e448
	goto loc_82A7E448;
loc_82A7E46C:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// b 0x82a7e348
	goto loc_82A7E348;
loc_82A7E484:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 ^ 1;
	// b 0x82a7e350
	goto loc_82A7E350;
loc_82A7E4A8:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7e4cc
	if (ctx.cr6.eq) goto loc_82A7E4CC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// bne cr6,0x82a7e350
	if (!ctx.cr6.eq) goto loc_82A7E350;
loc_82A7E4CC:
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82a7e350
	goto loc_82A7E350;
loc_82A7E4D4:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a7e4f8
	if (!ctx.cr6.eq) goto loc_82A7E4F8;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r11,0
	ctx.r11.s64 = 0;
	// beq cr6,0x82a7e350
	if (ctx.cr6.eq) goto loc_82A7E350;
loc_82A7E4F8:
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// b 0x82a7e350
	goto loc_82A7E350;
loc_82A7E500:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bne cr6,0x82a7e518
	if (!ctx.cr6.eq) goto loc_82A7E518;
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82A7E518:
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// b 0x82a7e350
	goto loc_82A7E350;
loc_82A7E520:
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82ab71b8
	ctx.lr = 0x82A7E528;
	sub_82AB71B8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7e540
	if (ctx.cr0.eq) goto loc_82A7E540;
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// bl 0x82ab77d8
	ctx.lr = 0x82A7E538;
	sub_82AB77D8(ctx, base);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// b 0x82a7e544
	goto loc_82A7E544;
loc_82A7E540:
	// li r28,0
	ctx.r28.s64 = 0;
loc_82A7E544:
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7baa0
	ctx.lr = 0x82A7E550;
	sub_82A7BAA0(ctx, base);
loc_82A7E550:
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a7e580
	if (!ctx.cr6.eq) goto loc_82A7E580;
	// lwz r3,108(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7e588
	if (ctx.cr0.eq) goto loc_82A7E588;
	// lwz r11,12(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// stw r11,108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 108, ctx.r11.u32);
	// stw r28,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r28.u32);
	// lwz r11,104(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r11.u32);
loc_82A7E57C:
	// stw r3,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r3.u32);
loc_82A7E580:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
loc_82A7E588:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x82ab71b8
	ctx.lr = 0x82A7E590;
	sub_82AB71B8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7e5b0
	if (ctx.cr0.eq) goto loc_82A7E5B0;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lwz r5,104(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// addi r6,r11,-21552
	ctx.r6.s64 = ctx.r11.s64 + -21552;
	// bl 0x82ab7380
	ctx.lr = 0x82A7E5AC;
	sub_82AB7380(ctx, base);
	// b 0x82a7e5b4
	goto loc_82A7E5B4;
loc_82A7E5B0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A7E5B4:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82a7e57c
	if (!ctx.cr6.eq) goto loc_82A7E57C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r6,r11,-21584
	ctx.r6.s64 = ctx.r11.s64 + -21584;
	// b 0x82a7e150
	goto loc_82A7E150;
}

__attribute__((alias("__imp__sub_82A7E5C8"))) PPC_WEAK_FUNC(sub_82A7E5C8);
PPC_FUNC_IMPL(__imp__sub_82A7E5C8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b4
	ctx.lr = 0x82A7E5D0;
	__savegprlr_23(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r25,0
	ctx.r25.s64 = 0;
	// addi r11,r31,1032
	ctx.r11.s64 = ctx.r31.s64 + 1032;
	// addi r23,r31,32
	ctx.r23.s64 = ctx.r31.s64 + 32;
	// li r26,-1
	ctx.r26.s64 = -1;
	// mr r30,r25
	ctx.r30.u64 = ctx.r25.u64;
	// stw r25,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r25.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r25,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r25.u32);
	// addi r27,r11,-24860
	ctx.r27.s64 = ctx.r11.s64 + -24860;
	// stw r26,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r26.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r23,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r23.u32);
	// sth r25,32(r31)
	PPC_STORE_U16(ctx.r31.u32 + 32, ctx.r25.u16);
	// addi r24,r11,-21916
	ctx.r24.s64 = ctx.r11.s64 + -21916;
loc_82A7E614:
	// rlwinm r29,r30,1,0,30
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r11,r27,220
	ctx.r11.s64 = ctx.r27.s64 + 220;
	// lhax r11,r29,r11
	ctx.r11.s64 = int16_t(PPC_LOAD_U16(ctx.r29.u32 + ctx.r11.u32));
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a7e710
	if (!ctx.cr0.eq) goto loc_82A7E710;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge cr6,0x82a7e64c
	if (!ctx.cr6.lt) goto loc_82A7E64C;
	// lwz r3,3032(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 3032);
	// bl 0x82a7bf68
	ctx.lr = 0x82A7E63C;
	sub_82A7BF68(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// stw r3,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r3.u32);
	// bge 0x82a7e64c
	if (!ctx.cr0.lt) goto loc_82A7E64C;
	// stw r25,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r25.u32);
loc_82A7E64C:
	// addi r11,r27,380
	ctx.r11.s64 = ctx.r27.s64 + 380;
	// lhax r10,r29,r11
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(ctx.r29.u32 + ctx.r11.u32));
	// cmpwi r10,0
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82a7e6d4
	if (ctx.cr0.eq) goto loc_82A7E6D4;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplwi cr6,r10,369
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 369, ctx.xer);
	// bgt cr6,0x82a7e6d4
	if (ctx.cr6.gt) goto loc_82A7E6D4;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r10,r27,1476
	ctx.r10.s64 = ctx.r27.s64 + 1476;
	// lhax r10,r9,r10
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(ctx.r9.u32 + ctx.r10.u32));
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82a7e6d4
	if (!ctx.cr6.eq) goto loc_82A7E6D4;
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// addi r10,r31,1030
	ctx.r10.s64 = ctx.r31.s64 + 1030;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82a7eb64
	if (!ctx.cr6.lt) goto loc_82A7EB64;
	// addi r8,r27,732
	ctx.r8.s64 = ctx.r27.s64 + 732;
	// addi r10,r11,2
	ctx.r10.s64 = ctx.r11.s64 + 2;
	// lhax r30,r9,r8
	ctx.r30.s64 = int16_t(PPC_LOAD_U16(ctx.r9.u32 + ctx.r8.u32));
	// stw r10,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r10.u32);
	// sth r30,2(r11)
	PPC_STORE_U16(ctx.r11.u32 + 2, ctx.r30.u16);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r26,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r26.u32);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble 0x82a7e614
	if (!ctx.cr0.gt) goto loc_82A7E614;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// b 0x82a7e614
	goto loc_82A7E614;
loc_82A7E6D4:
	// addi r11,r27,540
	ctx.r11.s64 = ctx.r27.s64 + 540;
	// lhax r10,r29,r11
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(ctx.r29.u32 + ctx.r11.u32));
	// cmpwi r10,0
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82a7ea8c
	if (ctx.cr0.eq) goto loc_82A7EA8C;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplwi cr6,r10,369
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 369, ctx.xer);
	// bgt cr6,0x82a7ea8c
	if (ctx.cr6.gt) goto loc_82A7EA8C;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r9,r27,1476
	ctx.r9.s64 = ctx.r27.s64 + 1476;
	// lhax r9,r10,r9
	ctx.r9.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + ctx.r9.u32));
	// cmpw cr6,r9,r11
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82a7ea8c
	if (!ctx.cr6.eq) goto loc_82A7EA8C;
	// addi r11,r27,732
	ctx.r11.s64 = ctx.r27.s64 + 732;
	// lhax r11,r10,r11
	ctx.r11.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + ctx.r11.u32));
loc_82A7E710:
	// rlwinm r30,r11,1,0,30
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// addi r9,r27,124
	ctx.r9.s64 = ctx.r27.s64 + 124;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// cmplwi cr6,r11,46
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 46, ctx.xer);
	// lhax r29,r30,r9
	ctx.r29.s64 = int16_t(PPC_LOAD_U16(ctx.r30.u32 + ctx.r9.u32));
	// rlwinm r28,r29,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r28,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r28.s64;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r10,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r10.u32);
	// bgt cr6,0x82a7e978
	if (ctx.cr6.gt) goto loc_82A7E978;
	// lis r12,-32239
	ctx.r12.s64 = -2112815104;
	// addi r12,r12,-22528
	ctx.r12.s64 = ctx.r12.s64 + -22528;
	// lbzx r0,r12,r11
	ctx.r0.u64 = PPC_LOAD_U8(ctx.r12.u32 + ctx.r11.u32);
	// rlwinm r0,r0,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r0.u32 | (ctx.r0.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r12,-32088
	ctx.r12.s64 = -2102919168;
	// addi r12,r12,-6300
	ctx.r12.s64 = ctx.r12.s64 + -6300;
	// add r12,r12,r0
	ctx.r12.u64 = ctx.r12.u64 + ctx.r0.u64;
	// mtctr r12
	ctx.ctr.u64 = ctx.r12.u64;
	// nop 
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82A7E764;
	case 1:
		goto loc_82A7E770;
	case 2:
		goto loc_82A7E77C;
	case 3:
		goto loc_82A7E788;
	case 4:
		goto loc_82A7E794;
	case 5:
		goto loc_82A7E79C;
	case 6:
		goto loc_82A7E7A4;
	case 7:
		goto loc_82A7E7B0;
	case 8:
		goto loc_82A7E7BC;
	case 9:
		goto loc_82A7E7C8;
	case 10:
		goto loc_82A7E7D4;
	case 11:
		goto loc_82A7E7DC;
	case 12:
		goto loc_82A7E7E4;
	case 13:
		goto loc_82A7E7EC;
	case 14:
		goto loc_82A7E7F4;
	case 15:
		goto loc_82A7E7FC;
	case 16:
		goto loc_82A7E808;
	case 17:
		goto loc_82A7E814;
	case 18:
		goto loc_82A7E820;
	case 19:
		goto loc_82A7E82C;
	case 20:
		goto loc_82A7E838;
	case 21:
		goto loc_82A7E844;
	case 22:
		goto loc_82A7E850;
	case 23:
		goto loc_82A7E85C;
	case 24:
		goto loc_82A7E868;
	case 25:
		goto loc_82A7E874;
	case 26:
		goto loc_82A7E880;
	case 27:
		goto loc_82A7E88C;
	case 28:
		goto loc_82A7E898;
	case 29:
		goto loc_82A7E8A4;
	case 30:
		goto loc_82A7E8B0;
	case 31:
		goto loc_82A7E8BC;
	case 32:
		goto loc_82A7E8C8;
	case 33:
		goto loc_82A7E8D4;
	case 34:
		goto loc_82A7E8E0;
	case 35:
		goto loc_82A7E8EC;
	case 36:
		goto loc_82A7E8F8;
	case 37:
		goto loc_82A7E904;
	case 38:
		goto loc_82A7E910;
	case 39:
		goto loc_82A7E91C;
	case 40:
		goto loc_82A7E928;
	case 41:
		goto loc_82A7E934;
	case 42:
		goto loc_82A7E940;
	case 43:
		goto loc_82A7E94C;
	case 44:
		goto loc_82A7E958;
	case 45:
		goto loc_82A7E960;
	case 46:
		goto loc_82A7E968;
	default:
		__builtin_unreachable();
	}
loc_82A7E764:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E770:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E77C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,2
	ctx.r4.s64 = 2;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E788:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,3
	ctx.r4.s64 = 3;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E794:
	// li r4,4
	ctx.r4.s64 = 4;
	// b 0x82a7e96c
	goto loc_82A7E96C;
loc_82A7E79C:
	// li r4,5
	ctx.r4.s64 = 5;
	// b 0x82a7e96c
	goto loc_82A7E96C;
loc_82A7E7A4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,6
	ctx.r4.s64 = 6;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E7B0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,7
	ctx.r4.s64 = 7;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E7BC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,8
	ctx.r4.s64 = 8;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E7C8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,9
	ctx.r4.s64 = 9;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E7D4:
	// li r4,10
	ctx.r4.s64 = 10;
	// b 0x82a7e96c
	goto loc_82A7E96C;
loc_82A7E7DC:
	// li r4,11
	ctx.r4.s64 = 11;
	// b 0x82a7e96c
	goto loc_82A7E96C;
loc_82A7E7E4:
	// li r4,12
	ctx.r4.s64 = 12;
	// b 0x82a7e96c
	goto loc_82A7E96C;
loc_82A7E7EC:
	// li r4,13
	ctx.r4.s64 = 13;
	// b 0x82a7e96c
	goto loc_82A7E96C;
loc_82A7E7F4:
	// li r4,14
	ctx.r4.s64 = 14;
	// b 0x82a7e96c
	goto loc_82A7E96C;
loc_82A7E7FC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,15
	ctx.r4.s64 = 15;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E808:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,16
	ctx.r4.s64 = 16;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E814:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,17
	ctx.r4.s64 = 17;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E820:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,18
	ctx.r4.s64 = 18;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E82C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,19
	ctx.r4.s64 = 19;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E838:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,20
	ctx.r4.s64 = 20;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E844:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,21
	ctx.r4.s64 = 21;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E850:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,22
	ctx.r4.s64 = 22;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E85C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,23
	ctx.r4.s64 = 23;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E868:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,24
	ctx.r4.s64 = 24;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E874:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,25
	ctx.r4.s64 = 25;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E880:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,26
	ctx.r4.s64 = 26;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E88C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,27
	ctx.r4.s64 = 27;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E898:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,28
	ctx.r4.s64 = 28;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E8A4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,29
	ctx.r4.s64 = 29;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E8B0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,30
	ctx.r4.s64 = 30;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E8BC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,31
	ctx.r4.s64 = 31;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E8C8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,32
	ctx.r4.s64 = 32;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E8D4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,33
	ctx.r4.s64 = 33;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E8E0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,34
	ctx.r4.s64 = 34;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E8EC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,35
	ctx.r4.s64 = 35;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E8F8:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,36
	ctx.r4.s64 = 36;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E904:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,37
	ctx.r4.s64 = 37;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E910:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,38
	ctx.r4.s64 = 38;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E91C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,39
	ctx.r4.s64 = 39;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E928:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,40
	ctx.r4.s64 = 40;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E934:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,41
	ctx.r4.s64 = 41;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E940:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,42
	ctx.r4.s64 = 42;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E94C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,43
	ctx.r4.s64 = 43;
	// b 0x82a7e970
	goto loc_82A7E970;
loc_82A7E958:
	// li r4,44
	ctx.r4.s64 = 44;
	// b 0x82a7e96c
	goto loc_82A7E96C;
loc_82A7E960:
	// li r4,45
	ctx.r4.s64 = 45;
	// b 0x82a7e96c
	goto loc_82A7E96C;
loc_82A7E968:
	// li r4,46
	ctx.r4.s64 = 46;
loc_82A7E96C:
	// li r5,0
	ctx.r5.s64 = 0;
loc_82A7E970:
	// lwz r3,3032(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 3032);
	// bl 0x82a7e078
	ctx.lr = 0x82A7E978;
	sub_82A7E078(ctx, base);
loc_82A7E978:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// rlwinm r10,r29,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r8,r27,28
	ctx.r8.s64 = ctx.r27.s64 + 28;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// subf r10,r28,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r28.s64;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// lha r11,0(r11)
	ctx.r11.s64 = int16_t(PPC_LOAD_U16(ctx.r11.u32 + 0));
	// stw r10,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r10.u32);
	// lhax r10,r30,r8
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(ctx.r30.u32 + ctx.r8.u32));
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a7ea14
	if (!ctx.cr0.eq) goto loc_82A7EA14;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82a7ea14
	if (!ctx.cr6.eq) goto loc_82A7EA14;
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// li r10,15
	ctx.r10.s64 = 15;
	// li r30,15
	ctx.r30.s64 = 15;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// sth r10,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r10.u16);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge cr6,0x82a7ea00
	if (!ctx.cr6.lt) goto loc_82A7EA00;
	// lwz r3,3032(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 3032);
	// bl 0x82a7bf68
	ctx.lr = 0x82A7E9F0;
	sub_82A7BF68(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// stw r3,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r3.u32);
	// bge 0x82a7ea00
	if (!ctx.cr0.lt) goto loc_82A7EA00;
	// stw r25,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r25.u32);
loc_82A7EA00:
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a7e614
	if (!ctx.cr6.eq) goto loc_82A7E614;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82a7eb78
	goto loc_82A7EB78;
loc_82A7EA14:
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r10,r27,700
	ctx.r10.s64 = ctx.r27.s64 + 700;
	// lhax r10,r9,r10
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(ctx.r9.u32 + ctx.r10.u32));
	// cmpwi r10,0
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82a7ea54
	if (ctx.cr0.eq) goto loc_82A7EA54;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// cmplwi cr6,r10,369
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 369, ctx.xer);
	// bgt cr6,0x82a7ea54
	if (ctx.cr6.gt) goto loc_82A7EA54;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r8,r27,1476
	ctx.r8.s64 = ctx.r27.s64 + 1476;
	// lhax r8,r10,r8
	ctx.r8.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + ctx.r8.u32));
	// cmpw cr6,r8,r11
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82a7ea54
	if (!ctx.cr6.eq) goto loc_82A7EA54;
	// addi r11,r27,732
	ctx.r11.s64 = ctx.r27.s64 + 732;
	// lhax r30,r10,r11
	ctx.r30.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + ctx.r11.u32));
	// b 0x82a7ea58
	goto loc_82A7EA58;
loc_82A7EA54:
	// lhax r30,r9,r27
	ctx.r30.s64 = int16_t(PPC_LOAD_U16(ctx.r9.u32 + ctx.r27.u32));
loc_82A7EA58:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// addi r10,r31,1030
	ctx.r10.s64 = ctx.r31.s64 + 1030;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82a7eb64
	if (!ctx.cr6.lt) goto loc_82A7EB64;
	// addi r10,r11,2
	ctx.r10.s64 = ctx.r11.s64 + 2;
	// stw r10,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r10.u32);
	// sth r30,2(r11)
	PPC_STORE_U16(ctx.r11.u32 + 2, ctx.r30.u16);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
loc_82A7EA78:
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// b 0x82a7e614
	goto loc_82A7E614;
loc_82A7EA8C:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a7eab0
	if (!ctx.cr6.eq) goto loc_82A7EAB0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// bl 0x82a7d748
	ctx.lr = 0x82A7EAA4;
	sub_82A7D748(ctx, base);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
loc_82A7EAB0:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82a7eb50
	if (!ctx.cr6.lt) goto loc_82A7EB50;
	// li r11,3
	ctx.r11.s64 = 3;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
loc_82A7EAC4:
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// addi r11,r27,380
	ctx.r11.s64 = ctx.r27.s64 + 380;
	// lha r10,0(r9)
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(ctx.r9.u32 + 0));
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// lhax r11,r10,r11
	ctx.r11.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + ctx.r11.u32));
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a7eb00
	if (ctx.cr0.eq) goto loc_82A7EB00;
	// addi r10,r11,256
	ctx.r10.s64 = ctx.r11.s64 + 256;
	// cmplwi cr6,r10,369
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 369, ctx.xer);
	// bgt cr6,0x82a7eb00
	if (ctx.cr6.gt) goto loc_82A7EB00;
	// addi r11,r27,1476
	ctx.r11.s64 = ctx.r27.s64 + 1476;
	// rlwinm r8,r10,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r11,r8,r11
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r8.u32 + ctx.r11.u32);
	// cmplwi cr6,r11,256
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 256, ctx.xer);
	// beq cr6,0x82a7eb20
	if (ctx.cr6.eq) goto loc_82A7EB20;
loc_82A7EB00:
	// cmplw cr6,r9,r23
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r23.u32, ctx.xer);
	// ble cr6,0x82a7eb74
	if (!ctx.cr6.gt) goto loc_82A7EB74;
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// addi r10,r9,-2
	ctx.r10.s64 = ctx.r9.s64 + -2;
	// addi r11,r11,-4
	ctx.r11.s64 = ctx.r11.s64 + -4;
	// stw r10,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r10.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// b 0x82a7eac4
	goto loc_82A7EAC4;
loc_82A7EB20:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// addi r9,r31,1030
	ctx.r9.s64 = ctx.r31.s64 + 1030;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82a7eb64
	if (!ctx.cr6.lt) goto loc_82A7EB64;
	// rlwinm r8,r10,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r9,r27,732
	ctx.r9.s64 = ctx.r27.s64 + 732;
	// addi r10,r11,2
	ctx.r10.s64 = ctx.r11.s64 + 2;
	// lhax r30,r8,r9
	ctx.r30.s64 = int16_t(PPC_LOAD_U16(ctx.r8.u32 + ctx.r9.u32));
	// stw r10,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r10.u32);
	// sth r30,2(r11)
	PPC_STORE_U16(ctx.r11.u32 + 2, ctx.r30.u16);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// b 0x82a7ea78
	goto loc_82A7EA78;
loc_82A7EB50:
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a7eb74
	if (ctx.cr6.eq) goto loc_82A7EB74;
	// stw r26,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r26.u32);
	// b 0x82a7e614
	goto loc_82A7E614;
loc_82A7EB64:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-21468
	ctx.r4.s64 = ctx.r11.s64 + -21468;
	// bl 0x82a7d748
	ctx.lr = 0x82A7EB74;
	sub_82A7D748(ctx, base);
loc_82A7EB74:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82A7EB78:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82d5c504
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7EB80"))) PPC_WEAK_FUNC(sub_82A7EB80);
PPC_FUNC_IMPL(__imp__sub_82A7EB80) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4ac
	ctx.lr = 0x82A7EB88;
	__savegprlr_21(ctx, base);
	// stwu r1,-3232(r1)
	ea = -3232 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r11,84(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a7ef50
	if (!ctx.cr6.eq) goto loc_82A7EF50;
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// li r28,0
	ctx.r28.s64 = 0;
	// addi r22,r11,5983
	ctx.r22.s64 = ctx.r11.s64 + 5983;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r27,1
	ctx.r27.s64 = 1;
	// addi r25,r11,-21964
	ctx.r25.s64 = ctx.r11.s64 + -21964;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r21,12
	ctx.r21.s64 = 12;
	// addi r26,r11,-21372
	ctx.r26.s64 = ctx.r11.s64 + -21372;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r23,r11,-21424
	ctx.r23.s64 = ctx.r11.s64 + -21424;
	// lis r11,-32242
	ctx.r11.s64 = -2113011712;
	// addi r24,r11,-19648
	ctx.r24.s64 = ctx.r11.s64 + -19648;
loc_82A7EBD4:
	// lwz r11,116(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a7ebec
	if (ctx.cr0.eq) goto loc_82A7EBEC;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7ef7c
	if (ctx.cr6.eq) goto loc_82A7EF7C;
loc_82A7EBEC:
	// lwz r10,112(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq 0x82a7ec4c
	if (ctx.cr0.eq) goto loc_82A7EC4C;
	// addi r11,r10,16
	ctx.r11.s64 = ctx.r10.s64 + 16;
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// std r9,0(r29)
	PPC_STORE_U64(ctx.r29.u32 + 0, ctx.r9.u64);
	// ld r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// std r9,8(r29)
	PPC_STORE_U64(ctx.r29.u32 + 8, ctx.r9.u64);
	// ld r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// std r9,16(r29)
	PPC_STORE_U64(ctx.r29.u32 + 16, ctx.r9.u64);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// std r11,24(r29)
	PPC_STORE_U64(ctx.r29.u32 + 24, ctx.r11.u64);
	// lwz r11,112(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r11,112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 112, ctx.r11.u32);
	// stw r28,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r28.u32);
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// stw r11,16(r29)
	PPC_STORE_U32(ctx.r29.u32 + 16, ctx.r11.u32);
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r11,28(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// stw r11,20(r29)
	PPC_STORE_U32(ctx.r29.u32 + 20, ctx.r11.u32);
	// stw r28,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r28.u32);
	// b 0x82a7ec64
	goto loc_82A7EC64;
loc_82A7EC4C:
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7EC5C;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7f084
	if (ctx.cr0.lt) goto loc_82A7F084;
loc_82A7EC64:
	// lwz r7,0(r29)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmpwi cr6,r7,1
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 1, ctx.xer);
	// bne cr6,0x82a7ee04
	if (!ctx.cr6.eq) goto loc_82A7EE04;
	// addi r10,r29,8
	ctx.r10.s64 = ctx.r29.s64 + 8;
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
loc_82A7EC78:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7ec9c
	if (ctx.cr0.eq) goto loc_82A7EC9C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7ec78
	if (ctx.cr6.eq) goto loc_82A7EC78;
loc_82A7EC9C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7ee04
	if (!ctx.cr0.eq) goto loc_82A7EE04;
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a7ee04
	if (ctx.cr6.eq) goto loc_82A7EE04;
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// li r5,3036
	ctx.r5.s64 = 3036;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r28,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r28.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r28,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r28.u32);
	// stw r27,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r27.u32);
	// stw r11,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r11.u32);
	// bl 0x82d5cb60
	ctx.lr = 0x82A7ECD4;
	sub_82D5CB60(ctx, base);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r31,3128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 3128, ctx.r31.u32);
	// bl 0x82a7e5c8
	ctx.lr = 0x82A7ECE0;
	sub_82A7E5C8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a7ecec
	if (ctx.cr0.eq) goto loc_82A7ECEC;
	// stw r27,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r27.u32);
loc_82A7ECEC:
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// stw r28,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r28.u32);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a7ed64
	if (!ctx.cr6.eq) goto loc_82A7ED64;
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a7ed64
	if (!ctx.cr6.eq) goto loc_82A7ED64;
	// addi r30,r31,640
	ctx.r30.s64 = ctx.r31.s64 + 640;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82a86ed8
	ctx.lr = 0x82A7ED1C;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7f084
	if (ctx.cr0.lt) goto loc_82A7F084;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82a7ed60
	if (ctx.cr6.eq) goto loc_82A7ED60;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82a7ed60
	if (ctx.cr6.eq) goto loc_82A7ED60;
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a7ed58
	if (ctx.cr6.eq) goto loc_82A7ED58;
	// li r5,1501
	ctx.r5.s64 = 1501;
	// mr r6,r23
	ctx.r6.u64 = ctx.r23.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82a85c20
	ctx.lr = 0x82A7ED58;
	sub_82A85C20(ctx, base);
loc_82A7ED58:
	// stw r27,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r27.u32);
	// b 0x82a7ed64
	goto loc_82A7ED64;
loc_82A7ED60:
	// stw r27,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r27.u32);
loc_82A7ED64:
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a7ed9c
	if (!ctx.cr6.eq) goto loc_82A7ED9C;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82a862c0
	ctx.lr = 0x82A7ED7C;
	sub_82A862C0(ctx, base);
	// addi r5,r31,640
	ctx.r5.s64 = ctx.r31.s64 + 640;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// stw r28,112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 112, ctx.r28.u32);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7ED90;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7f084
	if (ctx.cr0.lt) goto loc_82A7F084;
	// stw r27,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r27.u32);
loc_82A7ED9C:
	// lwz r11,96(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// lwz r10,628(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r11,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r11.u32);
	// stw r10,632(r31)
	PPC_STORE_U32(ctx.r31.u32 + 632, ctx.r10.u32);
	// beq 0x82a7ef44
	if (ctx.cr0.eq) goto loc_82A7EF44;
	// addi r11,r31,640
	ctx.r11.s64 = ctx.r31.s64 + 640;
	// ld r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// std r10,0(r29)
	PPC_STORE_U64(ctx.r29.u32 + 0, ctx.r10.u64);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// std r10,8(r29)
	PPC_STORE_U64(ctx.r29.u32 + 8, ctx.r10.u64);
	// ld r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// std r10,16(r29)
	PPC_STORE_U64(ctx.r29.u32 + 16, ctx.r10.u64);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// std r11,24(r29)
	PPC_STORE_U64(ctx.r29.u32 + 24, ctx.r11.u64);
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r11,92(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7edec
	if (ctx.cr6.eq) goto loc_82A7EDEC;
	// stw r21,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r21.u32);
loc_82A7EDEC:
	// lwz r11,84(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a7ef84
	if (ctx.cr6.eq) goto loc_82A7EF84;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82a7f084
	goto loc_82A7F084;
loc_82A7EE04:
	// cmpwi cr6,r7,13
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 13, ctx.xer);
	// beq cr6,0x82a7ef8c
	if (ctx.cr6.eq) goto loc_82A7EF8C;
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a7ee74
	if (ctx.cr6.eq) goto loc_82A7EE74;
	// cmpwi cr6,r7,9
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 9, ctx.xer);
	// bne cr6,0x82a7ee74
	if (!ctx.cr6.eq) goto loc_82A7EE74;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// lwz r4,8(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7b920
	ctx.lr = 0x82A7EE34;
	sub_82A7B920(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a7ee74
	if (ctx.cr0.eq) goto loc_82A7EE74;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82a7f130
	ctx.lr = 0x82A7EE50;
	sub_82A7F130(ctx, base);
	// cmpwi cr6,r3,2
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 2, ctx.xer);
	// beq cr6,0x82a7ee74
	if (ctx.cr6.eq) goto loc_82A7EE74;
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82a7ef44
	if (!ctx.cr6.eq) goto loc_82A7EF44;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// stw r27,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r27.u32);
	// stw r27,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r27.u32);
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82a7f084
	goto loc_82A7F084;
loc_82A7EE74:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82a7ef24
	if (!ctx.cr6.eq) goto loc_82A7EF24;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// mr r10,r26
	ctx.r10.u64 = ctx.r26.u64;
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_82A7EE8C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7eeb0
	if (ctx.cr0.eq) goto loc_82A7EEB0;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7ee8c
	if (ctx.cr6.eq) goto loc_82A7EE8C;
loc_82A7EEB0:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7eedc
	if (!ctx.cr0.eq) goto loc_82A7EEDC;
	// li r11,10
	ctx.r11.s64 = 10;
	// stw r11,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r11.u32);
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// bne 0x82a7ef24
	if (!ctx.cr0.eq) goto loc_82A7EF24;
	// stw r22,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r22.u32);
	// b 0x82a7ef24
	goto loc_82A7EF24;
loc_82A7EEDC:
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
loc_82A7EEE4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7ef08
	if (ctx.cr0.eq) goto loc_82A7EF08;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7eee4
	if (ctx.cr6.eq) goto loc_82A7EEE4;
loc_82A7EF08:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7ef24
	if (!ctx.cr0.eq) goto loc_82A7EF24;
	// li r11,2
	ctx.r11.s64 = 2;
	// stw r11,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r11.u32);
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r11,28(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
loc_82A7EF24:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lwz r10,92(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// subf r11,r21,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r21.s64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// stw r11,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r11.u32);
	// bne cr6,0x82a7eff8
	if (!ctx.cr6.eq) goto loc_82A7EFF8;
loc_82A7EF44:
	// lwz r11,84(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82a7ebd4
	if (ctx.cr6.eq) goto loc_82A7EBD4;
loc_82A7EF50:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_82A7EF58:
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// stw r11,16(r29)
	PPC_STORE_U32(ctx.r29.u32 + 16, ctx.r11.u32);
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r11,28(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// stw r11,20(r29)
	PPC_STORE_U32(ctx.r29.u32 + 20, ctx.r11.u32);
	// li r11,13
	ctx.r11.s64 = 13;
	// stw r11,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r11.u32);
	// b 0x82a7f084
	goto loc_82A7F084;
loc_82A7EF7C:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// b 0x82a7ef58
	goto loc_82A7EF58;
loc_82A7EF84:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// b 0x82a7f084
	goto loc_82A7F084;
loc_82A7EF8C:
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r11,56(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7efb4
	if (ctx.cr6.eq) goto loc_82A7EFB4;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1502
	ctx.r5.s64 = 1502;
	// addi r6,r11,-21448
	ctx.r6.s64 = ctx.r11.s64 + -21448;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82a85c20
	ctx.lr = 0x82A7EFB4;
	sub_82A85C20(ctx, base);
loc_82A7EFB4:
	// lwz r30,628(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r11,92(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 92);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7f080
	if (ctx.cr6.eq) goto loc_82A7F080;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r11,628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 628, ctx.r11.u32);
	// stw r28,92(r30)
	PPC_STORE_U32(ctx.r30.u32 + 92, ctx.r28.u32);
	// bl 0x82a7bb68
	ctx.lr = 0x82A7EFD8;
	sub_82A7BB68(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A7EFE4;
	sub_8247F398(ctx, base);
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// stw r11,632(r31)
	PPC_STORE_U32(ctx.r31.u32 + 632, ctx.r11.u32);
	// stw r21,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r21.u32);
	// stw r27,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r27.u32);
	// b 0x82a7f080
	goto loc_82A7F080;
loc_82A7EFF8:
	// lwz r11,116(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a7f080
	if (ctx.cr0.eq) goto loc_82A7F080;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a7f080
	if (ctx.cr6.eq) goto loc_82A7F080;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bne cr6,0x82a7f068
	if (!ctx.cr6.eq) goto loc_82A7F068;
	// lbz r10,9(r29)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r29.u32 + 9);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82a7f068
	if (!ctx.cr6.eq) goto loc_82A7F068;
	// lbz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r29.u32 + 8);
	// cmplwi cr6,r10,123
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 123, ctx.xer);
	// bne cr6,0x82a7f040
	if (!ctx.cr6.eq) goto loc_82A7F040;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
loc_82A7F040:
	// lbz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 8);
	// cmplwi cr6,r11,125
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 125, ctx.xer);
	// bne cr6,0x82a7f068
	if (!ctx.cr6.eq) goto loc_82A7F068;
	// lwz r11,116(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a7f068
	if (ctx.cr6.eq) goto loc_82A7F068;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
loc_82A7F068:
	// lwz r11,116(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a7f080
	if (!ctx.cr6.eq) goto loc_82A7F080;
	// li r11,13
	ctx.r11.s64 = 13;
	// stw r11,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r11.u32);
loc_82A7F080:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A7F084:
	// addi r1,r1,3232
	ctx.r1.s64 = ctx.r1.s64 + 3232;
	// b 0x82d5c4fc
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7F090"))) PPC_WEAK_FUNC(sub_82A7F090);
PPC_FUNC_IMPL(__imp__sub_82A7F090) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,116(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a7f0c8
	if (!ctx.cr6.eq) goto loc_82A7F0C8;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82a7f11c
	goto loc_82A7F11C;
loc_82A7F0BC:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82a7f0e0
	if (ctx.cr6.eq) goto loc_82A7F0E0;
loc_82A7F0C8:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a7eb80
	ctx.lr = 0x82A7F0D4;
	sub_82A7EB80(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a7f0bc
	if (!ctx.cr0.lt) goto loc_82A7F0BC;
	// b 0x82a7f11c
	goto loc_82A7F11C;
loc_82A7F0E0:
	// lwz r3,116(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// li r11,0
	ctx.r11.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r10,116(r31)
	PPC_STORE_U32(ctx.r31.u32 + 116, ctx.r10.u32);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r11.u32);
	// bl 0x82a7bca8
	ctx.lr = 0x82A7F0FC;
	sub_82A7BCA8(ctx, base);
	// lwz r11,116(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a7f110
	if (ctx.cr0.eq) goto loc_82A7F110;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// b 0x82a7f114
	goto loc_82A7F114;
loc_82A7F110:
	// li r11,1
	ctx.r11.s64 = 1;
loc_82A7F114:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,672(r31)
	PPC_STORE_U32(ctx.r31.u32 + 672, ctx.r11.u32);
loc_82A7F11C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7F130"))) PPC_WEAK_FUNC(sub_82A7F130);
PPC_FUNC_IMPL(__imp__sub_82A7F130) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4a0
	ctx.lr = 0x82A7F138;
	__savegprlr_18(ctx, base);
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r18,0
	ctx.r18.s64 = 0;
	// mr r19,r5
	ctx.r19.u64 = ctx.r5.u64;
	// mr r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// stw r18,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r18.u32);
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// stw r18,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r18.u32);
	// bne cr6,0x82a7f1b4
	if (!ctx.cr6.eq) goto loc_82A7F1B4;
	// addi r31,r1,80
	ctx.r31.s64 = ctx.r1.s64 + 80;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a7f1a8
	if (ctx.cr6.eq) goto loc_82A7F1A8;
loc_82A7F16C:
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82ab71b8
	ctx.lr = 0x82A7F174;
	sub_82AB71B8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7f188
	if (ctx.cr0.eq) goto loc_82A7F188;
	// addi r4,r27,16
	ctx.r4.s64 = ctx.r27.s64 + 16;
	// bl 0x82ab77d8
	ctx.lr = 0x82A7F184;
	sub_82AB77D8(ctx, base);
	// b 0x82a7f18c
	goto loc_82A7F18C;
loc_82A7F188:
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
loc_82A7F18C:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82a7fa2c
	if (ctx.cr6.eq) goto loc_82A7FA2C;
	// lwz r27,12(r27)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// addi r31,r3,12
	ctx.r31.s64 = ctx.r3.s64 + 12;
	// cmplwi r27,0
	ctx.cr0.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// bne 0x82a7f16c
	if (!ctx.cr0.eq) goto loc_82A7F16C;
loc_82A7F1A8:
	// lwz r11,112(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 112);
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// b 0x82a7fa6c
	goto loc_82A7FA6C;
loc_82A7F1B4:
	// lwz r7,112(r20)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r20.u32 + 112);
	// cmplwi r7,0
	ctx.cr0.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq 0x82a7f238
	if (ctx.cr0.eq) goto loc_82A7F238;
	// addi r11,r7,16
	ctx.r11.s64 = ctx.r7.s64 + 16;
	// ld r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// std r10,640(r20)
	PPC_STORE_U64(ctx.r20.u32 + 640, ctx.r10.u64);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// lwz r9,640(r20)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r20.u32 + 640);
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// std r10,648(r20)
	PPC_STORE_U64(ctx.r20.u32 + 648, ctx.r10.u64);
	// ld r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// std r10,656(r20)
	PPC_STORE_U64(ctx.r20.u32 + 656, ctx.r10.u64);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// std r11,664(r20)
	PPC_STORE_U64(ctx.r20.u32 + 664, ctx.r11.u64);
	// bne cr6,0x82a7fa7c
	if (!ctx.cr6.eq) goto loc_82A7FA7C;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r10,r11,23068
	ctx.r10.s64 = ctx.r11.s64 + 23068;
	// addi r11,r20,648
	ctx.r11.s64 = ctx.r20.s64 + 648;
loc_82A7F1FC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7f220
	if (ctx.cr0.eq) goto loc_82A7F220;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7f1fc
	if (ctx.cr6.eq) goto loc_82A7F1FC;
loc_82A7F220:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7fa7c
	if (!ctx.cr0.eq) goto loc_82A7FA7C;
	// lwz r11,12(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// stw r11,112(r20)
	PPC_STORE_U32(ctx.r20.u32 + 112, ctx.r11.u32);
	// stw r18,12(r7)
	PPC_STORE_U32(ctx.r7.u32 + 12, ctx.r18.u32);
	// b 0x82a7f2f0
	goto loc_82A7F2F0;
loc_82A7F238:
	// lwz r3,632(r20)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r20.u32 + 632);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r9,4(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82a7f294
	if (!ctx.cr6.lt) goto loc_82A7F294;
loc_82A7F24C:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,32
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 32, ctx.xer);
	// beq cr6,0x82a7f26c
	if (ctx.cr6.eq) goto loc_82A7F26C;
	// cmpwi cr6,r10,9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 9, ctx.xer);
	// blt cr6,0x82a7f280
	if (ctx.cr6.lt) goto loc_82A7F280;
	// cmpwi cr6,r10,13
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 13, ctx.xer);
	// bgt cr6,0x82a7f280
	if (ctx.cr6.gt) goto loc_82A7F280;
loc_82A7F26C:
	// lwz r10,632(r20)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r20.u32 + 632);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a7f24c
	if (ctx.cr6.lt) goto loc_82A7F24C;
loc_82A7F280:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82a7f294
	if (!ctx.cr6.lt) goto loc_82A7F294;
	// lbz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r11,40
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 40, ctx.xer);
	// bne cr6,0x82a7fa7c
	if (!ctx.cr6.eq) goto loc_82A7FA7C;
loc_82A7F294:
	// addi r31,r20,640
	ctx.r31.s64 = ctx.r20.s64 + 640;
	// lwz r4,672(r20)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r20.u32 + 672);
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// bl 0x82a86ed8
	ctx.lr = 0x82A7F2A4;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7fa7c
	if (ctx.cr0.lt) goto loc_82A7FA7C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82a7fa7c
	if (!ctx.cr6.eq) goto loc_82A7FA7C;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r10,r11,23068
	ctx.r10.s64 = ctx.r11.s64 + 23068;
	// addi r11,r20,648
	ctx.r11.s64 = ctx.r20.s64 + 648;
loc_82A7F2C4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7f2e8
	if (ctx.cr0.eq) goto loc_82A7F2E8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7f2c4
	if (ctx.cr6.eq) goto loc_82A7F2C4;
loc_82A7F2E8:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7fa7c
	if (!ctx.cr0.eq) goto loc_82A7FA7C;
loc_82A7F2F0:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r29,1
	ctx.r29.s64 = 1;
	// addi r30,r1,84
	ctx.r30.s64 = ctx.r1.s64 + 84;
	// mr r31,r18
	ctx.r31.u64 = ctx.r18.u64;
	// addi r28,r11,-21228
	ctx.r28.s64 = ctx.r11.s64 + -21228;
loc_82A7F304:
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x82a7eb80
	ctx.lr = 0x82A7F310;
	sub_82A7EB80(ctx, base);
	// lwz r11,84(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 84);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82a7fa2c
	if (!ctx.cr6.eq) goto loc_82A7FA2C;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82a7f490
	if (ctx.cr6.eq) goto loc_82A7F490;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a7f36c
	if (!ctx.cr6.eq) goto loc_82A7F36C;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x82ab71b8
	ctx.lr = 0x82A7F33C;
	sub_82AB71B8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7f358
	if (ctx.cr0.eq) goto loc_82A7F358;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82ab7380
	ctx.lr = 0x82A7F354;
	sub_82AB7380(ctx, base);
	// b 0x82a7f35c
	goto loc_82A7F35C;
loc_82A7F358:
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
loc_82A7F35C:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82a7fa2c
	if (ctx.cr6.eq) goto loc_82A7FA2C;
	// addi r31,r3,8
	ctx.r31.s64 = ctx.r3.s64 + 8;
loc_82A7F36C:
	// cmplwi cr6,r29,1
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 1, ctx.xer);
	// bne cr6,0x82a7f3b0
	if (!ctx.cr6.eq) goto loc_82A7F3B0;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82a7f3b0
	if (!ctx.cr6.eq) goto loc_82A7F3B0;
	// lbz r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 104);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,44
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 44, ctx.xer);
	// beq cr6,0x82a7f398
	if (ctx.cr6.eq) goto loc_82A7F398;
	// cmpwi cr6,r11,41
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 41, ctx.xer);
	// bne cr6,0x82a7f3b0
	if (!ctx.cr6.eq) goto loc_82A7F3B0;
loc_82A7F398:
	// lbz r11,105(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 105);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82a7f3b0
	if (!ctx.cr0.eq) goto loc_82A7F3B0;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r30,r11,12
	ctx.r30.s64 = ctx.r11.s64 + 12;
	// b 0x82a7f3ec
	goto loc_82A7F3EC;
loc_82A7F3B0:
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82ab71b8
	ctx.lr = 0x82A7F3B8;
	sub_82AB71B8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7f3cc
	if (ctx.cr0.eq) goto loc_82A7F3CC;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82ab77d8
	ctx.lr = 0x82A7F3C8;
	sub_82AB77D8(ctx, base);
	// b 0x82a7f3d0
	goto loc_82A7F3D0;
loc_82A7F3CC:
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
loc_82A7F3D0:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82a7fa2c
	if (ctx.cr6.eq) goto loc_82A7FA2C;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r31,r3,12
	ctx.r31.s64 = ctx.r3.s64 + 12;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82a7f43c
	if (!ctx.cr6.eq) goto loc_82A7F43C;
loc_82A7F3EC:
	// lbz r11,105(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 105);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82a7f43c
	if (!ctx.cr0.eq) goto loc_82A7F43C;
	// lbz r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 104);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,40
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 40, ctx.xer);
	// beq cr6,0x82a7f438
	if (ctx.cr6.eq) goto loc_82A7F438;
	// cmpwi cr6,r11,41
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 41, ctx.xer);
	// beq cr6,0x82a7f430
	if (ctx.cr6.eq) goto loc_82A7F430;
	// cmpwi cr6,r11,91
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 91, ctx.xer);
	// beq cr6,0x82a7f438
	if (ctx.cr6.eq) goto loc_82A7F438;
	// cmpwi cr6,r11,93
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 93, ctx.xer);
	// beq cr6,0x82a7f430
	if (ctx.cr6.eq) goto loc_82A7F430;
	// cmpwi cr6,r11,123
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 123, ctx.xer);
	// beq cr6,0x82a7f438
	if (ctx.cr6.eq) goto loc_82A7F438;
	// cmpwi cr6,r11,125
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 125, ctx.xer);
	// bne cr6,0x82a7f43c
	if (!ctx.cr6.eq) goto loc_82A7F43C;
loc_82A7F430:
	// addi r29,r29,-1
	ctx.r29.s64 = ctx.r29.s64 + -1;
	// b 0x82a7f43c
	goto loc_82A7F43C;
loc_82A7F438:
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
loc_82A7F43C:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82a7f304
	if (!ctx.cr6.eq) goto loc_82A7F304;
	// lwz r21,84(r1)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r10,r19
	ctx.r10.u64 = ctx.r19.u64;
	// mr r11,r21
	ctx.r11.u64 = ctx.r21.u64;
loc_82A7F450:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7f474
	if (ctx.cr6.eq) goto loc_82A7F474;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82a7f474
	if (ctx.cr6.eq) goto loc_82A7F474;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne 0x82a7f450
	if (!ctx.cr0.eq) goto loc_82A7F450;
loc_82A7F474:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a7f4d0
	if (ctx.cr6.eq) goto loc_82A7F4D0;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82a7f4ac
	if (!ctx.cr6.eq) goto loc_82A7F4AC;
	// lwz r7,8(r26)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// b 0x82a7f4b4
	goto loc_82A7F4B4;
loc_82A7F490:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1515
	ctx.r5.s64 = 1515;
	// addi r6,r11,-21272
	ctx.r6.s64 = ctx.r11.s64 + -21272;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// addi r3,r20,24
	ctx.r3.s64 = ctx.r20.s64 + 24;
	// bl 0x82a85c20
	ctx.lr = 0x82A7F4A8;
	sub_82A85C20(ctx, base);
	// b 0x82a7fa2c
	goto loc_82A7FA2C;
loc_82A7F4AC:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r7,r11,-5092
	ctx.r7.s64 = ctx.r11.s64 + -5092;
loc_82A7F4B4:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r6,r11,-21316
	ctx.r6.s64 = ctx.r11.s64 + -21316;
loc_82A7F4BC:
	// li r5,1516
	ctx.r5.s64 = 1516;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// addi r3,r20,24
	ctx.r3.s64 = ctx.r20.s64 + 24;
	// bl 0x82a85c20
	ctx.lr = 0x82A7F4CC;
	sub_82A85C20(ctx, base);
	// b 0x82a7fa2c
	goto loc_82A7FA2C;
loc_82A7F4D0:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7f500
	if (ctx.cr6.eq) goto loc_82A7F500;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82a7f4ec
	if (!ctx.cr6.eq) goto loc_82A7F4EC;
	// lwz r7,8(r26)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// b 0x82a7f4f4
	goto loc_82A7F4F4;
loc_82A7F4EC:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r7,r11,-5092
	ctx.r7.s64 = ctx.r11.s64 + -5092;
loc_82A7F4F4:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r6,r11,-21352
	ctx.r6.s64 = ctx.r11.s64 + -21352;
	// b 0x82a7f4bc
	goto loc_82A7F4BC;
loc_82A7F500:
	// mr r28,r18
	ctx.r28.u64 = ctx.r18.u64;
	// mr r29,r18
	ctx.r29.u64 = ctx.r18.u64;
	// mr r25,r18
	ctx.r25.u64 = ctx.r18.u64;
	// addi r30,r1,80
	ctx.r30.s64 = ctx.r1.s64 + 80;
	// mr r24,r27
	ctx.r24.u64 = ctx.r27.u64;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a7f850
	if (ctx.cr6.eq) goto loc_82A7F850;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r23,r11,-21356
	ctx.r23.s64 = ctx.r11.s64 + -21356;
	// lis r11,-32242
	ctx.r11.s64 = -2113011712;
	// addi r22,r11,-19648
	ctx.r22.s64 = ctx.r11.s64 + -19648;
loc_82A7F52C:
	// addi r31,r24,16
	ctx.r31.s64 = ctx.r24.s64 + 16;
	// mr r26,r30
	ctx.r26.u64 = ctx.r30.u64;
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// bne cr6,0x82a7f5d8
	if (!ctx.cr6.eq) goto loc_82A7F5D8;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// bne cr6,0x82a7f5d8
	if (!ctx.cr6.eq) goto loc_82A7F5D8;
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmpwi cr6,r7,1
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 1, ctx.xer);
	// bne cr6,0x82a7f5d8
	if (!ctx.cr6.eq) goto loc_82A7F5D8;
	// addi r11,r31,8
	ctx.r11.s64 = ctx.r31.s64 + 8;
	// mr r10,r22
	ctx.r10.u64 = ctx.r22.u64;
loc_82A7F558:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7f57c
	if (ctx.cr0.eq) goto loc_82A7F57C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7f558
	if (ctx.cr6.eq) goto loc_82A7F558;
loc_82A7F57C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7f590
	if (!ctx.cr0.eq) goto loc_82A7F590;
	// mr r25,r31
	ctx.r25.u64 = ctx.r31.u64;
	// li r28,1
	ctx.r28.s64 = 1;
	// b 0x82a7f844
	goto loc_82A7F844;
loc_82A7F590:
	// cmpwi cr6,r7,1
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 1, ctx.xer);
	// bne cr6,0x82a7f5d8
	if (!ctx.cr6.eq) goto loc_82A7F5D8;
	// addi r11,r31,8
	ctx.r11.s64 = ctx.r31.s64 + 8;
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
loc_82A7F5A0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7f5c4
	if (ctx.cr0.eq) goto loc_82A7F5C4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7f5a0
	if (ctx.cr6.eq) goto loc_82A7F5A0;
loc_82A7F5C4:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7f5d8
	if (!ctx.cr0.eq) goto loc_82A7F5D8;
	// mr r25,r31
	ctx.r25.u64 = ctx.r31.u64;
	// li r29,1
	ctx.r29.s64 = 1;
	// b 0x82a7f844
	goto loc_82A7F844;
loc_82A7F5D8:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82a7f684
	if (!ctx.cr6.eq) goto loc_82A7F684;
	// lwz r6,8(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r8,r19
	ctx.r8.u64 = ctx.r19.u64;
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
loc_82A7F5F0:
	// lwz r11,24(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 24);
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
loc_82A7F5F8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r7,r7,r9
	ctx.r7.s64 = ctx.r9.s64 - ctx.r7.s64;
	// beq 0x82a7f61c
	if (ctx.cr0.eq) goto loc_82A7F61C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82a7f5f8
	if (ctx.cr6.eq) goto loc_82A7F5F8;
loc_82A7F61C:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq 0x82a7f634
	if (ctx.cr0.eq) goto loc_82A7F634;
	// lwz r8,12(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// lwz r5,12(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// cmplwi r8,0
	ctx.cr0.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne 0x82a7f5f0
	if (!ctx.cr0.eq) goto loc_82A7F5F0;
loc_82A7F634:
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82a7f684
	if (ctx.cr6.eq) goto loc_82A7F684;
	// lwz r31,8(r5)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// b 0x82a7f678
	goto loc_82A7F678;
loc_82A7F644:
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82ab71b8
	ctx.lr = 0x82A7F64C;
	sub_82AB71B8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7f660
	if (ctx.cr0.eq) goto loc_82A7F660;
	// addi r4,r31,16
	ctx.r4.s64 = ctx.r31.s64 + 16;
	// bl 0x82ab77d8
	ctx.lr = 0x82A7F65C;
	sub_82AB77D8(ctx, base);
	// b 0x82a7f664
	goto loc_82A7F664;
loc_82A7F660:
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
loc_82A7F664:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82a7fa2c
	if (ctx.cr6.eq) goto loc_82A7FA2C;
	// lwz r31,12(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r30,r3,12
	ctx.r30.s64 = ctx.r3.s64 + 12;
loc_82A7F678:
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne 0x82a7f644
	if (!ctx.cr0.eq) goto loc_82A7F644;
	// b 0x82a7f6b4
	goto loc_82A7F6B4;
loc_82A7F684:
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82ab71b8
	ctx.lr = 0x82A7F68C;
	sub_82AB71B8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7f6a0
	if (ctx.cr0.eq) goto loc_82A7F6A0;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82ab77d8
	ctx.lr = 0x82A7F69C;
	sub_82AB77D8(ctx, base);
	// b 0x82a7f6a4
	goto loc_82A7F6A4;
loc_82A7F6A0:
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
loc_82A7F6A4:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82a7fa2c
	if (ctx.cr6.eq) goto loc_82A7FA2C;
	// addi r30,r3,12
	ctx.r30.s64 = ctx.r3.s64 + 12;
loc_82A7F6B4:
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// bne cr6,0x82a7f6c4
	if (!ctx.cr6.eq) goto loc_82A7F6C4;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq cr6,0x82a7f844
	if (ctx.cr6.eq) goto loc_82A7F844;
loc_82A7F6C4:
	// lwz r31,0(r26)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// mr r11,r18
	ctx.r11.u64 = ctx.r18.u64;
	// li r30,1
	ctx.r30.s64 = 1;
	// b 0x82a7f718
	goto loc_82A7F718;
loc_82A7F6D4:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7f6ec
	if (ctx.cr6.eq) goto loc_82A7F6EC;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a7f6ec
	if (ctx.cr6.eq) goto loc_82A7F6EC;
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
loc_82A7F6EC:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r5,44(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,40(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x82a7b9f0
	ctx.lr = 0x82A7F704;
	sub_82A7B9F0(ctx, base);
	// lwz r11,44(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// add r30,r3,r30
	ctx.r30.u64 = ctx.r3.u64 + ctx.r30.u64;
	// lwz r31,12(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82A7F718:
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne 0x82a7f6d4
	if (!ctx.cr0.eq) goto loc_82A7F6D4;
	// addi r4,r30,1
	ctx.r4.s64 = ctx.r30.s64 + 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// bl 0x82ab7070
	ctx.lr = 0x82A7F734;
	sub_82AB7070(ctx, base);
	// mr. r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq 0x82a7fa2c
	if (ctx.cr0.eq) goto loc_82A7FA2C;
	// subfic r10,r28,0
	ctx.xer.ca = ctx.r28.u32 <= 0;
	ctx.r10.s64 = 0 - ctx.r28.s64;
	// mr r11,r18
	ctx.r11.u64 = ctx.r18.u64;
	// subfe r10,r10,r10
	temp.u8 = (~ctx.r10.u32 + ctx.r10.u32 < ~ctx.r10.u32) | (~ctx.r10.u32 + ctx.r10.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r10.u64 = ~ctx.r10.u64 + ctx.r10.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// li r30,1
	ctx.r30.s64 = 1;
	// rlwinm r10,r10,0,30,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
	// addi r28,r10,39
	ctx.r28.s64 = ctx.r10.s64 + 39;
	// stb r28,0(r29)
	PPC_STORE_U8(ctx.r29.u32 + 0, ctx.r28.u8);
	// lwz r31,0(r26)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// b 0x82a7f7ac
	goto loc_82A7F7AC;
loc_82A7F760:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7f780
	if (ctx.cr6.eq) goto loc_82A7F780;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a7f780
	if (ctx.cr6.eq) goto loc_82A7F780;
	// li r11,32
	ctx.r11.s64 = 32;
	// stbx r11,r29,r30
	PPC_STORE_U8(ctx.r29.u32 + ctx.r30.u32, ctx.r11.u8);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
loc_82A7F780:
	// subf r7,r30,r27
	ctx.r7.s64 = ctx.r27.s64 - ctx.r30.s64;
	// lwz r5,44(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// add r6,r29,r30
	ctx.r6.u64 = ctx.r29.u64 + ctx.r30.u64;
	// lwz r4,40(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x82a7b9f0
	ctx.lr = 0x82A7F798;
	sub_82A7B9F0(ctx, base);
	// lwz r11,44(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// add r30,r3,r30
	ctx.r30.u64 = ctx.r3.u64 + ctx.r30.u64;
	// lwz r31,12(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82A7F7AC:
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne 0x82a7f760
	if (!ctx.cr0.eq) goto loc_82A7F760;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// stbx r28,r29,r30
	PPC_STORE_U8(ctx.r29.u32 + ctx.r30.u32, ctx.r28.u8);
	// bl 0x82a850b0
	ctx.lr = 0x82A7F7C0;
	sub_82A850B0(ctx, base);
	// addi r9,r20,24
	ctx.r9.s64 = ctx.r20.s64 + 24;
	// mr r8,r20
	ctx.r8.u64 = ctx.r20.u64;
	// lwz r7,20(r25)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r25.u32 + 20);
	// addi r5,r30,1
	ctx.r5.s64 = ctx.r30.s64 + 1;
	// lwz r6,16(r25)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r25.u32 + 16);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82a850d8
	ctx.lr = 0x82A7F7E0;
	sub_82A850D8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// blt 0x82a7fa28
	if (ctx.cr0.lt) goto loc_82A7FA28;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// lwz r4,672(r20)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r20.u32 + 672);
	// bl 0x82a86ed8
	ctx.lr = 0x82A7F7F8;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7fa24
	if (ctx.cr0.lt) goto loc_82A7FA24;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82ab71b8
	ctx.lr = 0x82A7F808;
	sub_82AB71B8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7f820
	if (ctx.cr0.eq) goto loc_82A7F820;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82ab77d8
	ctx.lr = 0x82A7F818;
	sub_82AB77D8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// b 0x82a7f824
	goto loc_82A7F824;
loc_82A7F820:
	// mr r11,r18
	ctx.r11.u64 = ctx.r18.u64;
loc_82A7F824:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// beq cr6,0x82a7fa28
	if (ctx.cr6.eq) goto loc_82A7FA28;
	// addi r30,r11,12
	ctx.r30.s64 = ctx.r11.s64 + 12;
	// mr r29,r18
	ctx.r29.u64 = ctx.r18.u64;
	// mr r28,r18
	ctx.r28.u64 = ctx.r18.u64;
	// bl 0x82d09218
	ctx.lr = 0x82A7F844;
	sub_82D09218(ctx, base);
loc_82A7F844:
	// lwz r24,12(r24)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r24.u32 + 12);
	// cmplwi r24,0
	ctx.cr0.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// bne 0x82a7f52c
	if (!ctx.cr0.eq) goto loc_82A7F52C;
loc_82A7F850:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r25,r1,80
	ctx.r25.s64 = ctx.r1.s64 + 80;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a7fa64
	if (ctx.cr6.eq) goto loc_82A7FA64;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r24,r11,-21360
	ctx.r24.s64 = ctx.r11.s64 + -21360;
loc_82A7F868:
	// lwz r26,0(r25)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// cmplwi r26,0
	ctx.cr0.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq 0x82a7f87c
	if (ctx.cr0.eq) goto loc_82A7F87C;
	// lwz r10,12(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 12);
	// b 0x82a7f880
	goto loc_82A7F880;
loc_82A7F87C:
	// mr r10,r18
	ctx.r10.u64 = ctx.r18.u64;
loc_82A7F880:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a7f890
	if (ctx.cr6.eq) goto loc_82A7F890;
	// lwz r27,12(r10)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// b 0x82a7f894
	goto loc_82A7F894;
loc_82A7F890:
	// mr r27,r18
	ctx.r27.u64 = ctx.r18.u64;
loc_82A7F894:
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// addi r29,r26,16
	ctx.r29.s64 = ctx.r26.s64 + 16;
	// bne cr6,0x82a7f8a4
	if (!ctx.cr6.eq) goto loc_82A7F8A4;
	// mr r29,r18
	ctx.r29.u64 = ctx.r18.u64;
loc_82A7F8A4:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// addi r11,r10,16
	ctx.r11.s64 = ctx.r10.s64 + 16;
	// bne cr6,0x82a7f8b4
	if (!ctx.cr6.eq) goto loc_82A7F8B4;
	// mr r11,r18
	ctx.r11.u64 = ctx.r18.u64;
loc_82A7F8B4:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// addi r28,r27,16
	ctx.r28.s64 = ctx.r27.s64 + 16;
	// bne cr6,0x82a7f8c4
	if (!ctx.cr6.eq) goto loc_82A7F8C4;
	// mr r28,r18
	ctx.r28.u64 = ctx.r18.u64;
loc_82A7F8C4:
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a7fa54
	if (ctx.cr6.eq) goto loc_82A7FA54;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a7fa54
	if (ctx.cr6.eq) goto loc_82A7FA54;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a7fa54
	if (ctx.cr6.eq) goto loc_82A7FA54;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bne cr6,0x82a7fa54
	if (!ctx.cr6.eq) goto loc_82A7FA54;
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
loc_82A7F8F0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a7f914
	if (ctx.cr0.eq) goto loc_82A7F914;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a7f8f0
	if (ctx.cr6.eq) goto loc_82A7F8F0;
loc_82A7F914:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7fa54
	if (!ctx.cr0.eq) goto loc_82A7FA54;
	// lwz r11,28(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 28);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r10,28(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// add r30,r11,r10
	ctx.r30.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82ab7070
	ctx.lr = 0x82A7F938;
	sub_82AB7070(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// beq 0x82a7fa2c
	if (ctx.cr0.eq) goto loc_82A7FA2C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r5,28(r29)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r29.u32 + 28);
	// lwz r4,24(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 24);
	// bl 0x82d5c630
	ctx.lr = 0x82A7F950;
	sub_82D5C630(ctx, base);
	// lwz r11,28(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 28);
	// lwz r5,28(r28)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// add r3,r11,r31
	ctx.r3.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lwz r4,24(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// bl 0x82d5c630
	ctx.lr = 0x82A7F964;
	sub_82D5C630(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82a850b0
	ctx.lr = 0x82A7F96C;
	sub_82A850B0(ctx, base);
	// addi r9,r20,24
	ctx.r9.s64 = ctx.r20.s64 + 24;
	// mr r8,r20
	ctx.r8.u64 = ctx.r20.u64;
	// lwz r7,20(r29)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r6,16(r29)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r29.u32 + 16);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82a850d8
	ctx.lr = 0x82A7F98C;
	sub_82A850D8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7fa24
	if (ctx.cr0.lt) goto loc_82A7FA24;
	// lwz r30,12(r27)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// mr r31,r26
	ctx.r31.u64 = ctx.r26.u64;
loc_82A7F99C:
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// lwz r4,672(r20)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r20.u32 + 672);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82a86ed8
	ctx.lr = 0x82A7F9AC;
	sub_82A86ED8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a7fa24
	if (ctx.cr0.lt) goto loc_82A7FA24;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82a7fa34
	if (ctx.cr6.eq) goto loc_82A7FA34;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82a7f9f8
	if (ctx.cr6.eq) goto loc_82A7F9F8;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// addi r10,r31,16
	ctx.r10.s64 = ctx.r31.s64 + 16;
	// mr r31,r18
	ctx.r31.u64 = ctx.r18.u64;
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// ld r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// ld r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// std r9,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.r9.u64);
	// std r8,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, ctx.r8.u64);
	// std r7,16(r10)
	PPC_STORE_U64(ctx.r10.u32 + 16, ctx.r7.u64);
	// std r11,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, ctx.r11.u64);
	// b 0x82a7f99c
	goto loc_82A7F99C;
loc_82A7F9F8:
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82ab71b8
	ctx.lr = 0x82A7FA00;
	sub_82AB71B8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7fa14
	if (ctx.cr0.eq) goto loc_82A7FA14;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82ab77d8
	ctx.lr = 0x82A7FA10;
	sub_82AB77D8(ctx, base);
	// b 0x82a7fa18
	goto loc_82A7FA18;
loc_82A7FA14:
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
loc_82A7FA18:
	// stw r3,12(r26)
	PPC_STORE_U32(ctx.r26.u32 + 12, ctx.r3.u32);
	// mr. r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// bne 0x82a7f99c
	if (!ctx.cr0.eq) goto loc_82A7F99C;
loc_82A7FA24:
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
loc_82A7FA28:
	// bl 0x82d09218
	ctx.lr = 0x82A7FA2C;
	sub_82D09218(ctx, base);
loc_82A7FA2C:
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
	// b 0x82a7fa80
	goto loc_82A7FA80;
loc_82A7FA34:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82a7fa44
	if (!ctx.cr6.eq) goto loc_82A7FA44;
	// stw r30,12(r26)
	PPC_STORE_U32(ctx.r26.u32 + 12, ctx.r30.u32);
	// b 0x82a7fa48
	goto loc_82A7FA48;
loc_82A7FA44:
	// stw r30,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r30.u32);
loc_82A7FA48:
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82d09218
	ctx.lr = 0x82A7FA50;
	sub_82D09218(ctx, base);
	// b 0x82a7fa58
	goto loc_82A7FA58;
loc_82A7FA54:
	// addi r25,r26,12
	ctx.r25.s64 = ctx.r26.s64 + 12;
loc_82A7FA58:
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a7f868
	if (!ctx.cr6.eq) goto loc_82A7F868;
loc_82A7FA64:
	// lwz r11,112(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 112);
	// stw r11,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r11.u32);
loc_82A7FA6C:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,112(r20)
	PPC_STORE_U32(ctx.r20.u32 + 112, ctx.r11.u32);
	// b 0x82a7fa80
	goto loc_82A7FA80;
loc_82A7FA7C:
	// li r3,2
	ctx.r3.s64 = 2;
loc_82A7FA80:
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x82d5c4f0
	__restgprlr_18(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7FA88"))) PPC_WEAK_FUNC(sub_82A7FA88);
PPC_FUNC_IMPL(__imp__sub_82A7FA88) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r31,r11,-1
	ctx.r31.s64 = ctx.r11.s64 + -1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// bne cr6,0x82a7fac0
	if (!ctx.cr6.eq) goto loc_82A7FAC0;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A7FAC0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82A7FAC0:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7FAD8"))) PPC_WEAK_FUNC(sub_82A7FAD8);
PPC_FUNC_IMPL(__imp__sub_82A7FAD8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8247f370
	ctx.lr = 0x82A7FB00;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r3.u32);
	// bne 0x82a7fb18
	if (!ctx.cr0.eq) goto loc_82A7FB18;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82a7fb20
	goto loc_82A7FB20;
loc_82A7FB18:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r30,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r30.u32);
loc_82A7FB20:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7FB38"))) PPC_WEAK_FUNC(sub_82A7FB38);
PPC_FUNC_IMPL(__imp__sub_82A7FB38) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,2348
	ctx.r10.s64 = ctx.r10.s64 + 2348;
	// stw r9,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r9.u32);
	// addi r9,r11,16
	ctx.r9.s64 = ctx.r11.s64 + 16;
loc_82A7FB5C:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7fb7c
	if (!ctx.cr0.eq) goto loc_82A7FB7C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82a7fb5c
	if (!ctx.cr6.eq) goto loc_82A7FB5C;
loc_82A7FB7C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a7fbbc
	if (ctx.cr0.eq) goto loc_82A7FBBC;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r11,16
	ctx.r9.s64 = ctx.r11.s64 + 16;
	// addi r10,r10,2316
	ctx.r10.s64 = ctx.r10.s64 + 2316;
loc_82A7FB94:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7fbb4
	if (!ctx.cr0.eq) goto loc_82A7FBB4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82a7fb94
	if (!ctx.cr6.eq) goto loc_82A7FB94;
loc_82A7FBB4:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a7fbd8
	if (!ctx.cr0.eq) goto loc_82A7FBD8;
loc_82A7FBBC:
	// stw r3,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r3.u32);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A7FBD0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82a7fbe0
	goto loc_82A7FBE0;
loc_82A7FBD8:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16386
	ctx.r3.u64 = ctx.r3.u64 | 16386;
loc_82A7FBE0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7FBF0"))) PPC_WEAK_FUNC(sub_82A7FBF0);
PPC_FUNC_IMPL(__imp__sub_82A7FBF0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r11,r11,-21224
	ctx.r11.s64 = ctx.r11.s64 + -21224;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// bl 0x8247f398
	ctx.lr = 0x82A7FC24;
	sub_8247F398(ctx, base);
	// clrlwi. r11,r30,31
	ctx.r11.u64 = ctx.r30.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a7fc38
	if (ctx.cr0.eq) goto loc_82A7FC38;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A7FC38;
	sub_8247F398(ctx, base);
loc_82A7FC38:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7FC58"))) PPC_WEAK_FUNC(sub_82A7FC58);
PPC_FUNC_IMPL(__imp__sub_82A7FC58) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A7FC60;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82a7fc80
	if (!ctx.cr6.eq) goto loc_82A7FC80;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82a7fd1c
	goto loc_82A7FD1C;
loc_82A7FC80:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,16
	ctx.r3.s64 = 16;
	// bl 0x8247f370
	ctx.lr = 0x82A7FC8C;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a7fcbc
	if (ctx.cr0.eq) goto loc_82A7FCBC;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,-21224
	ctx.r11.s64 = ctx.r11.s64 + -21224;
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// b 0x82a7fcc0
	goto loc_82A7FCC0;
loc_82A7FCBC:
	// li r31,0
	ctx.r31.s64 = 0;
loc_82A7FCC0:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82a7fcd4
	if (!ctx.cr6.eq) goto loc_82A7FCD4;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82a7fd1c
	goto loc_82A7FD1C;
loc_82A7FCD4:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A7FCEC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bge 0x82a7fd14
	if (!ctx.cr0.lt) goto loc_82A7FD14;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A7FD0C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// b 0x82a7fd1c
	goto loc_82A7FD1C;
loc_82A7FD14:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r31.u32);
loc_82A7FD1C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7FD28"))) PPC_WEAK_FUNC(sub_82A7FD28);
PPC_FUNC_IMPL(__imp__sub_82A7FD28) {
	PPC_FUNC_PROLOGUE();
	// b 0x82a7fc58
	sub_82A7FC58(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7FD30"))) PPC_WEAK_FUNC(sub_82A7FD30);
PPC_FUNC_IMPL(__imp__sub_82A7FD30) {
	PPC_FUNC_PROLOGUE();
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82a7fd40
	if (ctx.cr6.eq) goto loc_82A7FD40;
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r11.u32);
loc_82A7FD40:
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82a7fd4c
	if (ctx.cr6.eq) goto loc_82A7FD4C;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82A7FD4C:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82a7fd60
	if (!ctx.cr6.eq) goto loc_82A7FD60;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// blr 
	return;
loc_82A7FD60:
	// lwz r8,0(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lis r11,4138
	ctx.r11.s64 = 271187968;
	// ori r11,r11,4352
	ctx.r11.u64 = ctx.r11.u64 | 4352;
	// rlwinm r10,r8,0,0,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFF00;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82a7fd80
	if (!ctx.cr6.eq) goto loc_82A7FD80;
loc_82A7FD78:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82A7FD80:
	// rlwinm r11,r8,0,0,15
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFF0000;
	// lis r10,18008
	ctx.r10.s64 = 1180172288;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a7fdd8
	if (ctx.cr6.eq) goto loc_82A7FDD8;
	// lis r10,21592
	ctx.r10.s64 = 1415053312;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a7fdd8
	if (ctx.cr6.eq) goto loc_82A7FDD8;
	// lis r10,32766
	ctx.r10.s64 = 2147352576;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a7fdd8
	if (ctx.cr6.eq) goto loc_82A7FDD8;
	// lis r10,32767
	ctx.r10.s64 = 2147418112;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a7fdd8
	if (ctx.cr6.eq) goto loc_82A7FDD8;
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a7fdd8
	if (ctx.cr6.eq) goto loc_82A7FDD8;
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a7fdd8
	if (ctx.cr6.eq) goto loc_82A7FDD8;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2905
	ctx.r3.u64 = ctx.r3.u64 | 2905;
	// blr 
	return;
loc_82A7FDD8:
	// addi r11,r3,4
	ctx.r11.s64 = ctx.r3.s64 + 4;
loc_82A7FDDC:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// rlwinm. r9,r10,0,0,0
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80000000;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne 0x82a7fe40
	if (!ctx.cr0.eq) goto loc_82A7FE40;
	// clrlwi r9,r10,16
	ctx.r9.u64 = ctx.r10.u32 & 0xFFFF;
	// cmplwi cr6,r9,65535
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 65535, ctx.xer);
	// beq cr6,0x82a7fd78
	if (ctx.cr6.eq) goto loc_82A7FD78;
	// cmplwi cr6,r9,65534
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 65534, ctx.xer);
	// bne cr6,0x82a7fe20
	if (!ctx.cr6.eq) goto loc_82A7FE20;
	// rlwinm r10,r10,16,17,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0x7FFF;
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// ble cr6,0x82a7fe14
	if (!ctx.cr6.gt) goto loc_82A7FE14;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplw cr6,r4,r9
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82a7fe48
	if (ctx.cr6.eq) goto loc_82A7FE48;
loc_82A7FE14:
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_82A7FE18:
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// b 0x82a7fe40
	goto loc_82A7FE40;
loc_82A7FE20:
	// clrlwi r7,r8,16
	ctx.r7.u64 = ctx.r8.u32 & 0xFFFF;
	// cmplwi cr6,r7,512
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 512, ctx.xer);
	// blt cr6,0x82a7fe34
	if (ctx.cr6.lt) goto loc_82A7FE34;
	// rlwinm r10,r10,10,26,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 10) & 0x3C;
	// b 0x82a7fe18
	goto loc_82A7FE18;
loc_82A7FE34:
	// cmplwi cr6,r9,81
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 81, ctx.xer);
	// bne cr6,0x82a7fe40
	if (!ctx.cr6.eq) goto loc_82A7FE40;
	// addi r11,r11,20
	ctx.r11.s64 = ctx.r11.s64 + 20;
loc_82A7FE40:
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// b 0x82a7fddc
	goto loc_82A7FDDC;
loc_82A7FE48:
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82a7fe58
	if (ctx.cr6.eq) goto loc_82A7FE58;
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r11.u32);
loc_82A7FE58:
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82a7fe6c
	if (ctx.cr6.eq) goto loc_82A7FE6C;
	// addi r11,r10,-1
	ctx.r11.s64 = ctx.r10.s64 + -1;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82A7FE6C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A7FE78"))) PPC_WEAK_FUNC(sub_82A7FE78);
PPC_FUNC_IMPL(__imp__sub_82A7FE78) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b8
	ctx.lr = 0x82A7FE80;
	__savegprlr_24(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r25,r4
	ctx.r25.u64 = ctx.r4.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r30,r7
	ctx.r30.u64 = ctx.r7.u64;
	// lhz r11,10(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 10);
	// mr r24,r8
	ctx.r24.u64 = ctx.r8.u64;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a7ff0c
	if (ctx.cr0.eq) goto loc_82A7FF0C;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// li r27,0
	ctx.r27.s64 = 0;
	// lwz r9,8(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// beq cr6,0x82a7ff7c
	if (ctx.cr6.eq) goto loc_82A7FF7C;
	// addi r26,r10,4
	ctx.r26.s64 = ctx.r10.s64 + 4;
loc_82A7FEC4:
	// lwz r10,0(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq 0x82a7fef4
	if (ctx.cr0.eq) goto loc_82A7FEF4;
	// lwz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// mr r8,r24
	ctx.r8.u64 = ctx.r24.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// add r5,r10,r11
	ctx.r5.u64 = ctx.r10.u64 + ctx.r11.u64;
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lhz r11,8(r5)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r5.u32 + 8);
	// mullw r6,r11,r28
	ctx.r6.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// bl 0x82a7fe78
	ctx.lr = 0x82A7FEF4;
	sub_82A7FE78(ctx, base);
loc_82A7FEF4:
	// lhz r11,10(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 10);
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// addi r26,r26,8
	ctx.r26.s64 = ctx.r26.s64 + 8;
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a7fec4
	if (ctx.cr6.lt) goto loc_82A7FEC4;
	// b 0x82a7ff7c
	goto loc_82A7FF7C;
loc_82A7FF0C:
	// lhz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82a7ff24
	if (!ctx.cr0.eq) goto loc_82A7FF24;
	// lhz r11,6(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// b 0x82a7ff4c
	goto loc_82A7FF4C;
loc_82A7FF24:
	// lhz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82a7ff3c
	if (ctx.cr6.eq) goto loc_82A7FF3C;
	// lhz r11,6(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// b 0x82a7ff44
	goto loc_82A7FF44;
loc_82A7FF3C:
	// lhz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// lhz r9,6(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
loc_82A7FF44:
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// srawi r11,r11,2
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 2;
loc_82A7FF4C:
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mullw r11,r11,r28
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r11.u32);
	// lhz r11,6(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// lwz r10,0(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// mullw r11,r11,r28
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,0(r24)
	PPC_STORE_U32(ctx.r24.u32 + 0, ctx.r11.u32);
loc_82A7FF7C:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82d5c508
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A7FF88"))) PPC_WEAK_FUNC(sub_82A7FF88);
PPC_FUNC_IMPL(__imp__sub_82A7FF88) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A7FF90;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// addi r9,r31,4
	ctx.r9.s64 = ctx.r31.s64 + 4;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// li r11,5
	ctx.r11.s64 = 5;
	// stw r3,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r3.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
loc_82A7FFB8:
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r11.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x82a7ffb8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82A7FFB8;
	// li r30,0
	ctx.r30.s64 = 0;
	// stw r7,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r7.u32);
	// addi r11,r31,44
	ctx.r11.s64 = ctx.r31.s64 + 44;
	// stw r8,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r8.u32);
	// addi r10,r31,52
	ctx.r10.s64 = ctx.r31.s64 + 52;
	// stw r29,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r29.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// stw r30,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r30.u32);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// stw r30,44(r31)
	PPC_STORE_U32(ctx.r31.u32 + 44, ctx.r30.u32);
	// stw r30,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r30.u32);
	// bl 0x82a7fe78
	ctx.lr = 0x82A80004;
	sub_82A7FE78(ctx, base);
	// lhz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r29.u32 + 8);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r9,52(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// stw r11,40(r31)
	PPC_STORE_U32(ctx.r31.u32 + 40, ctx.r11.u32);
	// lhz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r29.u32 + 8);
	// stw r30,56(r31)
	PPC_STORE_U32(ctx.r31.u32 + 56, ctx.r30.u32);
	// stw r30,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r30.u32);
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// stw r30,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r30.u32);
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A80040"))) PPC_WEAK_FUNC(sub_82A80040);
PPC_FUNC_IMPL(__imp__sub_82A80040) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A80048;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// lwz r11,24(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// stw r29,32(r30)
	PPC_STORE_U32(ctx.r30.u32 + 32, ctx.r29.u32);
	// lhz r11,10(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 10);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a800d4
	if (ctx.cr0.eq) goto loc_82A800D4;
	// lwz r10,56(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	// li r31,0
	ctx.r31.s64 = 0;
loc_82A80074:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwzx r3,r31,r10
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r10.u32);
	// bl 0x82a80040
	ctx.lr = 0x82A80080;
	sub_82A80040(ctx, base);
	// lwz r10,56(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	// li r9,1
	ctx.r9.s64 = 1;
	// lwzx r11,r31,r10
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r10.u32);
	// lhz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 8);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a8009c
	if (ctx.cr0.eq) goto loc_82A8009C;
	// li r9,4
	ctx.r9.s64 = 4;
loc_82A8009C:
	// lwzx r11,r31,r10
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r10.u32);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// lwz r8,24(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// lwz r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lhz r8,10(r8)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r8.u32 + 10);
	// lwz r11,44(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	// cmplw cr6,r28,r8
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r8.u32, ctx.xer);
	// lhz r8,8(r7)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r7.u32 + 8);
	// mullw r11,r8,r11
	ctx.r11.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r11.s32);
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r29,r11,r29
	ctx.r29.u64 = ctx.r11.u64 + ctx.r29.u64;
	// blt cr6,0x82a80074
	if (ctx.cr6.lt) goto loc_82A80074;
loc_82A800D4:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A800E0"))) PPC_WEAK_FUNC(sub_82A800E0);
PPC_FUNC_IMPL(__imp__sub_82A800E0) {
	PPC_FUNC_PROLOGUE();
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r9,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r9.u32);
	// stw r9,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r9.u32);
	// stw r9,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r9.u32);
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a8010c
	if (ctx.cr0.eq) goto loc_82A8010C;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// b 0x82a80110
	goto loc_82A80110;
loc_82A8010C:
	// mr r11,r9
	ctx.r11.u64 = ctx.r9.u64;
loc_82A80110:
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
	// lhz r11,8(r3)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 8);
	// stw r11,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r11.u32);
	// lhz r11,10(r3)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 10);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r11.u32);
	// lhz r11,12(r3)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 12);
	// stw r11,12(r4)
	PPC_STORE_U32(ctx.r4.u32 + 12, ctx.r11.u32);
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lhz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// stw r11,16(r4)
	PPC_STORE_U32(ctx.r4.u32 + 16, ctx.r11.u32);
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lhz r11,2(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 2);
	// stw r11,20(r4)
	PPC_STORE_U32(ctx.r4.u32 + 20, ctx.r11.u32);
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lhz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 4);
	// stw r11,24(r4)
	PPC_STORE_U32(ctx.r4.u32 + 24, ctx.r11.u32);
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r10,24(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// lhz r11,6(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 6);
	// stw r11,28(r4)
	PPC_STORE_U32(ctx.r4.u32 + 28, ctx.r11.u32);
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r8,28(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// lhz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 8);
	// stw r11,32(r4)
	PPC_STORE_U32(ctx.r4.u32 + 32, ctx.r11.u32);
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// lwz r7,24(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// lhz r10,10(r7)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r7.u32 + 10);
	// mullw r11,r11,r8
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r8.s32);
	// stw r10,36(r4)
	PPC_STORE_U32(ctx.r4.u32 + 36, ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r11,40(r4)
	PPC_STORE_U32(ctx.r4.u32 + 40, ctx.r11.u32);
	// lwz r11,20(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a801ac
	if (ctx.cr0.eq) goto loc_82A801AC;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// b 0x82a801b0
	goto loc_82A801B0;
loc_82A801AC:
	// mr r11,r9
	ctx.r11.u64 = ctx.r9.u64;
loc_82A801B0:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,44(r4)
	PPC_STORE_U32(ctx.r4.u32 + 44, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A801C0"))) PPC_WEAK_FUNC(sub_82A801C0);
PPC_FUNC_IMPL(__imp__sub_82A801C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// lwz r31,20(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a80248
	if (ctx.cr0.eq) goto loc_82A80248;
	// lhz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 8);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// li r10,1
	ctx.r10.s64 = 1;
	// beq 0x82a801f8
	if (ctx.cr0.eq) goto loc_82A801F8;
	// li r10,4
	ctx.r10.s64 = 4;
loc_82A801F8:
	// lwz r8,28(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// cmplwi r8,0
	ctx.cr0.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne 0x82a80210
	if (!ctx.cr0.eq) goto loc_82A80210;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82a8024c
	goto loc_82A8024C;
loc_82A80210:
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mullw r10,r10,r5
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r5.s32);
	// lhz r9,10(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 10);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lhz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r11.u32 + 12);
	// lwz r6,32(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// lwz r11,8(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// add r4,r9,r5
	ctx.r4.u64 = ctx.r9.u64 + ctx.r5.u64;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// add r5,r11,r31
	ctx.r5.u64 = ctx.r11.u64 + ctx.r31.u64;
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x82A80240;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a8024c
	if (ctx.cr0.lt) goto loc_82A8024C;
loc_82A80248:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A8024C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80260"))) PPC_WEAK_FUNC(sub_82A80260);
PPC_FUNC_IMPL(__imp__sub_82A80260) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,2348
	ctx.r10.s64 = ctx.r10.s64 + 2348;
	// stw r9,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r9.u32);
	// addi r9,r11,16
	ctx.r9.s64 = ctx.r11.s64 + 16;
loc_82A80284:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a802a4
	if (!ctx.cr0.eq) goto loc_82A802A4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82a80284
	if (!ctx.cr6.eq) goto loc_82A80284;
loc_82A802A4:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a802e4
	if (ctx.cr0.eq) goto loc_82A802E4;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r11,16
	ctx.r9.s64 = ctx.r11.s64 + 16;
	// addi r10,r10,2332
	ctx.r10.s64 = ctx.r10.s64 + 2332;
loc_82A802BC:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a802dc
	if (!ctx.cr0.eq) goto loc_82A802DC;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82a802bc
	if (!ctx.cr6.eq) goto loc_82A802BC;
loc_82A802DC:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a80300
	if (!ctx.cr0.eq) goto loc_82A80300;
loc_82A802E4:
	// stw r3,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r3.u32);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A802F8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82a80308
	goto loc_82A80308;
loc_82A80300:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16386
	ctx.r3.u64 = ctx.r3.u64 | 16386;
loc_82A80308:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80318"))) PPC_WEAK_FUNC(sub_82A80318);
PPC_FUNC_IMPL(__imp__sub_82A80318) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne cr6,0x82a8032c
	if (!ctx.cr6.eq) goto loc_82A8032C;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// blr 
	return;
loc_82A8032C:
	// lwz r11,12(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmplwi cr6,r11,28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 28, ctx.xer);
	// blt cr6,0x82a80354
	if (ctx.cr6.lt) goto loc_82A80354;
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r10,28
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 28, ctx.xer);
	// blt cr6,0x82a80354
	if (ctx.cr6.lt) goto loc_82A80354;
	// lwz r10,4(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a80360
	if (ctx.cr6.lt) goto loc_82A80360;
loc_82A80354:
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2905
	ctx.r3.u64 = ctx.r3.u64 | 2905;
	// blr 
	return;
loc_82A80360:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// stw r10,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r10.u32);
	// stw r10,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r10.u32);
	// lwz r11,4(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a80384
	if (ctx.cr0.eq) goto loc_82A80384;
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
loc_82A80384:
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r11,8(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// stw r11,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r11.u32);
	// lwz r11,12(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A803A0"))) PPC_WEAK_FUNC(sub_82A803A0);
PPC_FUNC_IMPL(__imp__sub_82A803A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A803A8;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// li r29,0
	ctx.r29.s64 = 0;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x82a803f8
	if (!ctx.cr6.gt) goto loc_82A803F8;
	// li r30,0
	ctx.r30.s64 = 0;
loc_82A803C8:
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwzx r3,r11,r30
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// bl 0x82a801c0
	ctx.lr = 0x82A803DC;
	sub_82A801C0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a803fc
	if (ctx.cr0.lt) goto loc_82A803FC;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a803c8
	if (ctx.cr6.lt) goto loc_82A803C8;
loc_82A803F8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A803FC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A80408"))) PPC_WEAK_FUNC(sub_82A80408);
PPC_FUNC_IMPL(__imp__sub_82A80408) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A80410;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a80478
	if (ctx.cr6.eq) goto loc_82A80478;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// li r29,0
	ctx.r29.s64 = 0;
	// lhz r11,10(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 10);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a8046c
	if (ctx.cr0.eq) goto loc_82A8046C;
	// li r30,0
	ctx.r30.s64 = 0;
loc_82A8043C:
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// lwzx r3,r30,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r11.u32);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a80454
	if (ctx.cr0.eq) goto loc_82A80454;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82a837f0
	ctx.lr = 0x82A80454;
	sub_82A837F0(ctx, base);
loc_82A80454:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// lhz r11,10(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 10);
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a8043c
	if (ctx.cr6.lt) goto loc_82A8043C;
loc_82A8046C:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,56(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// bl 0x8247f398
	ctx.lr = 0x82A80478;
	sub_8247F398(ctx, base);
loc_82A80478:
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a804d8
	if (ctx.cr6.eq) goto loc_82A804D8;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// li r29,0
	ctx.r29.s64 = 0;
	// lhz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 8);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a804cc
	if (ctx.cr0.eq) goto loc_82A804CC;
	// li r30,0
	ctx.r30.s64 = 0;
loc_82A8049C:
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// lwzx r3,r11,r30
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a804b4
	if (ctx.cr0.eq) goto loc_82A804B4;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82a837f0
	ctx.lr = 0x82A804B4;
	sub_82A837F0(ctx, base);
loc_82A804B4:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// lhz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 8);
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a8049c
	if (ctx.cr6.lt) goto loc_82A8049C;
loc_82A804CC:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,60(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// bl 0x8247f398
	ctx.lr = 0x82A804D8;
	sub_8247F398(ctx, base);
loc_82A804D8:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// bl 0x8247f398
	ctx.lr = 0x82A804E4;
	sub_8247F398(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A804F0"))) PPC_WEAK_FUNC(sub_82A804F0);
PPC_FUNC_IMPL(__imp__sub_82A804F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// bne cr6,0x82a80524
	if (!ctx.cr6.eq) goto loc_82A80524;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// bne cr6,0x82a80524
	if (!ctx.cr6.eq) goto loc_82A80524;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82a805b4
	goto loc_82A805B4;
loc_82A80524:
	// not. r31,r11
	ctx.r31.u64 = ~ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r30,1
	ctx.r30.s64 = 1;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// beq 0x82a80548
	if (ctx.cr0.eq) goto loc_82A80548;
loc_82A80538:
	// lwz r11,36(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82a80538
	if (!ctx.cr0.eq) goto loc_82A80538;
loc_82A80548:
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82a80570
	if (ctx.cr6.eq) goto loc_82A80570;
	// lwz r30,0(r6)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplwi r30,0
	ctx.cr0.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne 0x82a80560
	if (!ctx.cr0.eq) goto loc_82A80560;
	// li r30,1
	ctx.r30.s64 = 1;
loc_82A80560:
	// cmplw cr6,r30,r10
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a8056c
	if (!ctx.cr6.gt) goto loc_82A8056C;
	// mr r30,r10
	ctx.r30.u64 = ctx.r10.u64;
loc_82A8056C:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82A80570:
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82a805b0
	if (ctx.cr6.eq) goto loc_82A805B0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82a805b0
	if (ctx.cr6.eq) goto loc_82A805B0;
loc_82A80580:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82a805b0
	if (ctx.cr6.eq) goto loc_82A805B0;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a800e0
	ctx.lr = 0x82A80594;
	sub_82A800E0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a805b4
	if (ctx.cr0.lt) goto loc_82A805B4;
	// lwz r31,36(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// addi r5,r5,48
	ctx.r5.s64 = ctx.r5.s64 + 48;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne 0x82a80580
	if (!ctx.cr0.eq) goto loc_82A80580;
loc_82A805B0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A805B4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A805D0"))) PPC_WEAK_FUNC(sub_82A805D0);
PPC_FUNC_IMPL(__imp__sub_82A805D0) {
	PPC_FUNC_PROLOGUE();
	// not r11,r4
	ctx.r11.u64 = ~ctx.r4.u64;
	// li r3,-1
	ctx.r3.s64 = -1;
	// lhz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 8);
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// bnelr cr6
	if (!ctx.cr6.eq) return;
	// lhz r3,10(r11)
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r11.u32 + 10);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A805F0"))) PPC_WEAK_FUNC(sub_82A805F0);
PPC_FUNC_IMPL(__imp__sub_82A805F0) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne cr6,0x82a8061c
	if (!ctx.cr6.eq) goto loc_82A8061C;
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a8060c
	if (ctx.cr6.lt) goto loc_82A8060C;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82A8060C:
	// lwz r11,20(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// b 0x82a80650
	goto loc_82A80650;
loc_82A8061C:
	// not r11,r4
	ctx.r11.u64 = ~ctx.r4.u64;
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lhz r10,10(r10)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r10.u32 + 10);
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a80638
	if (ctx.cr6.lt) goto loc_82A80638;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82a80644
	goto loc_82A80644;
loc_82A80638:
	// lwz r11,56(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
loc_82A80644:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82A80650:
	// not r3,r11
	ctx.r3.u64 = ~ctx.r11.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80658"))) PPC_WEAK_FUNC(sub_82A80658);
PPC_FUNC_IMPL(__imp__sub_82A80658) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82a494c8
	ctx.lr = 0x82A8066C;
	sub_82A494C8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80680"))) PPC_WEAK_FUNC(sub_82A80680);
PPC_FUNC_IMPL(__imp__sub_82A80680) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82a806c0
	if (ctx.cr6.eq) goto loc_82A806C0;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
loc_82A806A0:
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a806a0
	if (!ctx.cr0.eq) goto loc_82A806A0;
loc_82A806C0:
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82a494c8
	ctx.lr = 0x82A806C8;
	sub_82A494C8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A806E0"))) PPC_WEAK_FUNC(sub_82A806E0);
PPC_FUNC_IMPL(__imp__sub_82A806E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82a8072c
	if (ctx.cr6.eq) goto loc_82A8072C;
	// lis r9,-32230
	ctx.r9.s64 = -2112225280;
	// subf r8,r11,r5
	ctx.r8.s64 = ctx.r5.s64 - ctx.r11.s64;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// lfs f0,21348(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 21348);
	ctx.f0.f64 = double(temp.f32);
loc_82A80708:
	// lfsx f13,r8,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r11.u32);
	ctx.f13.f64 = double(temp.f32);
	// li r9,1
	ctx.r9.s64 = 1;
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bne cr6,0x82a8071c
	if (!ctx.cr6.eq) goto loc_82A8071C;
	// li r9,0
	ctx.r9.s64 = 0;
loc_82A8071C:
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a80708
	if (!ctx.cr0.eq) goto loc_82A80708;
loc_82A8072C:
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82a494c8
	ctx.lr = 0x82A80734;
	sub_82A494C8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80748"))) PPC_WEAK_FUNC(sub_82A80748);
PPC_FUNC_IMPL(__imp__sub_82A80748) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82a49588
	ctx.lr = 0x82A8075C;
	sub_82A49588(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80770"))) PPC_WEAK_FUNC(sub_82A80770);
PPC_FUNC_IMPL(__imp__sub_82A80770) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82a807ac
	if (ctx.cr0.eq) goto loc_82A807AC;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
loc_82A8078C:
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a8078c
	if (!ctx.cr0.eq) goto loc_82A8078C;
loc_82A807AC:
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82a49588
	ctx.lr = 0x82A807B4;
	sub_82A49588(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A807C8"))) PPC_WEAK_FUNC(sub_82A807C8);
PPC_FUNC_IMPL(__imp__sub_82A807C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82a807fc
	if (ctx.cr0.eq) goto loc_82A807FC;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
loc_82A807E4:
	// lfsx f0,r9,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	ctx.f0.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a807e4
	if (!ctx.cr0.eq) goto loc_82A807E4;
loc_82A807FC:
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82a49588
	ctx.lr = 0x82A80804;
	sub_82A49588(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80818"))) PPC_WEAK_FUNC(sub_82A80818);
PPC_FUNC_IMPL(__imp__sub_82A80818) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// add r10,r4,r7
	ctx.r10.u64 = ctx.r4.u64 + ctx.r7.u64;
	// rlwinm r11,r4,30,2,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// rldicr r9,r9,63,63
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// srad r10,r9,r10
	temp.u64 = ctx.r10.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r9.s64 < 0) & (((ctx.r9.s64 >> temp.u64) << temp.u64) != ctx.r9.s64);
	ctx.r10.s64 = ctx.r9.s64 >> temp.u64;
	// srd r7,r10,r11
	ctx.r7.u64 = ctx.r11.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r11.u8 & 0x7F));
	// bl 0x82a49308
	ctx.lr = 0x82A80854;
	sub_82A49308(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80868"))) PPC_WEAK_FUNC(sub_82A80868);
PPC_FUNC_IMPL(__imp__sub_82A80868) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82a808b8
	if (ctx.cr0.eq) goto loc_82A808B8;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
loc_82A80884:
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// extsw r8,r8
	ctx.r8.s64 = ctx.r8.s32;
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a80884
	if (!ctx.cr0.eq) goto loc_82A80884;
loc_82A808B8:
	// add r10,r4,r7
	ctx.r10.u64 = ctx.r4.u64 + ctx.r7.u64;
	// rlwinm r11,r4,30,2,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// rldicr r9,r9,63,63
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// srad r10,r9,r10
	temp.u64 = ctx.r10.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r9.s64 < 0) & (((ctx.r9.s64 >> temp.u64) << temp.u64) != ctx.r9.s64);
	ctx.r10.s64 = ctx.r9.s64 >> temp.u64;
	// srd r7,r10,r11
	ctx.r7.u64 = ctx.r11.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r11.u8 & 0x7F));
	// bl 0x82a49308
	ctx.lr = 0x82A808E8;
	sub_82A49308(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80900"))) PPC_WEAK_FUNC(sub_82A80900);
PPC_FUNC_IMPL(__imp__sub_82A80900) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82a80940
	if (ctx.cr0.eq) goto loc_82A80940;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
loc_82A8091C:
	// lwax r8,r9,r11
	ctx.r8.s64 = int32_t(PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a8091c
	if (!ctx.cr0.eq) goto loc_82A8091C;
loc_82A80940:
	// add r10,r4,r7
	ctx.r10.u64 = ctx.r4.u64 + ctx.r7.u64;
	// rlwinm r11,r4,30,2,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// rldicr r9,r9,63,63
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// srad r10,r9,r10
	temp.u64 = ctx.r10.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r9.s64 < 0) & (((ctx.r9.s64 >> temp.u64) << temp.u64) != ctx.r9.s64);
	ctx.r10.s64 = ctx.r9.s64 >> temp.u64;
	// srd r7,r10,r11
	ctx.r7.u64 = ctx.r11.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r11.u8 & 0x7F));
	// bl 0x82a49308
	ctx.lr = 0x82A80970;
	sub_82A49308(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80988"))) PPC_WEAK_FUNC(sub_82A80988);
PPC_FUNC_IMPL(__imp__sub_82A80988) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82a49528
	ctx.lr = 0x82A8099C;
	sub_82A49528(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A809B0"))) PPC_WEAK_FUNC(sub_82A809B0);
PPC_FUNC_IMPL(__imp__sub_82A809B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82a809f0
	if (ctx.cr6.eq) goto loc_82A809F0;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
loc_82A809D0:
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a809d0
	if (!ctx.cr0.eq) goto loc_82A809D0;
loc_82A809F0:
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82a49528
	ctx.lr = 0x82A809F8;
	sub_82A49528(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80A10"))) PPC_WEAK_FUNC(sub_82A80A10);
PPC_FUNC_IMPL(__imp__sub_82A80A10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82a80a5c
	if (ctx.cr6.eq) goto loc_82A80A5C;
	// lis r9,-32230
	ctx.r9.s64 = -2112225280;
	// subf r8,r11,r5
	ctx.r8.s64 = ctx.r5.s64 - ctx.r11.s64;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// lfs f0,21348(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 21348);
	ctx.f0.f64 = double(temp.f32);
loc_82A80A38:
	// lfsx f13,r8,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r11.u32);
	ctx.f13.f64 = double(temp.f32);
	// li r9,1
	ctx.r9.s64 = 1;
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bne cr6,0x82a80a4c
	if (!ctx.cr6.eq) goto loc_82A80A4C;
	// li r9,0
	ctx.r9.s64 = 0;
loc_82A80A4C:
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a80a38
	if (!ctx.cr0.eq) goto loc_82A80A38;
loc_82A80A5C:
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82a49528
	ctx.lr = 0x82A80A64;
	sub_82A49528(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80A78"))) PPC_WEAK_FUNC(sub_82A80A78);
PPC_FUNC_IMPL(__imp__sub_82A80A78) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82a495e0
	ctx.lr = 0x82A80A8C;
	sub_82A495E0(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80AA0"))) PPC_WEAK_FUNC(sub_82A80AA0);
PPC_FUNC_IMPL(__imp__sub_82A80AA0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82a80adc
	if (ctx.cr0.eq) goto loc_82A80ADC;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
loc_82A80ABC:
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a80abc
	if (!ctx.cr0.eq) goto loc_82A80ABC;
loc_82A80ADC:
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82a495e0
	ctx.lr = 0x82A80AE4;
	sub_82A495E0(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80AF8"))) PPC_WEAK_FUNC(sub_82A80AF8);
PPC_FUNC_IMPL(__imp__sub_82A80AF8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82a80b2c
	if (ctx.cr0.eq) goto loc_82A80B2C;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
loc_82A80B14:
	// lfsx f0,r9,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	ctx.f0.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a80b14
	if (!ctx.cr0.eq) goto loc_82A80B14;
loc_82A80B2C:
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82a495e0
	ctx.lr = 0x82A80B34;
	sub_82A495E0(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80B48"))) PPC_WEAK_FUNC(sub_82A80B48);
PPC_FUNC_IMPL(__imp__sub_82A80B48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82a80b98
	if (ctx.cr0.eq) goto loc_82A80B98;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
loc_82A80B64:
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// extsw r8,r8
	ctx.r8.s64 = ctx.r8.s32;
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a80b64
	if (!ctx.cr0.eq) goto loc_82A80B64;
loc_82A80B98:
	// add r10,r4,r7
	ctx.r10.u64 = ctx.r4.u64 + ctx.r7.u64;
	// rlwinm r11,r4,30,2,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// rldicr r9,r9,63,63
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// srad r10,r9,r10
	temp.u64 = ctx.r10.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r9.s64 < 0) & (((ctx.r9.s64 >> temp.u64) << temp.u64) != ctx.r9.s64);
	ctx.r10.s64 = ctx.r9.s64 >> temp.u64;
	// srd r7,r10,r11
	ctx.r7.u64 = ctx.r11.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r11.u8 & 0x7F));
	// bl 0x82a493e8
	ctx.lr = 0x82A80BC8;
	sub_82A493E8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80BE0"))) PPC_WEAK_FUNC(sub_82A80BE0);
PPC_FUNC_IMPL(__imp__sub_82A80BE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82a80c20
	if (ctx.cr0.eq) goto loc_82A80C20;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
loc_82A80BFC:
	// lwax r8,r9,r11
	ctx.r8.s64 = int32_t(PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a80bfc
	if (!ctx.cr0.eq) goto loc_82A80BFC;
loc_82A80C20:
	// add r10,r4,r7
	ctx.r10.u64 = ctx.r4.u64 + ctx.r7.u64;
	// rlwinm r11,r4,30,2,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// rldicr r9,r9,63,63
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// srad r10,r9,r10
	temp.u64 = ctx.r10.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r9.s64 < 0) & (((ctx.r9.s64 >> temp.u64) << temp.u64) != ctx.r9.s64);
	ctx.r10.s64 = ctx.r9.s64 >> temp.u64;
	// srd r7,r10,r11
	ctx.r7.u64 = ctx.r11.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r11.u8 & 0x7F));
	// bl 0x82a493e8
	ctx.lr = 0x82A80C50;
	sub_82A493E8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80C68"))) PPC_WEAK_FUNC(sub_82A80C68);
PPC_FUNC_IMPL(__imp__sub_82A80C68) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// add r10,r4,r7
	ctx.r10.u64 = ctx.r4.u64 + ctx.r7.u64;
	// rlwinm r11,r4,30,2,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// rldicr r9,r9,63,63
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// srad r10,r9,r10
	temp.u64 = ctx.r10.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r9.s64 < 0) & (((ctx.r9.s64 >> temp.u64) << temp.u64) != ctx.r9.s64);
	ctx.r10.s64 = ctx.r9.s64 >> temp.u64;
	// srd r7,r10,r11
	ctx.r7.u64 = ctx.r11.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r11.u8 & 0x7F));
	// bl 0x82a493e8
	ctx.lr = 0x82A80CA4;
	sub_82A493E8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A80CB8"))) PPC_WEAK_FUNC(sub_82A80CB8);
PPC_FUNC_IMPL(__imp__sub_82A80CB8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A80CC0;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A80CE0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// rlwinm r11,r31,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// add r3,r3,r11
	ctx.r3.u64 = ctx.r3.u64 + ctx.r11.u64;
	// rlwinm r5,r29,4,0,27
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x82d5c630
	ctx.lr = 0x82A80CF4;
	sub_82D5C630(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A80D00"))) PPC_WEAK_FUNC(sub_82A80D00);
PPC_FUNC_IMPL(__imp__sub_82A80D00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A80D08;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r7
	ctx.r30.u64 = ctx.r7.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r30,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82a80d5c
	if (ctx.cr0.eq) goto loc_82A80D5C;
	// subf r9,r11,r31
	ctx.r9.s64 = ctx.r31.s64 - ctx.r11.s64;
loc_82A80D28:
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// extsw r8,r8
	ctx.r8.s64 = ctx.r8.s32;
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a80d28
	if (!ctx.cr0.eq) goto loc_82A80D28;
loc_82A80D5C:
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A80D6C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// rlwinm r11,r29,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// add r3,r3,r11
	ctx.r3.u64 = ctx.r3.u64 + ctx.r11.u64;
	// rlwinm r5,r30,4,0,27
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x82d5c630
	ctx.lr = 0x82A80D80;
	sub_82D5C630(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A80D90"))) PPC_WEAK_FUNC(sub_82A80D90);
PPC_FUNC_IMPL(__imp__sub_82A80D90) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A80D98;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r7
	ctx.r30.u64 = ctx.r7.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r30,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82a80ddc
	if (ctx.cr0.eq) goto loc_82A80DDC;
	// subf r9,r11,r31
	ctx.r9.s64 = ctx.r31.s64 - ctx.r11.s64;
loc_82A80DB8:
	// lwax r8,r9,r11
	ctx.r8.s64 = int32_t(PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a80db8
	if (!ctx.cr0.eq) goto loc_82A80DB8;
loc_82A80DDC:
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A80DEC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// rlwinm r11,r29,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// add r3,r3,r11
	ctx.r3.u64 = ctx.r3.u64 + ctx.r11.u64;
	// rlwinm r5,r30,4,0,27
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x82d5c630
	ctx.lr = 0x82A80E00;
	sub_82D5C630(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A80E10"))) PPC_WEAK_FUNC(sub_82A80E10);
PPC_FUNC_IMPL(__imp__sub_82A80E10) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b0
	ctx.lr = 0x82A80E18;
	__savegprlr_22(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// mr r22,r7
	ctx.r22.u64 = ctx.r7.u64;
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// lwz r31,24(r24)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r24.u32 + 24);
	// lwz r6,32(r24)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r24.u32 + 32);
	// lhz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 0);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// blt cr6,0x82a80fc8
	if (ctx.cr6.lt) goto loc_82A80FC8;
	// beq cr6,0x82a80fc0
	if (ctx.cr6.eq) goto loc_82A80FC0;
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// blt cr6,0x82a80fa0
	if (ctx.cr6.lt) goto loc_82A80FA0;
	// beq cr6,0x82a80efc
	if (ctx.cr6.eq) goto loc_82A80EFC;
	// cmplwi cr6,r10,5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 5, ctx.xer);
	// beq cr6,0x82a80e68
	if (ctx.cr6.eq) goto loc_82A80E68;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16385
	ctx.r3.u64 = ctx.r3.u64 | 16385;
	// b 0x82a81134
	goto loc_82A81134;
loc_82A80E68:
	// lwz r9,52(r24)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r24.u32 + 52);
	// lhz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 8);
	// divwu r27,r11,r9
	ctx.r27.u32 = ctx.r11.u32 / ctx.r9.u32;
	// twllei r9,0
	// cmplw cr6,r27,r10
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a80e84
	if (!ctx.cr6.gt) goto loc_82A80E84;
	// mr r27,r10
	ctx.r27.u64 = ctx.r10.u64;
loc_82A80E84:
	// li r26,0
	ctx.r26.s64 = 0;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a81130
	if (ctx.cr6.eq) goto loc_82A81130;
loc_82A80E90:
	// lhz r11,10(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 10);
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a80eec
	if (ctx.cr0.eq) goto loc_82A80EEC;
	// li r29,0
	ctx.r29.s64 = 0;
loc_82A80EA4:
	// lwz r11,56(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 56);
	// mr r7,r22
	ctx.r7.u64 = ctx.r22.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// lwzx r30,r29,r11
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r11.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r6,48(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// bl 0x82a80e10
	ctx.lr = 0x82A80EC4;
	sub_82A80E10(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a81134
	if (ctx.cr0.lt) goto loc_82A81134;
	// lwz r11,48(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// lhz r10,10(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 10);
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r28,r10
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r10.u32, ctx.xer);
	// add r25,r11,r25
	ctx.r25.u64 = ctx.r11.u64 + ctx.r25.u64;
	// blt cr6,0x82a80ea4
	if (ctx.cr6.lt) goto loc_82A80EA4;
loc_82A80EEC:
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// cmplw cr6,r26,r27
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r27.u32, ctx.xer);
	// blt cr6,0x82a80e90
	if (ctx.cr6.lt) goto loc_82A80E90;
	// b 0x82a81130
	goto loc_82A81130;
loc_82A80EFC:
	// lhz r7,6(r31)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// lhz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 8);
	// mullw r8,r10,r7
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r7.s32);
	// divwu r28,r11,r8
	ctx.r28.u32 = ctx.r11.u32 / ctx.r8.u32;
	// twllei r8,0
	// cmplw cr6,r28,r9
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r9.u32, ctx.xer);
	// ble cr6,0x82a80f20
	if (!ctx.cr6.gt) goto loc_82A80F20;
	// mr r28,r9
	ctx.r28.u64 = ctx.r9.u64;
loc_82A80F20:
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82a80f98
	if (ctx.cr6.eq) goto loc_82A80F98;
loc_82A80F30:
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82a80f8c
	if (ctx.cr6.eq) goto loc_82A80F8C;
loc_82A80F3C:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a80f7c
	if (ctx.cr6.eq) goto loc_82A80F7C;
loc_82A80F48:
	// mullw r10,r10,r4
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r4.s32);
	// lhz r7,6(r31)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// mullw r10,r10,r7
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r7.s32);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a80f48
	if (ctx.cr6.lt) goto loc_82A80F48;
loc_82A80F7C:
	// lhz r7,6(r31)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// cmplw cr6,r8,r7
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, ctx.xer);
	// blt cr6,0x82a80f3c
	if (ctx.cr6.lt) goto loc_82A80F3C;
loc_82A80F8C:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r4,r28
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r28.u32, ctx.xer);
	// blt cr6,0x82a80f30
	if (ctx.cr6.lt) goto loc_82A80F30;
loc_82A80F98:
	// mr r25,r6
	ctx.r25.u64 = ctx.r6.u64;
	// b 0x82a80fdc
	goto loc_82A80FDC;
loc_82A80FA0:
	// lhz r9,6(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r8,4(r31)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// mullw r9,r9,r8
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r8.s32);
loc_82A80FAC:
	// lhz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 8);
	// divwu r28,r11,r9
	ctx.r28.u32 = ctx.r11.u32 / ctx.r9.u32;
	// twllei r9,0
	// cmplw cr6,r28,r10
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r10.u32, ctx.xer);
	// b 0x82a80fd4
	goto loc_82A80FD4;
loc_82A80FC0:
	// lhz r9,6(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// b 0x82a80fac
	goto loc_82A80FAC;
loc_82A80FC8:
	// lhz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 8);
	// mr r28,r11
	ctx.r28.u64 = ctx.r11.u64;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
loc_82A80FD4:
	// ble cr6,0x82a80fdc
	if (!ctx.cr6.gt) goto loc_82A80FDC;
	// mr r28,r10
	ctx.r28.u64 = ctx.r10.u64;
loc_82A80FDC:
	// lhz r9,8(r24)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r24.u32 + 8);
	// cmplwi r9,0
	ctx.cr0.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq 0x82a810e0
	if (ctx.cr0.eq) goto loc_82A810E0;
	// lhz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82a81000
	if (ctx.cr6.eq) goto loc_82A81000;
	// lhz r11,6(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// b 0x82a81008
	goto loc_82A81008;
loc_82A81000:
	// lhz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// lhz r10,6(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
loc_82A81008:
	// clrlwi. r8,r11,30
	ctx.r8.u64 = ctx.r11.u32 & 0x3;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a810e0
	if (ctx.cr0.eq) goto loc_82A810E0;
	// cmplwi cr6,r9,1
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 1, ctx.xer);
	// bne cr6,0x82a81024
	if (!ctx.cr6.eq) goto loc_82A81024;
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// addi r27,r9,-21196
	ctx.r27.s64 = ctx.r9.s64 + -21196;
	// b 0x82a8102c
	goto loc_82A8102C;
loc_82A81024:
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r27,r9,-17092
	ctx.r27.s64 = ctx.r9.s64 + -17092;
loc_82A8102C:
	// mullw. r8,r10,r28
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r28.s32);
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// beq 0x82a810dc
	if (ctx.cr0.eq) goto loc_82A810DC;
	// mullw r7,r8,r10
	ctx.r7.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r10.s32);
	// add r7,r7,r11
	ctx.r7.u64 = ctx.r7.u64 + ctx.r11.u64;
	// addi r9,r8,1
	ctx.r9.s64 = ctx.r8.s64 + 1;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r5,r7,r6
	ctx.r5.u64 = ctx.r7.u64 + ctx.r6.u64;
	// mullw r7,r9,r11
	ctx.r7.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r11.s32);
	// mullw r9,r9,r10
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r3,r10,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r7,r25
	ctx.r7.u64 = ctx.r7.u64 + ctx.r25.u64;
	// add r4,r9,r6
	ctx.r4.u64 = ctx.r9.u64 + ctx.r6.u64;
loc_82A8106C:
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// subf r5,r3,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r3.s64;
	// subf r4,r3,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r3.s64;
	// subf r7,r30,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r30.s64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a810a8
	if (!ctx.cr6.gt) goto loc_82A810A8;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
loc_82A8108C:
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// addi r31,r31,-4
	ctx.r31.s64 = ctx.r31.s64 + -4;
	// rlwinm r29,r9,2,28,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xC;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// lwzx r29,r29,r27
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r27.u32);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// bgt cr6,0x82a8108c
	if (ctx.cr6.gt) goto loc_82A8108C;
loc_82A810A8:
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a810d4
	if (ctx.cr6.eq) goto loc_82A810D4;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
loc_82A810BC:
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r31,r31,-4
	ctx.r31.s64 = ctx.r31.s64 + -4;
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// lwz r26,0(r9)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r26,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r26.u32);
	// bne 0x82a810bc
	if (!ctx.cr0.eq) goto loc_82A810BC;
loc_82A810D4:
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82a8106c
	if (!ctx.cr6.eq) goto loc_82A8106C;
loc_82A810DC:
	// mr r25,r6
	ctx.r25.u64 = ctx.r6.u64;
loc_82A810E0:
	// lwz r10,44(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 44);
	// lhz r11,12(r24)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r24.u32 + 12);
	// mullw r7,r10,r28
	ctx.r7.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r28.s32);
	// cmplw cr6,r7,r11
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a810f8
	if (!ctx.cr6.gt) goto loc_82A810F8;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
loc_82A810F8:
	// lwz r10,28(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 28);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne 0x82a81110
	if (!ctx.cr0.eq) goto loc_82A81110;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82a81134
	goto loc_82A81134;
loc_82A81110:
	// lhz r11,10(r24)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r24.u32 + 10);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// add r4,r11,r22
	ctx.r4.u64 = ctx.r11.u64 + ctx.r22.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82A81128;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a81134
	if (ctx.cr0.lt) goto loc_82A81134;
loc_82A81130:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A81134:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82d5c500
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A81140"))) PPC_WEAK_FUNC(sub_82A81140);
PPC_FUNC_IMPL(__imp__sub_82A81140) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b0
	ctx.lr = 0x82A81148;
	__savegprlr_22(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// mr r22,r7
	ctx.r22.u64 = ctx.r7.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// lwz r31,24(r24)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r24.u32 + 24);
	// lwz r6,32(r24)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r24.u32 + 32);
	// lhz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 0);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// blt cr6,0x82a812f8
	if (ctx.cr6.lt) goto loc_82A812F8;
	// beq cr6,0x82a812f0
	if (ctx.cr6.eq) goto loc_82A812F0;
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// blt cr6,0x82a812d0
	if (ctx.cr6.lt) goto loc_82A812D0;
	// beq cr6,0x82a8122c
	if (ctx.cr6.eq) goto loc_82A8122C;
	// cmplwi cr6,r10,5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 5, ctx.xer);
	// beq cr6,0x82a81198
	if (ctx.cr6.eq) goto loc_82A81198;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16385
	ctx.r3.u64 = ctx.r3.u64 | 16385;
	// b 0x82a81508
	goto loc_82A81508;
loc_82A81198:
	// lwz r9,52(r24)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r24.u32 + 52);
	// lhz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 8);
	// divwu r27,r11,r9
	ctx.r27.u32 = ctx.r11.u32 / ctx.r9.u32;
	// twllei r9,0
	// cmplw cr6,r27,r10
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a811b4
	if (!ctx.cr6.gt) goto loc_82A811B4;
	// mr r27,r10
	ctx.r27.u64 = ctx.r10.u64;
loc_82A811B4:
	// li r25,0
	ctx.r25.s64 = 0;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a81504
	if (ctx.cr6.eq) goto loc_82A81504;
loc_82A811C0:
	// lhz r11,10(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 10);
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a8121c
	if (ctx.cr0.eq) goto loc_82A8121C;
	// li r29,0
	ctx.r29.s64 = 0;
loc_82A811D4:
	// lwz r11,56(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 56);
	// mr r7,r22
	ctx.r7.u64 = ctx.r22.u64;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// lwzx r30,r29,r11
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r11.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r6,48(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// bl 0x82a81140
	ctx.lr = 0x82A811F4;
	sub_82A81140(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a81508
	if (ctx.cr0.lt) goto loc_82A81508;
	// lwz r11,48(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// lhz r10,10(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 10);
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r28,r10
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r10.u32, ctx.xer);
	// add r26,r11,r26
	ctx.r26.u64 = ctx.r11.u64 + ctx.r26.u64;
	// blt cr6,0x82a811d4
	if (ctx.cr6.lt) goto loc_82A811D4;
loc_82A8121C:
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// cmplw cr6,r25,r27
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, ctx.r27.u32, ctx.xer);
	// blt cr6,0x82a811c0
	if (ctx.cr6.lt) goto loc_82A811C0;
	// b 0x82a81504
	goto loc_82A81504;
loc_82A8122C:
	// lhz r7,6(r31)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// lhz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 8);
	// mullw r8,r10,r7
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r7.s32);
	// divwu r27,r11,r8
	ctx.r27.u32 = ctx.r11.u32 / ctx.r8.u32;
	// twllei r8,0
	// cmplw cr6,r27,r9
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r9.u32, ctx.xer);
	// ble cr6,0x82a81250
	if (!ctx.cr6.gt) goto loc_82A81250;
	// mr r27,r9
	ctx.r27.u64 = ctx.r9.u64;
loc_82A81250:
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a812c8
	if (ctx.cr6.eq) goto loc_82A812C8;
loc_82A81260:
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82a812bc
	if (ctx.cr6.eq) goto loc_82A812BC;
loc_82A8126C:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a812ac
	if (ctx.cr6.eq) goto loc_82A812AC;
loc_82A81278:
	// mullw r10,r10,r4
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r4.s32);
	// lhz r7,6(r31)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// mullw r10,r10,r7
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r7.s32);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a81278
	if (ctx.cr6.lt) goto loc_82A81278;
loc_82A812AC:
	// lhz r7,6(r31)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// cmplw cr6,r8,r7
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, ctx.xer);
	// blt cr6,0x82a8126c
	if (ctx.cr6.lt) goto loc_82A8126C;
loc_82A812BC:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r4,r27
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r27.u32, ctx.xer);
	// blt cr6,0x82a81260
	if (ctx.cr6.lt) goto loc_82A81260;
loc_82A812C8:
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// b 0x82a8130c
	goto loc_82A8130C;
loc_82A812D0:
	// lhz r9,6(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r8,4(r31)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// mullw r9,r9,r8
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r8.s32);
loc_82A812DC:
	// lhz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 8);
	// divwu r27,r11,r9
	ctx.r27.u32 = ctx.r11.u32 / ctx.r9.u32;
	// twllei r9,0
	// cmplw cr6,r27,r10
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r10.u32, ctx.xer);
	// b 0x82a81304
	goto loc_82A81304;
loc_82A812F0:
	// lhz r9,6(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// b 0x82a812dc
	goto loc_82A812DC;
loc_82A812F8:
	// lhz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 8);
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
loc_82A81304:
	// ble cr6,0x82a8130c
	if (!ctx.cr6.gt) goto loc_82A8130C;
	// mr r27,r10
	ctx.r27.u64 = ctx.r10.u64;
loc_82A8130C:
	// lhz r11,2(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 2);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82a813b0
	if (ctx.cr6.eq) goto loc_82A813B0;
	// lwz r10,52(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 52);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// mullw r10,r10,r27
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r27.s32);
	// beq cr6,0x82a8137c
	if (ctx.cr6.eq) goto loc_82A8137C;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bne cr6,0x82a813ac
	if (!ctx.cr6.eq) goto loc_82A813AC;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a813ac
	if (ctx.cr6.eq) goto loc_82A813AC;
	// lis r7,-32230
	ctx.r7.s64 = -2112225280;
	// lis r8,-32230
	ctx.r8.s64 = -2112225280;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// subf r9,r6,r26
	ctx.r9.s64 = ctx.r26.s64 - ctx.r6.s64;
	// lfs f12,21348(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 21348);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,21344(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 21344);
	ctx.f13.f64 = double(temp.f32);
loc_82A81350:
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a81364
	if (ctx.cr6.eq) goto loc_82A81364;
	// fmr f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f13.f64;
	// b 0x82a81368
	goto loc_82A81368;
loc_82A81364:
	// fmr f0,f12
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f12.f64;
loc_82A81368:
	// stfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a81350
	if (!ctx.cr0.eq) goto loc_82A81350;
	// b 0x82a813ac
	goto loc_82A813AC;
loc_82A8137C:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a813ac
	if (ctx.cr6.eq) goto loc_82A813AC;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// subf r9,r6,r26
	ctx.r9.s64 = ctx.r26.s64 - ctx.r6.s64;
loc_82A8138C:
	// lwzx r8,r11,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r9.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a8138c
	if (!ctx.cr0.eq) goto loc_82A8138C;
loc_82A813AC:
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
loc_82A813B0:
	// lhz r9,8(r24)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r24.u32 + 8);
	// cmplwi r9,0
	ctx.cr0.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq 0x82a814b4
	if (ctx.cr0.eq) goto loc_82A814B4;
	// lhz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82a813d4
	if (ctx.cr6.eq) goto loc_82A813D4;
	// lhz r11,6(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// b 0x82a813dc
	goto loc_82A813DC;
loc_82A813D4:
	// lhz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// lhz r10,6(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
loc_82A813DC:
	// clrlwi. r8,r11,30
	ctx.r8.u64 = ctx.r11.u32 & 0x3;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a814b4
	if (ctx.cr0.eq) goto loc_82A814B4;
	// cmplwi cr6,r9,1
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 1, ctx.xer);
	// bne cr6,0x82a813f8
	if (!ctx.cr6.eq) goto loc_82A813F8;
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// addi r28,r9,-21196
	ctx.r28.s64 = ctx.r9.s64 + -21196;
	// b 0x82a81400
	goto loc_82A81400;
loc_82A813F8:
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r28,r9,-17092
	ctx.r28.s64 = ctx.r9.s64 + -17092;
loc_82A81400:
	// mullw. r8,r10,r27
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r27.s32);
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// beq 0x82a814b0
	if (ctx.cr0.eq) goto loc_82A814B0;
	// mullw r7,r8,r10
	ctx.r7.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r10.s32);
	// add r7,r7,r11
	ctx.r7.u64 = ctx.r7.u64 + ctx.r11.u64;
	// addi r9,r8,1
	ctx.r9.s64 = ctx.r8.s64 + 1;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r5,r7,r6
	ctx.r5.u64 = ctx.r7.u64 + ctx.r6.u64;
	// mullw r7,r9,r11
	ctx.r7.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r11.s32);
	// mullw r9,r9,r10
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r3,r10,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r7,r26
	ctx.r7.u64 = ctx.r7.u64 + ctx.r26.u64;
	// add r4,r9,r6
	ctx.r4.u64 = ctx.r9.u64 + ctx.r6.u64;
loc_82A81440:
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// subf r5,r3,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r3.s64;
	// subf r4,r3,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r3.s64;
	// subf r7,r30,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r30.s64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a8147c
	if (!ctx.cr6.gt) goto loc_82A8147C;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
loc_82A81460:
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// addi r31,r31,-4
	ctx.r31.s64 = ctx.r31.s64 + -4;
	// rlwinm r29,r9,2,28,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xC;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// lwzx r29,r29,r28
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r28.u32);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// bgt cr6,0x82a81460
	if (ctx.cr6.gt) goto loc_82A81460;
loc_82A8147C:
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a814a8
	if (ctx.cr6.eq) goto loc_82A814A8;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
loc_82A81490:
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r31,r31,-4
	ctx.r31.s64 = ctx.r31.s64 + -4;
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// lwz r26,0(r9)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r26,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r26.u32);
	// bne 0x82a81490
	if (!ctx.cr0.eq) goto loc_82A81490;
loc_82A814A8:
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82a81440
	if (!ctx.cr6.eq) goto loc_82A81440;
loc_82A814B0:
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
loc_82A814B4:
	// lwz r10,44(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 44);
	// lhz r11,12(r24)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r24.u32 + 12);
	// mullw r7,r10,r27
	ctx.r7.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r27.s32);
	// cmplw cr6,r7,r11
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a814cc
	if (!ctx.cr6.gt) goto loc_82A814CC;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
loc_82A814CC:
	// lwz r10,28(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 28);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne 0x82a814e4
	if (!ctx.cr0.eq) goto loc_82A814E4;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82a81508
	goto loc_82A81508;
loc_82A814E4:
	// lhz r11,10(r24)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r24.u32 + 10);
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// add r4,r11,r22
	ctx.r4.u64 = ctx.r11.u64 + ctx.r22.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82A814FC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a81508
	if (ctx.cr0.lt) goto loc_82A81508;
loc_82A81504:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A81508:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82d5c500
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A81510"))) PPC_WEAK_FUNC(sub_82A81510);
PPC_FUNC_IMPL(__imp__sub_82A81510) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b0
	ctx.lr = 0x82A81518;
	__savegprlr_22(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// mr r22,r7
	ctx.r22.u64 = ctx.r7.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// lwz r31,24(r24)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r24.u32 + 24);
	// lwz r6,32(r24)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r24.u32 + 32);
	// lhz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 0);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// blt cr6,0x82a816c8
	if (ctx.cr6.lt) goto loc_82A816C8;
	// beq cr6,0x82a816c0
	if (ctx.cr6.eq) goto loc_82A816C0;
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// blt cr6,0x82a816a0
	if (ctx.cr6.lt) goto loc_82A816A0;
	// beq cr6,0x82a815fc
	if (ctx.cr6.eq) goto loc_82A815FC;
	// cmplwi cr6,r10,5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 5, ctx.xer);
	// beq cr6,0x82a81568
	if (ctx.cr6.eq) goto loc_82A81568;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16385
	ctx.r3.u64 = ctx.r3.u64 | 16385;
	// b 0x82a818c4
	goto loc_82A818C4;
loc_82A81568:
	// lwz r9,52(r24)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r24.u32 + 52);
	// lhz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 8);
	// divwu r27,r11,r9
	ctx.r27.u32 = ctx.r11.u32 / ctx.r9.u32;
	// twllei r9,0
	// cmplw cr6,r27,r10
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a81584
	if (!ctx.cr6.gt) goto loc_82A81584;
	// mr r27,r10
	ctx.r27.u64 = ctx.r10.u64;
loc_82A81584:
	// li r25,0
	ctx.r25.s64 = 0;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a818c0
	if (ctx.cr6.eq) goto loc_82A818C0;
loc_82A81590:
	// lhz r11,10(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 10);
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a815ec
	if (ctx.cr0.eq) goto loc_82A815EC;
	// li r29,0
	ctx.r29.s64 = 0;
loc_82A815A4:
	// lwz r11,56(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 56);
	// mr r7,r22
	ctx.r7.u64 = ctx.r22.u64;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// lwzx r30,r29,r11
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r11.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r6,48(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// bl 0x82a81510
	ctx.lr = 0x82A815C4;
	sub_82A81510(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a818c4
	if (ctx.cr0.lt) goto loc_82A818C4;
	// lwz r11,48(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// lhz r10,10(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 10);
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r28,r10
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r10.u32, ctx.xer);
	// add r26,r11,r26
	ctx.r26.u64 = ctx.r11.u64 + ctx.r26.u64;
	// blt cr6,0x82a815a4
	if (ctx.cr6.lt) goto loc_82A815A4;
loc_82A815EC:
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// cmplw cr6,r25,r27
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, ctx.r27.u32, ctx.xer);
	// blt cr6,0x82a81590
	if (ctx.cr6.lt) goto loc_82A81590;
	// b 0x82a818c0
	goto loc_82A818C0;
loc_82A815FC:
	// lhz r7,6(r31)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// lhz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 8);
	// mullw r8,r10,r7
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r7.s32);
	// divwu r27,r11,r8
	ctx.r27.u32 = ctx.r11.u32 / ctx.r8.u32;
	// twllei r8,0
	// cmplw cr6,r27,r9
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r9.u32, ctx.xer);
	// ble cr6,0x82a81620
	if (!ctx.cr6.gt) goto loc_82A81620;
	// mr r27,r9
	ctx.r27.u64 = ctx.r9.u64;
loc_82A81620:
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a81698
	if (ctx.cr6.eq) goto loc_82A81698;
loc_82A81630:
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82a8168c
	if (ctx.cr6.eq) goto loc_82A8168C;
loc_82A8163C:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a8167c
	if (ctx.cr6.eq) goto loc_82A8167C;
loc_82A81648:
	// mullw r10,r10,r4
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r4.s32);
	// lhz r7,6(r31)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// mullw r10,r10,r7
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r7.s32);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a81648
	if (ctx.cr6.lt) goto loc_82A81648;
loc_82A8167C:
	// lhz r7,6(r31)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// cmplw cr6,r8,r7
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, ctx.xer);
	// blt cr6,0x82a8163c
	if (ctx.cr6.lt) goto loc_82A8163C;
loc_82A8168C:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r4,r27
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r27.u32, ctx.xer);
	// blt cr6,0x82a81630
	if (ctx.cr6.lt) goto loc_82A81630;
loc_82A81698:
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// b 0x82a816dc
	goto loc_82A816DC;
loc_82A816A0:
	// lhz r9,6(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r8,4(r31)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// mullw r9,r9,r8
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r8.s32);
loc_82A816AC:
	// lhz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 8);
	// divwu r27,r11,r9
	ctx.r27.u32 = ctx.r11.u32 / ctx.r9.u32;
	// twllei r9,0
	// cmplw cr6,r27,r10
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r10.u32, ctx.xer);
	// b 0x82a816d4
	goto loc_82A816D4;
loc_82A816C0:
	// lhz r9,6(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// b 0x82a816ac
	goto loc_82A816AC;
loc_82A816C8:
	// lhz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 8);
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
loc_82A816D4:
	// ble cr6,0x82a816dc
	if (!ctx.cr6.gt) goto loc_82A816DC;
	// mr r27,r10
	ctx.r27.u64 = ctx.r10.u64;
loc_82A816DC:
	// lhz r11,2(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 2);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82a8176c
	if (ctx.cr6.eq) goto loc_82A8176C;
	// lwz r10,52(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 52);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// mullw r10,r10,r27
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r27.s32);
	// beq cr6,0x82a81738
	if (ctx.cr6.eq) goto loc_82A81738;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bne cr6,0x82a81768
	if (!ctx.cr6.eq) goto loc_82A81768;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a81768
	if (ctx.cr6.eq) goto loc_82A81768;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// subf r9,r6,r26
	ctx.r9.s64 = ctx.r26.s64 - ctx.r6.s64;
loc_82A81710:
	// lwax r8,r9,r11
	ctx.r8.s64 = int32_t(PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a81710
	if (!ctx.cr0.eq) goto loc_82A81710;
	// b 0x82a81768
	goto loc_82A81768;
loc_82A81738:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a81768
	if (ctx.cr6.eq) goto loc_82A81768;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// subf r9,r6,r26
	ctx.r9.s64 = ctx.r26.s64 - ctx.r6.s64;
loc_82A81748:
	// lwzx r8,r11,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r9.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a81748
	if (!ctx.cr0.eq) goto loc_82A81748;
loc_82A81768:
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
loc_82A8176C:
	// lhz r9,8(r24)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r24.u32 + 8);
	// cmplwi r9,0
	ctx.cr0.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq 0x82a81870
	if (ctx.cr0.eq) goto loc_82A81870;
	// lhz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82a81790
	if (ctx.cr6.eq) goto loc_82A81790;
	// lhz r11,6(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// b 0x82a81798
	goto loc_82A81798;
loc_82A81790:
	// lhz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// lhz r10,6(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
loc_82A81798:
	// clrlwi. r8,r11,30
	ctx.r8.u64 = ctx.r11.u32 & 0x3;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a81870
	if (ctx.cr0.eq) goto loc_82A81870;
	// cmplwi cr6,r9,1
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 1, ctx.xer);
	// bne cr6,0x82a817b4
	if (!ctx.cr6.eq) goto loc_82A817B4;
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// addi r28,r9,-21196
	ctx.r28.s64 = ctx.r9.s64 + -21196;
	// b 0x82a817bc
	goto loc_82A817BC;
loc_82A817B4:
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r28,r9,-17092
	ctx.r28.s64 = ctx.r9.s64 + -17092;
loc_82A817BC:
	// mullw. r8,r10,r27
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r27.s32);
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// beq 0x82a8186c
	if (ctx.cr0.eq) goto loc_82A8186C;
	// mullw r7,r8,r10
	ctx.r7.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r10.s32);
	// add r7,r7,r11
	ctx.r7.u64 = ctx.r7.u64 + ctx.r11.u64;
	// addi r9,r8,1
	ctx.r9.s64 = ctx.r8.s64 + 1;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r5,r7,r6
	ctx.r5.u64 = ctx.r7.u64 + ctx.r6.u64;
	// mullw r7,r9,r11
	ctx.r7.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r11.s32);
	// mullw r9,r9,r10
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r3,r10,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r7,r26
	ctx.r7.u64 = ctx.r7.u64 + ctx.r26.u64;
	// add r4,r9,r6
	ctx.r4.u64 = ctx.r9.u64 + ctx.r6.u64;
loc_82A817FC:
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// subf r5,r3,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r3.s64;
	// subf r4,r3,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r3.s64;
	// subf r7,r30,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r30.s64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a81838
	if (!ctx.cr6.gt) goto loc_82A81838;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
loc_82A8181C:
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// addi r31,r31,-4
	ctx.r31.s64 = ctx.r31.s64 + -4;
	// rlwinm r29,r9,2,28,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xC;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// lwzx r29,r29,r28
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r28.u32);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// bgt cr6,0x82a8181c
	if (ctx.cr6.gt) goto loc_82A8181C;
loc_82A81838:
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a81864
	if (ctx.cr6.eq) goto loc_82A81864;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
loc_82A8184C:
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r31,r31,-4
	ctx.r31.s64 = ctx.r31.s64 + -4;
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// lwz r26,0(r9)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r26,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r26.u32);
	// bne 0x82a8184c
	if (!ctx.cr0.eq) goto loc_82A8184C;
loc_82A81864:
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82a817fc
	if (!ctx.cr6.eq) goto loc_82A817FC;
loc_82A8186C:
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
loc_82A81870:
	// lwz r10,44(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 44);
	// lhz r11,12(r24)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r24.u32 + 12);
	// mullw r7,r10,r27
	ctx.r7.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r27.s32);
	// cmplw cr6,r7,r11
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a81888
	if (!ctx.cr6.gt) goto loc_82A81888;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
loc_82A81888:
	// lwz r10,28(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 28);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne 0x82a818a0
	if (!ctx.cr0.eq) goto loc_82A818A0;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82a818c4
	goto loc_82A818C4;
loc_82A818A0:
	// lhz r11,10(r24)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r24.u32 + 10);
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// add r4,r11,r22
	ctx.r4.u64 = ctx.r11.u64 + ctx.r22.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82A818B8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a818c4
	if (ctx.cr0.lt) goto loc_82A818C4;
loc_82A818C0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A818C4:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82d5c500
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A818D0"))) PPC_WEAK_FUNC(sub_82A818D0);
PPC_FUNC_IMPL(__imp__sub_82A818D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b0
	ctx.lr = 0x82A818D8;
	__savegprlr_22(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// mr r22,r7
	ctx.r22.u64 = ctx.r7.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// lwz r31,24(r24)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r24.u32 + 24);
	// lwz r6,32(r24)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r24.u32 + 32);
	// lhz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 0);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// blt cr6,0x82a81a88
	if (ctx.cr6.lt) goto loc_82A81A88;
	// beq cr6,0x82a81a80
	if (ctx.cr6.eq) goto loc_82A81A80;
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// blt cr6,0x82a81a60
	if (ctx.cr6.lt) goto loc_82A81A60;
	// beq cr6,0x82a819bc
	if (ctx.cr6.eq) goto loc_82A819BC;
	// cmplwi cr6,r10,5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 5, ctx.xer);
	// beq cr6,0x82a81928
	if (ctx.cr6.eq) goto loc_82A81928;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16385
	ctx.r3.u64 = ctx.r3.u64 | 16385;
	// b 0x82a81c84
	goto loc_82A81C84;
loc_82A81928:
	// lwz r9,52(r24)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r24.u32 + 52);
	// lhz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 8);
	// divwu r27,r11,r9
	ctx.r27.u32 = ctx.r11.u32 / ctx.r9.u32;
	// twllei r9,0
	// cmplw cr6,r27,r10
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a81944
	if (!ctx.cr6.gt) goto loc_82A81944;
	// mr r27,r10
	ctx.r27.u64 = ctx.r10.u64;
loc_82A81944:
	// li r25,0
	ctx.r25.s64 = 0;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a81c80
	if (ctx.cr6.eq) goto loc_82A81C80;
loc_82A81950:
	// lhz r11,10(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 10);
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a819ac
	if (ctx.cr0.eq) goto loc_82A819AC;
	// li r29,0
	ctx.r29.s64 = 0;
loc_82A81964:
	// lwz r11,56(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 56);
	// mr r7,r22
	ctx.r7.u64 = ctx.r22.u64;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// lwzx r30,r29,r11
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r11.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r6,48(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// bl 0x82a818d0
	ctx.lr = 0x82A81984;
	sub_82A818D0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a81c84
	if (ctx.cr0.lt) goto loc_82A81C84;
	// lwz r11,48(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// lhz r10,10(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 10);
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r28,r10
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r10.u32, ctx.xer);
	// add r26,r11,r26
	ctx.r26.u64 = ctx.r11.u64 + ctx.r26.u64;
	// blt cr6,0x82a81964
	if (ctx.cr6.lt) goto loc_82A81964;
loc_82A819AC:
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// cmplw cr6,r25,r27
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, ctx.r27.u32, ctx.xer);
	// blt cr6,0x82a81950
	if (ctx.cr6.lt) goto loc_82A81950;
	// b 0x82a81c80
	goto loc_82A81C80;
loc_82A819BC:
	// lhz r7,6(r31)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// lhz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 8);
	// mullw r8,r10,r7
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r7.s32);
	// divwu r27,r11,r8
	ctx.r27.u32 = ctx.r11.u32 / ctx.r8.u32;
	// twllei r8,0
	// cmplw cr6,r27,r9
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r9.u32, ctx.xer);
	// ble cr6,0x82a819e0
	if (!ctx.cr6.gt) goto loc_82A819E0;
	// mr r27,r9
	ctx.r27.u64 = ctx.r9.u64;
loc_82A819E0:
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a81a58
	if (ctx.cr6.eq) goto loc_82A81A58;
loc_82A819F0:
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82a81a4c
	if (ctx.cr6.eq) goto loc_82A81A4C;
loc_82A819FC:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a81a3c
	if (ctx.cr6.eq) goto loc_82A81A3C;
loc_82A81A08:
	// mullw r10,r10,r4
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r4.s32);
	// lhz r7,6(r31)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// mullw r10,r10,r7
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r7.s32);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a81a08
	if (ctx.cr6.lt) goto loc_82A81A08;
loc_82A81A3C:
	// lhz r7,6(r31)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// cmplw cr6,r8,r7
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, ctx.xer);
	// blt cr6,0x82a819fc
	if (ctx.cr6.lt) goto loc_82A819FC;
loc_82A81A4C:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r4,r27
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r27.u32, ctx.xer);
	// blt cr6,0x82a819f0
	if (ctx.cr6.lt) goto loc_82A819F0;
loc_82A81A58:
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// b 0x82a81a9c
	goto loc_82A81A9C;
loc_82A81A60:
	// lhz r9,6(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r8,4(r31)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// mullw r9,r9,r8
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r8.s32);
loc_82A81A6C:
	// lhz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 8);
	// divwu r27,r11,r9
	ctx.r27.u32 = ctx.r11.u32 / ctx.r9.u32;
	// twllei r9,0
	// cmplw cr6,r27,r10
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r10.u32, ctx.xer);
	// b 0x82a81a94
	goto loc_82A81A94;
loc_82A81A80:
	// lhz r9,6(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// b 0x82a81a6c
	goto loc_82A81A6C;
loc_82A81A88:
	// lhz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 8);
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
loc_82A81A94:
	// ble cr6,0x82a81a9c
	if (!ctx.cr6.gt) goto loc_82A81A9C;
	// mr r27,r10
	ctx.r27.u64 = ctx.r10.u64;
loc_82A81A9C:
	// lhz r11,2(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 2);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82a81b2c
	if (ctx.cr6.eq) goto loc_82A81B2C;
	// lwz r10,52(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 52);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// mullw r10,r10,r27
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r27.s32);
	// beq cr6,0x82a81aec
	if (ctx.cr6.eq) goto loc_82A81AEC;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82a81b28
	if (!ctx.cr6.eq) goto loc_82A81B28;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a81b28
	if (ctx.cr6.eq) goto loc_82A81B28;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// subf r9,r6,r26
	ctx.r9.s64 = ctx.r26.s64 - ctx.r6.s64;
loc_82A81AD0:
	// lfsx f0,r9,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	ctx.f0.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a81ad0
	if (!ctx.cr0.eq) goto loc_82A81AD0;
	// b 0x82a81b28
	goto loc_82A81B28;
loc_82A81AEC:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a81b28
	if (ctx.cr6.eq) goto loc_82A81B28;
	// lis r9,-32230
	ctx.r9.s64 = -2112225280;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// subf r8,r6,r26
	ctx.r8.s64 = ctx.r26.s64 - ctx.r6.s64;
	// lfs f0,21348(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 21348);
	ctx.f0.f64 = double(temp.f32);
loc_82A81B04:
	// lfsx f13,r11,r8
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	ctx.f13.f64 = double(temp.f32);
	// li r9,1
	ctx.r9.s64 = 1;
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bne cr6,0x82a81b18
	if (!ctx.cr6.eq) goto loc_82A81B18;
	// li r9,0
	ctx.r9.s64 = 0;
loc_82A81B18:
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a81b04
	if (!ctx.cr0.eq) goto loc_82A81B04;
loc_82A81B28:
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
loc_82A81B2C:
	// lhz r9,8(r24)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r24.u32 + 8);
	// cmplwi r9,0
	ctx.cr0.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq 0x82a81c30
	if (ctx.cr0.eq) goto loc_82A81C30;
	// lhz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82a81b50
	if (ctx.cr6.eq) goto loc_82A81B50;
	// lhz r11,6(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// b 0x82a81b58
	goto loc_82A81B58;
loc_82A81B50:
	// lhz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// lhz r10,6(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
loc_82A81B58:
	// clrlwi. r8,r11,30
	ctx.r8.u64 = ctx.r11.u32 & 0x3;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a81c30
	if (ctx.cr0.eq) goto loc_82A81C30;
	// cmplwi cr6,r9,1
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 1, ctx.xer);
	// bne cr6,0x82a81b74
	if (!ctx.cr6.eq) goto loc_82A81B74;
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// addi r28,r9,-21196
	ctx.r28.s64 = ctx.r9.s64 + -21196;
	// b 0x82a81b7c
	goto loc_82A81B7C;
loc_82A81B74:
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r28,r9,-17092
	ctx.r28.s64 = ctx.r9.s64 + -17092;
loc_82A81B7C:
	// mullw. r8,r10,r27
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r27.s32);
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// beq 0x82a81c2c
	if (ctx.cr0.eq) goto loc_82A81C2C;
	// mullw r7,r8,r10
	ctx.r7.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r10.s32);
	// add r7,r7,r11
	ctx.r7.u64 = ctx.r7.u64 + ctx.r11.u64;
	// addi r9,r8,1
	ctx.r9.s64 = ctx.r8.s64 + 1;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r5,r7,r6
	ctx.r5.u64 = ctx.r7.u64 + ctx.r6.u64;
	// mullw r7,r9,r11
	ctx.r7.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r11.s32);
	// mullw r9,r9,r10
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r3,r10,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r7,r26
	ctx.r7.u64 = ctx.r7.u64 + ctx.r26.u64;
	// add r4,r9,r6
	ctx.r4.u64 = ctx.r9.u64 + ctx.r6.u64;
loc_82A81BBC:
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// subf r5,r3,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r3.s64;
	// subf r4,r3,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r3.s64;
	// subf r7,r30,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r30.s64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a81bf8
	if (!ctx.cr6.gt) goto loc_82A81BF8;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
loc_82A81BDC:
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// addi r31,r31,-4
	ctx.r31.s64 = ctx.r31.s64 + -4;
	// rlwinm r29,r9,2,28,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xC;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// lwzx r29,r29,r28
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r28.u32);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// bgt cr6,0x82a81bdc
	if (ctx.cr6.gt) goto loc_82A81BDC;
loc_82A81BF8:
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a81c24
	if (ctx.cr6.eq) goto loc_82A81C24;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
loc_82A81C0C:
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r31,r31,-4
	ctx.r31.s64 = ctx.r31.s64 + -4;
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// lwz r26,0(r9)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r26,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r26.u32);
	// bne 0x82a81c0c
	if (!ctx.cr0.eq) goto loc_82A81C0C;
loc_82A81C24:
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82a81bbc
	if (!ctx.cr6.eq) goto loc_82A81BBC;
loc_82A81C2C:
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
loc_82A81C30:
	// lwz r10,44(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 44);
	// lhz r11,12(r24)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r24.u32 + 12);
	// mullw r7,r10,r27
	ctx.r7.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r27.s32);
	// cmplw cr6,r7,r11
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a81c48
	if (!ctx.cr6.gt) goto loc_82A81C48;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
loc_82A81C48:
	// lwz r10,28(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 28);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne 0x82a81c60
	if (!ctx.cr0.eq) goto loc_82A81C60;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82a81c84
	goto loc_82A81C84;
loc_82A81C60:
	// lhz r11,10(r24)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r24.u32 + 10);
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// add r4,r11,r22
	ctx.r4.u64 = ctx.r11.u64 + ctx.r22.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82A81C78;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a81c84
	if (ctx.cr0.lt) goto loc_82A81C84;
loc_82A81C80:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A81C84:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82d5c500
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A81C90"))) PPC_WEAK_FUNC(sub_82A81C90);
PPC_FUNC_IMPL(__imp__sub_82A81C90) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b0
	ctx.lr = 0x82A81C98;
	__savegprlr_22(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// mr r22,r7
	ctx.r22.u64 = ctx.r7.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// lwz r25,24(r24)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r24.u32 + 24);
	// lwz r6,32(r24)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r24.u32 + 32);
	// lhz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 0);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// blt cr6,0x82a81f64
	if (ctx.cr6.lt) goto loc_82A81F64;
	// beq cr6,0x82a81edc
	if (ctx.cr6.eq) goto loc_82A81EDC;
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// blt cr6,0x82a81e28
	if (ctx.cr6.lt) goto loc_82A81E28;
	// beq cr6,0x82a81d80
	if (ctx.cr6.eq) goto loc_82A81D80;
	// cmplwi cr6,r10,5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 5, ctx.xer);
	// beq cr6,0x82a81ce8
	if (ctx.cr6.eq) goto loc_82A81CE8;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16385
	ctx.r3.u64 = ctx.r3.u64 | 16385;
	// b 0x82a82160
	goto loc_82A82160;
loc_82A81CE8:
	// lwz r10,52(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 52);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lhz r11,8(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// divwu r28,r9,r10
	ctx.r28.u32 = ctx.r9.u32 / ctx.r10.u32;
	// twllei r10,0
	// cmplw cr6,r28,r11
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a81d08
	if (!ctx.cr6.gt) goto loc_82A81D08;
	// mr r28,r11
	ctx.r28.u64 = ctx.r11.u64;
loc_82A81D08:
	// li r26,0
	ctx.r26.s64 = 0;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82a8215c
	if (ctx.cr6.eq) goto loc_82A8215C;
loc_82A81D14:
	// lhz r11,10(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 10);
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a81d70
	if (ctx.cr0.eq) goto loc_82A81D70;
	// li r30,0
	ctx.r30.s64 = 0;
loc_82A81D28:
	// lwz r11,56(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 56);
	// mr r7,r22
	ctx.r7.u64 = ctx.r22.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// lwzx r31,r30,r11
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r11.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r6,48(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// bl 0x82a818d0
	ctx.lr = 0x82A81D48;
	sub_82A818D0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a82160
	if (ctx.cr0.lt) goto loc_82A82160;
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// lhz r10,10(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 10);
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r29,r10
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r10.u32, ctx.xer);
	// add r27,r11,r27
	ctx.r27.u64 = ctx.r11.u64 + ctx.r27.u64;
	// blt cr6,0x82a81d28
	if (ctx.cr6.lt) goto loc_82A81D28;
loc_82A81D70:
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// cmplw cr6,r26,r28
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r28.u32, ctx.xer);
	// blt cr6,0x82a81d14
	if (ctx.cr6.lt) goto loc_82A81D14;
	// b 0x82a8215c
	goto loc_82A8215C;
loc_82A81D80:
	// lhz r9,6(r25)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// divwu r26,r11,r9
	ctx.r26.u32 = ctx.r11.u32 / ctx.r9.u32;
	// twllei r9,0
	// cmplw cr6,r26,r10
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a81d9c
	if (!ctx.cr6.gt) goto loc_82A81D9C;
	// mr r26,r10
	ctx.r26.u64 = ctx.r10.u64;
loc_82A81D9C:
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a81f5c
	if (ctx.cr6.eq) goto loc_82A81F5C;
loc_82A81DAC:
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82a81e18
	if (ctx.cr6.eq) goto loc_82A81E18;
	// lhz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
loc_82A81DBC:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a81e08
	if (ctx.cr6.eq) goto loc_82A81E08;
loc_82A81DC8:
	// cmplwi cr6,r8,4
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 4, ctx.xer);
	// ble cr6,0x82a81dd8
	if (!ctx.cr6.gt) goto loc_82A81DD8;
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x82a81df0
	goto loc_82A81DF0;
loc_82A81DD8:
	// mullw r10,r10,r7
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r7.s32);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
loc_82A81DF0:
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lhz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a81dc8
	if (ctx.cr6.lt) goto loc_82A81DC8;
loc_82A81E08:
	// lhz r9,6(r25)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// cmplw cr6,r8,r9
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82a81dbc
	if (ctx.cr6.lt) goto loc_82A81DBC;
loc_82A81E18:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// cmplw cr6,r7,r26
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r26.u32, ctx.xer);
	// blt cr6,0x82a81dac
	if (ctx.cr6.lt) goto loc_82A81DAC;
	// b 0x82a81f5c
	goto loc_82A81F5C;
loc_82A81E28:
	// lhz r8,4(r25)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// divwu r26,r11,r8
	ctx.r26.u32 = ctx.r11.u32 / ctx.r8.u32;
	// twllei r8,0
	// cmplw cr6,r26,r10
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a81e44
	if (!ctx.cr6.gt) goto loc_82A81E44;
	// mr r26,r10
	ctx.r26.u64 = ctx.r10.u64;
loc_82A81E44:
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// cmplwi cr6,r10,4
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 4, ctx.xer);
	// beq cr6,0x82a81f78
	if (ctx.cr6.eq) goto loc_82A81F78;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a81f5c
	if (ctx.cr6.eq) goto loc_82A81F5C;
loc_82A81E60:
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82a81ecc
	if (ctx.cr6.eq) goto loc_82A81ECC;
loc_82A81E6C:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a81ebc
	if (ctx.cr6.eq) goto loc_82A81EBC;
loc_82A81E78:
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// ble cr6,0x82a81e88
	if (!ctx.cr6.gt) goto loc_82A81E88;
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x82a81ea4
	goto loc_82A81EA4;
loc_82A81E88:
	// lhz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// mullw r10,r10,r7
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r7.s32);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
loc_82A81EA4:
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a81e78
	if (ctx.cr6.lt) goto loc_82A81E78;
loc_82A81EBC:
	// lhz r8,4(r25)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// blt cr6,0x82a81e6c
	if (ctx.cr6.lt) goto loc_82A81E6C;
loc_82A81ECC:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// cmplw cr6,r7,r26
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r26.u32, ctx.xer);
	// blt cr6,0x82a81e60
	if (ctx.cr6.lt) goto loc_82A81E60;
	// b 0x82a81f5c
	goto loc_82A81F5C;
loc_82A81EDC:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// mr r26,r11
	ctx.r26.u64 = ctx.r11.u64;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a81ef0
	if (!ctx.cr6.gt) goto loc_82A81EF0;
	// mr r26,r10
	ctx.r26.u64 = ctx.r10.u64;
loc_82A81EF0:
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// cmplwi cr6,r10,4
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 4, ctx.xer);
	// beq cr6,0x82a81f78
	if (ctx.cr6.eq) goto loc_82A81F78;
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a81f5c
	if (ctx.cr6.eq) goto loc_82A81F5C;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
loc_82A81F10:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a81f50
	if (ctx.cr6.eq) goto loc_82A81F50;
loc_82A81F1C:
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// ble cr6,0x82a81f2c
	if (!ctx.cr6.gt) goto loc_82A81F2C;
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x82a81f38
	goto loc_82A81F38;
loc_82A81F2C:
	// add r10,r8,r11
	ctx.r10.u64 = ctx.r8.u64 + ctx.r11.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
loc_82A81F38:
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a81f1c
	if (ctx.cr6.lt) goto loc_82A81F1C;
loc_82A81F50:
	// addic. r7,r7,-1
	ctx.xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x82a81f10
	if (!ctx.cr0.eq) goto loc_82A81F10;
loc_82A81F5C:
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// b 0x82a81f78
	goto loc_82A81F78;
loc_82A81F64:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// rlwinm r26,r11,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r26,r10
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a81f78
	if (!ctx.cr6.gt) goto loc_82A81F78;
	// mr r26,r10
	ctx.r26.u64 = ctx.r10.u64;
loc_82A81F78:
	// lhz r11,2(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 2);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82a82008
	if (ctx.cr6.eq) goto loc_82A82008;
	// lwz r10,52(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 52);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// mullw r10,r10,r26
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r26.s32);
	// beq cr6,0x82a81fc8
	if (ctx.cr6.eq) goto loc_82A81FC8;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82a82004
	if (!ctx.cr6.eq) goto loc_82A82004;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a82004
	if (ctx.cr6.eq) goto loc_82A82004;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// subf r9,r6,r27
	ctx.r9.s64 = ctx.r27.s64 - ctx.r6.s64;
loc_82A81FAC:
	// lfsx f0,r9,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	ctx.f0.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a81fac
	if (!ctx.cr0.eq) goto loc_82A81FAC;
	// b 0x82a82004
	goto loc_82A82004;
loc_82A81FC8:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a82004
	if (ctx.cr6.eq) goto loc_82A82004;
	// lis r9,-32230
	ctx.r9.s64 = -2112225280;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// subf r8,r6,r27
	ctx.r8.s64 = ctx.r27.s64 - ctx.r6.s64;
	// lfs f0,21348(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 21348);
	ctx.f0.f64 = double(temp.f32);
loc_82A81FE0:
	// lfsx f13,r11,r8
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	ctx.f13.f64 = double(temp.f32);
	// li r9,1
	ctx.r9.s64 = 1;
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bne cr6,0x82a81ff4
	if (!ctx.cr6.eq) goto loc_82A81FF4;
	// li r9,0
	ctx.r9.s64 = 0;
loc_82A81FF4:
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a81fe0
	if (!ctx.cr0.eq) goto loc_82A81FE0;
loc_82A82004:
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
loc_82A82008:
	// lhz r9,8(r24)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r24.u32 + 8);
	// cmplwi r9,0
	ctx.cr0.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq 0x82a8210c
	if (ctx.cr0.eq) goto loc_82A8210C;
	// lhz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 0);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82a8202c
	if (ctx.cr6.eq) goto loc_82A8202C;
	// lhz r11,6(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// lhz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// b 0x82a82034
	goto loc_82A82034;
loc_82A8202C:
	// lhz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
loc_82A82034:
	// clrlwi. r8,r11,30
	ctx.r8.u64 = ctx.r11.u32 & 0x3;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a8210c
	if (ctx.cr0.eq) goto loc_82A8210C;
	// cmplwi cr6,r9,1
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 1, ctx.xer);
	// bne cr6,0x82a82050
	if (!ctx.cr6.eq) goto loc_82A82050;
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// addi r28,r9,-21196
	ctx.r28.s64 = ctx.r9.s64 + -21196;
	// b 0x82a82058
	goto loc_82A82058;
loc_82A82050:
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r28,r9,-17092
	ctx.r28.s64 = ctx.r9.s64 + -17092;
loc_82A82058:
	// mullw. r8,r10,r26
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r26.s32);
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// beq 0x82a82108
	if (ctx.cr0.eq) goto loc_82A82108;
	// mullw r7,r8,r10
	ctx.r7.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r10.s32);
	// add r7,r7,r11
	ctx.r7.u64 = ctx.r7.u64 + ctx.r11.u64;
	// addi r9,r8,1
	ctx.r9.s64 = ctx.r8.s64 + 1;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r5,r7,r6
	ctx.r5.u64 = ctx.r7.u64 + ctx.r6.u64;
	// mullw r7,r9,r11
	ctx.r7.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r11.s32);
	// mullw r9,r9,r10
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r3,r10,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r7,r27
	ctx.r7.u64 = ctx.r7.u64 + ctx.r27.u64;
	// add r4,r9,r6
	ctx.r4.u64 = ctx.r9.u64 + ctx.r6.u64;
loc_82A82098:
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// subf r5,r3,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r3.s64;
	// subf r4,r3,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r3.s64;
	// subf r7,r30,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r30.s64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a820d4
	if (!ctx.cr6.gt) goto loc_82A820D4;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
loc_82A820B8:
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// addi r31,r31,-4
	ctx.r31.s64 = ctx.r31.s64 + -4;
	// rlwinm r29,r9,2,28,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xC;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// lwzx r29,r29,r28
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r28.u32);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// bgt cr6,0x82a820b8
	if (ctx.cr6.gt) goto loc_82A820B8;
loc_82A820D4:
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a82100
	if (ctx.cr6.eq) goto loc_82A82100;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
loc_82A820E8:
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r31,r31,-4
	ctx.r31.s64 = ctx.r31.s64 + -4;
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// lwz r27,0(r9)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r27,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r27.u32);
	// bne 0x82a820e8
	if (!ctx.cr0.eq) goto loc_82A820E8;
loc_82A82100:
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82a82098
	if (!ctx.cr6.eq) goto loc_82A82098;
loc_82A82108:
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
loc_82A8210C:
	// lwz r10,44(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 44);
	// lhz r11,12(r24)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r24.u32 + 12);
	// mullw r7,r10,r26
	ctx.r7.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r26.s32);
	// cmplw cr6,r7,r11
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a82124
	if (!ctx.cr6.gt) goto loc_82A82124;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
loc_82A82124:
	// lwz r10,28(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 28);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne 0x82a8213c
	if (!ctx.cr0.eq) goto loc_82A8213C;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82a82160
	goto loc_82A82160;
loc_82A8213C:
	// lhz r11,10(r24)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r24.u32 + 10);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// add r4,r11,r22
	ctx.r4.u64 = ctx.r11.u64 + ctx.r22.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82A82154;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a82160
	if (ctx.cr0.lt) goto loc_82A82160;
loc_82A8215C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A82160:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82d5c500
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A82168"))) PPC_WEAK_FUNC(sub_82A82168);
PPC_FUNC_IMPL(__imp__sub_82A82168) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b0
	ctx.lr = 0x82A82170;
	__savegprlr_22(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// mr r22,r7
	ctx.r22.u64 = ctx.r7.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// lwz r25,24(r24)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r24.u32 + 24);
	// lwz r6,32(r24)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r24.u32 + 32);
	// lhz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 0);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// blt cr6,0x82a82518
	if (ctx.cr6.lt) goto loc_82A82518;
	// beq cr6,0x82a82484
	if (ctx.cr6.eq) goto loc_82A82484;
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// blt cr6,0x82a823c4
	if (ctx.cr6.lt) goto loc_82A823C4;
	// beq cr6,0x82a82258
	if (ctx.cr6.eq) goto loc_82A82258;
	// cmplwi cr6,r10,5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 5, ctx.xer);
	// beq cr6,0x82a821c0
	if (ctx.cr6.eq) goto loc_82A821C0;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16385
	ctx.r3.u64 = ctx.r3.u64 | 16385;
	// b 0x82a82714
	goto loc_82A82714;
loc_82A821C0:
	// lwz r10,52(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 52);
	// rlwinm r9,r11,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// lhz r11,8(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// divwu r28,r9,r10
	ctx.r28.u32 = ctx.r9.u32 / ctx.r10.u32;
	// twllei r10,0
	// cmplw cr6,r28,r11
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a821e0
	if (!ctx.cr6.gt) goto loc_82A821E0;
	// mr r28,r11
	ctx.r28.u64 = ctx.r11.u64;
loc_82A821E0:
	// li r26,0
	ctx.r26.s64 = 0;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82a82710
	if (ctx.cr6.eq) goto loc_82A82710;
loc_82A821EC:
	// lhz r11,10(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 10);
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a82248
	if (ctx.cr0.eq) goto loc_82A82248;
	// li r30,0
	ctx.r30.s64 = 0;
loc_82A82200:
	// lwz r11,56(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 56);
	// mr r7,r22
	ctx.r7.u64 = ctx.r22.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// lwzx r31,r11,r30
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r6,48(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// bl 0x82a818d0
	ctx.lr = 0x82A82220;
	sub_82A818D0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a82714
	if (ctx.cr0.lt) goto loc_82A82714;
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// lhz r10,10(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 10);
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r29,r10
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r10.u32, ctx.xer);
	// add r27,r11,r27
	ctx.r27.u64 = ctx.r11.u64 + ctx.r27.u64;
	// blt cr6,0x82a82200
	if (ctx.cr6.lt) goto loc_82A82200;
loc_82A82248:
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// cmplw cr6,r26,r28
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r28.u32, ctx.xer);
	// blt cr6,0x82a821ec
	if (ctx.cr6.lt) goto loc_82A821EC;
	// b 0x82a82710
	goto loc_82A82710;
loc_82A82258:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// mr r26,r11
	ctx.r26.u64 = ctx.r11.u64;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a8226c
	if (!ctx.cr6.gt) goto loc_82A8226C;
	// mr r26,r10
	ctx.r26.u64 = ctx.r10.u64;
loc_82A8226C:
	// lhz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// cmplwi cr6,r10,4
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 4, ctx.xer);
	// bne cr6,0x82a82330
	if (!ctx.cr6.eq) goto loc_82A82330;
	// lhz r11,6(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// bne cr6,0x82a82330
	if (!ctx.cr6.eq) goto loc_82A82330;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a82510
	if (ctx.cr6.eq) goto loc_82A82510;
	// addi r10,r6,8
	ctx.r10.s64 = ctx.r6.s64 + 8;
	// addi r11,r5,32
	ctx.r11.s64 = ctx.r5.s64 + 32;
	// subf r8,r5,r6
	ctx.r8.s64 = ctx.r6.s64 - ctx.r5.s64;
	// mr r9,r26
	ctx.r9.u64 = ctx.r26.u64;
loc_82A8229C:
	// lfs f0,-32(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -32);
	ctx.f0.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// stfs f0,-8(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + -8, temp.u32);
	// lfs f0,-16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -16);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,-4(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + -4, temp.u32);
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lfs f0,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,4(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lfs f0,-28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,8(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lfs f0,-12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -12);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,12(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 12, temp.u32);
	// lfs f0,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,16(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 16, temp.u32);
	// lfs f0,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,20(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 20, temp.u32);
	// lfs f0,-24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -24);
	ctx.f0.f64 = double(temp.f32);
	// stfsx f0,r8,r11
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r11.u32, temp.u32);
	// lfs f0,-8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,28(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 28, temp.u32);
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,32(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 32, temp.u32);
	// lfs f0,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,36(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// lfs f0,-20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -20);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,40(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// lfs f0,-4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,44(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// lfs f0,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,48(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 48, temp.u32);
	// lfs f0,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f0.f64 = double(temp.f32);
	// addi r11,r11,64
	ctx.r11.s64 = ctx.r11.s64 + 64;
	// stfs f0,52(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 52, temp.u32);
	// addi r10,r10,64
	ctx.r10.s64 = ctx.r10.s64 + 64;
	// bne 0x82a8229c
	if (!ctx.cr0.eq) goto loc_82A8229C;
	// b 0x82a82510
	goto loc_82A82510;
loc_82A82330:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a82510
	if (ctx.cr6.eq) goto loc_82A82510;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
loc_82A82344:
	// lhz r11,6(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a823b4
	if (ctx.cr0.eq) goto loc_82A823B4;
loc_82A82354:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a823a4
	if (ctx.cr6.eq) goto loc_82A823A4;
loc_82A82360:
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// bgt cr6,0x82a82388
	if (ctx.cr6.gt) goto loc_82A82388;
	// cmplwi cr6,r9,4
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 4, ctx.xer);
	// bgt cr6,0x82a82388
	if (ctx.cr6.gt) goto loc_82A82388;
	// add r10,r8,r11
	ctx.r10.u64 = ctx.r8.u64 + ctx.r11.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// b 0x82a8238c
	goto loc_82A8238C;
loc_82A82388:
	// li r10,0
	ctx.r10.s64 = 0;
loc_82A8238C:
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lhz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a82360
	if (ctx.cr6.lt) goto loc_82A82360;
loc_82A823A4:
	// lhz r11,6(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a82354
	if (ctx.cr6.lt) goto loc_82A82354;
loc_82A823B4:
	// addic. r4,r4,-1
	ctx.xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x82a82344
	if (!ctx.cr0.eq) goto loc_82A82344;
	// b 0x82a82510
	goto loc_82A82510;
loc_82A823C4:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// mr r26,r11
	ctx.r26.u64 = ctx.r11.u64;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a823d8
	if (!ctx.cr6.gt) goto loc_82A823D8;
	// mr r26,r10
	ctx.r26.u64 = ctx.r10.u64;
loc_82A823D8:
	// lhz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// bne cr6,0x82a823f0
	if (!ctx.cr6.eq) goto loc_82A823F0;
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// cmplwi cr6,r10,4
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 4, ctx.xer);
	// beq cr6,0x82a8252c
	if (ctx.cr6.eq) goto loc_82A8252C;
loc_82A823F0:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a82510
	if (ctx.cr6.eq) goto loc_82A82510;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
loc_82A82404:
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a82474
	if (ctx.cr6.eq) goto loc_82A82474;
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
loc_82A82414:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a82464
	if (ctx.cr6.eq) goto loc_82A82464;
loc_82A82420:
	// cmplwi cr6,r9,4
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 4, ctx.xer);
	// bgt cr6,0x82a82448
	if (ctx.cr6.gt) goto loc_82A82448;
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// bgt cr6,0x82a82448
	if (ctx.cr6.gt) goto loc_82A82448;
	// add r10,r8,r9
	ctx.r10.u64 = ctx.r8.u64 + ctx.r9.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// b 0x82a8244c
	goto loc_82A8244C;
loc_82A82448:
	// li r10,0
	ctx.r10.s64 = 0;
loc_82A8244C:
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a82420
	if (ctx.cr6.lt) goto loc_82A82420;
loc_82A82464:
	// lhz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a82414
	if (ctx.cr6.lt) goto loc_82A82414;
loc_82A82474:
	// addic. r4,r4,-1
	ctx.xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x82a82404
	if (!ctx.cr0.eq) goto loc_82A82404;
	// b 0x82a82510
	goto loc_82A82510;
loc_82A82484:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// rlwinm r26,r11,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r26,r10
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a82498
	if (!ctx.cr6.gt) goto loc_82A82498;
	// mr r26,r10
	ctx.r26.u64 = ctx.r10.u64;
loc_82A82498:
	// lhz r9,6(r25)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// cmplwi cr6,r9,4
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 4, ctx.xer);
	// beq cr6,0x82a8252c
	if (ctx.cr6.eq) goto loc_82A8252C;
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a82510
	if (ctx.cr6.eq) goto loc_82A82510;
loc_82A824B4:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82a82504
	if (ctx.cr6.eq) goto loc_82A82504;
loc_82A824C0:
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// ble cr6,0x82a824d0
	if (!ctx.cr6.gt) goto loc_82A824D0;
	// li r9,0
	ctx.r9.s64 = 0;
	// b 0x82a824ec
	goto loc_82A824EC;
loc_82A824D0:
	// rlwinm r9,r10,0,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// clrlwi r8,r10,30
	ctx.r8.u64 = ctx.r10.u32 & 0x3;
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + ctx.r11.u64;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r5
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
loc_82A824EC:
	// stw r9,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r9.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lhz r9,6(r25)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82a824c0
	if (ctx.cr6.lt) goto loc_82A824C0;
loc_82A82504:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r26
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r26.u32, ctx.xer);
	// blt cr6,0x82a824b4
	if (ctx.cr6.lt) goto loc_82A824B4;
loc_82A82510:
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// b 0x82a8252c
	goto loc_82A8252C;
loc_82A82518:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// rlwinm r26,r11,4,0,27
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// cmplw cr6,r26,r10
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a8252c
	if (!ctx.cr6.gt) goto loc_82A8252C;
	// mr r26,r10
	ctx.r26.u64 = ctx.r10.u64;
loc_82A8252C:
	// lhz r11,2(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 2);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82a825bc
	if (ctx.cr6.eq) goto loc_82A825BC;
	// lwz r10,52(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 52);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// mullw r10,r10,r26
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r26.s32);
	// beq cr6,0x82a8257c
	if (ctx.cr6.eq) goto loc_82A8257C;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82a825b8
	if (!ctx.cr6.eq) goto loc_82A825B8;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a825b8
	if (ctx.cr6.eq) goto loc_82A825B8;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// subf r9,r6,r27
	ctx.r9.s64 = ctx.r27.s64 - ctx.r6.s64;
loc_82A82560:
	// lfsx f0,r9,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	ctx.f0.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a82560
	if (!ctx.cr0.eq) goto loc_82A82560;
	// b 0x82a825b8
	goto loc_82A825B8;
loc_82A8257C:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a825b8
	if (ctx.cr6.eq) goto loc_82A825B8;
	// lis r9,-32230
	ctx.r9.s64 = -2112225280;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// subf r8,r6,r27
	ctx.r8.s64 = ctx.r27.s64 - ctx.r6.s64;
	// lfs f0,21348(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 21348);
	ctx.f0.f64 = double(temp.f32);
loc_82A82594:
	// lfsx f13,r11,r8
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	ctx.f13.f64 = double(temp.f32);
	// li r9,1
	ctx.r9.s64 = 1;
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bne cr6,0x82a825a8
	if (!ctx.cr6.eq) goto loc_82A825A8;
	// li r9,0
	ctx.r9.s64 = 0;
loc_82A825A8:
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a82594
	if (!ctx.cr0.eq) goto loc_82A82594;
loc_82A825B8:
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
loc_82A825BC:
	// lhz r9,8(r24)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r24.u32 + 8);
	// cmplwi r9,0
	ctx.cr0.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq 0x82a826c0
	if (ctx.cr0.eq) goto loc_82A826C0;
	// lhz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 0);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82a825e0
	if (ctx.cr6.eq) goto loc_82A825E0;
	// lhz r11,6(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// lhz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// b 0x82a825e8
	goto loc_82A825E8;
loc_82A825E0:
	// lhz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
loc_82A825E8:
	// clrlwi. r8,r11,30
	ctx.r8.u64 = ctx.r11.u32 & 0x3;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a826c0
	if (ctx.cr0.eq) goto loc_82A826C0;
	// cmplwi cr6,r9,1
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 1, ctx.xer);
	// bne cr6,0x82a82604
	if (!ctx.cr6.eq) goto loc_82A82604;
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// addi r28,r9,-21196
	ctx.r28.s64 = ctx.r9.s64 + -21196;
	// b 0x82a8260c
	goto loc_82A8260C;
loc_82A82604:
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r28,r9,-17092
	ctx.r28.s64 = ctx.r9.s64 + -17092;
loc_82A8260C:
	// mullw. r8,r10,r26
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r26.s32);
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// beq 0x82a826bc
	if (ctx.cr0.eq) goto loc_82A826BC;
	// mullw r7,r8,r10
	ctx.r7.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r10.s32);
	// add r7,r7,r11
	ctx.r7.u64 = ctx.r7.u64 + ctx.r11.u64;
	// addi r9,r8,1
	ctx.r9.s64 = ctx.r8.s64 + 1;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r5,r7,r6
	ctx.r5.u64 = ctx.r7.u64 + ctx.r6.u64;
	// mullw r7,r9,r11
	ctx.r7.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r11.s32);
	// mullw r9,r9,r10
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r3,r10,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r7,r27
	ctx.r7.u64 = ctx.r7.u64 + ctx.r27.u64;
	// add r4,r9,r6
	ctx.r4.u64 = ctx.r9.u64 + ctx.r6.u64;
loc_82A8264C:
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// subf r5,r3,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r3.s64;
	// subf r4,r3,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r3.s64;
	// subf r7,r30,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r30.s64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a82688
	if (!ctx.cr6.gt) goto loc_82A82688;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
loc_82A8266C:
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// addi r31,r31,-4
	ctx.r31.s64 = ctx.r31.s64 + -4;
	// rlwinm r29,r9,2,28,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xC;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// lwzx r29,r29,r28
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r28.u32);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// bgt cr6,0x82a8266c
	if (ctx.cr6.gt) goto loc_82A8266C;
loc_82A82688:
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a826b4
	if (ctx.cr6.eq) goto loc_82A826B4;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
loc_82A8269C:
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r31,r31,-4
	ctx.r31.s64 = ctx.r31.s64 + -4;
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// lwz r27,0(r9)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r27,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r27.u32);
	// bne 0x82a8269c
	if (!ctx.cr0.eq) goto loc_82A8269C;
loc_82A826B4:
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82a8264c
	if (!ctx.cr6.eq) goto loc_82A8264C;
loc_82A826BC:
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
loc_82A826C0:
	// lwz r10,44(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 44);
	// lhz r11,12(r24)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r24.u32 + 12);
	// mullw r7,r10,r26
	ctx.r7.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r26.s32);
	// cmplw cr6,r7,r11
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a826d8
	if (!ctx.cr6.gt) goto loc_82A826D8;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
loc_82A826D8:
	// lwz r10,28(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 28);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne 0x82a826f0
	if (!ctx.cr0.eq) goto loc_82A826F0;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82a82714
	goto loc_82A82714;
loc_82A826F0:
	// lhz r11,10(r24)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r24.u32 + 10);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// add r4,r11,r22
	ctx.r4.u64 = ctx.r11.u64 + ctx.r22.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82A82708;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a82714
	if (ctx.cr0.lt) goto loc_82A82714;
loc_82A82710:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A82714:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82d5c500
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A82720"))) PPC_WEAK_FUNC(sub_82A82720);
PPC_FUNC_IMPL(__imp__sub_82A82720) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4ac
	ctx.lr = 0x82A82728;
	__savegprlr_21(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// mr r22,r4
	ctx.r22.u64 = ctx.r4.u64;
	// mr r21,r7
	ctx.r21.u64 = ctx.r7.u64;
	// lwz r25,24(r23)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r23.u32 + 24);
	// lwz r6,32(r23)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r23.u32 + 32);
	// lhz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 0);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// blt cr6,0x82a82a30
	if (ctx.cr6.lt) goto loc_82A82A30;
	// beq cr6,0x82a829ac
	if (ctx.cr6.eq) goto loc_82A829AC;
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// blt cr6,0x82a828fc
	if (ctx.cr6.lt) goto loc_82A828FC;
	// beq cr6,0x82a82854
	if (ctx.cr6.eq) goto loc_82A82854;
	// cmplwi cr6,r10,5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 5, ctx.xer);
	// beq cr6,0x82a82774
	if (ctx.cr6.eq) goto loc_82A82774;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16385
	ctx.r3.u64 = ctx.r3.u64 | 16385;
	// b 0x82a82c60
	goto loc_82A82C60;
loc_82A82774:
	// lwz r10,52(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 52);
	// rlwinm r9,r11,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// lhz r11,8(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// divwu r27,r9,r10
	ctx.r27.u32 = ctx.r9.u32 / ctx.r10.u32;
	// twllei r10,0
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a82794
	if (!ctx.cr6.gt) goto loc_82A82794;
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
loc_82A82794:
	// mullw. r8,r10,r27
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r27.s32);
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// beq 0x82a827d8
	if (ctx.cr0.eq) goto loc_82A827D8;
loc_82A827A4:
	// rlwinm r9,r11,30,2,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x3FFFFFFF;
	// clrlwi r4,r11,30
	ctx.r4.u64 = ctx.r11.u32 & 0x3;
	// rlwinm r7,r9,2,28,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xC;
	// rlwinm r9,r9,0,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFC;
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r11,r8
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r8.u32, ctx.xer);
	// lwzx r9,r9,r5
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	// lwzx r9,r7,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// blt cr6,0x82a827a4
	if (ctx.cr6.lt) goto loc_82A827A4;
loc_82A827D8:
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// li r26,0
	ctx.r26.s64 = 0;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a82c5c
	if (ctx.cr6.eq) goto loc_82A82C5C;
loc_82A827E8:
	// lhz r11,10(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 10);
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a82844
	if (ctx.cr0.eq) goto loc_82A82844;
	// li r30,0
	ctx.r30.s64 = 0;
loc_82A827FC:
	// lwz r11,56(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 56);
	// mr r7,r21
	ctx.r7.u64 = ctx.r21.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// lwzx r31,r30,r11
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r11.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r6,48(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// bl 0x82a818d0
	ctx.lr = 0x82A8281C;
	sub_82A818D0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a82c60
	if (ctx.cr0.lt) goto loc_82A82C60;
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// lhz r10,10(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 10);
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r28,r10
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r10.u32, ctx.xer);
	// add r29,r11,r29
	ctx.r29.u64 = ctx.r11.u64 + ctx.r29.u64;
	// blt cr6,0x82a827fc
	if (ctx.cr6.lt) goto loc_82A827FC;
loc_82A82844:
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// cmplw cr6,r26,r27
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r27.u32, ctx.xer);
	// blt cr6,0x82a827e8
	if (ctx.cr6.lt) goto loc_82A827E8;
	// b 0x82a82c5c
	goto loc_82A82C5C;
loc_82A82854:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// mr r24,r11
	ctx.r24.u64 = ctx.r11.u64;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a82868
	if (!ctx.cr6.gt) goto loc_82A82868;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
loc_82A82868:
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82a82a88
	if (ctx.cr6.eq) goto loc_82A82A88;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
loc_82A8287C:
	// lhz r11,6(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a828ec
	if (ctx.cr0.eq) goto loc_82A828EC;
	// lhz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
loc_82A82890:
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a828dc
	if (ctx.cr6.eq) goto loc_82A828DC;
	// rlwinm r9,r7,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
loc_82A828A0:
	// cmplwi cr6,r10,4
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 4, ctx.xer);
	// bgt cr6,0x82a828bc
	if (ctx.cr6.gt) goto loc_82A828BC;
	// cmplwi cr6,r7,4
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 4, ctx.xer);
	// bgt cr6,0x82a828bc
	if (ctx.cr6.gt) goto loc_82A828BC;
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwzx r11,r9,r11
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// b 0x82a828c0
	goto loc_82A828C0;
loc_82A828BC:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82A828C0:
	// stw r11,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r11.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lhz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// addi r9,r9,16
	ctx.r9.s64 = ctx.r9.s64 + 16;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a828a0
	if (ctx.cr6.lt) goto loc_82A828A0;
loc_82A828DC:
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// cmplw cr6,r7,r10
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a82890
	if (ctx.cr6.lt) goto loc_82A82890;
loc_82A828EC:
	// addic. r3,r3,-1
	ctx.xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// bne 0x82a8287c
	if (!ctx.cr0.eq) goto loc_82A8287C;
	// b 0x82a82a88
	goto loc_82A82A88;
loc_82A828FC:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// mr r24,r11
	ctx.r24.u64 = ctx.r11.u64;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a82910
	if (!ctx.cr6.gt) goto loc_82A82910;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
loc_82A82910:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82a82a88
	if (ctx.cr6.eq) goto loc_82A82A88;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
loc_82A82924:
	// lhz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a8299c
	if (ctx.cr0.eq) goto loc_82A8299C;
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// li r9,0
	ctx.r9.s64 = 0;
loc_82A8293C:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a82988
	if (ctx.cr6.eq) goto loc_82A82988;
loc_82A82948:
	// cmplwi cr6,r9,16
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 16, ctx.xer);
	// bgt cr6,0x82a8296c
	if (ctx.cr6.gt) goto loc_82A8296C;
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// bgt cr6,0x82a8296c
	if (ctx.cr6.gt) goto loc_82A8296C;
	// add r10,r9,r11
	ctx.r10.u64 = ctx.r9.u64 + ctx.r11.u64;
	// lwz r5,0(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// b 0x82a82970
	goto loc_82A82970;
loc_82A8296C:
	// li r10,0
	ctx.r10.s64 = 0;
loc_82A82970:
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a82948
	if (ctx.cr6.lt) goto loc_82A82948;
loc_82A82988:
	// lhz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r8,r11
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a8293c
	if (ctx.cr6.lt) goto loc_82A8293C;
loc_82A8299C:
	// addic. r3,r3,-1
	ctx.xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// bne 0x82a82924
	if (!ctx.cr0.eq) goto loc_82A82924;
	// b 0x82a82a88
	goto loc_82A82A88;
loc_82A829AC:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// rlwinm r24,r11,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r24,r10
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a829c0
	if (!ctx.cr6.gt) goto loc_82A829C0;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
loc_82A829C0:
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82a82a88
	if (ctx.cr6.eq) goto loc_82A82A88;
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
loc_82A829D4:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a82a20
	if (ctx.cr6.eq) goto loc_82A82A20;
loc_82A829E0:
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// ble cr6,0x82a829f0
	if (!ctx.cr6.gt) goto loc_82A829F0;
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x82a82a08
	goto loc_82A82A08;
loc_82A829F0:
	// rlwinm r10,r9,2,28,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xC;
	// rlwinm r7,r9,0,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFC;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r5
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
loc_82A82A08:
	// stw r10,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a829e0
	if (ctx.cr6.lt) goto loc_82A829E0;
loc_82A82A20:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r9,r24
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r24.u32, ctx.xer);
	// blt cr6,0x82a829d4
	if (ctx.cr6.lt) goto loc_82A829D4;
	// b 0x82a82a88
	goto loc_82A82A88;
loc_82A82A30:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// rlwinm r24,r11,4,0,27
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// cmplw cr6,r24,r10
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a82a44
	if (!ctx.cr6.gt) goto loc_82A82A44;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
loc_82A82A44:
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82a82a88
	if (ctx.cr6.eq) goto loc_82A82A88;
loc_82A82A54:
	// rlwinm r9,r11,30,2,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x3FFFFFFF;
	// clrlwi r7,r11,30
	ctx.r7.u64 = ctx.r11.u32 & 0x3;
	// rlwinm r8,r9,2,28,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xC;
	// rlwinm r9,r9,0,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFC;
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r11,r24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r24.u32, ctx.xer);
	// lwzx r9,r9,r5
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	// lwzx r9,r8,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// blt cr6,0x82a82a54
	if (ctx.cr6.lt) goto loc_82A82A54;
loc_82A82A88:
	// lhz r10,2(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 2);
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// beq cr6,0x82a82b0c
	if (ctx.cr6.eq) goto loc_82A82B0C;
	// lwz r11,52(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 52);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// mullw r11,r11,r24
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r24.s32);
	// beq cr6,0x82a82ad4
	if (ctx.cr6.eq) goto loc_82A82AD4;
	// cmpwi cr6,r10,2
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 2, ctx.xer);
	// bne cr6,0x82a82b0c
	if (!ctx.cr6.eq) goto loc_82A82B0C;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a82b0c
	if (ctx.cr6.eq) goto loc_82A82B0C;
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
loc_82A82AB8:
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, ctx.f0.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82a82ab8
	if (!ctx.cr0.eq) goto loc_82A82AB8;
	// b 0x82a82b0c
	goto loc_82A82B0C;
loc_82A82AD4:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a82b0c
	if (ctx.cr6.eq) goto loc_82A82B0C;
	// lis r9,-32230
	ctx.r9.s64 = -2112225280;
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// lfs f0,21348(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 21348);
	ctx.f0.f64 = double(temp.f32);
loc_82A82AE8:
	// lfs f13,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// li r9,1
	ctx.r9.s64 = 1;
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bne cr6,0x82a82afc
	if (!ctx.cr6.eq) goto loc_82A82AFC;
	// li r9,0
	ctx.r9.s64 = 0;
loc_82A82AFC:
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82a82ae8
	if (!ctx.cr0.eq) goto loc_82A82AE8;
loc_82A82B0C:
	// lhz r9,8(r23)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r23.u32 + 8);
	// cmplwi r9,0
	ctx.cr0.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq 0x82a82c0c
	if (ctx.cr0.eq) goto loc_82A82C0C;
	// lhz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 0);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82a82b30
	if (ctx.cr6.eq) goto loc_82A82B30;
	// lhz r11,6(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// lhz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// b 0x82a82b38
	goto loc_82A82B38;
loc_82A82B30:
	// lhz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
loc_82A82B38:
	// clrlwi. r8,r11,30
	ctx.r8.u64 = ctx.r11.u32 & 0x3;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a82c0c
	if (ctx.cr0.eq) goto loc_82A82C0C;
	// cmplwi cr6,r9,1
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 1, ctx.xer);
	// bne cr6,0x82a82b54
	if (!ctx.cr6.eq) goto loc_82A82B54;
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// addi r26,r9,-21196
	ctx.r26.s64 = ctx.r9.s64 + -21196;
	// b 0x82a82b5c
	goto loc_82A82B5C;
loc_82A82B54:
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r26,r9,-17092
	ctx.r26.s64 = ctx.r9.s64 + -17092;
loc_82A82B5C:
	// mullw. r9,r10,r24
	ctx.r9.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r24.s32);
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// beq 0x82a82c0c
	if (ctx.cr0.eq) goto loc_82A82C0C;
	// mullw r7,r9,r10
	ctx.r7.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// add r7,r7,r11
	ctx.r7.u64 = ctx.r7.u64 + ctx.r11.u64;
	// addi r8,r9,1
	ctx.r8.s64 = ctx.r9.s64 + 1;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r7,r6
	ctx.r4.u64 = ctx.r7.u64 + ctx.r6.u64;
	// mullw r7,r8,r11
	ctx.r7.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r11.s32);
	// mullw r8,r8,r10
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r10.s32);
	// rlwinm r27,r11,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r31,r10,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r7,r6
	ctx.r7.u64 = ctx.r7.u64 + ctx.r6.u64;
	// add r3,r8,r6
	ctx.r3.u64 = ctx.r8.u64 + ctx.r6.u64;
loc_82A82B9C:
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// subf r4,r31,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r31.s64;
	// subf r3,r31,r3
	ctx.r3.s64 = ctx.r3.s64 - ctx.r31.s64;
	// subf r7,r27,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r27.s64;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a82bd8
	if (!ctx.cr6.gt) goto loc_82A82BD8;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
loc_82A82BBC:
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
	// rlwinm r5,r8,2,28,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xC;
	// cmplw cr6,r8,r11
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r11.u32, ctx.xer);
	// lwzx r5,r5,r26
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r26.u32);
	// stw r5,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r5.u32);
	// bgt cr6,0x82a82bbc
	if (ctx.cr6.gt) goto loc_82A82BBC;
loc_82A82BD8:
	// mr r28,r11
	ctx.r28.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a82c04
	if (ctx.cr6.eq) goto loc_82A82C04;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r8,r7
	ctx.r8.u64 = ctx.r7.u64;
loc_82A82BEC:
	// addi r8,r8,-4
	ctx.r8.s64 = ctx.r8.s64 + -4;
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// lwz r5,0(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// stw r5,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r5.u32);
	// bne 0x82a82bec
	if (!ctx.cr0.eq) goto loc_82A82BEC;
loc_82A82C04:
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82a82b9c
	if (!ctx.cr6.eq) goto loc_82A82B9C;
loc_82A82C0C:
	// lwz r10,44(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 44);
	// lhz r11,12(r23)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r23.u32 + 12);
	// mullw r7,r10,r24
	ctx.r7.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r24.s32);
	// cmplw cr6,r7,r11
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a82c24
	if (!ctx.cr6.gt) goto loc_82A82C24;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
loc_82A82C24:
	// lwz r10,28(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 28);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne 0x82a82c3c
	if (!ctx.cr0.eq) goto loc_82A82C3C;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82a82c60
	goto loc_82A82C60;
loc_82A82C3C:
	// lhz r11,10(r23)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r23.u32 + 10);
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// add r4,r11,r21
	ctx.r4.u64 = ctx.r11.u64 + ctx.r21.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82A82C54;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a82c60
	if (ctx.cr0.lt) goto loc_82A82C60;
loc_82A82C5C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A82C60:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82d5c4fc
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A82C68"))) PPC_WEAK_FUNC(sub_82A82C68);
PPC_FUNC_IMPL(__imp__sub_82A82C68) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b0
	ctx.lr = 0x82A82C70;
	__savegprlr_22(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// mr r22,r7
	ctx.r22.u64 = ctx.r7.u64;
	// lwz r25,24(r24)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r24.u32 + 24);
	// lwz r6,32(r24)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r24.u32 + 32);
	// lhz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 0);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// blt cr6,0x82a83054
	if (ctx.cr6.lt) goto loc_82A83054;
	// beq cr6,0x82a82fcc
	if (ctx.cr6.eq) goto loc_82A82FCC;
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// blt cr6,0x82a82e60
	if (ctx.cr6.lt) goto loc_82A82E60;
	// beq cr6,0x82a82da0
	if (ctx.cr6.eq) goto loc_82A82DA0;
	// cmplwi cr6,r10,5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 5, ctx.xer);
	// beq cr6,0x82a82cbc
	if (ctx.cr6.eq) goto loc_82A82CBC;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16385
	ctx.r3.u64 = ctx.r3.u64 | 16385;
	// b 0x82a83298
	goto loc_82A83298;
loc_82A82CBC:
	// lwz r10,52(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 52);
	// rlwinm r9,r11,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// lhz r11,8(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// divwu r27,r9,r10
	ctx.r27.u32 = ctx.r9.u32 / ctx.r10.u32;
	// twllei r10,0
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a82cdc
	if (!ctx.cr6.gt) goto loc_82A82CDC;
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
loc_82A82CDC:
	// mullw. r8,r10,r27
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r27.s32);
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// beq 0x82a82d24
	if (ctx.cr0.eq) goto loc_82A82D24;
loc_82A82CEC:
	// rlwinm r9,r11,30,2,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x3FFFFFFF;
	// clrlwi r3,r11,30
	ctx.r3.u64 = ctx.r11.u32 & 0x3;
	// rlwinm r4,r9,0,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFC;
	// clrlwi r7,r9,30
	ctx.r7.u64 = ctx.r9.u32 & 0x3;
	// add r9,r4,r3
	ctx.r9.u64 = ctx.r4.u64 + ctx.r3.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r11,r8
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r8.u32, ctx.xer);
	// add r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 + ctx.r7.u64;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r5
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// blt cr6,0x82a82cec
	if (ctx.cr6.lt) goto loc_82A82CEC;
loc_82A82D24:
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// li r26,0
	ctx.r26.s64 = 0;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a83294
	if (ctx.cr6.eq) goto loc_82A83294;
loc_82A82D34:
	// lhz r11,10(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 10);
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a82d90
	if (ctx.cr0.eq) goto loc_82A82D90;
	// li r30,0
	ctx.r30.s64 = 0;
loc_82A82D48:
	// lwz r11,56(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 56);
	// mr r7,r22
	ctx.r7.u64 = ctx.r22.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// lwzx r31,r30,r11
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r11.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r6,48(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// bl 0x82a818d0
	ctx.lr = 0x82A82D68;
	sub_82A818D0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a83298
	if (ctx.cr0.lt) goto loc_82A83298;
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// lhz r10,10(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 10);
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r28,r10
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r10.u32, ctx.xer);
	// add r29,r11,r29
	ctx.r29.u64 = ctx.r11.u64 + ctx.r29.u64;
	// blt cr6,0x82a82d48
	if (ctx.cr6.lt) goto loc_82A82D48;
loc_82A82D90:
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// cmplw cr6,r26,r27
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r27.u32, ctx.xer);
	// blt cr6,0x82a82d34
	if (ctx.cr6.lt) goto loc_82A82D34;
	// b 0x82a83294
	goto loc_82A83294;
loc_82A82DA0:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// mr r26,r11
	ctx.r26.u64 = ctx.r11.u64;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a82db4
	if (!ctx.cr6.gt) goto loc_82A82DB4;
	// mr r26,r10
	ctx.r26.u64 = ctx.r10.u64;
loc_82A82DB4:
	// lhz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// cmplwi cr6,r10,4
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 4, ctx.xer);
	// bne cr6,0x82a82dcc
	if (!ctx.cr6.eq) goto loc_82A82DCC;
	// lhz r11,6(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// beq cr6,0x82a830b4
	if (ctx.cr6.eq) goto loc_82A830B4;
loc_82A82DCC:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a830b0
	if (ctx.cr6.eq) goto loc_82A830B0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
loc_82A82DE0:
	// lhz r11,6(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a82e50
	if (ctx.cr0.eq) goto loc_82A82E50;
loc_82A82DF0:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a82e40
	if (ctx.cr6.eq) goto loc_82A82E40;
loc_82A82DFC:
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// bgt cr6,0x82a82e24
	if (ctx.cr6.gt) goto loc_82A82E24;
	// cmplwi cr6,r9,4
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 4, ctx.xer);
	// bgt cr6,0x82a82e24
	if (ctx.cr6.gt) goto loc_82A82E24;
	// add r10,r8,r9
	ctx.r10.u64 = ctx.r8.u64 + ctx.r9.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// b 0x82a82e28
	goto loc_82A82E28;
loc_82A82E24:
	// li r10,0
	ctx.r10.s64 = 0;
loc_82A82E28:
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lhz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a82dfc
	if (ctx.cr6.lt) goto loc_82A82DFC;
loc_82A82E40:
	// lhz r11,6(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a82df0
	if (ctx.cr6.lt) goto loc_82A82DF0;
loc_82A82E50:
	// addic. r4,r4,-1
	ctx.xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x82a82de0
	if (!ctx.cr0.eq) goto loc_82A82DE0;
	// b 0x82a830b0
	goto loc_82A830B0;
loc_82A82E60:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// mr r26,r11
	ctx.r26.u64 = ctx.r11.u64;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a82e74
	if (!ctx.cr6.gt) goto loc_82A82E74;
	// mr r26,r10
	ctx.r26.u64 = ctx.r10.u64;
loc_82A82E74:
	// lhz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// bne cr6,0x82a82f38
	if (!ctx.cr6.eq) goto loc_82A82F38;
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// cmplwi cr6,r10,4
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 4, ctx.xer);
	// bne cr6,0x82a82f38
	if (!ctx.cr6.eq) goto loc_82A82F38;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a830b0
	if (ctx.cr6.eq) goto loc_82A830B0;
	// addi r10,r6,8
	ctx.r10.s64 = ctx.r6.s64 + 8;
	// addi r11,r5,32
	ctx.r11.s64 = ctx.r5.s64 + 32;
	// subf r8,r5,r6
	ctx.r8.s64 = ctx.r6.s64 - ctx.r5.s64;
	// mr r9,r26
	ctx.r9.u64 = ctx.r26.u64;
loc_82A82EA4:
	// lfs f0,-32(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -32);
	ctx.f0.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// stfs f0,-8(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + -8, temp.u32);
	// lfs f0,-16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -16);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,-4(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + -4, temp.u32);
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lfs f0,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,4(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lfs f0,-28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,8(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lfs f0,-12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -12);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,12(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 12, temp.u32);
	// lfs f0,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,16(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 16, temp.u32);
	// lfs f0,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,20(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 20, temp.u32);
	// lfs f0,-24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -24);
	ctx.f0.f64 = double(temp.f32);
	// stfsx f0,r8,r11
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r11.u32, temp.u32);
	// lfs f0,-8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,28(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 28, temp.u32);
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,32(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 32, temp.u32);
	// lfs f0,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,36(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 36, temp.u32);
	// lfs f0,-20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -20);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,40(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 40, temp.u32);
	// lfs f0,-4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,44(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 44, temp.u32);
	// lfs f0,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,48(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 48, temp.u32);
	// lfs f0,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f0.f64 = double(temp.f32);
	// addi r11,r11,64
	ctx.r11.s64 = ctx.r11.s64 + 64;
	// stfs f0,52(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 52, temp.u32);
	// addi r10,r10,64
	ctx.r10.s64 = ctx.r10.s64 + 64;
	// bne 0x82a82ea4
	if (!ctx.cr0.eq) goto loc_82A82EA4;
	// b 0x82a830b0
	goto loc_82A830B0;
loc_82A82F38:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a830b0
	if (ctx.cr6.eq) goto loc_82A830B0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
loc_82A82F4C:
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a82fbc
	if (ctx.cr6.eq) goto loc_82A82FBC;
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
loc_82A82F5C:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a82fac
	if (ctx.cr6.eq) goto loc_82A82FAC;
loc_82A82F68:
	// cmplwi cr6,r9,4
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 4, ctx.xer);
	// bgt cr6,0x82a82f90
	if (ctx.cr6.gt) goto loc_82A82F90;
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// bgt cr6,0x82a82f90
	if (ctx.cr6.gt) goto loc_82A82F90;
	// add r10,r8,r11
	ctx.r10.u64 = ctx.r8.u64 + ctx.r11.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// b 0x82a82f94
	goto loc_82A82F94;
loc_82A82F90:
	// li r10,0
	ctx.r10.s64 = 0;
loc_82A82F94:
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a82f68
	if (ctx.cr6.lt) goto loc_82A82F68;
loc_82A82FAC:
	// lhz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a82f5c
	if (ctx.cr6.lt) goto loc_82A82F5C;
loc_82A82FBC:
	// addic. r4,r4,-1
	ctx.xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x82a82f4c
	if (!ctx.cr0.eq) goto loc_82A82F4C;
	// b 0x82a830b0
	goto loc_82A830B0;
loc_82A82FCC:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// rlwinm r26,r11,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r26,r10
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a82fe0
	if (!ctx.cr6.gt) goto loc_82A82FE0;
	// mr r26,r10
	ctx.r26.u64 = ctx.r10.u64;
loc_82A82FE0:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a830b0
	if (ctx.cr6.eq) goto loc_82A830B0;
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
loc_82A82FF4:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a83044
	if (ctx.cr6.eq) goto loc_82A83044;
loc_82A83000:
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// ble cr6,0x82a83010
	if (!ctx.cr6.gt) goto loc_82A83010;
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x82a8302c
	goto loc_82A8302C;
loc_82A83010:
	// rlwinm r10,r8,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFC;
	// clrlwi r9,r8,30
	ctx.r9.u64 = ctx.r8.u32 & 0x3;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
loc_82A8302C:
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a83000
	if (ctx.cr6.lt) goto loc_82A83000;
loc_82A83044:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// cmplw cr6,r8,r26
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r26.u32, ctx.xer);
	// blt cr6,0x82a82ff4
	if (ctx.cr6.lt) goto loc_82A82FF4;
	// b 0x82a830b0
	goto loc_82A830B0;
loc_82A83054:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// rlwinm r26,r11,4,0,27
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// cmplw cr6,r26,r10
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a83068
	if (!ctx.cr6.gt) goto loc_82A83068;
	// mr r26,r10
	ctx.r26.u64 = ctx.r10.u64;
loc_82A83068:
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a830b0
	if (ctx.cr6.eq) goto loc_82A830B0;
loc_82A83078:
	// rlwinm r9,r11,30,2,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x3FFFFFFF;
	// clrlwi r4,r11,30
	ctx.r4.u64 = ctx.r11.u32 & 0x3;
	// rlwinm r7,r9,0,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFC;
	// clrlwi r8,r9,30
	ctx.r8.u64 = ctx.r9.u32 & 0x3;
	// add r9,r7,r4
	ctx.r9.u64 = ctx.r7.u64 + ctx.r4.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r11,r26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r26.u32, ctx.xer);
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r5
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// blt cr6,0x82a83078
	if (ctx.cr6.lt) goto loc_82A83078;
loc_82A830B0:
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
loc_82A830B4:
	// lhz r11,2(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 2);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82a83144
	if (ctx.cr6.eq) goto loc_82A83144;
	// lwz r10,52(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 52);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// mullw r10,r10,r26
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r26.s32);
	// beq cr6,0x82a83104
	if (ctx.cr6.eq) goto loc_82A83104;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82a83140
	if (!ctx.cr6.eq) goto loc_82A83140;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a83140
	if (ctx.cr6.eq) goto loc_82A83140;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// subf r9,r6,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r6.s64;
loc_82A830E8:
	// lfsx f0,r9,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	ctx.f0.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a830e8
	if (!ctx.cr0.eq) goto loc_82A830E8;
	// b 0x82a83140
	goto loc_82A83140;
loc_82A83104:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a83140
	if (ctx.cr6.eq) goto loc_82A83140;
	// lis r9,-32230
	ctx.r9.s64 = -2112225280;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// subf r8,r6,r5
	ctx.r8.s64 = ctx.r5.s64 - ctx.r6.s64;
	// lfs f0,21348(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 21348);
	ctx.f0.f64 = double(temp.f32);
loc_82A8311C:
	// lfsx f13,r11,r8
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	ctx.f13.f64 = double(temp.f32);
	// li r9,1
	ctx.r9.s64 = 1;
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bne cr6,0x82a83130
	if (!ctx.cr6.eq) goto loc_82A83130;
	// li r9,0
	ctx.r9.s64 = 0;
loc_82A83130:
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82a8311c
	if (!ctx.cr0.eq) goto loc_82A8311C;
loc_82A83140:
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
loc_82A83144:
	// lhz r9,8(r24)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r24.u32 + 8);
	// cmplwi r9,0
	ctx.cr0.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq 0x82a83248
	if (ctx.cr0.eq) goto loc_82A83248;
	// lhz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 0);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82a83168
	if (ctx.cr6.eq) goto loc_82A83168;
	// lhz r11,6(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// lhz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// b 0x82a83170
	goto loc_82A83170;
loc_82A83168:
	// lhz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
loc_82A83170:
	// clrlwi. r8,r11,30
	ctx.r8.u64 = ctx.r11.u32 & 0x3;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a83248
	if (ctx.cr0.eq) goto loc_82A83248;
	// cmplwi cr6,r9,1
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 1, ctx.xer);
	// bne cr6,0x82a8318c
	if (!ctx.cr6.eq) goto loc_82A8318C;
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// addi r27,r9,-21196
	ctx.r27.s64 = ctx.r9.s64 + -21196;
	// b 0x82a83194
	goto loc_82A83194;
loc_82A8318C:
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r27,r9,-17092
	ctx.r27.s64 = ctx.r9.s64 + -17092;
loc_82A83194:
	// mullw. r8,r10,r26
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r26.s32);
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// beq 0x82a83244
	if (ctx.cr0.eq) goto loc_82A83244;
	// mullw r7,r8,r10
	ctx.r7.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r10.s32);
	// add r7,r7,r11
	ctx.r7.u64 = ctx.r7.u64 + ctx.r11.u64;
	// addi r9,r8,1
	ctx.r9.s64 = ctx.r8.s64 + 1;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r7,r6
	ctx.r4.u64 = ctx.r7.u64 + ctx.r6.u64;
	// mullw r7,r9,r11
	ctx.r7.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r11.s32);
	// mullw r9,r9,r10
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// add r7,r7,r5
	ctx.r7.u64 = ctx.r7.u64 + ctx.r5.u64;
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r3,r10,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r5,r9,r6
	ctx.r5.u64 = ctx.r9.u64 + ctx.r6.u64;
loc_82A831D4:
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// subf r4,r3,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r3.s64;
	// subf r5,r3,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r3.s64;
	// subf r7,r30,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r30.s64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a83210
	if (!ctx.cr6.gt) goto loc_82A83210;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
loc_82A831F4:
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// addi r31,r31,-4
	ctx.r31.s64 = ctx.r31.s64 + -4;
	// rlwinm r29,r9,2,28,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xC;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// lwzx r29,r29,r27
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r27.u32);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// bgt cr6,0x82a831f4
	if (ctx.cr6.gt) goto loc_82A831F4;
loc_82A83210:
	// mr r28,r11
	ctx.r28.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a8323c
	if (ctx.cr6.eq) goto loc_82A8323C;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
loc_82A83224:
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r31,r31,-4
	ctx.r31.s64 = ctx.r31.s64 + -4;
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// lwz r29,0(r9)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// bne 0x82a83224
	if (!ctx.cr0.eq) goto loc_82A83224;
loc_82A8323C:
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82a831d4
	if (!ctx.cr6.eq) goto loc_82A831D4;
loc_82A83244:
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
loc_82A83248:
	// lwz r10,44(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 44);
	// lhz r11,12(r24)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r24.u32 + 12);
	// mullw r7,r10,r26
	ctx.r7.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r26.s32);
	// cmplw cr6,r7,r11
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a83260
	if (!ctx.cr6.gt) goto loc_82A83260;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
loc_82A83260:
	// lwz r10,28(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 28);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne 0x82a83278
	if (!ctx.cr0.eq) goto loc_82A83278;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82a83298
	goto loc_82A83298;
loc_82A83278:
	// lhz r11,10(r24)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r24.u32 + 10);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// add r4,r11,r22
	ctx.r4.u64 = ctx.r11.u64 + ctx.r22.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82A8328C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a83298
	if (ctx.cr0.lt) goto loc_82A83298;
loc_82A83294:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A83298:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82d5c500
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A832A0"))) PPC_WEAK_FUNC(sub_82A832A0);
PPC_FUNC_IMPL(__imp__sub_82A832A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4ac
	ctx.lr = 0x82A832A8;
	__savegprlr_21(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// mr r22,r4
	ctx.r22.u64 = ctx.r4.u64;
	// mr r21,r7
	ctx.r21.u64 = ctx.r7.u64;
	// lwz r25,24(r23)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r23.u32 + 24);
	// lwz r6,32(r23)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r23.u32 + 32);
	// lhz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 0);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// blt cr6,0x82a835b8
	if (ctx.cr6.lt) goto loc_82A835B8;
	// beq cr6,0x82a8352c
	if (ctx.cr6.eq) goto loc_82A8352C;
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// blt cr6,0x82a83484
	if (ctx.cr6.lt) goto loc_82A83484;
	// beq cr6,0x82a833d4
	if (ctx.cr6.eq) goto loc_82A833D4;
	// cmplwi cr6,r10,5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 5, ctx.xer);
	// beq cr6,0x82a832f4
	if (ctx.cr6.eq) goto loc_82A832F4;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16385
	ctx.r3.u64 = ctx.r3.u64 | 16385;
	// b 0x82a837e8
	goto loc_82A837E8;
loc_82A832F4:
	// lwz r10,52(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 52);
	// rlwinm r9,r11,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// lhz r11,8(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// divwu r27,r9,r10
	ctx.r27.u32 = ctx.r9.u32 / ctx.r10.u32;
	// twllei r10,0
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a83314
	if (!ctx.cr6.gt) goto loc_82A83314;
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
loc_82A83314:
	// mullw. r8,r10,r27
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r27.s32);
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// beq 0x82a83358
	if (ctx.cr0.eq) goto loc_82A83358;
loc_82A83324:
	// rlwinm r9,r11,30,2,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x3FFFFFFF;
	// rlwinm r7,r11,2,28,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xC;
	// clrlwi r4,r9,30
	ctx.r4.u64 = ctx.r9.u32 & 0x3;
	// rlwinm r9,r9,0,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFC;
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r11,r8
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r8.u32, ctx.xer);
	// lwzx r9,r9,r5
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	// lwzx r9,r7,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r9.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// blt cr6,0x82a83324
	if (ctx.cr6.lt) goto loc_82A83324;
loc_82A83358:
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// li r26,0
	ctx.r26.s64 = 0;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a837e4
	if (ctx.cr6.eq) goto loc_82A837E4;
loc_82A83368:
	// lhz r11,10(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 10);
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a833c4
	if (ctx.cr0.eq) goto loc_82A833C4;
	// li r30,0
	ctx.r30.s64 = 0;
loc_82A8337C:
	// lwz r11,56(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 56);
	// mr r7,r21
	ctx.r7.u64 = ctx.r21.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// lwzx r31,r30,r11
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r11.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r6,48(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// bl 0x82a818d0
	ctx.lr = 0x82A8339C;
	sub_82A818D0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a837e8
	if (ctx.cr0.lt) goto loc_82A837E8;
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// lhz r10,10(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 10);
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r28,r10
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r10.u32, ctx.xer);
	// add r29,r11,r29
	ctx.r29.u64 = ctx.r11.u64 + ctx.r29.u64;
	// blt cr6,0x82a8337c
	if (ctx.cr6.lt) goto loc_82A8337C;
loc_82A833C4:
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// cmplw cr6,r26,r27
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r27.u32, ctx.xer);
	// blt cr6,0x82a83368
	if (ctx.cr6.lt) goto loc_82A83368;
	// b 0x82a837e4
	goto loc_82A837E4;
loc_82A833D4:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// mr r24,r11
	ctx.r24.u64 = ctx.r11.u64;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a833e8
	if (!ctx.cr6.gt) goto loc_82A833E8;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
loc_82A833E8:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82a83610
	if (ctx.cr6.eq) goto loc_82A83610;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
loc_82A833FC:
	// lhz r11,6(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a83474
	if (ctx.cr0.eq) goto loc_82A83474;
	// lhz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// li r9,0
	ctx.r9.s64 = 0;
loc_82A83414:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a83460
	if (ctx.cr6.eq) goto loc_82A83460;
loc_82A83420:
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// bgt cr6,0x82a83444
	if (ctx.cr6.gt) goto loc_82A83444;
	// cmplwi cr6,r9,16
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 16, ctx.xer);
	// bgt cr6,0x82a83444
	if (ctx.cr6.gt) goto loc_82A83444;
	// add r10,r9,r11
	ctx.r10.u64 = ctx.r9.u64 + ctx.r11.u64;
	// lwz r5,0(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// b 0x82a83448
	goto loc_82A83448;
loc_82A83444:
	// li r10,0
	ctx.r10.s64 = 0;
loc_82A83448:
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lhz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a83420
	if (ctx.cr6.lt) goto loc_82A83420;
loc_82A83460:
	// lhz r11,6(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r8,r11
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a83414
	if (ctx.cr6.lt) goto loc_82A83414;
loc_82A83474:
	// addic. r3,r3,-1
	ctx.xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// bne 0x82a833fc
	if (!ctx.cr0.eq) goto loc_82A833FC;
	// b 0x82a83610
	goto loc_82A83610;
loc_82A83484:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// mr r24,r11
	ctx.r24.u64 = ctx.r11.u64;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a83498
	if (!ctx.cr6.gt) goto loc_82A83498;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
loc_82A83498:
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82a83610
	if (ctx.cr6.eq) goto loc_82A83610;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
loc_82A834AC:
	// lhz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a8351c
	if (ctx.cr0.eq) goto loc_82A8351C;
	// lhz r11,6(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
loc_82A834C0:
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a8350c
	if (ctx.cr6.eq) goto loc_82A8350C;
	// rlwinm r9,r7,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
loc_82A834D0:
	// cmplwi cr6,r7,4
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 4, ctx.xer);
	// bgt cr6,0x82a834ec
	if (ctx.cr6.gt) goto loc_82A834EC;
	// cmplwi cr6,r10,4
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 4, ctx.xer);
	// bgt cr6,0x82a834ec
	if (ctx.cr6.gt) goto loc_82A834EC;
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwzx r11,r9,r11
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// b 0x82a834f0
	goto loc_82A834F0;
loc_82A834EC:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82A834F0:
	// stw r11,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r11.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lhz r11,6(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// addi r9,r9,16
	ctx.r9.s64 = ctx.r9.s64 + 16;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a834d0
	if (ctx.cr6.lt) goto loc_82A834D0;
loc_82A8350C:
	// lhz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// cmplw cr6,r7,r10
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a834c0
	if (ctx.cr6.lt) goto loc_82A834C0;
loc_82A8351C:
	// addic. r3,r3,-1
	ctx.xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// bne 0x82a834ac
	if (!ctx.cr0.eq) goto loc_82A834AC;
	// b 0x82a83610
	goto loc_82A83610;
loc_82A8352C:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// rlwinm r24,r11,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r24,r10
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a83540
	if (!ctx.cr6.gt) goto loc_82A83540;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
loc_82A83540:
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82a83610
	if (ctx.cr6.eq) goto loc_82A83610;
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
loc_82A83554:
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a835a8
	if (ctx.cr6.eq) goto loc_82A835A8;
	// li r11,0
	ctx.r11.s64 = 0;
loc_82A83564:
	// cmplwi cr6,r9,4
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 4, ctx.xer);
	// ble cr6,0x82a83574
	if (!ctx.cr6.gt) goto loc_82A83574;
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x82a8358c
	goto loc_82A8358C;
loc_82A83574:
	// rlwinm r4,r7,0,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFC;
	// clrlwi r10,r7,30
	ctx.r10.u64 = ctx.r7.u32 & 0x3;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwzx r4,r4,r5
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r5.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r4,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r10.u32);
loc_82A8358C:
	// stw r10,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a83564
	if (ctx.cr6.lt) goto loc_82A83564;
loc_82A835A8:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// cmplw cr6,r7,r24
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r24.u32, ctx.xer);
	// blt cr6,0x82a83554
	if (ctx.cr6.lt) goto loc_82A83554;
	// b 0x82a83610
	goto loc_82A83610;
loc_82A835B8:
	// lhz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 8);
	// rlwinm r24,r11,4,0,27
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// cmplw cr6,r24,r10
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82a835cc
	if (!ctx.cr6.gt) goto loc_82A835CC;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
loc_82A835CC:
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82a83610
	if (ctx.cr6.eq) goto loc_82A83610;
loc_82A835DC:
	// rlwinm r9,r11,30,2,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x3FFFFFFF;
	// rlwinm r8,r11,2,28,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xC;
	// clrlwi r7,r9,30
	ctx.r7.u64 = ctx.r9.u32 & 0x3;
	// rlwinm r9,r9,0,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFC;
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r11,r24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r24.u32, ctx.xer);
	// lwzx r9,r9,r5
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	// lwzx r9,r8,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// blt cr6,0x82a835dc
	if (ctx.cr6.lt) goto loc_82A835DC;
loc_82A83610:
	// lhz r10,2(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 2);
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// beq cr6,0x82a83694
	if (ctx.cr6.eq) goto loc_82A83694;
	// lwz r11,52(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 52);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// mullw r11,r11,r24
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r24.s32);
	// beq cr6,0x82a8365c
	if (ctx.cr6.eq) goto loc_82A8365C;
	// cmpwi cr6,r10,2
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 2, ctx.xer);
	// bne cr6,0x82a83694
	if (!ctx.cr6.eq) goto loc_82A83694;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a83694
	if (ctx.cr6.eq) goto loc_82A83694;
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
loc_82A83640:
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, ctx.f0.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82a83640
	if (!ctx.cr0.eq) goto loc_82A83640;
	// b 0x82a83694
	goto loc_82A83694;
loc_82A8365C:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a83694
	if (ctx.cr6.eq) goto loc_82A83694;
	// lis r9,-32230
	ctx.r9.s64 = -2112225280;
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// lfs f0,21348(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 21348);
	ctx.f0.f64 = double(temp.f32);
loc_82A83670:
	// lfs f13,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// li r9,1
	ctx.r9.s64 = 1;
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bne cr6,0x82a83684
	if (!ctx.cr6.eq) goto loc_82A83684;
	// li r9,0
	ctx.r9.s64 = 0;
loc_82A83684:
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82a83670
	if (!ctx.cr0.eq) goto loc_82A83670;
loc_82A83694:
	// lhz r9,8(r23)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r23.u32 + 8);
	// cmplwi r9,0
	ctx.cr0.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq 0x82a83794
	if (ctx.cr0.eq) goto loc_82A83794;
	// lhz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 0);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82a836b8
	if (ctx.cr6.eq) goto loc_82A836B8;
	// lhz r11,6(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
	// lhz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// b 0x82a836c0
	goto loc_82A836C0;
loc_82A836B8:
	// lhz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// lhz r10,6(r25)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r25.u32 + 6);
loc_82A836C0:
	// clrlwi. r8,r11,30
	ctx.r8.u64 = ctx.r11.u32 & 0x3;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82a83794
	if (ctx.cr0.eq) goto loc_82A83794;
	// cmplwi cr6,r9,1
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 1, ctx.xer);
	// bne cr6,0x82a836dc
	if (!ctx.cr6.eq) goto loc_82A836DC;
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// addi r26,r9,-21196
	ctx.r26.s64 = ctx.r9.s64 + -21196;
	// b 0x82a836e4
	goto loc_82A836E4;
loc_82A836DC:
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r26,r9,-17092
	ctx.r26.s64 = ctx.r9.s64 + -17092;
loc_82A836E4:
	// mullw. r9,r10,r24
	ctx.r9.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r24.s32);
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// beq 0x82a83794
	if (ctx.cr0.eq) goto loc_82A83794;
	// mullw r7,r9,r10
	ctx.r7.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// add r7,r7,r11
	ctx.r7.u64 = ctx.r7.u64 + ctx.r11.u64;
	// addi r8,r9,1
	ctx.r8.s64 = ctx.r9.s64 + 1;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r7,r6
	ctx.r4.u64 = ctx.r7.u64 + ctx.r6.u64;
	// mullw r7,r11,r8
	ctx.r7.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r8.s32);
	// mullw r8,r10,r8
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r8.s32);
	// rlwinm r27,r11,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r31,r10,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r7,r6
	ctx.r7.u64 = ctx.r7.u64 + ctx.r6.u64;
	// add r3,r8,r6
	ctx.r3.u64 = ctx.r8.u64 + ctx.r6.u64;
loc_82A83724:
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// subf r4,r31,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r31.s64;
	// subf r3,r31,r3
	ctx.r3.s64 = ctx.r3.s64 - ctx.r31.s64;
	// subf r7,r27,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r27.s64;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a83760
	if (!ctx.cr6.gt) goto loc_82A83760;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
loc_82A83744:
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
	// rlwinm r5,r8,2,28,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xC;
	// cmplw cr6,r8,r11
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r11.u32, ctx.xer);
	// lwzx r5,r5,r26
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r26.u32);
	// stw r5,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r5.u32);
	// bgt cr6,0x82a83744
	if (ctx.cr6.gt) goto loc_82A83744;
loc_82A83760:
	// mr r28,r11
	ctx.r28.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a8378c
	if (ctx.cr6.eq) goto loc_82A8378C;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r8,r7
	ctx.r8.u64 = ctx.r7.u64;
loc_82A83774:
	// addi r8,r8,-4
	ctx.r8.s64 = ctx.r8.s64 + -4;
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// lwz r5,0(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// stw r5,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r5.u32);
	// bne 0x82a83774
	if (!ctx.cr0.eq) goto loc_82A83774;
loc_82A8378C:
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82a83724
	if (!ctx.cr6.eq) goto loc_82A83724;
loc_82A83794:
	// lwz r10,44(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 44);
	// lhz r11,12(r23)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r23.u32 + 12);
	// mullw r7,r10,r24
	ctx.r7.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r24.s32);
	// cmplw cr6,r7,r11
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82a837ac
	if (!ctx.cr6.gt) goto loc_82A837AC;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
loc_82A837AC:
	// lwz r10,28(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 28);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne 0x82a837c4
	if (!ctx.cr0.eq) goto loc_82A837C4;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82a837e8
	goto loc_82A837E8;
loc_82A837C4:
	// lhz r11,10(r23)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r23.u32 + 10);
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// add r4,r11,r21
	ctx.r4.u64 = ctx.r11.u64 + ctx.r21.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82A837DC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a837e8
	if (ctx.cr0.lt) goto loc_82A837E8;
loc_82A837E4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A837E8:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82d5c4fc
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A837F0"))) PPC_WEAK_FUNC(sub_82A837F0);
PPC_FUNC_IMPL(__imp__sub_82A837F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82a80408
	ctx.lr = 0x82A83810;
	sub_82A80408(ctx, base);
	// clrlwi. r11,r30,31
	ctx.r11.u64 = ctx.r30.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a83824
	if (ctx.cr0.eq) goto loc_82A83824;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A83824;
	sub_8247F398(ctx, base);
loc_82A83824:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A83840"))) PPC_WEAK_FUNC(sub_82A83840);
PPC_FUNC_IMPL(__imp__sub_82A83840) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A83848;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r11,r11,-21176
	ctx.r11.s64 = ctx.r11.s64 + -21176;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// beq cr6,0x82a838c0
	if (ctx.cr6.eq) goto loc_82A838C0;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x82a838b4
	if (!ctx.cr6.gt) goto loc_82A838B4;
	// li r30,0
	ctx.r30.s64 = 0;
loc_82A8387C:
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwzx r29,r11,r30
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// cmplwi r29,0
	ctx.cr0.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq 0x82a838a0
	if (ctx.cr0.eq) goto loc_82A838A0;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82a80408
	ctx.lr = 0x82A83894;
	sub_82A80408(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A838A0;
	sub_8247F398(ctx, base);
loc_82A838A0:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplw cr6,r28,r11
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a8387c
	if (ctx.cr6.lt) goto loc_82A8387C;
loc_82A838B4:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// bl 0x8247f398
	ctx.lr = 0x82A838C0;
	sub_8247F398(ctx, base);
loc_82A838C0:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// bl 0x8247f398
	ctx.lr = 0x82A838CC;
	sub_8247F398(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// bl 0x8247f398
	ctx.lr = 0x82A838D8;
	sub_8247F398(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A838E0"))) PPC_WEAK_FUNC(sub_82A838E0);
PPC_FUNC_IMPL(__imp__sub_82A838E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A838E8;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// not r31,r5
	ctx.r31.u64 = ~ctx.r5.u64;
	// rlwinm r28,r7,30,2,31
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 30) & 0x3FFFFFFF;
	// b 0x82a8390c
	goto loc_82A8390C;
loc_82A83900:
	// lwz r31,36(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a83930
	if (ctx.cr0.eq) goto loc_82A83930;
loc_82A8390C:
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a80e10
	ctx.lr = 0x82A83924;
	sub_82A80E10(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a83900
	if (!ctx.cr0.lt) goto loc_82A83900;
	// b 0x82a83934
	goto loc_82A83934;
loc_82A83930:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A83934:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A83940"))) PPC_WEAK_FUNC(sub_82A83940);
PPC_FUNC_IMPL(__imp__sub_82A83940) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// stw r6,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r6.u32);
	// not r31,r5
	ctx.r31.u64 = ~ctx.r5.u64;
	// b 0x82a83970
	goto loc_82A83970;
loc_82A83964:
	// lwz r31,36(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a83994
	if (ctx.cr0.eq) goto loc_82A83994;
loc_82A83970:
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,156
	ctx.r5.s64 = ctx.r1.s64 + 156;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a81140
	ctx.lr = 0x82A83988;
	sub_82A81140(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a83964
	if (!ctx.cr0.lt) goto loc_82A83964;
	// b 0x82a83998
	goto loc_82A83998;
loc_82A83994:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A83998:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A839B0"))) PPC_WEAK_FUNC(sub_82A839B0);
PPC_FUNC_IMPL(__imp__sub_82A839B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A839B8;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// not r31,r5
	ctx.r31.u64 = ~ctx.r5.u64;
	// b 0x82a839dc
	goto loc_82A839DC;
loc_82A839D0:
	// lwz r31,36(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a83a00
	if (ctx.cr0.eq) goto loc_82A83A00;
loc_82A839DC:
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a81140
	ctx.lr = 0x82A839F4;
	sub_82A81140(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a839d0
	if (!ctx.cr0.lt) goto loc_82A839D0;
	// b 0x82a83a04
	goto loc_82A83A04;
loc_82A83A00:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A83A04:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A83A10"))) PPC_WEAK_FUNC(sub_82A83A10);
PPC_FUNC_IMPL(__imp__sub_82A83A10) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// stw r6,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r6.u32);
	// not r31,r5
	ctx.r31.u64 = ~ctx.r5.u64;
	// b 0x82a83a40
	goto loc_82A83A40;
loc_82A83A34:
	// lwz r31,36(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a83a64
	if (ctx.cr0.eq) goto loc_82A83A64;
loc_82A83A40:
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,156
	ctx.r5.s64 = ctx.r1.s64 + 156;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a81510
	ctx.lr = 0x82A83A58;
	sub_82A81510(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a83a34
	if (!ctx.cr0.lt) goto loc_82A83A34;
	// b 0x82a83a68
	goto loc_82A83A68;
loc_82A83A64:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A83A68:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A83A80"))) PPC_WEAK_FUNC(sub_82A83A80);
PPC_FUNC_IMPL(__imp__sub_82A83A80) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A83A88;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// not r31,r5
	ctx.r31.u64 = ~ctx.r5.u64;
	// b 0x82a83aac
	goto loc_82A83AAC;
loc_82A83AA0:
	// lwz r31,36(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a83ad0
	if (ctx.cr0.eq) goto loc_82A83AD0;
loc_82A83AAC:
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a81510
	ctx.lr = 0x82A83AC4;
	sub_82A81510(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a83aa0
	if (!ctx.cr0.lt) goto loc_82A83AA0;
	// b 0x82a83ad4
	goto loc_82A83AD4;
loc_82A83AD0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A83AD4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A83AE0"))) PPC_WEAK_FUNC(sub_82A83AE0);
PPC_FUNC_IMPL(__imp__sub_82A83AE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// stfs f1,156(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// not r31,r5
	ctx.r31.u64 = ~ctx.r5.u64;
	// b 0x82a83b10
	goto loc_82A83B10;
loc_82A83B04:
	// lwz r31,36(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a83b34
	if (ctx.cr0.eq) goto loc_82A83B34;
loc_82A83B10:
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,156
	ctx.r5.s64 = ctx.r1.s64 + 156;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a818d0
	ctx.lr = 0x82A83B28;
	sub_82A818D0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a83b04
	if (!ctx.cr0.lt) goto loc_82A83B04;
	// b 0x82a83b38
	goto loc_82A83B38;
loc_82A83B34:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A83B38:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A83B50"))) PPC_WEAK_FUNC(sub_82A83B50);
PPC_FUNC_IMPL(__imp__sub_82A83B50) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A83B58;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// not r31,r5
	ctx.r31.u64 = ~ctx.r5.u64;
	// b 0x82a83b7c
	goto loc_82A83B7C;
loc_82A83B70:
	// lwz r31,36(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a83ba0
	if (ctx.cr0.eq) goto loc_82A83BA0;
loc_82A83B7C:
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a818d0
	ctx.lr = 0x82A83B94;
	sub_82A818D0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a83b70
	if (!ctx.cr0.lt) goto loc_82A83B70;
	// b 0x82a83ba4
	goto loc_82A83BA4;
loc_82A83BA0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A83BA4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A83BB0"))) PPC_WEAK_FUNC(sub_82A83BB0);
PPC_FUNC_IMPL(__imp__sub_82A83BB0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A83BB8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// not r31,r5
	ctx.r31.u64 = ~ctx.r5.u64;
	// b 0x82a83bd8
	goto loc_82A83BD8;
loc_82A83BCC:
	// lwz r31,36(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a83bfc
	if (ctx.cr0.eq) goto loc_82A83BFC;
loc_82A83BD8:
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a81c90
	ctx.lr = 0x82A83BF0;
	sub_82A81C90(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a83bcc
	if (!ctx.cr0.lt) goto loc_82A83BCC;
	// b 0x82a83c00
	goto loc_82A83C00;
loc_82A83BFC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A83C00:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A83C08"))) PPC_WEAK_FUNC(sub_82A83C08);
PPC_FUNC_IMPL(__imp__sub_82A83C08) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A83C10;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// not r31,r5
	ctx.r31.u64 = ~ctx.r5.u64;
	// b 0x82a83c34
	goto loc_82A83C34;
loc_82A83C28:
	// lwz r31,36(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a83c58
	if (ctx.cr0.eq) goto loc_82A83C58;
loc_82A83C34:
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a81c90
	ctx.lr = 0x82A83C4C;
	sub_82A81C90(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a83c28
	if (!ctx.cr0.lt) goto loc_82A83C28;
	// b 0x82a83c5c
	goto loc_82A83C5C;
loc_82A83C58:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A83C5C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A83C68"))) PPC_WEAK_FUNC(sub_82A83C68);
PPC_FUNC_IMPL(__imp__sub_82A83C68) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A83C70;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// not r31,r5
	ctx.r31.u64 = ~ctx.r5.u64;
	// b 0x82a83c90
	goto loc_82A83C90;
loc_82A83C84:
	// lwz r31,36(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a83cb4
	if (ctx.cr0.eq) goto loc_82A83CB4;
loc_82A83C90:
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a82168
	ctx.lr = 0x82A83CA8;
	sub_82A82168(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a83c84
	if (!ctx.cr0.lt) goto loc_82A83C84;
	// b 0x82a83cb8
	goto loc_82A83CB8;
loc_82A83CB4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A83CB8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A83CC0"))) PPC_WEAK_FUNC(sub_82A83CC0);
PPC_FUNC_IMPL(__imp__sub_82A83CC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A83CC8;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// not r31,r5
	ctx.r31.u64 = ~ctx.r5.u64;
	// b 0x82a83cec
	goto loc_82A83CEC;
loc_82A83CE0:
	// lwz r31,36(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a83d10
	if (ctx.cr0.eq) goto loc_82A83D10;
loc_82A83CEC:
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a82168
	ctx.lr = 0x82A83D04;
	sub_82A82168(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a83ce0
	if (!ctx.cr0.lt) goto loc_82A83CE0;
	// b 0x82a83d14
	goto loc_82A83D14;
loc_82A83D10:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A83D14:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A83D20"))) PPC_WEAK_FUNC(sub_82A83D20);
PPC_FUNC_IMPL(__imp__sub_82A83D20) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A83D28;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// not r31,r5
	ctx.r31.u64 = ~ctx.r5.u64;
	// b 0x82a83d4c
	goto loc_82A83D4C;
loc_82A83D40:
	// lwz r31,36(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a83d70
	if (ctx.cr0.eq) goto loc_82A83D70;
loc_82A83D4C:
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a82720
	ctx.lr = 0x82A83D64;
	sub_82A82720(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a83d40
	if (!ctx.cr0.lt) goto loc_82A83D40;
	// b 0x82a83d74
	goto loc_82A83D74;
loc_82A83D70:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A83D74:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A83D80"))) PPC_WEAK_FUNC(sub_82A83D80);
PPC_FUNC_IMPL(__imp__sub_82A83D80) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A83D88;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// not r31,r5
	ctx.r31.u64 = ~ctx.r5.u64;
	// b 0x82a83da8
	goto loc_82A83DA8;
loc_82A83D9C:
	// lwz r31,36(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a83dcc
	if (ctx.cr0.eq) goto loc_82A83DCC;
loc_82A83DA8:
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a82c68
	ctx.lr = 0x82A83DC0;
	sub_82A82C68(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a83d9c
	if (!ctx.cr0.lt) goto loc_82A83D9C;
	// b 0x82a83dd0
	goto loc_82A83DD0;
loc_82A83DCC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A83DD0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A83DD8"))) PPC_WEAK_FUNC(sub_82A83DD8);
PPC_FUNC_IMPL(__imp__sub_82A83DD8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A83DE0;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// not r31,r5
	ctx.r31.u64 = ~ctx.r5.u64;
	// b 0x82a83e04
	goto loc_82A83E04;
loc_82A83DF8:
	// lwz r31,36(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a83e28
	if (ctx.cr0.eq) goto loc_82A83E28;
loc_82A83E04:
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a82c68
	ctx.lr = 0x82A83E1C;
	sub_82A82C68(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a83df8
	if (!ctx.cr0.lt) goto loc_82A83DF8;
	// b 0x82a83e2c
	goto loc_82A83E2C;
loc_82A83E28:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A83E2C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A83E38"))) PPC_WEAK_FUNC(sub_82A83E38);
PPC_FUNC_IMPL(__imp__sub_82A83E38) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A83E40;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// not r31,r5
	ctx.r31.u64 = ~ctx.r5.u64;
	// b 0x82a83e64
	goto loc_82A83E64;
loc_82A83E58:
	// lwz r31,36(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82a83e88
	if (ctx.cr0.eq) goto loc_82A83E88;
loc_82A83E64:
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a832a0
	ctx.lr = 0x82A83E7C;
	sub_82A832A0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a83e58
	if (!ctx.cr0.lt) goto loc_82A83E58;
	// b 0x82a83e8c
	goto loc_82A83E8C;
loc_82A83E88:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A83E8C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A83E98"))) PPC_WEAK_FUNC(sub_82A83E98);
PPC_FUNC_IMPL(__imp__sub_82A83E98) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c4
	ctx.lr = 0x82A83EA0;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// li r31,0
	ctx.r31.s64 = 0;
	// lhz r11,10(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 10);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,16(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// rlwinm r11,r11,0,0,15
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFF0000;
	// bne 0x82a84118
	if (!ctx.cr0.eq) goto loc_82A84118;
	// lis r10,21592
	ctx.r10.s64 = 1415053312;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a840c0
	if (ctx.cr6.eq) goto loc_82A840C0;
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a83fe4
	if (ctx.cr6.eq) goto loc_82A83FE4;
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82a84190
	if (!ctx.cr6.eq) goto loc_82A84190;
	// lhz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r29.u32 + 4);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82a83fa4
	if (ctx.cr6.lt) goto loc_82A83FA4;
	// beq cr6,0x82a83f58
	if (ctx.cr6.eq) goto loc_82A83F58;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// bge cr6,0x82a84190
	if (!ctx.cr6.lt) goto loc_82A84190;
	// lhz r11,2(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 2);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82a83f4c
	if (ctx.cr6.lt) goto loc_82A83F4C;
	// beq cr6,0x82a83f40
	if (ctx.cr6.eq) goto loc_82A83F40;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// blt cr6,0x82a83f34
	if (ctx.cr6.lt) goto loc_82A83F34;
	// bne cr6,0x82a84190
	if (!ctx.cr6.eq) goto loc_82A84190;
loc_82A83F28:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,3176
	ctx.r31.s64 = ctx.r11.s64 + 3176;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A83F34:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,3040
	ctx.r31.s64 = ctx.r11.s64 + 3040;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A83F40:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,2888
	ctx.r31.s64 = ctx.r11.s64 + 2888;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A83F4C:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,3176
	ctx.r31.s64 = ctx.r11.s64 + 3176;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A83F58:
	// lhz r11,2(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 2);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82a83f98
	if (ctx.cr6.lt) goto loc_82A83F98;
	// beq cr6,0x82a83f8c
	if (ctx.cr6.eq) goto loc_82A83F8C;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// blt cr6,0x82a83f80
	if (ctx.cr6.lt) goto loc_82A83F80;
	// bne cr6,0x82a84190
	if (!ctx.cr6.eq) goto loc_82A84190;
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,2808
	ctx.r31.s64 = ctx.r11.s64 + 2808;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A83F80:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,2680
	ctx.r31.s64 = ctx.r11.s64 + 2680;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A83F8C:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,2720
	ctx.r31.s64 = ctx.r11.s64 + 2720;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A83F98:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,2680
	ctx.r31.s64 = ctx.r11.s64 + 2680;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A83FA4:
	// lhz r11,2(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 2);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82a83fd8
	if (ctx.cr6.lt) goto loc_82A83FD8;
	// beq cr6,0x82a8414c
	if (ctx.cr6.eq) goto loc_82A8414C;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// blt cr6,0x82a83fcc
	if (ctx.cr6.lt) goto loc_82A83FCC;
	// bne cr6,0x82a84190
	if (!ctx.cr6.eq) goto loc_82A84190;
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,2576
	ctx.r31.s64 = ctx.r11.s64 + 2576;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A83FCC:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,2480
	ctx.r31.s64 = ctx.r11.s64 + 2480;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A83FD8:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,2440
	ctx.r31.s64 = ctx.r11.s64 + 2440;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A83FE4:
	// lhz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r29.u32 + 4);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82a84080
	if (ctx.cr6.lt) goto loc_82A84080;
	// beq cr6,0x82a84040
	if (ctx.cr6.eq) goto loc_82A84040;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// bge cr6,0x82a84190
	if (!ctx.cr6.lt) goto loc_82A84190;
	// lhz r11,2(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 2);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82a84034
	if (ctx.cr6.lt) goto loc_82A84034;
	// beq cr6,0x82a84028
	if (ctx.cr6.eq) goto loc_82A84028;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// blt cr6,0x82a8401c
	if (ctx.cr6.lt) goto loc_82A8401C;
	// bne cr6,0x82a84190
	if (!ctx.cr6.eq) goto loc_82A84190;
	// b 0x82a84170
	goto loc_82A84170;
loc_82A8401C:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,2304
	ctx.r31.s64 = ctx.r11.s64 + 2304;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A84028:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,2152
	ctx.r31.s64 = ctx.r11.s64 + 2152;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A84034:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,2072
	ctx.r31.s64 = ctx.r11.s64 + 2072;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A84040:
	// lhz r11,2(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 2);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82a84074
	if (ctx.cr6.lt) goto loc_82A84074;
	// beq cr6,0x82a84068
	if (ctx.cr6.eq) goto loc_82A84068;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// blt cr6,0x82a8417c
	if (ctx.cr6.lt) goto loc_82A8417C;
	// bne cr6,0x82a84190
	if (!ctx.cr6.eq) goto loc_82A84190;
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,1992
	ctx.r31.s64 = ctx.r11.s64 + 1992;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A84068:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,1904
	ctx.r31.s64 = ctx.r11.s64 + 1904;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A84074:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,1864
	ctx.r31.s64 = ctx.r11.s64 + 1864;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A84080:
	// lhz r11,2(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 2);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82a840b4
	if (ctx.cr6.lt) goto loc_82A840B4;
	// beq cr6,0x82a84188
	if (ctx.cr6.eq) goto loc_82A84188;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// blt cr6,0x82a840a8
	if (ctx.cr6.lt) goto loc_82A840A8;
	// bne cr6,0x82a84190
	if (!ctx.cr6.eq) goto loc_82A84190;
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,1760
	ctx.r31.s64 = ctx.r11.s64 + 1760;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A840A8:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,1664
	ctx.r31.s64 = ctx.r11.s64 + 1664;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A840B4:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,1624
	ctx.r31.s64 = ctx.r11.s64 + 1624;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A840C0:
	// lhz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r29.u32 + 4);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// bne cr6,0x82a84190
	if (!ctx.cr6.eq) goto loc_82A84190;
	// lhz r11,2(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 2);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82a8410c
	if (ctx.cr6.lt) goto loc_82A8410C;
	// beq cr6,0x82a84100
	if (ctx.cr6.eq) goto loc_82A84100;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// blt cr6,0x82a840f4
	if (ctx.cr6.lt) goto loc_82A840F4;
	// bne cr6,0x82a84190
	if (!ctx.cr6.eq) goto loc_82A84190;
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,3256
	ctx.r31.s64 = ctx.r11.s64 + 3256;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A840F4:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,3472
	ctx.r31.s64 = ctx.r11.s64 + 3472;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A84100:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,3328
	ctx.r31.s64 = ctx.r11.s64 + 3328;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A8410C:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,3256
	ctx.r31.s64 = ctx.r11.s64 + 3256;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A84118:
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a84158
	if (ctx.cr6.eq) goto loc_82A84158;
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82a84190
	if (!ctx.cr6.eq) goto loc_82A84190;
	// lhz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r29.u32 + 4);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82a8414c
	if (ctx.cr6.lt) goto loc_82A8414C;
	// beq cr6,0x82a83f80
	if (ctx.cr6.eq) goto loc_82A83F80;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// bge cr6,0x82a84190
	if (!ctx.cr6.lt) goto loc_82A84190;
	// b 0x82a83f28
	goto loc_82A83F28;
loc_82A8414C:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,2440
	ctx.r31.s64 = ctx.r11.s64 + 2440;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A84158:
	// lhz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r29.u32 + 4);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82a84188
	if (ctx.cr6.lt) goto loc_82A84188;
	// beq cr6,0x82a8417c
	if (ctx.cr6.eq) goto loc_82A8417C;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// bge cr6,0x82a84190
	if (!ctx.cr6.lt) goto loc_82A84190;
loc_82A84170:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,2072
	ctx.r31.s64 = ctx.r11.s64 + 2072;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A8417C:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,1864
	ctx.r31.s64 = ctx.r11.s64 + 1864;
	// b 0x82a84190
	goto loc_82A84190;
loc_82A84188:
	// lis r11,-32088
	ctx.r11.s64 = -2102919168;
	// addi r31,r11,1624
	ctx.r31.s64 = ctx.r11.s64 + 1624;
loc_82A84190:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,68
	ctx.r3.s64 = 68;
	// bl 0x8247f370
	ctx.lr = 0x82A8419C;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a841c4
	if (ctx.cr0.eq) goto loc_82A841C4;
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82a7ff88
	ctx.lr = 0x82A841BC;
	sub_82A7FF88(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// b 0x82a841c8
	goto loc_82A841C8;
loc_82A841C4:
	// li r31,0
	ctx.r31.s64 = 0;
loc_82A841C8:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82a841f4
	if (ctx.cr6.eq) goto loc_82A841F4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a84200
	ctx.lr = 0x82A841D8;
	sub_82A84200(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bge 0x82a841f8
	if (!ctx.cr0.lt) goto loc_82A841F8;
	// bl 0x82a80408
	ctx.lr = 0x82A841E8;
	sub_82A80408(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A841F4;
	sub_8247F398(ctx, base);
loc_82A841F4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A841F8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c514
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A84200"))) PPC_WEAK_FUNC(sub_82A84200);
PPC_FUNC_IMPL(__imp__sub_82A84200) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4bc
	ctx.lr = 0x82A84208;
	__savegprlr_25(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lhz r10,10(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 10);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq 0x82a8441c
	if (ctx.cr0.eq) goto loc_82A8441C;
	// clrlwi r11,r10,16
	ctx.r11.u64 = ctx.r10.u32 & 0xFFFF;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rotlwi r3,r11,2
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r11.u32, 2);
	// bl 0x8247f370
	ctx.lr = 0x82A84230;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,56(r31)
	PPC_STORE_U32(ctx.r31.u32 + 56, ctx.r3.u32);
	// bne 0x82a84248
	if (!ctx.cr0.eq) goto loc_82A84248;
loc_82A8423C:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82a84420
	goto loc_82A84420;
loc_82A84248:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// lhz r11,10(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 10);
	// rotlwi r5,r11,2
	ctx.r5.u64 = __builtin_rotateleft32(ctx.r11.u32, 2);
	// bl 0x82d5cb60
	ctx.lr = 0x82A8425C;
	sub_82D5CB60(ctx, base);
	// lwz r25,32(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// addi r11,r31,4
	ctx.r11.s64 = ctx.r31.s64 + 4;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// li r9,5
	ctx.r9.s64 = 5;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_82A84270:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x82a84270
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82A84270;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lhz r10,10(r9)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + 10);
	// lwz r9,12(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// rotlwi r8,r10,3
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r10.u32, 3);
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// add r8,r8,r9
	ctx.r8.u64 = ctx.r8.u64 + ctx.r9.u64;
	// cmplw cr6,r8,r7
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, ctx.xer);
	// ble cr6,0x82a842b4
	if (!ctx.cr6.gt) goto loc_82A842B4;
loc_82A842A8:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82a84420
	goto loc_82A84420;
loc_82A842B4:
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// li r26,0
	ctx.r26.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// mr r27,r26
	ctx.r27.u64 = ctx.r26.u64;
	// add r29,r11,r9
	ctx.r29.u64 = ctx.r11.u64 + ctx.r9.u64;
	// beq cr6,0x82a8441c
	if (ctx.cr6.eq) goto loc_82A8441C;
	// mr r28,r26
	ctx.r28.u64 = ctx.r26.u64;
loc_82A842D0:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// addi r11,r10,16
	ctx.r11.s64 = ctx.r10.s64 + 16;
	// lwz r9,12(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bgt cr6,0x82a842a8
	if (ctx.cr6.gt) goto loc_82A842A8;
	// lwz r11,8(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r8,r1,84
	ctx.r8.s64 = ctx.r1.s64 + 84;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// stw r26,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r26.u32);
	// add r30,r11,r10
	ctx.r30.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82a7fe78
	ctx.lr = 0x82A84310;
	sub_82A7FE78(ctx, base);
	// lwz r8,0(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lhz r9,10(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 10);
	// lhz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 12);
	// lhz r11,102(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 102);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r8,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r8.u32);
	// lwz r9,4(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r9,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r9.u32);
	// lhz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r30.u32 + 8);
	// mullw r9,r9,r8
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r8.s32);
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// sth r9,104(r1)
	PPC_STORE_U16(ctx.r1.u32 + 104, ctx.r9.u16);
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + ctx.r11.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// ble cr6,0x82a84360
	if (!ctx.cr6.gt) goto loc_82A84360;
	// subf. r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge 0x82a8435c
	if (!ctx.cr0.lt) goto loc_82A8435C;
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
loc_82A8435C:
	// sth r11,104(r1)
	PPC_STORE_U16(ctx.r1.u32 + 104, ctx.r11.u16);
loc_82A84360:
	// mr r6,r25
	ctx.r6.u64 = ctx.r25.u64;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82a83e98
	ctx.lr = 0x82A84374;
	sub_82A83E98(ctx, base);
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// stwx r3,r28,r11
	PPC_STORE_U32(ctx.r28.u32 + ctx.r11.u32, ctx.r3.u32);
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// lwzx r10,r28,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r11.u32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a8423c
	if (ctx.cr6.eq) goto loc_82A8423C;
	// lhz r10,102(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 102);
	// lhz r8,104(r1)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r1.u32 + 104);
	// lhz r9,100(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + 100);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// cmplwi r9,0
	ctx.cr0.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// sth r10,102(r1)
	PPC_STORE_U16(ctx.r1.u32 + 102, ctx.r10.u16);
	// li r10,1
	ctx.r10.s64 = 1;
	// beq 0x82a843b0
	if (ctx.cr0.eq) goto loc_82A843B0;
	// li r10,4
	ctx.r10.s64 = 4;
loc_82A843B0:
	// lwzx r8,r28,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r11.u32);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// lhz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r30.u32 + 8);
	// lwz r8,44(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 44);
	// mullw r9,r8,r9
	ctx.r9.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r9.s32);
	// mullw r10,r9,r10
	ctx.r10.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// lwz r9,112(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r10.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// beq cr6,0x82a843e4
	if (ctx.cr6.eq) goto loc_82A843E4;
	// li r10,4
	ctx.r10.s64 = 4;
loc_82A843E4:
	// lwzx r11,r28,r11
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r11.u32);
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// lhz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r30.u32 + 8);
	// addi r29,r29,8
	ctx.r29.s64 = ctx.r29.s64 + 8;
	// lwz r8,24(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// addi r28,r28,4
	ctx.r28.s64 = ctx.r28.s64 + 4;
	// lwz r11,44(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// lhz r9,10(r8)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r8.u32 + 10);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r27,r9
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r9.u32, ctx.xer);
	// add r25,r11,r25
	ctx.r25.u64 = ctx.r11.u64 + ctx.r25.u64;
	// blt cr6,0x82a842d0
	if (ctx.cr6.lt) goto loc_82A842D0;
loc_82A8441C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A84420:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82d5c50c
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A84428"))) PPC_WEAK_FUNC(sub_82A84428);
PPC_FUNC_IMPL(__imp__sub_82A84428) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A84430;
	__savegprlr_29(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lhz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 8);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a84454
	if (ctx.cr6.lt) goto loc_82A84454;
loc_82A8444C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82a84650
	goto loc_82A84650;
loc_82A84454:
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// bne cr6,0x82a84464
	if (!ctx.cr6.eq) goto loc_82A84464;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// b 0x82a84650
	goto loc_82A84650;
loc_82A84464:
	// lwz r10,60(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82a8449c
	if (!ctx.cr6.eq) goto loc_82A8449C;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// bl 0x8247f370
	ctx.lr = 0x82A8447C;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r3.u32);
	// beq 0x82a8444c
	if (ctx.cr0.eq) goto loc_82A8444C;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// lhz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 8);
	// rotlwi r5,r11,2
	ctx.r5.u64 = __builtin_rotateleft32(ctx.r11.u32, 2);
	// bl 0x82d5cb60
	ctx.lr = 0x82A8449C;
	sub_82D5CB60(ctx, base);
loc_82A8449C:
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// rlwinm r29,r30,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r29,r11
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r11.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a84648
	if (!ctx.cr6.eq) goto loc_82A84648;
	// lwz r11,64(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a84504
	if (!ctx.cr6.eq) goto loc_82A84504;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,16
	ctx.r3.s64 = 16;
	// bl 0x8247f370
	ctx.lr = 0x82A844C8;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r3.u32);
	// beq 0x82a8444c
	if (ctx.cr0.eq) goto loc_82A8444C;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r11.u32);
	// lwz r11,64(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// sth r10,8(r11)
	PPC_STORE_U16(ctx.r11.u32 + 8, ctx.r10.u16);
loc_82A84504:
	// addi r11,r31,4
	ctx.r11.s64 = ctx.r31.s64 + 4;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// li r9,5
	ctx.r9.s64 = 5;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_82A84514:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x82a84514
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82A84514;
	// lwz r11,44(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// lhz r10,10(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 10);
	// mullw r9,r11,r30
	ctx.r9.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r30.s32);
	// lhz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r31.u32 + 12);
	// add r7,r9,r10
	ctx.r7.u64 = ctx.r9.u64 + ctx.r10.u64;
	// clrlwi r9,r11,16
	ctx.r9.u64 = ctx.r11.u32 & 0xFFFF;
	// mr r6,r9
	ctx.r6.u64 = ctx.r9.u64;
	// sth r9,88(r1)
	PPC_STORE_U16(ctx.r1.u32 + 88, ctx.r9.u16);
	// clrlwi r9,r7,16
	ctx.r9.u64 = ctx.r7.u32 & 0xFFFF;
	// sth r9,86(r1)
	PPC_STORE_U16(ctx.r1.u32 + 86, ctx.r9.u16);
	// subf r9,r9,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r9.s64;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmpw cr6,r6,r10
	ctx.cr6.compare<int32_t>(ctx.r6.s32, ctx.r10.s32, ctx.xer);
	// ble cr6,0x82a84570
	if (!ctx.cr6.gt) goto loc_82A84570;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge cr6,0x82a8456c
	if (!ctx.cr6.lt) goto loc_82A8456C;
	// li r10,0
	ctx.r10.s64 = 0;
loc_82A8456C:
	// sth r10,88(r1)
	PPC_STORE_U16(ctx.r1.u32 + 88, ctx.r10.u16);
loc_82A84570:
	// lhz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 8);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// li r10,1
	ctx.r10.s64 = 1;
	// beq 0x82a84584
	if (ctx.cr0.eq) goto loc_82A84584;
	// li r10,4
	ctx.r10.s64 = 4;
loc_82A84584:
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplwi r8,0
	ctx.cr0.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq 0x82a845a4
	if (ctx.cr0.eq) goto loc_82A845A4;
	// mullw r9,r11,r10
	ctx.r9.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// mullw r9,r9,r30
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r30.s32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// stw r9,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r9.u32);
loc_82A845A4:
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// mullw r11,r11,r30
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r30.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,68
	ctx.r3.s64 = 68;
	// add r30,r11,r10
	ctx.r30.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bl 0x8247f370
	ctx.lr = 0x82A845C4;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a845e8
	if (ctx.cr0.eq) goto loc_82A845E8;
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// lwz r7,28(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r6,64(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82a7ff88
	ctx.lr = 0x82A845E4;
	sub_82A7FF88(ctx, base);
	// b 0x82a845ec
	goto loc_82A845EC;
loc_82A845E8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A845EC:
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stwx r3,r29,r11
	PPC_STORE_U32(ctx.r29.u32 + ctx.r11.u32, ctx.r3.u32);
	// beq cr6,0x82a8444c
	if (ctx.cr6.eq) goto loc_82A8444C;
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// lwzx r3,r29,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r11.u32);
	// bl 0x82a84200
	ctx.lr = 0x82A84608;
	sub_82A84200(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a84648
	if (!ctx.cr0.lt) goto loc_82A84648;
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// lwzx r30,r29,r11
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r11.u32);
	// cmplwi r30,0
	ctx.cr0.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq 0x82a84634
	if (ctx.cr0.eq) goto loc_82A84634;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82a80408
	ctx.lr = 0x82A84628;
	sub_82A80408(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A84634;
	sub_8247F398(ctx, base);
loc_82A84634:
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stwx r10,r29,r11
	PPC_STORE_U32(ctx.r29.u32 + ctx.r11.u32, ctx.r10.u32);
	// b 0x82a84650
	goto loc_82A84650;
loc_82A84648:
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// lwzx r3,r29,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r11.u32);
loc_82A84650:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A84658"))) PPC_WEAK_FUNC(sub_82A84658);
PPC_FUNC_IMPL(__imp__sub_82A84658) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r9,1
	ctx.r9.s64 = 1;
	// addi r10,r11,-21176
	ctx.r10.s64 = ctx.r11.s64 + -21176;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A84688"))) PPC_WEAK_FUNC(sub_82A84688);
PPC_FUNC_IMPL(__imp__sub_82A84688) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c4
	ctx.lr = 0x82A84690;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// stw r5,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r5.u32);
	// bl 0x8247f370
	ctx.lr = 0x82A846B0;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r3.u32);
	// bne 0x82a846c8
	if (!ctx.cr0.eq) goto loc_82A846C8;
loc_82A846BC:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82a848b0
	goto loc_82A848B0;
loc_82A846C8:
	// lwz r5,12(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// clrlwi. r11,r29,24
	ctx.r11.u64 = ctx.r29.u32 & 0xFF;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a846e4
	if (ctx.cr0.eq) goto loc_82A846E4;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82a49dc8
	ctx.lr = 0x82A846E0;
	sub_82A49DC8(ctx, base);
	// b 0x82a846ec
	goto loc_82A846EC;
loc_82A846E4:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82d5c630
	ctx.lr = 0x82A846EC;
	sub_82D5C630(ctx, base);
loc_82A846EC:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,28
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 28, ctx.xer);
	// bge cr6,0x82a8470c
	if (!ctx.cr6.lt) goto loc_82A8470C;
loc_82A84700:
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2905
	ctx.r3.u64 = ctx.r3.u64 | 2905;
	// b 0x82a848b0
	goto loc_82A848B0;
loc_82A8470C:
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8247f370
	ctx.lr = 0x82A8471C;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r3.u32);
	// beq 0x82a846bc
	if (ctx.cr0.eq) goto loc_82A846BC;
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82d5cb60
	ctx.lr = 0x82A8473C;
	sub_82D5CB60(ctx, base);
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r10,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r10.u32);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mulli r11,r11,20
	ctx.r11.s64 = ctx.r11.s64 * 20;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bgt cr6,0x82a84700
	if (ctx.cr6.gt) goto loc_82A84700;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// li r27,0
	ctx.r27.s64 = 0;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// li r28,0
	ctx.r28.s64 = 0;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// ble cr6,0x82a84818
	if (!ctx.cr6.gt) goto loc_82A84818;
	// li r30,0
	ctx.r30.s64 = 0;
	// addi r29,r11,12
	ctx.r29.s64 = ctx.r11.s64 + 12;
loc_82A84788:
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r9,r10,16
	ctx.r9.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// bgt cr6,0x82a84700
	if (ctx.cr6.gt) goto loc_82A84700;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r4,r29,-12
	ctx.r4.s64 = ctx.r29.s64 + -12;
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82a83e98
	ctx.lr = 0x82A847B4;
	sub_82A83E98(ctx, base);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// stwx r3,r11,r30
	PPC_STORE_U32(ctx.r11.u32 + ctx.r30.u32, ctx.r3.u32);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwzx r10,r11,r30
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82a846bc
	if (ctx.cr6.eq) goto loc_82A846BC;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lhz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r10.u32 + 8);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// li r10,1
	ctx.r10.s64 = 1;
	// beq 0x82a847e4
	if (ctx.cr0.eq) goto loc_82A847E4;
	// li r10,4
	ctx.r10.s64 = 4;
loc_82A847E4:
	// lwzx r11,r11,r30
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// addi r29,r29,20
	ctx.r29.s64 = ctx.r29.s64 + 20;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplw cr6,r28,r9
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r9.u32, ctx.xer);
	// lwz r8,24(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r11,44(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	// lhz r9,8(r8)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r8.u32 + 8);
	// mullw r11,r9,r11
	ctx.r11.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r11.s32);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// add r27,r11,r27
	ctx.r27.u64 = ctx.r11.u64 + ctx.r27.u64;
	// blt cr6,0x82a84788
	if (ctx.cr6.lt) goto loc_82A84788;
loc_82A84818:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r27,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8247f370
	ctx.lr = 0x82A84824;
	sub_8247F370(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r3.u32);
	// beq 0x82a846bc
	if (ctx.cr0.eq) goto loc_82A846BC;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r30,0
	ctx.r30.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x82a848ac
	if (!ctx.cr6.gt) goto loc_82A848AC;
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// li r6,0
	ctx.r6.s64 = 0;
loc_82A8484C:
	// lwz r9,28(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r6,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r11.u32);
	// add r4,r10,r9
	ctx.r4.u64 = ctx.r10.u64 + ctx.r9.u64;
	// bl 0x82a80040
	ctx.lr = 0x82A84860;
	sub_82A80040(ctx, base);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// li r9,1
	ctx.r9.s64 = 1;
	// lwzx r10,r6,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r11.u32);
	// lhz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r10.u32 + 8);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq 0x82a8487c
	if (ctx.cr0.eq) goto loc_82A8487C;
	// li r9,4
	ctx.r9.s64 = 4;
loc_82A8487C:
	// lwzx r10,r6,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r11.u32);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// lwz r8,24(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r30,r8
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r8.u32, ctx.xer);
	// lwz r7,24(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwz r10,44(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 44);
	// lhz r8,8(r7)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r7.u32 + 8);
	// mullw r10,r8,r10
	ctx.r10.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r10.s32);
	// mullw r10,r10,r9
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r9.s32);
	// add r5,r10,r5
	ctx.r5.u64 = ctx.r10.u64 + ctx.r5.u64;
	// blt cr6,0x82a8484c
	if (ctx.cr6.lt) goto loc_82A8484C;
loc_82A848AC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A848B0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c514
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A848B8"))) PPC_WEAK_FUNC(sub_82A848B8);
PPC_FUNC_IMPL(__imp__sub_82A848B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// addi r30,r11,-1
	ctx.r30.s64 = ctx.r11.s64 + -1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// stw r30,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r30.u32);
	// bne cr6,0x82a848f4
	if (!ctx.cr6.eq) goto loc_82A848F4;
	// bl 0x82a83840
	ctx.lr = 0x82A848E8;
	sub_82A83840(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8247f398
	ctx.lr = 0x82A848F4;
	sub_8247F398(ctx, base);
loc_82A848F4:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A84910"))) PPC_WEAK_FUNC(sub_82A84910);
PPC_FUNC_IMPL(__imp__sub_82A84910) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// not r3,r11
	ctx.r3.u64 = ~ctx.r11.u64;
	// bl 0x82a84428
	ctx.lr = 0x82A8492C;
	sub_82A84428(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a84938
	if (ctx.cr0.eq) goto loc_82A84938;
	// not r3,r3
	ctx.r3.u64 = ~ctx.r3.u64;
loc_82A84938:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A84948"))) PPC_WEAK_FUNC(sub_82A84948);
PPC_FUNC_IMPL(__imp__sub_82A84948) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A84950;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
loc_82A8495C:
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// b 0x82a84970
	goto loc_82A84970;
loc_82A84968:
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// lbz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
loc_82A84970:
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// bl 0x82d5f970
	ctx.lr = 0x82A84978;
	sub_82D5F970(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a84968
	if (!ctx.cr0.eq) goto loc_82A84968;
	// lbz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// extsb. r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82a84b6c
	if (ctx.cr0.eq) goto loc_82A84B6C;
	// cmpwi cr6,r11,91
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 91, ctx.xer);
	// bne cr6,0x82a84a48
	if (!ctx.cr6.eq) goto loc_82A84A48;
	// addi r31,r30,1
	ctx.r31.s64 = ctx.r30.s64 + 1;
	// b 0x82a849a0
	goto loc_82A849A0;
loc_82A8499C:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
loc_82A849A0:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// bl 0x82d5f970
	ctx.lr = 0x82A849AC;
	sub_82D5F970(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a8499c
	if (!ctx.cr0.eq) goto loc_82A8499C;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// bl 0x82d5f930
	ctx.lr = 0x82A849C0;
	sub_82D5F930(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a84b74
	if (ctx.cr0.eq) goto loc_82A84B74;
	// li r30,0
	ctx.r30.s64 = 0;
	// b 0x82a849e8
	goto loc_82A849E8;
loc_82A849D0:
	// lbz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// mulli r11,r30,10
	ctx.r11.s64 = ctx.r30.s64 * 10;
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r30,r11,-48
	ctx.r30.s64 = ctx.r11.s64 + -48;
loc_82A849E8:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// bl 0x82d5f930
	ctx.lr = 0x82A849F4;
	sub_82D5F930(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a849d0
	if (!ctx.cr0.eq) goto loc_82A849D0;
	// b 0x82a84a04
	goto loc_82A84A04;
loc_82A84A00:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
loc_82A84A04:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// bl 0x82d5f970
	ctx.lr = 0x82A84A10;
	sub_82D5F970(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a84a00
	if (!ctx.cr0.eq) goto loc_82A84A00;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82a84b74
	if (!ctx.cr6.eq) goto loc_82A84B74;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82a84428
	ctx.lr = 0x82A84A30;
	sub_82A84428(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a84b74
	if (ctx.cr0.eq) goto loc_82A84B74;
	// addi r4,r31,1
	ctx.r4.s64 = ctx.r31.s64 + 1;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
loc_82A84A40:
	// li r31,0
	ctx.r31.s64 = 0;
	// b 0x82a8495c
	goto loc_82A8495C;
loc_82A84A48:
	// cmpwi cr6,r11,46
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 46, ctx.xer);
	// beq cr6,0x82a84a60
	if (ctx.cr6.eq) goto loc_82A84A60;
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// beq cr6,0x82a84b74
	if (ctx.cr6.eq) goto loc_82A84B74;
	// cmpwi cr6,r11,46
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 46, ctx.xer);
	// bne cr6,0x82a84a64
	if (!ctx.cr6.eq) goto loc_82A84A64;
loc_82A84A60:
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
loc_82A84A64:
	// lbz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// bl 0x82d5f970
	ctx.lr = 0x82A84A70;
	sub_82D5F970(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a84a60
	if (!ctx.cr0.eq) goto loc_82A84A60;
	// li r31,0
	ctx.r31.s64 = 0;
loc_82A84A7C:
	// lbzx r11,r31,r30
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + ctx.r30.u32);
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// bl 0x82d5f9b0
	ctx.lr = 0x82A84A88;
	sub_82D5F9B0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a84a9c
	if (!ctx.cr0.eq) goto loc_82A84A9C;
	// lbzx r11,r31,r30
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + ctx.r30.u32);
	// cmplwi cr6,r11,95
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 95, ctx.xer);
	// bne cr6,0x82a84aa4
	if (!ctx.cr6.eq) goto loc_82A84AA4;
loc_82A84A9C:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x82a84a7c
	goto loc_82A84A7C;
loc_82A84AA4:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82a84b74
	if (ctx.cr6.eq) goto loc_82A84B74;
	// lwz r11,24(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 24);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lhz r3,10(r11)
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r11.u32 + 10);
loc_82A84ABC:
	// cmplw cr6,r5,r3
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r3.u32, ctx.xer);
	// bge cr6,0x82a84b74
	if (!ctx.cr6.lt) goto loc_82A84B74;
	// lwz r11,56(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 56);
	// lwzx r11,r11,r4
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq 0x82a84b38
	if (ctx.cr0.eq) goto loc_82A84B38;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// add r6,r11,r10
	ctx.r6.u64 = ctx.r11.u64 + ctx.r10.u64;
	// beq cr6,0x82a84b24
	if (ctx.cr6.eq) goto loc_82A84B24;
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// subf r7,r30,r6
	ctx.r7.s64 = ctx.r6.s64 - ctx.r30.s64;
loc_82A84AF8:
	// lbzx r10,r7,r11
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r7.u32 + ctx.r11.u32);
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// extsb r8,r8
	ctx.r8.s64 = ctx.r8.s8;
	// cmpw cr6,r10,r8
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r8.s32, ctx.xer);
	// blt cr6,0x82a84b38
	if (ctx.cr6.lt) goto loc_82A84B38;
	// bgt cr6,0x82a84b38
	if (ctx.cr6.gt) goto loc_82A84B38;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r9,r31
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r31.u32, ctx.xer);
	// blt cr6,0x82a84af8
	if (ctx.cr6.lt) goto loc_82A84AF8;
loc_82A84B24:
	// cmplw cr6,r9,r31
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82a84b44
	if (!ctx.cr6.eq) goto loc_82A84B44;
	// lbzx r11,r9,r6
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r6.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a84b44
	if (ctx.cr6.eq) goto loc_82A84B44;
loc_82A84B38:
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// b 0x82a84abc
	goto loc_82A84ABC;
loc_82A84B44:
	// cmplw cr6,r5,r3
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r3.u32, ctx.xer);
	// bge cr6,0x82a84b74
	if (!ctx.cr6.lt) goto loc_82A84B74;
	// lwz r11,56(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 56);
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a84b74
	if (ctx.cr0.eq) goto loc_82A84B74;
	// add r4,r31,r30
	ctx.r4.u64 = ctx.r31.u64 + ctx.r30.u64;
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
	// b 0x82a84a40
	goto loc_82A84A40;
loc_82A84B6C:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// b 0x82a84b78
	goto loc_82A84B78;
loc_82A84B74:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A84B78:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A84B80"))) PPC_WEAK_FUNC(sub_82A84B80);
PPC_FUNC_IMPL(__imp__sub_82A84B80) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A84B88;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82a84bac
	if (!ctx.cr6.eq) goto loc_82A84BAC;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82a84c8c
	goto loc_82A84C8C;
loc_82A84BAC:
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lis r10,4138
	ctx.r10.s64 = 271187968;
	// li r9,0
	ctx.r9.s64 = 0;
	// ori r10,r10,4352
	ctx.r10.u64 = ctx.r10.u64 | 4352;
	// rlwinm r11,r11,0,0,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF00;
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// bne cr6,0x82a84c94
	if (!ctx.cr6.eq) goto loc_82A84C94;
	// lwz r11,16(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82a84cbc
	if (ctx.cr0.eq) goto loc_82A84CBC;
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// addi r30,r31,12
	ctx.r30.s64 = ctx.r31.s64 + 12;
	// addi r10,r11,4
	ctx.r10.s64 = ctx.r11.s64 + 4;
	// li r29,1
	ctx.r29.s64 = 1;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
loc_82A84BF8:
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82a84688
	ctx.lr = 0x82A84C0C;
	sub_82A84688(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a84c8c
	if (ctx.cr0.lt) goto loc_82A84C8C;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82a84c88
	if (ctx.cr6.eq) goto loc_82A84C88;
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// lwz r11,16(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// ble cr6,0x82a84c74
	if (!ctx.cr6.gt) goto loc_82A84C74;
	// rotlwi r7,r9,0
	ctx.r7.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
loc_82A84C44:
	// lhz r10,-4(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + -4);
	// cmplwi cr6,r10,2
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 2, ctx.xer);
	// bne cr6,0x82a84c68
	if (!ctx.cr6.eq) goto loc_82A84C68;
	// lhz r10,-2(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + -2);
	// lhz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r8,r10
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82a84c68
	if (!ctx.cr6.lt) goto loc_82A84C68;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82A84C68:
	// addic. r7,r7,-1
	ctx.xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// addi r11,r11,20
	ctx.r11.s64 = ctx.r11.s64 + 20;
	// bne 0x82a84c44
	if (!ctx.cr0.eq) goto loc_82A84C44;
loc_82A84C74:
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// rlwinm r3,r8,4,0,27
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x82a7fd28
	ctx.lr = 0x82A84C80;
	sub_82A7FD28(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a84c8c
	if (ctx.cr0.lt) goto loc_82A84C8C;
loc_82A84C88:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A84C8C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
loc_82A84C94:
	// addi r30,r31,12
	ctx.r30.s64 = ctx.r31.s64 + 12;
	// lis r4,16961
	ctx.r4.s64 = 1111556096;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// ori r4,r4,21571
	ctx.r4.u64 = ctx.r4.u64 | 21571;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// bl 0x82a7fd30
	ctx.lr = 0x82A84CAC;
	sub_82A7FD30(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a84c8c
	if (ctx.cr0.lt) goto loc_82A84C8C;
	// cmpwi cr6,r3,1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 1, ctx.xer);
	// bne cr6,0x82a84bf8
	if (!ctx.cr6.eq) goto loc_82A84BF8;
loc_82A84CBC:
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2905
	ctx.r3.u64 = ctx.r3.u64 | 2905;
	// b 0x82a84c8c
	goto loc_82A84C8C;
}

__attribute__((alias("__imp__sub_82A84CC8"))) PPC_WEAK_FUNC(sub_82A84CC8);
PPC_FUNC_IMPL(__imp__sub_82A84CC8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4bc
	ctx.lr = 0x82A84CD0;
	__savegprlr_25(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// b 0x82a84cf0
	goto loc_82A84CF0;
loc_82A84CE8:
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// lbz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 0);
loc_82A84CF0:
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// bl 0x82d5f970
	ctx.lr = 0x82A84CF8;
	sub_82D5F970(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a84ce8
	if (!ctx.cr0.eq) goto loc_82A84CE8;
	// lbz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// bl 0x82d5f9b0
	ctx.lr = 0x82A84D0C;
	sub_82D5F9B0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a84d38
	if (!ctx.cr0.eq) goto loc_82A84D38;
	// lbz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,95
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 95, ctx.xer);
	// beq cr6,0x82a84d38
	if (ctx.cr6.eq) goto loc_82A84D38;
	// cmpwi cr6,r11,36
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 36, ctx.xer);
	// beq cr6,0x82a84d38
	if (ctx.cr6.eq) goto loc_82A84D38;
loc_82A84D2C:
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82a84f2c
	goto loc_82A84F2C;
loc_82A84D38:
	// li r30,1
	ctx.r30.s64 = 1;
loc_82A84D3C:
	// lbzx r11,r30,r28
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + ctx.r28.u32);
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// bl 0x82d5f9b0
	ctx.lr = 0x82A84D48;
	sub_82D5F9B0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a84d5c
	if (!ctx.cr0.eq) goto loc_82A84D5C;
	// lbzx r11,r30,r28
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + ctx.r28.u32);
	// cmplwi cr6,r11,95
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 95, ctx.xer);
	// bne cr6,0x82a84d64
	if (!ctx.cr6.eq) goto loc_82A84D64;
loc_82A84D5C:
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// b 0x82a84d3c
	goto loc_82A84D3C;
loc_82A84D64:
	// lwz r11,16(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 16);
	// li r31,0
	ctx.r31.s64 = 0;
	// lwz r3,8(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r11,16(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// add r29,r11,r3
	ctx.r29.u64 = ctx.r11.u64 + ctx.r3.u64;
	// beq 0x82a84dfc
	if (ctx.cr0.eq) goto loc_82A84DFC;
loc_82A84D88:
	// add r11,r10,r6
	ctx.r11.u64 = ctx.r10.u64 + ctx.r6.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwinm r31,r11,31,1,31
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// mulli r11,r31,20
	ctx.r11.s64 = ctx.r31.s64 * 20;
	// lwzx r11,r11,r29
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r29.u32);
	// add r5,r11,r3
	ctx.r5.u64 = ctx.r11.u64 + ctx.r3.u64;
	// beq cr6,0x82a84ddc
	if (ctx.cr6.eq) goto loc_82A84DDC;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// subf r4,r28,r5
	ctx.r4.s64 = ctx.r5.s64 - ctx.r28.s64;
loc_82A84DB0:
	// lbzx r8,r4,r11
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r4.u32 + ctx.r11.u32);
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// extsb r8,r8
	ctx.r8.s64 = ctx.r8.s8;
	// extsb r7,r7
	ctx.r7.s64 = ctx.r7.s8;
	// cmpw cr6,r8,r7
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r7.s32, ctx.xer);
	// blt cr6,0x82a84f20
	if (ctx.cr6.lt) goto loc_82A84F20;
	// bgt cr6,0x82a84df0
	if (ctx.cr6.gt) goto loc_82A84DF0;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r9,r30
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r30.u32, ctx.xer);
	// blt cr6,0x82a84db0
	if (ctx.cr6.lt) goto loc_82A84DB0;
loc_82A84DDC:
	// cmplw cr6,r9,r30
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r30.u32, ctx.xer);
	// bne cr6,0x82a84dfc
	if (!ctx.cr6.eq) goto loc_82A84DFC;
	// lbzx r11,r9,r5
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r5.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82a84dfc
	if (ctx.cr6.eq) goto loc_82A84DFC;
loc_82A84DF0:
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
loc_82A84DF4:
	// cmplw cr6,r6,r10
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82a84d88
	if (ctx.cr6.lt) goto loc_82A84D88;
loc_82A84DFC:
	// cmplw cr6,r6,r10
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a84d2c
	if (ctx.cr6.eq) goto loc_82A84D2C;
	// mulli r11,r31,20
	ctx.r11.s64 = ctx.r31.s64 * 20;
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r27,r10,r3
	ctx.r27.u64 = ctx.r10.u64 + ctx.r3.u64;
	// beq cr6,0x82a84e6c
	if (ctx.cr6.eq) goto loc_82A84E6C;
	// addi r7,r11,-20
	ctx.r7.s64 = ctx.r11.s64 + -20;
loc_82A84E20:
	// lwz r11,0(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// add r10,r11,r3
	ctx.r10.u64 = ctx.r11.u64 + ctx.r3.u64;
	// cmplw cr6,r27,r10
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82a84e60
	if (ctx.cr6.eq) goto loc_82A84E60;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
loc_82A84E34:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a84e58
	if (ctx.cr0.eq) goto loc_82A84E58;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a84e34
	if (ctx.cr6.eq) goto loc_82A84E34;
loc_82A84E58:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a84e6c
	if (!ctx.cr0.eq) goto loc_82A84E6C;
loc_82A84E60:
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// addi r7,r7,-20
	ctx.r7.s64 = ctx.r7.s64 + -20;
	// bne 0x82a84e20
	if (!ctx.cr0.eq) goto loc_82A84E20;
loc_82A84E6C:
	// add r28,r30,r28
	ctx.r28.u64 = ctx.r30.u64 + ctx.r28.u64;
	// lwz r11,20(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 20);
	// rlwinm r30,r31,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwzx r3,r30,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r11.u32);
	// bl 0x82a84948
	ctx.lr = 0x82A84E88;
	sub_82A84948(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82a84d2c
	if (ctx.cr0.eq) goto loc_82A84D2C;
	// mulli r11,r31,20
	ctx.r11.s64 = ctx.r31.s64 * 20;
	// add r29,r11,r29
	ctx.r29.u64 = ctx.r11.u64 + ctx.r29.u64;
loc_82A84E98:
	// stw r3,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r3.u32);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// lwz r11,16(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 16);
	// addi r29,r29,20
	ctx.r29.s64 = ctx.r29.s64 + 20;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// addi r25,r3,36
	ctx.r25.s64 = ctx.r3.s64 + 36;
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82a84f28
	if (!ctx.cr6.lt) goto loc_82A84F28;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lwz r10,8(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82a84f00
	if (ctx.cr6.eq) goto loc_82A84F00;
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
loc_82A84ED4:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82a84ef8
	if (ctx.cr0.eq) goto loc_82A84EF8;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82a84ed4
	if (ctx.cr6.eq) goto loc_82A84ED4;
loc_82A84EF8:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82a84f28
	if (!ctx.cr0.eq) goto loc_82A84F28;
loc_82A84F00:
	// lwz r11,20(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 20);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwzx r3,r30,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r11.u32);
	// bl 0x82a84948
	ctx.lr = 0x82A84F14;
	sub_82A84948(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne 0x82a84e98
	if (!ctx.cr0.eq) goto loc_82A84E98;
	// b 0x82a84d2c
	goto loc_82A84D2C;
loc_82A84F20:
	// addi r6,r31,1
	ctx.r6.s64 = ctx.r31.s64 + 1;
	// b 0x82a84df4
	goto loc_82A84DF4;
loc_82A84F28:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A84F2C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82d5c50c
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A84F38"))) PPC_WEAK_FUNC(sub_82A84F38);
PPC_FUNC_IMPL(__imp__sub_82A84F38) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a84f6c
	if (!ctx.cr6.eq) goto loc_82A84F6C;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// bl 0x82a84cc8
	ctx.lr = 0x82A84F5C;
	sub_82A84CC8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82a84f84
	if (!ctx.cr0.lt) goto loc_82A84F84;
loc_82A84F64:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82a84f8c
	goto loc_82A84F8C;
loc_82A84F6C:
	// li r5,1
	ctx.r5.s64 = 1;
	// not r3,r11
	ctx.r3.u64 = ~ctx.r11.u64;
	// bl 0x82a84948
	ctx.lr = 0x82A84F78;
	sub_82A84948(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne 0x82a84f88
	if (!ctx.cr0.eq) goto loc_82A84F88;
	// b 0x82a84f64
	goto loc_82A84F64;
loc_82A84F84:
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82A84F88:
	// not r3,r3
	ctx.r3.u64 = ~ctx.r3.u64;
loc_82A84F8C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A84FA0"))) PPC_WEAK_FUNC(sub_82A84FA0);
PPC_FUNC_IMPL(__imp__sub_82A84FA0) {
	PPC_FUNC_PROLOGUE();
	// li r11,0
	ctx.r11.s64 = 0;
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r11.u32);
	// stw r10,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r10.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r11.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A84FD0"))) PPC_WEAK_FUNC(sub_82A84FD0);
PPC_FUNC_IMPL(__imp__sub_82A84FD0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82a85088
	if (ctx.cr6.eq) goto loc_82A85088;
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82a85008
	if (!ctx.cr0.eq) goto loc_82A85008;
	// stw r11,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r11.u32);
	// b 0x82a85088
	goto loc_82A85088;
loc_82A85008:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r11,1
	ctx.r3.s64 = ctx.r11.s64 + 1;
	// bl 0x82a7fc58
	ctx.lr = 0x82A85014;
	sub_82A7FC58(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a8508c
	if (ctx.cr0.lt) goto loc_82A8508C;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82A85030;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// li r10,0
	ctx.r10.s64 = 0;
	// add r30,r3,r11
	ctx.r30.u64 = ctx.r3.u64 + ctx.r11.u64;
	// stb r10,0(r30)
	PPC_STORE_U8(ctx.r30.u32 + 0, ctx.r10.u8);
	// lwz r31,16(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// b 0x82a85080
	goto loc_82A85080;
loc_82A85048:
	// addi r4,r31,4
	ctx.r4.s64 = ctx.r31.s64 + 4;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A85054:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82a85054
	if (!ctx.cr6.eq) goto loc_82A85054;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r5,r11,0
	ctx.r5.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// subf r30,r5,r30
	ctx.r30.s64 = ctx.r30.s64 - ctx.r5.s64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82d5c630
	ctx.lr = 0x82A8507C;
	sub_82D5C630(ctx, base);
	// lwz r31,0(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
loc_82A85080:
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne 0x82a85048
	if (!ctx.cr0.eq) goto loc_82A85048;
loc_82A85088:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A8508C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A850A8"))) PPC_WEAK_FUNC(sub_82A850A8);
PPC_FUNC_IMPL(__imp__sub_82A850A8) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,24(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A850B0"))) PPC_WEAK_FUNC(sub_82A850B0);
PPC_FUNC_IMPL(__imp__sub_82A850B0) {
	PPC_FUNC_PROLOGUE();
	// li r11,0
	ctx.r11.s64 = 0;
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r11.u32);
	// stw r10,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r10.u32);
	// stw r11,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, ctx.r11.u32);
	// stw r11,48(r3)
	PPC_STORE_U32(ctx.r3.u32 + 48, ctx.r11.u32);
	// stw r11,52(r3)
	PPC_STORE_U32(ctx.r3.u32 + 52, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A850D8"))) PPC_WEAK_FUNC(sub_82A850D8);
PPC_FUNC_IMPL(__imp__sub_82A850D8) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82a85164
	if (ctx.cr6.eq) goto loc_82A85164;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82a85164
	if (ctx.cr6.eq) goto loc_82A85164;
	// cmpwi cr6,r5,-1
	ctx.cr6.compare<int32_t>(ctx.r5.s32, -1, ctx.xer);
	// bne cr6,0x82a85128
	if (!ctx.cr6.eq) goto loc_82A85128;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82a85124
	if (ctx.cr6.eq) goto loc_82A85124;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r5,r10
	ctx.r5.u64 = ctx.r10.u64;
loc_82A85104:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82a85104
	if (!ctx.cr6.eq) goto loc_82A85104;
	// subf r10,r5,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r5.s64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// rotlwi r5,r10,0
	ctx.r5.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// b 0x82a85128
	goto loc_82A85128;
loc_82A85124:
	// li r5,0
	ctx.r5.s64 = 0;
loc_82A85128:
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne cr6,0x82a85138
	if (!ctx.cr6.eq) goto loc_82A85138;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// bne cr6,0x82a85164
	if (!ctx.cr6.eq) goto loc_82A85164;
loc_82A85138:
	// add r10,r4,r5
	ctx.r10.u64 = ctx.r4.u64 + ctx.r5.u64;
	// stw r4,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r4.u32);
	// stw r6,24(r11)
	PPC_STORE_U32(ctx.r11.u32 + 24, ctx.r6.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r7,28(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28, ctx.r7.u32);
	// stw r8,44(r11)
	PPC_STORE_U32(ctx.r11.u32 + 44, ctx.r8.u32);
	// stw r9,48(r11)
	PPC_STORE_U32(ctx.r11.u32 + 48, ctx.r9.u32);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,52(r11)
	PPC_STORE_U32(ctx.r11.u32 + 52, ctx.r10.u32);
	// blr 
	return;
loc_82A85164:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A85170"))) PPC_WEAK_FUNC(sub_82A85170);
PPC_FUNC_IMPL(__imp__sub_82A85170) {
	PPC_FUNC_PROLOGUE();
	// stw r4,52(r3)
	PPC_STORE_U32(ctx.r3.u32 + 52, ctx.r4.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A85178"))) PPC_WEAK_FUNC(sub_82A85178);
PPC_FUNC_IMPL(__imp__sub_82A85178) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b8
	ctx.lr = 0x82A85180;
	__savegprlr_24(ctx, base);
	// addi r31,r1,-160
	ctx.r31.s64 = ctx.r1.s64 + -160;
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// mr r24,r5
	ctx.r24.u64 = ctx.r5.u64;
	// li r25,0
	ctx.r25.s64 = 0;
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// cmplw cr6,r26,r11
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82a85220
	if (!ctx.cr6.lt) goto loc_82A85220;
	// lbz r3,0(r26)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r26.u32 + 0);
	// bl 0x82d5f930
	ctx.lr = 0x82A851AC;
	sub_82D5F930(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a85220
	if (ctx.cr0.eq) goto loc_82A85220;
	// addi r30,r26,1
	ctx.r30.s64 = ctx.r26.s64 + 1;
	// b 0x82a851d0
	goto loc_82A851D0;
loc_82A851BC:
	// lbz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// bl 0x82d5f930
	ctx.lr = 0x82A851C4;
	sub_82D5F930(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a851dc
	if (ctx.cr0.eq) goto loc_82A851DC;
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
loc_82A851D0:
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a851bc
	if (ctx.cr6.lt) goto loc_82A851BC;
loc_82A851DC:
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82a851f4
	if (!ctx.cr6.lt) goto loc_82A851F4;
	// lbz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// cmplwi cr6,r10,46
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 46, ctx.xer);
	// beq cr6,0x82a85210
	if (ctx.cr6.eq) goto loc_82A85210;
loc_82A851F4:
	// li r25,1
	ctx.r25.s64 = 1;
	// b 0x82a85274
	goto loc_82A85274;
loc_82A851FC:
	// lbz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// bl 0x82d5f930
	ctx.lr = 0x82A85204;
	sub_82D5F930(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a85274
	if (ctx.cr0.eq) goto loc_82A85274;
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
loc_82A85210:
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a851fc
	if (ctx.cr6.lt) goto loc_82A851FC;
	// b 0x82a85274
	goto loc_82A85274;
loc_82A85220:
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// addi r11,r26,1
	ctx.r11.s64 = ctx.r26.s64 + 1;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82a85420
	if (!ctx.cr6.lt) goto loc_82A85420;
	// lbz r10,0(r26)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r26.u32 + 0);
	// cmplwi cr6,r10,46
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 46, ctx.xer);
	// bne cr6,0x82a85420
	if (!ctx.cr6.eq) goto loc_82A85420;
	// lbz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// bl 0x82d5f930
	ctx.lr = 0x82A85244;
	sub_82D5F930(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a85420
	if (ctx.cr0.eq) goto loc_82A85420;
	// addi r30,r26,2
	ctx.r30.s64 = ctx.r26.s64 + 2;
	// b 0x82a85268
	goto loc_82A85268;
loc_82A85254:
	// lbz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// bl 0x82d5f930
	ctx.lr = 0x82A8525C;
	sub_82D5F930(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a85274
	if (ctx.cr0.eq) goto loc_82A85274;
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
loc_82A85268:
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a85254
	if (ctx.cr6.lt) goto loc_82A85254;
loc_82A85274:
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// addi r29,r30,1
	ctx.r29.s64 = ctx.r30.s64 + 1;
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82a852d0
	if (!ctx.cr6.lt) goto loc_82A852D0;
	// lbz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// bl 0x82d62970
	ctx.lr = 0x82A8528C;
	sub_82D62970(ctx, base);
	// cmpwi cr6,r3,101
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 101, ctx.xer);
	// bne cr6,0x82a852d0
	if (!ctx.cr6.eq) goto loc_82A852D0;
	// lbz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r29.u32 + 0);
	// bl 0x82d5f930
	ctx.lr = 0x82A8529C;
	sub_82D5F930(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a852d0
	if (ctx.cr0.eq) goto loc_82A852D0;
	// addi r30,r30,2
	ctx.r30.s64 = ctx.r30.s64 + 2;
	// b 0x82a852c0
	goto loc_82A852C0;
loc_82A852AC:
	// lbz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// bl 0x82d5f930
	ctx.lr = 0x82A852B4;
	sub_82D5F930(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a853bc
	if (ctx.cr0.eq) goto loc_82A853BC;
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
loc_82A852C0:
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a852ac
	if (ctx.cr6.lt) goto loc_82A852AC;
	// b 0x82a853bc
	goto loc_82A853BC;
loc_82A852D0:
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// addi r27,r30,2
	ctx.r27.s64 = ctx.r30.s64 + 2;
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82a85344
	if (!ctx.cr6.lt) goto loc_82A85344;
	// lbz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// bl 0x82d62970
	ctx.lr = 0x82A852E8;
	sub_82D62970(ctx, base);
	// cmpwi cr6,r3,101
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 101, ctx.xer);
	// bne cr6,0x82a85344
	if (!ctx.cr6.eq) goto loc_82A85344;
	// lbz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,43
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 43, ctx.xer);
	// beq cr6,0x82a85308
	if (ctx.cr6.eq) goto loc_82A85308;
	// cmpwi cr6,r11,45
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 45, ctx.xer);
	// bne cr6,0x82a85344
	if (!ctx.cr6.eq) goto loc_82A85344;
loc_82A85308:
	// lbz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r27.u32 + 0);
	// bl 0x82d5f930
	ctx.lr = 0x82A85310;
	sub_82D5F930(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a85344
	if (ctx.cr0.eq) goto loc_82A85344;
	// addi r30,r30,3
	ctx.r30.s64 = ctx.r30.s64 + 3;
	// b 0x82a85334
	goto loc_82A85334;
loc_82A85320:
	// lbz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// bl 0x82d5f930
	ctx.lr = 0x82A85328;
	sub_82D5F930(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a853bc
	if (ctx.cr0.eq) goto loc_82A853BC;
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
loc_82A85334:
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a85320
	if (ctx.cr6.lt) goto loc_82A85320;
	// b 0x82a853bc
	goto loc_82A853BC;
loc_82A85344:
	// lbz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,35
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 35, ctx.xer);
	// bne cr6,0x82a853b4
	if (!ctx.cr6.eq) goto loc_82A853B4;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r27,r11,-21032
	ctx.r27.s64 = ctx.r11.s64 + -21032;
loc_82A85358:
	// lwz r4,0(r27)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A85364:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82a85364
	if (!ctx.cr6.eq) goto loc_82A85364;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r29,r11,0
	ctx.r29.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// add r11,r29,r26
	ctx.r11.u64 = ctx.r29.u64 + ctx.r26.u64;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bgt cr6,0x82a853a4
	if (ctx.cr6.gt) goto loc_82A853A4;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82d625b0
	ctx.lr = 0x82A8539C;
	sub_82D625B0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82a85410
	if (ctx.cr0.eq) goto loc_82A85410;
loc_82A853A4:
	// addi r27,r27,8
	ctx.r27.s64 = ctx.r27.s64 + 8;
	// lwz r11,4(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a85358
	if (!ctx.cr6.eq) goto loc_82A85358;
loc_82A853B4:
	// cmpwi cr6,r25,0
	ctx.cr6.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// bne cr6,0x82a85420
	if (!ctx.cr6.eq) goto loc_82A85420;
loc_82A853BC:
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82a85408
	if (ctx.cr6.eq) goto loc_82A85408;
	// subf r29,r26,r30
	ctx.r29.s64 = ctx.r30.s64 - ctx.r26.s64;
	// addi r11,r29,1
	ctx.r11.s64 = ctx.r29.s64 + 1;
	// neg r11,r11
	ctx.r11.s64 = -ctx.r11.s64;
	// rlwinm r12,r11,0,0,27
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// bl 0x82d5dad4
	ctx.lr = 0x82A853D8;
	sub_82D5DAD4(ctx, base);
	// lwz r11,0(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// stwux r11,r1,r12
	ea = ctx.r1.u32 + ctx.r12.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r1.u32 = ea;
	// addi r28,r1,80
	ctx.r28.s64 = ctx.r1.s64 + 80;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82d5c630
	ctx.lr = 0x82A853F4;
	sub_82D5C630(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// stbx r11,r28,r29
	PPC_STORE_U8(ctx.r28.u32 + ctx.r29.u32, ctx.r11.u8);
	// bl 0x82d5d600
	ctx.lr = 0x82A85404;
	sub_82D5D600(ctx, base);
	// stfd f1,0(r24)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r24.u32 + 0, ctx.f1.u64);
loc_82A85408:
	// subf r3,r26,r30
	ctx.r3.s64 = ctx.r30.s64 - ctx.r26.s64;
	// b 0x82a85424
	goto loc_82A85424;
loc_82A85410:
	// lfs f0,4(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stfd f0,0(r24)
	PPC_STORE_U64(ctx.r24.u32 + 0, ctx.f0.u64);
	// b 0x82a85424
	goto loc_82A85424;
loc_82A85420:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A85424:
	// addi r1,r31,160
	ctx.r1.s64 = ctx.r31.s64 + 160;
	// b 0x82d5c508
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A85430"))) PPC_WEAK_FUNC(sub_82A85430);
PPC_FUNC_IMPL(__imp__sub_82A85430) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c4
	ctx.lr = 0x82A85438;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r31,r28
	ctx.r31.u64 = ctx.r28.u64;
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// cmplw cr6,r28,r11
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82a8549c
	if (!ctx.cr6.lt) goto loc_82A8549C;
	// lbz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r28.u32 + 0);
	// bl 0x82d5f910
	ctx.lr = 0x82A85460;
	sub_82D5F910(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a854c4
	if (!ctx.cr0.eq) goto loc_82A854C4;
	// lbz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 0);
	// cmplwi cr6,r11,95
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 95, ctx.xer);
	// beq cr6,0x82a854c4
	if (ctx.cr6.eq) goto loc_82A854C4;
	// lwz r10,52(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 52);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82a8549c
	if (ctx.cr6.eq) goto loc_82A8549C;
	// lwz r10,40(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 40);
	// rlwinm. r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82a8549c
	if (!ctx.cr0.eq) goto loc_82A8549C;
	// clrlwi r3,r11,24
	ctx.r3.u64 = ctx.r11.u32 & 0xFF;
	// bl 0x82d5f9b0
	ctx.lr = 0x82A85494;
	sub_82D5F9B0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a854c4
	if (!ctx.cr0.eq) goto loc_82A854C4;
loc_82A8549C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A854A0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c514
	__restgprlr_27(ctx, base);
	return;
loc_82A854A8:
	// lbz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// bl 0x82d5f9b0
	ctx.lr = 0x82A854B0;
	sub_82D5F9B0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a854c4
	if (!ctx.cr0.eq) goto loc_82A854C4;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,95
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 95, ctx.xer);
	// bne cr6,0x82a854d4
	if (!ctx.cr6.eq) goto loc_82A854D4;
loc_82A854C4:
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a854a8
	if (ctx.cr6.lt) goto loc_82A854A8;
loc_82A854D4:
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// addi r30,r31,2
	ctx.r30.s64 = ctx.r31.s64 + 2;
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82a85528
	if (!ctx.cr6.lt) goto loc_82A85528;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,58
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 58, ctx.xer);
	// bne cr6,0x82a85528
	if (!ctx.cr6.eq) goto loc_82A85528;
	// lbz r11,1(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 1);
	// cmplwi cr6,r11,58
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 58, ctx.xer);
	// bne cr6,0x82a85528
	if (!ctx.cr6.eq) goto loc_82A85528;
	// lbz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// bl 0x82d5f9b0
	ctx.lr = 0x82A85504;
	sub_82D5F9B0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82a85518
	if (!ctx.cr0.eq) goto loc_82A85518;
	// lbz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,95
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 95, ctx.xer);
	// bne cr6,0x82a85528
	if (!ctx.cr6.eq) goto loc_82A85528;
loc_82A85518:
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// mr r31,r30
	ctx.r31.u64 = ctx.r30.u64;
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a854c4
	if (ctx.cr6.lt) goto loc_82A854C4;
loc_82A85528:
	// subf r31,r28,r31
	ctx.r31.s64 = ctx.r31.s64 - ctx.r28.s64;
	// addi r4,r31,1
	ctx.r4.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r4,r31
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r31.u32, ctx.xer);
	// blt cr6,0x82a8549c
	if (ctx.cr6.lt) goto loc_82A8549C;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,44(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 44);
	// bl 0x82ab7070
	ctx.lr = 0x82A85544;
	sub_82AB7070(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq 0x82a8549c
	if (ctx.cr0.eq) goto loc_82A8549C;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82d5c630
	ctx.lr = 0x82A8555C;
	sub_82D5C630(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stbx r11,r30,r31
	PPC_STORE_U8(ctx.r30.u32 + ctx.r31.u32, ctx.r11.u8);
	// stw r30,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r30.u32);
	// b 0x82a854a0
	goto loc_82A854A0;
}

__attribute__((alias("__imp__sub_82A85570"))) PPC_WEAK_FUNC(sub_82A85570);
PPC_FUNC_IMPL(__imp__sub_82A85570) {
	PPC_FUNC_PROLOGUE();
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r10,r4,1
	ctx.r10.s64 = ctx.r4.s64 + 1;
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r11.u32);
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// stb r11,0(r5)
	PPC_STORE_U8(ctx.r5.u32 + 0, ctx.r11.u8);
	// lwz r7,4(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplw cr6,r10,r7
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, ctx.xer);
	// bge cr6,0x82a85644
	if (!ctx.cr6.lt) goto loc_82A85644;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,35
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 35, ctx.xer);
	// bne cr6,0x82a855c4
	if (!ctx.cr6.eq) goto loc_82A855C4;
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// extsb r8,r9
	ctx.r8.s64 = ctx.r9.s8;
	// cmpwi cr6,r8,35
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 35, ctx.xer);
	// beq cr6,0x82a855b8
	if (ctx.cr6.eq) goto loc_82A855B8;
	// cmpwi cr6,r8,64
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 64, ctx.xer);
	// bne cr6,0x82a855c4
	if (!ctx.cr6.eq) goto loc_82A855C4;
loc_82A855B8:
	// li r3,2
	ctx.r3.s64 = 2;
	// stb r9,1(r5)
	PPC_STORE_U8(ctx.r5.u32 + 1, ctx.r9.u8);
	// blr 
	return;
loc_82A855C4:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// extsb r10,r9
	ctx.r10.s64 = ctx.r9.s8;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82a85680
	if (!ctx.cr6.eq) goto loc_82A85680;
	// cmpwi cr6,r11,58
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 58, ctx.xer);
	// bgt cr6,0x82a85624
	if (ctx.cr6.gt) goto loc_82A85624;
	// beq cr6,0x82a855b8
	if (ctx.cr6.eq) goto loc_82A855B8;
	// cmpwi cr6,r11,38
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 38, ctx.xer);
	// beq cr6,0x82a855b8
	if (ctx.cr6.eq) goto loc_82A855B8;
	// cmpwi cr6,r11,43
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 43, ctx.xer);
	// beq cr6,0x82a855b8
	if (ctx.cr6.eq) goto loc_82A855B8;
	// cmpwi cr6,r11,45
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 45, ctx.xer);
	// beq cr6,0x82a855b8
	if (ctx.cr6.eq) goto loc_82A855B8;
	// cmpwi cr6,r11,46
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 46, ctx.xer);
	// bne cr6,0x82a85644
	if (!ctx.cr6.eq) goto loc_82A85644;
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplw cr6,r11,r7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r7.u32, ctx.xer);
	// bge cr6,0x82a85644
	if (!ctx.cr6.lt) goto loc_82A85644;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,46
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 46, ctx.xer);
	// bne cr6,0x82a85644
	if (!ctx.cr6.eq) goto loc_82A85644;
	// stb r9,1(r5)
	PPC_STORE_U8(ctx.r5.u32 + 1, ctx.r9.u8);
	// lbz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// b 0x82a8566c
	goto loc_82A8566C;
loc_82A85624:
	// cmpwi cr6,r11,60
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 60, ctx.xer);
	// beq cr6,0x82a8564c
	if (ctx.cr6.eq) goto loc_82A8564C;
	// cmpwi cr6,r11,61
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 61, ctx.xer);
	// beq cr6,0x82a855b8
	if (ctx.cr6.eq) goto loc_82A855B8;
	// cmpwi cr6,r11,62
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 62, ctx.xer);
	// beq cr6,0x82a8564c
	if (ctx.cr6.eq) goto loc_82A8564C;
loc_82A8563C:
	// cmpwi cr6,r11,124
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 124, ctx.xer);
loc_82A85640:
	// beq cr6,0x82a855b8
	if (ctx.cr6.eq) goto loc_82A855B8;
loc_82A85644:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82A8564C:
	// stb r9,1(r5)
	PPC_STORE_U8(ctx.r5.u32 + 1, ctx.r9.u8);
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82a85678
	if (!ctx.cr6.lt) goto loc_82A85678;
	// lbz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r11,61
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 61, ctx.xer);
	// bne cr6,0x82a85678
	if (!ctx.cr6.eq) goto loc_82A85678;
loc_82A8566C:
	// li r3,3
	ctx.r3.s64 = 3;
	// stb r11,2(r5)
	PPC_STORE_U8(ctx.r5.u32 + 2, ctx.r11.u8);
	// blr 
	return;
loc_82A85678:
	// li r3,2
	ctx.r3.s64 = 2;
	// blr 
	return;
loc_82A85680:
	// cmpwi cr6,r10,61
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 61, ctx.xer);
	// bne cr6,0x82a856e4
	if (!ctx.cr6.eq) goto loc_82A856E4;
	// cmpwi cr6,r11,47
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 47, ctx.xer);
	// bgt cr6,0x82a856c8
	if (ctx.cr6.gt) goto loc_82A856C8;
	// beq cr6,0x82a855b8
	if (ctx.cr6.eq) goto loc_82A855B8;
	// cmpwi cr6,r11,33
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 33, ctx.xer);
	// beq cr6,0x82a855b8
	if (ctx.cr6.eq) goto loc_82A855B8;
	// cmpwi cr6,r11,36
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 36, ctx.xer);
	// ble cr6,0x82a85644
	if (!ctx.cr6.gt) goto loc_82A85644;
	// cmpwi cr6,r11,38
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 38, ctx.xer);
	// ble cr6,0x82a855b8
	if (!ctx.cr6.gt) goto loc_82A855B8;
	// cmpwi cr6,r11,41
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 41, ctx.xer);
	// ble cr6,0x82a85644
	if (!ctx.cr6.gt) goto loc_82A85644;
	// cmpwi cr6,r11,43
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 43, ctx.xer);
	// ble cr6,0x82a855b8
	if (!ctx.cr6.gt) goto loc_82A855B8;
	// cmpwi cr6,r11,45
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 45, ctx.xer);
	// beq cr6,0x82a855b8
	if (ctx.cr6.eq) goto loc_82A855B8;
	// b 0x82a85644
	goto loc_82A85644;
loc_82A856C8:
	// cmpwi cr6,r11,60
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 60, ctx.xer);
	// beq cr6,0x82a855b8
	if (ctx.cr6.eq) goto loc_82A855B8;
	// cmpwi cr6,r11,62
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 62, ctx.xer);
	// beq cr6,0x82a855b8
	if (ctx.cr6.eq) goto loc_82A855B8;
	// cmpwi cr6,r11,94
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 94, ctx.xer);
	// beq cr6,0x82a855b8
	if (ctx.cr6.eq) goto loc_82A855B8;
	// b 0x82a8563c
	goto loc_82A8563C;
loc_82A856E4:
	// cmpwi cr6,r11,45
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 45, ctx.xer);
	// bne cr6,0x82a85644
	if (!ctx.cr6.eq) goto loc_82A85644;
	// cmpwi cr6,r10,62
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 62, ctx.xer);
	// b 0x82a85640
	goto loc_82A85640;
}

__attribute__((alias("__imp__sub_82A856F8"))) PPC_WEAK_FUNC(sub_82A856F8);
PPC_FUNC_IMPL(__imp__sub_82A856F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82A85700;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
	// li r30,5
	ctx.r30.s64 = 5;
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a85728
	if (ctx.cr6.lt) goto loc_82A85728;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82a85764
	goto loc_82A85764;
loc_82A85728:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// bl 0x82d62970
	ctx.lr = 0x82A85734;
	sub_82D62970(ctx, base);
	// cmpwi cr6,r3,102
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 102, ctx.xer);
	// beq cr6,0x82a8574c
	if (ctx.cr6.eq) goto loc_82A8574C;
	// cmpwi cr6,r3,104
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 104, ctx.xer);
	// bne cr6,0x82a85754
	if (!ctx.cr6.eq) goto loc_82A85754;
	// li r30,6
	ctx.r30.s64 = 6;
	// b 0x82a85750
	goto loc_82A85750;
loc_82A8574C:
	// li r30,7
	ctx.r30.s64 = 7;
loc_82A85750:
	// addi r29,r31,1
	ctx.r29.s64 = ctx.r31.s64 + 1;
loc_82A85754:
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82a85760
	if (ctx.cr6.eq) goto loc_82A85760;
	// stw r30,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r30.u32);
loc_82A85760:
	// subf r3,r31,r29
	ctx.r3.s64 = ctx.r29.s64 - ctx.r31.s64;
loc_82A85764:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A85770"))) PPC_WEAK_FUNC(sub_82A85770);
PPC_FUNC_IMPL(__imp__sub_82A85770) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82A85778;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// mr r31,r29
	ctx.r31.u64 = ctx.r29.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// li r27,0
	ctx.r27.s64 = 0;
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82a857f4
	if (!ctx.cr6.lt) goto loc_82A857F4;
loc_82A857A0:
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// bne cr6,0x82a857c4
	if (!ctx.cr6.eq) goto loc_82A857C4;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// bl 0x82d62970
	ctx.lr = 0x82A857B4;
	sub_82D62970(ctx, base);
	// cmpwi cr6,r3,117
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 117, ctx.xer);
	// bne cr6,0x82a857c4
	if (!ctx.cr6.eq) goto loc_82A857C4;
	// li r28,1
	ctx.r28.s64 = 1;
	// b 0x82a857e4
	goto loc_82A857E4;
loc_82A857C4:
	// cmpwi cr6,r27,0
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// bne cr6,0x82a857f4
	if (!ctx.cr6.eq) goto loc_82A857F4;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// bl 0x82d62970
	ctx.lr = 0x82A857D8;
	sub_82D62970(ctx, base);
	// cmpwi cr6,r3,108
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 108, ctx.xer);
	// bne cr6,0x82a857f4
	if (!ctx.cr6.eq) goto loc_82A857F4;
	// li r27,1
	ctx.r27.s64 = 1;
loc_82A857E4:
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a857a0
	if (ctx.cr6.lt) goto loc_82A857A0;
loc_82A857F4:
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82a8581c
	if (ctx.cr6.eq) goto loc_82A8581C;
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// beq cr6,0x82a8580c
	if (ctx.cr6.eq) goto loc_82A8580C;
	// li r11,4
	ctx.r11.s64 = 4;
	// b 0x82a85818
	goto loc_82A85818;
loc_82A8580C:
	// cmpwi cr6,r27,0
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// beq cr6,0x82a8581c
	if (ctx.cr6.eq) goto loc_82A8581C;
	// li r11,3
	ctx.r11.s64 = 3;
loc_82A85818:
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
loc_82A8581C:
	// subf r3,r29,r31
	ctx.r3.s64 = ctx.r31.s64 - ctx.r29.s64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A85828"))) PPC_WEAK_FUNC(sub_82A85828);
PPC_FUNC_IMPL(__imp__sub_82A85828) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// b 0x82a85854
	goto loc_82A85854;
loc_82A85844:
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r30,0(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// bl 0x8247f398
	ctx.lr = 0x82A85850;
	sub_8247F398(ctx, base);
	// stw r30,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r30.u32);
loc_82A85854:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a85844
	if (!ctx.cr6.eq) goto loc_82A85844;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x8247f398
	ctx.lr = 0x82A8586C;
	sub_8247F398(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// bl 0x8247f398
	ctx.lr = 0x82A85878;
	sub_8247F398(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A85890"))) PPC_WEAK_FUNC(sub_82A85890);
PPC_FUNC_IMPL(__imp__sub_82A85890) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82A85898;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// li r26,0
	ctx.r26.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr. r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// rlwinm r29,r11,31,1,31
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// beq 0x82a858fc
	if (ctx.cr0.eq) goto loc_82A858FC;
	// lwz r7,4(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
loc_82A858C4:
	// rlwinm r9,r29,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r7
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// cmplw cr6,r28,r9
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r9.u32, ctx.xer);
	// ble cr6,0x82a858dc
	if (!ctx.cr6.gt) goto loc_82A858DC;
	// addi r8,r29,1
	ctx.r8.s64 = ctx.r29.s64 + 1;
	// b 0x82a858e4
	goto loc_82A858E4;
loc_82A858DC:
	// bge cr6,0x82a858f4
	if (!ctx.cr6.lt) goto loc_82A858F4;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
loc_82A858E4:
	// add r9,r11,r8
	ctx.r9.u64 = ctx.r11.u64 + ctx.r8.u64;
	// cmplw cr6,r8,r11
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r11.u32, ctx.xer);
	// rlwinm r29,r9,31,1,31
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 31) & 0x7FFFFFFF;
	// blt cr6,0x82a858c4
	if (ctx.cr6.lt) goto loc_82A858C4;
loc_82A858F4:
	// cmplw cr6,r8,r11
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82a85a14
	if (ctx.cr6.lt) goto loc_82A85A14;
loc_82A858FC:
	// not r11,r10
	ctx.r11.u64 = ~ctx.r10.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// and r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 & ctx.r10.u64;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82a859b0
	if (!ctx.cr6.eq) goto loc_82A859B0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// rlwinm r11,r10,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// bne cr6,0x82a85920
	if (!ctx.cr6.eq) goto loc_82A85920;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82A85920:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8247f370
	ctx.lr = 0x82A8592C;
	sub_8247F370(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq 0x82a85980
	if (ctx.cr0.eq) goto loc_82A85980;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82d5c630
	ctx.lr = 0x82A85948;
	sub_82D5C630(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// bl 0x8247f398
	ctx.lr = 0x82A85954;
	sub_8247F398(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stw r30,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r30.u32);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// bne 0x82a8596c
	if (!ctx.cr0.eq) goto loc_82A8596C;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82A8596C:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8247f370
	ctx.lr = 0x82A85978;
	sub_8247F370(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne 0x82a8598c
	if (!ctx.cr0.eq) goto loc_82A8598C;
loc_82A85980:
	// lis r26,-32761
	ctx.r26.s64 = -2147024896;
	// ori r26,r26,14
	ctx.r26.u64 = ctx.r26.u64 | 14;
	// b 0x82a85a20
	goto loc_82A85A20;
loc_82A8598C:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82d5c630
	ctx.lr = 0x82A859A0;
	sub_82D5C630(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x8247f398
	ctx.lr = 0x82A859AC;
	sub_8247F398(ctx, base);
	// stw r30,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r30.u32);
loc_82A859B0:
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r10,r29
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r29.u32, ctx.xer);
	// ble cr6,0x82a859f0
	if (!ctx.cr6.gt) goto loc_82A859F0;
	// rlwinm r11,r10,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r29,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r29.s64;
loc_82A859C4:
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + ctx.r11.u64;
	// lwz r8,-4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + -4);
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// addi r11,r11,-4
	ctx.r11.s64 = ctx.r11.s64 + -4;
	// lwz r8,-4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + -4);
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// bne 0x82a859c4
	if (!ctx.cr0.eq) goto loc_82A859C4;
loc_82A859F0:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// rlwinm r11,r29,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// li r9,1
	ctx.r9.s64 = 1;
	// stwx r28,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r28.u32);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r9.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
loc_82A85A14:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82a85a20
	if (ctx.cr6.eq) goto loc_82A85A20;
	// stw r29,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r29.u32);
loc_82A85A20:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8247f398
	ctx.lr = 0x82A85A2C;
	sub_8247F398(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A85A38"))) PPC_WEAK_FUNC(sub_82A85A38);
PPC_FUNC_IMPL(__imp__sub_82A85A38) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// b 0x82a85a68
	goto loc_82A85A68;
loc_82A85A54:
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r30,0(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// bl 0x8247f398
	ctx.lr = 0x82A85A64;
	sub_8247F398(ctx, base);
	// stw r30,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r30.u32);
loc_82A85A68:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82a85a54
	if (!ctx.cr6.eq) goto loc_82A85A54;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// stw r11,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r11.u32);
	// stw r11,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r11.u32);
	// ble cr6,0x82a85ab8
	if (!ctx.cr6.gt) goto loc_82A85AB8;
loc_82A85A90:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + ctx.r11.u64;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r8,r8,0,27,25
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFFFDF;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82a85a90
	if (ctx.cr6.lt) goto loc_82A85A90;
loc_82A85AB8:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82A85AD8"))) PPC_WEAK_FUNC(sub_82A85AD8);
PPC_FUNC_IMPL(__imp__sub_82A85AD8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82A85AE0;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82A85AF4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82a85af4
	if (!ctx.cr6.eq) goto loc_82A85AF4;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// addi r31,r11,1
	ctx.r31.s64 = ctx.r11.s64 + 1;
	// addi r3,r31,4
	ctx.r3.s64 = ctx.r31.s64 + 4;
	// bl 0x8247f370
	ctx.lr = 0x82A85B20;
	sub_8247F370(ctx, base);
	// mr. r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82a85b34
	if (!ctx.cr0.eq) goto loc_82A85B34;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82a85b64
	goto loc_82A85B64;
loc_82A85B34:
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// addi r3,r11,4
	ctx.r3.s64 = ctx.r11.s64 + 4;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// stw r11,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r11.u32);
	// add r11,r10,r31
	ctx.r11.u64 = ctx.r10.u64 + ctx.r31.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,20(r30)
	PPC_STORE_U32(ctx.r30.u32 + 20, ctx.r11.u32);
	// bl 0x82d5c630
	ctx.lr = 0x82A85B60;
	sub_82D5C630(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82A85B64:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82A85B70"))) PPC_WEAK_FUNC(sub_82A85B70);
PPC_FUNC_IMPL(__imp__sub_82A85B70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82a85890
	ctx.lr = 0x82A85B94;
	sub_82A85890(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82a85c04
	if (ctx.cr0.lt) goto loc_82A85C04;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r30,255
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 255, ctx.xer);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bne cr6,0x82a85bcc
	if (!ctx.cr6.eq) goto loc_82A85BCC;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// rlwinm r9,r9,0,26,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x20;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r9.u32);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// ori r9,r9,1
	ctx.r9.u64 = ctx.r9.u64 | 1;
	// b 0x82a85c00
	goto loc_82A85C00;
loc_82A85BCC:
	// cmplwi cr6,r30,16
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 16, ctx.xer);
	// bne cr6,0x82a85be4
	if (!ctx.cr6.eq) goto loc_82A85BE4;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// ori r9,r9,16
	ctx.r9.u64 = ctx.r9.u64 | 16;
	// stwx r9,r11,r10
	PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// b 0x82a85c04
	goto loc_82A85C04;
loc_82A85BE4:
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// clrlwi r9,r30,28
	ctx.r9.u64 = ctx.r30.u32 & 0xF;
	// rlwinm r8,r8,0,0,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFF0;
	// stwx r8,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r8.u32);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
loc_82A85C00:
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r9.u32);
loc_82A85C04:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

