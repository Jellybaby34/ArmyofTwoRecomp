#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_82D21D88"))) PPC_WEAK_FUNC(sub_82D21D88);
PPC_FUNC_IMPL(__imp__sub_82D21D88) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82d21ddc
	if (ctx.cr6.eq) goto loc_82D21DDC;
loc_82D21D90:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmpw cr6,r11,r3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r3.s32, ctx.xer);
	// bne cr6,0x82d21db4
	if (!ctx.cr6.eq) goto loc_82D21DB4;
	// lwz r11,4(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmpw cr6,r11,r4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r4.s32, ctx.xer);
	// bne cr6,0x82d21db4
	if (!ctx.cr6.eq) goto loc_82D21DB4;
	// lwz r11,8(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	// cmpw cr6,r11,r5
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r5.s32, ctx.xer);
	// beq cr6,0x82d21dc0
	if (ctx.cr6.eq) goto loc_82D21DC0;
loc_82D21DB4:
	// lwz r6,20(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 20);
	// cmplwi r6,0
	ctx.cr0.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// bne 0x82d21d90
	if (!ctx.cr0.eq) goto loc_82D21D90;
loc_82D21DC0:
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82d21ddc
	if (ctx.cr6.eq) goto loc_82D21DDC;
	// lwz r11,16(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 16);
	// lwz r3,12(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 12);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,16(r6)
	PPC_STORE_U32(ctx.r6.u32 + 16, ctx.r11.u32);
	// blr 
	return;
loc_82D21DDC:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D21DE8"))) PPC_WEAK_FUNC(sub_82D21DE8);
PPC_FUNC_IMPL(__imp__sub_82D21DE8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82d21e58
	if (ctx.cr6.eq) goto loc_82D21E58;
	// lwz r31,0(r4)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82d21e58
	if (ctx.cr0.eq) goto loc_82D21E58;
loc_82D21E0C:
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplw cr6,r11,r3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r3.u32, ctx.xer);
	// beq cr6,0x82d21e28
	if (ctx.cr6.eq) goto loc_82D21E28;
	// addi r4,r31,20
	ctx.r4.s64 = ctx.r31.s64 + 20;
	// lwz r31,0(r4)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne 0x82d21e0c
	if (!ctx.cr0.eq) goto loc_82D21E0C;
loc_82D21E28:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82d21e58
	if (ctx.cr6.eq) goto loc_82D21E58;
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// bgt 0x82d21e58
	if (ctx.cr0.gt) goto loc_82D21E58;
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// bl 0x82d0c490
	ctx.lr = 0x82D21E50;
	sub_82D0C490(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d0c490
	ctx.lr = 0x82D21E58;
	sub_82D0C490(ctx, base);
loc_82D21E58:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D21E70"))) PPC_WEAK_FUNC(sub_82D21E70);
PPC_FUNC_IMPL(__imp__sub_82D21E70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stfd f30,-40(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -40, ctx.f30.u64);
	// stfd f31,-32(r1)
	PPC_STORE_U64(ctx.r1.u32 + -32, ctx.f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// rlwinm. r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// mr r9,r4
	ctx.r9.u64 = ctx.r4.u64;
	// li r31,0
	ctx.r31.s64 = 0;
	// rlwinm r8,r4,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// bge 0x82d21ea8
	if (!ctx.cr0.lt) goto loc_82D21EA8;
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
loc_82D21EA8:
	// subf r10,r11,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r11.s64;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// ble cr6,0x82d21ebc
	if (!ctx.cr6.gt) goto loc_82D21EBC;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// li r31,4
	ctx.r31.s64 = 4;
loc_82D21EBC:
	// subf. r10,r9,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r9.s64;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble 0x82d21ecc
	if (!ctx.cr0.gt) goto loc_82D21ECC;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// ori r31,r31,2
	ctx.r31.u64 = ctx.r31.u64 | 2;
loc_82D21ECC:
	// subf r10,r11,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r11.s64;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// ble cr6,0x82d21ee0
	if (!ctx.cr6.gt) goto loc_82D21EE0;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// ori r31,r31,1
	ctx.r31.u64 = ctx.r31.u64 | 1;
loc_82D21EE0:
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// extsw r10,r8
	ctx.r10.s64 = ctx.r8.s32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f0
	ctx.f13.f64 = double(ctx.f0.s64);
	// lfd f0,88(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f12,f0
	ctx.f12.f64 = double(ctx.f0.s64);
	// lfd f0,-8200(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -8200);
	// fmul f0,f13,f0
	ctx.f0.f64 = ctx.f13.f64 * ctx.f0.f64;
	// fdiv f30,f0,f12
	ctx.f30.f64 = ctx.f0.f64 / ctx.f12.f64;
	// fmr f1,f30
	ctx.f1.f64 = ctx.f30.f64;
	// bl 0x82e27f28
	ctx.lr = 0x82D21F18;
	sub_82E27F28(ctx, base);
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = ctx.f1.f64;
	// fmr f1,f30
	ctx.f1.f64 = ctx.f30.f64;
	// bl 0x82e27e58
	ctx.lr = 0x82D21F24;
	sub_82E27E58(ctx, base);
	// clrlwi. r11,r31,31
	ctx.r11.u64 = ctx.r31.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82d21f38
	if (ctx.cr0.eq) goto loc_82D21F38;
	// fmr f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f31.f64;
	// fmr f31,f1
	ctx.f31.f64 = ctx.f1.f64;
	// fmr f1,f0
	ctx.f1.f64 = ctx.f0.f64;
loc_82D21F38:
	// rlwinm. r11,r31,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82d21f4c
	if (ctx.cr0.eq) goto loc_82D21F4C;
	// fmr f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f31.f64;
	// fneg f31,f1
	ctx.f31.u64 = ctx.f1.u64 ^ 0x8000000000000000;
	// fmr f1,f0
	ctx.f1.f64 = ctx.f0.f64;
loc_82D21F4C:
	// rlwinm. r11,r31,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0x4;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82d21f58
	if (ctx.cr0.eq) goto loc_82D21F58;
	// fneg f1,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = ctx.f1.u64 ^ 0x8000000000000000;
loc_82D21F58:
	// stfd f31,0(r30)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r30.u32 + 0, ctx.f31.u64);
	// stfd f1,8(r30)
	PPC_STORE_U64(ctx.r30.u32 + 8, ctx.f1.u64);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// lfd f30,-40(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// lfd f31,-32(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D21F80"))) PPC_WEAK_FUNC(sub_82D21F80);
PPC_FUNC_IMPL(__imp__sub_82D21F80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blelr cr6
	if (!ctx.cr6.gt) return;
loc_82D21F90:
	// srawi r11,r11,2
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 2;
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addze. r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bgt 0x82d21f90
	if (ctx.cr0.gt) goto loc_82D21F90;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D21FA8"))) PPC_WEAK_FUNC(sub_82D21FA8);
PPC_FUNC_IMPL(__imp__sub_82D21FA8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// cntlzw r11,r4
	ctx.r11.u64 = ctx.r4.u32 == 0 ? 32 : __builtin_clz(ctx.r4.u32);
	// lwz r10,32(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// lwz r9,12(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// lwz r6,20(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r7,24(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// lwz r8,28(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// add r11,r11,r4
	ctx.r11.u64 = ctx.r11.u64 + ctx.r4.u64;
	// and r10,r6,r11
	ctx.r10.u64 = ctx.r6.u64 & ctx.r11.u64;
	// sraw r9,r11,r9
	temp.u32 = ctx.r9.u32 & 0x3F;
	if (temp.u32 > 0x1F) temp.u32 = 0x1F;
	ctx.xer.ca = (ctx.r11.s32 < 0) & (((ctx.r11.s32 >> temp.u32) << temp.u32) != ctx.r11.s32);
	ctx.r9.s64 = ctx.r11.s32 >> temp.u32;
	// rlwinm r11,r10,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r10,r9,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lfd f13,8(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// lfd f11,8(r10)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r10.u32 + 8);
	// lfd f0,0(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// fmul f10,f11,f13
	ctx.f10.f64 = ctx.f11.f64 * ctx.f13.f64;
	// fmul f11,f11,f0
	ctx.f11.f64 = ctx.f11.f64 * ctx.f0.f64;
	// lfd f12,0(r10)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// fmsub f0,f12,f0,f10
	ctx.f0.f64 = ctx.f12.f64 * ctx.f0.f64 - ctx.f10.f64;
	// stfd f0,0(r5)
	PPC_STORE_U64(ctx.r5.u32 + 0, ctx.f0.u64);
	// fmadd f0,f12,f13,f11
	ctx.f0.f64 = ctx.f12.f64 * ctx.f13.f64 + ctx.f11.f64;
	// stfd f0,8(r5)
	PPC_STORE_U64(ctx.r5.u32 + 8, ctx.f0.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D22018"))) PPC_WEAK_FUNC(sub_82D22018);
PPC_FUNC_IMPL(__imp__sub_82D22018) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// cntlzw r11,r4
	ctx.r11.u64 = ctx.r4.u32 == 0 ? 32 : __builtin_clz(ctx.r4.u32);
	// lwz r10,32(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// lwz r9,12(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// lwz r5,20(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r6,24(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// lwz r8,28(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// add r11,r11,r4
	ctx.r11.u64 = ctx.r11.u64 + ctx.r4.u64;
	// and r10,r5,r11
	ctx.r10.u64 = ctx.r5.u64 & ctx.r11.u64;
	// sraw r9,r11,r9
	temp.u32 = ctx.r9.u32 & 0x3F;
	if (temp.u32 > 0x1F) temp.u32 = 0x1F;
	ctx.xer.ca = (ctx.r11.s32 < 0) & (((ctx.r11.s32 >> temp.u32) << temp.u32) != ctx.r11.s32);
	ctx.r9.s64 = ctx.r11.s32 >> temp.u32;
	// rlwinm r11,r10,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r10,r9,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r6
	ctx.r11.u64 = ctx.r11.u64 + ctx.r6.u64;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lfd f13,8(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// lfd f11,8(r10)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r10.u32 + 8);
	// lfd f0,0(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// fmul f10,f11,f13
	ctx.f10.f64 = ctx.f11.f64 * ctx.f13.f64;
	// fmul f11,f11,f0
	ctx.f11.f64 = ctx.f11.f64 * ctx.f0.f64;
	// lfd f12,0(r10)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// fmsub f0,f12,f0,f10
	ctx.f0.f64 = ctx.f12.f64 * ctx.f0.f64 - ctx.f10.f64;
	// fmadd f13,f12,f13,f11
	ctx.f13.f64 = ctx.f12.f64 * ctx.f13.f64 + ctx.f11.f64;
	// fmul f12,f1,f0
	ctx.f12.f64 = ctx.f1.f64 * ctx.f0.f64;
	// fmul f11,f1,f13
	ctx.f11.f64 = ctx.f1.f64 * ctx.f13.f64;
	// fmadd f13,f2,f13,f12
	ctx.f13.f64 = ctx.f2.f64 * ctx.f13.f64 + ctx.f12.f64;
	// fmsub f0,f2,f0,f11
	ctx.f0.f64 = ctx.f2.f64 * ctx.f0.f64 - ctx.f11.f64;
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// stfs f13,0(r7)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,4(r7)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 4, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D220A0"))) PPC_WEAK_FUNC(sub_82D220A0);
PPC_FUNC_IMPL(__imp__sub_82D220A0) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// lwz r4,32(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// b 0x82d21e70
	sub_82D21E70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D220B0"))) PPC_WEAK_FUNC(sub_82D220B0);
PPC_FUNC_IMPL(__imp__sub_82D220B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f0,-13892(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13892);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// stfs f0,4(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 4, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D220C8"))) PPC_WEAK_FUNC(sub_82D220C8);
PPC_FUNC_IMPL(__imp__sub_82D220C8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfd f0,-11432(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -11432);
	// stfd f0,0(r5)
	PPC_STORE_U64(ctx.r5.u32 + 0, ctx.f0.u64);
	// stfd f0,8(r5)
	PPC_STORE_U64(ctx.r5.u32 + 8, ctx.f0.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D220E0"))) PPC_WEAK_FUNC(sub_82D220E0);
PPC_FUNC_IMPL(__imp__sub_82D220E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D22104;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// stfs f0,0(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// stfs f13,4(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 4, temp.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D22130"))) PPC_WEAK_FUNC(sub_82D22130);
PPC_FUNC_IMPL(__imp__sub_82D22130) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stfd f30,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, ctx.f30.u64);
	// stfd f31,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// fmr f31,f1
	ctx.f31.f64 = ctx.f1.f64;
	// fmr f30,f2
	ctx.f30.f64 = ctx.f2.f64;
	// mr r31,r7
	ctx.r31.u64 = ctx.r7.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D22164;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lfd f13,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// lfd f0,-7240(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -7240);
	// fmul f0,f13,f0
	ctx.f0.f64 = ctx.f13.f64 * ctx.f0.f64;
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fmul f12,f30,f13
	ctx.f12.f64 = ctx.f30.f64 * ctx.f13.f64;
	// fmul f11,f30,f0
	ctx.f11.f64 = ctx.f30.f64 * ctx.f0.f64;
	// fmadd f0,f31,f0,f12
	ctx.f0.f64 = ctx.f31.f64 * ctx.f0.f64 + ctx.f12.f64;
	// fmsub f13,f31,f13,f11
	ctx.f13.f64 = ctx.f31.f64 * ctx.f13.f64 - ctx.f11.f64;
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,4(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 4, temp.u32);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// stfs f13,0(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// lfd f30,-32(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// lfd f31,-24(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D221B8"))) PPC_WEAK_FUNC(sub_82D221B8);
PPC_FUNC_IMPL(__imp__sub_82D221B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82D221C0;
	__savegprlr_25(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r3,36
	ctx.r3.s64 = 36;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// bl 0x82d0c438
	ctx.lr = 0x82D221D4;
	sub_82D0C438(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r25,0
	ctx.r25.s64 = 0;
	// cmpwi cr6,r30,1
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 1, ctx.xer);
	// stw r28,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r28.u32);
	// stw r25,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r25.u32);
	// stw r25,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r25.u32);
	// stw r25,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r25.u32);
	// stw r25,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r25.u32);
	// beq cr6,0x82d22314
	if (ctx.cr6.eq) goto loc_82D22314;
	// cmpwi cr6,r30,2
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 2, ctx.xer);
	// beq cr6,0x82d22218
	if (ctx.cr6.eq) goto loc_82D22218;
	// cmpwi cr6,r30,3
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 3, ctx.xer);
	// bne cr6,0x82d22338
	if (!ctx.cr6.eq) goto loc_82D22338;
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// addi r11,r11,8352
	ctx.r11.s64 = ctx.r11.s64 + 8352;
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// b 0x82d22338
	goto loc_82D22338;
loc_82D22218:
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// ble cr6,0x82d22238
	if (!ctx.cr6.gt) goto loc_82D22238;
loc_82D22228:
	// srawi r10,r10,2
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 2;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addze. r10,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bgt 0x82d22228
	if (ctx.cr0.gt) goto loc_82D22228;
loc_82D22238:
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
	// slw r30,r10,r11
	ctx.r30.u64 = ctx.r11.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r11.u8 & 0x3F));
	// addi r11,r30,-1
	ctx.r11.s64 = ctx.r30.s64 + -1;
	// rlwinm r3,r30,4,0,27
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 4) & 0xFFFFFFF0;
	// twllei r30,0
	// stw r30,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r30.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// add r11,r30,r28
	ctx.r11.u64 = ctx.r30.u64 + ctx.r28.u64;
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// rotlwi r11,r10,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 1);
	// divw r26,r10,r30
	ctx.r26.s32 = ctx.r10.s32 / ctx.r30.s32;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// andc r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 & ~ctx.r11.u64;
	// twlgei r11,-1
	// bl 0x82d0c438
	ctx.lr = 0x82D22278;
	sub_82D0C438(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// rlwinm r3,r26,4,0,27
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 4) & 0xFFFFFFF0;
	// stw r11,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r11.u32);
	// bl 0x82d0c438
	ctx.lr = 0x82D22288;
	sub_82D0C438(ctx, base);
	// mr r29,r25
	ctx.r29.u64 = ctx.r25.u64;
	// stw r3,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r3.u32);
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82d222c0
	if (!ctx.cr6.gt) goto loc_82D222C0;
	// mr r27,r25
	ctx.r27.u64 = ctx.r25.u64;
loc_82D2229C:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// add r5,r27,r11
	ctx.r5.u64 = ctx.r27.u64 + ctx.r11.u64;
	// bl 0x82d21e70
	ctx.lr = 0x82D222B0;
	sub_82D21E70(ctx, base);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r27,r27,16
	ctx.r27.s64 = ctx.r27.s64 + 16;
	// cmpw cr6,r29,r30
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r30.s32, ctx.xer);
	// blt cr6,0x82d2229c
	if (ctx.cr6.lt) goto loc_82D2229C;
loc_82D222C0:
	// mr r30,r25
	ctx.r30.u64 = ctx.r25.u64;
	// cmpwi cr6,r26,0
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// ble cr6,0x82d222f8
	if (!ctx.cr6.gt) goto loc_82D222F8;
	// mr r29,r25
	ctx.r29.u64 = ctx.r25.u64;
loc_82D222D0:
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// add r5,r11,r29
	ctx.r5.u64 = ctx.r11.u64 + ctx.r29.u64;
	// mullw r3,r10,r30
	ctx.r3.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r30.s32);
	// bl 0x82d21e70
	ctx.lr = 0x82D222E8;
	sub_82D21E70(ctx, base);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// addi r29,r29,16
	ctx.r29.s64 = ctx.r29.s64 + 16;
	// cmpw cr6,r30,r26
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r26.s32, ctx.xer);
	// blt cr6,0x82d222d0
	if (ctx.cr6.lt) goto loc_82D222D0;
loc_82D222F8:
	// lis r10,-32046
	ctx.r10.s64 = -2100166656;
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// addi r10,r10,8104
	ctx.r10.s64 = ctx.r10.s64 + 8104;
	// addi r11,r11,8216
	ctx.r11.s64 = ctx.r11.s64 + 8216;
	// stw r10,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r10.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// b 0x82d2232c
	goto loc_82D2232C;
loc_82D22314:
	// lis r10,-32046
	ctx.r10.s64 = -2100166656;
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// addi r10,r10,8368
	ctx.r10.s64 = ctx.r10.s64 + 8368;
	// addi r11,r11,8392
	ctx.r11.s64 = ctx.r11.s64 + 8392;
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
loc_82D2232C:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82d22344
	if (!ctx.cr6.eq) goto loc_82D22344;
loc_82D22338:
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// addi r11,r11,8416
	ctx.r11.s64 = ctx.r11.s64 + 8416;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
loc_82D22344:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82d2235c
	if (!ctx.cr6.eq) goto loc_82D2235C;
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// addi r11,r11,8496
	ctx.r11.s64 = ctx.r11.s64 + 8496;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
loc_82D2235C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D22368"))) PPC_WEAK_FUNC(sub_82D22368);
PPC_FUNC_IMPL(__imp__sub_82D22368) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// bl 0x82d0c498
	ctx.lr = 0x82D22384;
	sub_82D0C498(ctx, base);
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// bl 0x82d0c498
	ctx.lr = 0x82D2238C;
	sub_82D0C498(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d0c490
	ctx.lr = 0x82D22394;
	sub_82D0C490(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D223A8"))) PPC_WEAK_FUNC(sub_82D223A8);
PPC_FUNC_IMPL(__imp__sub_82D223A8) {
	PPC_FUNC_PROLOGUE();
	// lwz r7,24(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// lwz r6,20(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// lwz r5,16(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// lwz r4,12(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
}

__attribute__((alias("__imp__sub_82D223C8"))) PPC_WEAK_FUNC(sub_82D223C8);
PPC_FUNC_IMPL(__imp__sub_82D223C8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// bl 0x82d0c2a0
	ctx.lr = 0x82D223E0;
	sub_82D0C2A0(ctx, base);
	// stw r31,56(r3)
	PPC_STORE_U32(ctx.r3.u32 + 56, ctx.r31.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D223F8"))) PPC_WEAK_FUNC(sub_82D223F8);
PPC_FUNC_IMPL(__imp__sub_82D223F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// cmpwi cr6,r8,1
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 1, ctx.xer);
	// beq cr6,0x82d22460
	if (ctx.cr6.eq) goto loc_82D22460;
	// cmpwi cr6,r8,2
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 2, ctx.xer);
	// beq cr6,0x82d22488
	if (ctx.cr6.eq) goto loc_82D22488;
	// cmpwi cr6,r8,4
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 4, ctx.xer);
	// beq cr6,0x82d224b0
	if (ctx.cr6.eq) goto loc_82D224B0;
	// cmpwi cr6,r5,0
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// blelr cr6
	if (!ctx.cr6.gt) return;
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D22420:
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// ble cr6,0x82d2244c
	if (!ctx.cr6.gt) goto loc_82D2244C;
	// mr r9,r4
	ctx.r9.u64 = ctx.r4.u64;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// mr r11,r8
	ctx.r11.u64 = ctx.r8.u64;
loc_82D22434:
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stfs f0,0(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82d22434
	if (!ctx.cr0.eq) goto loc_82D22434;
loc_82D2244C:
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// add r4,r4,r7
	ctx.r4.u64 = ctx.r4.u64 + ctx.r7.u64;
	// add r3,r3,r6
	ctx.r3.u64 = ctx.r3.u64 + ctx.r6.u64;
	// bne 0x82d22420
	if (!ctx.cr0.eq) goto loc_82D22420;
	// blr 
	return;
loc_82D22460:
	// clrlwi. r11,r5,31
	ctx.r11.u64 = ctx.r5.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82d22528
	if (!ctx.cr0.eq) goto loc_82D22528;
	// cmpwi cr6,r6,1
	ctx.cr6.compare<int32_t>(ctx.r6.s32, 1, ctx.xer);
	// bne cr6,0x82d22528
	if (!ctx.cr6.eq) goto loc_82D22528;
	// cmpwi cr6,r7,1
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 1, ctx.xer);
	// bne cr6,0x82d22528
	if (!ctx.cr6.eq) goto loc_82D22528;
	// srawi r11,r5,1
	ctx.xer.ca = (ctx.r5.s32 < 0) & ((ctx.r5.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r5.s32 >> 1;
	// li r6,2
	ctx.r6.s64 = 2;
	// addze r5,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r5.s64 = temp.s64;
	// li r7,2
	ctx.r7.s64 = 2;
loc_82D22488:
	// clrlwi. r11,r5,31
	ctx.r11.u64 = ctx.r5.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82d224f4
	if (!ctx.cr0.eq) goto loc_82D224F4;
	// cmpwi cr6,r6,2
	ctx.cr6.compare<int32_t>(ctx.r6.s32, 2, ctx.xer);
	// bne cr6,0x82d224f4
	if (!ctx.cr6.eq) goto loc_82D224F4;
	// cmpwi cr6,r7,2
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 2, ctx.xer);
	// bne cr6,0x82d224f4
	if (!ctx.cr6.eq) goto loc_82D224F4;
	// srawi r11,r5,1
	ctx.xer.ca = (ctx.r5.s32 < 0) & ((ctx.r5.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r5.s32 >> 1;
	// li r6,4
	ctx.r6.s64 = 4;
	// addze r5,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r5.s64 = temp.s64;
	// li r7,4
	ctx.r7.s64 = 4;
loc_82D224B0:
	// cmpwi cr6,r5,0
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// blelr cr6
	if (!ctx.cr6.gt) return;
	// rlwinm r11,r6,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D224C0:
	// lfs f0,4(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// lfs f13,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// add r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfs f0,4(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 4, temp.u32);
	// stfs f13,8(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 8, temp.u32);
	// stfs f12,12(r4)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + 12, temp.u32);
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// bgt 0x82d224c0
	if (ctx.cr0.gt) goto loc_82D224C0;
	// blr 
	return;
loc_82D224F4:
	// cmpwi cr6,r5,0
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// blelr cr6
	if (!ctx.cr6.gt) return;
	// rlwinm r11,r6,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D22504:
	// lfs f0,4(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// lfs f13,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// add r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
	// stfs f13,0(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfs f0,4(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 4, temp.u32);
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// bgt 0x82d22504
	if (ctx.cr0.gt) goto loc_82D22504;
	// blr 
	return;
loc_82D22528:
	// cmpwi cr6,r5,0
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// blelr cr6
	if (!ctx.cr6.gt) return;
	// rlwinm r11,r6,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D22538:
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// stfs f0,0(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// add r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// bgt 0x82d22538
	if (ctx.cr0.gt) goto loc_82D22538;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D22558"))) PPC_WEAK_FUNC(sub_82D22558);
PPC_FUNC_IMPL(__imp__sub_82D22558) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D22560;
	__savegprlr_24(ctx, base);
	// lwz r24,84(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpwi cr6,r24,1
	ctx.cr6.compare<int32_t>(ctx.r24.s32, 1, ctx.xer);
	// beq cr6,0x82d22658
	if (ctx.cr6.eq) goto loc_82D22658;
	// cmpwi cr6,r24,2
	ctx.cr6.compare<int32_t>(ctx.r24.s32, 2, ctx.xer);
	// beq cr6,0x82d225f8
	if (ctx.cr6.eq) goto loc_82D225F8;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// ble cr6,0x82d226ac
	if (!ctx.cr6.gt) goto loc_82D226AC;
	// li r26,0
	ctx.r26.s64 = 0;
	// li r27,0
	ctx.r27.s64 = 0;
loc_82D22584:
	// cmpwi cr6,r5,0
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// ble cr6,0x82d225e4
	if (!ctx.cr6.gt) goto loc_82D225E4;
	// li r29,0
	ctx.r29.s64 = 0;
	// li r30,0
	ctx.r30.s64 = 0;
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
loc_82D22598:
	// cmpwi cr6,r24,0
	ctx.cr6.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// ble cr6,0x82d225d4
	if (!ctx.cr6.gt) goto loc_82D225D4;
	// add r11,r27,r30
	ctx.r11.u64 = ctx.r27.u64 + ctx.r30.u64;
	// add r28,r26,r29
	ctx.r28.u64 = ctx.r26.u64 + ctx.r29.u64;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r28,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// add r28,r31,r4
	ctx.r28.u64 = ctx.r31.u64 + ctx.r4.u64;
	// add r31,r11,r3
	ctx.r31.u64 = ctx.r11.u64 + ctx.r3.u64;
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
loc_82D225BC:
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stfs f0,0(r28)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r28,r28,4
	ctx.r28.s64 = ctx.r28.s64 + 4;
	// bne 0x82d225bc
	if (!ctx.cr0.eq) goto loc_82D225BC;
loc_82D225D4:
	// addic. r25,r25,-1
	ctx.xer.ca = ctx.r25.u32 > 0;
	ctx.r25.s64 = ctx.r25.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// add r30,r30,r7
	ctx.r30.u64 = ctx.r30.u64 + ctx.r7.u64;
	// add r29,r29,r6
	ctx.r29.u64 = ctx.r29.u64 + ctx.r6.u64;
	// bne 0x82d22598
	if (!ctx.cr0.eq) goto loc_82D22598;
loc_82D225E4:
	// addic. r8,r8,-1
	ctx.xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// add r27,r27,r10
	ctx.r27.u64 = ctx.r27.u64 + ctx.r10.u64;
	// add r26,r26,r9
	ctx.r26.u64 = ctx.r26.u64 + ctx.r9.u64;
	// bne 0x82d22584
	if (!ctx.cr0.eq) goto loc_82D22584;
	// b 0x82d226ac
	goto loc_82D226AC;
loc_82D225F8:
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// ble cr6,0x82d226ac
	if (!ctx.cr6.gt) goto loc_82D226AC;
	// rlwinm r29,r9,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r28,r10,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D22608:
	// cmpwi cr6,r5,0
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// ble cr6,0x82d22644
	if (!ctx.cr6.gt) goto loc_82D22644;
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r30,r6,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r9,r5
	ctx.r9.u64 = ctx.r5.u64;
loc_82D22624:
	// lfs f0,4(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// add r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 + ctx.r11.u64;
	// stfs f13,0(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// stfs f0,4(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// add r10,r31,r10
	ctx.r10.u64 = ctx.r31.u64 + ctx.r10.u64;
	// bne 0x82d22624
	if (!ctx.cr0.eq) goto loc_82D22624;
loc_82D22644:
	// addic. r8,r8,-1
	ctx.xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// add r4,r28,r4
	ctx.r4.u64 = ctx.r28.u64 + ctx.r4.u64;
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// bne 0x82d22608
	if (!ctx.cr0.eq) goto loc_82D22608;
	// b 0x82d226ac
	goto loc_82D226AC;
loc_82D22658:
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// ble cr6,0x82d226ac
	if (!ctx.cr6.gt) goto loc_82D226AC;
	// rlwinm r29,r9,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r28,r10,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D22668:
	// cmpwi cr6,r5,0
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// ble cr6,0x82d2269c
	if (!ctx.cr6.gt) goto loc_82D2269C;
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r30,r6,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r9,r4
	ctx.r9.u64 = ctx.r4.u64;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
loc_82D22684:
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stfs f0,0(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// add r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 + ctx.r30.u64;
	// add r9,r9,r31
	ctx.r9.u64 = ctx.r9.u64 + ctx.r31.u64;
	// bne 0x82d22684
	if (!ctx.cr0.eq) goto loc_82D22684;
loc_82D2269C:
	// addic. r8,r8,-1
	ctx.xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// add r4,r28,r4
	ctx.r4.u64 = ctx.r28.u64 + ctx.r4.u64;
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// bne 0x82d22668
	if (!ctx.cr0.eq) goto loc_82D22668;
loc_82D226AC:
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D226B0"))) PPC_WEAK_FUNC(sub_82D226B0);
PPC_FUNC_IMPL(__imp__sub_82D226B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r9
	ctx.r11.u64 = ctx.r9.u64;
	// mr r31,r8
	ctx.r31.u64 = ctx.r8.u64;
	// mr r30,r10
	ctx.r30.u64 = ctx.r10.u64;
	// cmpwi cr6,r6,0
	ctx.cr6.compare<int32_t>(ctx.r6.s32, 0, ctx.xer);
	// neg r9,r6
	ctx.r9.s64 = -ctx.r6.s64;
	// blt cr6,0x82d226e0
	if (ctx.cr6.lt) goto loc_82D226E0;
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
loc_82D226E0:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// neg r10,r11
	ctx.r10.s64 = -ctx.r11.s64;
	// blt cr6,0x82d226f0
	if (ctx.cr6.lt) goto loc_82D226F0;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82D226F0:
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82d22714
	if (!ctx.cr6.lt) goto loc_82D22714;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r11,196(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// mr r8,r31
	ctx.r8.u64 = ctx.r31.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82d22558
	ctx.lr = 0x82D22710;
	sub_82D22558(ctx, base);
	// b 0x82d22738
	goto loc_82D22738;
loc_82D22714:
	// lwz r9,196(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// mr r8,r5
	ctx.r8.u64 = ctx.r5.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
	// bl 0x82d22558
	ctx.lr = 0x82D22738;
	sub_82D22558(ctx, base);
loc_82D22738:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D22750"))) PPC_WEAK_FUNC(sub_82D22750);
PPC_FUNC_IMPL(__imp__sub_82D22750) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r9
	ctx.r30.u64 = ctx.r9.u64;
	// mr r31,r8
	ctx.r31.u64 = ctx.r8.u64;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// neg r9,r7
	ctx.r9.s64 = -ctx.r7.s64;
	// blt cr6,0x82d22780
	if (ctx.cr6.lt) goto loc_82D22780;
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
loc_82D22780:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// neg r10,r11
	ctx.r10.s64 = -ctx.r11.s64;
	// blt cr6,0x82d22790
	if (ctx.cr6.lt) goto loc_82D22790;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82D22790:
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82d227b4
	if (!ctx.cr6.lt) goto loc_82D227B4;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// lwz r11,196(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// mr r8,r31
	ctx.r8.u64 = ctx.r31.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82d22558
	ctx.lr = 0x82D227B0;
	sub_82D22558(ctx, base);
	// b 0x82d227d8
	goto loc_82D227D8;
loc_82D227B4:
	// lwz r9,196(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// mr r8,r5
	ctx.r8.u64 = ctx.r5.u64;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// bl 0x82d22558
	ctx.lr = 0x82D227D8;
	sub_82D22558(ctx, base);
loc_82D227D8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D227F0"))) PPC_WEAK_FUNC(sub_82D227F0);
PPC_FUNC_IMPL(__imp__sub_82D227F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82D227F8;
	__savegprlr_27(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// subf r5,r3,r4
	ctx.r5.s64 = ctx.r4.s64 - ctx.r3.s64;
	// subf r8,r31,r6
	ctx.r8.s64 = ctx.r6.s64 - ctx.r31.s64;
	// lwz r4,24(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mullw r27,r10,r31
	ctx.r27.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r31.s32);
	// lwz r6,8(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r29,4(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r30,0(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r4,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r4.u32);
	// mullw r11,r6,r3
	ctx.r11.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r3.s32);
	// mullw r28,r7,r3
	ctx.r28.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r3.s32);
	// mullw r4,r9,r31
	ctx.r4.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r31.s32);
	// add r11,r11,r4
	ctx.r11.u64 = ctx.r11.u64 + ctx.r4.u64;
	// add r3,r28,r27
	ctx.r3.u64 = ctx.r28.u64 + ctx.r27.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r4,r3,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r11,r30
	ctx.r3.u64 = ctx.r11.u64 + ctx.r30.u64;
	// add r4,r4,r29
	ctx.r4.u64 = ctx.r4.u64 + ctx.r29.u64;
	// bl 0x82d22558
	ctx.lr = 0x82D22858;
	sub_82D22558(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D22860"))) PPC_WEAK_FUNC(sub_82D22860);
PPC_FUNC_IMPL(__imp__sub_82D22860) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82D22868;
	__savegprlr_27(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r7
	ctx.r31.u64 = ctx.r7.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// subf r30,r29,r4
	ctx.r30.s64 = ctx.r4.s64 - ctx.r29.s64;
	// subf r27,r28,r6
	ctx.r27.s64 = ctx.r6.s64 - ctx.r28.s64;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// mullw r10,r11,r29
	ctx.r10.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r29.s32);
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r4,28(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// stw r7,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r7.u32);
	// mullw r8,r9,r28
	ctx.r8.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r28.s32);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// mullw r10,r7,r30
	ctx.r10.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r30.s32);
	// bl 0x82d226b0
	ctx.lr = 0x82D228C0;
	sub_82D226B0(ctx, base);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mullw r9,r10,r28
	ctx.r9.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r28.s32);
	// stw r6,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r6.u32);
	// mullw r11,r7,r29
	ctx.r11.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r29.s32);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mullw r9,r6,r30
	ctx.r9.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r30.s32);
	// add r4,r11,r4
	ctx.r4.u64 = ctx.r11.u64 + ctx.r4.u64;
	// bl 0x82d22750
	ctx.lr = 0x82D228FC;
	sub_82D22750(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D22908"))) PPC_WEAK_FUNC(sub_82D22908);
PPC_FUNC_IMPL(__imp__sub_82D22908) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82D22910;
	__savegprlr_23(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r23,276(r1)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// mr r26,r8
	ctx.r26.u64 = ctx.r8.u64;
	// mr r25,r9
	ctx.r25.u64 = ctx.r9.u64;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
	// bl 0x82d22af0
	ctx.lr = 0x82D22944;
	sub_82D22AF0(ctx, base);
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r31.u32);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r30.u32);
	// addi r8,r11,10224
	ctx.r8.s64 = ctx.r11.s64 + 10224;
	// stw r28,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r28.u32);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r27.u32);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// stw r25,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r25.u32);
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// stw r24,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r24.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r23,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r23.u32);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// bl 0x82d22a28
	ctx.lr = 0x82D2298C;
	sub_82D22A28(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D22998"))) PPC_WEAK_FUNC(sub_82D22998);
PPC_FUNC_IMPL(__imp__sub_82D22998) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82D229A0;
	__savegprlr_23(ctx, base);
	// ld r12,-4096(r1)
	ctx.r12.u64 = PPC_LOAD_U64(ctx.r1.u32 + -4096);
	// stwu r1,-4288(r1)
	ea = -4288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r23,4372(r1)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 4372);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// mr r26,r8
	ctx.r26.u64 = ctx.r8.u64;
	// mr r25,r9
	ctx.r25.u64 = ctx.r9.u64;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
	// bl 0x82d22af0
	ctx.lr = 0x82D229D8;
	sub_82D22AF0(ctx, base);
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r31.u32);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r30.u32);
	// addi r8,r11,10336
	ctx.r8.s64 = ctx.r11.s64 + 10336;
	// stw r28,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r28.u32);
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r27.u32);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// stw r25,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r25.u32);
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// stw r24,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r24.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r23,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r23.u32);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// bl 0x82d22a28
	ctx.lr = 0x82D22A20;
	sub_82D22A28(ctx, base);
	// addi r1,r1,4288
	ctx.r1.s64 = ctx.r1.s64 + 4288;
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D22A28"))) PPC_WEAK_FUNC(sub_82D22A28);
PPC_FUNC_IMPL(__imp__sub_82D22A28) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D22A30;
	__savegprlr_24(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r26,r7
	ctx.r26.u64 = ctx.r7.u64;
	// mr r25,r8
	ctx.r25.u64 = ctx.r8.u64;
	// mr r24,r9
	ctx.r24.u64 = ctx.r9.u64;
loc_82D22A50:
	// subf r11,r30,r29
	ctx.r11.s64 = ctx.r29.s64 - ctx.r30.s64;
	// subf r10,r31,r28
	ctx.r10.s64 = ctx.r28.s64 - ctx.r31.s64;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82d22a9c
	if (ctx.cr6.lt) goto loc_82D22A9C;
	// cmpw cr6,r11,r26
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r26.s32, ctx.xer);
	// ble cr6,0x82d22a9c
	if (!ctx.cr6.gt) goto loc_82D22A9C;
	// add r11,r30,r29
	ctx.r11.u64 = ctx.r30.u64 + ctx.r29.u64;
	// mr r9,r24
	ctx.r9.u64 = ctx.r24.u64;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// addze r27,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r27.s64 = temp.s64;
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// bl 0x82d22a28
	ctx.lr = 0x82D22A94;
	sub_82D22A28(ctx, base);
	// mr r30,r27
	ctx.r30.u64 = ctx.r27.u64;
	// b 0x82d22a50
	goto loc_82D22A50;
loc_82D22A9C:
	// cmpw cr6,r10,r26
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r26.s32, ctx.xer);
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// ble cr6,0x82d22ad8
	if (!ctx.cr6.gt) goto loc_82D22AD8;
	// add r11,r31,r28
	ctx.r11.u64 = ctx.r31.u64 + ctx.r28.u64;
	// mr r9,r24
	ctx.r9.u64 = ctx.r24.u64;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// addze r27,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r27.s64 = temp.s64;
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// bl 0x82d22a28
	ctx.lr = 0x82D22AD0;
	sub_82D22A28(ctx, base);
	// mr r31,r27
	ctx.r31.u64 = ctx.r27.u64;
	// b 0x82d22a50
	goto loc_82D22A50;
loc_82D22AD8:
	// mr r7,r24
	ctx.r7.u64 = ctx.r24.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mtctr r25
	ctx.ctr.u64 = ctx.r25.u64;
	// bctrl 
	ctx.lr = 0x82D22AE8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D22AF0"))) PPC_WEAK_FUNC(sub_82D22AF0);
PPC_FUNC_IMPL(__imp__sub_82D22AF0) {
	PPC_FUNC_PROLOGUE();
	// mullw r11,r3,r4
	ctx.r11.s64 = int64_t(ctx.r3.s32) * int64_t(ctx.r4.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r10,8192
	ctx.r10.s64 = 8192;
	// twllei r11,0
	// divw r3,r10,r11
	ctx.r3.s32 = ctx.r10.s32 / ctx.r11.s32;
	// b 0x82d0eb38
	sub_82D0EB38(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D22B08"))) PPC_WEAK_FUNC(sub_82D22B08);
PPC_FUNC_IMPL(__imp__sub_82D22B08) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82D22B10;
	__savegprlr_27(ctx, base);
	// cmpwi cr6,r7,1
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 1, ctx.xer);
	// beq cr6,0x82d22c30
	if (ctx.cr6.eq) goto loc_82D22C30;
	// cmpwi cr6,r7,2
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 2, ctx.xer);
	// beq cr6,0x82d22bb4
	if (ctx.cr6.eq) goto loc_82D22BB4;
	// li r27,1
	ctx.r27.s64 = 1;
	// cmpwi cr6,r4,1
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 1, ctx.xer);
	// ble cr6,0x82d22c94
	if (!ctx.cr6.gt) goto loc_82D22C94;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
loc_82D22B34:
	// cmpwi cr6,r27,0
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// ble cr6,0x82d22b9c
	if (!ctx.cr6.gt) goto loc_82D22B9C;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r28,r27
	ctx.r28.u64 = ctx.r27.u64;
loc_82D22B48:
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// ble cr6,0x82d22b8c
	if (!ctx.cr6.gt) goto loc_82D22B8C;
	// add r11,r30,r9
	ctx.r11.u64 = ctx.r30.u64 + ctx.r9.u64;
	// add r31,r29,r8
	ctx.r31.u64 = ctx.r29.u64 + ctx.r8.u64;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r31,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// mr r31,r7
	ctx.r31.u64 = ctx.r7.u64;
loc_82D22B6C:
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,0(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82d22b6c
	if (!ctx.cr0.eq) goto loc_82D22B6C;
loc_82D22B8C:
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// add r9,r9,r6
	ctx.r9.u64 = ctx.r9.u64 + ctx.r6.u64;
	// add r8,r8,r5
	ctx.r8.u64 = ctx.r8.u64 + ctx.r5.u64;
	// bne 0x82d22b48
	if (!ctx.cr0.eq) goto loc_82D22B48;
loc_82D22B9C:
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// add r30,r30,r5
	ctx.r30.u64 = ctx.r30.u64 + ctx.r5.u64;
	// add r29,r29,r6
	ctx.r29.u64 = ctx.r29.u64 + ctx.r6.u64;
	// cmpw cr6,r27,r4
	ctx.cr6.compare<int32_t>(ctx.r27.s32, ctx.r4.s32, ctx.xer);
	// blt cr6,0x82d22b34
	if (ctx.cr6.lt) goto loc_82D22B34;
	// b 0x82d22c94
	goto loc_82D22C94;
loc_82D22BB4:
	// li r31,1
	ctx.r31.s64 = 1;
	// cmpwi cr6,r4,1
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 1, ctx.xer);
	// ble cr6,0x82d22c94
	if (!ctx.cr6.gt) goto loc_82D22C94;
	// rlwinm r8,r6,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r7,r5,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// add r5,r8,r3
	ctx.r5.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r6,r7,r3
	ctx.r6.u64 = ctx.r7.u64 + ctx.r3.u64;
loc_82D22BD0:
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// ble cr6,0x82d22c18
	if (!ctx.cr6.gt) goto loc_82D22C18;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
	// mr r9,r31
	ctx.r9.u64 = ctx.r31.u64;
loc_82D22BE4:
	// addi r3,r10,4
	ctx.r3.s64 = ctx.r10.s64 + 4;
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// stfs f11,0(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// add r10,r7,r10
	ctx.r10.u64 = ctx.r7.u64 + ctx.r10.u64;
	// lfs f12,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f13,0(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// stfs f12,4(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 4, temp.u32);
	// add r11,r8,r11
	ctx.r11.u64 = ctx.r8.u64 + ctx.r11.u64;
	// bne 0x82d22be4
	if (!ctx.cr0.eq) goto loc_82D22BE4;
loc_82D22C18:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// add r6,r6,r7
	ctx.r6.u64 = ctx.r6.u64 + ctx.r7.u64;
	// add r5,r5,r8
	ctx.r5.u64 = ctx.r5.u64 + ctx.r8.u64;
	// cmpw cr6,r31,r4
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r4.s32, ctx.xer);
	// blt cr6,0x82d22bd0
	if (ctx.cr6.lt) goto loc_82D22BD0;
	// b 0x82d22c94
	goto loc_82D22C94;
loc_82D22C30:
	// li r31,1
	ctx.r31.s64 = 1;
	// cmpwi cr6,r4,1
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 1, ctx.xer);
	// ble cr6,0x82d22c94
	if (!ctx.cr6.gt) goto loc_82D22C94;
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r6,r3
	ctx.r7.u64 = ctx.r6.u64 + ctx.r3.u64;
	// add r8,r5,r3
	ctx.r8.u64 = ctx.r5.u64 + ctx.r3.u64;
loc_82D22C4C:
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// ble cr6,0x82d22c80
	if (!ctx.cr6.gt) goto loc_82D22C80;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
	// mr r9,r31
	ctx.r9.u64 = ctx.r31.u64;
loc_82D22C60:
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,0(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// add r11,r5,r11
	ctx.r11.u64 = ctx.r5.u64 + ctx.r11.u64;
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// add r10,r6,r10
	ctx.r10.u64 = ctx.r6.u64 + ctx.r10.u64;
	// bne 0x82d22c60
	if (!ctx.cr0.eq) goto loc_82D22C60;
loc_82D22C80:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// add r8,r8,r5
	ctx.r8.u64 = ctx.r8.u64 + ctx.r5.u64;
	// add r7,r7,r6
	ctx.r7.u64 = ctx.r7.u64 + ctx.r6.u64;
	// cmpw cr6,r31,r4
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r4.s32, ctx.xer);
	// blt cr6,0x82d22c4c
	if (ctx.cr6.lt) goto loc_82D22C4C;
loc_82D22C94:
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D22C98"))) PPC_WEAK_FUNC(sub_82D22C98);
PPC_FUNC_IMPL(__imp__sub_82D22C98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D22CA0;
	__savegprlr_26(ctx, base);
	// lwz r27,12(r7)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// lwz r29,0(r7)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// lwz r11,4(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// cmpwi cr6,r27,1
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 1, ctx.xer);
	// lwz r10,8(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// beq cr6,0x82d22de0
	if (ctx.cr6.eq) goto loc_82D22DE0;
	// cmpwi cr6,r27,2
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 2, ctx.xer);
	// beq cr6,0x82d22d50
	if (ctx.cr6.eq) goto loc_82D22D50;
	// cmpw cr6,r5,r6
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r6.s32, ctx.xer);
	// bge cr6,0x82d22e58
	if (!ctx.cr6.lt) goto loc_82D22E58;
	// mullw r30,r10,r5
	ctx.r30.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r5.s32);
	// mullw r31,r11,r5
	ctx.r31.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r5.s32);
	// subf r26,r5,r6
	ctx.r26.s64 = ctx.r6.s64 - ctx.r5.s64;
loc_82D22CD4:
	// cmpw cr6,r3,r4
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r4.s32, ctx.xer);
	// bge cr6,0x82d22d3c
	if (!ctx.cr6.lt) goto loc_82D22D3C;
	// mullw r8,r11,r3
	ctx.r8.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r3.s32);
	// mullw r9,r10,r3
	ctx.r9.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r3.s32);
	// subf r28,r3,r4
	ctx.r28.s64 = ctx.r4.s64 - ctx.r3.s64;
loc_82D22CE8:
	// cmpwi cr6,r27,0
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// ble cr6,0x82d22d2c
	if (!ctx.cr6.gt) goto loc_82D22D2C;
	// add r7,r31,r9
	ctx.r7.u64 = ctx.r31.u64 + ctx.r9.u64;
	// add r5,r30,r8
	ctx.r5.u64 = ctx.r30.u64 + ctx.r8.u64;
	// rlwinm r6,r7,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r7,r5,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// add r6,r6,r29
	ctx.r6.u64 = ctx.r6.u64 + ctx.r29.u64;
	// add r7,r7,r29
	ctx.r7.u64 = ctx.r7.u64 + ctx.r29.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
loc_82D22D0C:
	// lfs f0,0(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// lfs f13,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,0(r7)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// bne 0x82d22d0c
	if (!ctx.cr0.eq) goto loc_82D22D0C;
loc_82D22D2C:
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// add r8,r8,r11
	ctx.r8.u64 = ctx.r8.u64 + ctx.r11.u64;
	// bne 0x82d22ce8
	if (!ctx.cr0.eq) goto loc_82D22CE8;
loc_82D22D3C:
	// addic. r26,r26,-1
	ctx.xer.ca = ctx.r26.u32 > 0;
	ctx.r26.s64 = ctx.r26.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// add r31,r31,r11
	ctx.r31.u64 = ctx.r31.u64 + ctx.r11.u64;
	// add r30,r30,r10
	ctx.r30.u64 = ctx.r30.u64 + ctx.r10.u64;
	// bne 0x82d22cd4
	if (!ctx.cr0.eq) goto loc_82D22CD4;
	// b 0x82d22e58
	goto loc_82D22E58;
loc_82D22D50:
	// cmpw cr6,r5,r6
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r6.s32, ctx.xer);
	// bge cr6,0x82d22e58
	if (!ctx.cr6.lt) goto loc_82D22E58;
	// mullw r30,r10,r5
	ctx.r30.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r5.s32);
	// mullw r31,r11,r5
	ctx.r31.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r5.s32);
	// subf r27,r5,r6
	ctx.r27.s64 = ctx.r6.s64 - ctx.r5.s64;
loc_82D22D64:
	// cmpw cr6,r3,r4
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r4.s32, ctx.xer);
	// bge cr6,0x82d22dcc
	if (!ctx.cr6.lt) goto loc_82D22DCC;
	// mullw r8,r10,r3
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r3.s32);
	// mullw r9,r11,r3
	ctx.r9.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r3.s32);
	// add r8,r8,r31
	ctx.r8.u64 = ctx.r8.u64 + ctx.r31.u64;
	// add r7,r9,r30
	ctx.r7.u64 = ctx.r9.u64 + ctx.r30.u64;
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r7,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r6,r10,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r9,r29
	ctx.r9.u64 = ctx.r9.u64 + ctx.r29.u64;
	// add r8,r8,r29
	ctx.r8.u64 = ctx.r8.u64 + ctx.r29.u64;
	// subf r7,r3,r4
	ctx.r7.s64 = ctx.r4.s64 - ctx.r3.s64;
loc_82D22D98:
	// addi r28,r8,4
	ctx.r28.s64 = ctx.r8.s64 + 4;
	// lfs f0,0(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// addic. r7,r7,-1
	ctx.xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// lfs f13,4(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// stfs f11,0(r8)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// add r8,r5,r8
	ctx.r8.u64 = ctx.r5.u64 + ctx.r8.u64;
	// lfs f12,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f13,0(r28)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// stfs f0,0(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// stfs f12,4(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 4, temp.u32);
	// add r9,r6,r9
	ctx.r9.u64 = ctx.r6.u64 + ctx.r9.u64;
	// bne 0x82d22d98
	if (!ctx.cr0.eq) goto loc_82D22D98;
loc_82D22DCC:
	// addic. r27,r27,-1
	ctx.xer.ca = ctx.r27.u32 > 0;
	ctx.r27.s64 = ctx.r27.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// add r31,r31,r11
	ctx.r31.u64 = ctx.r31.u64 + ctx.r11.u64;
	// add r30,r30,r10
	ctx.r30.u64 = ctx.r30.u64 + ctx.r10.u64;
	// bne 0x82d22d64
	if (!ctx.cr0.eq) goto loc_82D22D64;
	// b 0x82d22e58
	goto loc_82D22E58;
loc_82D22DE0:
	// cmpw cr6,r5,r6
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r6.s32, ctx.xer);
	// bge cr6,0x82d22e58
	if (!ctx.cr6.lt) goto loc_82D22E58;
	// mullw r30,r10,r5
	ctx.r30.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r5.s32);
	// mullw r31,r11,r5
	ctx.r31.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r5.s32);
	// subf r28,r5,r6
	ctx.r28.s64 = ctx.r6.s64 - ctx.r5.s64;
loc_82D22DF4:
	// cmpw cr6,r3,r4
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r4.s32, ctx.xer);
	// bge cr6,0x82d22e48
	if (!ctx.cr6.lt) goto loc_82D22E48;
	// mullw r8,r10,r3
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r3.s32);
	// mullw r9,r11,r3
	ctx.r9.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r3.s32);
	// add r8,r8,r31
	ctx.r8.u64 = ctx.r8.u64 + ctx.r31.u64;
	// add r9,r9,r30
	ctx.r9.u64 = ctx.r9.u64 + ctx.r30.u64;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r6,r10,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r8,r8,r29
	ctx.r8.u64 = ctx.r8.u64 + ctx.r29.u64;
	// add r9,r9,r29
	ctx.r9.u64 = ctx.r9.u64 + ctx.r29.u64;
	// subf r7,r3,r4
	ctx.r7.s64 = ctx.r4.s64 - ctx.r3.s64;
loc_82D22E28:
	// lfs f0,0(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r7,r7,-1
	ctx.xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// lfs f13,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,0(r9)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// add r9,r5,r9
	ctx.r9.u64 = ctx.r5.u64 + ctx.r9.u64;
	// stfs f0,0(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// add r8,r6,r8
	ctx.r8.u64 = ctx.r6.u64 + ctx.r8.u64;
	// bne 0x82d22e28
	if (!ctx.cr0.eq) goto loc_82D22E28;
loc_82D22E48:
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// add r31,r31,r11
	ctx.r31.u64 = ctx.r31.u64 + ctx.r11.u64;
	// add r30,r30,r10
	ctx.r30.u64 = ctx.r30.u64 + ctx.r10.u64;
	// bne 0x82d22df4
	if (!ctx.cr0.eq) goto loc_82D22DF4;
loc_82D22E58:
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D22E60"))) PPC_WEAK_FUNC(sub_82D22E60);
PPC_FUNC_IMPL(__imp__sub_82D22E60) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82D22E68;
	__savegprlr_27(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r7
	ctx.r31.u64 = ctx.r7.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// subf r27,r28,r6
	ctx.r27.s64 = ctx.r6.s64 - ctx.r28.s64;
	// subf r30,r29,r4
	ctx.r30.s64 = ctx.r4.s64 - ctx.r29.s64;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mullw r10,r9,r28
	ctx.r10.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r28.s32);
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// stw r7,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r7.u32);
	// mullw r11,r6,r29
	ctx.r11.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r29.s32);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mullw r10,r7,r30
	ctx.r10.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r30.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
	// bl 0x82d226b0
	ctx.lr = 0x82D22EBC;
	sub_82D226B0(ctx, base);
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r6,8(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// mullw r10,r9,r28
	ctx.r10.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r28.s32);
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// stw r7,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r7.u32);
	// mullw r11,r6,r29
	ctx.r11.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r29.s32);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mullw r10,r7,r30
	ctx.r10.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r30.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
	// bl 0x82d226b0
	ctx.lr = 0x82D22EF8;
	sub_82D226B0(ctx, base);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r7,4(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// mullw r9,r10,r28
	ctx.r9.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r28.s32);
	// lwz r6,12(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// stw r6,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r6.u32);
	// mullw r11,r7,r29
	ctx.r11.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r29.s32);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mullw r9,r6,r30
	ctx.r9.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r30.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r11,r4
	ctx.r4.u64 = ctx.r11.u64 + ctx.r4.u64;
	// bl 0x82d22750
	ctx.lr = 0x82D22F34;
	sub_82D22750(ctx, base);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// mullw r9,r10,r28
	ctx.r9.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r28.s32);
	// lwz r6,12(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// stw r6,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r6.u32);
	// mullw r11,r7,r29
	ctx.r11.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r29.s32);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mullw r9,r6,r30
	ctx.r9.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r30.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r11,r4
	ctx.r4.u64 = ctx.r11.u64 + ctx.r4.u64;
	// bl 0x82d22750
	ctx.lr = 0x82D22F70;
	sub_82D22750(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D22F78"))) PPC_WEAK_FUNC(sub_82D22F78);
PPC_FUNC_IMPL(__imp__sub_82D22F78) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82D22F80;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// b 0x82d22ff4
	goto loc_82D22FF4;
loc_82D22F98:
	// srawi r11,r29,1
	ctx.xer.ca = (ctx.r29.s32 < 0) & ((ctx.r29.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r29.s32 >> 1;
	// lwz r7,16(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// mr r9,r31
	ctx.r9.u64 = ctx.r31.u64;
	// stw r28,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r28.u32);
	// addze r30,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r30.s64 = temp.s64;
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82d22a28
	ctx.lr = 0x82D22FC4;
	sub_82D22A28(ctx, base);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82d22f78
	ctx.lr = 0x82D22FD8;
	sub_82D22F78(ctx, base);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// subf r29,r30,r29
	ctx.r29.s64 = ctx.r29.s64 - ctx.r30.s64;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mullw r11,r11,r30
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r30.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r28,r11,r28
	ctx.r28.u64 = ctx.r11.u64 + ctx.r28.u64;
loc_82D22FF4:
	// cmpwi cr6,r29,1
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 1, ctx.xer);
	// bgt cr6,0x82d22f98
	if (ctx.cr6.gt) goto loc_82D22F98;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D23008"))) PPC_WEAK_FUNC(sub_82D23008);
PPC_FUNC_IMPL(__imp__sub_82D23008) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// stw r6,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r6.u32);
	// li r4,2
	ctx.r4.s64 = 2;
	// stw r7,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r7.u32);
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82d22af0
	ctx.lr = 0x82D2303C;
	sub_82D22AF0(ctx, base);
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// stw r3,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r3.u32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r11,11416
	ctx.r5.s64 = ctx.r11.s64 + 11416;
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r11.u32);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
	// bl 0x82d22f78
	ctx.lr = 0x82D23064;
	sub_82D22F78(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D23080"))) PPC_WEAK_FUNC(sub_82D23080);
PPC_FUNC_IMPL(__imp__sub_82D23080) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// ld r12,-4096(r1)
	ctx.r12.u64 = PPC_LOAD_U64(ctx.r1.u32 + -4096);
	// ld r12,-8192(r1)
	ctx.r12.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8192);
	// stwu r1,-8336(r1)
	ea = -8336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// stw r6,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r6.u32);
	// li r4,2
	ctx.r4.s64 = 2;
	// stw r7,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r7.u32);
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82d22af0
	ctx.lr = 0x82D230BC;
	sub_82D22AF0(ctx, base);
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// stw r3,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r3.u32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r11,11872
	ctx.r5.s64 = ctx.r11.s64 + 11872;
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
	// addi r11,r1,4208
	ctx.r11.s64 = ctx.r1.s64 + 4208;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r11.u32);
	// bl 0x82d22f78
	ctx.lr = 0x82D230E8;
	sub_82D22F78(ctx, base);
	// addi r1,r1,8336
	ctx.r1.s64 = ctx.r1.s64 + 8336;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D23100"))) PPC_WEAK_FUNC(sub_82D23100);
PPC_FUNC_IMPL(__imp__sub_82D23100) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82D23108;
	__savegprlr_25(ctx, base);
	// addi r12,r1,-64
	ctx.r12.s64 = ctx.r1.s64 + -64;
	// bl 0x82e28f10
	ctx.lr = 0x82D23110;
	__savefpr_26(ctx, base);
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// ble cr6,0x82d23290
	if (!ctx.cr6.gt) goto loc_82D23290;
	// rlwinm r26,r8,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r25,r9,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lis r29,-32236
	ctx.r29.s64 = -2112618496;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r7,-32229
	ctx.r7.s64 = -2112159744;
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lfs f29,-8128(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8128);
	ctx.f29.f64 = double(temp.f32);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lfs f30,124(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 124);
	ctx.f30.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f31,-8132(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8132);
	ctx.f31.f64 = double(temp.f32);
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f1,-8136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8136);
	ctx.f1.f64 = double(temp.f32);
	// lfs f27,-13884(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -13884);
	ctx.f27.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f28,120(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 120);
	ctx.f28.f64 = double(temp.f32);
	// lfs f2,-8140(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8140);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,-8144(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8144);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f4.f64 = double(temp.f32);
loc_82D23170:
	// rlwinm r11,r5,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// mulli r10,r5,20
	ctx.r10.s64 = ctx.r5.s64 * 20;
	// lfsx f13,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f13.f64 = double(temp.f32);
	// lfsx f12,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f6,f13,f12
	ctx.f6.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// rlwinm r11,r5,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// mulli r10,r5,24
	ctx.r10.s64 = ctx.r5.s64 * 24;
	// lfsx f11,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f12,f11,f10
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// mulli r11,r5,28
	ctx.r11.s64 = ctx.r5.s64 * 28;
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// lfsx f9,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f10,f0,f9
	ctx.f10.f64 = double(float(ctx.f0.f64 - ctx.f9.f64));
	// rlwinm r11,r5,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f0,f9,f0
	ctx.f0.f64 = double(float(ctx.f9.f64 + ctx.f0.f64));
	// mulli r10,r5,12
	ctx.r10.s64 = ctx.r5.s64 * 12;
	// lfsx f8,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f9,f8,f7
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// mulli r11,r6,12
	ctx.r11.s64 = ctx.r6.s64 * 12;
	// fadds f7,f12,f6
	ctx.f7.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
	// fsubs f6,f6,f12
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// fadds f12,f13,f11
	ctx.f12.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// mulli r10,r6,20
	ctx.r10.s64 = ctx.r6.s64 * 20;
	// fmuls f11,f7,f4
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f4.f64));
	// fmuls f7,f6,f4
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// fadds f6,f8,f0
	ctx.f6.f64 = double(float(ctx.f8.f64 + ctx.f0.f64));
	// fsubs f0,f0,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f8.f64));
	// fmuls f26,f13,f29
	ctx.f26.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// rlwinm r9,r6,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r8,r6,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r7,r6,28
	ctx.r7.s64 = ctx.r6.s64 * 28;
	// fsubs f8,f10,f11
	ctx.f8.f64 = double(float(ctx.f10.f64 - ctx.f11.f64));
	// fadds f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// fsubs f5,f7,f9
	ctx.f5.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// fadds f10,f7,f9
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fmuls f7,f0,f29
	ctx.f7.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// fsubs f9,f6,f12
	ctx.f9.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// rlwinm r31,r6,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f12,f12,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
	// mulli r30,r6,24
	ctx.r30.s64 = ctx.r6.s64 * 24;
	// fmsubs f0,f0,f30,f26
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f30.f64 - ctx.f26.f64));
	// fmuls f26,f11,f31
	ctx.f26.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fmuls f6,f5,f3
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// fmadds f13,f13,f30,f7
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64 + ctx.f7.f64));
	// add r3,r26,r3
	ctx.r3.u64 = ctx.r26.u64 + ctx.r3.u64;
	// fmuls f7,f5,f2
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// fmuls f5,f10,f31
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f9,f9,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f12,f12,f27
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f27.f64));
	// fmsubs f7,f8,f3,f7
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f3.f64 - ctx.f7.f64));
	// stfsx f7,r11,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fmadds f8,f8,f2,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f2.f64 + ctx.f6.f64));
	// stfsx f8,r10,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfsx f9,r9,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfs f12,0(r4)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmsubs f12,f11,f1,f5
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 - ctx.f5.f64));
	// stfsx f12,r8,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f10,f1,f26
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f1.f64 + ctx.f26.f64));
	// stfsx f12,r7,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// stfsx f0,r31,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// stfsx f13,r30,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,3532(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 3532);
	// add r4,r25,r4
	ctx.r4.u64 = ctx.r25.u64 + ctx.r4.u64;
	// xor r5,r11,r5
	ctx.r5.u64 = ctx.r11.u64 ^ ctx.r5.u64;
	// xor r6,r11,r6
	ctx.r6.u64 = ctx.r11.u64 ^ ctx.r6.u64;
	// bdnz 0x82d23170
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D23170;
loc_82D23290:
	// addi r12,r1,-64
	ctx.r12.s64 = ctx.r1.s64 + -64;
	// bl 0x82e28f5c
	ctx.lr = 0x82D23298;
	__restfpr_26(ctx, base);
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D232A0"))) PPC_WEAK_FUNC(sub_82D232A0);
PPC_FUNC_IMPL(__imp__sub_82D232A0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-8192
	ctx.r5.s64 = ctx.r11.s64 + -8192;
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// addi r4,r11,12544
	ctx.r4.s64 = ctx.r11.s64 + 12544;
	// b 0x82d77e58
	sub_82D77E58(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D232B8"))) PPC_WEAK_FUNC(sub_82D232B8);
PPC_FUNC_IMPL(__imp__sub_82D232B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D232C0;
	__savegprlr_26(ctx, base);
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28f10
	ctx.lr = 0x82D232C8;
	__savefpr_26(ctx, base);
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// ble cr6,0x82d2343c
	if (!ctx.cr6.gt) goto loc_82D2343C;
	// rlwinm r27,r8,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r26,r9,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lis r9,-32236
	ctx.r9.s64 = -2112618496;
	// lfs f29,-8144(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -8144);
	ctx.f29.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f30,-8140(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8140);
	ctx.f30.f64 = double(temp.f32);
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f31,-8132(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8132);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,-8136(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -8136);
	ctx.f1.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f2,140(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 140);
	ctx.f2.f64 = double(temp.f32);
	// lfs f28,120(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 120);
	ctx.f28.f64 = double(temp.f32);
	// lfs f3,-8128(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8128);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,124(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 124);
	ctx.f4.f64 = double(temp.f32);
loc_82D23320:
	// mulli r11,r5,20
	ctx.r11.s64 = ctx.r5.s64 * 20;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// mulli r10,r5,12
	ctx.r10.s64 = ctx.r5.s64 * 12;
	// lfsx f13,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f13.f64 = double(temp.f32);
	// lfsx f12,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// fadds f6,f12,f13
	ctx.f6.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// rlwinm r11,r5,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f12,f13,f12
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// mulli r10,r5,24
	ctx.r10.s64 = ctx.r5.s64 * 24;
	// lfsx f11,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f5,f10,f3
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// rlwinm r11,r5,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f13,f6,f2
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// fmuls f6,f10,f4
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// mulli r10,r5,28
	ctx.r10.s64 = ctx.r5.s64 * 28;
	// fmuls f12,f12,f2
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// lfsx f9,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// rlwinm r11,r5,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 4) & 0xFFFFFFF0;
	// fmadds f10,f11,f4,f5
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f4.f64 + ctx.f5.f64));
	// mulli r10,r6,28
	ctx.r10.s64 = ctx.r6.s64 * 28;
	// fmsubs f11,f11,f3,f6
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 - ctx.f6.f64));
	// fsubs f5,f12,f8
	ctx.f5.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// fadds f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// lfsx f7,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// mulli r11,r6,20
	ctx.r11.s64 = ctx.r6.s64 * 20;
	// fmuls f26,f12,f30
	ctx.f26.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fadds f6,f7,f0
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f0.f64));
	// rlwinm r9,r6,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f0,f0,f7
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f7.f64));
	// rlwinm r8,r6,4,0,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f7,f13,f9
	ctx.f7.f64 = double(float(ctx.f13.f64 + ctx.f9.f64));
	// mulli r7,r6,12
	ctx.r7.s64 = ctx.r6.s64 * 12;
	// fsubs f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// fadds f9,f6,f10
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// mulli r31,r6,24
	ctx.r31.s64 = ctx.r6.s64 * 24;
	// fsubs f8,f0,f11
	ctx.f8.f64 = double(float(ctx.f0.f64 - ctx.f11.f64));
	// fadds f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// fmuls f11,f5,f31
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fsubs f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 - ctx.f10.f64));
	// fmuls f6,f12,f29
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f29.f64));
	// fmuls f27,f7,f31
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// rlwinm r30,r6,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fmsubs f12,f7,f1,f11
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f1.f64 - ctx.f11.f64));
	// fmadds f11,f13,f30,f6
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f30.f64 + ctx.f6.f64));
	// fmadds f7,f5,f1,f27
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 + ctx.f27.f64));
	// fmsubs f13,f13,f29,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f29.f64 - ctx.f26.f64));
	// fsubs f6,f9,f12
	ctx.f6.f64 = double(float(ctx.f9.f64 - ctx.f12.f64));
	// stfsx f6,r10,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f12,f12,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f9.f64));
	// stfs f12,0(r4)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f12,f8,f11
	ctx.f12.f64 = double(float(ctx.f8.f64 - ctx.f11.f64));
	// stfsx f12,r11,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fadds f12,f11,f8
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f8.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f12,f10,f7
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// stfsx f12,r8,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fadds f12,f7,f10
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// stfsx f12,r7,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfsx f12,r31,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfsx f0,r30,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,3532(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3532);
	// add r4,r26,r4
	ctx.r4.u64 = ctx.r26.u64 + ctx.r4.u64;
	// xor r5,r11,r5
	ctx.r5.u64 = ctx.r11.u64 ^ ctx.r5.u64;
	// xor r6,r11,r6
	ctx.r6.u64 = ctx.r11.u64 ^ ctx.r6.u64;
	// bdnz 0x82d23320
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D23320;
loc_82D2343C:
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28f5c
	ctx.lr = 0x82D23444;
	__restfpr_26(ctx, base);
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D23448"))) PPC_WEAK_FUNC(sub_82D23448);
PPC_FUNC_IMPL(__imp__sub_82D23448) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-8120
	ctx.r5.s64 = ctx.r11.s64 + -8120;
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// addi r4,r11,12984
	ctx.r4.s64 = ctx.r11.s64 + 12984;
	// b 0x82d77e58
	sub_82D77E58(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D23460"))) PPC_WEAK_FUNC(sub_82D23460);
PPC_FUNC_IMPL(__imp__sub_82D23460) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D23468;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D23470;
	__savefpr_14(ctx, base);
	// mulli r11,r9,248
	ctx.r11.s64 = ctx.r9.s64 * 248;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-248
	ctx.r11.s64 = ctx.r11.s64 + -248;
	// bge cr6,0x82d24aa8
	if (!ctx.cr6.lt) goto loc_82D24AA8;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r15,r9,r10
	ctx.r15.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r19,r7,2,0,29
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r7,-32236
	ctx.r7.s64 = -2112618496;
	// lfs f8,-8000(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8000);
	ctx.f8.f64 = double(temp.f32);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f9,-8004(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -8004);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-8008(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8008);
	ctx.f10.f64 = double(temp.f32);
	// lis r14,-32234
	ctx.r14.s64 = -2112487424;
	// lfs f11,-8012(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8012);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,136(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D234CC:
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// lfs f7,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// mulli r9,r8,48
	ctx.r9.s64 = ctx.r8.s64 * 48;
	// lfs f6,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f18,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f3,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f2,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f22,f5,f3
	ctx.f22.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// rlwinm r7,r8,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f21,f2,f4
	ctx.f21.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// mulli r31,r8,44
	ctx.r31.s64 = ctx.r8.s64 * 44;
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// lfsx f17,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f1,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f30,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f2,f31,f1
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// lfsx f29,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r30,r8,60
	ctx.r30.s64 = ctx.r8.s64 * 60;
	// fsubs f3,f1,f31
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// lfsx f15,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f1,f29,f30
	ctx.f1.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fsubs f31,f30,f29
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// lfsx f28,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f27,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f30,f7,f28
	ctx.f30.f64 = double(float(ctx.f7.f64 - ctx.f28.f64));
	// rlwinm r29,r8,5,0,26
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f29,f27,f6
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f6.f64));
	// mulli r28,r8,28
	ctx.r28.s64 = ctx.r8.s64 * 28;
	// fadds f7,f28,f7
	ctx.f7.f64 = double(float(ctx.f28.f64 + ctx.f7.f64));
	// fsubs f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// lfsx f26,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f25,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f24,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f28,f26,f25
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfsx f23,r28,r6
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fadds f26,f23,f24
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f25,f24,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f21,f22
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f23,f22,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f21,f1,f3
	ctx.f21.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fsubs f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// fadds f22,f2,f5
	ctx.f22.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// fsubs f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 - ctx.f5.f64));
	// fsubs f1,f29,f28
	ctx.f1.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fadds f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fadds f19,f26,f30
	ctx.f19.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// fsubs f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// fadds f20,f27,f7
	ctx.f20.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fsubs f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// fadds f28,f21,f24
	ctx.f28.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// fsubs f26,f3,f23
	ctx.f26.f64 = double(float(ctx.f3.f64 - ctx.f23.f64));
	// fsubs f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// fadds f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 + ctx.f23.f64));
	// fsubs f27,f4,f31
	ctx.f27.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// fsubs f2,f6,f25
	ctx.f2.f64 = double(float(ctx.f6.f64 - ctx.f25.f64));
	// fadds f4,f31,f4
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// lfsx f31,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f6,f25,f6
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f6.f64));
	// lfsx f25,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f3,f28,f0
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f28,f26,f0
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmuls f26,f24,f0
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f24,f23,f0
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fadds f23,f22,f20
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// fsubs f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// fadds f16,f27,f7
	ctx.f16.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fsubs f21,f19,f3
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f3.f64));
	// fadds f20,f28,f1
	ctx.f20.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// fsubs f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// fadds f28,f26,f29
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fsubs f29,f29,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// fadds f26,f30,f24
	ctx.f26.f64 = double(float(ctx.f30.f64 + ctx.f24.f64));
	// fadds f3,f3,f19
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// lfs f19,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// lfs f24,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fadds f14,f2,f5
	ctx.f14.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// stfs f14,-300(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fsubs f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 - ctx.f5.f64));
	// lfsx f2,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,-420(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// fadds f2,f6,f4
	ctx.f2.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// fsubs f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// lfsx f4,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,-460(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fsubs f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// lfsx f4,r29,r6
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r6.u32);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,-456(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfsx f4,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,-444(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfsx f4,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,-484(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfsx f4,r29,r5
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r5.u32);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,-428(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fsubs f4,f31,f25
	ctx.f4.f64 = double(float(ctx.f31.f64 - ctx.f25.f64));
	// fadds f31,f25,f31
	ctx.f31.f64 = double(float(ctx.f25.f64 + ctx.f31.f64));
	// lfsx f27,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f25,f17,f18
	ctx.f25.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfsx f14,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f2,-480(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fsubs f17,f15,f27
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// lfsx f2,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f27,f27,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// lfs f15,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-496(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fsubs f15,f2,f24
	ctx.f15.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// stfs f15,-472(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f15,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f15.f64 = double(temp.f32);
	// fadds f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f24.f64));
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-420(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// stfs f2,-492(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f15.f64 = double(temp.f32);
	// lfs f2,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f14.f64 = double(temp.f32);
	// lfs f24,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f24.f64 = double(temp.f32);
	// fadds f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// fadds f24,f24,f2
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// stfs f24,-488(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f24,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// lfs f24,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f24.f64));
	// stfs f24,-428(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f19,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f19.f64 = double(temp.f32);
	// lfs f24,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// fadds f19,f25,f4
	ctx.f19.f64 = double(float(ctx.f25.f64 + ctx.f4.f64));
	// fsubs f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f25.f64));
	// fsubs f25,f31,f27
	ctx.f25.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// stfs f25,-460(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fadds f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// lfs f25,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f17.f64));
	// lfs f27,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f18.f64));
	// stfs f27,-456(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f27,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f15.f64));
	// stfs f27,-444(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f27,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 + ctx.f27.f64));
	// lfs f15,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-472(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,-488(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,-496(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f14,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f19,f25
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f25.f64));
	// lfs f17,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f25,f19
	ctx.f19.f64 = double(float(ctx.f25.f64 + ctx.f19.f64));
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-380(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fadds f17,f18,f27
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f27.f64));
	// stfs f17,-412(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f17,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f27,f27,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f18.f64));
	// fadds f17,f31,f17
	ctx.f17.f64 = double(float(ctx.f31.f64 + ctx.f17.f64));
	// stfs f17,-388(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// rlwinm r27,r8,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f17,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f17.f64 = double(temp.f32);
	// mulli r26,r8,56
	ctx.r26.s64 = ctx.r8.s64 * 56;
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f2,f14
	ctx.f14.f64 = double(float(ctx.f2.f64 - ctx.f14.f64));
	// stfs f14,-484(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f25,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f25.f64 = double(temp.f32);
	// mulli r25,r8,36
	ctx.r25.s64 = ctx.r8.s64 * 36;
	// fadds f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f14,-364(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// mulli r24,r8,24
	ctx.r24.s64 = ctx.r8.s64 * 24;
	// mulli r20,r8,20
	ctx.r20.s64 = ctx.r8.s64 * 20;
	// mulli r23,r8,40
	ctx.r23.s64 = ctx.r8.s64 * 40;
	// lfs f18,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,-360(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-488(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f14,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f4,f14
	ctx.f14.f64 = double(float(ctx.f4.f64 + ctx.f14.f64));
	// fsubs f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f25.f64));
	// lfs f25,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfs f25,-496(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f25,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f25.f64 = double(temp.f32);
	// stfs f4,-484(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fadds f4,f24,f25
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// lfs f25,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f19,f0
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fsubs f31,f25,f31
	ctx.f31.f64 = double(float(ctx.f25.f64 - ctx.f31.f64));
	// lfs f25,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f25.f64 = double(temp.f32);
	// fadds f2,f25,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// fmuls f25,f17,f12
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// stfs f25,-448(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// fmuls f25,f14,f0
	ctx.f25.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f19,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f14,f18,f13,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f14,-384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fmsubs f18,f18,f12,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 - ctx.f17.f64));
	// stfs f18,-396(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fmuls f17,f15,f12
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfs f18,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f18,f12
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// fadds f18,f27,f31
	ctx.f18.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// fsubs f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f31.f64));
	// lfs f27,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f13,f17
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 + ctx.f17.f64));
	// lfs f17,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f25
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// stfs f17,-348(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f17,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f25,f17,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 - ctx.f25.f64));
	// fmsubs f17,f15,f13,f14
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f17,-308(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fsubs f17,f4,f24
	ctx.f17.f64 = double(float(ctx.f4.f64 - ctx.f24.f64));
	// stfs f17,-304(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fadds f4,f24,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f4.f64));
	// lfsx f14,r24,r5
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// add r18,r20,r3
	ctx.r18.u64 = ctx.r20.u64 + ctx.r3.u64;
	// stfs f14,-492(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// add r17,r20,r4
	ctx.r17.u64 = ctx.r20.u64 + ctx.r4.u64;
	// lfsx f14,r24,r6
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// rlwinm r22,r8,3,0,28
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// stfs f14,-496(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// mulli r21,r8,52
	ctx.r21.s64 = ctx.r8.s64 * 52;
	// lfsx f14,r23,r5
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-488(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfsx f14,r23,r6
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-472(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// stfs f4,-336(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fsubs f4,f19,f2
	ctx.f4.f64 = double(float(ctx.f19.f64 - ctx.f2.f64));
	// stfs f4,-320(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fadds f4,f2,f19
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// stfs f4,-400(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfsx f2,r26,r5
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r5.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f4,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f14,f2,f4
	ctx.f14.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// lfsx f19,r26,r6
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f24,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f2,f24,f19
	ctx.f2.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// lfsx f17,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// lfsx f15,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfs f19,-456(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f19,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f19,-460(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f19,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// lfs f17,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,-496(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f17,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f15,-328(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,-484(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f17,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f15,-492(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f15,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-444(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f15,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f2,f14
	ctx.f14.f64 = double(float(ctx.f2.f64 - ctx.f14.f64));
	// stfs f14,-468(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f14,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f14.f64 = double(temp.f32);
	// fadds f2,f14,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 + ctx.f2.f64));
	// stfs f2,-460(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f2,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f2.f64 = double(temp.f32);
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f2
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f2.f64));
	// stfs f14,-452(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f14.f64));
	// fadds f14,f24,f19
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f19.f64));
	// stfs f14,-428(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// fsubs f14,f4,f14
	ctx.f14.f64 = double(float(ctx.f4.f64 - ctx.f14.f64));
	// stfs f14,-368(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fadds f4,f14,f4
	ctx.f4.f64 = double(float(ctx.f14.f64 + ctx.f4.f64));
	// lfsx f14,r22,r6
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f24,-416(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfsx f24,r22,r5
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r5.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f19,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f14,-484(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfsx f14,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-492(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfsx f14,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfsx f14,r21,r5
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-496(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfsx f14,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-448(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfsx f14,r21,r6
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-488(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// fadds f14,f19,f24
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// stfs f24,-332(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f24,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f24.f64 = double(temp.f32);
	// lfs f19,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f24
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// stfs f19,-472(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f19,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f24.f64));
	// stfs f24,-492(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f24,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f24.f64 = double(temp.f32);
	// lfs f19,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f24
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// stfs f19,-432(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f19,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// stfs f24,-440(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f24,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f24.f64 = double(temp.f32);
	// lfs f19,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f24
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// stfs f19,-404(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f19,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// lfs f19,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f19.f64 = double(temp.f32);
	// stfs f24,-376(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fsubs f24,f19,f14
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// fadds f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f19,-456(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f19,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f14,-488(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,-496(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f14,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,-492(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f17,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f17,f24
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f24.f64));
	// stfs f14,-484(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fadds f24,f24,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f17.f64));
	// stfs f24,-420(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f24,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f24.f64 = double(temp.f32);
	// lfs f17,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f24,f17
	ctx.f17.f64 = double(float(ctx.f24.f64 - ctx.f17.f64));
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f14,-468(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// stfs f15,-472(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fadds f15,f2,f19
	ctx.f15.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// fsubs f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f19.f64));
	// lfs f19,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f19.f64 = double(temp.f32);
	// fadds f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfs f19,-496(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f14,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f19,-380(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f19,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,-392(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f19,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f24,f24,f0
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,-424(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// fmuls f19,f17,f0
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f19,-448(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// fmuls f19,f15,f0
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f19,-452(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// stfs f24,-436(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f2,-408(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// add r16,r20,r5
	ctx.r16.u64 = ctx.r20.u64 + ctx.r5.u64;
	// lfs f2,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f2.f64 = double(temp.f32);
	// add r20,r20,r6
	ctx.r20.u64 = ctx.r20.u64 + ctx.r6.u64;
	// fmuls f24,f2,f13
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f19,f2,f12
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f2,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f17,f2,f12
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f2,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f15,f2,f12
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f2,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f14,f14,f2
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f2.f64));
	// stfs f14,-332(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fadds f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f14.f64));
	// stfs f2,-328(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f14,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f14.f64 = double(temp.f32);
	// lfs f2,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f2.f64 = double(temp.f32);
	// fadds f14,f2,f14
	ctx.f14.f64 = double(float(ctx.f2.f64 + ctx.f14.f64));
	// stfs f14,-456(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f14,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f2,f14,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 - ctx.f2.f64));
	// stfs f2,-340(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f2,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f24,f2,f12,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 - ctx.f24.f64));
	// stfs f24,-344(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fmadds f2,f2,f13,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f19.f64));
	// stfs f2,-352(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f2,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f2.f64 = double(temp.f32);
	// lfs f24,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f24.f64 = double(temp.f32);
	// fadds f19,f2,f24
	ctx.f19.f64 = double(float(ctx.f2.f64 + ctx.f24.f64));
	// lfsx f14,r27,r6
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// stfs f2,-356(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfs f2,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f2,f2,f13,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 - ctx.f17.f64));
	// stfs f2,-316(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f2,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f2,f2,f13,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f2,-380(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f2,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f2.f64 = double(temp.f32);
	// stfs f14,-484(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fsubs f24,f4,f2
	ctx.f24.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// lfsx f14,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// stfs f14,-492(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfsx f14,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f4,-464(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f2,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f4.f64 = double(temp.f32);
	// stfs f14,-496(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfsx f14,r25,r5
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f24,-312(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fadds f24,f2,f4
	ctx.f24.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// stfs f14,-448(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// fsubs f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// lfsx f14,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-468(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// stfs f4,-368(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfsx f14,r25,r6
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f4,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfs f2,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// stfs f19,-372(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// stfs f24,-324(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// stfs f14,-488(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// fsubs f14,f4,f2
	ctx.f14.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// lfsx f24,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfs f19,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f17,r27,r5
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f15,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fadds f2,f19,f24
	ctx.f2.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// stfs f24,-460(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fsubs f24,f17,f15
	ctx.f24.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f19,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f19.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f15,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f15,-452(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f15,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f19,-428(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f19,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f15,-484(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f19,-492(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f19,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f15,-448(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// lfs f15,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f15.f64 = double(temp.f32);
	// stfs f19,-444(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fsubs f19,f15,f14
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f14.f64 = double(temp.f32);
	// stfs f15,-496(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fadds f15,f2,f14
	ctx.f15.f64 = double(float(ctx.f2.f64 + ctx.f14.f64));
	// fsubs f2,f14,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 - ctx.f2.f64));
	// stfs f2,-472(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f2,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f4,f2
	ctx.f2.f64 = double(float(ctx.f4.f64 + ctx.f2.f64));
	// stfs f2,-440(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f2,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f2.f64 = double(temp.f32);
	// lfs f14,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f14.f64));
	// stfs f2,-404(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f2,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// lfs f2,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f2.f64 = double(temp.f32);
	// stfs f4,-420(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// fadds f4,f14,f2
	ctx.f4.f64 = double(float(ctx.f14.f64 + ctx.f2.f64));
	// fsubs f2,f14,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 - ctx.f2.f64));
	// stfs f2,-488(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f2,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f2.f64 = double(temp.f32);
	// fadds f14,f2,f24
	ctx.f14.f64 = double(float(ctx.f2.f64 + ctx.f24.f64));
	// stfs f14,-484(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fsubs f2,f24,f2
	ctx.f2.f64 = double(float(ctx.f24.f64 - ctx.f2.f64));
	// lfs f24,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f17.f64));
	// stfs f24,-432(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f14,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f14.f64 = double(temp.f32);
	// lfs f24,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// stfs f24,-416(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f24,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f4,f12
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// fsubs f24,f17,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 - ctx.f24.f64));
	// stfs f24,-492(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// fmuls f24,f19,f12
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f17,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// stfs f2,-476(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmuls f4,f4,f13
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// stfs f4,-448(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,-468(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fmadds f4,f15,f13,f24
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f24.f64));
	// lfs f24,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f24,f13,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f24,-436(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fmsubs f2,f15,f12,f19
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f19.f64));
	// lfs f24,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f24.f64 = double(temp.f32);
	// lfs f19,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f24
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// stfs f19,-408(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f19,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// fmadds f19,f17,f13,f14
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f14.f64));
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f17,f17,f12,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f14.f64));
	// lfs f14,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f15,f15,f13,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 - ctx.f14.f64));
	// fsubs f14,f4,f19
	ctx.f14.f64 = double(float(ctx.f4.f64 - ctx.f19.f64));
	// fadds f4,f19,f4
	ctx.f4.f64 = double(float(ctx.f19.f64 + ctx.f4.f64));
	// stfs f4,-468(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fadds f4,f17,f2
	ctx.f4.f64 = double(float(ctx.f17.f64 + ctx.f2.f64));
	// stfs f4,-484(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fsubs f4,f2,f17
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f17.f64));
	// stfs f4,-452(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f4,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f4.f64 = double(temp.f32);
	// fadds f2,f15,f4
	ctx.f2.f64 = double(float(ctx.f15.f64 + ctx.f4.f64));
	// stfs f2,-432(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fsubs f4,f15,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 - ctx.f4.f64));
	// stfs f4,-448(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f4,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,-436(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f4,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// lfs f2,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f15,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f10
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// lfs f17,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f10
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// fmsubs f4,f15,f13,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 - ctx.f4.f64));
	// stfs f4,-496(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f4,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f4,f4,f13,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f2.f64));
	// stfs f4,-440(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f4,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f15,f4,f11
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// lfs f4,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// stfs f4,-476(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f2,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f4,f2,f11,f19
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 - ctx.f19.f64));
	// lfs f2,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f2,f2,f11,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f17.f64));
	// stfs f2,-488(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f19,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f19.f64 = double(temp.f32);
	// lfs f2,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// stfs f2,-472(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f19,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f19.f64 = double(temp.f32);
	// lfs f2,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// stfs f2,-376(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f19,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f17.f64 = double(temp.f32);
	// lfs f2,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f28.f64));
	// stfs f2,-460(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f2,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f19.f64));
	// lfs f19,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f10,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 + ctx.f15.f64));
	// stfs f19,-456(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f19,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f19,-372(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f17,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// lfs f17,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f17,f17,f11,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 - ctx.f15.f64));
	// stfs f17,-476(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f17,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,-364(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f17,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f23
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// stfs f17,-404(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f15,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,-416(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f15,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,-444(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f15,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f23,-492(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f15,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f15.f64 = double(temp.f32);
	// lfs f23,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f23,-424(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f23,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f28,f28,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// stfs f28,-388(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f23,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f23.f64 = double(temp.f32);
	// lfs f28,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f28.f64 = double(temp.f32);
	// fadds f15,f23,f28
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// stfs f15,-440(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fsubs f28,f28,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// stfs f28,-348(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f28,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f28.f64 = double(temp.f32);
	// fadds f23,f28,f4
	ctx.f23.f64 = double(float(ctx.f28.f64 + ctx.f4.f64));
	// stfs f23,-496(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fsubs f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f28.f64));
	// stfs f4,-408(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f28,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f28.f64 = double(temp.f32);
	// lfs f4,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f4.f64 = double(temp.f32);
	// fadds f23,f28,f4
	ctx.f23.f64 = double(float(ctx.f28.f64 + ctx.f4.f64));
	// stfs f23,-412(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fsubs f4,f28,f4
	ctx.f4.f64 = double(float(ctx.f28.f64 - ctx.f4.f64));
	// stfs f4,-376(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f4,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f15,f2,f4
	ctx.f15.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// fadds f23,f4,f2
	ctx.f23.f64 = double(float(ctx.f4.f64 + ctx.f2.f64));
	// lfs f2,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f4.f64 = double(temp.f32);
	// fadds f28,f2,f4
	ctx.f28.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// stfs f28,-392(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fsubs f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// stfs f4,-488(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f4,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f4.f64 = double(temp.f32);
	// fadds f2,f4,f19
	ctx.f2.f64 = double(float(ctx.f4.f64 + ctx.f19.f64));
	// stfs f2,-476(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fsubs f19,f4,f19
	ctx.f19.f64 = double(float(ctx.f4.f64 - ctx.f19.f64));
	// fmuls f2,f23,f0
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f23,f15,f0
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f4,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f4.f64 = double(temp.f32);
	// stfs f23,-404(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f28,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f4
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f4.f64));
	// stfs f28,-364(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f28,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f28.f64));
	// stfs f4,-416(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f28,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f28.f64 = double(temp.f32);
	// lfs f4,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f4.f64 = double(temp.f32);
	// lfs f23,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f23.f64 = double(temp.f32);
	// fadds f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f28.f64));
	// fsubs f28,f28,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// lfs f15,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f15.f64 = double(temp.f32);
	// lfs f23,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f23,-432(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fmuls f23,f19,f0
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f19,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f19.f64 = double(temp.f32);
	// stfs f23,-372(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// fadds f23,f19,f26
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f26.f64));
	// fsubs f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f19.f64));
	// lfs f19,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f19,-492(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f19,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f15,-480(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f15,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// stfs f19,-476(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f15,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f19,-388(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f19,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f15,-440(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f15,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// stfs f19,-424(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// fadds f19,f15,f23
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f23,-408(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f23,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f15,f26,f23
	ctx.f15.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// stfs f15,-496(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fadds f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// lfs f23,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f23.f64 = double(temp.f32);
	// stfs f26,-392(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f15,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f15.f64 = double(temp.f32);
	// fadds f26,f15,f23
	ctx.f26.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// fsubs f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// stfs f23,-412(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f23,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f23.f64 = double(temp.f32);
	// fadds f15,f23,f17
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f17.f64));
	// stfs f15,-488(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// fsubs f23,f23,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f17.f64));
	// stfs f23,-476(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f23,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f23.f64 = double(temp.f32);
	// stfs f23,-480(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fmuls f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f19.f64));
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f23,f15,f17,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f17.f64 + ctx.f23.f64));
	// lfs f15,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f17.f64));
	// lfs f15,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// stfs f15,0(r3)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f15,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// lfs f23,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f23,f19,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f19.f64 - ctx.f17.f64));
	// fadds f19,f23,f26
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f19,0(r4)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// stfs f15,0(r5)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// stfs f26,0(r6)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f17,196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 196);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-436(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f23,184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	ctx.f23.f64 = double(temp.f32);
	// stfs f23,-480(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f17,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f17.f64 = double(temp.f32);
	// lfs f26,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f26,f17
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// lfs f26,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f23,f17
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// lfs f19,192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 192);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f26
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f26.f64));
	// lfs f23,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f26.f64));
	// lfs f23,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f23.f64 = double(temp.f32);
	// stfs f26,-480(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fmsubs f23,f23,f28,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f28.f64 - ctx.f15.f64));
	// stfs f23,-476(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// lfs f23,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f26,f15,f23,f19
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f23.f64 + ctx.f19.f64));
	// lfs f19,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f28,f19,f28,f17
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f28.f64 + ctx.f17.f64));
	// lfs f19,192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 192);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f23,f19,f23,f17
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f23.f64 - ctx.f17.f64));
	// lfs f19,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f17,f19,f26
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// stfsx f17,r9,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// lfs f15,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f23,f28
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// stfsx f19,r9,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f26,r9,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f28,f23,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 - ctx.f28.f64));
	// stfsx f28,r9,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f23.f64 = double(temp.f32);
	// stfs f23,-480(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f26,124(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 124);
	ctx.f26.f64 = double(temp.f32);
	// lfs f19,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f26,f15
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f15.f64));
	// fmuls f19,f26,f19
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// lfs f23,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f23.f64 = double(temp.f32);
	// lfs f26,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f23,f17
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// fmuls f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f26.f64));
	// lfs f28,120(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 120);
	ctx.f28.f64 = double(temp.f32);
	// lfs f23,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f28,f23,f19
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f23.f64 - ctx.f19.f64));
	// stfs f23,-476(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f19,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f19.f64 = double(temp.f32);
	// lfs f23,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f23.f64 = double(temp.f32);
	// stfs f26,-480(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fmadds f26,f23,f19,f17
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f19.f64 + ctx.f17.f64));
	// lfs f19,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f28,f28,f19,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64 + ctx.f15.f64));
	// lfs f19,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f23,f23,f19,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f19.f64 - ctx.f17.f64));
	// lfs f19,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f17,f19,f26
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// stfsx f17,r29,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fadds f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// lfs f17,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f23,f28
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// stfsx f19,r29,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// stfsx f26,r29,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fsubs f28,f23,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 - ctx.f28.f64));
	// stfsx f28,r29,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// lfs f26,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f26,f17
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// fmuls f17,f28,f17
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// lfs f19,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f19.f64 = double(temp.f32);
	// lfs f23,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f28,f28,f4,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f4.f64 - ctx.f15.f64));
	// stfs f28,-436(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fmadds f4,f26,f4,f17
	ctx.f4.f64 = double(float(ctx.f26.f64 * ctx.f4.f64 + ctx.f17.f64));
	// stfs f4,-424(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f4,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f28,f4,f11
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// lfs f4,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f26,f4,f11
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// lfs f4,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f17,f4,f11
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// lfs f15,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f11
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// fmsubs f4,f4,f10,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f10.f64 - ctx.f28.f64));
	// lfs f28,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f28,f10,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 - ctx.f26.f64));
	// lfs f26,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f10,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f10.f64 + ctx.f17.f64));
	// stfs f26,-440(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f26,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f26.f64 = double(temp.f32);
	// stfs f4,-476(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fadds f26,f26,f7
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f7.f64));
	// lfs f4,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f4.f64 = double(temp.f32);
	// stfs f28,-336(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fmuls f4,f19,f4
	ctx.f4.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// lfs f28,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f28.f64 = double(temp.f32);
	// stfs f26,-368(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fmuls f28,f23,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// lfs f26,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f26.f64 = double(temp.f32);
	// lfs f17,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f17.f64 = double(temp.f32);
	// stfs f4,-464(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// stfs f28,-480(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fadds f4,f26,f17
	ctx.f4.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// lfs f26,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f10,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f10.f64 + ctx.f15.f64));
	// stfs f26,-400(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f26,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f26.f64 = double(temp.f32);
	// lfs f17,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f17.f64 = double(temp.f32);
	// fadds f28,f26,f17
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// lfs f17,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f17.f64 = double(temp.f32);
	// lfs f26,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f23,f26,f17
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 + ctx.f17.f64));
	// lfs f17,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f3,f17
	ctx.f17.f64 = double(float(ctx.f3.f64 - ctx.f17.f64));
	// stfs f17,-464(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f17,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f1
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f1.f64));
	// stfs f17,-412(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f17,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f17.f64 = double(temp.f32);
	// lfs f23,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// lfs f15,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f19,f19,f17,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f5,f5,f15
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f15.f64));
	// lfs f15,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f7,f7,f15
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f15.f64));
	// stfs f7,-384(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f15,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f15.f64 = double(temp.f32);
	// lfs f7,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f7,f15,f7
	ctx.f7.f64 = double(float(ctx.f15.f64 - ctx.f7.f64));
	// lfs f15,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f1,f1,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f15.f64));
	// lfs f15,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f15.f64 = double(temp.f32);
	// fadds f3,f15,f3
	ctx.f3.f64 = double(float(ctx.f15.f64 + ctx.f3.f64));
	// stfs f3,-352(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f3,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f3.f64 = double(temp.f32);
	// lfs f15,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f3
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f3.f64));
	// stfs f15,-468(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f15,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f3,f3,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f15.f64));
	// stfs f3,-452(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f3,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f4,f3
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// stfs f3,-480(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f3,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f3.f64 = double(temp.f32);
	// lfs f15,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f3,f15
	ctx.f15.f64 = double(float(ctx.f3.f64 - ctx.f15.f64));
	// stfs f15,-396(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f15,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f15.f64 = double(temp.f32);
	// fadds f3,f15,f3
	ctx.f3.f64 = double(float(ctx.f15.f64 + ctx.f3.f64));
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f26.f64));
	// stfsx f15,r7,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// fadds f26,f26,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f15.f64));
	// fadds f15,f23,f28
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// stfs f15,-344(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f15,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f28,f23,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 - ctx.f28.f64));
	// fsubs f4,f15,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 - ctx.f4.f64));
	// lfs f15,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f19,f15
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfsx f15,r7,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// stfsx f26,r7,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f5,f17
	ctx.f23.f64 = double(float(ctx.f5.f64 + ctx.f17.f64));
	// lfs f26,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f5,f5,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f17.f64));
	// fsubs f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// stfsx f26,r7,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// lfs f26,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f26.f64 = double(temp.f32);
	// lfs f19,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f7,f15
	ctx.f15.f64 = double(float(ctx.f7.f64 + ctx.f15.f64));
	// stfs f15,-440(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f15,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f7,f15,f7
	ctx.f7.f64 = double(float(ctx.f15.f64 - ctx.f7.f64));
	// stfs f7,-400(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f7,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f7.f64 = double(temp.f32);
	// lfs f15,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f7
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f7.f64));
	// stfs f15,-384(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f15,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f1,f15
	ctx.f15.f64 = double(float(ctx.f1.f64 - ctx.f15.f64));
	// stfs f15,-476(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f15,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f7,f7,f15
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f15.f64));
	// lfs f15,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f15.f64 = double(temp.f32);
	// fadds f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 + ctx.f1.f64));
	// stfs f1,-452(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f1,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f1.f64 = double(temp.f32);
	// lfs f15,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f1
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f1.f64));
	// stfs f15,-464(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f15,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f3,f15
	ctx.f15.f64 = double(float(ctx.f3.f64 + ctx.f15.f64));
	// stfs f15,-468(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f15,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f1,f1,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f15.f64));
	// lfs f15,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f3,f15,f3
	ctx.f3.f64 = double(float(ctx.f15.f64 - ctx.f3.f64));
	// stfs f3,-396(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f3,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f19,f3
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// lfs f3,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fmsubs f3,f26,f3,f15
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f3.f64 - ctx.f15.f64));
	// lfs f15,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f26,f26,f15,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f15.f64 + ctx.f19.f64));
	// stfs f26,-480(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f26,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f26.f64 = double(temp.f32);
	// lfs f19,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f26,f19
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// lfs f19,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// stfs f26,-464(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fmadds f26,f17,f19,f15
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f19.f64 + ctx.f15.f64));
	// lfs f19,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f19,f17,f19,f15
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f19.f64 - ctx.f15.f64));
	// fsubs f17,f3,f26
	ctx.f17.f64 = double(float(ctx.f3.f64 - ctx.f26.f64));
	// stfsx f17,r10,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f26,f26,f3
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// lfs f3,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f3.f64 = double(temp.f32);
	// fadds f17,f19,f3
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f3.f64));
	// stfsx f17,r10,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfsx f26,r10,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f3,f19,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 - ctx.f3.f64));
	// stfsx f3,r10,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f26,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f26.f64 = double(temp.f32);
	// lfs f3,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f26,f5
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fmuls f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// stfs f5,-464(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f19,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f19.f64 = double(temp.f32);
	// lfs f26,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f19,f19,f26
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f26.f64));
	// lfs f17,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f26
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f26.f64));
	// lfs f26,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f5,f3,f26,f15
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f26.f64 - ctx.f15.f64));
	// lfs f3,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f3.f64 = double(temp.f32);
	// lfs f26,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f3,f3,f26,f19
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f26.f64 + ctx.f19.f64));
	// lfs f26,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f26.f64 = double(temp.f32);
	// lfs f19,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f26,f26,f19,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f19.f64 + ctx.f15.f64));
	// lfs f19,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f19,f19,f15,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f15.f64 - ctx.f17.f64));
	// fsubs f17,f5,f3
	ctx.f17.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfsx f17,r30,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fadds f3,f19,f26
	ctx.f3.f64 = double(float(ctx.f19.f64 + ctx.f26.f64));
	// stfsx f3,r30,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// stfsx f5,r30,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fsubs f5,f19,f26
	ctx.f5.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// stfsx f5,r30,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f3,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f3,f28
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// lfs f19,180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 180);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f3,f3,f4
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// stfs f3,-464(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fmuls f15,f19,f7
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f7.f64));
	// lfs f5,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f19,f19,f1
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// lfs f26,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f4,f5,f4,f17
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmadds f3,f26,f1,f15
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 + ctx.f15.f64));
	// fmsubs f7,f26,f7,f19
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 - ctx.f19.f64));
	// fmuls f15,f25,f8
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// fsubs f1,f4,f3
	ctx.f1.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// stfsx f1,r31,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// lfs f1,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f1.f64 = double(temp.f32);
	// lfs f17,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f5,f5,f28,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f28.f64 + ctx.f17.f64));
	// fadds f3,f7,f5
	ctx.f3.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// stfsx f3,r31,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// stfsx f4,r31,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// stfsx f7,r31,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f7,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f7.f64 = double(temp.f32);
	// lfs f5,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f26,f7,f23
	ctx.f26.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// fmuls f28,f5,f23
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// lfs f4,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f23,f4,f1
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// lfs f1,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f5,f5,f1,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 + ctx.f26.f64));
	// fmsubs f7,f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f1.f64 - ctx.f28.f64));
	// lfs f1,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f3,f1,f23
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f1.f64 + ctx.f23.f64));
	// lfs f23,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f23.f64 = double(temp.f32);
	// lfs f28,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f23,f8
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fmuls f19,f28,f8
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// lfs f28,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f17,f28,f8
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// fmsubs f28,f28,f9,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f9.f64 - ctx.f26.f64));
	// fmadds f26,f25,f9,f19
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f9.f64 + ctx.f19.f64));
	// lfs f25,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f19,f3,f25
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f3,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f3,f18
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f18.f64));
	// stfs f3,-356(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfs f25,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f3,f23,f9,f17
	ctx.f3.f64 = double(float(ctx.f23.f64 * ctx.f9.f64 + ctx.f17.f64));
	// fadds f17,f25,f31
	ctx.f17.f64 = double(float(ctx.f25.f64 + ctx.f31.f64));
	// lfs f25,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f25.f64 = double(temp.f32);
	// fadds f23,f24,f6
	ctx.f23.f64 = double(float(ctx.f24.f64 + ctx.f6.f64));
	// stfs f23,-464(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f23,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f23.f64 = double(temp.f32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// stfs f25,-340(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fadds f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// lfs f25,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f6,f6,f24
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f24.f64));
	// stfs f23,-360(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fmsubs f25,f25,f9,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f9.f64 - ctx.f15.f64));
	// lfs f23,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f29
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// stfs f23,-468(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fsubs f23,f7,f1
	ctx.f23.f64 = double(float(ctx.f7.f64 - ctx.f1.f64));
	// stfsx f23,r28,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f23,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f4,f4,f23,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f23.f64 - ctx.f19.f64));
	// lfs f19,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f23,f19,f0
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fadds f19,f1,f7
	ctx.f19.f64 = double(float(ctx.f1.f64 + ctx.f7.f64));
	// lfs f1,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f18,f1,f18
	ctx.f18.f64 = double(float(ctx.f1.f64 - ctx.f18.f64));
	// lfs f1,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f7,f17,f0
	ctx.f7.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fsubs f17,f31,f1
	ctx.f17.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// lfs f1,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f1,f22,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 - ctx.f1.f64));
	// lfs f31,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f24,f17,f0
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fsubs f31,f29,f31
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f31.f64));
	// lfs f29,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// lfs f17,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f29,f18,f0
	ctx.f29.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// lfs f18,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f18.f64 = double(temp.f32);
	// fadds f22,f26,f28
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fsubs f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// fadds f26,f25,f3
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f3.f64));
	// fsubs f3,f25,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 - ctx.f3.f64));
	// fadds f25,f4,f5
	ctx.f25.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// stfsx f25,r28,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// stfsx f19,r28,r5
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fsubs f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// stfsx f5,r28,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f25,f17,f7
	ctx.f25.f64 = double(float(ctx.f17.f64 + ctx.f7.f64));
	// fadds f5,f23,f18
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// lfs f19,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// lfs f4,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f7,f17,f7
	ctx.f7.f64 = double(float(ctx.f17.f64 - ctx.f7.f64));
	// fadds f15,f6,f29
	ctx.f15.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// lfs f17,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f29.f64));
	// fadds f29,f24,f1
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f1.f64));
	// fsubs f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f24.f64));
	// lfs f24,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f24,-356(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fsubs f24,f31,f28
	ctx.f24.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// stfs f24,-340(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f24,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f24.f64 = double(temp.f32);
	// fadds f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// lfs f28,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f22,f30,f3
	ctx.f22.f64 = double(float(ctx.f30.f64 - ctx.f3.f64));
	// stfs f22,-464(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f22,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f22.f64 = double(temp.f32);
	// fadds f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f30.f64));
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fmuls f30,f19,f25
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f25.f64));
	// fsubs f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// fmuls f22,f19,f5
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f5.f64));
	// fsubs f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// lfs f18,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f5,f4,f5,f30
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f5.f64 - ctx.f30.f64));
	// fmadds f4,f4,f25,f22
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f25.f64 + ctx.f22.f64));
	// lfs f25,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f30,f17,f25
	ctx.f30.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// fmadds f30,f18,f28,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 + ctx.f30.f64));
	// fmuls f28,f17,f28
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// fsubs f22,f5,f30
	ctx.f22.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// stfsx f22,r22,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f30,f5
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// fmsubs f5,f18,f25,f28
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f25.f64 - ctx.f28.f64));
	// lfs f25,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f25.f64 = double(temp.f32);
	// fadds f28,f5,f4
	ctx.f28.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// stfsx f28,r22,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// stfsx f30,r22,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r5.u32, temp.u32);
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfsx f5,r22,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// lfs f4,220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f4.f64 = double(temp.f32);
	// lfs f30,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f22,f4,f6
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f5,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f19,f30,f25
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lfs f28,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f5,f6
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fmuls f17,f28,f25
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// lfs f25,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f6,f5,f1,f22
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 - ctx.f22.f64));
	// fmadds f5,f28,f25,f19
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f25.f64 + ctx.f19.f64));
	// fmadds f4,f4,f1,f18
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f1.f64 + ctx.f18.f64));
	// fmsubs f1,f30,f25,f17
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f25.f64 - ctx.f17.f64));
	// fsubs f30,f6,f5
	ctx.f30.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// stfsx f30,r26,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fadds f5,f1,f4
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// stfsx f5,r26,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// stfsx f6,r26,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fsubs f6,f1,f4
	ctx.f6.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// stfsx f6,r26,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// lfs f5,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f5.f64 = double(temp.f32);
	// lfs f1,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f30,f5,f7
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// fmuls f28,f1,f24
	ctx.f28.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// lfs f6,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f25,f5,f23
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// lfs f4,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f22,f1,f26
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// lfs f17,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f5,f6,f23,f30
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f23.f64 - ctx.f30.f64));
	// fmadds f1,f4,f26,f28
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f26.f64 + ctx.f28.f64));
	// lfs f26,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f7,f6,f7,f25
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f7.f64 + ctx.f25.f64));
	// fmsubs f6,f4,f24,f22
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f24.f64 - ctx.f22.f64));
	// fsubs f4,f5,f1
	ctx.f4.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// stfsx f4,r23,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fadds f4,f6,f7
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// stfsx f4,r23,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// stfsx f5,r23,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f7.f64));
	// stfsx f7,r23,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// lfs f6,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f6,f15
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f15.f64));
	// fmuls f30,f7,f15
	ctx.f30.f64 = double(float(ctx.f7.f64 * ctx.f15.f64));
	// lfs f4,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f4,f31
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f15,f5,f31
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fmsubs f7,f7,f29,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f29.f64 - ctx.f1.f64));
	// lfs f1,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f6,f6,f29,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f29.f64 + ctx.f30.f64));
	// lfs f30,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f25,f1,f8
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// lfs f29,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f24,f30,f8
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// fmuls f23,f1,f9
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// fmuls f28,f30,f9
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// fmadds f5,f5,f3,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f3.f64 + ctx.f22.f64));
	// fmsubs f4,f4,f3,f15
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 - ctx.f15.f64));
	// fsubs f3,f17,f27
	ctx.f3.f64 = double(float(ctx.f17.f64 - ctx.f27.f64));
	// fadds f22,f14,f20
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// fsubs f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// fmadds f30,f26,f9,f25
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f9.f64 + ctx.f25.f64));
	// lfs f25,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f31,f29,f9,f24
	ctx.f31.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 + ctx.f24.f64));
	// lfs f24,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f26,f26,f8,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f8.f64 - ctx.f23.f64));
	// lfs f23,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f1,f29,f8,f28
	ctx.f1.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 - ctx.f28.f64));
	// fadds f28,f17,f27
	ctx.f28.f64 = double(float(ctx.f17.f64 + ctx.f27.f64));
	// lfs f27,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f27.f64 = double(temp.f32);
	// fadds f29,f2,f16
	ctx.f29.f64 = double(float(ctx.f2.f64 + ctx.f16.f64));
	// fadds f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f19.f64));
	// fsubs f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 - ctx.f27.f64));
	// lfs f19,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f19.f64 = double(temp.f32);
	// fadds f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f18.f64));
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// lfs f18,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f18.f64 = double(temp.f32);
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// fadds f17,f26,f31
	ctx.f17.f64 = double(float(ctx.f26.f64 + ctx.f31.f64));
	// fsubs f31,f26,f31
	ctx.f31.f64 = double(float(ctx.f26.f64 - ctx.f31.f64));
	// fsubs f26,f7,f5
	ctx.f26.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// stfsx f26,r24,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fadds f18,f30,f1
	ctx.f18.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fadds f26,f5,f7
	ctx.f26.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fsubs f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// fadds f30,f28,f29
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fsubs f5,f29,f28
	ctx.f5.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fadds f29,f4,f6
	ctx.f29.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// stfsx f29,r24,r4
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// stfsx f26,r24,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fsubs f2,f16,f2
	ctx.f2.f64 = double(float(ctx.f16.f64 - ctx.f2.f64));
	// fadds f7,f24,f25
	ctx.f7.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fsubs f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// stfsx f6,r24,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fsubs f6,f24,f25
	ctx.f6.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// fadds f24,f18,f23
	ctx.f24.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// lfs f28,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// lfs f4,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f18,f21,f31
	ctx.f18.f64 = double(float(ctx.f21.f64 - ctx.f31.f64));
	// lfs f25,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f25.f64 = double(temp.f32);
	// fadds f31,f31,f21
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f21.f64));
	// fmuls f21,f28,f7
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f7.f64));
	// fadds f26,f19,f2
	ctx.f26.f64 = double(float(ctx.f19.f64 + ctx.f2.f64));
	// fmuls f28,f28,f30
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// fsubs f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f19.f64));
	// fsubs f19,f20,f1
	ctx.f19.f64 = double(float(ctx.f20.f64 - ctx.f1.f64));
	// fadds f1,f1,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f20.f64));
	// fadds f20,f17,f22
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fadds f29,f27,f3
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// fsubs f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 - ctx.f3.f64));
	// lfs f27,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fmsubs f30,f4,f30,f21
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f30.f64 - ctx.f21.f64));
	// fmadds f7,f4,f7,f28
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f7.f64 + ctx.f28.f64));
	// fmuls f4,f25,f24
	ctx.f4.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// fmuls f28,f25,f20
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f20.f64));
	// fmadds f4,f27,f20,f4
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 + ctx.f4.f64));
	// fmsubs f28,f27,f24,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f24.f64 - ctx.f28.f64));
	// fsubs f27,f30,f4
	ctx.f27.f64 = double(float(ctx.f30.f64 - ctx.f4.f64));
	// stfsx f27,r27,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fadds f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f30.f64));
	// fadds f30,f28,f7
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f7.f64));
	// stfsx f30,r27,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// stfsx f4,r27,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f28,f7
	ctx.f7.f64 = double(float(ctx.f28.f64 - ctx.f7.f64));
	// stfsx f7,r27,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// lfs f30,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f30.f64 = double(temp.f32);
	// lfs f4,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f25,f30,f19
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f19.f64));
	// lfs f7,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f27,f4,f3
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f28,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f24,f7,f3
	ctx.f24.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// fmuls f21,f28,f19
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fmadds f3,f28,f18,f25
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f18.f64 + ctx.f25.f64));
	// fmsubs f7,f7,f2,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f2.f64 - ctx.f27.f64));
	// fmadds f4,f4,f2,f24
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64 + ctx.f24.f64));
	// fmsubs f2,f30,f18,f21
	ctx.f2.f64 = double(float(ctx.f30.f64 * ctx.f18.f64 - ctx.f21.f64));
	// fsubs f30,f7,f3
	ctx.f30.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfsx f30,r21,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// fadds f3,f2,f4
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// stfsx f3,r21,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// stfsx f7,r21,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f2,f4
	ctx.f7.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// stfsx f7,r21,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r6.u32, temp.u32);
	// lfs f4,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f4.f64 = double(temp.f32);
	// lfs f2,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f30,f4,f6
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// fmuls f28,f2,f23
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f3,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f27,f4,f5
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// lfs f7,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// fmsubs f5,f7,f5,f30
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f5.f64 - ctx.f30.f64));
	// fmadds f4,f3,f22,f28
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 + ctx.f28.f64));
	// fmadds f7,f7,f6,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64 + ctx.f27.f64));
	// fmsubs f6,f3,f23,f2
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f23.f64 - ctx.f2.f64));
	// fsubs f3,f5,f4
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfsx f3,r25,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fadds f4,f6,f7
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// stfsx f4,r25,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// stfsx f5,r25,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f7.f64));
	// stfsx f7,r25,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// lfs f7,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f2,f7,f29
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// lfs f5,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f3,f6,f29
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// lfs f4,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f30,f5,f1
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// fmsubs f7,f7,f26,f3
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64 - ctx.f3.f64));
	// addic. r15,r15,-1
	ctx.xer.ca = ctx.r15.u32 > 0;
	ctx.r15.s64 = ctx.r15.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r15.s32, 0, ctx.xer);
	// fmadds f3,f4,f31,f30
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f31.f64 + ctx.f30.f64));
	// add r3,r19,r3
	ctx.r3.u64 = ctx.r19.u64 + ctx.r3.u64;
	// fmuls f4,f4,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// add r4,r19,r4
	ctx.r4.u64 = ctx.r19.u64 + ctx.r4.u64;
	// fmadds f6,f6,f26,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f26.f64 + ctx.f2.f64));
	// subf r5,r19,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r19.s64;
	// subf r6,r19,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r19.s64;
	// addi r11,r11,248
	ctx.r11.s64 = ctx.r11.s64 + 248;
	// fsubs f2,f7,f3
	ctx.f2.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfs f2,0(r18)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// fadds f3,f7,f3
	ctx.f3.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// fmsubs f7,f5,f31,f4
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f31.f64 - ctx.f4.f64));
	// fadds f5,f6,f7
	ctx.f5.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// stfs f5,0(r17)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r17.u32 + 0, temp.u32);
	// stfs f3,0(r16)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fsubs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// stfs f7,0(r20)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// lwz r10,3532(r14)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r14.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d234cc
	if (!ctx.cr0.eq) goto loc_82D234CC;
loc_82D24AA8:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D24AB0;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D24AB8"))) PPC_WEAK_FUNC(sub_82D24AB8);
PPC_FUNC_IMPL(__imp__sub_82D24AB8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-8064
	ctx.r5.s64 = ctx.r11.s64 + -8064;
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// addi r4,r11,13408
	ctx.r4.s64 = ctx.r11.s64 + 13408;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D24AD0"))) PPC_WEAK_FUNC(sub_82D24AD0);
PPC_FUNC_IMPL(__imp__sub_82D24AD0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e44
	ctx.lr = 0x82D24AD8;
	__savegprlr_19(ctx, base);
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28ee0
	ctx.lr = 0x82D24AE0;
	__savefpr_14(ctx, base);
	// mulli r11,r9,120
	ctx.r11.s64 = ctx.r9.s64 * 120;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-120
	ctx.r11.s64 = ctx.r11.s64 + -120;
	// bge cr6,0x82d25298
	if (!ctx.cr6.lt) goto loc_82D25298;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r20,r9,r10
	ctx.r20.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// rlwinm r27,r7,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32236
	ctx.r7.s64 = -2112618496;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lfs f13,-8016(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,136(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D24B1C:
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f11,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// mulli r9,r8,20
	ctx.r9.s64 = ctx.r8.s64 * 20;
	// lfs f10,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f26,f9,f8
	ctx.f26.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// lfsx f6,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f6.f64 = double(temp.f32);
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f7,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// mulli r31,r8,24
	ctx.r31.s64 = ctx.r8.s64 * 24;
	// fadds f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fadds f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// fsubs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// lfsx f5,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfsx f2,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// mulli r29,r8,28
	ctx.r29.s64 = ctx.r8.s64 * 28;
	// lfsx f3,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fadds f4,f2,f3
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fsubs f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f3.f64));
	// mulli r28,r8,12
	ctx.r28.s64 = ctx.r8.s64 * 12;
	// add r26,r29,r5
	ctx.r26.u64 = ctx.r29.u64 + ctx.r5.u64;
	// add r25,r29,r6
	ctx.r25.u64 = ctx.r29.u64 + ctx.r6.u64;
	// rlwinm r30,r8,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// add r24,r28,r5
	ctx.r24.u64 = ctx.r28.u64 + ctx.r5.u64;
	// add r23,r28,r6
	ctx.r23.u64 = ctx.r28.u64 + ctx.r6.u64;
	// add r22,r29,r3
	ctx.r22.u64 = ctx.r29.u64 + ctx.r3.u64;
	// lfs f1,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// add r21,r28,r3
	ctx.r21.u64 = ctx.r28.u64 + ctx.r3.u64;
	// lfs f31,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fadds f2,f1,f11
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f11.f64));
	// lfsx f30,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f25,f10,f31
	ctx.f25.f64 = double(float(ctx.f10.f64 - ctx.f31.f64));
	// lfs f29,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f1.f64));
	// fadds f1,f29,f30
	ctx.f1.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// lfsx f28,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfs f27,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fadds f10,f31,f10
	ctx.f10.f64 = double(float(ctx.f31.f64 + ctx.f10.f64));
	// fsubs f31,f30,f29
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// add r29,r29,r4
	ctx.r29.u64 = ctx.r29.u64 + ctx.r4.u64;
	// fsubs f30,f28,f27
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// add r28,r28,r4
	ctx.r28.u64 = ctx.r28.u64 + ctx.r4.u64;
	// fadds f29,f27,f28
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fadds f28,f8,f26
	ctx.f28.f64 = double(float(ctx.f8.f64 + ctx.f26.f64));
	// fsubs f8,f26,f8
	ctx.f8.f64 = double(float(ctx.f26.f64 - ctx.f8.f64));
	// fadds f26,f4,f6
	ctx.f26.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fsubs f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// fadds f27,f5,f9
	ctx.f27.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// fsubs f9,f9,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f5.f64));
	// fadds f5,f3,f7
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// fadds f4,f1,f2
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fsubs f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// fsubs f3,f2,f1
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fsubs f2,f25,f30
	ctx.f2.f64 = double(float(ctx.f25.f64 - ctx.f30.f64));
	// fadds f1,f30,f25
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// lfs f25,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fadds f30,f31,f10
	ctx.f30.f64 = double(float(ctx.f31.f64 + ctx.f10.f64));
	// fsubs f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f31.f64));
	// fadds f31,f29,f11
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f11.f64));
	// fsubs f11,f11,f29
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f29.f64));
	// fsubs f29,f28,f26
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// fadds f24,f6,f8
	ctx.f24.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fsubs f6,f8,f6
	ctx.f6.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// fadds f26,f27,f4
	ctx.f26.f64 = double(float(ctx.f27.f64 + ctx.f4.f64));
	// fsubs f4,f4,f27
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f27.f64));
	// fadds f27,f2,f9
	ctx.f27.f64 = double(float(ctx.f2.f64 + ctx.f9.f64));
	// fsubs f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 - ctx.f9.f64));
	// fadds f2,f1,f5
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fsubs f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// fadds f1,f7,f3
	ctx.f1.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// fsubs f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// lfs f3,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f29,f29,f0
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f28,f28,f0
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f8,f24,f0
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// lfsx f14,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-304(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfsx f23,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f24,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f14,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-300(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fsubs f14,f24,f23
	ctx.f14.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfsx f21,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfsx f22,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f23,f21,f22
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfsx f19,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f20,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfsx f17,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// lfsx f18,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fadds f19,f17,f18
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f16,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// stfs f19,-272(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fsubs f19,f3,f16
	ctx.f19.f64 = double(float(ctx.f3.f64 - ctx.f16.f64));
	// fadds f3,f16,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 + ctx.f3.f64));
	// stfs f3,-288(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f3,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f15,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// stfs f19,-292(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fadds f19,f15,f25
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// fsubs f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// stfs f25,-276(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f16,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f3,f16
	ctx.f16.f64 = double(float(ctx.f3.f64 - ctx.f16.f64));
	// stfs f16,-296(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f16,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f16.f64 = double(temp.f32);
	// fadds f3,f16,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 + ctx.f3.f64));
	// stfs f3,-284(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lfs f3,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfs f16,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f16.f64 = double(temp.f32);
	// lfs f25,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f25.f64 = double(temp.f32);
	// fadds f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f3.f64));
	// fsubs f3,f3,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f25.f64));
	// stfs f3,-280(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fadds f25,f21,f23
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfs f25,-300(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fsubs f3,f23,f21
	ctx.f3.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// lfs f25,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f25.f64 = double(temp.f32);
	// lfs f17,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f17.f64 = double(temp.f32);
	// fadds f23,f25,f14
	ctx.f23.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// stfs f23,-268(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fsubs f21,f14,f25
	ctx.f21.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// fadds f25,f20,f24
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// stfs f21,-260(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// fmuls f14,f3,f13
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfs f23,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// lfs f15,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,-272(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fmuls f15,f3,f12
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// fmuls f3,f21,f12
	ctx.f3.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmuls f21,f23,f12
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// stfs f23,-264(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fadds f17,f17,f25
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// stfs f17,-304(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f17,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f25,f25,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f17.f64));
	// lfs f17,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f17.f64 = double(temp.f32);
	// stfs f3,-268(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fmr f3,f17
	ctx.f3.f64 = ctx.f17.f64;
	// stfs f21,-272(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fmadds f23,f3,f13,f15
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f15.f64));
	// fmsubs f21,f3,f12,f14
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 - ctx.f14.f64));
	// lfs f3,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f3.f64 = double(temp.f32);
	// lfs f15,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f17,f3,f13,f15
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f15.f64));
	// lfs f3,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f16,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 + ctx.f3.f64));
	// lfs f15,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f15,f3,f13,f15
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f15.f64));
	// lfs f14,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f24,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f20.f64));
	// fmsubs f3,f3,f12,f14
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 - ctx.f14.f64));
	// lfs f14,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f19,-296(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f19,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// stfs f19,-272(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f19,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f19,f12
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f20,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f20.f64 = double(temp.f32);
	// fadds f19,f18,f22
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f19,-292(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// lfs f18,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// lfs f14,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f26
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f26.f64));
	// stfs f14,-300(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f14,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// fmsubs f20,f20,f13,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f16.f64));
	// lfs f16,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,-260(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f16,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f18,-276(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f16,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f18,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// lfs f14,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f19,f14
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f14,-264(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfs f14,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f14,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f18,f14,f13,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 - ctx.f18.f64));
	// lfs f14,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f16,f14,f13,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f16,-280(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfs f16,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f16,f26
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f26.f64));
	// fsubs f16,f24,f22
	ctx.f16.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f24,-284(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lfs f24,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f24.f64 = double(temp.f32);
	// lfs f22,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f24
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f22,-288(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f22,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// stfs f24,-276(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f24,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f24.f64 = double(temp.f32);
	// fadds f22,f24,f2
	ctx.f22.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// stfs f22,-272(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fsubs f24,f2,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// lfs f22,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f22.f64 = double(temp.f32);
	// stfs f24,-264(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fadds f2,f18,f17
	ctx.f2.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// fmuls f22,f22,f24
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f24.f64));
	// fadds f24,f29,f30
	ctx.f24.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// stfs f24,-260(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// fadds f24,f2,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 + ctx.f24.f64));
	// stfs f24,-268(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// lfs f24,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f2,f24,f2
	ctx.f2.f64 = double(float(ctx.f24.f64 - ctx.f2.f64));
	// stfs f2,-296(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fadds f24,f8,f11
	ctx.f24.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// stfs f24,-260(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f2,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f20.f64));
	// fadds f24,f24,f2
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// stfs f24,-292(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f24,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f2,f24,f2
	ctx.f2.f64 = double(float(ctx.f24.f64 - ctx.f2.f64));
	// lfs f24,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fmsubs f26,f24,f26,f22
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f26.f64 - ctx.f22.f64));
	// stfs f26,-304(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f26,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// fmadds f26,f24,f26,f14
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f26.f64 + ctx.f14.f64));
	// stfs f26,-264(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfs f26,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,-260(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f24,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f22,f26,f24
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// lfs f26,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f26,f24
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// lfs f24,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f24.f64 = double(temp.f32);
	// lfs f29,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f20,f29
	ctx.f29.f64 = double(float(ctx.f20.f64 - ctx.f29.f64));
	// fmadds f26,f26,f24,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 + ctx.f22.f64));
	// lfs f22,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f24,f22,f24,f14
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f24.f64 - ctx.f14.f64));
	// lfs f22,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f22,f26
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// stfs f14,0(r3)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f14,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f14.f64 = double(temp.f32);
	// fadds f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// lfs f22,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f24,f14
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// stfs f14,0(r4)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfs f26,0(r5)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lfs f26,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// stfs f26,0(r6)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f26,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f26,f22
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f22.f64));
	// lfs f24,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f22,f24,f22
	ctx.f22.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// fmadds f24,f24,f2,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f2.f64 + ctx.f14.f64));
	// lfs f14,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f2,f26,f2,f22
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 - ctx.f22.f64));
	// lfs f26,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f22,f26,f24
	ctx.f22.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// stfsx f22,r30,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfs f24,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f24.f64 = double(temp.f32);
	// fadds f22,f2,f24
	ctx.f22.f64 = double(float(ctx.f2.f64 + ctx.f24.f64));
	// stfsx f22,r30,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// stfsx f26,r30,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fsubs f26,f18,f17
	ctx.f26.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f18,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f8,f2,f24
	ctx.f8.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// fadds f17,f18,f16
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// lfs f18,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfsx f8,r30,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f22,f25,f5
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// lfs f24,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f24.f64 = double(temp.f32);
	// fadds f2,f19,f4
	ctx.f2.f64 = double(float(ctx.f19.f64 + ctx.f4.f64));
	// lfs f8,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f4,f4,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f19.f64));
	// lfs f20,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f5,f5,f25
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f25.f64));
	// lfs f19,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f19.f64 = double(temp.f32);
	// lfs f25,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f18,f23,f15
	ctx.f18.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f14,-264(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fadds f14,f29,f30
	ctx.f14.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fadds f29,f11,f26
	ctx.f29.f64 = double(float(ctx.f11.f64 + ctx.f26.f64));
	// fsubs f11,f11,f26
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f26.f64));
	// stfs f11,-280(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfs f11,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f26,f24,f22
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// stfs f11,-260(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// fmuls f24,f24,f2
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// fmuls f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// fmsubs f2,f8,f2,f26
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f2.f64 - ctx.f26.f64));
	// stfs f2,-272(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f2,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f4
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// stfs f11,-260(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// fmadds f8,f8,f22,f24
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f22.f64 + ctx.f24.f64));
	// stfs f2,-268(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fadds f11,f17,f1
	ctx.f11.f64 = double(float(ctx.f17.f64 + ctx.f1.f64));
	// lfs f26,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f2,f1,f17
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f17.f64));
	// fadds f1,f26,f27
	ctx.f1.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// lfs f24,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f24.f64 = double(temp.f32);
	// lfs f22,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f4,f25,f4,f24
	ctx.f4.f64 = double(float(ctx.f25.f64 * ctx.f4.f64 - ctx.f24.f64));
	// fmadds f5,f25,f5,f22
	ctx.f5.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 + ctx.f22.f64));
	// fmuls f25,f20,f14
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f14.f64));
	// fmuls f22,f19,f14
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f14.f64));
	// fadds f24,f6,f10
	ctx.f24.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fsubs f6,f21,f3
	ctx.f6.f64 = double(float(ctx.f21.f64 - ctx.f3.f64));
	// fmadds f25,f19,f29,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f29.f64 + ctx.f25.f64));
	// fmsubs f29,f20,f29,f22
	ctx.f29.f64 = double(float(ctx.f20.f64 * ctx.f29.f64 - ctx.f22.f64));
	// lfs f22,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f22.f64 = double(temp.f32);
	// fadds f26,f18,f24
	ctx.f26.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// fsubs f24,f24,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// fsubs f20,f22,f25
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// stfsx f20,r10,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f20,f29,f8
	ctx.f20.f64 = double(float(ctx.f29.f64 + ctx.f8.f64));
	// stfsx f20,r10,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// stfsx f25,r10,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f8,f29,f8
	ctx.f8.f64 = double(float(ctx.f29.f64 - ctx.f8.f64));
	// stfsx f8,r10,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f8,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f8.f64 = double(temp.f32);
	// lfs f29,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f22,f8,f30
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fmuls f20,f29,f30
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f30.f64));
	// lfs f25,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f30,f29,f25,f22
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f25.f64 + ctx.f22.f64));
	// lfs f22,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f8,f8,f25,f20
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f25.f64 - ctx.f20.f64));
	// lfs f20,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// lfs f20,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// fsubs f29,f4,f30
	ctx.f29.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// stfsx f29,r31,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// fadds f30,f8,f5
	ctx.f30.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// stfsx f30,r31,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// stfsx f4,r31,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fsubs f8,f8,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// stfsx f8,r31,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f4,f31,f28
	ctx.f4.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// fadds f8,f3,f21
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f21.f64));
	// lfs f30,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f30.f64 = double(temp.f32);
	// fadds f3,f28,f31
	ctx.f3.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f30,f1
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f1.f64));
	// lfs f25,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f28,f22,f0
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// lfs f29,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f30,f30,f11
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fadds f31,f15,f23
	ctx.f31.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// fmuls f23,f20,f0
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmuls f20,f25,f26
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fadds f22,f4,f8
	ctx.f22.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fsubs f8,f4,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f8.f64));
	// fmsubs f11,f5,f11,f21
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 - ctx.f21.f64));
	// fadds f4,f6,f10
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fmadds f5,f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 + ctx.f30.f64));
	// fadds f1,f28,f7
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f7.f64));
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fsubs f6,f3,f31
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fsubs f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f28.f64));
	// fadds f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// fmuls f30,f25,f22
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f22.f64));
	// fadds f31,f23,f9
	ctx.f31.f64 = double(float(ctx.f23.f64 + ctx.f9.f64));
	// fsubs f9,f9,f23
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f23.f64));
	// fmadds f30,f29,f26,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f26.f64 + ctx.f30.f64));
	// fmsubs f29,f29,f22,f20
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f22.f64 - ctx.f20.f64));
	// fsubs f28,f11,f30
	ctx.f28.f64 = double(float(ctx.f11.f64 - ctx.f30.f64));
	// stfsx f28,r7,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f28,f29,f5
	ctx.f28.f64 = double(float(ctx.f29.f64 + ctx.f5.f64));
	// stfsx f28,r7,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fadds f11,f30,f11
	ctx.f11.f64 = double(float(ctx.f30.f64 + ctx.f11.f64));
	// stfsx f11,r7,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// fsubs f11,f29,f5
	ctx.f11.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// stfsx f11,r7,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// addic. r20,r20,-1
	ctx.xer.ca = ctx.r20.u32 > 0;
	ctx.r20.s64 = ctx.r20.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r20.s32, 0, ctx.xer);
	// lfs f5,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f5.f64 = double(temp.f32);
	// lfs f30,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f28,f5,f27
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// lfs f29,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f26,f30,f24
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f24.f64));
	// fmuls f25,f5,f2
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// lfs f11,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f24,f29,f24
	ctx.f24.f64 = double(float(ctx.f29.f64 * ctx.f24.f64));
	// fmsubs f5,f11,f2,f28
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f2.f64 - ctx.f28.f64));
	// fmadds f2,f29,f8,f26
	ctx.f2.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 + ctx.f26.f64));
	// fmadds f11,f11,f27,f25
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f27.f64 + ctx.f25.f64));
	// fmsubs f8,f30,f8,f24
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 - ctx.f24.f64));
	// fsubs f30,f5,f2
	ctx.f30.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// stfsx f30,r9,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fadds f2,f8,f11
	ctx.f2.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// stfsx f2,r9,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f5,r9,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 - ctx.f11.f64));
	// stfsx f11,r9,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// add r4,r27,r4
	ctx.r4.u64 = ctx.r27.u64 + ctx.r4.u64;
	// lfs f8,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f8.f64 = double(temp.f32);
	// subf r5,r27,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r27.s64;
	// fmuls f30,f8,f31
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// lfs f11,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f29,f8,f1
	ctx.f29.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// lfs f5,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f2.f64 = double(temp.f32);
	// subf r6,r27,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r27.s64;
	// fmsubs f8,f11,f1,f30
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 - ctx.f30.f64));
	// fmuls f1,f5,f4
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// fmadds f11,f11,f31,f29
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f31.f64 + ctx.f29.f64));
	// fmuls f31,f2,f4
	ctx.f31.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// fmadds f4,f2,f6,f1
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f1.f64));
	// fmsubs f6,f5,f6,f31
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f6.f64 - ctx.f31.f64));
	// fsubs f5,f8,f4
	ctx.f5.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// stfs f5,0(r21)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// fadds f8,f4,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fadds f5,f6,f11
	ctx.f5.f64 = double(float(ctx.f6.f64 + ctx.f11.f64));
	// stfs f5,0(r28)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// stfs f8,0(r24)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fsubs f11,f6,f11
	ctx.f11.f64 = double(float(ctx.f6.f64 - ctx.f11.f64));
	// stfs f11,0(r23)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// lfs f8,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f8.f64 = double(temp.f32);
	// lfs f6,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f4,f8,f9
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f5,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f2,f6,f10
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmuls f1,f8,f7
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// lfs f11,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f31,f5,f10
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// addi r11,r11,120
	ctx.r11.s64 = ctx.r11.s64 + 120;
	// fmsubs f10,f11,f7,f4
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f7.f64 - ctx.f4.f64));
	// fmadds f8,f5,f3,f2
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f3.f64 + ctx.f2.f64));
	// fmadds f11,f11,f9,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f9.f64 + ctx.f1.f64));
	// fmsubs f9,f6,f3,f31
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 - ctx.f31.f64));
	// fsubs f7,f10,f8
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// stfs f7,0(r22)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// fadds f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fadds f8,f9,f11
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// stfs f8,0(r29)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// stfs f10,0(r26)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fsubs f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// stfs f11,0(r25)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// lwz r10,3532(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d24b1c
	if (!ctx.cr0.eq) goto loc_82D24B1C;
loc_82D25298:
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28f2c
	ctx.lr = 0x82D252A0;
	__restfpr_14(ctx, base);
	// b 0x82e28e94
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D252A8"))) PPC_WEAK_FUNC(sub_82D252A8);
PPC_FUNC_IMPL(__imp__sub_82D252A8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-7984
	ctx.r5.s64 = ctx.r11.s64 + -7984;
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// addi r4,r11,19152
	ctx.r4.s64 = ctx.r11.s64 + 19152;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D252C0"))) PPC_WEAK_FUNC(sub_82D252C0);
PPC_FUNC_IMPL(__imp__sub_82D252C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D252C8;
	__savegprlr_26(ctx, base);
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28ef8
	ctx.lr = 0x82D252D0;
	__savefpr_20(ctx, base);
	// mulli r11,r9,56
	ctx.r11.s64 = ctx.r9.s64 * 56;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-56
	ctx.r11.s64 = ctx.r11.s64 + -56;
	// bge cr6,0x82d25584
	if (!ctx.cr6.lt) goto loc_82D25584;
	// subf r30,r9,r10
	ctx.r30.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f0,140(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D252FC:
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f5,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f26,f13,f7
	ctx.f26.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
	// rlwinm r9,r8,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f24,f11,f5
	ctx.f24.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// add r29,r7,r3
	ctx.r29.u64 = ctx.r7.u64 + ctx.r3.u64;
	// lfsx f6,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// add r28,r7,r4
	ctx.r28.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fadds f13,f7,f13
	ctx.f13.f64 = double(float(ctx.f7.f64 + ctx.f13.f64));
	// fadds f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 + ctx.f11.f64));
	// add r27,r7,r5
	ctx.r27.u64 = ctx.r7.u64 + ctx.r5.u64;
	// fadds f25,f6,f12
	ctx.f25.f64 = double(float(ctx.f6.f64 + ctx.f12.f64));
	// add r7,r7,r6
	ctx.r7.u64 = ctx.r7.u64 + ctx.r6.u64;
	// lfsx f4,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f12,f6,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// lfsx f2,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f23,f4,f10
	ctx.f23.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// lfs f3,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// lfs f1,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f7,f3,f2
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// lfsx f31,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f6,f2,f3
	ctx.f6.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fadds f5,f31,f1
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// lfsx f30,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f4,f1,f31
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// lfsx f28,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f2,f29,f30
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// lfs f27,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f3,f30,f29
	ctx.f3.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fsubs f31,f28,f27
	ctx.f31.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f1,f27,f28
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fadds f29,f25,f26
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f30,f26,f25
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fadds f28,f13,f6
	ctx.f28.f64 = double(float(ctx.f13.f64 + ctx.f6.f64));
	// fsubs f27,f7,f5
	ctx.f27.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// fadds f7,f5,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fadds f26,f2,f11
	ctx.f26.f64 = double(float(ctx.f2.f64 + ctx.f11.f64));
	// fsubs f11,f11,f2
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f2.f64));
	// fadds f21,f12,f4
	ctx.f21.f64 = double(float(ctx.f12.f64 + ctx.f4.f64));
	// fsubs f12,f12,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f4.f64));
	// fadds f5,f3,f23
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f23.f64));
	// fadds f22,f31,f10
	ctx.f22.f64 = double(float(ctx.f31.f64 + ctx.f10.f64));
	// fsubs f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f31.f64));
	// fsubs f25,f24,f1
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f1.f64));
	// fadds f4,f30,f27
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// fsubs f2,f7,f29
	ctx.f2.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// fsubs f31,f27,f30
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f30.f64));
	// fadds f30,f29,f7
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// fadds f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f24.f64));
	// fadds f7,f28,f26
	ctx.f7.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// fsubs f3,f23,f3
	ctx.f3.f64 = double(float(ctx.f23.f64 - ctx.f3.f64));
	// fsubs f13,f6,f13
	ctx.f13.f64 = double(float(ctx.f6.f64 - ctx.f13.f64));
	// fsubs f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// fadds f6,f21,f22
	ctx.f6.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f31,f31,f0
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f30,f30,f0
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fsubs f26,f22,f21
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f29,f4,f25
	ctx.f29.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// fadds f27,f2,f5
	ctx.f27.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// fmuls f24,f9,f27
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// fmuls f23,f8,f27
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fsubs f27,f3,f31
	ctx.f27.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fmadds f24,f8,f29,f24
	ctx.f24.f64 = double(float(ctx.f8.f64 * ctx.f29.f64 + ctx.f24.f64));
	// fsubs f8,f7,f24
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f24.f64));
	// stfs f8,0(r3)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f20,f24,f7
	ctx.f20.f64 = double(float(ctx.f24.f64 + ctx.f7.f64));
	// fsubs f8,f11,f12
	ctx.f8.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// fsubs f7,f10,f13
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f13.f64));
	// fadds f24,f30,f1
	ctx.f24.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fmsubs f9,f9,f29,f23
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f29.f64 - ctx.f23.f64));
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// fadds f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// fadds f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f10.f64));
	// fsubs f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// fsubs f4,f25,f4
	ctx.f4.f64 = double(float(ctx.f25.f64 - ctx.f4.f64));
	// fadds f11,f9,f6
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f6.f64));
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfs f20,0(r5)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f11,f9,f6
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// stfs f11,0(r6)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f10,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f2,f10,f7
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// lfs f6,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f29,f9,f27
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// fmuls f25,f10,f8
	ctx.f25.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f11,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f27,f6,f27
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// fmsubs f10,f11,f8,f2
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 - ctx.f2.f64));
	// fmadds f8,f6,f24,f29
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 + ctx.f29.f64));
	// fmadds f11,f11,f7,f25
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64 + ctx.f25.f64));
	// fmsubs f9,f9,f24,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f24.f64 - ctx.f27.f64));
	// fsubs f7,f10,f8
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// stfsx f7,r10,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fadds f8,f9,f11
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// stfsx f8,r10,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfsx f10,r10,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// stfsx f11,r10,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f10,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f7,f10,f26
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// lfs f8,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f9,f5
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmuls f2,f10,f28
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// lfs f11,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f5,f8,f5
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// fmsubs f10,f11,f28,f7
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f28.f64 - ctx.f7.f64));
	// fmadds f8,f8,f4,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f4.f64 + ctx.f6.f64));
	// fmadds f11,f11,f26,f2
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f26.f64 + ctx.f2.f64));
	// fmsubs f9,f9,f4,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f4.f64 - ctx.f5.f64));
	// fsubs f6,f1,f30
	ctx.f6.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// fsubs f7,f10,f8
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// stfsx f7,r9,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fadds f8,f9,f11
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// stfsx f8,r9,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f10,r9,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// stfsx f11,r9,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f8,f31,f3
	ctx.f8.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// lfs f10,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fmuls f5,f10,f13
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f11,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f10,f12
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f9,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// lfs f7,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f7.f64 = double(temp.f32);
	// subf r5,r31,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r31.s64;
	// subf r6,r31,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r31.s64;
	// addi r11,r11,56
	ctx.r11.s64 = ctx.r11.s64 + 56;
	// fmsubs f12,f11,f12,f5
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f12.f64 - ctx.f5.f64));
	// fmadds f13,f11,f13,f10
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f10.f64));
	// fmuls f11,f9,f8
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// fmuls f10,f7,f8
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// fmadds f11,f7,f6,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f6.f64 + ctx.f11.f64));
	// fmsubs f10,f9,f6,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f6.f64 - ctx.f10.f64));
	// fsubs f9,f12,f11
	ctx.f9.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// stfs f9,0(r29)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fadds f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// fadds f11,f10,f13
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// stfs f11,0(r28)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// stfs f12,0(r27)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fsubs f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 - ctx.f13.f64));
	// stfs f13,0(r7)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// lwz r10,3532(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d252fc
	if (!ctx.cr0.eq) goto loc_82D252FC;
loc_82D25584:
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28f44
	ctx.lr = 0x82D2558C;
	__restfpr_20(ctx, base);
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D25590"))) PPC_WEAK_FUNC(sub_82D25590);
PPC_FUNC_IMPL(__imp__sub_82D25590) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-7928
	ctx.r5.s64 = ctx.r11.s64 + -7928;
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// addi r4,r11,21184
	ctx.r4.s64 = ctx.r11.s64 + 21184;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D255A8"))) PPC_WEAK_FUNC(sub_82D255A8);
PPC_FUNC_IMPL(__imp__sub_82D255A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D255B0;
	__savegprlr_28(ctx, base);
	// mulli r11,r9,24
	ctx.r11.s64 = ctx.r9.s64 * 24;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-24
	ctx.r11.s64 = ctx.r11.s64 + -24;
	// bge cr6,0x82d256f4
	if (!ctx.cr6.lt) goto loc_82D256F4;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r9,r9,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D255D4:
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// add r30,r10,r6
	ctx.r30.u64 = ctx.r10.u64 + ctx.r6.u64;
	// lfs f0,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// add r29,r10,r3
	ctx.r29.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lfs f11,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// add r31,r10,r5
	ctx.r31.u64 = ctx.r10.u64 + ctx.r5.u64;
	// lfs f10,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lfs f9,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// lfs f7,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fadds f3,f7,f13
	ctx.f3.f64 = double(float(ctx.f7.f64 + ctx.f13.f64));
	// fsubs f2,f6,f12
	ctx.f2.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// lfs f8,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f5,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f4,f0,f8
	ctx.f4.f64 = double(float(ctx.f0.f64 - ctx.f8.f64));
	// fadds f12,f12,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
	// fadds f1,f11,f5
	ctx.f1.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// fadds f0,f8,f0
	ctx.f0.f64 = double(float(ctx.f8.f64 + ctx.f0.f64));
	// fsubs f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 - ctx.f11.f64));
	// fsubs f13,f13,f7
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
	// fadds f8,f2,f3
	ctx.f8.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fsubs f7,f4,f1
	ctx.f7.f64 = double(float(ctx.f4.f64 - ctx.f1.f64));
	// fadds f5,f12,f0
	ctx.f5.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fadds f6,f1,f4
	ctx.f6.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fsubs f4,f3,f2
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// fadds f3,f11,f13
	ctx.f3.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// fmuls f12,f10,f8
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// fmuls f11,f9,f8
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// fmadds f12,f9,f7,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f7.f64 + ctx.f12.f64));
	// fmsubs f11,f10,f7,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f7.f64 - ctx.f11.f64));
	// fsubs f10,f5,f12
	ctx.f10.f64 = double(float(ctx.f5.f64 - ctx.f12.f64));
	// stfs f10,0(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f10,f11,f3
	ctx.f10.f64 = double(float(ctx.f11.f64 + ctx.f3.f64));
	// stfs f10,0(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f12,f12,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f5.f64));
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f12,f11,f3
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f3.f64));
	// stfs f12,0(r6)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f11,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// add r3,r7,r3
	ctx.r3.u64 = ctx.r7.u64 + ctx.r3.u64;
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f11,f13
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f7,f9,f6
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f5,f12,f13
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f9,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// add r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 + ctx.r4.u64;
	// subf r5,r7,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r7.s64;
	// subf r6,r7,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r7.s64;
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// fmsubs f13,f12,f0,f8
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 - ctx.f8.f64));
	// fmadds f12,f10,f4,f7
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 + ctx.f7.f64));
	// fmadds f0,f11,f0,f5
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 + ctx.f5.f64));
	// fmsubs f11,f10,f6,f9
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f6.f64 - ctx.f9.f64));
	// fsubs f10,f13,f12
	ctx.f10.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// stfs f10,0(r29)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fadds f12,f11,f0
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// stfs f13,0(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fsubs f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// stfs f0,0(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// lwz r10,3532(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d255d4
	if (!ctx.cr0.eq) goto loc_82D255D4;
loc_82D256F4:
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D256F8"))) PPC_WEAK_FUNC(sub_82D256F8);
PPC_FUNC_IMPL(__imp__sub_82D256F8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-7872
	ctx.r5.s64 = ctx.r11.s64 + -7872;
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// addi r4,r11,21928
	ctx.r4.s64 = ctx.r11.s64 + 21928;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D25710"))) PPC_WEAK_FUNC(sub_82D25710);
PPC_FUNC_IMPL(__imp__sub_82D25710) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D25718;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D25720;
	__savefpr_14(ctx, base);
	// mulli r11,r9,248
	ctx.r11.s64 = ctx.r9.s64 * 248;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-248
	ctx.r11.s64 = ctx.r11.s64 + -248;
	// bge cr6,0x82d26d58
	if (!ctx.cr6.lt) goto loc_82D26D58;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r15,r9,r10
	ctx.r15.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r19,r7,2,0,29
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r7,-32236
	ctx.r7.s64 = -2112618496;
	// lfs f8,-8000(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8000);
	ctx.f8.f64 = double(temp.f32);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f9,-8004(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -8004);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-8008(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8008);
	ctx.f10.f64 = double(temp.f32);
	// lis r14,-32234
	ctx.r14.s64 = -2112487424;
	// lfs f11,-8012(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8012);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,136(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D2577C:
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// lfs f7,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// mulli r9,r8,48
	ctx.r9.s64 = ctx.r8.s64 * 48;
	// lfs f6,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f18,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f3,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f2,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f22,f5,f3
	ctx.f22.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// rlwinm r7,r8,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f21,f2,f4
	ctx.f21.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// mulli r31,r8,44
	ctx.r31.s64 = ctx.r8.s64 * 44;
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// lfsx f17,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f1,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f30,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f2,f31,f1
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// lfsx f29,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r30,r8,60
	ctx.r30.s64 = ctx.r8.s64 * 60;
	// fsubs f3,f1,f31
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// lfsx f15,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f1,f29,f30
	ctx.f1.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fsubs f31,f30,f29
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// lfsx f28,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f27,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f30,f7,f28
	ctx.f30.f64 = double(float(ctx.f7.f64 - ctx.f28.f64));
	// rlwinm r29,r8,5,0,26
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f29,f27,f6
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f6.f64));
	// mulli r28,r8,28
	ctx.r28.s64 = ctx.r8.s64 * 28;
	// fadds f7,f28,f7
	ctx.f7.f64 = double(float(ctx.f28.f64 + ctx.f7.f64));
	// fsubs f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// lfsx f26,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f25,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f24,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f28,f26,f25
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfsx f23,r28,r6
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fadds f26,f23,f24
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f25,f24,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f21,f22
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f23,f22,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f21,f1,f3
	ctx.f21.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fsubs f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// fadds f22,f2,f5
	ctx.f22.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// fsubs f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 - ctx.f5.f64));
	// fsubs f1,f29,f28
	ctx.f1.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fadds f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fadds f19,f26,f30
	ctx.f19.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// fsubs f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// fadds f20,f27,f7
	ctx.f20.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fsubs f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// fadds f28,f21,f24
	ctx.f28.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// fsubs f26,f3,f23
	ctx.f26.f64 = double(float(ctx.f3.f64 - ctx.f23.f64));
	// fsubs f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// fadds f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 + ctx.f23.f64));
	// fsubs f27,f4,f31
	ctx.f27.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// fsubs f2,f6,f25
	ctx.f2.f64 = double(float(ctx.f6.f64 - ctx.f25.f64));
	// fadds f4,f31,f4
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// lfsx f31,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f6,f25,f6
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f6.f64));
	// lfsx f25,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f3,f28,f0
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f28,f26,f0
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmuls f26,f24,f0
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f24,f23,f0
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fadds f23,f22,f20
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// fsubs f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// fadds f16,f27,f7
	ctx.f16.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fsubs f21,f19,f3
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f3.f64));
	// fadds f20,f28,f1
	ctx.f20.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// fsubs f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// fadds f28,f26,f29
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fsubs f29,f29,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// fadds f26,f30,f24
	ctx.f26.f64 = double(float(ctx.f30.f64 + ctx.f24.f64));
	// fadds f3,f3,f19
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// lfs f19,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// lfs f24,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fadds f14,f2,f5
	ctx.f14.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// stfs f14,-300(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fsubs f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 - ctx.f5.f64));
	// lfsx f2,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,-420(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// fadds f2,f6,f4
	ctx.f2.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// fsubs f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// lfsx f4,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,-460(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fsubs f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// lfsx f4,r29,r6
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r6.u32);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,-456(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfsx f4,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,-444(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfsx f4,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,-484(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfsx f4,r29,r5
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r5.u32);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,-428(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fsubs f4,f31,f25
	ctx.f4.f64 = double(float(ctx.f31.f64 - ctx.f25.f64));
	// fadds f31,f25,f31
	ctx.f31.f64 = double(float(ctx.f25.f64 + ctx.f31.f64));
	// lfsx f27,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f25,f17,f18
	ctx.f25.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfsx f14,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f2,-480(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fsubs f17,f15,f27
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// lfsx f2,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f27,f27,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// lfs f15,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-496(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fsubs f15,f2,f24
	ctx.f15.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// stfs f15,-472(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f15,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f15.f64 = double(temp.f32);
	// fadds f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f24.f64));
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-420(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// stfs f2,-492(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f15.f64 = double(temp.f32);
	// lfs f2,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f14.f64 = double(temp.f32);
	// lfs f24,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f24.f64 = double(temp.f32);
	// fadds f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// fadds f24,f24,f2
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// stfs f24,-488(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f24,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// lfs f24,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f24.f64));
	// stfs f24,-428(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f19,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f19.f64 = double(temp.f32);
	// lfs f24,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// fadds f19,f25,f4
	ctx.f19.f64 = double(float(ctx.f25.f64 + ctx.f4.f64));
	// fsubs f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f25.f64));
	// fsubs f25,f31,f27
	ctx.f25.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// stfs f25,-460(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fadds f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// lfs f25,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f17.f64));
	// lfs f27,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f18.f64));
	// stfs f27,-456(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f27,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f15.f64));
	// stfs f27,-444(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f27,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 + ctx.f27.f64));
	// lfs f15,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-472(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,-488(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,-496(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f14,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f19,f25
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f25.f64));
	// lfs f17,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f25,f19
	ctx.f19.f64 = double(float(ctx.f25.f64 + ctx.f19.f64));
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-380(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fadds f17,f18,f27
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f27.f64));
	// stfs f17,-412(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f17,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f27,f27,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f18.f64));
	// fadds f17,f31,f17
	ctx.f17.f64 = double(float(ctx.f31.f64 + ctx.f17.f64));
	// stfs f17,-388(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// rlwinm r27,r8,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f17,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f17.f64 = double(temp.f32);
	// mulli r26,r8,56
	ctx.r26.s64 = ctx.r8.s64 * 56;
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f2,f14
	ctx.f14.f64 = double(float(ctx.f2.f64 - ctx.f14.f64));
	// stfs f14,-484(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f25,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f25.f64 = double(temp.f32);
	// mulli r25,r8,36
	ctx.r25.s64 = ctx.r8.s64 * 36;
	// fadds f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f14,-364(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// mulli r24,r8,24
	ctx.r24.s64 = ctx.r8.s64 * 24;
	// mulli r20,r8,20
	ctx.r20.s64 = ctx.r8.s64 * 20;
	// mulli r23,r8,40
	ctx.r23.s64 = ctx.r8.s64 * 40;
	// lfs f18,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,-360(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-488(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f14,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f4,f14
	ctx.f14.f64 = double(float(ctx.f4.f64 + ctx.f14.f64));
	// fsubs f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f25.f64));
	// lfs f25,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfs f25,-496(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f25,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f25.f64 = double(temp.f32);
	// stfs f4,-484(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fadds f4,f24,f25
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// lfs f25,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f19,f0
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fsubs f31,f25,f31
	ctx.f31.f64 = double(float(ctx.f25.f64 - ctx.f31.f64));
	// lfs f25,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f25.f64 = double(temp.f32);
	// fadds f2,f25,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// fmuls f25,f17,f12
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// stfs f25,-448(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// fmuls f25,f14,f0
	ctx.f25.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f19,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f14,f18,f13,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f14,-384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fmsubs f18,f18,f12,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 - ctx.f17.f64));
	// stfs f18,-396(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fmuls f17,f15,f12
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfs f18,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f18,f12
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// fadds f18,f27,f31
	ctx.f18.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// fsubs f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f31.f64));
	// lfs f27,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f13,f17
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 + ctx.f17.f64));
	// lfs f17,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f25
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// stfs f17,-348(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f17,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f25,f17,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 - ctx.f25.f64));
	// fmsubs f17,f15,f13,f14
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f17,-308(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fsubs f17,f4,f24
	ctx.f17.f64 = double(float(ctx.f4.f64 - ctx.f24.f64));
	// stfs f17,-304(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fadds f4,f24,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f4.f64));
	// lfsx f14,r24,r5
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// add r18,r20,r3
	ctx.r18.u64 = ctx.r20.u64 + ctx.r3.u64;
	// stfs f14,-492(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// add r17,r20,r4
	ctx.r17.u64 = ctx.r20.u64 + ctx.r4.u64;
	// lfsx f14,r24,r6
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// rlwinm r22,r8,3,0,28
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// stfs f14,-496(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// mulli r21,r8,52
	ctx.r21.s64 = ctx.r8.s64 * 52;
	// lfsx f14,r23,r5
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-488(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfsx f14,r23,r6
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-472(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// stfs f4,-336(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fsubs f4,f19,f2
	ctx.f4.f64 = double(float(ctx.f19.f64 - ctx.f2.f64));
	// stfs f4,-320(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fadds f4,f2,f19
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// stfs f4,-400(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfsx f2,r26,r5
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r5.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f4,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f14,f2,f4
	ctx.f14.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// lfsx f19,r26,r6
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f24,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f2,f24,f19
	ctx.f2.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// lfsx f17,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// lfsx f15,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfs f19,-456(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f19,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f19,-460(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f19,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// lfs f17,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,-496(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f17,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f15,-328(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,-484(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f17,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f15,-492(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f15,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-444(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f15,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f2,f14
	ctx.f14.f64 = double(float(ctx.f2.f64 - ctx.f14.f64));
	// stfs f14,-468(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f14,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f14.f64 = double(temp.f32);
	// fadds f2,f14,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 + ctx.f2.f64));
	// stfs f2,-460(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f2,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f2.f64 = double(temp.f32);
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f2
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f2.f64));
	// stfs f14,-452(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f14.f64));
	// fadds f14,f24,f19
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f19.f64));
	// stfs f14,-428(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// fsubs f14,f4,f14
	ctx.f14.f64 = double(float(ctx.f4.f64 - ctx.f14.f64));
	// stfs f14,-368(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fadds f4,f14,f4
	ctx.f4.f64 = double(float(ctx.f14.f64 + ctx.f4.f64));
	// lfsx f14,r22,r6
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f24,-416(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfsx f24,r22,r5
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r5.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f19,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f14,-484(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfsx f14,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-492(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfsx f14,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfsx f14,r21,r5
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-496(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfsx f14,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-448(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfsx f14,r21,r6
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-488(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// fadds f14,f19,f24
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// stfs f24,-332(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f24,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f24.f64 = double(temp.f32);
	// lfs f19,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f24
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// stfs f19,-472(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f19,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f24.f64));
	// stfs f24,-492(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f24,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f24.f64 = double(temp.f32);
	// lfs f19,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f24
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// stfs f19,-432(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f19,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// stfs f24,-440(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f24,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f24.f64 = double(temp.f32);
	// lfs f19,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f24
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// stfs f19,-404(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f19,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// lfs f19,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f19.f64 = double(temp.f32);
	// stfs f24,-376(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fsubs f24,f19,f14
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// fadds f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f19,-456(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f19,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f14,-488(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,-496(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f14,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,-492(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f17,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f17,f24
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f24.f64));
	// stfs f14,-484(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fadds f24,f24,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f17.f64));
	// stfs f24,-420(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f24,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f24.f64 = double(temp.f32);
	// lfs f17,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f24,f17
	ctx.f17.f64 = double(float(ctx.f24.f64 - ctx.f17.f64));
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f14,-468(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// stfs f15,-472(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fadds f15,f2,f19
	ctx.f15.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// fsubs f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f19.f64));
	// lfs f19,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f19.f64 = double(temp.f32);
	// fadds f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfs f19,-496(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f14,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f19,-380(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f19,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,-392(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f19,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f24,f24,f0
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,-424(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// fmuls f19,f17,f0
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f19,-448(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// fmuls f19,f15,f0
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f19,-452(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// stfs f24,-436(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f2,-408(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// add r16,r20,r5
	ctx.r16.u64 = ctx.r20.u64 + ctx.r5.u64;
	// lfs f2,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f2.f64 = double(temp.f32);
	// add r20,r20,r6
	ctx.r20.u64 = ctx.r20.u64 + ctx.r6.u64;
	// fmuls f24,f2,f13
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f19,f2,f12
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f2,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f17,f2,f12
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f2,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f15,f2,f12
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f2,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f14,f14,f2
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f2.f64));
	// stfs f14,-332(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fadds f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f14.f64));
	// stfs f2,-328(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f14,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f14.f64 = double(temp.f32);
	// lfs f2,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f2.f64 = double(temp.f32);
	// fadds f14,f2,f14
	ctx.f14.f64 = double(float(ctx.f2.f64 + ctx.f14.f64));
	// stfs f14,-456(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f14,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f2,f14,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 - ctx.f2.f64));
	// stfs f2,-340(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f2,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f24,f2,f12,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 - ctx.f24.f64));
	// stfs f24,-344(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fmadds f2,f2,f13,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f19.f64));
	// stfs f2,-352(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f2,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f2.f64 = double(temp.f32);
	// lfs f24,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f24.f64 = double(temp.f32);
	// fadds f19,f2,f24
	ctx.f19.f64 = double(float(ctx.f2.f64 + ctx.f24.f64));
	// lfsx f14,r27,r6
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// stfs f2,-356(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfs f2,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f2,f2,f13,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 - ctx.f17.f64));
	// stfs f2,-316(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f2,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f2,f2,f13,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f2,-380(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f2,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f2.f64 = double(temp.f32);
	// stfs f14,-484(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fsubs f24,f4,f2
	ctx.f24.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// lfsx f14,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// stfs f14,-492(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfsx f14,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f4,-464(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f2,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f4.f64 = double(temp.f32);
	// stfs f14,-496(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfsx f14,r25,r5
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f24,-312(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fadds f24,f2,f4
	ctx.f24.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// stfs f14,-448(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// fsubs f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// lfsx f14,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-468(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// stfs f4,-368(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfsx f14,r25,r6
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f4,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfs f2,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// stfs f19,-372(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// stfs f24,-324(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// stfs f14,-488(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// fsubs f14,f4,f2
	ctx.f14.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// lfsx f24,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfs f19,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f17,r27,r5
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f15,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fadds f2,f19,f24
	ctx.f2.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// stfs f24,-460(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fsubs f24,f17,f15
	ctx.f24.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f19,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f19.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f15,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f15,-452(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f15,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f19,-428(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f19,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f15,-484(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f19,-492(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f19,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f15,-448(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// lfs f15,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f15.f64 = double(temp.f32);
	// stfs f19,-444(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fsubs f19,f15,f14
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f14.f64 = double(temp.f32);
	// stfs f15,-496(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fadds f15,f2,f14
	ctx.f15.f64 = double(float(ctx.f2.f64 + ctx.f14.f64));
	// fsubs f2,f14,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 - ctx.f2.f64));
	// stfs f2,-472(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f2,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f4,f2
	ctx.f2.f64 = double(float(ctx.f4.f64 + ctx.f2.f64));
	// stfs f2,-440(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f2,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f2.f64 = double(temp.f32);
	// lfs f14,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f14.f64));
	// stfs f2,-404(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f2,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// lfs f2,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f2.f64 = double(temp.f32);
	// stfs f4,-420(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// fadds f4,f14,f2
	ctx.f4.f64 = double(float(ctx.f14.f64 + ctx.f2.f64));
	// fsubs f2,f14,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 - ctx.f2.f64));
	// stfs f2,-488(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f2,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f2.f64 = double(temp.f32);
	// fadds f14,f2,f24
	ctx.f14.f64 = double(float(ctx.f2.f64 + ctx.f24.f64));
	// stfs f14,-484(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fsubs f2,f24,f2
	ctx.f2.f64 = double(float(ctx.f24.f64 - ctx.f2.f64));
	// lfs f24,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f17.f64));
	// stfs f24,-432(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f14,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f14.f64 = double(temp.f32);
	// lfs f24,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// stfs f24,-416(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f24,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f4,f12
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// fsubs f24,f17,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 - ctx.f24.f64));
	// stfs f24,-492(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// fmuls f24,f19,f12
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f17,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// stfs f2,-476(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmuls f4,f4,f13
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// stfs f4,-448(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,-468(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fmadds f4,f15,f13,f24
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f24.f64));
	// lfs f24,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f24,f13,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f24,-436(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fmsubs f2,f15,f12,f19
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f19.f64));
	// lfs f24,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f24.f64 = double(temp.f32);
	// lfs f19,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f24
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// stfs f19,-408(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f19,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// fmadds f19,f17,f13,f14
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f14.f64));
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f17,f17,f12,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f14.f64));
	// lfs f14,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f15,f15,f13,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 - ctx.f14.f64));
	// fsubs f14,f4,f19
	ctx.f14.f64 = double(float(ctx.f4.f64 - ctx.f19.f64));
	// fadds f4,f19,f4
	ctx.f4.f64 = double(float(ctx.f19.f64 + ctx.f4.f64));
	// stfs f4,-468(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fadds f4,f17,f2
	ctx.f4.f64 = double(float(ctx.f17.f64 + ctx.f2.f64));
	// stfs f4,-484(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fsubs f4,f2,f17
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f17.f64));
	// stfs f4,-452(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f4,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f4.f64 = double(temp.f32);
	// fadds f2,f15,f4
	ctx.f2.f64 = double(float(ctx.f15.f64 + ctx.f4.f64));
	// stfs f2,-432(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fsubs f4,f15,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 - ctx.f4.f64));
	// stfs f4,-448(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f4,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,-436(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f4,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// lfs f2,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f15,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f10
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// lfs f17,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f10
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// fmsubs f4,f15,f13,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 - ctx.f4.f64));
	// stfs f4,-496(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f4,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f4,f4,f13,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f2.f64));
	// stfs f4,-440(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f4,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f15,f4,f11
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// lfs f4,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// stfs f4,-476(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f2,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f4,f2,f11,f19
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 - ctx.f19.f64));
	// lfs f2,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f2,f2,f11,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f17.f64));
	// stfs f2,-488(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f19,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f19.f64 = double(temp.f32);
	// lfs f2,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// stfs f2,-472(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f19,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f19.f64 = double(temp.f32);
	// lfs f2,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// stfs f2,-376(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f19,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f17.f64 = double(temp.f32);
	// lfs f2,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f28.f64));
	// stfs f2,-460(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f2,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f19.f64));
	// lfs f19,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f10,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 + ctx.f15.f64));
	// stfs f19,-456(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f19,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f19,-372(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f17,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// lfs f17,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f17,f17,f11,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 - ctx.f15.f64));
	// stfs f17,-476(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f17,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,-364(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f17,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f23
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// stfs f17,-404(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f15,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,-416(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f15,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,-444(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f15,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f23,-492(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f15,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f15.f64 = double(temp.f32);
	// lfs f23,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f23,-424(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f23,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f28,f28,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// stfs f28,-388(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f23,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f23.f64 = double(temp.f32);
	// lfs f28,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f28.f64 = double(temp.f32);
	// fadds f15,f23,f28
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// stfs f15,-440(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fsubs f28,f28,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// stfs f28,-348(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f28,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f28.f64 = double(temp.f32);
	// fadds f23,f28,f4
	ctx.f23.f64 = double(float(ctx.f28.f64 + ctx.f4.f64));
	// stfs f23,-496(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fsubs f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f28.f64));
	// stfs f4,-408(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f28,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f28.f64 = double(temp.f32);
	// lfs f4,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f4.f64 = double(temp.f32);
	// fadds f23,f28,f4
	ctx.f23.f64 = double(float(ctx.f28.f64 + ctx.f4.f64));
	// stfs f23,-412(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fsubs f4,f28,f4
	ctx.f4.f64 = double(float(ctx.f28.f64 - ctx.f4.f64));
	// stfs f4,-376(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f4,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f15,f2,f4
	ctx.f15.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// fadds f23,f4,f2
	ctx.f23.f64 = double(float(ctx.f4.f64 + ctx.f2.f64));
	// lfs f2,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f4.f64 = double(temp.f32);
	// fadds f28,f2,f4
	ctx.f28.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// stfs f28,-392(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fsubs f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// stfs f4,-488(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f4,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f4.f64 = double(temp.f32);
	// fadds f2,f4,f19
	ctx.f2.f64 = double(float(ctx.f4.f64 + ctx.f19.f64));
	// stfs f2,-476(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fsubs f19,f4,f19
	ctx.f19.f64 = double(float(ctx.f4.f64 - ctx.f19.f64));
	// fmuls f2,f23,f0
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f23,f15,f0
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f4,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f4.f64 = double(temp.f32);
	// stfs f23,-404(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f28,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f4
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f4.f64));
	// stfs f28,-364(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f28,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f28.f64));
	// stfs f4,-416(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f28,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f28.f64 = double(temp.f32);
	// lfs f4,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f4.f64 = double(temp.f32);
	// lfs f23,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f23.f64 = double(temp.f32);
	// fadds f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f28.f64));
	// fsubs f28,f28,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// lfs f15,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f15.f64 = double(temp.f32);
	// lfs f23,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f23,-432(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fmuls f23,f19,f0
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f19,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f19.f64 = double(temp.f32);
	// stfs f23,-372(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// fadds f23,f19,f26
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f26.f64));
	// fsubs f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f19.f64));
	// lfs f19,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f19,-492(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f19,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f15,-480(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f15,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// stfs f19,-476(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f15,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f19,-388(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f19,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f15,-440(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f15,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// stfs f19,-424(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// fadds f19,f15,f23
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f23,-408(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f23,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f15,f26,f23
	ctx.f15.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// stfs f15,-496(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fadds f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// lfs f23,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f23.f64 = double(temp.f32);
	// stfs f26,-392(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f15,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f15.f64 = double(temp.f32);
	// fadds f26,f15,f23
	ctx.f26.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// fsubs f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// stfs f23,-412(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f23,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f23.f64 = double(temp.f32);
	// fadds f15,f23,f17
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f17.f64));
	// stfs f15,-488(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// fsubs f23,f23,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f17.f64));
	// stfs f23,-476(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f23,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f23.f64 = double(temp.f32);
	// stfs f23,-480(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fmuls f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f19.f64));
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f23,f15,f17,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f17.f64 + ctx.f23.f64));
	// lfs f15,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f17.f64));
	// lfs f15,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// stfs f15,0(r3)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f15,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// lfs f23,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f23,f19,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f19.f64 - ctx.f17.f64));
	// fadds f19,f23,f26
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f19,0(r4)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// stfs f15,0(r5)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// stfs f26,0(r6)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f17,196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 196);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-436(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f23,184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	ctx.f23.f64 = double(temp.f32);
	// stfs f23,-480(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f17,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f17.f64 = double(temp.f32);
	// lfs f26,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f26,f17
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// lfs f26,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f23,f17
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// lfs f19,192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 192);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f26
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f26.f64));
	// lfs f23,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f26.f64));
	// lfs f23,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f23.f64 = double(temp.f32);
	// stfs f26,-480(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fmsubs f23,f23,f28,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f28.f64 - ctx.f15.f64));
	// stfs f23,-476(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// lfs f23,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f26,f15,f23,f19
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f23.f64 + ctx.f19.f64));
	// lfs f19,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f28,f19,f28,f17
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f28.f64 + ctx.f17.f64));
	// lfs f19,192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 192);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f23,f19,f23,f17
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f23.f64 - ctx.f17.f64));
	// lfs f19,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f17,f19,f26
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// stfsx f17,r9,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// lfs f15,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f23,f28
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// stfsx f19,r9,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f26,r9,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f28,f23,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 - ctx.f28.f64));
	// stfsx f28,r9,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f23.f64 = double(temp.f32);
	// stfs f23,-480(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f26,124(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 124);
	ctx.f26.f64 = double(temp.f32);
	// lfs f19,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f26,f15
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f15.f64));
	// fmuls f19,f26,f19
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// lfs f23,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f23.f64 = double(temp.f32);
	// lfs f26,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f23,f17
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// fmuls f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f26.f64));
	// lfs f28,120(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 120);
	ctx.f28.f64 = double(temp.f32);
	// lfs f23,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f28,f23,f19
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f23.f64 - ctx.f19.f64));
	// stfs f23,-476(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f19,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f19.f64 = double(temp.f32);
	// lfs f23,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f23.f64 = double(temp.f32);
	// stfs f26,-480(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fmadds f26,f23,f19,f17
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f19.f64 + ctx.f17.f64));
	// lfs f19,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f28,f28,f19,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64 + ctx.f15.f64));
	// lfs f19,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f23,f23,f19,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f19.f64 - ctx.f17.f64));
	// lfs f19,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f17,f19,f26
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// stfsx f17,r29,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fadds f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// lfs f17,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f23,f28
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// stfsx f19,r29,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// stfsx f26,r29,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fsubs f28,f23,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 - ctx.f28.f64));
	// stfsx f28,r29,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// lfs f26,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f26,f17
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// fmuls f17,f28,f17
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// lfs f19,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f19.f64 = double(temp.f32);
	// lfs f23,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f28,f28,f4,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f4.f64 - ctx.f15.f64));
	// stfs f28,-436(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fmadds f4,f26,f4,f17
	ctx.f4.f64 = double(float(ctx.f26.f64 * ctx.f4.f64 + ctx.f17.f64));
	// stfs f4,-424(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f4,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f28,f4,f11
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// lfs f4,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f26,f4,f11
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// lfs f4,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f17,f4,f11
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// lfs f15,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f11
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// fmsubs f4,f4,f10,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f10.f64 - ctx.f28.f64));
	// lfs f28,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f28,f10,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 - ctx.f26.f64));
	// lfs f26,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f10,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f10.f64 + ctx.f17.f64));
	// stfs f26,-440(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f26,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f26.f64 = double(temp.f32);
	// stfs f4,-476(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fadds f26,f26,f7
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f7.f64));
	// lfs f4,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f4.f64 = double(temp.f32);
	// stfs f28,-336(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fmuls f4,f19,f4
	ctx.f4.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// lfs f28,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f28.f64 = double(temp.f32);
	// stfs f26,-368(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fmuls f28,f23,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// lfs f26,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f26.f64 = double(temp.f32);
	// lfs f17,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f17.f64 = double(temp.f32);
	// stfs f4,-464(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// stfs f28,-480(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fadds f4,f26,f17
	ctx.f4.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// lfs f26,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f10,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f10.f64 + ctx.f15.f64));
	// stfs f26,-400(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f26,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f26.f64 = double(temp.f32);
	// lfs f17,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f17.f64 = double(temp.f32);
	// fadds f28,f26,f17
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// lfs f17,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f17.f64 = double(temp.f32);
	// lfs f26,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f23,f26,f17
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 + ctx.f17.f64));
	// lfs f17,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f3,f17
	ctx.f17.f64 = double(float(ctx.f3.f64 - ctx.f17.f64));
	// stfs f17,-464(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f17,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f1
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f1.f64));
	// stfs f17,-412(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f17,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f17.f64 = double(temp.f32);
	// lfs f23,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// lfs f15,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f19,f19,f17,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f5,f5,f15
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f15.f64));
	// lfs f15,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f7,f7,f15
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f15.f64));
	// stfs f7,-384(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f15,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f15.f64 = double(temp.f32);
	// lfs f7,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f7,f15,f7
	ctx.f7.f64 = double(float(ctx.f15.f64 - ctx.f7.f64));
	// lfs f15,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f1,f1,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f15.f64));
	// lfs f15,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f15.f64 = double(temp.f32);
	// fadds f3,f15,f3
	ctx.f3.f64 = double(float(ctx.f15.f64 + ctx.f3.f64));
	// stfs f3,-352(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f3,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f3.f64 = double(temp.f32);
	// lfs f15,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f3
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f3.f64));
	// stfs f15,-468(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f15,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f3,f3,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f15.f64));
	// stfs f3,-452(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f3,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f4,f3
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// stfs f3,-480(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f3,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f3.f64 = double(temp.f32);
	// lfs f15,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f3,f15
	ctx.f15.f64 = double(float(ctx.f3.f64 - ctx.f15.f64));
	// stfs f15,-396(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f15,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f15.f64 = double(temp.f32);
	// fadds f3,f15,f3
	ctx.f3.f64 = double(float(ctx.f15.f64 + ctx.f3.f64));
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f26.f64));
	// stfsx f15,r7,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// fadds f26,f26,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f15.f64));
	// fadds f15,f23,f28
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// stfs f15,-344(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f15,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f28,f23,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 - ctx.f28.f64));
	// fsubs f4,f15,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 - ctx.f4.f64));
	// lfs f15,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f19,f15
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfsx f15,r7,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// stfsx f26,r7,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f5,f17
	ctx.f23.f64 = double(float(ctx.f5.f64 + ctx.f17.f64));
	// lfs f26,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f5,f5,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f17.f64));
	// fsubs f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// stfsx f26,r7,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// lfs f26,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f26.f64 = double(temp.f32);
	// lfs f19,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f7,f15
	ctx.f15.f64 = double(float(ctx.f7.f64 + ctx.f15.f64));
	// stfs f15,-440(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f15,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f7,f15,f7
	ctx.f7.f64 = double(float(ctx.f15.f64 - ctx.f7.f64));
	// stfs f7,-400(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f7,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f7.f64 = double(temp.f32);
	// lfs f15,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f7
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f7.f64));
	// stfs f15,-384(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f15,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f1,f15
	ctx.f15.f64 = double(float(ctx.f1.f64 - ctx.f15.f64));
	// stfs f15,-476(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f15,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f7,f7,f15
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f15.f64));
	// lfs f15,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f15.f64 = double(temp.f32);
	// fadds f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 + ctx.f1.f64));
	// stfs f1,-452(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f1,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f1.f64 = double(temp.f32);
	// lfs f15,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f1
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f1.f64));
	// stfs f15,-464(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f15,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f3,f15
	ctx.f15.f64 = double(float(ctx.f3.f64 + ctx.f15.f64));
	// stfs f15,-468(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f15,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f1,f1,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f15.f64));
	// lfs f15,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f3,f15,f3
	ctx.f3.f64 = double(float(ctx.f15.f64 - ctx.f3.f64));
	// stfs f3,-396(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f3,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f19,f3
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// lfs f3,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fmsubs f3,f26,f3,f15
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f3.f64 - ctx.f15.f64));
	// lfs f15,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f26,f26,f15,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f15.f64 + ctx.f19.f64));
	// stfs f26,-480(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f26,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f26.f64 = double(temp.f32);
	// lfs f19,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f26,f19
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// lfs f19,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// stfs f26,-464(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fmadds f26,f17,f19,f15
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f19.f64 + ctx.f15.f64));
	// lfs f19,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f19,f17,f19,f15
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f19.f64 - ctx.f15.f64));
	// fsubs f17,f3,f26
	ctx.f17.f64 = double(float(ctx.f3.f64 - ctx.f26.f64));
	// stfsx f17,r10,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f26,f26,f3
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// lfs f3,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f3.f64 = double(temp.f32);
	// fadds f17,f19,f3
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f3.f64));
	// stfsx f17,r10,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfsx f26,r10,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f3,f19,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 - ctx.f3.f64));
	// stfsx f3,r10,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f26,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f26.f64 = double(temp.f32);
	// lfs f3,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f26,f5
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fmuls f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// stfs f5,-464(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f19,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f19.f64 = double(temp.f32);
	// lfs f26,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f19,f19,f26
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f26.f64));
	// lfs f17,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f26
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f26.f64));
	// lfs f26,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f5,f3,f26,f15
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f26.f64 - ctx.f15.f64));
	// lfs f3,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f3.f64 = double(temp.f32);
	// lfs f26,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f3,f3,f26,f19
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f26.f64 + ctx.f19.f64));
	// lfs f26,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f26.f64 = double(temp.f32);
	// lfs f19,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f26,f26,f19,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f19.f64 + ctx.f15.f64));
	// lfs f19,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f19,f19,f15,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f15.f64 - ctx.f17.f64));
	// fsubs f17,f5,f3
	ctx.f17.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfsx f17,r30,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fadds f3,f19,f26
	ctx.f3.f64 = double(float(ctx.f19.f64 + ctx.f26.f64));
	// stfsx f3,r30,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// stfsx f5,r30,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fsubs f5,f19,f26
	ctx.f5.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// stfsx f5,r30,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f3,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f3,f28
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// lfs f19,180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 180);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f3,f3,f4
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// stfs f3,-464(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fmuls f15,f19,f7
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f7.f64));
	// lfs f5,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f19,f19,f1
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// lfs f26,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f4,f5,f4,f17
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f4.f64 - ctx.f17.f64));
	// fmadds f3,f26,f1,f15
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 + ctx.f15.f64));
	// fmsubs f7,f26,f7,f19
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 - ctx.f19.f64));
	// fmuls f15,f25,f8
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// fsubs f1,f4,f3
	ctx.f1.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// stfsx f1,r31,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// lfs f1,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f1.f64 = double(temp.f32);
	// lfs f17,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f5,f5,f28,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f28.f64 + ctx.f17.f64));
	// fadds f3,f7,f5
	ctx.f3.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// stfsx f3,r31,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// stfsx f4,r31,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// stfsx f7,r31,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f7,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f7.f64 = double(temp.f32);
	// lfs f5,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f26,f7,f23
	ctx.f26.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// fmuls f28,f5,f23
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// lfs f4,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f23,f4,f1
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// lfs f1,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f5,f5,f1,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 + ctx.f26.f64));
	// fmsubs f7,f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f1.f64 - ctx.f28.f64));
	// lfs f1,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f3,f1,f23
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f1.f64 + ctx.f23.f64));
	// lfs f23,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f23.f64 = double(temp.f32);
	// lfs f28,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f23,f8
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fmuls f19,f28,f8
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// lfs f28,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f17,f28,f8
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// fmsubs f28,f28,f9,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f9.f64 - ctx.f26.f64));
	// fmadds f26,f25,f9,f19
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f9.f64 + ctx.f19.f64));
	// lfs f25,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f19,f3,f25
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f3,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f3,f18
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f18.f64));
	// stfs f3,-356(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfs f25,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f3,f23,f9,f17
	ctx.f3.f64 = double(float(ctx.f23.f64 * ctx.f9.f64 + ctx.f17.f64));
	// fadds f17,f25,f31
	ctx.f17.f64 = double(float(ctx.f25.f64 + ctx.f31.f64));
	// lfs f25,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f25.f64 = double(temp.f32);
	// fadds f23,f24,f6
	ctx.f23.f64 = double(float(ctx.f24.f64 + ctx.f6.f64));
	// stfs f23,-464(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f23,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f23.f64 = double(temp.f32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// stfs f25,-340(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fadds f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// lfs f25,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f6,f6,f24
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f24.f64));
	// stfs f23,-360(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fmsubs f25,f25,f9,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f9.f64 - ctx.f15.f64));
	// lfs f23,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f29
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// stfs f23,-468(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fsubs f23,f7,f1
	ctx.f23.f64 = double(float(ctx.f7.f64 - ctx.f1.f64));
	// stfsx f23,r28,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f23,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f4,f4,f23,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f23.f64 - ctx.f19.f64));
	// lfs f19,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f23,f19,f0
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fadds f19,f1,f7
	ctx.f19.f64 = double(float(ctx.f1.f64 + ctx.f7.f64));
	// lfs f1,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f18,f1,f18
	ctx.f18.f64 = double(float(ctx.f1.f64 - ctx.f18.f64));
	// lfs f1,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f7,f17,f0
	ctx.f7.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fsubs f17,f31,f1
	ctx.f17.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// lfs f1,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f1,f22,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 - ctx.f1.f64));
	// lfs f31,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f24,f17,f0
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fsubs f31,f29,f31
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f31.f64));
	// lfs f29,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// lfs f17,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f29,f18,f0
	ctx.f29.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// lfs f18,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f18.f64 = double(temp.f32);
	// fadds f22,f26,f28
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fsubs f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// fadds f26,f25,f3
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f3.f64));
	// fsubs f3,f25,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 - ctx.f3.f64));
	// fadds f25,f4,f5
	ctx.f25.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// stfsx f25,r28,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// stfsx f19,r28,r5
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fsubs f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// stfsx f5,r28,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f25,f17,f7
	ctx.f25.f64 = double(float(ctx.f17.f64 + ctx.f7.f64));
	// fadds f5,f23,f18
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// lfs f19,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// lfs f4,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f7,f17,f7
	ctx.f7.f64 = double(float(ctx.f17.f64 - ctx.f7.f64));
	// fadds f15,f6,f29
	ctx.f15.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// lfs f17,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f29.f64));
	// fadds f29,f24,f1
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f1.f64));
	// fsubs f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f24.f64));
	// lfs f24,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f24,-356(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fsubs f24,f31,f28
	ctx.f24.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// stfs f24,-340(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f24,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f24.f64 = double(temp.f32);
	// fadds f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// lfs f28,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f22,f30,f3
	ctx.f22.f64 = double(float(ctx.f30.f64 - ctx.f3.f64));
	// stfs f22,-464(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f22,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f22.f64 = double(temp.f32);
	// fadds f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f30.f64));
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fmuls f30,f19,f25
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f25.f64));
	// fsubs f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// fmuls f22,f19,f5
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f5.f64));
	// fsubs f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// lfs f18,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f5,f4,f5,f30
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f5.f64 - ctx.f30.f64));
	// fmadds f4,f4,f25,f22
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f25.f64 + ctx.f22.f64));
	// lfs f25,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f30,f17,f25
	ctx.f30.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// fmadds f30,f18,f28,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 + ctx.f30.f64));
	// fmuls f28,f17,f28
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// fsubs f22,f5,f30
	ctx.f22.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// stfsx f22,r22,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f30,f5
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// fmsubs f5,f18,f25,f28
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f25.f64 - ctx.f28.f64));
	// lfs f25,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f25.f64 = double(temp.f32);
	// fadds f28,f5,f4
	ctx.f28.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// stfsx f28,r22,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// stfsx f30,r22,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r5.u32, temp.u32);
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfsx f5,r22,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// lfs f4,220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f4.f64 = double(temp.f32);
	// lfs f30,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f22,f4,f6
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f5,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f19,f30,f25
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lfs f28,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f5,f6
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fmuls f17,f28,f25
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// lfs f25,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f6,f5,f1,f22
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 - ctx.f22.f64));
	// fmadds f5,f28,f25,f19
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f25.f64 + ctx.f19.f64));
	// fmadds f4,f4,f1,f18
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f1.f64 + ctx.f18.f64));
	// fmsubs f1,f30,f25,f17
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f25.f64 - ctx.f17.f64));
	// fsubs f30,f6,f5
	ctx.f30.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// stfsx f30,r26,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fadds f5,f1,f4
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// stfsx f5,r26,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// stfsx f6,r26,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fsubs f6,f1,f4
	ctx.f6.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// stfsx f6,r26,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// lfs f5,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f5.f64 = double(temp.f32);
	// lfs f1,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f30,f5,f7
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// fmuls f28,f1,f24
	ctx.f28.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// lfs f6,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f25,f5,f23
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// lfs f4,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f22,f1,f26
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// lfs f17,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f5,f6,f23,f30
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f23.f64 - ctx.f30.f64));
	// fmadds f1,f4,f26,f28
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f26.f64 + ctx.f28.f64));
	// lfs f26,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f7,f6,f7,f25
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f7.f64 + ctx.f25.f64));
	// fmsubs f6,f4,f24,f22
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f24.f64 - ctx.f22.f64));
	// fsubs f4,f5,f1
	ctx.f4.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// stfsx f4,r23,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fadds f4,f6,f7
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// stfsx f4,r23,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// stfsx f5,r23,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f7.f64));
	// stfsx f7,r23,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// lfs f6,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f6,f15
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f15.f64));
	// fmuls f30,f7,f15
	ctx.f30.f64 = double(float(ctx.f7.f64 * ctx.f15.f64));
	// lfs f4,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f4,f31
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f15,f5,f31
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fmsubs f7,f7,f29,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f29.f64 - ctx.f1.f64));
	// lfs f1,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f6,f6,f29,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f29.f64 + ctx.f30.f64));
	// lfs f30,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f25,f1,f8
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// lfs f29,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f24,f30,f8
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// fmuls f23,f1,f9
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// fmuls f28,f30,f9
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// fmadds f5,f5,f3,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f3.f64 + ctx.f22.f64));
	// fmsubs f4,f4,f3,f15
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 - ctx.f15.f64));
	// fsubs f3,f17,f27
	ctx.f3.f64 = double(float(ctx.f17.f64 - ctx.f27.f64));
	// fadds f22,f14,f20
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// fsubs f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// fmadds f30,f26,f9,f25
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f9.f64 + ctx.f25.f64));
	// lfs f25,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f31,f29,f9,f24
	ctx.f31.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 + ctx.f24.f64));
	// lfs f24,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f26,f26,f8,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f8.f64 - ctx.f23.f64));
	// lfs f23,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f1,f29,f8,f28
	ctx.f1.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 - ctx.f28.f64));
	// fadds f28,f17,f27
	ctx.f28.f64 = double(float(ctx.f17.f64 + ctx.f27.f64));
	// lfs f27,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f27.f64 = double(temp.f32);
	// fadds f29,f2,f16
	ctx.f29.f64 = double(float(ctx.f2.f64 + ctx.f16.f64));
	// fadds f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f19.f64));
	// fsubs f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 - ctx.f27.f64));
	// lfs f19,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f19.f64 = double(temp.f32);
	// fadds f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f18.f64));
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// lfs f18,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f18.f64 = double(temp.f32);
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// fadds f17,f26,f31
	ctx.f17.f64 = double(float(ctx.f26.f64 + ctx.f31.f64));
	// fsubs f31,f26,f31
	ctx.f31.f64 = double(float(ctx.f26.f64 - ctx.f31.f64));
	// fsubs f26,f7,f5
	ctx.f26.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// stfsx f26,r24,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fadds f18,f30,f1
	ctx.f18.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fadds f26,f5,f7
	ctx.f26.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fsubs f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// fadds f30,f28,f29
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fsubs f5,f29,f28
	ctx.f5.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fadds f29,f4,f6
	ctx.f29.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// stfsx f29,r24,r4
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// stfsx f26,r24,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fsubs f2,f16,f2
	ctx.f2.f64 = double(float(ctx.f16.f64 - ctx.f2.f64));
	// fadds f7,f24,f25
	ctx.f7.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fsubs f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// stfsx f6,r24,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fsubs f6,f24,f25
	ctx.f6.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// fadds f24,f18,f23
	ctx.f24.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// lfs f28,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// lfs f4,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f18,f21,f31
	ctx.f18.f64 = double(float(ctx.f21.f64 - ctx.f31.f64));
	// lfs f25,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f25.f64 = double(temp.f32);
	// fadds f31,f31,f21
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f21.f64));
	// fmuls f21,f28,f7
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f7.f64));
	// fadds f26,f19,f2
	ctx.f26.f64 = double(float(ctx.f19.f64 + ctx.f2.f64));
	// fmuls f28,f28,f30
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// fsubs f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f19.f64));
	// fsubs f19,f20,f1
	ctx.f19.f64 = double(float(ctx.f20.f64 - ctx.f1.f64));
	// fadds f1,f1,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f20.f64));
	// fadds f20,f17,f22
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fadds f29,f27,f3
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// fsubs f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 - ctx.f3.f64));
	// lfs f27,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fmsubs f30,f4,f30,f21
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f30.f64 - ctx.f21.f64));
	// fmadds f7,f4,f7,f28
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f7.f64 + ctx.f28.f64));
	// fmuls f4,f25,f24
	ctx.f4.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// fmuls f28,f25,f20
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f20.f64));
	// fmadds f4,f27,f20,f4
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 + ctx.f4.f64));
	// fmsubs f28,f27,f24,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f24.f64 - ctx.f28.f64));
	// fsubs f27,f30,f4
	ctx.f27.f64 = double(float(ctx.f30.f64 - ctx.f4.f64));
	// stfsx f27,r27,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fadds f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f30.f64));
	// fadds f30,f28,f7
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f7.f64));
	// stfsx f30,r27,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// stfsx f4,r27,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f28,f7
	ctx.f7.f64 = double(float(ctx.f28.f64 - ctx.f7.f64));
	// stfsx f7,r27,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// lfs f30,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f30.f64 = double(temp.f32);
	// lfs f4,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f25,f30,f19
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f19.f64));
	// lfs f7,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f27,f4,f3
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f28,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f24,f7,f3
	ctx.f24.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// fmuls f21,f28,f19
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fmadds f3,f28,f18,f25
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f18.f64 + ctx.f25.f64));
	// fmsubs f7,f7,f2,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f2.f64 - ctx.f27.f64));
	// fmadds f4,f4,f2,f24
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64 + ctx.f24.f64));
	// fmsubs f2,f30,f18,f21
	ctx.f2.f64 = double(float(ctx.f30.f64 * ctx.f18.f64 - ctx.f21.f64));
	// fsubs f30,f7,f3
	ctx.f30.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfsx f30,r21,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// fadds f3,f2,f4
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// stfsx f3,r21,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// stfsx f7,r21,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f2,f4
	ctx.f7.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// stfsx f7,r21,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r6.u32, temp.u32);
	// lfs f4,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f4.f64 = double(temp.f32);
	// lfs f2,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f30,f4,f6
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// fmuls f28,f2,f23
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f3,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f27,f4,f5
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// lfs f7,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// fmsubs f5,f7,f5,f30
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f5.f64 - ctx.f30.f64));
	// fmadds f4,f3,f22,f28
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 + ctx.f28.f64));
	// fmadds f7,f7,f6,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64 + ctx.f27.f64));
	// fmsubs f6,f3,f23,f2
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f23.f64 - ctx.f2.f64));
	// fsubs f3,f5,f4
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfsx f3,r25,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fadds f4,f6,f7
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// stfsx f4,r25,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// stfsx f5,r25,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f7.f64));
	// stfsx f7,r25,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// lfs f7,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f2,f7,f29
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// lfs f5,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f3,f6,f29
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// lfs f4,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f30,f5,f1
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// fmsubs f7,f7,f26,f3
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64 - ctx.f3.f64));
	// addic. r15,r15,-1
	ctx.xer.ca = ctx.r15.u32 > 0;
	ctx.r15.s64 = ctx.r15.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r15.s32, 0, ctx.xer);
	// fmadds f3,f4,f31,f30
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f31.f64 + ctx.f30.f64));
	// add r3,r19,r3
	ctx.r3.u64 = ctx.r19.u64 + ctx.r3.u64;
	// fmuls f4,f4,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// add r4,r19,r4
	ctx.r4.u64 = ctx.r19.u64 + ctx.r4.u64;
	// fmadds f6,f6,f26,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f26.f64 + ctx.f2.f64));
	// subf r5,r19,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r19.s64;
	// subf r6,r19,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r19.s64;
	// addi r11,r11,248
	ctx.r11.s64 = ctx.r11.s64 + 248;
	// fsubs f2,f7,f3
	ctx.f2.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfs f2,0(r18)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// fadds f3,f7,f3
	ctx.f3.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// fmsubs f7,f5,f31,f4
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f31.f64 - ctx.f4.f64));
	// fadds f5,f6,f7
	ctx.f5.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// stfs f5,0(r17)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r17.u32 + 0, temp.u32);
	// stfs f3,0(r16)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fsubs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// stfs f7,0(r20)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// lwz r10,3532(r14)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r14.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d2577c
	if (!ctx.cr0.eq) goto loc_82D2577C;
loc_82D26D58:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D26D60;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D26D68"))) PPC_WEAK_FUNC(sub_82D26D68);
PPC_FUNC_IMPL(__imp__sub_82D26D68) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-7816
	ctx.r5.s64 = ctx.r11.s64 + -7816;
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// addi r4,r11,22288
	ctx.r4.s64 = ctx.r11.s64 + 22288;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D26D80"))) PPC_WEAK_FUNC(sub_82D26D80);
PPC_FUNC_IMPL(__imp__sub_82D26D80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e44
	ctx.lr = 0x82D26D88;
	__savegprlr_19(ctx, base);
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28ee0
	ctx.lr = 0x82D26D90;
	__savefpr_14(ctx, base);
	// mulli r11,r9,120
	ctx.r11.s64 = ctx.r9.s64 * 120;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-120
	ctx.r11.s64 = ctx.r11.s64 + -120;
	// bge cr6,0x82d27548
	if (!ctx.cr6.lt) goto loc_82D27548;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r20,r9,r10
	ctx.r20.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// rlwinm r27,r7,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32236
	ctx.r7.s64 = -2112618496;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lfs f13,-8016(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,136(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D26DCC:
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f11,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// mulli r9,r8,20
	ctx.r9.s64 = ctx.r8.s64 * 20;
	// lfs f10,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f26,f9,f8
	ctx.f26.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// lfsx f6,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f6.f64 = double(temp.f32);
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f7,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// mulli r31,r8,24
	ctx.r31.s64 = ctx.r8.s64 * 24;
	// fadds f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fadds f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// fsubs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// lfsx f5,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfsx f2,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// mulli r29,r8,28
	ctx.r29.s64 = ctx.r8.s64 * 28;
	// lfsx f3,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fadds f4,f2,f3
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fsubs f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f3.f64));
	// mulli r28,r8,12
	ctx.r28.s64 = ctx.r8.s64 * 12;
	// add r26,r29,r5
	ctx.r26.u64 = ctx.r29.u64 + ctx.r5.u64;
	// add r25,r29,r6
	ctx.r25.u64 = ctx.r29.u64 + ctx.r6.u64;
	// rlwinm r30,r8,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// add r24,r28,r5
	ctx.r24.u64 = ctx.r28.u64 + ctx.r5.u64;
	// add r23,r28,r6
	ctx.r23.u64 = ctx.r28.u64 + ctx.r6.u64;
	// add r22,r29,r3
	ctx.r22.u64 = ctx.r29.u64 + ctx.r3.u64;
	// lfs f1,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// add r21,r28,r3
	ctx.r21.u64 = ctx.r28.u64 + ctx.r3.u64;
	// lfs f31,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fadds f2,f1,f11
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f11.f64));
	// lfsx f30,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f25,f10,f31
	ctx.f25.f64 = double(float(ctx.f10.f64 - ctx.f31.f64));
	// lfs f29,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f1.f64));
	// fadds f1,f29,f30
	ctx.f1.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// lfsx f28,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfs f27,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fadds f10,f31,f10
	ctx.f10.f64 = double(float(ctx.f31.f64 + ctx.f10.f64));
	// fsubs f31,f30,f29
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// add r29,r29,r4
	ctx.r29.u64 = ctx.r29.u64 + ctx.r4.u64;
	// fsubs f30,f28,f27
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// add r28,r28,r4
	ctx.r28.u64 = ctx.r28.u64 + ctx.r4.u64;
	// fadds f29,f27,f28
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fadds f28,f8,f26
	ctx.f28.f64 = double(float(ctx.f8.f64 + ctx.f26.f64));
	// fsubs f8,f26,f8
	ctx.f8.f64 = double(float(ctx.f26.f64 - ctx.f8.f64));
	// fadds f26,f4,f6
	ctx.f26.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fsubs f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// fadds f27,f5,f9
	ctx.f27.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// fsubs f9,f9,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f5.f64));
	// fadds f5,f3,f7
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// fadds f4,f1,f2
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fsubs f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// fsubs f3,f2,f1
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fsubs f2,f25,f30
	ctx.f2.f64 = double(float(ctx.f25.f64 - ctx.f30.f64));
	// fadds f1,f30,f25
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// lfs f25,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fadds f30,f31,f10
	ctx.f30.f64 = double(float(ctx.f31.f64 + ctx.f10.f64));
	// fsubs f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f31.f64));
	// fadds f31,f29,f11
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f11.f64));
	// fsubs f11,f11,f29
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f29.f64));
	// fsubs f29,f28,f26
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// fadds f24,f6,f8
	ctx.f24.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fsubs f6,f8,f6
	ctx.f6.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// fadds f26,f27,f4
	ctx.f26.f64 = double(float(ctx.f27.f64 + ctx.f4.f64));
	// fsubs f4,f4,f27
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f27.f64));
	// fadds f27,f2,f9
	ctx.f27.f64 = double(float(ctx.f2.f64 + ctx.f9.f64));
	// fsubs f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 - ctx.f9.f64));
	// fadds f2,f1,f5
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fsubs f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// fadds f1,f7,f3
	ctx.f1.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// fsubs f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// lfs f3,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f29,f29,f0
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f28,f28,f0
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f8,f24,f0
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// lfsx f14,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-304(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfsx f23,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f24,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f14,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-300(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fsubs f14,f24,f23
	ctx.f14.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfsx f21,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfsx f22,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f23,f21,f22
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfsx f19,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f20,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfsx f17,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// lfsx f18,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fadds f19,f17,f18
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f16,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// stfs f19,-272(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fsubs f19,f3,f16
	ctx.f19.f64 = double(float(ctx.f3.f64 - ctx.f16.f64));
	// fadds f3,f16,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 + ctx.f3.f64));
	// stfs f3,-288(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f3,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f15,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// stfs f19,-292(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fadds f19,f15,f25
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// fsubs f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// stfs f25,-276(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f16,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f3,f16
	ctx.f16.f64 = double(float(ctx.f3.f64 - ctx.f16.f64));
	// stfs f16,-296(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f16,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f16.f64 = double(temp.f32);
	// fadds f3,f16,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 + ctx.f3.f64));
	// stfs f3,-284(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lfs f3,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfs f16,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f16.f64 = double(temp.f32);
	// lfs f25,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f25.f64 = double(temp.f32);
	// fadds f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f3.f64));
	// fsubs f3,f3,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f25.f64));
	// stfs f3,-280(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fadds f25,f21,f23
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfs f25,-300(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fsubs f3,f23,f21
	ctx.f3.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// lfs f25,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f25.f64 = double(temp.f32);
	// lfs f17,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f17.f64 = double(temp.f32);
	// fadds f23,f25,f14
	ctx.f23.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// stfs f23,-268(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fsubs f21,f14,f25
	ctx.f21.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// fadds f25,f20,f24
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// stfs f21,-260(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// fmuls f14,f3,f13
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfs f23,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// lfs f15,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,-272(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fmuls f15,f3,f12
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// fmuls f3,f21,f12
	ctx.f3.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmuls f21,f23,f12
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// stfs f23,-264(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fadds f17,f17,f25
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// stfs f17,-304(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f17,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f25,f25,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f17.f64));
	// lfs f17,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f17.f64 = double(temp.f32);
	// stfs f3,-268(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fmr f3,f17
	ctx.f3.f64 = ctx.f17.f64;
	// stfs f21,-272(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fmadds f23,f3,f13,f15
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f15.f64));
	// fmsubs f21,f3,f12,f14
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 - ctx.f14.f64));
	// lfs f3,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f3.f64 = double(temp.f32);
	// lfs f15,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f17,f3,f13,f15
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f15.f64));
	// lfs f3,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f16,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 + ctx.f3.f64));
	// lfs f15,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f15,f3,f13,f15
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f15.f64));
	// lfs f14,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f24,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f20.f64));
	// fmsubs f3,f3,f12,f14
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 - ctx.f14.f64));
	// lfs f14,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f19,-296(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f19,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// stfs f19,-272(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f19,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f19,f12
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f20,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f20.f64 = double(temp.f32);
	// fadds f19,f18,f22
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f19,-292(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// lfs f18,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// lfs f14,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f26
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f26.f64));
	// stfs f14,-300(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f14,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// fmsubs f20,f20,f13,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f16.f64));
	// lfs f16,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,-260(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f16,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f18,-276(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f16,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f18,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// lfs f14,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f19,f14
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f14,-264(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfs f14,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f14,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f18,f14,f13,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 - ctx.f18.f64));
	// lfs f14,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f16,f14,f13,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f16,-280(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfs f16,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f16,f26
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f26.f64));
	// fsubs f16,f24,f22
	ctx.f16.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f24,-284(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lfs f24,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f24.f64 = double(temp.f32);
	// lfs f22,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f24
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f22,-288(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f22,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// stfs f24,-276(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f24,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f24.f64 = double(temp.f32);
	// fadds f22,f24,f2
	ctx.f22.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// stfs f22,-272(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fsubs f24,f2,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// lfs f22,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f22.f64 = double(temp.f32);
	// stfs f24,-264(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fadds f2,f18,f17
	ctx.f2.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// fmuls f22,f22,f24
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f24.f64));
	// fadds f24,f29,f30
	ctx.f24.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// stfs f24,-260(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// fadds f24,f2,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 + ctx.f24.f64));
	// stfs f24,-268(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// lfs f24,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f2,f24,f2
	ctx.f2.f64 = double(float(ctx.f24.f64 - ctx.f2.f64));
	// stfs f2,-296(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fadds f24,f8,f11
	ctx.f24.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// stfs f24,-260(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f2,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f20.f64));
	// fadds f24,f24,f2
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// stfs f24,-292(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f24,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f2,f24,f2
	ctx.f2.f64 = double(float(ctx.f24.f64 - ctx.f2.f64));
	// lfs f24,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fmsubs f26,f24,f26,f22
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f26.f64 - ctx.f22.f64));
	// stfs f26,-304(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f26,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// fmadds f26,f24,f26,f14
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f26.f64 + ctx.f14.f64));
	// stfs f26,-264(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfs f26,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,-260(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f24,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f22,f26,f24
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// lfs f26,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f26,f24
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// lfs f24,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f24.f64 = double(temp.f32);
	// lfs f29,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f20,f29
	ctx.f29.f64 = double(float(ctx.f20.f64 - ctx.f29.f64));
	// fmadds f26,f26,f24,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 + ctx.f22.f64));
	// lfs f22,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f24,f22,f24,f14
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f24.f64 - ctx.f14.f64));
	// lfs f22,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f22,f26
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// stfs f14,0(r3)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f14,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f14.f64 = double(temp.f32);
	// fadds f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// lfs f22,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f24,f14
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// stfs f14,0(r4)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfs f26,0(r5)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lfs f26,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// stfs f26,0(r6)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f26,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f26,f22
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f22.f64));
	// lfs f24,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f22,f24,f22
	ctx.f22.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// fmadds f24,f24,f2,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f2.f64 + ctx.f14.f64));
	// lfs f14,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f2,f26,f2,f22
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 - ctx.f22.f64));
	// lfs f26,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f22,f26,f24
	ctx.f22.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// stfsx f22,r30,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfs f24,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f24.f64 = double(temp.f32);
	// fadds f22,f2,f24
	ctx.f22.f64 = double(float(ctx.f2.f64 + ctx.f24.f64));
	// stfsx f22,r30,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// stfsx f26,r30,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fsubs f26,f18,f17
	ctx.f26.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f18,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f8,f2,f24
	ctx.f8.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// fadds f17,f18,f16
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// lfs f18,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfsx f8,r30,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f22,f25,f5
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// lfs f24,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f24.f64 = double(temp.f32);
	// fadds f2,f19,f4
	ctx.f2.f64 = double(float(ctx.f19.f64 + ctx.f4.f64));
	// lfs f8,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f4,f4,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f19.f64));
	// lfs f20,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f5,f5,f25
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f25.f64));
	// lfs f19,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f19.f64 = double(temp.f32);
	// lfs f25,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f18,f23,f15
	ctx.f18.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f14,-264(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fadds f14,f29,f30
	ctx.f14.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fadds f29,f11,f26
	ctx.f29.f64 = double(float(ctx.f11.f64 + ctx.f26.f64));
	// fsubs f11,f11,f26
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f26.f64));
	// stfs f11,-280(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfs f11,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f26,f24,f22
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// stfs f11,-260(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// fmuls f24,f24,f2
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// fmuls f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// fmsubs f2,f8,f2,f26
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f2.f64 - ctx.f26.f64));
	// stfs f2,-272(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f2,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f4
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// stfs f11,-260(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// fmadds f8,f8,f22,f24
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f22.f64 + ctx.f24.f64));
	// stfs f2,-268(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fadds f11,f17,f1
	ctx.f11.f64 = double(float(ctx.f17.f64 + ctx.f1.f64));
	// lfs f26,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f2,f1,f17
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f17.f64));
	// fadds f1,f26,f27
	ctx.f1.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// lfs f24,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f24.f64 = double(temp.f32);
	// lfs f22,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f4,f25,f4,f24
	ctx.f4.f64 = double(float(ctx.f25.f64 * ctx.f4.f64 - ctx.f24.f64));
	// fmadds f5,f25,f5,f22
	ctx.f5.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 + ctx.f22.f64));
	// fmuls f25,f20,f14
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f14.f64));
	// fmuls f22,f19,f14
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f14.f64));
	// fadds f24,f6,f10
	ctx.f24.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fsubs f6,f21,f3
	ctx.f6.f64 = double(float(ctx.f21.f64 - ctx.f3.f64));
	// fmadds f25,f19,f29,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f29.f64 + ctx.f25.f64));
	// fmsubs f29,f20,f29,f22
	ctx.f29.f64 = double(float(ctx.f20.f64 * ctx.f29.f64 - ctx.f22.f64));
	// lfs f22,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f22.f64 = double(temp.f32);
	// fadds f26,f18,f24
	ctx.f26.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// fsubs f24,f24,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// fsubs f20,f22,f25
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// stfsx f20,r10,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f20,f29,f8
	ctx.f20.f64 = double(float(ctx.f29.f64 + ctx.f8.f64));
	// stfsx f20,r10,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// stfsx f25,r10,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f8,f29,f8
	ctx.f8.f64 = double(float(ctx.f29.f64 - ctx.f8.f64));
	// stfsx f8,r10,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f8,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f8.f64 = double(temp.f32);
	// lfs f29,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f22,f8,f30
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fmuls f20,f29,f30
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f30.f64));
	// lfs f25,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f30,f29,f25,f22
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f25.f64 + ctx.f22.f64));
	// lfs f22,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f8,f8,f25,f20
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f25.f64 - ctx.f20.f64));
	// lfs f20,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// lfs f20,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// fsubs f29,f4,f30
	ctx.f29.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// stfsx f29,r31,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// fadds f30,f8,f5
	ctx.f30.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// stfsx f30,r31,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// stfsx f4,r31,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fsubs f8,f8,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// stfsx f8,r31,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f4,f31,f28
	ctx.f4.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// fadds f8,f3,f21
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f21.f64));
	// lfs f30,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f30.f64 = double(temp.f32);
	// fadds f3,f28,f31
	ctx.f3.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f30,f1
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f1.f64));
	// lfs f25,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f28,f22,f0
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// lfs f29,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f30,f30,f11
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fadds f31,f15,f23
	ctx.f31.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// fmuls f23,f20,f0
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmuls f20,f25,f26
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fadds f22,f4,f8
	ctx.f22.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fsubs f8,f4,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f8.f64));
	// fmsubs f11,f5,f11,f21
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 - ctx.f21.f64));
	// fadds f4,f6,f10
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fmadds f5,f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 + ctx.f30.f64));
	// fadds f1,f28,f7
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f7.f64));
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fsubs f6,f3,f31
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fsubs f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f28.f64));
	// fadds f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// fmuls f30,f25,f22
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f22.f64));
	// fadds f31,f23,f9
	ctx.f31.f64 = double(float(ctx.f23.f64 + ctx.f9.f64));
	// fsubs f9,f9,f23
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f23.f64));
	// fmadds f30,f29,f26,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f26.f64 + ctx.f30.f64));
	// fmsubs f29,f29,f22,f20
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f22.f64 - ctx.f20.f64));
	// fsubs f28,f11,f30
	ctx.f28.f64 = double(float(ctx.f11.f64 - ctx.f30.f64));
	// stfsx f28,r7,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f28,f29,f5
	ctx.f28.f64 = double(float(ctx.f29.f64 + ctx.f5.f64));
	// stfsx f28,r7,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fadds f11,f30,f11
	ctx.f11.f64 = double(float(ctx.f30.f64 + ctx.f11.f64));
	// stfsx f11,r7,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// fsubs f11,f29,f5
	ctx.f11.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// stfsx f11,r7,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// addic. r20,r20,-1
	ctx.xer.ca = ctx.r20.u32 > 0;
	ctx.r20.s64 = ctx.r20.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r20.s32, 0, ctx.xer);
	// lfs f5,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f5.f64 = double(temp.f32);
	// lfs f30,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f28,f5,f27
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// lfs f29,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f26,f30,f24
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f24.f64));
	// fmuls f25,f5,f2
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// lfs f11,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f24,f29,f24
	ctx.f24.f64 = double(float(ctx.f29.f64 * ctx.f24.f64));
	// fmsubs f5,f11,f2,f28
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f2.f64 - ctx.f28.f64));
	// fmadds f2,f29,f8,f26
	ctx.f2.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 + ctx.f26.f64));
	// fmadds f11,f11,f27,f25
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f27.f64 + ctx.f25.f64));
	// fmsubs f8,f30,f8,f24
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 - ctx.f24.f64));
	// fsubs f30,f5,f2
	ctx.f30.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// stfsx f30,r9,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fadds f2,f8,f11
	ctx.f2.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// stfsx f2,r9,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f5,r9,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 - ctx.f11.f64));
	// stfsx f11,r9,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// add r4,r27,r4
	ctx.r4.u64 = ctx.r27.u64 + ctx.r4.u64;
	// lfs f8,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f8.f64 = double(temp.f32);
	// subf r5,r27,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r27.s64;
	// fmuls f30,f8,f31
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// lfs f11,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f29,f8,f1
	ctx.f29.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// lfs f5,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f2.f64 = double(temp.f32);
	// subf r6,r27,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r27.s64;
	// fmsubs f8,f11,f1,f30
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 - ctx.f30.f64));
	// fmuls f1,f5,f4
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// fmadds f11,f11,f31,f29
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f31.f64 + ctx.f29.f64));
	// fmuls f31,f2,f4
	ctx.f31.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// fmadds f4,f2,f6,f1
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f1.f64));
	// fmsubs f6,f5,f6,f31
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f6.f64 - ctx.f31.f64));
	// fsubs f5,f8,f4
	ctx.f5.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// stfs f5,0(r21)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// fadds f8,f4,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fadds f5,f6,f11
	ctx.f5.f64 = double(float(ctx.f6.f64 + ctx.f11.f64));
	// stfs f5,0(r28)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// stfs f8,0(r24)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fsubs f11,f6,f11
	ctx.f11.f64 = double(float(ctx.f6.f64 - ctx.f11.f64));
	// stfs f11,0(r23)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// lfs f8,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f8.f64 = double(temp.f32);
	// lfs f6,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f4,f8,f9
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f5,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f2,f6,f10
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmuls f1,f8,f7
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// lfs f11,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f31,f5,f10
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// addi r11,r11,120
	ctx.r11.s64 = ctx.r11.s64 + 120;
	// fmsubs f10,f11,f7,f4
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f7.f64 - ctx.f4.f64));
	// fmadds f8,f5,f3,f2
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f3.f64 + ctx.f2.f64));
	// fmadds f11,f11,f9,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f9.f64 + ctx.f1.f64));
	// fmsubs f9,f6,f3,f31
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 - ctx.f31.f64));
	// fsubs f7,f10,f8
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// stfs f7,0(r22)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// fadds f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fadds f8,f9,f11
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// stfs f8,0(r29)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// stfs f10,0(r26)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fsubs f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// stfs f11,0(r25)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// lwz r10,3532(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d26dcc
	if (!ctx.cr0.eq) goto loc_82D26DCC;
loc_82D27548:
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28f2c
	ctx.lr = 0x82D27550;
	__restfpr_14(ctx, base);
	// b 0x82e28e94
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D27558"))) PPC_WEAK_FUNC(sub_82D27558);
PPC_FUNC_IMPL(__imp__sub_82D27558) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-7760
	ctx.r5.s64 = ctx.r11.s64 + -7760;
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// addi r4,r11,28032
	ctx.r4.s64 = ctx.r11.s64 + 28032;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D27570"))) PPC_WEAK_FUNC(sub_82D27570);
PPC_FUNC_IMPL(__imp__sub_82D27570) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82D27578;
	__savegprlr_27(ctx, base);
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82e28ee0
	ctx.lr = 0x82D27580;
	__savefpr_14(ctx, base);
	// mulli r11,r9,88
	ctx.r11.s64 = ctx.r9.s64 * 88;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-88
	ctx.r11.s64 = ctx.r11.s64 + -88;
	// bge cr6,0x82d27a70
	if (!ctx.cr6.lt) goto loc_82D27A70;
	// subf r28,r9,r10
	ctx.r28.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// rlwinm r29,r7,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f13,-28552(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f0.f64 = double(temp.f32);
loc_82D275B4:
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f11,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// lfs f10,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f20,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-224(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -224, temp.u32);
	// lfsx f9,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f9.f64 = double(temp.f32);
	// rlwinm r7,r8,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f8,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f8.f64 = double(temp.f32);
	// rlwinm r9,r8,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f3,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f1,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f1.f64 = double(temp.f32);
	// mulli r30,r8,20
	ctx.r30.s64 = ctx.r8.s64 * 20;
	// lfsx f7,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f17,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f6,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f25,f9,f5
	ctx.f25.f64 = double(float(ctx.f9.f64 + ctx.f5.f64));
	// lfsx f2,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f24,f8,f4
	ctx.f24.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// lfsx f31,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f5,f5,f9
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// fadds f9,f2,f3
	ctx.f9.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfsx f28,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f4,f4,f8
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// lfsx f30,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f8,f1,f31
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// lfsx f29,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// lfsx f16,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f2,f31,f1
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// lfsx f15,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f1,f28,f10
	ctx.f1.f64 = double(float(ctx.f28.f64 - ctx.f10.f64));
	// lfsx f27,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f28.f64));
	// lfsx f26,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f28,f25,f12
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f12.f64));
	// fsubs f31,f11,f24
	ctx.f31.f64 = double(float(ctx.f11.f64 - ctx.f24.f64));
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmadds f11,f24,f13,f11
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f11.f64));
	// fadds f22,f9,f30
	ctx.f22.f64 = double(float(ctx.f9.f64 + ctx.f30.f64));
	// fadds f23,f8,f29
	ctx.f23.f64 = double(float(ctx.f8.f64 + ctx.f29.f64));
	// fnmsubs f9,f9,f13,f30
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fnmsubs f12,f25,f13,f12
	ctx.f12.f64 = double(float(-(ctx.f25.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmsubs f8,f8,f13,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 - ctx.f29.f64));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fadds f24,f11,f5
	ctx.f24.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// fsubs f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// fsubs f30,f31,f23
	ctx.f30.f64 = double(float(ctx.f31.f64 - ctx.f23.f64));
	// fadds f31,f23,f31
	ctx.f31.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// fadds f5,f9,f2
	ctx.f5.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// fadds f23,f10,f7
	ctx.f23.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// fsubs f25,f12,f4
	ctx.f25.f64 = double(float(ctx.f12.f64 - ctx.f4.f64));
	// fsubs f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f2.f64));
	// fadds f2,f8,f3
	ctx.f2.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// fadds f12,f12,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f4.f64));
	// lfs f4,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f10,f10,f13,f7
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// lfsx f7,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f14,f4,f7
	ctx.f14.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// fsubs f4,f7,f4
	ctx.f4.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// fadds f7,f16,f17
	ctx.f7.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f29,f22,f28
	ctx.f29.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// lfs f22,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f8,f8,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f3.f64));
	// lfs f3,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfs f16,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f21,f24,f2
	ctx.f21.f64 = double(float(ctx.f24.f64 - ctx.f2.f64));
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,-220(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -220, temp.u32);
	// lfs f16,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f19,f25,f5
	ctx.f19.f64 = double(float(ctx.f25.f64 - ctx.f5.f64));
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// fsubs f15,f6,f14
	ctx.f15.f64 = double(float(ctx.f6.f64 - ctx.f14.f64));
	// stfs f15,-224(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -224, temp.u32);
	// fadds f15,f7,f27
	ctx.f15.f64 = double(float(ctx.f7.f64 + ctx.f27.f64));
	// stfs f15,-216(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -216, temp.u32);
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// lfs f15,-220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -220);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f6,f14,f13,f6
	ctx.f6.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 + ctx.f6.f64));
	// fsubs f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f26.f64));
	// fnmsubs f7,f7,f13,f27
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f13.f64 - ctx.f27.f64)));
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fadds f14,f10,f4
	ctx.f14.f64 = double(float(ctx.f10.f64 + ctx.f4.f64));
	// fsubs f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// lfs f4,-220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -220);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f4,f4,f13,f26
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f26.f64));
	// lfs f26,-216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -216);
	ctx.f26.f64 = double(temp.f32);
	// fadds f27,f26,f23
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f23.f64));
	// fsubs f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// lfs f23,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// stfs f23,-220(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -220, temp.u32);
	// lfs f23,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// fadds f15,f6,f1
	ctx.f15.f64 = double(float(ctx.f6.f64 + ctx.f1.f64));
	// fsubs f6,f6,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// fadds f1,f7,f16
	ctx.f1.f64 = double(float(ctx.f7.f64 + ctx.f16.f64));
	// fsubs f7,f7,f16
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f16.f64));
	// fsubs f16,f17,f4
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f4.f64));
	// fadds f4,f4,f17
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f17.f64));
	// fsubs f17,f29,f27
	ctx.f17.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// lfs f27,-220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -220);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f30,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfs f27,-216(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -216, temp.u32);
	// lfs f27,-220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -220);
	ctx.f27.f64 = double(temp.f32);
	// fadds f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f30,-204(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -204, temp.u32);
	// fsubs f30,f14,f1
	ctx.f30.f64 = double(float(ctx.f14.f64 - ctx.f1.f64));
	// stfs f30,-220(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -220, temp.u32);
	// fsubs f30,f15,f16
	ctx.f30.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f30,-224(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -224, temp.u32);
	// fmuls f30,f18,f17
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f27,-216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -216);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f18,f27
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f27.f64));
	// lfs f27,-220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -220);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f21.f64));
	// stfs f27,-212(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -212, temp.u32);
	// lfs f27,-220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -220);
	ctx.f27.f64 = double(temp.f32);
	// stfs f30,-220(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -220, temp.u32);
	// fsubs f30,f21,f27
	ctx.f30.f64 = double(float(ctx.f21.f64 - ctx.f27.f64));
	// lfs f27,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 - ctx.f27.f64));
	// stfs f27,-208(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -208, temp.u32);
	// lfs f27,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f19.f64));
	// lfs f19,-216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -216);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f21,f20,f17,f18
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f17.f64 - ctx.f18.f64));
	// lfs f18,-220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -220);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f20,f20,f19,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64 + ctx.f18.f64));
	// lfs f19,-212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -212);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f3,f19
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// fmuls f17,f22,f19
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f19,-208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -208);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f22,f22,f19,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 + ctx.f18.f64));
	// fmsubs f3,f3,f19,f17
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f19.f64 - ctx.f17.f64));
	// fsubs f17,f31,f26
	ctx.f17.f64 = double(float(ctx.f31.f64 - ctx.f26.f64));
	// fsubs f19,f29,f22
	ctx.f19.f64 = double(float(ctx.f29.f64 - ctx.f22.f64));
	// stfs f19,0(r3)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f19,-204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -204);
	ctx.f19.f64 = double(temp.f32);
	// fadds f29,f22,f29
	ctx.f29.f64 = double(float(ctx.f22.f64 + ctx.f29.f64));
	// fadds f18,f3,f19
	ctx.f18.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// stfs f18,0(r4)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfs f29,0(r5)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f3,f3,f19
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f19.f64));
	// stfs f3,0(r6)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f22,f12,f9
	ctx.f22.f64 = double(float(ctx.f12.f64 + ctx.f9.f64));
	// lfs f3,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f3.f64 = double(temp.f32);
	// fadds f19,f7,f10
	ctx.f19.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// lfs f29,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f29.f64 = double(temp.f32);
	// fadds f18,f8,f11
	ctx.f18.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// fadds f31,f26,f31
	ctx.f31.f64 = double(float(ctx.f26.f64 + ctx.f31.f64));
	// stfs f17,-212(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -212, temp.u32);
	// fmuls f26,f3,f30
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// stfs f26,-204(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -204, temp.u32);
	// fmuls f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f30.f64));
	// stfs f30,-208(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -208, temp.u32);
	// fadds f17,f23,f28
	ctx.f17.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// fsubs f28,f28,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// fsubs f23,f22,f19
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f23,-216(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -216, temp.u32);
	// fadds f26,f19,f22
	ctx.f26.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// fsubs f30,f6,f4
	ctx.f30.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// fsubs f23,f6,f4
	ctx.f23.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// fadds f5,f25,f5
	ctx.f5.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// fadds f1,f1,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f14.f64));
	// fsubs f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// fsubs f12,f12,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// fadds f9,f6,f4
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// fsubs f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// fadds f6,f2,f24
	ctx.f6.f64 = double(float(ctx.f2.f64 + ctx.f24.f64));
	// fadds f4,f15,f16
	ctx.f4.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f30,f18,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 - ctx.f30.f64));
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// fadds f7,f1,f5
	ctx.f7.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fsubs f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// lfs f22,-204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -204);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f29,f29,f27,f22
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f27.f64 + ctx.f22.f64));
	// lfs f22,-208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -208);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f3,f3,f27,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f27.f64 - ctx.f22.f64));
	// lfs f18,-216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -216);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f27,f21,f29
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f29.f64));
	// stfsx f27,r10,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f27,f3,f20
	ctx.f27.f64 = double(float(ctx.f3.f64 + ctx.f20.f64));
	// stfsx f27,r10,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f29,f29,f21
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f21.f64));
	// stfsx f29,r10,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f3,f3,f20
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f20.f64));
	// stfsx f3,r10,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f21,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,-224(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -224, temp.u32);
	// lfs f21,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,-220(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -220, temp.u32);
	// lfs f3,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f3.f64 = double(temp.f32);
	// lfs f21,-212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -212);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f3,f21
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f21.f64));
	// lfs f22,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f22.f64 = double(temp.f32);
	// lfs f29,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f19,f22,f30
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// fmuls f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f27,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f21,f29,f21
	ctx.f21.f64 = double(float(ctx.f29.f64 * ctx.f21.f64));
	// fmadds f29,f29,f17,f20
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f17.f64 + ctx.f20.f64));
	// fmadds f30,f27,f30,f22
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f30.f64 + ctx.f22.f64));
	// fmsubs f3,f3,f17,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f17.f64 - ctx.f21.f64));
	// lfs f18,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f31
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f31.f64));
	// lfs f22,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,-220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -220);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f31
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f31.f64));
	// lfs f31,-216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -216);
	ctx.f31.f64 = double(temp.f32);
	// fmsubs f31,f27,f31,f19
	ctx.f31.f64 = double(float(ctx.f27.f64 * ctx.f31.f64 - ctx.f19.f64));
	// lfs f27,-220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -220);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f28,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f28.f64 + ctx.f18.f64));
	// fmsubs f28,f22,f28,f20
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 - ctx.f20.f64));
	// fsubs f22,f31,f29
	ctx.f22.f64 = double(float(ctx.f31.f64 - ctx.f29.f64));
	// stfsx f22,r31,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f31,f31,f29
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f29.f64));
	// fadds f29,f30,f3
	ctx.f29.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// stfsx f29,r31,r4
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// stfsx f31,r31,r5
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fsubs f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f30.f64));
	// stfsx f3,r31,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f31,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f31,f23
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// lfs f3,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f31,f31,f26
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f26.f64));
	// fmsubs f30,f3,f26,f30
	ctx.f30.f64 = double(float(ctx.f3.f64 * ctx.f26.f64 - ctx.f30.f64));
	// fsubs f8,f30,f27
	ctx.f8.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfsx f8,r7,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fmadds f8,f3,f23,f31
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f23.f64 + ctx.f31.f64));
	// fadds f2,f30,f27
	ctx.f2.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// fsubs f3,f12,f9
	ctx.f3.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// fadds f12,f9,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f12.f64));
	// fadds f9,f4,f6
	ctx.f9.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fsubs f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// fadds f4,f10,f11
	ctx.f4.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// fadds f10,f8,f28
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f28.f64));
	// stfsx f10,r7,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// stfsx f2,r7,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// fsubs f10,f28,f8
	ctx.f10.f64 = double(float(ctx.f28.f64 - ctx.f8.f64));
	// stfsx f10,r7,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// lfs f8,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// lfs f1,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f29,f8,f7
	ctx.f29.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fmuls f30,f1,f3
	ctx.f30.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f10,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f31,f8,f9
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f2,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f1,f4
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// fmsubs f8,f10,f7,f31
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f7.f64 - ctx.f31.f64));
	// fmadds f7,f2,f4,f30
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f4.f64 + ctx.f30.f64));
	// fmadds f10,f10,f9,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 + ctx.f29.f64));
	// fmsubs f9,f2,f3,f1
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f1.f64));
	// fsubs f4,f8,f7
	ctx.f4.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// stfsx f4,r9,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fadds f7,f9,f10
	ctx.f7.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// stfsx f7,r9,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f8,r9,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// stfsx f10,r9,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// lfs f9,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f9.f64 = double(temp.f32);
	// lfs f7,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f4,f9,f6
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f3,f7,f12
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// lfs f8,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f2,f9,f5
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// lfs f10,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f7,f7,f11
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// addi r11,r11,88
	ctx.r11.s64 = ctx.r11.s64 + 88;
	// fmsubs f9,f10,f5,f4
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f5.f64 - ctx.f4.f64));
	// fmadds f11,f8,f11,f3
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f11.f64 + ctx.f3.f64));
	// fmadds f10,f10,f6,f2
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f6.f64 + ctx.f2.f64));
	// fmsubs f12,f8,f12,f7
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 - ctx.f7.f64));
	// fsubs f8,f9,f11
	ctx.f8.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// stfsx f8,r30,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f9.f64));
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// fadds f9,f12,f10
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// stfsx f9,r30,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// stfsx f11,r30,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// stfsx f12,r30,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lwz r10,3532(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 3532);
	// add r4,r29,r4
	ctx.r4.u64 = ctx.r29.u64 + ctx.r4.u64;
	// subf r5,r29,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r29.s64;
	// subf r6,r29,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r29.s64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d275b4
	if (!ctx.cr0.eq) goto loc_82D275B4;
loc_82D27A70:
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82e28f2c
	ctx.lr = 0x82D27A78;
	__restfpr_14(ctx, base);
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D27A80"))) PPC_WEAK_FUNC(sub_82D27A80);
PPC_FUNC_IMPL(__imp__sub_82D27A80) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-7704
	ctx.r5.s64 = ctx.r11.s64 + -7704;
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// addi r4,r11,30064
	ctx.r4.s64 = ctx.r11.s64 + 30064;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D27A98"))) PPC_WEAK_FUNC(sub_82D27A98);
PPC_FUNC_IMPL(__imp__sub_82D27A98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e50
	ctx.lr = 0x82D27AA0;
	__savegprlr_22(ctx, base);
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82e28ee8
	ctx.lr = 0x82D27AA8;
	__savefpr_16(ctx, base);
	// mulli r11,r9,72
	ctx.r11.s64 = ctx.r9.s64 * 72;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-72
	ctx.r11.s64 = ctx.r11.s64 + -72;
	// bge cr6,0x82d27e88
	if (!ctx.cr6.lt) goto loc_82D27E88;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r23,r9,r10
	ctx.r23.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f13,-7584(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -7584);
	ctx.f13.f64 = double(temp.f32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f0,-7588(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -7588);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,-12288(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -12288);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-7592(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7592);
	ctx.f12.f64 = double(temp.f32);
loc_82D27AEC:
	// rlwinm r7,r8,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f10,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// mulli r31,r8,12
	ctx.r31.s64 = ctx.r8.s64 * 12;
	// lfs f9,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f23,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// add r29,r7,r3
	ctx.r29.u64 = ctx.r7.u64 + ctx.r3.u64;
	// add r26,r7,r5
	ctx.r26.u64 = ctx.r7.u64 + ctx.r5.u64;
	// add r25,r7,r6
	ctx.r25.u64 = ctx.r7.u64 + ctx.r6.u64;
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r28,r31,r5
	ctx.r28.u64 = ctx.r31.u64 + ctx.r5.u64;
	// lfs f6,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// rlwinm r9,r8,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f26,f10,f6
	ctx.f26.f64 = double(float(ctx.f10.f64 + ctx.f6.f64));
	// lfs f3,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 - ctx.f10.f64));
	// lfs f2,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fadds f6,f3,f9
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f9.f64));
	// lfs f1,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f9,f9,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f3.f64));
	// add r27,r31,r3
	ctx.r27.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fadds f3,f2,f8
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f8.f64));
	// lfsx f30,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f8,f8,f2
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f2.f64));
	// lfs f5,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fadds f2,f7,f1
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// lfsx f28,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f7,f1,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// lfsx f29,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f1,f30,f5
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// lfsx f27,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// lfs f4,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fadds f30,f28,f29
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// add r24,r31,r6
	ctx.r24.u64 = ctx.r31.u64 + ctx.r6.u64;
	// fsubs f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// add r31,r31,r4
	ctx.r31.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fadds f28,f4,f27
	ctx.f28.f64 = double(float(ctx.f4.f64 + ctx.f27.f64));
	// fsubs f4,f27,f4
	ctx.f4.f64 = double(float(ctx.f27.f64 - ctx.f4.f64));
	// lfs f31,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fadds f27,f1,f26
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// fadds f25,f5,f10
	ctx.f25.f64 = double(float(ctx.f5.f64 + ctx.f10.f64));
	// fsubs f1,f26,f1
	ctx.f1.f64 = double(float(ctx.f26.f64 - ctx.f1.f64));
	// fsubs f10,f10,f5
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f5.f64));
	// fadds f5,f28,f30
	ctx.f5.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// fadds f26,f4,f29
	ctx.f26.f64 = double(float(ctx.f4.f64 + ctx.f29.f64));
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fsubs f4,f29,f4
	ctx.f4.f64 = double(float(ctx.f29.f64 - ctx.f4.f64));
	// fmuls f24,f1,f0
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f28,f1,f13
	ctx.f28.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fadds f1,f5,f27
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f27.f64));
	// fadds f29,f26,f25
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// fsubs f5,f5,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f27.f64));
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fmuls f27,f10,f0
	ctx.f27.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f25,f10,f13
	ctx.f25.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmsubs f28,f30,f0,f28
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 - ctx.f28.f64));
	// fmadds f30,f30,f13,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 + ctx.f24.f64));
	// lfsx f24,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f10,f26,f12
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// fmadds f27,f4,f13,f27
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f27.f64));
	// fmsubs f4,f4,f0,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 - ctx.f25.f64));
	// fnmsubs f26,f1,f11,f6
	ctx.f26.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f6.f64)));
	// fnmsubs f25,f29,f11,f9
	ctx.f25.f64 = double(float(-(ctx.f29.f64 * ctx.f11.f64 - ctx.f9.f64)));
	// fadds f9,f29,f9
	ctx.f9.f64 = double(float(ctx.f29.f64 + ctx.f9.f64));
	// fadds f29,f24,f31
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f31.f64));
	// fadds f6,f1,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 + ctx.f6.f64));
	// lfsx f1,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f31,f24,f31
	ctx.f31.f64 = double(float(ctx.f24.f64 - ctx.f31.f64));
	// lfs f24,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fadds f20,f26,f5
	ctx.f20.f64 = double(float(ctx.f26.f64 + ctx.f5.f64));
	// fadds f21,f25,f10
	ctx.f21.f64 = double(float(ctx.f25.f64 + ctx.f10.f64));
	// fsubs f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 - ctx.f5.f64));
	// lfsx f26,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f10,f25,f10
	ctx.f10.f64 = double(float(ctx.f25.f64 - ctx.f10.f64));
	// lfsx f25,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f19,f2,f29
	ctx.f19.f64 = double(float(ctx.f2.f64 - ctx.f29.f64));
	// fadds f18,f26,f1
	ctx.f18.f64 = double(float(ctx.f26.f64 + ctx.f1.f64));
	// fsubs f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f26.f64));
	// fadds f26,f24,f25
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fsubs f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// fadds f24,f31,f7
	ctx.f24.f64 = double(float(ctx.f31.f64 + ctx.f7.f64));
	// fsubs f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f31.f64));
	// fadds f2,f29,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fsubs f31,f18,f26
	ctx.f31.f64 = double(float(ctx.f18.f64 - ctx.f26.f64));
	// fadds f29,f25,f1
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f1.f64));
	// fsubs f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f25.f64));
	// fmuls f25,f7,f13
	ctx.f25.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fadds f26,f26,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f18.f64));
	// fmuls f17,f2,f0
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f18,f7,f0
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f16,f2,f13
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fadds f7,f31,f19
	ctx.f7.f64 = double(float(ctx.f31.f64 + ctx.f19.f64));
	// fsubs f31,f31,f19
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f19.f64));
	// fadds f2,f29,f24
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f24.f64));
	// fsubs f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f24.f64));
	// fmsubs f25,f1,f0,f25
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 - ctx.f25.f64));
	// fmadds f24,f26,f13,f17
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fmadds f1,f1,f13,f18
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 + ctx.f18.f64));
	// fmsubs f26,f26,f0,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 - ctx.f16.f64));
	// fadds f18,f7,f3
	ctx.f18.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// fmuls f31,f31,f12
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// fnmsubs f7,f7,f11,f3
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f11.f64 - ctx.f3.f64)));
	// fadds f19,f2,f8
	ctx.f19.f64 = double(float(ctx.f2.f64 + ctx.f8.f64));
	// fnmsubs f8,f2,f11,f8
	ctx.f8.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 - ctx.f8.f64)));
	// fmuls f29,f29,f12
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// fsubs f3,f5,f25
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f25.f64));
	// fadds f5,f5,f25
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f25.f64));
	// fadds f25,f10,f26
	ctx.f25.f64 = double(float(ctx.f10.f64 + ctx.f26.f64));
	// fsubs f10,f10,f26
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f26.f64));
	// fsubs f17,f21,f24
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// fadds f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// fadds f26,f7,f31
	ctx.f26.f64 = double(float(ctx.f7.f64 + ctx.f31.f64));
	// fsubs f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f31.f64));
	// fadds f2,f20,f1
	ctx.f2.f64 = double(float(ctx.f20.f64 + ctx.f1.f64));
	// fadds f21,f8,f29
	ctx.f21.f64 = double(float(ctx.f8.f64 + ctx.f29.f64));
	// fsubs f8,f8,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f29.f64));
	// fsubs f1,f20,f1
	ctx.f1.f64 = double(float(ctx.f20.f64 - ctx.f1.f64));
	// fmuls f20,f23,f9
	ctx.f20.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// fmuls f16,f23,f18
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f18.f64));
	// fadds f31,f26,f27
	ctx.f31.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f29,f26,f27
	ctx.f29.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fsubs f26,f7,f4
	ctx.f26.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// fadds f7,f7,f4
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// fadds f4,f8,f28
	ctx.f4.f64 = double(float(ctx.f8.f64 + ctx.f28.f64));
	// fsubs f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// lfs f28,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f27,f21,f30
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f30.f64));
	// fmadds f23,f22,f18,f20
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 + ctx.f20.f64));
	// fmsubs f9,f22,f9,f16
	ctx.f9.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 - ctx.f16.f64));
	// fadds f30,f21,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// lfs f21,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f22,f28,f31
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// fmuls f20,f21,f31
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f31.f64));
	// fmadds f31,f21,f17,f22
	ctx.f31.f64 = double(float(ctx.f21.f64 * ctx.f17.f64 + ctx.f22.f64));
	// fmsubs f28,f28,f17,f20
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f17.f64 - ctx.f20.f64));
	// fsubs f22,f6,f31
	ctx.f22.f64 = double(float(ctx.f6.f64 - ctx.f31.f64));
	// stfs f22,0(r3)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f6,f31,f6
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// fadds f31,f28,f19
	ctx.f31.f64 = double(float(ctx.f28.f64 + ctx.f19.f64));
	// stfs f31,0(r4)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfs f6,0(r5)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f6,f28,f19
	ctx.f6.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// stfs f6,0(r6)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f31,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f31.f64 = double(temp.f32);
	// lfs f6,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f28,f31,f27
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f27.f64));
	// fmuls f27,f6,f27
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// fmsubs f6,f6,f2,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 - ctx.f28.f64));
	// fmadds f2,f31,f2,f27
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f2.f64 + ctx.f27.f64));
	// fsubs f31,f6,f23
	ctx.f31.f64 = double(float(ctx.f6.f64 - ctx.f23.f64));
	// stfsx f31,r9,r3
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f31,f2,f9
	ctx.f31.f64 = double(float(ctx.f2.f64 + ctx.f9.f64));
	// stfsx f31,r9,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f6,f6,f23
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f23.f64));
	// stfsx f6,r9,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f2.f64));
	// stfsx f9,r9,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// lfs f6,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f6.f64 = double(temp.f32);
	// addic. r23,r23,-1
	ctx.xer.ca = ctx.r23.u32 > 0;
	ctx.r23.s64 = ctx.r23.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// lfs f2,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f28,f6,f4
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// lfs f31,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f27,f2,f26
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// fmuls f23,f6,f3
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f9,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f26,f31,f26
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f26.f64));
	// fmsubs f6,f9,f3,f28
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f3.f64 - ctx.f28.f64));
	// fmadds f3,f31,f25,f27
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f25.f64 + ctx.f27.f64));
	// fmadds f9,f9,f4,f23
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fmsubs f4,f2,f25,f26
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f25.f64 - ctx.f26.f64));
	// fsubs f2,f6,f3
	ctx.f2.f64 = double(float(ctx.f6.f64 - ctx.f3.f64));
	// stfsx f2,r10,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// add r3,r30,r3
	ctx.r3.u64 = ctx.r30.u64 + ctx.r3.u64;
	// fadds f3,f4,f9
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f9.f64));
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfsx f6,r10,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f9,f4,f9
	ctx.f9.f64 = double(float(ctx.f4.f64 - ctx.f9.f64));
	// stfsx f9,r10,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// add r4,r30,r4
	ctx.r4.u64 = ctx.r30.u64 + ctx.r4.u64;
	// lfs f6,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f6.f64 = double(temp.f32);
	// subf r5,r30,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r30.s64;
	// fmuls f4,f6,f8
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// lfs f9,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f3,f6,f5
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// subf r6,r30,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r30.s64;
	// fmsubs f6,f9,f5,f4
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f5.f64 - ctx.f4.f64));
	// lfs f5,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f9,f9,f8,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 + ctx.f3.f64));
	// lfs f4,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f8,f5,f29
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f29.f64));
	// fmuls f3,f4,f29
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// fmadds f8,f4,f24,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f24.f64 + ctx.f8.f64));
	// fmsubs f5,f5,f24,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 - ctx.f3.f64));
	// fsubs f4,f6,f8
	ctx.f4.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// stfs f4,0(r29)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fadds f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// fadds f6,f5,f9
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// stfs f6,0(r7)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// stfs f8,0(r26)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fsubs f9,f5,f9
	ctx.f9.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// stfs f9,0(r25)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// lfs f6,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f6.f64 = double(temp.f32);
	// lfs f8,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f3,f6,f7
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f9,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f4,f8,f30
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// lfs f5,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f2,f9,f30
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fmuls f31,f5,f7
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// addi r11,r11,72
	ctx.r11.s64 = ctx.r11.s64 + 72;
	// fmadds f7,f5,f10,f3
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 + ctx.f3.f64));
	// fmsubs f9,f9,f1,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f1.f64 - ctx.f4.f64));
	// fmadds f8,f8,f1,f2
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f1.f64 + ctx.f2.f64));
	// fmsubs f10,f6,f10,f31
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f10.f64 - ctx.f31.f64));
	// fsubs f6,f9,f7
	ctx.f6.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// stfs f6,0(r27)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fadds f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fadds f7,f10,f8
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f8.f64));
	// stfs f7,0(r31)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// stfs f9,0(r28)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fsubs f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// stfs f10,0(r24)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// lwz r10,3532(r22)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r22.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d27aec
	if (!ctx.cr0.eq) goto loc_82D27AEC;
loc_82D27E88:
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82e28f34
	ctx.lr = 0x82D27E90;
	__restfpr_16(ctx, base);
	// b 0x82e28ea0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D27E98"))) PPC_WEAK_FUNC(sub_82D27E98);
PPC_FUNC_IMPL(__imp__sub_82D27E98) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-7640
	ctx.r5.s64 = ctx.r11.s64 + -7640;
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// addi r4,r11,31384
	ctx.r4.s64 = ctx.r11.s64 + 31384;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D27EB0"))) PPC_WEAK_FUNC(sub_82D27EB0);
PPC_FUNC_IMPL(__imp__sub_82D27EB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D27EB8;
	__savegprlr_26(ctx, base);
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28ef8
	ctx.lr = 0x82D27EC0;
	__savefpr_20(ctx, base);
	// mulli r11,r9,56
	ctx.r11.s64 = ctx.r9.s64 * 56;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-56
	ctx.r11.s64 = ctx.r11.s64 + -56;
	// bge cr6,0x82d28174
	if (!ctx.cr6.lt) goto loc_82D28174;
	// subf r30,r9,r10
	ctx.r30.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f0,140(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D27EEC:
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f5,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f26,f13,f7
	ctx.f26.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
	// rlwinm r9,r8,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f24,f11,f5
	ctx.f24.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// add r29,r7,r3
	ctx.r29.u64 = ctx.r7.u64 + ctx.r3.u64;
	// lfsx f6,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// add r28,r7,r4
	ctx.r28.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fadds f13,f7,f13
	ctx.f13.f64 = double(float(ctx.f7.f64 + ctx.f13.f64));
	// fadds f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 + ctx.f11.f64));
	// add r27,r7,r5
	ctx.r27.u64 = ctx.r7.u64 + ctx.r5.u64;
	// fadds f25,f6,f12
	ctx.f25.f64 = double(float(ctx.f6.f64 + ctx.f12.f64));
	// add r7,r7,r6
	ctx.r7.u64 = ctx.r7.u64 + ctx.r6.u64;
	// lfsx f4,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f12,f6,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// lfsx f2,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f23,f4,f10
	ctx.f23.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// lfs f3,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// lfs f1,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f7,f3,f2
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// lfsx f31,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f6,f2,f3
	ctx.f6.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fadds f5,f31,f1
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// lfsx f30,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f4,f1,f31
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// lfsx f28,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f2,f29,f30
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// lfs f27,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f3,f30,f29
	ctx.f3.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fsubs f31,f28,f27
	ctx.f31.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f1,f27,f28
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fadds f29,f25,f26
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f30,f26,f25
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fadds f28,f13,f6
	ctx.f28.f64 = double(float(ctx.f13.f64 + ctx.f6.f64));
	// fsubs f27,f7,f5
	ctx.f27.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// fadds f7,f5,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fadds f26,f2,f11
	ctx.f26.f64 = double(float(ctx.f2.f64 + ctx.f11.f64));
	// fsubs f11,f11,f2
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f2.f64));
	// fadds f21,f12,f4
	ctx.f21.f64 = double(float(ctx.f12.f64 + ctx.f4.f64));
	// fsubs f12,f12,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f4.f64));
	// fadds f5,f3,f23
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f23.f64));
	// fadds f22,f31,f10
	ctx.f22.f64 = double(float(ctx.f31.f64 + ctx.f10.f64));
	// fsubs f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f31.f64));
	// fsubs f25,f24,f1
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f1.f64));
	// fadds f4,f30,f27
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// fsubs f2,f7,f29
	ctx.f2.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// fsubs f31,f27,f30
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f30.f64));
	// fadds f30,f29,f7
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// fadds f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f24.f64));
	// fadds f7,f28,f26
	ctx.f7.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// fsubs f3,f23,f3
	ctx.f3.f64 = double(float(ctx.f23.f64 - ctx.f3.f64));
	// fsubs f13,f6,f13
	ctx.f13.f64 = double(float(ctx.f6.f64 - ctx.f13.f64));
	// fsubs f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// fadds f6,f21,f22
	ctx.f6.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f31,f31,f0
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f30,f30,f0
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fsubs f26,f22,f21
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f29,f4,f25
	ctx.f29.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// fadds f27,f2,f5
	ctx.f27.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// fmuls f24,f9,f27
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// fmuls f23,f8,f27
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fsubs f27,f3,f31
	ctx.f27.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fmadds f24,f8,f29,f24
	ctx.f24.f64 = double(float(ctx.f8.f64 * ctx.f29.f64 + ctx.f24.f64));
	// fsubs f8,f7,f24
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f24.f64));
	// stfs f8,0(r3)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f20,f24,f7
	ctx.f20.f64 = double(float(ctx.f24.f64 + ctx.f7.f64));
	// fsubs f8,f11,f12
	ctx.f8.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// fsubs f7,f10,f13
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f13.f64));
	// fadds f24,f30,f1
	ctx.f24.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fmsubs f9,f9,f29,f23
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f29.f64 - ctx.f23.f64));
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// fadds f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// fadds f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f10.f64));
	// fsubs f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// fsubs f4,f25,f4
	ctx.f4.f64 = double(float(ctx.f25.f64 - ctx.f4.f64));
	// fadds f11,f9,f6
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f6.f64));
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfs f20,0(r5)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f11,f9,f6
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// stfs f11,0(r6)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f10,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f2,f10,f7
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// lfs f6,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f29,f9,f27
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// fmuls f25,f10,f8
	ctx.f25.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f11,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f27,f6,f27
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// fmsubs f10,f11,f8,f2
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 - ctx.f2.f64));
	// fmadds f8,f6,f24,f29
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 + ctx.f29.f64));
	// fmadds f11,f11,f7,f25
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64 + ctx.f25.f64));
	// fmsubs f9,f9,f24,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f24.f64 - ctx.f27.f64));
	// fsubs f7,f10,f8
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// stfsx f7,r10,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fadds f8,f9,f11
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// stfsx f8,r10,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfsx f10,r10,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// stfsx f11,r10,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f10,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f7,f10,f26
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// lfs f8,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f9,f5
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmuls f2,f10,f28
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// lfs f11,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f5,f8,f5
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// fmsubs f10,f11,f28,f7
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f28.f64 - ctx.f7.f64));
	// fmadds f8,f8,f4,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f4.f64 + ctx.f6.f64));
	// fmadds f11,f11,f26,f2
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f26.f64 + ctx.f2.f64));
	// fmsubs f9,f9,f4,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f4.f64 - ctx.f5.f64));
	// fsubs f6,f1,f30
	ctx.f6.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// fsubs f7,f10,f8
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// stfsx f7,r9,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fadds f8,f9,f11
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// stfsx f8,r9,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f10,r9,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// stfsx f11,r9,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f8,f31,f3
	ctx.f8.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// lfs f10,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fmuls f5,f10,f13
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f11,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f10,f12
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f9,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// lfs f7,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f7.f64 = double(temp.f32);
	// subf r5,r31,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r31.s64;
	// subf r6,r31,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r31.s64;
	// addi r11,r11,56
	ctx.r11.s64 = ctx.r11.s64 + 56;
	// fmsubs f12,f11,f12,f5
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f12.f64 - ctx.f5.f64));
	// fmadds f13,f11,f13,f10
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f10.f64));
	// fmuls f11,f9,f8
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// fmuls f10,f7,f8
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// fmadds f11,f7,f6,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f6.f64 + ctx.f11.f64));
	// fmsubs f10,f9,f6,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f6.f64 - ctx.f10.f64));
	// fsubs f9,f12,f11
	ctx.f9.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// stfs f9,0(r29)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fadds f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// fadds f11,f10,f13
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// stfs f11,0(r28)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// stfs f12,0(r27)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fsubs f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 - ctx.f13.f64));
	// stfs f13,0(r7)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// lwz r10,3532(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d27eec
	if (!ctx.cr0.eq) goto loc_82D27EEC;
loc_82D28174:
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28f44
	ctx.lr = 0x82D2817C;
	__restfpr_20(ctx, base);
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D28180"))) PPC_WEAK_FUNC(sub_82D28180);
PPC_FUNC_IMPL(__imp__sub_82D28180) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-7568
	ctx.r5.s64 = ctx.r11.s64 + -7568;
	// lis r11,-32046
	ctx.r11.s64 = -2100166656;
	// addi r4,r11,32432
	ctx.r4.s64 = ctx.r11.s64 + 32432;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D28198"))) PPC_WEAK_FUNC(sub_82D28198);
PPC_FUNC_IMPL(__imp__sub_82D28198) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D281A0;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f08
	ctx.lr = 0x82D281A8;
	__savefpr_24(ctx, base);
	// mulli r11,r9,40
	ctx.r11.s64 = ctx.r9.s64 * 40;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-40
	ctx.r11.s64 = ctx.r11.s64 + -40;
	// bge cr6,0x82d283d0
	if (!ctx.cr6.lt) goto loc_82D283D0;
	// subf r31,r9,r10
	ctx.r31.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f13,-28552(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f0.f64 = double(temp.f32);
loc_82D281DC:
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f11,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// add r30,r10,r3
	ctx.r30.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// add r28,r9,r3
	ctx.r28.u64 = ctx.r9.u64 + ctx.r3.u64;
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// add r29,r9,r5
	ctx.r29.u64 = ctx.r9.u64 + ctx.r5.u64;
	// lfs f8,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// add r27,r9,r4
	ctx.r27.u64 = ctx.r9.u64 + ctx.r4.u64;
	// lfs f7,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// add r26,r10,r4
	ctx.r26.u64 = ctx.r10.u64 + ctx.r4.u64;
	// add r9,r9,r6
	ctx.r9.u64 = ctx.r9.u64 + ctx.r6.u64;
	// lfs f6,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfs f4,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f29,f6,f12
	ctx.f29.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// lfs f5,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fadds f12,f12,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
	// fsubs f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfs f3,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfs f1,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// lfs f2,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// add r25,r10,r5
	ctx.r25.u64 = ctx.r10.u64 + ctx.r5.u64;
	// fadds f4,f2,f3
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// add r10,r10,r6
	ctx.r10.u64 = ctx.r10.u64 + ctx.r6.u64;
	// fadds f28,f11,f1
	ctx.f28.f64 = double(float(ctx.f11.f64 + ctx.f1.f64));
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// fsubs f11,f1,f11
	ctx.f11.f64 = double(float(ctx.f1.f64 - ctx.f11.f64));
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// lfs f31,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f27,f10,f31
	ctx.f27.f64 = double(float(ctx.f10.f64 - ctx.f31.f64));
	// lfs f30,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fadds f10,f31,f10
	ctx.f10.f64 = double(float(ctx.f31.f64 + ctx.f10.f64));
	// fsubs f31,f29,f6
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f6.f64));
	// fadds f2,f29,f6
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f6.f64));
	// fadds f6,f12,f5
	ctx.f6.f64 = double(float(ctx.f12.f64 + ctx.f5.f64));
	// fadds f26,f30,f9
	ctx.f26.f64 = double(float(ctx.f30.f64 + ctx.f9.f64));
	// fsubs f1,f4,f28
	ctx.f1.f64 = double(float(ctx.f4.f64 - ctx.f28.f64));
	// fsubs f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f30.f64));
	// fsubs f30,f12,f5
	ctx.f30.f64 = double(float(ctx.f12.f64 - ctx.f5.f64));
	// fadds f12,f11,f3
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f3.f64));
	// fsubs f3,f3,f11
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f11.f64));
	// fadds f4,f28,f4
	ctx.f4.f64 = double(float(ctx.f28.f64 + ctx.f4.f64));
	// fmuls f11,f31,f0
	ctx.f11.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fnmsubs f29,f2,f13,f27
	ctx.f29.f64 = double(float(-(ctx.f2.f64 * ctx.f13.f64 - ctx.f27.f64)));
	// fadds f31,f6,f10
	ctx.f31.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fnmsubs f10,f6,f13,f10
	ctx.f10.f64 = double(float(-(ctx.f6.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// fmadds f6,f1,f13,f26
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 + ctx.f26.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f5,f4,f0
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f4,f30,f0
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fadds f30,f12,f9
	ctx.f30.f64 = double(float(ctx.f12.f64 + ctx.f9.f64));
	// fnmsubs f12,f12,f13,f9
	ctx.f12.f64 = double(float(-(ctx.f12.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// fadds f25,f6,f11
	ctx.f25.f64 = double(float(ctx.f6.f64 + ctx.f11.f64));
	// fsubs f11,f6,f11
	ctx.f11.f64 = double(float(ctx.f6.f64 - ctx.f11.f64));
	// fadds f28,f3,f10
	ctx.f28.f64 = double(float(ctx.f3.f64 + ctx.f10.f64));
	// fsubs f9,f29,f5
	ctx.f9.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// fadds f5,f5,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// fsubs f10,f10,f3
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f3.f64));
	// fmuls f24,f8,f25
	ctx.f24.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// fmuls f25,f7,f25
	ctx.f25.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// fmadds f7,f7,f9,f24
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f9.f64 + ctx.f24.f64));
	// fmsubs f9,f8,f9,f25
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f9.f64 - ctx.f25.f64));
	// fsubs f8,f31,f7
	ctx.f8.f64 = double(float(ctx.f31.f64 - ctx.f7.f64));
	// stfs f8,0(r3)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f8,f9,f30
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f30.f64));
	// stfs f8,0(r4)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f8,f7,f31
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f31.f64));
	// stfs f8,0(r5)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f30.f64));
	// stfs f9,0(r6)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f8,f12,f4
	ctx.f8.f64 = double(float(ctx.f12.f64 + ctx.f4.f64));
	// lfs f9,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f12,f12,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f4.f64));
	// lfs f7,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f6.f64 = double(temp.f32);
	// add r3,r7,r3
	ctx.r3.u64 = ctx.r7.u64 + ctx.r3.u64;
	// lfs f31,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// fadds f4,f2,f27
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f27.f64));
	// fsubs f3,f26,f1
	ctx.f3.f64 = double(float(ctx.f26.f64 - ctx.f1.f64));
	// add r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fmuls f2,f7,f8
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// subf r5,r7,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r7.s64;
	// fmuls f1,f6,f11
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// subf r6,r7,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r7.s64;
	// fmuls f30,f7,f28
	ctx.f30.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// fmuls f29,f31,f11
	ctx.f29.f64 = double(float(ctx.f31.f64 * ctx.f11.f64));
	// fmsubs f11,f9,f28,f2
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f28.f64 - ctx.f2.f64));
	// fmadds f7,f31,f5,f1
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f5.f64 + ctx.f1.f64));
	// fmadds f9,f9,f8,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 + ctx.f30.f64));
	// fmsubs f8,f6,f5,f29
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f5.f64 - ctx.f29.f64));
	// fsubs f6,f11,f7
	ctx.f6.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// stfs f6,0(r30)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fadds f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// fadds f7,f8,f9
	ctx.f7.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// stfs f7,0(r26)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// stfs f11,0(r25)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fsubs f11,f8,f9
	ctx.f11.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// stfs f11,0(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lfs f11,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// lfs f7,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f11,f10
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// fmuls f5,f7,f3
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// lfs f9,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f2,f11,f12
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f8,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f7,f4
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f4.f64));
	// addi r11,r11,40
	ctx.r11.s64 = ctx.r11.s64 + 40;
	// fmadds f12,f9,f12,f6
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 + ctx.f6.f64));
	// fmsubs f11,f8,f4,f5
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f4.f64 - ctx.f5.f64));
	// fmsubs f10,f9,f10,f2
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f10.f64 - ctx.f2.f64));
	// fmadds f9,f8,f3,f7
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f3.f64 + ctx.f7.f64));
	// fadds f8,f11,f12
	ctx.f8.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// stfs f8,0(r27)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fsubs f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// fsubs f11,f10,f9
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// stfs f11,0(r28)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// stfs f12,0(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// fadds f12,f9,f10
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// stfs f12,0(r29)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// lwz r10,3532(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d281dc
	if (!ctx.cr0.eq) goto loc_82D281DC;
loc_82D283D0:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f54
	ctx.lr = 0x82D283D8;
	__restfpr_24(ctx, base);
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D283E0"))) PPC_WEAK_FUNC(sub_82D283E0);
PPC_FUNC_IMPL(__imp__sub_82D283E0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-7512
	ctx.r5.s64 = ctx.r11.s64 + -7512;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-32360
	ctx.r4.s64 = ctx.r11.s64 + -32360;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D283F8"))) PPC_WEAK_FUNC(sub_82D283F8);
PPC_FUNC_IMPL(__imp__sub_82D283F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D28400;
	__savegprlr_28(ctx, base);
	// mulli r11,r9,24
	ctx.r11.s64 = ctx.r9.s64 * 24;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-24
	ctx.r11.s64 = ctx.r11.s64 + -24;
	// bge cr6,0x82d28544
	if (!ctx.cr6.lt) goto loc_82D28544;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r9,r9,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D28424:
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// add r30,r10,r6
	ctx.r30.u64 = ctx.r10.u64 + ctx.r6.u64;
	// lfs f0,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// add r29,r10,r3
	ctx.r29.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lfs f11,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// add r31,r10,r5
	ctx.r31.u64 = ctx.r10.u64 + ctx.r5.u64;
	// lfs f10,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lfs f9,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// lfs f7,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fadds f3,f7,f13
	ctx.f3.f64 = double(float(ctx.f7.f64 + ctx.f13.f64));
	// fsubs f2,f6,f12
	ctx.f2.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// lfs f8,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f5,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f4,f0,f8
	ctx.f4.f64 = double(float(ctx.f0.f64 - ctx.f8.f64));
	// fadds f12,f12,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
	// fadds f1,f11,f5
	ctx.f1.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// fadds f0,f8,f0
	ctx.f0.f64 = double(float(ctx.f8.f64 + ctx.f0.f64));
	// fsubs f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 - ctx.f11.f64));
	// fsubs f13,f13,f7
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
	// fadds f8,f2,f3
	ctx.f8.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fsubs f7,f4,f1
	ctx.f7.f64 = double(float(ctx.f4.f64 - ctx.f1.f64));
	// fadds f5,f12,f0
	ctx.f5.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fadds f6,f1,f4
	ctx.f6.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fsubs f4,f3,f2
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// fadds f3,f11,f13
	ctx.f3.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// fmuls f12,f10,f8
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// fmuls f11,f9,f8
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// fmadds f12,f9,f7,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f7.f64 + ctx.f12.f64));
	// fmsubs f11,f10,f7,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f7.f64 - ctx.f11.f64));
	// fsubs f10,f5,f12
	ctx.f10.f64 = double(float(ctx.f5.f64 - ctx.f12.f64));
	// stfs f10,0(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f10,f11,f3
	ctx.f10.f64 = double(float(ctx.f11.f64 + ctx.f3.f64));
	// stfs f10,0(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f12,f12,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f5.f64));
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f12,f11,f3
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f3.f64));
	// stfs f12,0(r6)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f11,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// add r3,r7,r3
	ctx.r3.u64 = ctx.r7.u64 + ctx.r3.u64;
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f11,f13
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f7,f9,f6
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f5,f12,f13
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f9,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// add r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 + ctx.r4.u64;
	// subf r5,r7,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r7.s64;
	// subf r6,r7,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r7.s64;
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// fmsubs f13,f12,f0,f8
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 - ctx.f8.f64));
	// fmadds f12,f10,f4,f7
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 + ctx.f7.f64));
	// fmadds f0,f11,f0,f5
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 + ctx.f5.f64));
	// fmsubs f11,f10,f6,f9
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f6.f64 - ctx.f9.f64));
	// fsubs f10,f13,f12
	ctx.f10.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// stfs f10,0(r29)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fadds f12,f11,f0
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// stfs f13,0(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fsubs f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// stfs f0,0(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// lwz r10,3532(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d28424
	if (!ctx.cr0.eq) goto loc_82D28424;
loc_82D28544:
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D28548"))) PPC_WEAK_FUNC(sub_82D28548);
PPC_FUNC_IMPL(__imp__sub_82D28548) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-7456
	ctx.r5.s64 = ctx.r11.s64 + -7456;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-31752
	ctx.r4.s64 = ctx.r11.s64 + -31752;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D28560"))) PPC_WEAK_FUNC(sub_82D28560);
PPC_FUNC_IMPL(__imp__sub_82D28560) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// addi r11,r11,-8
	ctx.r11.s64 = ctx.r11.s64 + -8;
	// bgelr cr6
	if (!ctx.cr6.lt) return;
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D28580:
	// lfs f13,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lfs f0,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fadds f8,f13,f0
	ctx.f8.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// lfs f11,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f9,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f13,f12,f11
	ctx.f13.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// fadds f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// lfs f10,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// fmuls f11,f9,f8
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// fmuls f8,f10,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// fmsubs f11,f10,f13,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 - ctx.f11.f64));
	// fmadds f13,f9,f13,f8
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 + ctx.f8.f64));
	// fadds f10,f11,f0
	ctx.f10.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// stfs f10,0(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f10,f12,f13
	ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// stfs f10,0(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f0,f13,f12
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// add r3,r8,r3
	ctx.r3.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r4,r8,r4
	ctx.r4.u64 = ctx.r8.u64 + ctx.r4.u64;
	// subf r5,r8,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r8.s64;
	// subf r6,r8,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r8.s64;
	// bne 0x82d28580
	if (!ctx.cr0.eq) goto loc_82D28580;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D285F8"))) PPC_WEAK_FUNC(sub_82D285F8);
PPC_FUNC_IMPL(__imp__sub_82D285F8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-7400
	ctx.r5.s64 = ctx.r11.s64 + -7400;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-31392
	ctx.r4.s64 = ctx.r11.s64 + -31392;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D28610"))) PPC_WEAK_FUNC(sub_82D28610);
PPC_FUNC_IMPL(__imp__sub_82D28610) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D28618;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D28620;
	__savefpr_14(ctx, base);
	// stwu r1,-784(r1)
	ea = -784 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// rlwinm r11,r9,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// addi r11,r11,-32
	ctx.r11.s64 = ctx.r11.s64 + -32;
	// bge cr6,0x82d29f84
	if (!ctx.cr6.lt) goto loc_82D29F84;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,868(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 868);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r19,r7,2,0,29
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// stw r10,428(r1)
	PPC_STORE_U32(ctx.r1.u32 + 428, ctx.r10.u32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lfs f31,-8000(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8000);
	ctx.f31.f64 = double(temp.f32);
	// lis r9,-32236
	ctx.r9.s64 = -2112618496;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f1,-8004(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -8004);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,-8008(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8008);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,-8012(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8012);
	ctx.f3.f64 = double(temp.f32);
	// lfs f10,-8016(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -8016);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,136(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 136);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f12.f64 = double(temp.f32);
loc_82D28680:
	// lfs f0,24(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// lfs f9,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f30,f0,f9
	ctx.f30.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f25,f0,f8
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f4,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f21,f8,f5
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// lfs f13,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f23,f9,f4
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// lfs f7,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f19,f0,f4
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// lfs f6,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f0,f7
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fmuls f16,f13,f6
	ctx.f16.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fmuls f15,f13,f5
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// fmuls f28,f4,f6
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// fmuls f29,f5,f7
	ctx.f29.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// fmadds f30,f13,f8,f30
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 + ctx.f30.f64));
	// stfs f30,404(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// fmsubs f30,f13,f9,f25
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 - ctx.f25.f64));
	// stfs f30,416(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fmuls f26,f4,f7
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// fadds f25,f21,f23
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fsubs f21,f21,f23
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// stfs f21,344(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// fmuls f27,f5,f6
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fsubs f23,f20,f16
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f23,320(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// fsubs f23,f15,f19
	ctx.f23.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f23,296(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fmuls f22,f8,f4
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fmuls f24,f9,f5
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmuls f18,f0,f6
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// fmuls f23,f13,f7
	ctx.f23.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fadds f30,f28,f29
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fsubs f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fmuls f17,f0,f5
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// fadds f28,f26,f27
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fsubs f26,f24,f22
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fadds f22,f23,f18
	ctx.f22.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f22,444(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// fmuls f22,f13,f4
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fsubs f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// stfs f23,268(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fadds f23,f15,f19
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f23,408(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// fmuls f15,f25,f0
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmuls f19,f13,f27
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f27.f64));
	// fmuls f18,f0,f27
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f27.f64));
	// fadds f23,f22,f17
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f23,240(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fadds f23,f16,f20
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f23,168(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fmuls f16,f26,f0
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fsubs f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f14,336(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// fmuls f14,f24,f0
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f23,f0,f30
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmuls f22,f13,f30
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// fmuls f20,f0,f29
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// fmuls f17,f13,f28
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// fmadds f16,f25,f13,f16
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f16,372(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// fmsubs f16,f26,f13,f15
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f16,304(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fmadds f16,f21,f13,f14
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f16,464(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// fsubs f16,f23,f19
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// stfs f16,256(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fadds f23,f19,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// stfs f23,368(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// fadds f23,f18,f22
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f23,452(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// fsubs f23,f22,f18
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f23,424(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// fadds f23,f17,f20
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f23,332(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fsubs f23,f20,f17
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f23,348(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fmuls f22,f0,f28
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// fmuls f23,f13,f29
	ctx.f23.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// mulli r10,r8,60
	ctx.r10.s64 = ctx.r8.s64 * 60;
	// fmuls f21,f21,f0
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fmuls f18,f8,f7
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fmuls f19,f9,f6
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f16,f9,f30
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fmuls f15,f8,f27
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmuls f14,f8,f30
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fmuls f17,f8,f6
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// fsubs f20,f23,f22
	ctx.f20.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f20,340(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f23,356(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// fmuls f23,f9,f27
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// stfs f23,28(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f20,f9,f7
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// fsubs f22,f18,f19
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f22,312(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fmsubs f21,f24,f13,f21
	ctx.f21.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 - ctx.f21.f64));
	// stfs f21,328(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f19,396(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// fsubs f21,f16,f15
	ctx.f21.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f21,280(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// fadds f23,f17,f20
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f20,380(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fadds f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f17,224(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fmuls f16,f8,f28
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f21,f14,f18
	ctx.f21.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfs f21,364(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f18,264(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fmuls f18,f9,f29
	ctx.f18.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// fmuls f14,f19,f0
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fsubs f15,f18,f16
	ctx.f15.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f15,248(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f18,196(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fmuls f16,f9,f28
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f18,f8,f29
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// fadds f15,f16,f18
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f15,212(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,204(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fmuls f18,f23,f0
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f16,f22,f0
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmuls f15,f20,f0
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmadds f22,f22,f13,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f18.f64));
	// stfs f22,476(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// fmsubs f22,f23,f13,f16
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f22,468(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// fmadds f22,f19,f13,f15
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f22,360(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// fmsubs f22,f20,f13,f14
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f22,432(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// lfsx f22,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f19,f21,f0
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// stfs f22,28(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f22,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fmuls f22,f17,f0
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f18,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f0
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// lfs f20,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmadds f21,f21,f13,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 + ctx.f22.f64));
	// lfs f22,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f20,f22,f13,f20
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f20.f64));
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f15,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f22,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f22.f64 = double(temp.f32);
	// rlwinm r9,r8,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fmsubs f22,f22,f13,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f19.f64));
	// stfs f22,420(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// lfs f22,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// mulli r7,r8,44
	ctx.r7.s64 = ctx.r8.s64 * 44;
	// fmadds f19,f22,f13,f18
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f18.f64));
	// lfs f22,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f13,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f22,436(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// lfs f22,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f13,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f22,400(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// lfs f22,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f13,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f22,352(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfs f22,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f22.f64 = double(temp.f32);
	// mulli r31,r8,12
	ctx.r31.s64 = ctx.r8.s64 * 12;
	// fmadds f22,f22,f13,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f22,292(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fadds f18,f17,f22
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// lfs f22,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f22,f15
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// lfsx f14,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// lfsx f15,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,60(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// mulli r30,r8,48
	ctx.r30.s64 = ctx.r8.s64 * 48;
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f14,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f14,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfsx f14,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// rlwinm r29,r8,5,0,26
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// mulli r28,r8,28
	ctx.r28.s64 = ctx.r8.s64 * 28;
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f15,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f14,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// rlwinm r27,r8,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r23,r8,52
	ctx.r23.s64 = ctx.r8.s64 * 52;
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r28,r6
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,84(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfsx f14,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,120(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfsx f14,r23,r5
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,92(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,108(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,216(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,140(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,192(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,84(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,144(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f15,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,108(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,208(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f15,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,128(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,140(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// stfs f15,200(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fadds f15,f14,f18
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,100(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f18,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f14,f16,f18
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,84(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f18,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f16,f17,f18
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f16,376(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f18,388(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// lfs f18,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f17,f22,f18
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f17,216(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,392(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f22,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f17,f22,f18
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// fadds f16,f18,f22
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// lfs f18,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f18,f22
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f18,124(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// stfs f22,28(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfs f18,288(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fmuls f18,f17,f12
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f17,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f17.f64 = double(temp.f32);
	// mulli r26,r8,40
	ctx.r26.s64 = ctx.r8.s64 * 40;
	// fmr f22,f17
	ctx.f22.f64 = ctx.f17.f64;
	// stfs f18,308(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fmuls f18,f16,f12
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// stfs f18,208(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f18,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f18.f64 = double(temp.f32);
	// mulli r22,r8,20
	ctx.r22.s64 = ctx.r8.s64 * 20;
	// lfsx f15,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f18,f22
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// stfs f17,188(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// stfs f22,180(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f18,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f17,f18,f22
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// stfs f17,164(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// stfs f22,116(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmuls f22,f14,f12
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// lfsx f14,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// rlwinm r21,r8,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f22,440(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// mulli r25,r8,56
	ctx.r25.s64 = ctx.r8.s64 * 56;
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// mulli r24,r8,24
	ctx.r24.s64 = ctx.r8.s64 * 24;
	// mulli r20,r8,36
	ctx.r20.s64 = ctx.r8.s64 * 36;
	// add r18,r23,r6
	ctx.r18.u64 = ctx.r23.u64 + ctx.r6.u64;
	// add r17,r22,r6
	ctx.r17.u64 = ctx.r22.u64 + ctx.r6.u64;
	// add r16,r21,r6
	ctx.r16.u64 = ctx.r21.u64 + ctx.r6.u64;
	// add r15,r20,r6
	ctx.r15.u64 = ctx.r20.u64 + ctx.r6.u64;
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f22,f17,f12
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfsx f14,r22,r5
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r21,r5
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// stfs f22,140(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f22,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f14,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f18,f22
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// stfs f14,84(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// lfsx f14,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f17,252(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// stfs f14,108(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f17,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f14,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// stfs f22,172(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f22,f18,f17
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfsx f14,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f16,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f17,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f14,r20,r5
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fadds f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,36(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f17,80(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f17,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f17,f16
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,24(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f16,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f15,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f16,f15
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f15,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,60(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,72(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f18
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,128(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,144(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f15,f17
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f16,f17,f10
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// fmuls f15,f17,f11
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f16,f17,f11,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 - ctx.f16.f64));
	// stfs f16,192(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// fmadds f17,f17,f10,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f15.f64));
	// stfs f17,108(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f17,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f17,f10
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// fmuls f15,f17,f11
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// lfs f17,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,112(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,156(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f17,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,160(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// add r14,r22,r4
	ctx.r14.u64 = ctx.r22.u64 + ctx.r4.u64;
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,104(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,384(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// lfs f17,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f17.f64 = double(temp.f32);
	// stw r14,28(r1)
	PPC_STORE_U32(ctx.r1.u32 + 28, ctx.r14.u32);
	// fmsubs f16,f17,f11,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 - ctx.f16.f64));
	// stfs f16,144(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmadds f17,f17,f10,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f15.f64));
	// stfs f17,84(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// add r14,r21,r4
	ctx.r14.u64 = ctx.r21.u64 + ctx.r4.u64;
	// lfs f17,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// stw r14,72(r1)
	PPC_STORE_U32(ctx.r1.u32 + 72, ctx.r14.u32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,32(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f22,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// add r14,r20,r4
	ctx.r14.u64 = ctx.r20.u64 + ctx.r4.u64;
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,24(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// stfs f17,96(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// stw r14,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r14.u32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// lfsx f14,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r26,r5
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// stfs f18,324(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfsx f18,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f14,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// stfs f18,136(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfsx f18,r25,r5
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r5.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,92(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fmuls f18,f16,f11
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// stfs f16,128(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfsx f16,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,148(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfsx f16,r24,r5
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,220(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfsx f16,r27,r5
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,52(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfsx f16,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,76(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// stfs f15,120(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fmuls f15,f15,f11
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// lwz r14,28(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f11
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,412(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// lfsx f14,r27,r6
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// lfsx f14,r26,r6
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// stfs f22,316(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fmsubs f18,f14,f10,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 - ctx.f18.f64));
	// lfs f22,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// stfs f18,200(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfsx f14,r25,r6
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,72(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f17,f14,f10,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 + ctx.f17.f64));
	// lfsx f14,r24,r6
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f16,f14,f10,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 + ctx.f16.f64));
	// lwz r14,100(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stfs f16,100(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f10,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 - ctx.f15.f64));
	// stfs f16,128(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f15,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,80(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f15,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,48(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,120(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fadds f15,f14,f22
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,68(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// stfs f17,96(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f17,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f18,f22
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// stfs f22,20(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f22,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f18,f17,f22
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f18,44(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f14,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f16
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// fadds f14,f18,f22
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f14,284(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f22,272(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fsubs f18,f15,f16
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfs f22,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f22.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fadds f14,f22,f17
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// fsubs f15,f22,f17
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f22,24(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f22,88(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f22,76(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f22,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f15,f12
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f16,136(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f17,f14,f12
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// stfs f17,60(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,36(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,92(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f15,148(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfsx f14,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f14,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfsx f14,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f14,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f14,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f14,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,176(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f14,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f14,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,184(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfsx f14,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,132(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f14,456(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// lfsx f14,r29,r5
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,80(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfs f18,300(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfsx f18,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,24(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f18,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f14,472(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// lfsx f14,r29,r6
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,120(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f18,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f22,f18
	ctx.f18.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// lfs f22,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,220(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,244(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f22,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f14,448(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f22,152(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f22,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f17,f16,f22
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// stfs f17,460(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// fadds f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// stfs f22,92(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f17,f22,f15
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f22,236(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f22,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f22.f64 = double(temp.f32);
	// stfs f17,136(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fsubs f17,f22,f16
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// fadds f16,f16,f22
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// fadds f15,f14,f22
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,60(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f22,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,20(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f22,36(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f22,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,40(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f22,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,64(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f22,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,52(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,24(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,80(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fadds f22,f15,f17
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,260(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,176(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,132(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,228(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,88(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,148(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,232(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fadds f15,f17,f22
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// lfs f17,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f22,76(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f22,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f22,276(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,104(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,112(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,32(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fmuls f16,f15,f12
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// stfs f16,116(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmuls f16,f14,f12
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f14,132(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,176(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f14,124(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,228(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f22,36(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f15,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f22,f14,f12
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f14,80(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,276(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f15,f17
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f15,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f15.f64 = double(temp.f32);
	// stfs f17,24(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f15
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,104(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f22,260(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f22,f16
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f14,132(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,124(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f14,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f14.f64 = double(temp.f32);
	// stfs f22,284(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f22,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// lfs f16,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,116(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f18
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f16,112(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f18,76(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f18,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// stfs f18,0(r3)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f17,f17,f20
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f20.f64));
	// lfs f18,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f18,0(r5)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fmuls f18,f22,f20
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// lfs f20,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f20.f64));
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f20.f64));
	// lfs f14,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f16,f14
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f14.f64));
	// fmsubs f22,f22,f19,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 - ctx.f17.f64));
	// stfsx f22,r29,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f22,f22,f19,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 + ctx.f18.f64));
	// stfsx f22,r29,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// lfs f22,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f19,f19,f22,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 - ctx.f15.f64));
	// stfsx f19,r30,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f19,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f22,f19,f22,f20
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 + ctx.f20.f64));
	// stfsx f22,r30,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f23,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 - ctx.f14.f64));
	// lfs f18,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f22,r9,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f18,f19
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f18,f15,f17
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f18,184(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fsubs f20,f15,f17
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// lfs f18,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f18
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f17,288(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f15,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f15,f17
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f14,164(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,156(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f17,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f18,160(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f17,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f15,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f15.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f11
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f11.f64));
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmadds f23,f16,f23,f15
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f23.f64 + ctx.f15.f64));
	// stfsx f23,r9,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f23.f64 = double(temp.f32);
	// fadds f16,f20,f22
	ctx.f16.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// fmsubs f23,f23,f10,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 - ctx.f14.f64));
	// stfs f23,272(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fsubs f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// fmuls f22,f22,f12
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f23,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f23.f64 = double(temp.f32);
	// fadds f20,f23,f19
	ctx.f20.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// fsubs f19,f19,f23
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f23.f64));
	// fmuls f23,f16,f12
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f16,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f16,f18
	ctx.f15.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmuls f19,f19,f12
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,232(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f18,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f16,f18,f17
	ctx.f16.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f16,296(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f17,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// lfs f16,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f16.f64 = double(temp.f32);
	// stfs f17,172(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f17,f16,f20
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// stfs f17,180(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fadds f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// stfs f15,184(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f15,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f15.f64 = double(temp.f32);
	// stfs f20,164(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f20,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// lfs f14,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f14.f64 = double(temp.f32);
	// stfs f22,156(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fsubs f22,f14,f19
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f18,240(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fsubs f18,f15,f23
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// fadds f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// lfs f20,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f20.f64 = double(temp.f32);
	// fadds f17,f19,f14
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// fmuls f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// fmuls f16,f23,f28
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// fmuls f15,f23,f29
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f29.f64));
	// lfs f23,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f19,f18,f21
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f21.f64));
	// fmuls f14,f22,f23
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// lfs f23,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f22,f23
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// fmuls f18,f17,f25
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// fmuls f17,f17,f26
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f26.f64));
	// lfs f23,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f21,f23,f21,f20
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f21.f64 - ctx.f20.f64));
	// stfsx f21,r26,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f23,f23,f21,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f21.f64 + ctx.f19.f64));
	// stfsx f23,r26,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f26,f23,f26,f18
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 - ctx.f18.f64));
	// stfsx f26,r24,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fmadds f26,f23,f25,f17
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f25.f64 + ctx.f17.f64));
	// stfsx f26,r24,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// lfs f26,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f29,f26,f29,f16
	ctx.f29.f64 = double(float(ctx.f26.f64 * ctx.f29.f64 - ctx.f16.f64));
	// stfsx f29,r27,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fmadds f29,f26,f28,f15
	ctx.f29.f64 = double(float(ctx.f26.f64 * ctx.f28.f64 + ctx.f15.f64));
	// stfsx f29,r27,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// lfs f29,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f29.f64 = double(temp.f32);
	// lfs f28,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f29,f28,f14
	ctx.f28.f64 = double(float(ctx.f29.f64 * ctx.f28.f64 - ctx.f14.f64));
	// stfsx f28,r25,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f29,f29,f28,f22
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f28.f64 + ctx.f22.f64));
	// lfs f28,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f28,f11
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// stfsx f29,r25,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// lfs f29,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f29.f64 = double(temp.f32);
	// lfs f21,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f25,f29,f11
	ctx.f25.f64 = double(float(ctx.f29.f64 * ctx.f11.f64));
	// lfs f22,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f20,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f23,f23,f10
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// lfs f21,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fmadds f29,f29,f10,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f10.f64 + ctx.f26.f64));
	// lfs f26,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f20,f26,f10
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// lfs f26,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f28,f28,f10,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 - ctx.f25.f64));
	// lfs f25,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f19,f25,f11
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// fmuls f25,f22,f12
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// fmadds f26,f26,f11,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f11.f64 + ctx.f23.f64));
	// fmuls f23,f21,f12
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfs f22,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f22,f22,f11,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 - ctx.f20.f64));
	// fmadds f21,f21,f10,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 + ctx.f19.f64));
	// lfs f19,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f20,f19,f29
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f29.f64));
	// lfs f18,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f18.f64 = double(temp.f32);
	// fadds f29,f29,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f19.f64));
	// lfs f17,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f19,f28,f26
	ctx.f19.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// lfs f16,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f16.f64 = double(temp.f32);
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// lfs f14,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f26,f18,f25
	ctx.f26.f64 = double(float(ctx.f18.f64 - ctx.f25.f64));
	// fadds f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f18.f64));
	// fsubs f18,f17,f23
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f23.f64));
	// fadds f23,f23,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f17.f64));
	// fsubs f17,f22,f21
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f17,180(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f17,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f17.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f22,172(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f22,f17,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfs f20,244(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fadds f21,f29,f16
	ctx.f21.f64 = double(float(ctx.f29.f64 + ctx.f16.f64));
	// lfs f20,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f29,f16,f29
	ctx.f29.f64 = double(float(ctx.f16.f64 - ctx.f29.f64));
	// lfs f17,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f20,f19
	ctx.f16.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfs f16,188(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fadds f15,f28,f17
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// stfs f15,252(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fsubs f28,f17,f28
	ctx.f28.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// stfs f28,236(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f28,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f28.f64 = double(temp.f32);
	// lfs f15,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f19,f22,f28
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// fmuls f17,f21,f27
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f27.f64));
	// fmuls f14,f29,f14
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f14.f64));
	// fmuls f28,f16,f28
	ctx.f28.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// lfs f16,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f21,f21,f30
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// fmuls f16,f20,f16
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f16.f64));
	// fmuls f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f15.f64));
	// lfs f15,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f29,f15
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f15.f64));
	// lfs f29,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f28,f22,f29,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f29.f64 - ctx.f28.f64));
	// stfsx f28,r23,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f29,f28,f29,f19
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f29.f64 + ctx.f19.f64));
	// stfsx f29,r23,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// lfs f29,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f30,f29,f30,f17
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f30.f64 - ctx.f17.f64));
	// stfsx f30,r21,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f29,f27,f21
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f27.f64 + ctx.f21.f64));
	// stfsx f30,r21,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r5.u32, temp.u32);
	// lfs f30,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f29,f30,f29,f16
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 - ctx.f16.f64));
	// stfsx f29,r22,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// lfs f29,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f30,f30,f29,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 + ctx.f20.f64));
	// stfsx f30,r22,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r5.u32, temp.u32);
	// lfs f30,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f29,f30,f29,f15
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 - ctx.f15.f64));
	// stfsx f29,r20,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// lfs f29,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f30,f30,f29,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 + ctx.f14.f64));
	// stfsx f30,r20,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r5.u32, temp.u32);
	// lfs f30,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f22,f30,f10
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// lfs f30,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f30.f64 = double(temp.f32);
	// lfs f28,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f21,f30,f10
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// lfs f27,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f30,f26,f28
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// fadds f29,f27,f23
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f23.f64));
	// fadds f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// lfs f26,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// lfs f23,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f23.f64 = double(temp.f32);
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f26,f26,f11,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f11.f64 - ctx.f22.f64));
	// fmadds f23,f23,f11,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f11.f64 + ctx.f21.f64));
	// lfs f22,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f17,f2
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// fmuls f15,f21,f2
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f2.f64));
	// lfs f21,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f22,f3
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f3.f64));
	// lfs f16,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f19,f22,f2
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// lfs f22,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f21,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f20,f16,f3,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 + ctx.f20.f64));
	// lfs f16,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f17,f17,f3,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 - ctx.f15.f64));
	// fmuls f15,f29,f24
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f24.f64));
	// fmsubs f19,f16,f3,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 - ctx.f19.f64));
	// fmadds f16,f16,f2,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f2.f64 + ctx.f14.f64));
	// stfs f16,92(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f16,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f29,f16
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f16.f64));
	// lfs f29,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f14,f27,f29
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f29.f64));
	// fsubs f29,f26,f23
	ctx.f29.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// fadds f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fadds f23,f21,f22
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f21,f19,f20
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfs f20,188(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fadds f19,f26,f25
	ctx.f19.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// stfs f19,152(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfs f26,168(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f25,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f25.f64 = double(temp.f32);
	// lfs f19,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfs f20,268(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fsubs f20,f18,f29
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f29.f64));
	// fadds f29,f29,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f18.f64));
	// lfs f18,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f25,f20,f25
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// fmuls f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64));
	// lfs f19,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f29,f19
	ctx.f19.f64 = double(float(ctx.f29.f64 * ctx.f19.f64));
	// fmuls f29,f29,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f18.f64));
	// lfs f18,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f26,f26,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f18.f64));
	// lfs f18,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f25,f30,f18,f25
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f18.f64 - ctx.f25.f64));
	// stfsx f25,r10,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f30,f30,f25,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f25.f64 + ctx.f20.f64));
	// stfsx f30,r10,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f30,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f25,f30,f24,f16
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f24.f64 - ctx.f16.f64));
	// stfsx f25,r31,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f30,f30,f25,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f25.f64 + ctx.f15.f64));
	// stfsx f30,r31,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lfs f30,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f28,f30,f19
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f30.f64 - ctx.f19.f64));
	// stfsx f30,r28,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f28,f30,f29
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f30.f64 + ctx.f29.f64));
	// stfsx f30,r28,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// lfs f30,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f29,f29,f30,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f30.f64 - ctx.f14.f64));
	// stfsx f29,r7,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f27,f30,f26
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f30.f64 + ctx.f26.f64));
	// stfsx f30,r7,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// lfs f25,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f27,f23,f25
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f25.f64));
	// fadds f26,f24,f22
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// lfs f29,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f29.f64 = double(temp.f32);
	// lfs f30,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f30.f64 = double(temp.f32);
	// fadds f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f23.f64));
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// lfs f23,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f22.f64 = double(temp.f32);
	// fadds f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// lfs f28,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f22,f3
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f3.f64));
	// lfs f29,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f20,f23,f2
	ctx.f20.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// fadds f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// lfs f22,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f23,f3
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f28,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f28.f64 = double(temp.f32);
	// lfs f23,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f28,f17,f28
	ctx.f28.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// lfs f19,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f19,f3
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f19,f19,f2,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f2.f64 + ctx.f18.f64));
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f20,f17,f3,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 + ctx.f20.f64));
	// lfs f17,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// lfs f17,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// lfs f14,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f14,f2,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f2.f64 - ctx.f16.f64));
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f14,f2,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f2.f64 - ctx.f15.f64));
	// fadds f14,f29,f30
	ctx.f14.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fsubs f29,f23,f22
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f22,f20,f19
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fadds f19,f17,f18
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f19,292(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fsubs f19,f18,f17
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f19,152(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f17,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f15,f16
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f19,300(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fsubs f19,f16,f15
	ctx.f19.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f19,168(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f19,f14,f21
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// lfs f15,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f30,f28
	ctx.f18.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// lfs f28,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f28.f64 = double(temp.f32);
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// lfs f14,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f28,f19,f28
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f28.f64));
	// fmuls f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// fmuls f17,f18,f8
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// fmuls f18,f18,f9
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// fmuls f15,f30,f15
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f15.f64));
	// fmuls f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f14.f64));
	// lfs f14,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f16,f21,f6
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// fmuls f21,f21,f7
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f7.f64));
	// fmsubs f28,f27,f14,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f14.f64 - ctx.f28.f64));
	// stfsx f28,r29,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f27,f28,f19
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f28.f64 + ctx.f19.f64));
	// stfsx f28,r29,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fmsubs f9,f26,f9,f17
	ctx.f9.f64 = double(float(ctx.f26.f64 * ctx.f9.f64 - ctx.f17.f64));
	// stfsx f9,r9,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f9,f26,f8,f18
	ctx.f9.f64 = double(float(ctx.f26.f64 * ctx.f8.f64 + ctx.f18.f64));
	// stfsx f9,r9,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fmsubs f9,f25,f7,f16
	ctx.f9.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 - ctx.f16.f64));
	// stfs f9,0(r4)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmadds f9,f25,f6,f21
	ctx.f9.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f21.f64));
	// stfs f9,0(r6)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f9,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f9,f24,f9,f15
	ctx.f9.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 - ctx.f15.f64));
	// stfsx f9,r30,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f9,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f9,f24,f9,f30
	ctx.f9.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 + ctx.f30.f64));
	// stfsx f9,r30,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f27,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f27.f64 = double(temp.f32);
	// lfs f9,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f6,f27,f31
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f30,f9,f31
	ctx.f30.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// lfs f7,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f21,f9,f1
	ctx.f21.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// lfs f8,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f26,f7,f31
	ctx.f26.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// lfs f28,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f28.f64 = double(temp.f32);
	// lfs f24,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f24.f64 = double(temp.f32);
	// lfs f8,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// lfs f28,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f28.f64 = double(temp.f32);
	// lfs f25,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f25.f64 = double(temp.f32);
	// lfs f18,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f7,f7,f1,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f1.f64 + ctx.f6.f64));
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f6,f24,f1,f30
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f1.f64 - ctx.f30.f64));
	// lfs f30,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// lfs f28,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// lfs f15,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f27,f27,f1,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 - ctx.f26.f64));
	// lfs f16,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f24,f24,f31,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f31.f64 + ctx.f21.f64));
	// lfs f14,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f25,f18,f22
	ctx.f25.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// fadds f18,f8,f9
	ctx.f18.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fsubs f19,f17,f15
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fadds f21,f20,f23
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// fadds f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// fsubs f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f7.f64));
	// fadds f6,f28,f30
	ctx.f6.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// fadds f20,f17,f15
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f15,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// lfs f28,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f28.f64 = double(temp.f32);
	// fadds f17,f24,f27
	ctx.f17.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// stfs f17,96(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f17,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f28.f64));
	// fsubs f26,f29,f16
	ctx.f26.f64 = double(float(ctx.f29.f64 - ctx.f16.f64));
	// fmuls f25,f25,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f17.f64));
	// lfs f17,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f17.f64 = double(temp.f32);
	// fadds f29,f16,f29
	ctx.f29.f64 = double(float(ctx.f16.f64 + ctx.f29.f64));
	// lfs f16,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f19,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// fmuls f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfs f16,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f22,f16
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// fmuls f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f15.f64));
	// lfs f15,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f20,f15
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f15.f64));
	// fmuls f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f14.f64));
	// lfs f14,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f28,f26,f14,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f14.f64 - ctx.f28.f64));
	// stfsx f28,r7,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f26,f28,f25
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f28.f64 + ctx.f25.f64));
	// stfsx f28,r7,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// lfs f28,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f21,f28,f17
	ctx.f28.f64 = double(float(ctx.f21.f64 * ctx.f28.f64 - ctx.f17.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f21,f28,f19
	ctx.f28.f64 = double(float(ctx.f21.f64 * ctx.f28.f64 + ctx.f19.f64));
	// stfsx f28,r10,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f28,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f29,f28,f16
	ctx.f28.f64 = double(float(ctx.f29.f64 * ctx.f28.f64 - ctx.f16.f64));
	// stfsx f28,r31,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f29,f29,f28,f22
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f28.f64 + ctx.f22.f64));
	// lfs f28,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f23,f28,f15
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f28.f64 - ctx.f15.f64));
	// stfsx f29,r31,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// stfsx f28,r28,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fsubs f29,f27,f24
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// lfs f28,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f23,f28,f20
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f28.f64 + ctx.f20.f64));
	// stfsx f28,r28,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f28,f6,f8
	ctx.f28.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// lfs f26,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f25.f64 = double(temp.f32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// fmuls f23,f25,f31
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// lfs f22,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f19,f25,f1
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f1.f64));
	// lfs f25,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f25.f64 = double(temp.f32);
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f21.f64 = double(temp.f32);
	// lfs f27,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f27.f64 = double(temp.f32);
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f27,f18,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 - ctx.f27.f64));
	// lfs f6,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f6.f64 = double(temp.f32);
	// lfs f16,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f28,f26
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f26.f64));
	// lfs f26,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f26,f31
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fmuls f24,f26,f1
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// lfs f26,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfs f25,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// lfs f22,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f21,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f23,f20,f1,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f1.f64 + ctx.f23.f64));
	// fmsubs f20,f20,f31,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f31.f64 - ctx.f19.f64));
	// fadds f19,f7,f9
	ctx.f19.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fsubs f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// fsubs f9,f9,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// fadds f17,f30,f29
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f29.f64));
	// fsubs f7,f30,f29
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fmuls f30,f28,f6
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f6.f64));
	// fmsubs f6,f27,f6,f15
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f6.f64 - ctx.f15.f64));
	// stfsx f6,r26,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f24,f16,f31,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f31.f64 - ctx.f24.f64));
	// fmadds f16,f16,f1,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f14.f64));
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// fmadds f6,f27,f6,f30
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f6.f64 + ctx.f30.f64));
	// stfsx f6,r26,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// fsubs f6,f26,f25
	ctx.f6.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fadds f30,f25,f26
	ctx.f30.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfs f25,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f27,f22,f21
	ctx.f27.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f26,f21,f22
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f22,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f17,f25
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// fmuls f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f22.f64));
	// fsubs f29,f24,f23
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f28,f23,f24
	ctx.f28.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfs f24,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f15,f8,f24
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f24.f64));
	// lfs f24,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f8,f24
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f24.f64));
	// lfs f24,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f8,f7,f23
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// stfs f8,256(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fsubs f25,f20,f16
	ctx.f25.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// fmuls f7,f7,f24
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f24.f64));
	// fmsubs f22,f19,f22,f21
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 - ctx.f21.f64));
	// stfsx f22,r24,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f19,f22,f17
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 + ctx.f17.f64));
	// stfsx f22,r24,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// lfs f22,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f22.f64 = double(temp.f32);
	// fadds f8,f16,f20
	ctx.f8.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// fmsubs f22,f18,f22,f15
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 - ctx.f15.f64));
	// stfsx f22,r27,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f22.f64 = double(temp.f32);
	// lwz r10,428(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	// lfs f21,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f22,f18,f22,f14
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 + ctx.f14.f64));
	// stfsx f22,r27,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fmsubs f24,f9,f24,f21
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f24.f64 - ctx.f21.f64));
	// stfsx f24,r25,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// fmadds f9,f9,f23,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f23.f64 + ctx.f7.f64));
	// stfsx f9,r25,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// fsubs f9,f27,f29
	ctx.f9.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// fsubs f7,f6,f25
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f25.f64));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// add r3,r19,r3
	ctx.r3.u64 = ctx.r19.u64 + ctx.r3.u64;
	// fadds f6,f25,f6
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f6.f64));
	// subf r5,r19,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r19.s64;
	// subf r6,r19,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r19.s64;
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// stw r10,428(r1)
	PPC_STORE_U32(ctx.r1.u32 + 428, ctx.r10.u32);
	// lwz r10,72(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	// fmuls f24,f9,f13
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f23,f9,f0
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fadds f9,f26,f8
	ctx.f9.f64 = double(float(ctx.f26.f64 + ctx.f8.f64));
	// fsubs f8,f26,f8
	ctx.f8.f64 = double(float(ctx.f26.f64 - ctx.f8.f64));
	// fmsubs f0,f7,f0,f24
	ctx.f0.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 - ctx.f24.f64));
	// stfsx f0,r23,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fadds f0,f28,f30
	ctx.f0.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// add r4,r19,r4
	ctx.r4.u64 = ctx.r19.u64 + ctx.r4.u64;
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fmuls f28,f9,f4
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// fmuls f27,f9,f5
	ctx.f27.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// lfs f9,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f13,f7,f13,f23
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 + ctx.f23.f64));
	// stfs f13,0(r18)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// lfs f13,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f26,f9,f29
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// fmuls f29,f13,f29
	ctx.f29.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// lfs f7,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f25,f7,f8
	ctx.f25.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// fmsubs f5,f0,f5,f28
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f5.f64 - ctx.f28.f64));
	// stfs f5,0(r10)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,28(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// fmadds f0,f0,f4,f27
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f4.f64 + ctx.f27.f64));
	// stfs f0,0(r16)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fmsubs f0,f13,f6,f26
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f6.f64 - ctx.f26.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// fmadds f0,f9,f6,f29
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f6.f64 + ctx.f29.f64));
	// stfs f0,0(r17)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r17.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f0,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f13,f0,f30,f25
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f30.f64 - ctx.f25.f64));
	// stfs f13,0(r14)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fmadds f0,f0,f8,f7
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f8.f64 + ctx.f7.f64));
	// stfs f0,0(r15)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r15.u32 + 0, temp.u32);
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d28680
	if (!ctx.cr0.eq) goto loc_82D28680;
loc_82D29F84:
	// addi r1,r1,784
	ctx.r1.s64 = ctx.r1.s64 + 784;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D29F90;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D29F98"))) PPC_WEAK_FUNC(sub_82D29F98);
PPC_FUNC_IMPL(__imp__sub_82D29F98) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-7328
	ctx.r5.s64 = ctx.r11.s64 + -7328;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-31216
	ctx.r4.s64 = ctx.r11.s64 + -31216;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D29FB0"))) PPC_WEAK_FUNC(sub_82D29FB0);
PPC_FUNC_IMPL(__imp__sub_82D29FB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e4c
	ctx.lr = 0x82D29FB8;
	__savegprlr_21(ctx, base);
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28ee0
	ctx.lr = 0x82D29FC0;
	__savefpr_14(ctx, base);
	// rlwinm r11,r9,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// addi r11,r11,-32
	ctx.r11.s64 = ctx.r11.s64 + -32;
	// bge cr6,0x82d2a9fc
	if (!ctx.cr6.lt) goto loc_82D2A9FC;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r22,r9,r10
	ctx.r22.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// rlwinm r27,r7,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32236
	ctx.r7.s64 = -2112618496;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lfs f9,-8016(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,136(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 136);
	ctx.f8.f64 = double(temp.f32);
	// lfs f10,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
loc_82D29FFC:
	// lfs f0,20(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r9,r8,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// mulli r7,r8,12
	ctx.r7.s64 = ctx.r8.s64 * 12;
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f22,f13,f12
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// fmuls f26,f0,f11
	ctx.f26.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f5,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f14,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f3,f5,f12
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// stfs f14,-392(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fmuls f2,f5,f11
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// lfs f7,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f20,f13,f11
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f6,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f31,f7,f12
	ctx.f31.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// fmuls f28,f6,f11
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f4,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f27,f6,f12
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// mulli r10,r8,28
	ctx.r10.s64 = ctx.r8.s64 * 28;
	// fmuls f1,f7,f11
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// lfs f29,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f21,f13,f6
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// lfs f30,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f25,f0,f7
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fsubs f14,f22,f26
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// stfs f14,-276(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfsx f14,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f24,f0,f12
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// stfs f14,-396(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fmuls f19,f13,f7
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fmuls f23,f0,f6
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// lfsx f15,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f18,f4,f11,f3
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 + ctx.f3.f64));
	// lfsx f16,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f17,f4,f12,f2
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 - ctx.f2.f64));
	// fadds f3,f28,f31
	ctx.f3.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// fsubs f2,f27,f1
	ctx.f2.f64 = double(float(ctx.f27.f64 - ctx.f1.f64));
	// fsubs f31,f31,f28
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// lfsx f28,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f14,f21,f25
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// stfs f14,-244(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// fadds f1,f27,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// lfsx f27,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f14,f24,f20
	ctx.f14.f64 = double(float(ctx.f24.f64 - ctx.f20.f64));
	// stfs f14,-328(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fsubs f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// fadds f14,f19,f23
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// fsubs f21,f29,f15
	ctx.f21.f64 = double(float(ctx.f29.f64 - ctx.f15.f64));
	// fsubs f23,f19,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 - ctx.f23.f64));
	// fadds f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// fadds f29,f15,f29
	ctx.f29.f64 = double(float(ctx.f15.f64 + ctx.f29.f64));
	// fadds f15,f27,f28
	ctx.f15.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fmuls f19,f13,f2
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f20,f0,f3
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// stfs f28,-408(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// fadds f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// fadds f22,f16,f30
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f30.f64));
	// fsubs f30,f30,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f16.f64));
	// fmuls f16,f13,f1
	ctx.f16.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// lfs f27,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f27.f64 = double(temp.f32);
	// lfs f28,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f27,f27,f28
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// stfs f27,-396(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f27,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f27.f64 = double(temp.f32);
	// fadds f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// stfs f28,-392(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fadds f28,f19,f20
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfs f28,-260(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// fmuls f28,f0,f31
	ctx.f28.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fmuls f27,f0,f1
	ctx.f27.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// fadds f19,f16,f28
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f28.f64));
	// fsubs f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f16.f64));
	// stfs f28,-268(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fmuls f28,f13,f31
	ctx.f28.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fsubs f16,f28,f27
	ctx.f16.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// stfs f16,-324(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// stfs f28,-252(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fmuls f27,f0,f2
	ctx.f27.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// fmuls f28,f13,f3
	ctx.f28.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// mulli r31,r8,20
	ctx.r31.s64 = ctx.r8.s64 * 20;
	// rlwinm r29,r8,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r30,r8,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r28,r8,24
	ctx.r28.s64 = ctx.r8.s64 * 24;
	// fsubs f16,f28,f27
	ctx.f16.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fadds f27,f15,f22
	ctx.f27.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f27,-288(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f27,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f27,-376(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f27,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f29,f27
	ctx.f27.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// stfs f27,-356(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fsubs f27,f22,f15
	ctx.f27.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f27,-312(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f27,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f27.f64 = double(temp.f32);
	// add r26,r29,r3
	ctx.r26.u64 = ctx.r29.u64 + ctx.r3.u64;
	// fsubs f22,f21,f27
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f27.f64));
	// stfs f22,-300(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f22,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f22.f64 = double(temp.f32);
	// add r25,r29,r5
	ctx.r25.u64 = ctx.r29.u64 + ctx.r5.u64;
	// fsubs f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// stfs f30,-272(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f30,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f30.f64 = double(temp.f32);
	// add r24,r28,r3
	ctx.r24.u64 = ctx.r28.u64 + ctx.r3.u64;
	// lfsx f15,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f29.f64));
	// stfs f15,-408(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// add r23,r28,r5
	ctx.r23.u64 = ctx.r28.u64 + ctx.r5.u64;
	// lfsx f15,r29,r6
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-340(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfsx f15,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-392(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfsx f15,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-336(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfsx f15,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-388(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfsx f15,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f30,-264(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fadds f30,f27,f21
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f21.f64));
	// stfs f15,-412(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfsx f15,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f30,-284(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// stfs f15,-400(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfsx f29,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfs f30,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f15,r28,r6
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-344(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fsubs f15,f30,f29
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// lfsx f22,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// lfsx f27,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f29,f22,f27
	ctx.f29.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// lfsx f21,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f27,f27,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f22.f64));
	// lfs f22,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-396(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfs f22,-384(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f22,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f22,-332(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f22,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f21,-404(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f21,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfs f22,-348(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f22,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f21,-396(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f21,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfs f22,-392(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f22,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f21,-408(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f21,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,-388(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f22,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f22,f21
	ctx.f21.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfs f21,-380(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f21,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f22,-416(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f22,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f21,-412(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f21,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f21,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f21.f64 = double(temp.f32);
	// stfs f22,-400(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fadds f21,f21,f30
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// fadds f22,f29,f15
	ctx.f22.f64 = double(float(ctx.f29.f64 + ctx.f15.f64));
	// stfs f21,-316(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fsubs f29,f15,f29
	ctx.f29.f64 = double(float(ctx.f15.f64 - ctx.f29.f64));
	// lfs f21,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f21
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// stfs f15,-396(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f15,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// stfs f21,-368(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f21,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// stfs f21,-408(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f21,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f27
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f27.f64));
	// stfs f21,-308(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f15,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f15.f64 = double(temp.f32);
	// lfs f21,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// lfs f15,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f15.f64 = double(temp.f32);
	// fadds f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 + ctx.f27.f64));
	// stfs f27,-336(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f27,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfs f30,-296(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f27,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f27.f64 = double(temp.f32);
	// lfs f30,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// stfs f30,-340(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f27,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f27.f64 = double(temp.f32);
	// lfs f30,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f30,-344(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f30,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f27,f22,f30
	ctx.f27.f64 = double(float(ctx.f22.f64 - ctx.f30.f64));
	// fadds f22,f30,f22
	ctx.f22.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// lfs f30,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f30.f64 = double(temp.f32);
	// fadds f15,f30,f29
	ctx.f15.f64 = double(float(ctx.f30.f64 + ctx.f29.f64));
	// fsubs f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f30.f64));
	// lfs f29,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f29,f21
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f21.f64));
	// stfs f29,-304(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fmuls f29,f27,f10
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// stfs f29,-248(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fmuls f29,f22,f10
	ctx.f29.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// stfs f29,-388(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fmuls f29,f15,f10
	ctx.f29.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// stfs f29,-256(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// lfs f27,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f30,f30,f10
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// lfs f29,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f27.f64));
	// stfs f29,-352(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f27,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f27.f64 = double(temp.f32);
	// lfs f29,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f29.f64 = double(temp.f32);
	// stfs f30,-392(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// lfs f30,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// lfs f22,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f15,-404(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f15,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,-396(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f22,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f27,f22,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 - ctx.f27.f64));
	// lfs f15,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,-364(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f22,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f22,-292(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfsx f22,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-368(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfsx f22,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-416(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfsx f22,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-380(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fmuls f15,f27,f9
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// lfsx f22,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f27,f27,f8
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// stfs f22,-412(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfsx f22,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f21,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,-384(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fmuls f21,f29,f8
	ctx.f21.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// stfs f22,-400(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f22,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f8
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// fmadds f29,f29,f9,f22
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 + ctx.f22.f64));
	// stfs f29,-332(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f29,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f29,f29,f9,f21
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 - ctx.f21.f64));
	// stfs f29,-348(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f29,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f22,f29,f8,f15
	ctx.f22.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 - ctx.f15.f64));
	// stfs f22,-372(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// fmadds f29,f29,f9,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 + ctx.f27.f64));
	// lfs f27,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f27.f64 = double(temp.f32);
	// stfs f29,-408(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// fadds f29,f27,f30
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// lfs f22,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f22.f64 = double(temp.f32);
	// lfs f27,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f27.f64 = double(temp.f32);
	// lfs f15,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f15.f64 = double(temp.f32);
	// fadds f27,f22,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// lfs f21,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f15,f21
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// fadds f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// stfs f21,-404(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f15,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f15.f64 = double(temp.f32);
	// lfs f21,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// stfs f21,-412(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f21,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// stfs f21,-416(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f15,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f15.f64 = double(temp.f32);
	// lfs f21,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// fadds f15,f27,f29
	ctx.f15.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfs f15,-396(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fsubs f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// lfs f15,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f15.f64 = double(temp.f32);
	// lfs f27,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f22.f64));
	// stfs f27,-368(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f27,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f15.f64));
	// stfs f27,-384(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fsubs f15,f30,f21
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// stfs f15,-400(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fadds f30,f21,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// stfs f30,-360(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f30,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f30.f64 = double(temp.f32);
	// lfs f21,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f21.f64 = double(temp.f32);
	// fadds f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// lfs f21,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,-416(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f21,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f27,f27,f8
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// lfs f22,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f22,-404(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f21,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f22,-412(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fmuls f22,f15,f8
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f8.f64));
	// fmuls f15,f30,f9
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// fmuls f30,f30,f8
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// lfs f21,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f29
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f29.f64));
	// stfs f21,-380(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f21,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f29
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f29.f64));
	// lfs f29,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f29,f29,f9,f22
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 - ctx.f22.f64));
	// stfs f29,-384(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f29,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f29,f29,f9,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 + ctx.f27.f64));
	// stfs f29,-320(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f29,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f29.f64 = double(temp.f32);
	// stfs f30,-360(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fmsubs f30,f29,f8,f15
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 - ctx.f15.f64));
	// lfs f22,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f22.f64 = double(temp.f32);
	// stfs f21,-280(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfs f27,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f29,f29,f9,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 + ctx.f27.f64));
	// lfs f27,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f15,f27,f22
	ctx.f15.f64 = double(float(ctx.f27.f64 - ctx.f22.f64));
	// stfs f15,-352(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fadds f27,f22,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// stfs f27,0(r3)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f22,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f22.f64 = double(temp.f32);
	// lfs f27,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f27.f64 = double(temp.f32);
	// fadds f15,f22,f27
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// stfs f15,0(r5)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f27,f27,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f22.f64));
	// stfs f27,-416(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f27,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f27.f64 = double(temp.f32);
	// lfs f22,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f27,f22
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f22.f64));
	// lfs f27,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f27.f64 = double(temp.f32);
	// fadds f21,f21,f27
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// lfs f15,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f15.f64 = double(temp.f32);
	// lfs f27,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// stfs f27,-364(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f27,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f30,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// stfs f27,-360(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f15,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f15.f64 = double(temp.f32);
	// lfs f27,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// stfs f27,-404(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f27,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f29
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// stfs f27,-400(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f15,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f22,f22,f10
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// lfs f27,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// lfs f15,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f15.f64 = double(temp.f32);
	// fadds f29,f29,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f15.f64));
	// stfs f29,-376(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f15,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f15.f64 = double(temp.f32);
	// lfs f29,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f29,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f15.f64));
	// lfs f15,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f30,f15,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 - ctx.f30.f64));
	// stfs f30,-372(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f30,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f30.f64 = double(temp.f32);
	// lfs f15,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f15.f64 = double(temp.f32);
	// stfs f22,-412(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fadds f30,f30,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f15.f64));
	// lfs f15,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,-388(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fmuls f22,f21,f10
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// stfs f22,-408(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f22,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f15,f21,f22
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f22.f64));
	// lfs f21,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f22.f64));
	// fmsubs f21,f21,f26,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f26.f64 - ctx.f15.f64));
	// stfsx f21,r9,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f26,f21,f26,f22
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f26.f64 + ctx.f22.f64));
	// lfs f22,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f26,r9,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f26,f22,f21
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f21,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f21
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// stfs f15,-356(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfs f15,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f15.f64 = double(temp.f32);
	// fadds f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// lfs f15,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f27,f15
	ctx.f15.f64 = double(float(ctx.f27.f64 - ctx.f15.f64));
	// stfs f15,-416(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f15,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f15.f64 = double(temp.f32);
	// fadds f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 + ctx.f27.f64));
	// lfs f15,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f29
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f29.f64));
	// stfs f15,-376(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f15,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f29,f29,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f15.f64));
	// stfs f22,-328(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// stfs f29,-372(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f29,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f15,f30,f29
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// stfs f21,-364(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fadds f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// stfs f30,-412(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// stfs f15,-400(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fmuls f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// fmuls f6,f22,f6
	ctx.f6.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// stfs f27,-352(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f30,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f15,f30,f29
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// stfs f15,-404(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// fadds f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// stfs f30,-388(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f30,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f29,f26,f30
	ctx.f29.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// lfs f15,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f30,f15,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 * ctx.f30.f64));
	// lfs f15,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// fmuls f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f20.f64));
	// lfs f15,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f4
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// fmsubs f30,f26,f16,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f16.f64 - ctx.f30.f64));
	// stfsx f30,r31,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f4,f27,f4
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fmadds f30,f30,f16,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f16.f64 + ctx.f29.f64));
	// stfsx f30,r31,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f30,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f30,f7,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f7.f64 - ctx.f21.f64));
	// stfsx f30,r30,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f7,f30,f7,f6
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f7.f64 + ctx.f6.f64));
	// stfsx f7,r30,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f7,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f7,f7,f28,f22
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64 - ctx.f22.f64));
	// stfsx f7,r7,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f7.f64 = double(temp.f32);
	// lfs f27,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f24.f64));
	// fmadds f7,f7,f28,f20
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64 + ctx.f20.f64));
	// stfsx f7,r7,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// lfs f7,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f7,f7,f5,f15
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f5.f64 - ctx.f15.f64));
	// stfsx f7,r10,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f7,f7,f5,f4
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f5.f64 + ctx.f4.f64));
	// stfsx f7,r10,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f20,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f20.f64 = double(temp.f32);
	// lfs f7,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f7,f7,f20,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f20.f64 - ctx.f27.f64));
	// stfsx f7,r31,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// lfs f7,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f22,f7,f6
	ctx.f22.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// lfs f7,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f15,f7,f6
	ctx.f15.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// lfs f6,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// lfs f5,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f6.f64 = double(temp.f32);
	// lfs f27,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// lfs f28,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f5,f28,f27
	ctx.f5.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// lfs f26,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f26.f64 = double(temp.f32);
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// lfs f30,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f30.f64 = double(temp.f32);
	// lfs f4,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f4.f64 = double(temp.f32);
	// lfs f29,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 - ctx.f4.f64));
	// lfs f27,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f29,f29,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// lfs f16,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f16.f64 = double(temp.f32);
	// fadds f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// lfs f21,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f26,f22,f10
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// fsubs f30,f21,f16
	ctx.f30.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// lfs f16,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f22,f15,f10
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// lfs f15,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,-320(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f16,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f20.f64));
	// lfs f16,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f2
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// lfs f15,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// lfs f15,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f24,f15,f24,f20
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f24.f64 + ctx.f20.f64));
	// stfsx f24,r31,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lfs f24,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f24,f24,f3,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 - ctx.f16.f64));
	// stfsx f24,r30,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f24,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f3,f24,f3,f2
	ctx.f3.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 + ctx.f2.f64));
	// stfsx f3,r30,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fsubs f3,f5,f4
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f4,f30,f29
	ctx.f4.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fadds f2,f29,f30
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fsubs f29,f7,f26
	ctx.f29.f64 = double(float(ctx.f7.f64 - ctx.f26.f64));
	// fsubs f24,f6,f22
	ctx.f24.f64 = double(float(ctx.f6.f64 - ctx.f22.f64));
	// fadds f6,f22,f6
	ctx.f6.f64 = double(float(ctx.f22.f64 + ctx.f6.f64));
	// fadds f7,f26,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 + ctx.f7.f64));
	// fsubs f30,f28,f27
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fmuls f22,f3,f19
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// fmuls f20,f24,f17
	ctx.f20.f64 = double(float(ctx.f24.f64 * ctx.f17.f64));
	// fmuls f16,f6,f14
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// lfs f26,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f27,f21,f26
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// fadds f26,f26,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// fmuls f21,f4,f19
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// fmuls f19,f29,f17
	ctx.f19.f64 = double(float(ctx.f29.f64 * ctx.f17.f64));
	// fmuls f17,f6,f25
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// lfs f6,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f29,f29,f18,f20
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f18.f64 - ctx.f20.f64));
	// stfsx f29,r10,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmuls f15,f2,f6
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f29,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// stfs f6,-324(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fmr f6,f29
	ctx.f6.f64 = ctx.f29.f64;
	// addic. r22,r22,-1
	ctx.xer.ca = ctx.r22.u32 > 0;
	ctx.r22.s64 = ctx.r22.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r22.s32, 0, ctx.xer);
	// fmadds f29,f24,f18,f19
	ctx.f29.f64 = double(float(ctx.f24.f64 * ctx.f18.f64 + ctx.f19.f64));
	// stfsx f29,r10,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// fmsubs f3,f3,f6,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f6.f64 - ctx.f21.f64));
	// fmadds f6,f4,f6,f22
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f6.f64 + ctx.f22.f64));
	// fmsubs f4,f7,f14,f17
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f14.f64 - ctx.f17.f64));
	// stfsx f4,r7,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fmadds f7,f7,f25,f16
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f25.f64 + ctx.f16.f64));
	// stfsx f7,r7,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// lfs f7,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f7.f64 = double(temp.f32);
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// stfsx f3,r28,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f5,f5,f7,f15
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 - ctx.f15.f64));
	// stfsx f6,r28,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// subf r5,r27,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r27.s64;
	// stfsx f5,r29,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f3.f64 = double(temp.f32);
	// lfs f22,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f2,f7,f22
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f7.f64 + ctx.f22.f64));
	// stfsx f7,r29,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// lfs f7,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f2,f26,f11
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// fsubs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// lfs f6,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// lfs f5,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfs f4,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fmuls f3,f27,f0
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f0,f30,f0
	ctx.f0.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f11,f28,f11
	ctx.f11.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// fmsubs f3,f30,f13,f3
	ctx.f3.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 - ctx.f3.f64));
	// stfsx f3,r9,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f0,f27,f13,f0
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 + ctx.f0.f64));
	// stfsx f0,r9,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fmsubs f0,f28,f12,f2
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 - ctx.f2.f64));
	// stfs f0,0(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmadds f0,f26,f12,f11
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f11.f64));
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fsubs f0,f7,f6
	ctx.f0.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// add r4,r27,r4
	ctx.r4.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fsubs f12,f5,f4
	ctx.f12.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// subf r6,r27,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r27.s64;
	// fadds f11,f4,f5
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fadds f13,f6,f7
	ctx.f13.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// lfs f7,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f0,f7
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fmuls f7,f12,f7
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// fmuls f5,f11,f1
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// fmuls f4,f13,f1
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// fmsubs f0,f0,f23,f7
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f23.f64 - ctx.f7.f64));
	// stfs f0,0(r24)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fmadds f0,f12,f23,f6
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f23.f64 + ctx.f6.f64));
	// stfs f0,0(r23)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// fmsubs f0,f13,f31,f5
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 - ctx.f5.f64));
	// stfs f0,0(r26)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fmadds f0,f11,f31,f4
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f31.f64 + ctx.f4.f64));
	// stfs f0,0(r25)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// lwz r10,3532(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d29ffc
	if (!ctx.cr0.eq) goto loc_82D29FFC;
loc_82D2A9FC:
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28f2c
	ctx.lr = 0x82D2AA04;
	__restfpr_14(ctx, base);
	// b 0x82e28e9c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2AA08"))) PPC_WEAK_FUNC(sub_82D2AA08);
PPC_FUNC_IMPL(__imp__sub_82D2AA08) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-7256
	ctx.r5.s64 = ctx.r11.s64 + -7256;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-24656
	ctx.r4.s64 = ctx.r11.s64 + -24656;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2AA20"))) PPC_WEAK_FUNC(sub_82D2AA20);
PPC_FUNC_IMPL(__imp__sub_82D2AA20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82D2AA28;
	__savegprlr_29(ctx, base);
	// addi r12,r1,-32
	ctx.r12.s64 = ctx.r1.s64 + -32;
	// bl 0x82e28ee0
	ctx.lr = 0x82D2AA30;
	__savefpr_14(ctx, base);
	// mulli r11,r9,24
	ctx.r11.s64 = ctx.r9.s64 * 24;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r7,r11,-24
	ctx.r7.s64 = ctx.r11.s64 + -24;
	// bge cr6,0x82d2acec
	if (!ctx.cr6.lt) goto loc_82D2ACEC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r30,r9,r10
	ctx.r30.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f6,140(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f6.f64 = double(temp.f32);
loc_82D2AA5C:
	// lfs f13,4(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,16(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f7,f12,f13
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f10,8(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f12,f0
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f9,12(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f1,f10,f13
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmuls f30,f9,f0
	ctx.f30.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f11,20(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f31,f9,f13
	ctx.f31.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// mulli r11,r8,12
	ctx.r11.s64 = ctx.r8.s64 * 12;
	// fmuls f2,f10,f0
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfsx f23,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfs f5,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f24,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f21,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f27,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f28,f11,f0,f7
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f7.f64));
	// lfsx f26,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f29,f11,f13,f8
	ctx.f29.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f8.f64));
	// lfs f4,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f22,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f18,f27,f5
	ctx.f18.f64 = double(float(ctx.f27.f64 + ctx.f5.f64));
	// fsubs f7,f30,f1
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f1.f64));
	// lfsx f19,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f1,f30,f1
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// lfsx f30,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f8,f31,f2
	ctx.f8.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// lfsx f20,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// lfsx f31,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f17,f30,f31
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// lfsx f25,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f31,f31,f30
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// lfs f3,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f30,f24,f23
	ctx.f30.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f5,f5,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f27.f64));
	// fsubs f27,f4,f26
	ctx.f27.f64 = double(float(ctx.f4.f64 - ctx.f26.f64));
	// fmuls f16,f12,f7
	ctx.f16.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// fadds f23,f21,f22
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fadds f4,f26,f4
	ctx.f4.f64 = double(float(ctx.f26.f64 + ctx.f4.f64));
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f26,f25,f3
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f3.f64));
	// fsubs f3,f3,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f25.f64));
	// fadds f25,f17,f18
	ctx.f25.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fmuls f15,f12,f8
	ctx.f15.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f14,f30,f27
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// stfs f14,-204(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -204, temp.u32);
	// fmsubs f21,f11,f8,f16
	ctx.f21.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 - ctx.f16.f64));
	// fsubs f16,f20,f19
	ctx.f16.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f19,f4,f31
	ctx.f19.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// fadds f4,f31,f4
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// fsubs f31,f27,f30
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f30.f64));
	// lfsx f30,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f14,f24,f5
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f5.f64));
	// fsubs f5,f5,f24
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f24.f64));
	// lfs f24,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f15,f11,f7,f15
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f7.f64 + ctx.f15.f64));
	// fsubs f27,f22,f20
	ctx.f27.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// fadds f20,f26,f23
	ctx.f20.f64 = double(float(ctx.f26.f64 + ctx.f23.f64));
	// fsubs f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// fadds f23,f24,f30
	ctx.f23.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// fsubs f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// fsubs f24,f25,f20
	ctx.f24.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// fadds f17,f26,f31
	ctx.f17.f64 = double(float(ctx.f26.f64 + ctx.f31.f64));
	// fsubs f31,f31,f26
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f26.f64));
	// fadds f26,f20,f25
	ctx.f26.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// stfs f26,0(r3)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f25,f23,f3
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// stfs f25,-192(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -192, temp.u32);
	// fsubs f26,f3,f23
	ctx.f26.f64 = double(float(ctx.f3.f64 - ctx.f23.f64));
	// fadds f3,f30,f16
	ctx.f3.f64 = double(float(ctx.f30.f64 + ctx.f16.f64));
	// fsubs f30,f30,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f16.f64));
	// stfs f30,-208(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -208, temp.u32);
	// fmuls f20,f17,f8
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f8.f64));
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// fmuls f23,f17,f7
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f7.f64));
	// addi r7,r7,24
	ctx.r7.s64 = ctx.r7.s64 + 24;
	// fmuls f17,f31,f28
	ctx.f17.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmuls f16,f31,f29
	ctx.f16.f64 = double(float(ctx.f31.f64 * ctx.f29.f64));
	// lfs f31,-204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -204);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f31,f31,f3
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f3.f64));
	// stfs f31,-200(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -200, temp.u32);
	// fsubs f30,f27,f26
	ctx.f30.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// lfs f31,-208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -208);
	ctx.f31.f64 = double(temp.f32);
	// fadds f31,f31,f18
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f18.f64));
	// stfs f31,-196(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -196, temp.u32);
	// lfs f31,-208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -208);
	ctx.f31.f64 = double(temp.f32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// fsubs f31,f18,f31
	ctx.f31.f64 = double(float(ctx.f18.f64 - ctx.f31.f64));
	// lfs f18,-204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -204);
	ctx.f18.f64 = double(temp.f32);
	// fadds f3,f3,f18
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f18.f64));
	// stfs f3,0(r5)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f26,f26,f27
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fmuls f3,f30,f6
	ctx.f3.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// fmuls f30,f25,f6
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// lfs f27,-200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -200);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f27,f2
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// fmuls f25,f27,f1
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// fadds f27,f3,f19
	ctx.f27.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// stfs f27,-200(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -200, temp.u32);
	// fsubs f27,f14,f30
	ctx.f27.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// fsubs f3,f19,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 - ctx.f3.f64));
	// fadds f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// fmsubs f2,f24,f2,f25
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f2.f64 - ctx.f25.f64));
	// stfsx f2,r10,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f2,f24,f1,f18
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f1.f64 + ctx.f18.f64));
	// stfsx f2,r10,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f2,-196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -196);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f8,f2,f8,f23
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f8.f64 - ctx.f23.f64));
	// stfsx f8,r9,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmadds f8,f2,f7,f20
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f7.f64 + ctx.f20.f64));
	// stfsx f8,r9,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fmsubs f8,f31,f29,f17
	ctx.f8.f64 = double(float(ctx.f31.f64 * ctx.f29.f64 - ctx.f17.f64));
	// stfsx f8,r11,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fmadds f8,f31,f28,f16
	ctx.f8.f64 = double(float(ctx.f31.f64 * ctx.f28.f64 + ctx.f16.f64));
	// stfsx f8,r11,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fmuls f2,f3,f11
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fmuls f11,f30,f11
	ctx.f11.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// subf r5,r31,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r31.s64;
	// lfs f8,-200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -200);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f8,f9
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// fmuls f9,f27,f9
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// fmsubs f7,f27,f10,f7
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f7.f64));
	// stfsx f7,r9,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f10,f8,f10,f9
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f10.f64 + ctx.f9.f64));
	// stfsx f10,r9,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fmsubs f10,f30,f12,f2
	ctx.f10.f64 = double(float(ctx.f30.f64 * ctx.f12.f64 - ctx.f2.f64));
	// stfsx f10,r11,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f3,f12,f11
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f11.f64));
	// stfsx f12,r11,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f12,-192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -192);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f11,f22,f12
	ctx.f11.f64 = double(float(ctx.f22.f64 - ctx.f12.f64));
	// fmuls f12,f26,f6
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// fmuls f11,f11,f6
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// fsubs f10,f5,f12
	ctx.f10.f64 = double(float(ctx.f5.f64 - ctx.f12.f64));
	// fadds f12,f12,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f5.f64));
	// fsubs f9,f4,f11
	ctx.f9.f64 = double(float(ctx.f4.f64 - ctx.f11.f64));
	// fadds f11,f11,f4
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f4.f64));
	// fmuls f7,f12,f13
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fmuls f8,f10,f21
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f21.f64));
	// fmuls f5,f9,f21
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f21.f64));
	// fmuls f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmsubs f10,f10,f15,f5
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f15.f64 - ctx.f5.f64));
	// stfsx f10,r10,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f10,f9,f15,f8
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f15.f64 + ctx.f8.f64));
	// stfsx f10,r10,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fmsubs f13,f12,f0,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64));
	// stfs f13,0(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmadds f0,f11,f0,f7
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 + ctx.f7.f64));
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lwz r11,3532(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3532);
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// subf r6,r31,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r31.s64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bne 0x82d2aa5c
	if (!ctx.cr0.eq) goto loc_82D2AA5C;
loc_82D2ACEC:
	// addi r12,r1,-32
	ctx.r12.s64 = ctx.r1.s64 + -32;
	// bl 0x82e28f2c
	ctx.lr = 0x82D2ACF4;
	__restfpr_14(ctx, base);
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2ACF8"))) PPC_WEAK_FUNC(sub_82D2ACF8);
PPC_FUNC_IMPL(__imp__sub_82D2ACF8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-7192
	ctx.r5.s64 = ctx.r11.s64 + -7192;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-21984
	ctx.r4.s64 = ctx.r11.s64 + -21984;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2AD10"))) PPC_WEAK_FUNC(sub_82D2AD10);
PPC_FUNC_IMPL(__imp__sub_82D2AD10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D2AD18;
	__savegprlr_28(ctx, base);
	// addi r12,r1,-40
	ctx.r12.s64 = ctx.r1.s64 + -40;
	// bl 0x82e28f18
	ctx.lr = 0x82D2AD20;
	__savefpr_28(ctx, base);
	// rlwinm r11,r9,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// addi r11,r11,-16
	ctx.r11.s64 = ctx.r11.s64 + -16;
	// bge cr6,0x82d2ae4c
	if (!ctx.cr6.lt) goto loc_82D2AE4C;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r9,r9,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D2AD44:
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f10,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// add r31,r10,r5
	ctx.r31.u64 = ctx.r10.u64 + ctx.r5.u64;
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// add r30,r10,r6
	ctx.r30.u64 = ctx.r10.u64 + ctx.r6.u64;
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// add r29,r10,r3
	ctx.r29.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lfs f7,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f5,f12,f13
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f4,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f6,f12,f0
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f3,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fadds f31,f4,f10
	ctx.f31.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// lfs f2,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f30,f9,f3
	ctx.f30.f64 = double(float(ctx.f9.f64 - ctx.f3.f64));
	// lfs f1,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fadds f29,f8,f2
	ctx.f29.f64 = double(float(ctx.f8.f64 + ctx.f2.f64));
	// fsubs f28,f1,f7
	ctx.f28.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// lfs f11,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f8,f2,f8
	ctx.f8.f64 = double(float(ctx.f2.f64 - ctx.f8.f64));
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// fadds f9,f3,f9
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f9.f64));
	// fsubs f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// fadds f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// fmsubs f5,f11,f0,f5
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f5.f64));
	// fmadds f6,f11,f13,f6
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f6.f64));
	// fadds f2,f29,f31
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// stfs f2,0(r3)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f3,f30,f28
	ctx.f3.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// add r3,r7,r3
	ctx.r3.u64 = ctx.r7.u64 + ctx.r3.u64;
	// fadds f2,f28,f30
	ctx.f2.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f2,0(r5)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f2,f8,f9
	ctx.f2.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// subf r5,r7,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r7.s64;
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fsubs f1,f10,f7
	ctx.f1.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// fsubs f4,f31,f29
	ctx.f4.f64 = double(float(ctx.f31.f64 - ctx.f29.f64));
	// fadds f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fmuls f8,f3,f5
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// fmuls f7,f3,f6
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// fmuls f3,f2,f13
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f31,f9,f11
	ctx.f31.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// fmuls f9,f9,f12
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// fmsubs f8,f4,f6,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f6.f64 - ctx.f8.f64));
	// stfs f8,0(r29)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fmadds f8,f4,f5,f7
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f5.f64 + ctx.f7.f64));
	// stfs f8,0(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fmsubs f0,f1,f0,f3
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 - ctx.f3.f64));
	// stfs f0,0(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmadds f0,f1,f13,f2
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 + ctx.f2.f64));
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fmsubs f0,f10,f12,f31
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 - ctx.f31.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// fmadds f0,f10,f11,f9
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 + ctx.f9.f64));
	// stfs f0,0(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// lwz r10,3532(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3532);
	// add r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 + ctx.r4.u64;
	// subf r6,r7,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r7.s64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d2ad44
	if (!ctx.cr0.eq) goto loc_82D2AD44;
loc_82D2AE4C:
	// addi r12,r1,-40
	ctx.r12.s64 = ctx.r1.s64 + -40;
	// bl 0x82e28f64
	ctx.lr = 0x82D2AE54;
	__restfpr_28(ctx, base);
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2AE58"))) PPC_WEAK_FUNC(sub_82D2AE58);
PPC_FUNC_IMPL(__imp__sub_82D2AE58) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-7128
	ctx.r5.s64 = ctx.r11.s64 + -7128;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-21232
	ctx.r4.s64 = ctx.r11.s64 + -21232;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2AE70"))) PPC_WEAK_FUNC(sub_82D2AE70);
PPC_FUNC_IMPL(__imp__sub_82D2AE70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D2AE78;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D2AE80;
	__savefpr_14(ctx, base);
	// mulli r11,r9,248
	ctx.r11.s64 = ctx.r9.s64 * 248;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-248
	ctx.r11.s64 = ctx.r11.s64 + -248;
	// bge cr6,0x82d2c264
	if (!ctx.cr6.lt) goto loc_82D2C264;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r14,r9,r10
	ctx.r14.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r19,r7,2,0,29
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lfs f8,-8000(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8000);
	ctx.f8.f64 = double(temp.f32);
	// lis r9,-32236
	ctx.r9.s64 = -2112618496;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f9,-8004(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -8004);
	ctx.f9.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f10,-8008(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8008);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,-8012(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8012);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-8016(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -8016);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,136(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
	// stw r27,-312(r1)
	PPC_STORE_U32(ctx.r1.u32 + -312, ctx.r27.u32);
loc_82D2AEE0:
	// rlwinm r10,r8,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f7,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// mulli r9,r8,44
	ctx.r9.s64 = ctx.r8.s64 * 44;
	// lfs f6,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f22,f5,f4
	ctx.f22.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfsx f2,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f2.f64 = double(temp.f32);
	// mulli r7,r8,12
	ctx.r7.s64 = ctx.r8.s64 * 12;
	// lfsx f3,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fadds f4,f2,f3
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// lfsx f1,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f31.f64 = double(temp.f32);
	// mulli r31,r8,48
	ctx.r31.s64 = ctx.r8.s64 * 48;
	// lfsx f30,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f29,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f2,f1,f30
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// mulli r30,r8,60
	ctx.r30.s64 = ctx.r8.s64 * 60;
	// fadds f21,f31,f29
	ctx.f21.f64 = double(float(ctx.f31.f64 + ctx.f29.f64));
	// fadds f1,f30,f1
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fsubs f31,f29,f31
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f31.f64));
	// lfsx f28,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f27,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f30,f28,f7
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f7.f64));
	// rlwinm r29,r8,5,0,26
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fsubs f29,f6,f27
	ctx.f29.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// mulli r28,r8,28
	ctx.r28.s64 = ctx.r8.s64 * 28;
	// fadds f6,f27,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 + ctx.f6.f64));
	// fsubs f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f28.f64));
	// lfsx f26,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f25,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f24,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f27,f26,f25
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfsx f23,r28,r6
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f28,f25,f26
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f26,f24,f23
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// mulli r21,r8,20
	ctx.r21.s64 = ctx.r8.s64 * 20;
	// fadds f25,f23,f24
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fadds f24,f4,f22
	ctx.f24.f64 = double(float(ctx.f4.f64 + ctx.f22.f64));
	// fadds f23,f21,f2
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f2.f64));
	// fsubs f4,f22,f4
	ctx.f4.f64 = double(float(ctx.f22.f64 - ctx.f4.f64));
	// fsubs f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f21.f64));
	// fadds f22,f1,f5
	ctx.f22.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fsubs f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// mulli r20,r8,36
	ctx.r20.s64 = ctx.r8.s64 * 36;
	// fsubs f20,f6,f27
	ctx.f20.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// fadds f6,f27,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 + ctx.f6.f64));
	// fsubs f19,f29,f26
	ctx.f19.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// fadds f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fsubs f26,f7,f25
	ctx.f26.f64 = double(float(ctx.f7.f64 - ctx.f25.f64));
	// fadds f7,f25,f7
	ctx.f7.f64 = double(float(ctx.f25.f64 + ctx.f7.f64));
	// fsubs f27,f24,f23
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f25,f23,f24
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// rlwinm r27,r8,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f24,f2,f4
	ctx.f24.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// mulli r26,r8,52
	ctx.r26.s64 = ctx.r8.s64 * 52;
	// fsubs f23,f4,f2
	ctx.f23.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fadds f1,f31,f3
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// fadds f21,f28,f30
	ctx.f21.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fsubs f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 - ctx.f3.f64));
	// fmuls f4,f27,f0
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// mulli r25,r8,40
	ctx.r25.s64 = ctx.r8.s64 * 40;
	// fmuls f2,f25,f0
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmuls f27,f24,f0
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f25,f23,f0
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fadds f24,f22,f21
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// fsubs f23,f21,f22
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// fsubs f22,f19,f5
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f5.f64));
	// fsubs f21,f29,f1
	ctx.f21.f64 = double(float(ctx.f29.f64 - ctx.f1.f64));
	// rlwinm r24,r8,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f31,f30,f3
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f3.f64));
	// mulli r23,r8,56
	ctx.r23.s64 = ctx.r8.s64 * 56;
	// fadds f5,f5,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f19.f64));
	// fadds f1,f1,f29
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f29.f64));
	// fadds f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f30.f64));
	// mulli r22,r8,24
	ctx.r22.s64 = ctx.r8.s64 * 24;
	// add r18,r21,r6
	ctx.r18.u64 = ctx.r21.u64 + ctx.r6.u64;
	// add r17,r20,r6
	ctx.r17.u64 = ctx.r20.u64 + ctx.r6.u64;
	// lfsx f14,r24,r5
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-400(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfsx f14,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfsx f14,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-388(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfsx f14,r24,r6
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-360(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfsx f14,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-396(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfsx f14,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-460(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfsx f14,r20,r5
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-448(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfsx f30,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f29,r26,r5
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r5.u32);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f14,f30,f29
	ctx.f14.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// lfsx f19,r26,r6
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f28,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f29,f29,f30
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// lfs f15,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// fadds f30,f19,f28
	ctx.f30.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// lfsx f17,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// stfs f30,-484(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fadds f30,f15,f17
	ctx.f30.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f30,-496(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfsx f16,r21,r5
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f18,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f19,f18,f16
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// lfs f30,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f30.f64 = double(temp.f32);
	// lfs f16,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f30,f16
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f16.f64));
	// stfs f15,-452(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fadds f30,f16,f30
	ctx.f30.f64 = double(float(ctx.f16.f64 + ctx.f30.f64));
	// stfs f30,-492(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f30,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f30.f64 = double(temp.f32);
	// lfs f16,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f16,f30
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f30.f64));
	// stfs f15,-476(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fsubs f30,f30,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f16.f64));
	// stfs f30,-384(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f16,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f15.f64 = double(temp.f32);
	// lfs f30,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f16,f30
	ctx.f30.f64 = double(float(ctx.f16.f64 - ctx.f30.f64));
	// stfs f30,-444(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f30,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fadds f15,f30,f15
	ctx.f15.f64 = double(float(ctx.f30.f64 + ctx.f15.f64));
	// stfs f15,-468(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f15,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,-500(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f16,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f30,f16,f30
	ctx.f30.f64 = double(float(ctx.f16.f64 - ctx.f30.f64));
	// stfs f30,-448(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f16,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,-400(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f30,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f19.f64));
	// lfs f15,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,-512(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f15,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,-508(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f15,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,-460(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fmuls f16,f30,f12
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// fmuls f15,f30,f13
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// lfs f30,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f16,f30,f13,f16
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f16,-316(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fmadds f30,f30,f12,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f12.f64 + ctx.f15.f64));
	// stfs f30,-400(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// add r16,r20,r4
	ctx.r16.u64 = ctx.r20.u64 + ctx.r4.u64;
	// lfs f30,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f30.f64 = double(temp.f32);
	// add r15,r21,r4
	ctx.r15.u64 = ctx.r21.u64 + ctx.r4.u64;
	// fmuls f16,f30,f12
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// lfs f15,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f15.f64 = double(temp.f32);
	// fadds f30,f18,f29
	ctx.f30.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// fsubs f29,f29,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// stfs f29,-364(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fsubs f29,f28,f17
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f17.f64));
	// fadds f15,f15,f30
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f30.f64));
	// stfs f15,-432(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f15,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f30,f30,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// lfs f15,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f16,f15,f13,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f16,-360(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f15,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,-476(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f15,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,-468(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f15,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,-496(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fadds f14,f17,f28
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// stfs f14,-388(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f14.f64 = double(temp.f32);
	// stfs f29,-500(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f29,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f29,f13
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// lfs f28,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f28.f64 = double(temp.f32);
	// stfs f15,-484(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f15,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-396(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fmuls f14,f19,f13
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmadds f29,f28,f12,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f29.f64));
	// stfs f29,-384(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfsx f29,r27,r5
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r5.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f16,f13
	ctx.f28.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// stfs f29,-424(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfsx f29,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-392(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfsx f29,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-404(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfsx f29,r27,r6
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r6.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-464(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f29,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f17,f29,f13
	ctx.f17.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// lfsx f29,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-488(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfsx f29,r23,r5
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r5.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-508(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f29,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f15,f29,f13
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// lfsx f29,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-512(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfsx f29,r23,r6
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r6.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-472(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfsx f29,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-440(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f29,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f29.f64 = double(temp.f32);
	// lfs f18,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f29
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f29.f64));
	// stfs f18,-428(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfsx f18,r22,r5
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r5.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,-492(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f18,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f18.f64 = double(temp.f32);
	// fadds f29,f29,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f18.f64));
	// stfs f29,-456(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// fmadds f17,f16,f12,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f17.f64));
	// stfs f17,-388(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fmadds f19,f19,f12,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 + ctx.f15.f64));
	// lfs f17,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f17.f64 = double(temp.f32);
	// stfs f19,-364(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f19,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// lfs f16,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f16.f64 = double(temp.f32);
	// stfs f19,-336(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f19,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f19.f64 = double(temp.f32);
	// stfs f16,-332(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fmsubs f19,f19,f12,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 - ctx.f14.f64));
	// lfs f16,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f16.f64 = double(temp.f32);
	// lfs f29,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f29.f64 = double(temp.f32);
	// lfs f17,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f17.f64 = double(temp.f32);
	// stfs f19,-396(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fsubs f19,f17,f16
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f14,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f18,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f18,f29
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f29.f64));
	// fadds f16,f14,f15
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f18,-328(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-444(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfsx f18,r22,r6
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r6.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,-496(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,-452(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f18,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f14.f64 = double(temp.f32);
	// fadds f29,f29,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f18.f64));
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfsx f18,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,-484(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// stfs f15,-500(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f15,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,-424(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f14,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-468(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f15,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f18,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f18.f64 = double(temp.f32);
	// stfs f14,-476(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fmsubs f28,f18,f12,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 - ctx.f28.f64));
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-512(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f15,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f18,r25,r5
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r5.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f14,-508(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfs f14,-392(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fadds f14,f16,f19
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// fsubs f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// lfsx f16,r25,r6
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-492(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f16,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,-496(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f16,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,-464(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f18,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,-448(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f18,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// stfs f18,-420(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f18,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f18
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f16,-460(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f16,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f16,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,-416(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f15,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,-376(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f15,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,-452(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f16,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,-508(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfsx f15,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-484(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfsx f15,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-500(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f15,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfsx f15,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-492(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f15,-512(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfsx f15,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-468(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f17,-424(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfsx f17,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-472(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfsx f17,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-436(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfsx f17,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-348(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfsx f17,r29,r5
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-476(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfsx f17,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-356(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfsx f17,r29,r6
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-372(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfsx f17,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-488(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f17,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f15,-344(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f15,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f16,f15
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f15,-408(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f15,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,-380(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f15,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,-368(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f16,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,-508(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f16,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,-504(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,-404(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f16,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f18,f16
	ctx.f15.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f15,-412(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f18,-392(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f16,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// fadds f15,f16,f18
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f15,-440(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,-480(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f16,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f15,f16,f18
	ctx.f15.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f15,-496(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,-436(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f16,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f18.f64 = double(temp.f32);
	// fadds f15,f16,f18
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f15,-472(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,-444(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f16,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f15,f18,f16
	ctx.f15.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f15,-512(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fsubs f15,f17,f19
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// lfs f17,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f17.f64 = double(temp.f32);
	// stfs f19,-408(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f18,-476(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fmr f19,f17
	ctx.f19.f64 = ctx.f17.f64;
	// lfs f16,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,-500(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f18,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,-372(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f18,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f15,f0
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fadds f16,f18,f14
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// fsubs f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// lfs f18,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f19
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f18,-464(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f18,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f19,-484(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f19,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f19
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f18,-356(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfs f18,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f19,-460(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f19,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f14,f0
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fadds f18,f18,f19
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f18,-492(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f18,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f14,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f18,f16,f0
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fsubs f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfs f14,-320(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,-324(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// lfs f14,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// lfs f14,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,-340(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f14,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,-424(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f16,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f16,f15
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f14,-352(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f14,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-416(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-420(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f15,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f15,f24
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f24.f64));
	// stfs f14,-508(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fsubs f24,f24,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f15.f64));
	// stfs f24,-408(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// lfs f24,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// stfs f24,-468(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f14,f1
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f1.f64));
	// lfs f24,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// stfs f14,-380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// stfs f24,-452(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f24,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f24.f64 = double(temp.f32);
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// lfs f14,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-376(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f14,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-368(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f14,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-436(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f15,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f14,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f1,f1,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f15.f64));
	// stfs f14,-456(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// stfs f16,-448(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfsx f16,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f16,f15
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f14.f64 = double(temp.f32);
	// stfs f1,-512(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfsx f1,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fadds f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f14,-472(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f1,f14
	ctx.f14.f64 = double(float(ctx.f1.f64 - ctx.f14.f64));
	// stfs f14,-488(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fadds f1,f14,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 + ctx.f1.f64));
	// lfs f14,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-480(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f14,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-456(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f14,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-440(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fadds f15,f1,f16
	ctx.f15.f64 = double(float(ctx.f1.f64 + ctx.f16.f64));
	// fsubs f1,f16,f1
	ctx.f1.f64 = double(float(ctx.f16.f64 - ctx.f1.f64));
	// lfs f16,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,-432(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f14,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,-416(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f16,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f24,f16
	ctx.f14.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// stfs f14,-496(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fadds f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// stfs f24,-500(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f24,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f24.f64 = double(temp.f32);
	// lfs f16,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f24
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// stfs f16,-488(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f14,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,-472(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fsubs f14,f1,f19
	ctx.f14.f64 = double(float(ctx.f1.f64 - ctx.f19.f64));
	// lfs f16,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f16.f64 = double(temp.f32);
	// fadds f1,f1,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f19.f64));
	// stfs f1,-504(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f19,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f19.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// lfs f19,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// stfs f24,-480(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f19,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f19.f64 = double(temp.f32);
	// lfs f24,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// stfs f24,-440(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f24,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f19,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f19.f64 = double(temp.f32);
	// fmr f1,f19
	ctx.f1.f64 = ctx.f19.f64;
	// fmuls f19,f14,f0
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f24,f1
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f1.f64));
	// stfs f24,-372(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f24,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f24.f64 = double(temp.f32);
	// fadds f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f24.f64));
	// fmuls f24,f16,f0
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f16,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f16.f64 = double(temp.f32);
	// stfs f15,-504(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f15,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,0(r3)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-432(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-344(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-488(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f15,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,-436(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f14,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f24
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// stfs f14,-476(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f14,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f19,f14
	ctx.f14.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfs f14,-444(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f14,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f19,-492(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f19,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f19.f64 = double(temp.f32);
	// fadds f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f19.f64));
	// stfs f24,-508(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f24,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f19,f24,f16
	ctx.f19.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// fadds f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// stfs f24,-348(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// stfs f19,-484(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f19,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f19.f64 = double(temp.f32);
	// lfs f24,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f16,f24,f19
	ctx.f16.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// stfs f16,-512(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fadds f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// lfs f16,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f19.f64 = double(temp.f32);
	// stfs f24,-420(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// fadds f24,f16,f19
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// fsubs f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// stfs f19,-456(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f16,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f16,f14
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f14,-472(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,-368(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// stfs f24,0(r5)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lfs f19,124(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 124);
	ctx.f19.f64 = double(temp.f32);
	// lfs f24,120(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 120);
	ctx.f24.f64 = double(temp.f32);
	// lfs f16,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f19,f16
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfs f16,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// fmsubs f16,f24,f16,f14
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f16.f64 - ctx.f14.f64));
	// stfsx f16,r29,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f16,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f24,f24,f16,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f16.f64 + ctx.f19.f64));
	// lfs f14,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,-480(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f14,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,-504(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f14,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,-376(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f14,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,-432(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// stfsx f24,r29,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// lfs f19,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f19.f64 = double(temp.f32);
	// lfs f16,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f16,f19,f16
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// fmuls f14,f19,f14
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f14.f64));
	// lfs f19,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f23
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// stfs f19,-408(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// fadds f19,f30,f21
	ctx.f19.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// lfs f24,184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f30,f21,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 - ctx.f30.f64));
	// lfs f21,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfs f23,-464(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f23,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f24,f23,f16
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f23.f64 - ctx.f16.f64));
	// stfsx f23,r31,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// lfs f23,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f24,f24,f23,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f23.f64 + ctx.f14.f64));
	// stfsx f24,r31,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lfs f24,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f24.f64 = double(temp.f32);
	// stfs f24,-380(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f24,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f23.f64 = double(temp.f32);
	// fadds f21,f23,f24
	ctx.f21.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f16,f23,f24
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// lfs f24,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f23.f64 = double(temp.f32);
	// fadds f14,f23,f24
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f23,f24,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fmuls f24,f21,f0
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fmuls f21,f16,f0
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f21,-404(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// fmuls f21,f14,f0
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f21,-428(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f23,-488(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f23,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f23.f64 = double(temp.f32);
	// lfs f21,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f23,f15
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f15.f64));
	// fmuls f14,f23,f21
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f21.f64));
	// lfs f23,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f21,f23,f21,f16
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f21.f64 - ctx.f16.f64));
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f23,f23,f15,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f19,f24
	ctx.f16.f64 = double(float(ctx.f19.f64 - ctx.f24.f64));
	// stfsx f23,r10,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f19.f64));
	// lfs f19,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f23.f64 = double(temp.f32);
	// lfs f15,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-432(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f15,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f14,-504(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f30
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f30.f64));
	// stfs f14,-480(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f14,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f14.f64));
	// stfs f30,-428(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fmuls f14,f21,f16
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f16.f64));
	// lfs f30,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f21,f21,f30
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// fmsubs f30,f23,f30,f14
	ctx.f30.f64 = double(float(ctx.f23.f64 * ctx.f30.f64 - ctx.f14.f64));
	// stfsx f30,r25,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f23,f16,f21
	ctx.f30.f64 = double(float(ctx.f23.f64 * ctx.f16.f64 + ctx.f21.f64));
	// stfsx f30,r25,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f23.f64 = double(temp.f32);
	// lfs f16,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f16.f64 = double(temp.f32);
	// lfs f21,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f23,f16
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// fmuls f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f21.f64));
	// lfs f30,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f21,f30,f21,f14
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f21.f64 - ctx.f14.f64));
	// stfsx f21,r22,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f30,f16,f23
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f16.f64 + ctx.f23.f64));
	// stfsx f30,r22,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f21,f23,f24
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f24.f64));
	// lfs f30,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f15.f64));
	// lfs f16,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fmuls f14,f14,f13
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// fmsubs f21,f30,f15,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f15.f64 - ctx.f21.f64));
	// stfsx f21,r27,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f30,f24,f23
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f24.f64 + ctx.f23.f64));
	// lfs f21,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// lfs f24,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f21,f1,f13
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f15,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f15.f64 = double(temp.f32);
	// fadds f24,f24,f29
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// stfsx f30,r27,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// lfs f30,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f23,-464(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f23,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f23,f12,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 - ctx.f21.f64));
	// lfs f21,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f24,f24,f0
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmadds f21,f21,f12,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f16.f64));
	// lfs f16,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f12,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 - ctx.f15.f64));
	// lfs f15,220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f1,f1,f12,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 + ctx.f14.f64));
	// lfs f14,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// fmuls f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f19.f64));
	// fmsubs f19,f30,f19,f14
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f19.f64 - ctx.f14.f64));
	// stfsx f19,r23,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// lfs f19,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f30,f30,f19,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f19.f64 + ctx.f15.f64));
	// lfs f14,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f3,f24
	ctx.f15.f64 = double(float(ctx.f3.f64 - ctx.f24.f64));
	// stfsx f30,r23,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fadds f3,f24,f3
	ctx.f3.f64 = double(float(ctx.f24.f64 + ctx.f3.f64));
	// lfs f19,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f24,f23,f21
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfs f24,-504(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f24,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f14,f5,f14
	ctx.f14.f64 = double(float(ctx.f5.f64 - ctx.f14.f64));
	// fadds f5,f24,f5
	ctx.f5.f64 = double(float(ctx.f24.f64 + ctx.f5.f64));
	// lfs f30,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f30.f64 = double(temp.f32);
	// fadds f24,f21,f23
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fsubs f23,f16,f1
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f1.f64));
	// fadds f1,f1,f16
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f16.f64));
	// lfs f16,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f21,f15,f16
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// fsubs f15,f14,f23
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// stfs f15,-504(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfs f23,-480(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fadds f15,f1,f3
	ctx.f15.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fmuls f14,f19,f21
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// lfs f23,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f19,f19,f23
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// fmsubs f21,f30,f21,f19
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f21.f64 - ctx.f19.f64));
	// stfsx f21,r26,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f21,f24,f5
	ctx.f21.f64 = double(float(ctx.f24.f64 + ctx.f5.f64));
	// fmadds f30,f30,f23,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f23.f64 + ctx.f14.f64));
	// stfsx f30,r26,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f23.f64 = double(temp.f32);
	// lfs f30,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f19,f23,f21
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f21.f64));
	// fmuls f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f15.f64));
	// fmsubs f19,f30,f15,f19
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f15.f64 - ctx.f19.f64));
	// stfsx f19,r24,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f30,f21,f23
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f21.f64 + ctx.f23.f64));
	// stfsx f30,r24,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f23.f64 = double(temp.f32);
	// lfs f21,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f23,f21
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f21.f64));
	// lfs f30,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// fmsubs f19,f30,f16,f19
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f16.f64 - ctx.f19.f64));
	// stfsx f19,r21,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f30,f21,f23
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f21.f64 + ctx.f23.f64));
	// stfsx f30,r21,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r5.u32, temp.u32);
	// lfs f30,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f30.f64 = double(temp.f32);
	// lfs f23,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f19,f30,f23
	ctx.f19.f64 = double(float(ctx.f30.f64 - ctx.f23.f64));
	// lfs f23,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f16,f23,f29
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// lfs f21,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f21,f12
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmuls f14,f23,f13
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// lfs f30,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// stfs f23,-412(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// stfs f21,-504(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f29,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f23,f19,f0
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fmuls f19,f16,f0
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f19,-480(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f19,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f19.f64 = double(temp.f32);
	// lfs f16,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f21,f19,f13,f15
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 - ctx.f15.f64));
	// fmadds f19,f16,f12,f14
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f14.f64));
	// fsubs f5,f5,f24
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f24.f64));
	// lfs f15,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// lfs f14,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f1,f16,f13,f15
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f15.f64));
	// lfs f15,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f31,f23
	ctx.f16.f64 = double(float(ctx.f31.f64 - ctx.f23.f64));
	// lfs f24,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f24.f64 = double(temp.f32);
	// fadds f31,f23,f31
	ctx.f31.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// fsubs f23,f21,f19
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfs f23,-480(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fmadds f24,f24,f12,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 + ctx.f15.f64));
	// fsubs f15,f22,f14
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// fmuls f23,f29,f5
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f5.f64));
	// stfs f23,-412(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fmuls f29,f29,f3
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// stfs f29,-504(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fadds f29,f14,f22
	ctx.f29.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// lfs f14,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f19,f21
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f23,f1,f24
	ctx.f23.f64 = double(float(ctx.f1.f64 - ctx.f24.f64));
	// fadds f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 + ctx.f1.f64));
	// fadds f19,f22,f29
	ctx.f19.f64 = double(float(ctx.f22.f64 + ctx.f29.f64));
	// fsubs f21,f15,f23
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// fadds f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// lfs f24,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f3,f30,f3,f24
	ctx.f3.f64 = double(float(ctx.f30.f64 * ctx.f3.f64 - ctx.f24.f64));
	// stfsx f3,r20,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// lfs f3,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f3.f64 = double(temp.f32);
	// lfs f24,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f5,f30,f5,f3
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f5.f64 + ctx.f3.f64));
	// fsubs f30,f16,f24
	ctx.f30.f64 = double(float(ctx.f16.f64 - ctx.f24.f64));
	// stfsx f5,r20,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r5.u32, temp.u32);
	// lfs f3,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f3.f64 = double(temp.f32);
	// fadds f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f16.f64));
	// fadds f16,f1,f31
	ctx.f16.f64 = double(float(ctx.f1.f64 + ctx.f31.f64));
	// lfs f5,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f15,f3,f30
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// fmuls f3,f3,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f21.f64));
	// fmsubs f3,f5,f30,f3
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f30.f64 - ctx.f3.f64));
	// stfsx f3,r30,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmadds f5,f5,f21,f15
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f21.f64 + ctx.f15.f64));
	// stfsx f5,r30,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// lfs f3,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f30,f3,f19
	ctx.f30.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// lfs f5,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f3,f3,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f16.f64));
	// fmsubs f30,f5,f16,f30
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f16.f64 - ctx.f30.f64));
	// stfsx f30,r7,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fmadds f5,f5,f19,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f19.f64 + ctx.f3.f64));
	// stfsx f5,r7,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// lfs f3,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f30,f3,f23
	ctx.f30.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfs f5,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f5.f64 = double(temp.f32);
	// lfs f16,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f10
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// fmsubs f30,f5,f24,f30
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 - ctx.f30.f64));
	// stfsx f30,r28,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f24,f3,f24
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fmuls f21,f30,f10
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// lfs f30,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f19,f30,f10
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// fmuls f15,f30,f11
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// lfs f30,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f3,f31,f1
	ctx.f3.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// lfs f1,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f31,f29,f22
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f22.f64));
	// fmadds f5,f5,f23,f24
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 + ctx.f24.f64));
	// stfsx f5,r28,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fmadds f21,f14,f11,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 + ctx.f21.f64));
	// lfs f14,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f19,f14,f11,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 - ctx.f19.f64));
	// lfs f14,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f14.f64 = double(temp.f32);
	// lfs f5,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f16,f14,f11,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 - ctx.f16.f64));
	// lfs f29,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f1,f1,f10,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f15.f64));
	// fadds f23,f27,f26
	ctx.f23.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// fadds f24,f30,f23
	ctx.f24.f64 = double(float(ctx.f30.f64 + ctx.f23.f64));
	// fsubs f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 - ctx.f30.f64));
	// fsubs f22,f19,f21
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// fadds f23,f19,f21
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// lfs f21,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f21.f64 = double(temp.f32);
	// fadds f15,f21,f28
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f28.f64));
	// fadds f19,f4,f6
	ctx.f19.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fmuls f14,f17,f11
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fadds f21,f15,f19
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// fadds f15,f1,f16
	ctx.f15.f64 = double(float(ctx.f1.f64 + ctx.f16.f64));
	// fsubs f1,f16,f1
	ctx.f1.f64 = double(float(ctx.f16.f64 - ctx.f1.f64));
	// fmuls f16,f29,f31
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f31.f64));
	// fmuls f29,f29,f3
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// fmsubs f3,f5,f3,f16
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f3.f64 - ctx.f16.f64));
	// stfsx f3,r9,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmadds f5,f5,f31,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64 + ctx.f29.f64));
	// stfsx f5,r9,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f29,f21,f23
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// lfs f3,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f3.f64 = double(temp.f32);
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// lfs f5,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f21,f24,f15
	ctx.f21.f64 = double(float(ctx.f24.f64 - ctx.f15.f64));
	// fadds f24,f15,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 + ctx.f24.f64));
	// fadds f16,f19,f1
	ctx.f16.f64 = double(float(ctx.f19.f64 + ctx.f1.f64));
	// fadds f31,f22,f30
	ctx.f31.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// fsubs f1,f19,f1
	ctx.f1.f64 = double(float(ctx.f19.f64 - ctx.f1.f64));
	// fmuls f15,f3,f29
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f29.f64));
	// fmuls f3,f3,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f21.f64));
	// fmsubs f21,f5,f21,f15
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f21.f64 - ctx.f15.f64));
	// stfsx f21,r29,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fmuls f21,f17,f10
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// lfs f17,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f5,f5,f29,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f29.f64 + ctx.f3.f64));
	// stfsx f5,r29,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// lfs f3,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f29,f3,f16
	ctx.f29.f64 = double(float(ctx.f3.f64 * ctx.f16.f64));
	// lfs f5,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// lfs f15,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f21,f18,f11,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 + ctx.f21.f64));
	// fmsubs f18,f18,f10,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64 - ctx.f14.f64));
	// fmsubs f31,f5,f31,f29
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f31.f64 - ctx.f29.f64));
	// stfsx f31,r10,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f5,f5,f16,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f16.f64 + ctx.f3.f64));
	// stfsx f5,r10,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f3,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f31,f3,f23
	ctx.f31.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfs f5,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// lfs f29,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f17.f64));
	// lfs f17,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f31,f5,f24,f31
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 - ctx.f31.f64));
	// stfs f31,0(r4)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f31,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f24,f3,f24
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fmuls f16,f31,f10
	ctx.f16.f64 = double(float(ctx.f31.f64 * ctx.f10.f64));
	// fmuls f31,f31,f11
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f11.f64));
	// stfs f31,-412(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fadds f31,f2,f7
	ctx.f31.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// fsubs f3,f30,f22
	ctx.f3.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// fmadds f5,f5,f23,f24
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 + ctx.f24.f64));
	// stfs f5,0(r6)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fmadds f17,f17,f11,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f16.f64));
	// stfs f17,-504(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f17,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f24,f31,f29
	ctx.f24.f64 = double(float(ctx.f31.f64 - ctx.f29.f64));
	// lfs f16,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f16.f64 = double(temp.f32);
	// fadds f31,f29,f31
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// lfs f5,192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 192);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// lfs f30,196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 196);
	ctx.f30.f64 = double(temp.f32);
	// lfs f14,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f16,f10,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 - ctx.f14.f64));
	// lfs f23,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f29,f21,f23
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// fsubs f21,f20,f25
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f25.f64));
	// fadds f19,f16,f18
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fadds f22,f17,f21
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// fsubs f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// fmuls f17,f30,f1
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f1.f64));
	// fmuls f30,f30,f3
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f3.f64));
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// fsubs f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// lfs f4,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f4.f64 = double(temp.f32);
	// fmsubs f3,f5,f3,f17
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f3.f64 - ctx.f17.f64));
	// stfsx f3,r31,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fmadds f5,f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 + ctx.f30.f64));
	// stfsx f5,r31,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f30,f22,f29
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f29.f64));
	// lfs f3,180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 180);
	ctx.f3.f64 = double(temp.f32);
	// fadds f29,f22,f29
	ctx.f29.f64 = double(float(ctx.f22.f64 + ctx.f29.f64));
	// lfs f5,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f22,f24,f19
	ctx.f22.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// fadds f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// fsubs f17,f21,f18
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// fadds f1,f23,f31
	ctx.f1.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// fmuls f19,f3,f30
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// fmuls f3,f3,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// fmsubs f22,f5,f22,f19
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 - ctx.f19.f64));
	// stfsx f22,r9,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f19,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f5,f5,f30,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64 + ctx.f3.f64));
	// stfsx f5,r9,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// lfs f3,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f30,f3,f17
	ctx.f30.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// lfs f5,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f22,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f22,f8
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// fmsubs f1,f5,f1,f30
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 - ctx.f30.f64));
	// stfsx f1,r30,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fmuls f1,f19,f8
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// lfs f30,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f30.f64 = double(temp.f32);
	// stfs f1,-352(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fmuls f30,f30,f8
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// stfs f30,-340(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fsubs f1,f26,f27
	ctx.f1.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// lfs f27,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f5,f5,f17,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f17.f64 + ctx.f3.f64));
	// fsubs f30,f28,f27
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// lfs f26,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f28,f19,f9,f16
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f9.f64 + ctx.f16.f64));
	// stfsx f5,r30,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f4,f4,f26
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f26.f64));
	// lfs f3,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f3.f64 = double(temp.f32);
	// lfs f17,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f19,f3,f29
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f29.f64));
	// fmuls f14,f17,f8
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f8.f64));
	// lfs f5,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f5.f64 = double(temp.f32);
	// lfs f27,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f27,f27,f9,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 - ctx.f14.f64));
	// lfs f16,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f26,f22,f9,f16
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 - ctx.f16.f64));
	// lfs f16,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f22,f17,f9,f16
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 + ctx.f16.f64));
	// fmuls f17,f3,f24
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fsubs f3,f31,f23
	ctx.f3.f64 = double(float(ctx.f31.f64 - ctx.f23.f64));
	// fadds f31,f21,f18
	ctx.f31.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// fmsubs f24,f5,f24,f19
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 - ctx.f19.f64));
	// stfsx f24,r7,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fadds f24,f30,f1
	ctx.f24.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fsubs f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// fadds f30,f27,f28
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fsubs f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// fadds f27,f4,f6
	ctx.f27.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fsubs f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// fmadds f5,f5,f29,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f29.f64 + ctx.f17.f64));
	// stfsx f5,r7,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// lfs f29,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f29.f64 = double(temp.f32);
	// fadds f4,f22,f26
	ctx.f4.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// fmuls f23,f29,f31
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f31.f64));
	// lfs f5,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f29,f29,f3
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// fsubs f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// fmsubs f3,f5,f3,f23
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f3.f64 - ctx.f23.f64));
	// stfsx f3,r28,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fmadds f5,f5,f31,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64 + ctx.f29.f64));
	// stfsx f5,r28,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f5,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f5.f64 = double(temp.f32);
	// lfs f3,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f29,f27,f30
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f30.f64));
	// fadds f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// fsubs f27,f24,f4
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f4.f64));
	// fadds f4,f4,f24
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f24.f64));
	// fadds f23,f6,f26
	ctx.f23.f64 = double(float(ctx.f6.f64 + ctx.f26.f64));
	// fadds f31,f28,f1
	ctx.f31.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// fsubs f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// fsubs f7,f7,f2
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f2.f64));
	// lfs f2,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f15.f64));
	// fsubs f6,f6,f26
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f26.f64));
	// fmuls f24,f3,f29
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f29.f64));
	// fmuls f3,f3,f27
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// fmsubs f27,f5,f27,f24
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64 - ctx.f24.f64));
	// stfsx f27,r25,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lfs f24,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f5,f5,f29,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f29.f64 + ctx.f3.f64));
	// stfsx f5,r25,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// lfs f3,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f29,f3,f23
	ctx.f29.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfs f5,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmsubs f31,f5,f31,f29
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f31.f64 - ctx.f29.f64));
	// stfsx f31,r22,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// lfs f31,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f31.f64 = double(temp.f32);
	// fmadds f5,f5,f23,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 + ctx.f3.f64));
	// lfs f29,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f27,f31,f9
	ctx.f27.f64 = double(float(ctx.f31.f64 * ctx.f9.f64));
	// fmuls f22,f29,f8
	ctx.f22.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// stfsx f5,r22,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// fmuls f21,f29,f9
	ctx.f21.f64 = double(float(ctx.f29.f64 * ctx.f9.f64));
	// lfs f3,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f31,f8
	ctx.f19.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// lfs f23,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f28,f3,f30
	ctx.f28.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// lfs f5,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f3,f3,f4
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// fmsubs f31,f23,f8,f27
	ctx.f31.f64 = double(float(ctx.f23.f64 * ctx.f8.f64 - ctx.f27.f64));
	// fmadds f29,f24,f9,f22
	ctx.f29.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 + ctx.f22.f64));
	// lfs f22,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f22.f64 = double(temp.f32);
	// fadds f27,f25,f20
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// lfs f25,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// fmsubs f24,f24,f8,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f8.f64 - ctx.f21.f64));
	// fmadds f23,f23,f9,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f9.f64 + ctx.f19.f64));
	// fmsubs f4,f5,f4,f28
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f4.f64 - ctx.f28.f64));
	// stfsx f4,r27,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fsubs f4,f7,f2
	ctx.f4.f64 = double(float(ctx.f7.f64 - ctx.f2.f64));
	// fmadds f5,f5,f30,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64 + ctx.f3.f64));
	// stfsx f5,r27,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fadds f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// lfs f3,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f22,f3,f1
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f5,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f30,f31,f29
	ctx.f30.f64 = double(float(ctx.f31.f64 - ctx.f29.f64));
	// fadds f31,f29,f31
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// fsubs f2,f27,f25
	ctx.f2.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// fadds f29,f25,f27
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f28,f24,f23
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f27,f23,f24
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fmuls f23,f3,f6
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// fmadds f6,f5,f6,f22
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f6.f64 + ctx.f22.f64));
	// fadds f26,f31,f7
	ctx.f26.f64 = double(float(ctx.f31.f64 + ctx.f7.f64));
	// fsubs f3,f2,f30
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f30.f64));
	// fsubs f25,f4,f28
	ctx.f25.f64 = double(float(ctx.f4.f64 - ctx.f28.f64));
	// fadds f24,f29,f27
	ctx.f24.f64 = double(float(ctx.f29.f64 + ctx.f27.f64));
	// fmsubs f1,f5,f1,f23
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 - ctx.f23.f64));
	// stfsx f1,r23,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// stfsx f6,r23,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// lfs f5,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f1,f5,f3
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// fmuls f5,f5,f25
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// fmsubs f1,f6,f25,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f25.f64 - ctx.f1.f64));
	// stfsx f1,r26,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fmadds f6,f6,f3,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 + ctx.f5.f64));
	// stfsx f6,r26,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// lfs f5,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f3,f5,f24
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// lfs f6,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f5,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// fmsubs f3,f6,f26,f3
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f26.f64 - ctx.f3.f64));
	// stfsx f3,r24,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// fmadds f6,f6,f24,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 + ctx.f5.f64));
	// stfsx f6,r24,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f28,f4
	ctx.f6.f64 = double(float(ctx.f28.f64 + ctx.f4.f64));
	// lfs f3,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f3.f64 = double(temp.f32);
	// fadds f4,f2,f30
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f30.f64));
	// lfs f5,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f2,f29,f27
	ctx.f2.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// lwz r10,-312(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	// fsubs f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f31.f64));
	// addic. r14,r14,-1
	ctx.xer.ca = ctx.r14.u32 > 0;
	ctx.r14.s64 = ctx.r14.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r14.s32, 0, ctx.xer);
	// add r3,r19,r3
	ctx.r3.u64 = ctx.r19.u64 + ctx.r3.u64;
	// add r4,r19,r4
	ctx.r4.u64 = ctx.r19.u64 + ctx.r4.u64;
	// subf r5,r19,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r19.s64;
	// subf r6,r19,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r19.s64;
	// fmuls f1,f3,f4
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// fmuls f3,f3,f6
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// fmsubs f6,f5,f6,f1
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f6.f64 - ctx.f1.f64));
	// stfs f6,0(r15)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r15.u32 + 0, temp.u32);
	// fmadds f6,f5,f4,f3
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f4.f64 + ctx.f3.f64));
	// stfs f6,0(r18)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// lfs f5,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f2
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// lfs f6,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f5,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// addi r11,r11,248
	ctx.r11.s64 = ctx.r11.s64 + 248;
	// fmsubs f7,f6,f7,f4
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f7.f64 - ctx.f4.f64));
	// stfs f7,0(r16)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fmadds f7,f6,f2,f5
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 + ctx.f5.f64));
	// stfs f7,0(r17)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r17.u32 + 0, temp.u32);
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d2aee0
	if (!ctx.cr0.eq) goto loc_82D2AEE0;
loc_82D2C264:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D2C26C;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2C270"))) PPC_WEAK_FUNC(sub_82D2C270);
PPC_FUNC_IMPL(__imp__sub_82D2C270) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-7072
	ctx.r5.s64 = ctx.r11.s64 + -7072;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-20880
	ctx.r4.s64 = ctx.r11.s64 + -20880;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2C288"))) PPC_WEAK_FUNC(sub_82D2C288);
PPC_FUNC_IMPL(__imp__sub_82D2C288) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e4c
	ctx.lr = 0x82D2C290;
	__savegprlr_21(ctx, base);
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28ee0
	ctx.lr = 0x82D2C298;
	__savefpr_14(ctx, base);
	// mulli r11,r9,120
	ctx.r11.s64 = ctx.r9.s64 * 120;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-120
	ctx.r11.s64 = ctx.r11.s64 + -120;
	// bge cr6,0x82d2c94c
	if (!ctx.cr6.lt) goto loc_82D2C94C;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r22,r9,r10
	ctx.r22.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// rlwinm r27,r7,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32236
	ctx.r7.s64 = -2112618496;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lfs f13,-8016(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,136(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D2C2D4:
	// mulli r29,r8,24
	ctx.r29.s64 = ctx.r8.s64 * 24;
	// lfs f11,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f10,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f7,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f21,r29,r6
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// add r26,r29,r3
	ctx.r26.u64 = ctx.r29.u64 + ctx.r3.u64;
	// rlwinm r28,r8,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r9,r8,20
	ctx.r9.s64 = ctx.r8.s64 * 20;
	// lfsx f9,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f6,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f24,f9,f8
	ctx.f24.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fadds f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// lfsx f2,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// lfsx f31,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f31.f64 = double(temp.f32);
	// add r24,r28,r3
	ctx.r24.u64 = ctx.r28.u64 + ctx.r3.u64;
	// fsubs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// mulli r7,r8,28
	ctx.r7.s64 = ctx.r8.s64 * 28;
	// lfsx f1,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f5,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f20,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f18,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f17,r28,r6
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfs f3,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f6,f3,f2
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// lfsx f30,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfsx f29,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f29.f64 = double(temp.f32);
	// rlwinm r31,r8,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f2,f31,f1
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// mulli r30,r8,12
	ctx.r30.s64 = ctx.r8.s64 * 12;
	// fsubs f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// fadds f31,f30,f11
	ctx.f31.f64 = double(float(ctx.f30.f64 + ctx.f11.f64));
	// lfsx f16,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f30.f64));
	// lfsx f15,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f30,f10,f29
	ctx.f30.f64 = double(float(ctx.f10.f64 - ctx.f29.f64));
	// fadds f10,f29,f10
	ctx.f10.f64 = double(float(ctx.f29.f64 + ctx.f10.f64));
	// lfsx f28,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f27,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f29,f27,f28
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// lfsx f25,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f26,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fsubs f27,f26,f25
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// add r25,r29,r5
	ctx.r25.u64 = ctx.r29.u64 + ctx.r5.u64;
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// add r23,r28,r5
	ctx.r23.u64 = ctx.r28.u64 + ctx.r5.u64;
	// fadds f25,f8,f24
	ctx.f25.f64 = double(float(ctx.f8.f64 + ctx.f24.f64));
	// fadds f23,f2,f6
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f6.f64));
	// fsubs f8,f24,f8
	ctx.f8.f64 = double(float(ctx.f24.f64 - ctx.f8.f64));
	// fsubs f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f2.f64));
	// lfs f4,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fadds f24,f9,f3
	ctx.f24.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// lfs f19,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f2,f7,f1
	ctx.f2.f64 = double(float(ctx.f7.f64 - ctx.f1.f64));
	// fsubs f9,f3,f9
	ctx.f9.f64 = double(float(ctx.f3.f64 - ctx.f9.f64));
	// fadds f3,f29,f31
	ctx.f3.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// fadds f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// fsubs f1,f10,f28
	ctx.f1.f64 = double(float(ctx.f10.f64 - ctx.f28.f64));
	// fsubs f22,f30,f27
	ctx.f22.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// fsubs f31,f31,f29
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f29.f64));
	// fadds f29,f26,f11
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f11.f64));
	// fadds f10,f28,f10
	ctx.f10.f64 = double(float(ctx.f28.f64 + ctx.f10.f64));
	// fadds f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// fsubs f28,f23,f25
	ctx.f28.f64 = double(float(ctx.f23.f64 - ctx.f25.f64));
	// fadds f27,f25,f23
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f23.f64));
	// fsubs f11,f11,f26
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f26.f64));
	// fadds f26,f8,f6
	ctx.f26.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// fsubs f25,f6,f8
	ctx.f25.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// fsubs f23,f5,f4
	ctx.f23.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// lfsx f4,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f8,f28,f0
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f6,f27,f0
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f28,f26,f0
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// lfs f26,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f27,f25,f0
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// lfs f25,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-288(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfsx f14,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-284(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-276(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfsx f14,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-280(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fadds f14,f21,f4
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f4.f64));
	// fsubs f4,f4,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f21.f64));
	// fsubs f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fadds f19,f17,f18
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f19,-272(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f18,-268(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fsubs f19,f26,f16
	ctx.f19.f64 = double(float(ctx.f26.f64 - ctx.f16.f64));
	// stfs f19,-264(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fadds f26,f16,f26
	ctx.f26.f64 = double(float(ctx.f16.f64 + ctx.f26.f64));
	// fadds f19,f25,f15
	ctx.f19.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// fsubs f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// lfs f18,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f15,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,-260(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f15,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// fadds f15,f21,f14
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// fsubs f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// lfs f14,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfs f14,-276(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f14,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// fsubs f14,f5,f20
	ctx.f14.f64 = double(float(ctx.f5.f64 - ctx.f20.f64));
	// stfs f14,-272(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f14,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f14.f64 = double(temp.f32);
	// fadds f5,f20,f5
	ctx.f5.f64 = double(float(ctx.f20.f64 + ctx.f5.f64));
	// fsubs f14,f4,f14
	ctx.f14.f64 = double(float(ctx.f4.f64 - ctx.f14.f64));
	// stfs f14,-256(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// stfs f5,-288(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fsubs f14,f18,f19
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// lfs f5,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f20,f5,f17
	ctx.f20.f64 = double(float(ctx.f5.f64 - ctx.f17.f64));
	// lfs f5,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// stfs f5,-284(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// stfs f20,-248(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// lfs f5,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f4,f26,f5
	ctx.f4.f64 = double(float(ctx.f26.f64 - ctx.f5.f64));
	// stfs f4,-252(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fadds f5,f5,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f26.f64));
	// stfs f5,-260(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// fadds f5,f16,f25
	ctx.f5.f64 = double(float(ctx.f16.f64 + ctx.f25.f64));
	// stfs f5,-280(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fsubs f4,f25,f16
	ctx.f4.f64 = double(float(ctx.f25.f64 - ctx.f16.f64));
	// stfs f4,-268(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fmuls f26,f15,f12
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfs f5,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f16,f21,f13
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmuls f4,f5,f12
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f5,f21,f12
	ctx.f5.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfs f25,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f25.f64 = double(temp.f32);
	// stfs f5,-256(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fmr f5,f25
	ctx.f5.f64 = ctx.f25.f64;
	// lfs f25,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f4,f15,f13,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f4.f64));
	// fsubs f25,f25,f5
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f5.f64));
	// stfs f25,-244(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// lfs f25,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f25.f64 = double(temp.f32);
	// fadds f5,f5,f25
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f25.f64));
	// lfs f25,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f26,f25,f13,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 - ctx.f26.f64));
	// fmsubs f16,f23,f12,f16
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 - ctx.f16.f64));
	// stfs f16,-272(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f21,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f21.f64 = double(temp.f32);
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f25,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f25.f64 = double(temp.f32);
	// fadds f18,f24,f3
	ctx.f18.f64 = double(float(ctx.f24.f64 + ctx.f3.f64));
	// lfs f16,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f16.f64 = double(temp.f32);
	// fadds f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f21.f64));
	// fsubs f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// lfs f16,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f23,f23,f13,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f16.f64));
	// lfs f16,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f15,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f20,f14,f13,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 - ctx.f20.f64));
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,-264(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfs f15,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// fsubs f15,f29,f6
	ctx.f15.f64 = double(float(ctx.f29.f64 - ctx.f6.f64));
	// stfs f15,-256(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fadds f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// fmuls f29,f14,f12
	ctx.f29.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// fadds f15,f27,f1
	ctx.f15.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// fsubs f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f27.f64));
	// lfs f27,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f14,f19,f13
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmadds f29,f27,f13,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 + ctx.f29.f64));
	// fmuls f27,f19,f12
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// stfs f27,-248(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fadds f27,f7,f30
	ctx.f27.f64 = double(float(ctx.f7.f64 + ctx.f30.f64));
	// fadds f27,f16,f27
	ctx.f27.f64 = double(float(ctx.f16.f64 + ctx.f27.f64));
	// lfs f19,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f19,0(r3)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f27,0(r5)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f19,f7,f30
	ctx.f19.f64 = double(float(ctx.f7.f64 + ctx.f30.f64));
	// lfs f27,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,-252(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// lfs f27,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f18,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 - ctx.f27.f64));
	// fmsubs f18,f17,f12,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f14.f64));
	// fsubs f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// lfs f14,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f17,f17,f13,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f17,-264(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfs f14,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f14,-248(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fmuls f14,f17,f27
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f27.f64));
	// fmuls f16,f17,f19
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f19.f64));
	// lfs f17,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f23,f17
	ctx.f17.f64 = double(float(ctx.f23.f64 - ctx.f17.f64));
	// stfs f17,-268(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// lfs f17,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f17.f64 = double(temp.f32);
	// fadds f23,f17,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// lfs f17,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// lfs f17,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f27,f17,f27,f16
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f27.f64 - ctx.f16.f64));
	// stfsx f27,r31,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmadds f27,f17,f19,f14
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f19.f64 + ctx.f14.f64));
	// lfs f14,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f14
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfsx f27,r31,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// lfs f27,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f27.f64 = double(temp.f32);
	// lfs f19,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f14,-248(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lfs f14,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// fsubs f14,f6,f23
	ctx.f14.f64 = double(float(ctx.f6.f64 - ctx.f23.f64));
	// stfs f14,-252(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fadds f14,f18,f1
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f1.f64));
	// fadds f6,f23,f6
	ctx.f6.f64 = double(float(ctx.f23.f64 + ctx.f6.f64));
	// fsubs f1,f1,f18
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f18.f64));
	// lfs f23,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f19,f17
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// fmuls f19,f19,f23
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// fmsubs f19,f27,f17,f19
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f17.f64 - ctx.f19.f64));
	// stfsx f19,r9,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f27,f27,f23,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f23.f64 + ctx.f18.f64));
	// stfsx f27,r9,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f19,f23,f15
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f15.f64));
	// lfs f27,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// fmsubs f19,f27,f16,f19
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f16.f64 - ctx.f19.f64));
	// stfsx f19,r10,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f27,f27,f15,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f15.f64 + ctx.f23.f64));
	// stfsx f27,r10,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f23.f64 = double(temp.f32);
	// fadds f15,f21,f5
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f5.f64));
	// fmuls f18,f23,f14
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f14.f64));
	// lfs f27,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f27.f64 = double(temp.f32);
	// lfs f19,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f5.f64));
	// fmuls f17,f23,f19
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f19.f64));
	// fadds f23,f2,f31
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f31.f64));
	// fsubs f5,f31,f2
	ctx.f5.f64 = double(float(ctx.f31.f64 - ctx.f2.f64));
	// fmsubs f18,f27,f19,f18
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f19.f64 - ctx.f18.f64));
	// stfsx f18,r30,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f18,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f9,f22
	ctx.f19.f64 = double(float(ctx.f9.f64 + ctx.f22.f64));
	// fadds f16,f25,f18
	ctx.f16.f64 = double(float(ctx.f25.f64 + ctx.f18.f64));
	// fsubs f18,f18,f25
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f25.f64));
	// fmuls f25,f15,f0
	ctx.f25.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fmadds f2,f27,f14,f17
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f14.f64 + ctx.f17.f64));
	// stfsx f2,r30,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f27,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f9,f22,f9
	ctx.f9.f64 = double(float(ctx.f22.f64 - ctx.f9.f64));
	// fmuls f17,f27,f1
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// lfs f2,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f22,f21,f0
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fmuls f31,f16,f0
	ctx.f31.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f16,f27,f6
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fmuls f21,f18,f0
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fsubs f18,f19,f25
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f25.f64));
	// fadds f25,f25,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f19.f64));
	// fmsubs f6,f2,f6,f17
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 - ctx.f17.f64));
	// stfsx f6,r7,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f27,f23,f31
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f31.f64));
	// fmadds f6,f2,f1,f16
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f1.f64 + ctx.f16.f64));
	// stfsx f6,r7,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// lfs f2,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f2.f64 = double(temp.f32);
	// fadds f31,f31,f23
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f23.f64));
	// fmuls f1,f2,f18
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// lfs f6,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f19,f9,f21
	ctx.f19.f64 = double(float(ctx.f9.f64 - ctx.f21.f64));
	// fsubs f23,f5,f22
	ctx.f23.f64 = double(float(ctx.f5.f64 - ctx.f22.f64));
	// fadds f9,f21,f9
	ctx.f9.f64 = double(float(ctx.f21.f64 + ctx.f9.f64));
	// fadds f5,f22,f5
	ctx.f5.f64 = double(float(ctx.f22.f64 + ctx.f5.f64));
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// fmsubs f1,f6,f27,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f27.f64 - ctx.f1.f64));
	// stfsx f1,r9,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmadds f6,f6,f18,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f18.f64 + ctx.f2.f64));
	// stfsx f6,r9,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// lfs f2,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f25
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfs f6,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmsubs f1,f6,f31,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f31.f64 - ctx.f1.f64));
	// stfsx f1,r10,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f6,f6,f25,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f25.f64 + ctx.f2.f64));
	// stfsx f6,r10,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f2,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f19
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f19.f64));
	// lfs f6,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// fmsubs f1,f6,f23,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f23.f64 - ctx.f1.f64));
	// stfsx f1,r7,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fmadds f6,f6,f19,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f19.f64 + ctx.f2.f64));
	// stfsx f6,r7,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// lfs f2,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f2.f64 = double(temp.f32);
	// lfs f6,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f1,f2,f9
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// fmsubs f1,f6,f5,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f5.f64 - ctx.f1.f64));
	// stfsx f1,r30,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fsubs f1,f11,f28
	ctx.f1.f64 = double(float(ctx.f11.f64 - ctx.f28.f64));
	// addic. r22,r22,-1
	ctx.xer.ca = ctx.r22.u32 > 0;
	ctx.r22.s64 = ctx.r22.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r22.s32, 0, ctx.xer);
	// fsubs f31,f20,f4
	ctx.f31.f64 = double(float(ctx.f20.f64 - ctx.f4.f64));
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fsubs f27,f10,f8
	ctx.f27.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// fadds f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fsubs f25,f26,f29
	ctx.f25.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// fmuls f23,f2,f5
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// lfs f2,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f2.f64 = double(temp.f32);
	// fadds f8,f20,f4
	ctx.f8.f64 = double(float(ctx.f20.f64 + ctx.f4.f64));
	// fadds f11,f28,f11
	ctx.f11.f64 = double(float(ctx.f28.f64 + ctx.f11.f64));
	// fsubs f4,f3,f24
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f24.f64));
	// lfs f3,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f3.f64 = double(temp.f32);
	// fadds f5,f29,f26
	ctx.f5.f64 = double(float(ctx.f29.f64 + ctx.f26.f64));
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// lfs f2,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f7,f30,f7
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f7.f64));
	// lfs f30,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f30.f64));
	// fsubs f30,f1,f31
	ctx.f30.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fsubs f31,f27,f25
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// fmadds f9,f6,f9,f23
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 + ctx.f23.f64));
	// stfsx f9,r30,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// lfs f6,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f6.f64 = double(temp.f32);
	// fadds f29,f25,f27
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// lfs f9,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f9.f64 = double(temp.f32);
	// subf r5,r27,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r27.s64;
	// fsubs f28,f11,f5
	ctx.f28.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// fadds f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 + ctx.f11.f64));
	// fsubs f5,f10,f8
	ctx.f5.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// fadds f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fsubs f8,f4,f3
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fsubs f3,f7,f2
	ctx.f3.f64 = double(float(ctx.f7.f64 - ctx.f2.f64));
	// fadds f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// fmuls f2,f6,f30
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmsubs f6,f9,f30,f6
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f30.f64 - ctx.f6.f64));
	// stfsx f6,r29,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fmadds f9,f9,f31,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f31.f64 + ctx.f2.f64));
	// stfsx f9,r29,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// lfs f6,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f2,f6,f29
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// lfs f9,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f6,f6,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// fmsubs f2,f9,f1,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f1.f64 - ctx.f2.f64));
	// stfsx f2,r28,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fmadds f9,f9,f29,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f29.f64 + ctx.f6.f64));
	// stfsx f9,r28,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f6,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f2,f6,f5
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f9,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fmsubs f2,f9,f28,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f28.f64 - ctx.f2.f64));
	// stfsx f2,r31,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fmadds f9,f9,f5,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f5.f64 + ctx.f6.f64));
	// stfsx f9,r31,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f6,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f6,f10
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// lfs f9,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f6,f6,f11
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// fmsubs f11,f9,f11,f5
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f11.f64 - ctx.f5.f64));
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmadds f11,f9,f10,f6
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f10.f64 + ctx.f6.f64));
	// stfs f11,0(r6)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f10,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f10.f64 = double(temp.f32);
	// add r4,r27,r4
	ctx.r4.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fmuls f9,f10,f3
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f11,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// subf r6,r27,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r27.s64;
	// fmsubs f9,f11,f8,f9
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 - ctx.f9.f64));
	// stfs f9,0(r26)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fmadds f11,f11,f3,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f10.f64));
	// stfs f11,0(r25)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// lfs f11,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// addi r11,r11,120
	ctx.r11.s64 = ctx.r11.s64 + 120;
	// fmuls f9,f10,f7
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// fmuls f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// fmsubs f9,f11,f4,f9
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f4.f64 - ctx.f9.f64));
	// stfs f9,0(r24)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fmadds f11,f11,f7,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64 + ctx.f10.f64));
	// stfs f11,0(r23)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// lwz r10,3532(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d2c2d4
	if (!ctx.cr0.eq) goto loc_82D2C2D4;
loc_82D2C94C:
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28f2c
	ctx.lr = 0x82D2C954;
	__restfpr_14(ctx, base);
	// b 0x82e28e9c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2C958"))) PPC_WEAK_FUNC(sub_82D2C958);
PPC_FUNC_IMPL(__imp__sub_82D2C958) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-7016
	ctx.r5.s64 = ctx.r11.s64 + -7016;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-15736
	ctx.r4.s64 = ctx.r11.s64 + -15736;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2C970"))) PPC_WEAK_FUNC(sub_82D2C970);
PPC_FUNC_IMPL(__imp__sub_82D2C970) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e4c
	ctx.lr = 0x82D2C978;
	__savegprlr_21(ctx, base);
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28ef0
	ctx.lr = 0x82D2C980;
	__savefpr_18(ctx, base);
	// mulli r11,r9,88
	ctx.r11.s64 = ctx.r9.s64 * 88;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-88
	ctx.r11.s64 = ctx.r11.s64 + -88;
	// bge cr6,0x82d2cd6c
	if (!ctx.cr6.lt) goto loc_82D2CD6C;
	// subf r28,r9,r10
	ctx.r28.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// rlwinm r29,r7,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lfs f13,-28552(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f0.f64 = double(temp.f32);
loc_82D2C9B4:
	// mulli r7,r8,20
	ctx.r7.s64 = ctx.r8.s64 * 20;
	// lfs f12,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f11,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f7,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f3,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f3.f64 = double(temp.f32);
	// add r27,r7,r3
	ctx.r27.u64 = ctx.r7.u64 + ctx.r3.u64;
	// mulli r31,r8,12
	ctx.r31.s64 = ctx.r8.s64 * 12;
	// lfsx f10,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f24,f10,f9
	ctx.f24.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// lfsx f8,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fadds f25,f9,f10
	ctx.f25.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// lfsx f5,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f5.f64 = double(temp.f32);
	// rlwinm r30,r8,3,0,28
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f10,f7,f8
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// rlwinm r9,r8,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f23,f7,f8
	ctx.f23.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// add r25,r31,r6
	ctx.r25.u64 = ctx.r31.u64 + ctx.r6.u64;
	// lfsx f6,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f6.f64 = double(temp.f32);
	// add r23,r30,r3
	ctx.r23.u64 = ctx.r30.u64 + ctx.r3.u64;
	// lfsx f1,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f1.f64 = double(temp.f32);
	// add r24,r30,r5
	ctx.r24.u64 = ctx.r30.u64 + ctx.r5.u64;
	// lfsx f21,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// add r26,r7,r5
	ctx.r26.u64 = ctx.r7.u64 + ctx.r5.u64;
	// lfsx f26,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// add r22,r31,r4
	ctx.r22.u64 = ctx.r31.u64 + ctx.r4.u64;
	// lfsx f31,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfs f30,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f7,f24,f0
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fsubs f8,f31,f30
	ctx.f8.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// lfs f27,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fadds f24,f5,f26
	ctx.f24.f64 = double(float(ctx.f5.f64 + ctx.f26.f64));
	// lfsx f2,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f31,f30,f31
	ctx.f31.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// lfs f29,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f30,f6,f27
	ctx.f30.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// lfsx f28,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f9,f1,f2
	ctx.f9.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// lfs f4,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fadds f6,f27,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 + ctx.f6.f64));
	// lfs f19,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fsubs f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 - ctx.f5.f64));
	// fadds f26,f25,f29
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// fmuls f2,f23,f0
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fnmsubs f29,f25,f13,f29
	ctx.f29.f64 = double(float(-(ctx.f25.f64 * ctx.f13.f64 - ctx.f29.f64)));
	// fmuls f27,f24,f0
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fsubs f24,f10,f28
	ctx.f24.f64 = double(float(ctx.f10.f64 - ctx.f28.f64));
	// fmadds f10,f10,f13,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + ctx.f28.f64));
	// fadds f28,f9,f12
	ctx.f28.f64 = double(float(ctx.f9.f64 + ctx.f12.f64));
	// fadds f23,f6,f4
	ctx.f23.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// fmuls f31,f31,f0
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fnmsubs f12,f9,f13,f12
	ctx.f12.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// fadds f25,f8,f11
	ctx.f25.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// fnmsubs f6,f6,f13,f4
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f13.f64 - ctx.f4.f64)));
	// lfsx f4,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f22,f5,f3
	ctx.f22.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fnmsubs f11,f8,f13,f11
	ctx.f11.f64 = double(float(-(ctx.f8.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// fmadds f5,f5,f13,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 + ctx.f3.f64));
	// lfsx f3,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f30,f30,f0
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fadds f9,f29,f2
	ctx.f9.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fsubs f8,f29,f2
	ctx.f8.f64 = double(float(ctx.f29.f64 - ctx.f2.f64));
	// lfs f29,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f2,f7,f10
	ctx.f2.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// fadds f20,f23,f28
	ctx.f20.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// fadds f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// fsubs f7,f12,f31
	ctx.f7.f64 = double(float(ctx.f12.f64 - ctx.f31.f64));
	// fsubs f28,f28,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// fadds f23,f6,f27
	ctx.f23.f64 = double(float(ctx.f6.f64 + ctx.f27.f64));
	// fadds f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f31.f64));
	// fadds f31,f11,f1
	ctx.f31.f64 = double(float(ctx.f11.f64 + ctx.f1.f64));
	// fsubs f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// fsubs f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f1.f64));
	// lfs f1,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fadds f18,f22,f25
	ctx.f18.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// fsubs f27,f30,f5
	ctx.f27.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// fsubs f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// fadds f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// fadds f30,f1,f4
	ctx.f30.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// fadds f22,f29,f3
	ctx.f22.f64 = double(float(ctx.f29.f64 + ctx.f3.f64));
	// fsubs f4,f4,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f1.f64));
	// fsubs f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// fadds f1,f30,f21
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// fsubs f29,f19,f22
	ctx.f29.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// fnmsubs f30,f30,f13,f21
	ctx.f30.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f21.f64)));
	// fmadds f22,f22,f13,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f19.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fadds f21,f1,f26
	ctx.f21.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// fadds f19,f29,f24
	ctx.f19.f64 = double(float(ctx.f29.f64 + ctx.f24.f64));
	// fsubs f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f26.f64));
	// fsubs f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f24.f64));
	// fadds f26,f22,f4
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f4.f64));
	// fadds f24,f30,f3
	ctx.f24.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// fsubs f3,f30,f3
	ctx.f3.f64 = double(float(ctx.f30.f64 - ctx.f3.f64));
	// fsubs f4,f22,f4
	ctx.f4.f64 = double(float(ctx.f22.f64 - ctx.f4.f64));
	// fsubs f22,f20,f21
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// fadds f30,f21,f20
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f30,0(r3)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f20,f18,f19
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// fadds f30,f19,f18
	ctx.f30.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f30,0(r5)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lfs f21,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f19,f28,f29
	ctx.f19.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// fadds f18,f25,f1
	ctx.f18.f64 = double(float(ctx.f25.f64 + ctx.f1.f64));
	// lfs f30,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f30.f64 = double(temp.f32);
	// fadds f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// fsubs f1,f25,f1
	ctx.f1.f64 = double(float(ctx.f25.f64 - ctx.f1.f64));
	// fmuls f25,f21,f22
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f22.f64));
	// fmuls f28,f21,f20
	ctx.f28.f64 = double(float(ctx.f21.f64 * ctx.f20.f64));
	// fadds f21,f5,f11
	ctx.f21.f64 = double(float(ctx.f5.f64 + ctx.f11.f64));
	// fsubs f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// fadds f5,f24,f9
	ctx.f5.f64 = double(float(ctx.f24.f64 + ctx.f9.f64));
	// fmsubs f28,f30,f22,f28
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f22.f64 - ctx.f28.f64));
	// stfsx f28,r31,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f30,f20,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f20.f64 + ctx.f25.f64));
	// stfsx f30,r31,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lfs f28,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f20,f3,f8
	ctx.f20.f64 = double(float(ctx.f3.f64 - ctx.f8.f64));
	// fmuls f25,f28,f18
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfs f30,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fadds f8,f3,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f8.f64));
	// fadds f3,f20,f21
	ctx.f3.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fmsubs f25,f30,f19,f25
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f19.f64 - ctx.f25.f64));
	// stfsx f25,r9,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f30,f30,f18,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f18.f64 + ctx.f28.f64));
	// stfsx f30,r9,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f25,f4,f10
	ctx.f25.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// lfs f22,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f30,f12,f6
	ctx.f30.f64 = double(float(ctx.f12.f64 - ctx.f6.f64));
	// lfs f28,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// fadds f12,f6,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 + ctx.f12.f64));
	// fsubs f10,f4,f10
	ctx.f10.f64 = double(float(ctx.f4.f64 - ctx.f10.f64));
	// fmuls f19,f22,f1
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fmuls f18,f22,f29
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f29.f64));
	// fadds f6,f23,f7
	ctx.f6.f64 = double(float(ctx.f23.f64 + ctx.f7.f64));
	// fsubs f4,f30,f25
	ctx.f4.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// fadds f30,f25,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// fsubs f22,f12,f8
	ctx.f22.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// fsubs f25,f21,f20
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fsubs f21,f11,f10
	ctx.f21.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// fadds f12,f8,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fmsubs f8,f28,f29,f19
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f29.f64 - ctx.f19.f64));
	// stfsx f8,r10,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f10,f28,f1,f18
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f1.f64 + ctx.f18.f64));
	// stfsx f10,r10,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f1,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f8,f6,f5
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// lfs f10,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f5,f1,f3
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// fmuls f1,f1,f4
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// fmsubs f5,f10,f4,f5
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 - ctx.f5.f64));
	// stfsx f5,r30,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fmadds f10,f10,f3,f1
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f3.f64 + ctx.f1.f64));
	// stfsx f10,r30,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f10,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f10.f64 = double(temp.f32);
	// lfs f5,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f3,f31,f27
	ctx.f3.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// fmuls f4,f5,f25
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fsubs f9,f24,f9
	ctx.f9.f64 = double(float(ctx.f24.f64 - ctx.f9.f64));
	// fsubs f7,f7,f23
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f23.f64));
	// fmsubs f4,f10,f30,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f30.f64 - ctx.f4.f64));
	// stfsx f4,r7,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fmadds f10,f10,f25,f5
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f25.f64 + ctx.f5.f64));
	// stfsx f10,r7,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// lfs f5,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f5.f64 = double(temp.f32);
	// fadds f1,f9,f3
	ctx.f1.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// fmuls f4,f5,f21
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f21.f64));
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f5,f5,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f22.f64));
	// fsubs f9,f3,f9
	ctx.f9.f64 = double(float(ctx.f3.f64 - ctx.f9.f64));
	// fmsubs f4,f10,f22,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f22.f64 - ctx.f4.f64));
	// stfsx f4,r10,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f10,f10,f21,f5
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f21.f64 + ctx.f5.f64));
	// stfsx f10,r10,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f5,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f5.f64 = double(temp.f32);
	// lfs f10,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f5,f11
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fmuls f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// fmsubs f10,f10,f12,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 - ctx.f4.f64));
	// stfsx f10,r9,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmadds f12,f5,f12,f11
	ctx.f12.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 + ctx.f11.f64));
	// stfsx f12,r9,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f12,f27,f31
	ctx.f12.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// lfs f5,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f5.f64 = double(temp.f32);
	// fadds f10,f26,f2
	ctx.f10.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// lfs f11,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f4,f26,f2
	ctx.f4.f64 = double(float(ctx.f26.f64 - ctx.f2.f64));
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// fmuls f31,f5,f8
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// subf r5,r29,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r29.s64;
	// fsubs f2,f12,f10
	ctx.f2.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f10,f7,f4
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// fadds f7,f4,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// fmuls f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// fmsubs f8,f11,f8,f5
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 - ctx.f5.f64));
	// stfs f8,0(r27)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fmadds f11,f11,f2,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f2.f64 + ctx.f31.f64));
	// stfs f11,0(r26)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// lfs f8,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f5,f8,f12
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// lfs f11,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// fmsubs f6,f11,f6,f5
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f6.f64 - ctx.f5.f64));
	// stfs f6,0(r23)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// fmadds f12,f11,f12,f8
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f12.f64 + ctx.f8.f64));
	// stfs f12,0(r24)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f8,f11,f1
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// fmsubs f10,f12,f10,f8
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 - ctx.f8.f64));
	// stfs f10,0(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmadds f12,f12,f1,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f1.f64 + ctx.f11.f64));
	// stfs f12,0(r6)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f11,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f11.f64 = double(temp.f32);
	// add r4,r29,r4
	ctx.r4.u64 = ctx.r29.u64 + ctx.r4.u64;
	// fmuls f10,f11,f9
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f12,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// subf r6,r29,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r29.s64;
	// addi r11,r11,88
	ctx.r11.s64 = ctx.r11.s64 + 88;
	// fmsubs f10,f12,f7,f10
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f7.f64 - ctx.f10.f64));
	// stfs f10,0(r22)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// fmadds f12,f12,f9,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 + ctx.f11.f64));
	// stfs f12,0(r25)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// lwz r10,3532(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d2c9b4
	if (!ctx.cr0.eq) goto loc_82D2C9B4;
loc_82D2CD6C:
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28f3c
	ctx.lr = 0x82D2CD74;
	__restfpr_18(ctx, base);
	// b 0x82e28e9c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2CD78"))) PPC_WEAK_FUNC(sub_82D2CD78);
PPC_FUNC_IMPL(__imp__sub_82D2CD78) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-6960
	ctx.r5.s64 = ctx.r11.s64 + -6960;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-13968
	ctx.r4.s64 = ctx.r11.s64 + -13968;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2CD90"))) PPC_WEAK_FUNC(sub_82D2CD90);
PPC_FUNC_IMPL(__imp__sub_82D2CD90) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D2CD98;
	__savegprlr_28(ctx, base);
	// addi r12,r1,-40
	ctx.r12.s64 = ctx.r1.s64 + -40;
	// bl 0x82e28ee8
	ctx.lr = 0x82D2CDA0;
	__savefpr_16(ctx, base);
	// mulli r11,r9,72
	ctx.r11.s64 = ctx.r9.s64 * 72;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-72
	ctx.r11.s64 = ctx.r11.s64 + -72;
	// bge cr6,0x82d2d110
	if (!ctx.cr6.lt) goto loc_82D2D110;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r29,r9,r10
	ctx.r29.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r31,-32255
	ctx.r31.s64 = -2113863680;
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f11,-12288(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -12288);
	ctx.f11.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f13,-7584(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -7584);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7588(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -7588);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,-7592(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7592);
	ctx.f12.f64 = double(temp.f32);
loc_82D2CDE4:
	// rlwinm r10,r8,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f10,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// mulli r7,r8,12
	ctx.r7.s64 = ctx.r8.s64 * 12;
	// lfs f9,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfs f7,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f6,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f3,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f21,f10,f6
	ctx.f21.f64 = double(float(ctx.f10.f64 + ctx.f6.f64));
	// lfsx f2,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 - ctx.f10.f64));
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f30,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f30.f64 = double(temp.f32);
	// rlwinm r9,r8,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f28,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f22,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f29,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f23,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f27,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f4,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f20,f27,f3
	ctx.f20.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// lfsx f26,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f3,f3,f27
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f27.f64));
	// lfsx f5,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f27,f2,f26
	ctx.f27.f64 = double(float(ctx.f2.f64 + ctx.f26.f64));
	// fadds f6,f4,f5
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// lfsx f31,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 - ctx.f2.f64));
	// lfsx f1,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfsx f25,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fadds f4,f31,f1
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// lfsx f24,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f26,f30,f25
	ctx.f26.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// fsubs f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// fadds f31,f9,f28
	ctx.f31.f64 = double(float(ctx.f9.f64 + ctx.f28.f64));
	// fsubs f30,f25,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 - ctx.f30.f64));
	// fadds f19,f24,f29
	ctx.f19.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// fsubs f9,f28,f9
	ctx.f9.f64 = double(float(ctx.f28.f64 - ctx.f9.f64));
	// fsubs f25,f7,f22
	ctx.f25.f64 = double(float(ctx.f7.f64 - ctx.f22.f64));
	// fsubs f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f24.f64));
	// fadds f28,f23,f8
	ctx.f28.f64 = double(float(ctx.f23.f64 + ctx.f8.f64));
	// fadds f7,f22,f7
	ctx.f7.f64 = double(float(ctx.f22.f64 + ctx.f7.f64));
	// fadds f22,f27,f6
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f6.f64));
	// fadds f24,f21,f20
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// fsubs f8,f8,f23
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f23.f64));
	// fadds f23,f10,f3
	ctx.f23.f64 = double(float(ctx.f10.f64 + ctx.f3.f64));
	// fadds f18,f2,f5
	ctx.f18.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// fsubs f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// fsubs f27,f21,f20
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fsubs f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// fsubs f2,f9,f30
	ctx.f2.f64 = double(float(ctx.f9.f64 - ctx.f30.f64));
	// fsubs f10,f10,f3
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f3.f64));
	// fsubs f3,f1,f29
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f29.f64));
	// fsubs f21,f22,f24
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// fadds f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// fsubs f17,f31,f26
	ctx.f17.f64 = double(float(ctx.f31.f64 - ctx.f26.f64));
	// fsubs f20,f18,f23
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// fsubs f16,f4,f19
	ctx.f16.f64 = double(float(ctx.f4.f64 - ctx.f19.f64));
	// fadds f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f30.f64));
	// fadds f4,f19,f4
	ctx.f4.f64 = double(float(ctx.f19.f64 + ctx.f4.f64));
	// fmuls f19,f27,f13
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// fadds f31,f31,f26
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f26.f64));
	// fadds f26,f23,f18
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// fmuls f22,f21,f12
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fadds f30,f24,f28
	ctx.f30.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// stfs f30,0(r3)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fnmsubs f28,f24,f11,f28
	ctx.f28.f64 = double(float(-(ctx.f24.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// fmuls f21,f20,f12
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmuls f20,f2,f13
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmuls f24,f27,f0
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fadds f23,f17,f16
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fadds f1,f29,f1
	ctx.f1.f64 = double(float(ctx.f29.f64 + ctx.f1.f64));
	// fsubs f18,f16,f17
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// fadds f30,f26,f8
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f8.f64));
	// fmsubs f27,f3,f0,f20
	ctx.f27.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f20.f64));
	// fmuls f20,f2,f0
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmsubs f2,f6,f0,f19
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 - ctx.f19.f64));
	// fadds f29,f23,f7
	ctx.f29.f64 = double(float(ctx.f23.f64 + ctx.f7.f64));
	// fmadds f6,f6,f13,f24
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f24.f64));
	// fmadds f3,f3,f13,f20
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f20.f64));
	// fadds f20,f9,f1
	ctx.f20.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// fsubs f9,f1,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 - ctx.f9.f64));
	// fsubs f1,f28,f22
	ctx.f1.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// fadds f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// fmuls f24,f18,f12
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// fnmsubs f7,f23,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f23.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// fnmsubs f8,f26,f11,f8
	ctx.f8.f64 = double(float(-(ctx.f26.f64 * ctx.f11.f64 - ctx.f8.f64)));
	// fadds f22,f20,f25
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// stfs f22,0(r5)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fnmsubs f25,f20,f11,f25
	ctx.f25.f64 = double(float(-(ctx.f20.f64 * ctx.f11.f64 - ctx.f25.f64)));
	// lfs f19,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f9,f9,f12
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// lfs f22,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f1,f27
	ctx.f20.f64 = double(float(ctx.f1.f64 - ctx.f27.f64));
	// fadds f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// fmuls f17,f19,f29
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f29.f64));
	// fmuls f19,f19,f30
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// fsubs f18,f28,f3
	ctx.f18.f64 = double(float(ctx.f28.f64 - ctx.f3.f64));
	// fadds f3,f28,f3
	ctx.f3.f64 = double(float(ctx.f28.f64 + ctx.f3.f64));
	// fmuls f28,f10,f13
	ctx.f28.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fsubs f27,f25,f9
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f9.f64));
	// fadds f9,f25,f9
	ctx.f9.f64 = double(float(ctx.f25.f64 + ctx.f9.f64));
	// fmsubs f30,f22,f30,f17
	ctx.f30.f64 = double(float(ctx.f22.f64 * ctx.f30.f64 - ctx.f17.f64));
	// stfsx f30,r9,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f30,f22,f29,f19
	ctx.f30.f64 = double(float(ctx.f22.f64 * ctx.f29.f64 + ctx.f19.f64));
	// stfsx f30,r9,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// lfs f29,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f29.f64 = double(temp.f32);
	// lfs f30,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f30.f64 = double(temp.f32);
	// fadds f25,f27,f2
	ctx.f25.f64 = double(float(ctx.f27.f64 + ctx.f2.f64));
	// fsubs f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 - ctx.f2.f64));
	// fadds f22,f9,f6
	ctx.f22.f64 = double(float(ctx.f9.f64 + ctx.f6.f64));
	// fsubs f9,f9,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// fmuls f6,f31,f13
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// fmuls f31,f31,f0
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f27,f29,f25
	ctx.f27.f64 = double(float(ctx.f29.f64 * ctx.f25.f64));
	// fmuls f25,f30,f25
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// fmsubs f30,f30,f20,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f20.f64 - ctx.f27.f64));
	// stfsx f30,r31,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f29,f20,f25
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f20.f64 + ctx.f25.f64));
	// stfsx f30,r31,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lfs f29,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f27,f29,f22
	ctx.f27.f64 = double(float(ctx.f29.f64 * ctx.f22.f64));
	// lfs f30,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f29,f29,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f18.f64));
	// fmsubs f27,f30,f18,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f18.f64 - ctx.f27.f64));
	// stfsx f27,r7,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f30,f22,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f22.f64 + ctx.f29.f64));
	// stfsx f30,r7,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// fmuls f27,f10,f0
	ctx.f27.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f29,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f10,f4,f0,f6
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 - ctx.f6.f64));
	// lfs f30,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f4,f4,f13,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f31.f64));
	// fmuls f31,f29,f2
	ctx.f31.f64 = double(float(ctx.f29.f64 * ctx.f2.f64));
	// fmuls f29,f29,f1
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f1.f64));
	// fmsubs f6,f5,f0,f28
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 - ctx.f28.f64));
	// fmadds f5,f5,f13,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 + ctx.f27.f64));
	// fmsubs f1,f30,f1,f31
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f1.f64 - ctx.f31.f64));
	// stfsx f1,r10,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f1,f7,f24
	ctx.f1.f64 = double(float(ctx.f7.f64 - ctx.f24.f64));
	// fmadds f2,f30,f2,f29
	ctx.f2.f64 = double(float(ctx.f30.f64 * ctx.f2.f64 + ctx.f29.f64));
	// stfsx f2,r10,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f30,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f31,f8,f21
	ctx.f31.f64 = double(float(ctx.f8.f64 - ctx.f21.f64));
	// fmuls f26,f30,f9
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// lfs f2,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f30,f3
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f3.f64));
	// fadds f7,f7,f24
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f24.f64));
	// fadds f8,f8,f21
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f21.f64));
	// fadds f29,f1,f6
	ctx.f29.f64 = double(float(ctx.f1.f64 + ctx.f6.f64));
	// fsubs f30,f31,f10
	ctx.f30.f64 = double(float(ctx.f31.f64 - ctx.f10.f64));
	// fmsubs f3,f2,f3,f26
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f26.f64));
	// stfsx f3,r9,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmadds f9,f2,f9,f25
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f25.f64));
	// stfsx f9,r9,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// lfs f3,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f27,f7,f5
	ctx.f27.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// lfs f9,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f9.f64 = double(temp.f32);
	// fadds f28,f8,f4
	ctx.f28.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// fadds f10,f31,f10
	ctx.f10.f64 = double(float(ctx.f31.f64 + ctx.f10.f64));
	// fmuls f2,f3,f29
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f29.f64));
	// fmuls f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// fmsubs f2,f9,f30,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f30.f64 - ctx.f2.f64));
	// stfsx f2,r7,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f1,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 - ctx.f6.f64));
	// add r3,r30,r3
	ctx.r3.u64 = ctx.r30.u64 + ctx.r3.u64;
	// fadds f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// subf r5,r30,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r30.s64;
	// fsubs f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// fmadds f9,f9,f29,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f29.f64 + ctx.f3.f64));
	// stfsx f9,r7,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// lfs f3,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f3,f27
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f9,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// fmsubs f2,f9,f28,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f28.f64 - ctx.f2.f64));
	// stfsx f2,r10,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f9,f9,f27,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f27.f64 + ctx.f3.f64));
	// stfsx f9,r10,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f3,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f5,f3,f6
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f9,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f4,f3,f10
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmsubs f10,f9,f10,f5
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f10.f64 - ctx.f5.f64));
	// stfsx f10,r31,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fmadds f10,f9,f6,f4
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f6.f64 + ctx.f4.f64));
	// stfsx f10,r31,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f9,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f6,f9,f7
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f10,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// addi r11,r11,72
	ctx.r11.s64 = ctx.r11.s64 + 72;
	// fmsubs f8,f10,f8,f6
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f8.f64 - ctx.f6.f64));
	// stfs f8,0(r4)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmadds f10,f10,f7,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f7.f64 + ctx.f9.f64));
	// stfs f10,0(r6)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lwz r10,3532(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3532);
	// add r4,r30,r4
	ctx.r4.u64 = ctx.r30.u64 + ctx.r4.u64;
	// subf r6,r30,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r30.s64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d2cde4
	if (!ctx.cr0.eq) goto loc_82D2CDE4;
loc_82D2D110:
	// addi r12,r1,-40
	ctx.r12.s64 = ctx.r1.s64 + -40;
	// bl 0x82e28f34
	ctx.lr = 0x82D2D118;
	__restfpr_16(ctx, base);
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2D120"))) PPC_WEAK_FUNC(sub_82D2D120);
PPC_FUNC_IMPL(__imp__sub_82D2D120) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-6904
	ctx.r5.s64 = ctx.r11.s64 + -6904;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-12912
	ctx.r4.s64 = ctx.r11.s64 + -12912;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2D138"))) PPC_WEAK_FUNC(sub_82D2D138);
PPC_FUNC_IMPL(__imp__sub_82D2D138) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82D2D140;
	__savegprlr_29(ctx, base);
	// addi r12,r1,-32
	ctx.r12.s64 = ctx.r1.s64 + -32;
	// bl 0x82e28f04
	ctx.lr = 0x82D2D148;
	__savefpr_23(ctx, base);
	// mulli r11,r9,56
	ctx.r11.s64 = ctx.r9.s64 * 56;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-56
	ctx.r11.s64 = ctx.r11.s64 + -56;
	// bge cr6,0x82d2d3ac
	if (!ctx.cr6.lt) goto loc_82D2D3AC;
	// subf r30,r9,r10
	ctx.r30.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f0,140(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D2D174:
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// lfs f13,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r9,r8,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f11,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f7,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f28,f9,f13
	ctx.f28.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// lfsx f8,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f26,f11,f7
	ctx.f26.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f6,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f25,f6,f10
	ctx.f25.f64 = double(float(ctx.f6.f64 - ctx.f10.f64));
	// fadds f27,f8,f12
	ctx.f27.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fadds f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// fsubs f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// lfsx f5,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f6.f64));
	// lfsx f3,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// lfsx f1,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f7,f5,f3
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// lfsx f31,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f9,f3,f5
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// lfsx f30,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f6,f1,f31
	ctx.f6.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// lfsx f29,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f5,f31,f1
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// lfsx f2,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f3,f30,f29
	ctx.f3.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// lfsx f4,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f8,f4,f2
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f2.f64));
	// fsubs f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// fadds f2,f29,f30
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fadds f1,f10,f12
	ctx.f1.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fadds f10,f9,f28
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f28.f64));
	// fadds f29,f6,f26
	ctx.f29.f64 = double(float(ctx.f6.f64 + ctx.f26.f64));
	// fsubs f30,f11,f7
	ctx.f30.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// fadds f23,f25,f3
	ctx.f23.f64 = double(float(ctx.f25.f64 + ctx.f3.f64));
	// fadds f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// fadds f31,f27,f8
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f8.f64));
	// fsubs f7,f26,f6
	ctx.f7.f64 = double(float(ctx.f26.f64 - ctx.f6.f64));
	// fadds f6,f2,f4
	ctx.f6.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fadds f24,f5,f13
	ctx.f24.f64 = double(float(ctx.f5.f64 + ctx.f13.f64));
	// fsubs f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f13,f13,f5
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f5.f64));
	// fsubs f5,f25,f3
	ctx.f5.f64 = double(float(ctx.f25.f64 - ctx.f3.f64));
	// fsubs f9,f28,f9
	ctx.f9.f64 = double(float(ctx.f28.f64 - ctx.f9.f64));
	// fsubs f2,f29,f23
	ctx.f2.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// fsubs f8,f8,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f27.f64));
	// fadds f3,f31,f10
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f10.f64));
	// stfs f3,0(r3)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f31.f64));
	// fadds f3,f23,f29
	ctx.f3.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// stfs f3,0(r5)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lfs f31,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f31.f64 = double(temp.f32);
	// lfs f3,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f29,f31,f2
	ctx.f29.f64 = double(float(ctx.f31.f64 * ctx.f2.f64));
	// fmuls f31,f31,f10
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f10.f64));
	// fmsubs f10,f3,f10,f29
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 - ctx.f29.f64));
	// stfsx f10,r9,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmadds f10,f3,f2,f31
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f2.f64 + ctx.f31.f64));
	// stfsx f10,r9,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f3,f5,f9
	ctx.f3.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// lfs f2,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f2.f64 = double(temp.f32);
	// fadds f31,f8,f7
	ctx.f31.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f9,f9,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f5.f64));
	// fsubs f5,f4,f12
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f12.f64));
	// fsubs f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// fadds f7,f1,f6
	ctx.f7.f64 = double(float(ctx.f1.f64 + ctx.f6.f64));
	// fadds f4,f12,f4
	ctx.f4.f64 = double(float(ctx.f12.f64 + ctx.f4.f64));
	// fsubs f1,f6,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// fmuls f12,f7,f0
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f6,f4,f0
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f7,f5,f0
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f4,f2,f31
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f5,f1,f0
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f2,f2,f3
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// fmsubs f4,f10,f3,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f3.f64 - ctx.f4.f64));
	// stfsx f4,r7,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fmadds f10,f10,f31,f2
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64 + ctx.f2.f64));
	// stfsx f10,r7,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// lfs f2,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f1,f13,f6
	ctx.f1.f64 = double(float(ctx.f13.f64 - ctx.f6.f64));
	// fsubs f31,f11,f5
	ctx.f31.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// lfs f10,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f10.f64 = double(temp.f32);
	// fadds f13,f6,f13
	ctx.f13.f64 = double(float(ctx.f6.f64 + ctx.f13.f64));
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// fmuls f6,f2,f8
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// fadds f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 + ctx.f11.f64));
	// fmuls f5,f2,f9
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// fadds f3,f7,f30
	ctx.f3.f64 = double(float(ctx.f7.f64 + ctx.f30.f64));
	// fsubs f4,f24,f12
	ctx.f4.f64 = double(float(ctx.f24.f64 - ctx.f12.f64));
	// fsubs f7,f30,f7
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f7.f64));
	// fadds f12,f12,f24
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f24.f64));
	// fmsubs f9,f10,f9,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 - ctx.f6.f64));
	// stfsx f9,r10,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fmadds f10,f10,f8,f5
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f8.f64 + ctx.f5.f64));
	// stfsx f10,r10,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// subf r5,r31,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r31.s64;
	// fmuls f8,f9,f3
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f9,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// fmsubs f8,f10,f4,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 - ctx.f8.f64));
	// stfsx f8,r7,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fmadds f10,f10,f3,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f3.f64 + ctx.f9.f64));
	// stfsx f10,r7,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// lfs f9,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f9,f7
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f10,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f9,f12
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// fmsubs f12,f10,f12,f8
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 - ctx.f8.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f10,f7,f9
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f7.f64 + ctx.f9.f64));
	// stfsx f12,r10,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f10,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f10,f31
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// lfs f12,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f1
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f1.f64));
	// fmsubs f9,f12,f1,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f1.f64 - ctx.f9.f64));
	// stfsx f9,r9,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f31,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64 + ctx.f10.f64));
	// stfsx f12,r9,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// lfs f10,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f10,f11
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f13
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// addi r11,r11,56
	ctx.r11.s64 = ctx.r11.s64 + 56;
	// fmsubs f13,f12,f13,f9
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 - ctx.f9.f64));
	// stfs f13,0(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmadds f13,f12,f11,f10
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f10.f64));
	// stfs f13,0(r6)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lwz r10,3532(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3532);
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// subf r6,r31,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r31.s64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d2d174
	if (!ctx.cr0.eq) goto loc_82D2D174;
loc_82D2D3AC:
	// addi r12,r1,-32
	ctx.r12.s64 = ctx.r1.s64 + -32;
	// bl 0x82e28f50
	ctx.lr = 0x82D2D3B4;
	__restfpr_23(ctx, base);
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2D3B8"))) PPC_WEAK_FUNC(sub_82D2D3B8);
PPC_FUNC_IMPL(__imp__sub_82D2D3B8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-6848
	ctx.r5.s64 = ctx.r11.s64 + -6848;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-11976
	ctx.r4.s64 = ctx.r11.s64 + -11976;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2D3D0"))) PPC_WEAK_FUNC(sub_82D2D3D0);
PPC_FUNC_IMPL(__imp__sub_82D2D3D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D2D3D8;
	__savegprlr_26(ctx, base);
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28f18
	ctx.lr = 0x82D2D3E0;
	__savefpr_28(ctx, base);
	// mulli r11,r9,40
	ctx.r11.s64 = ctx.r9.s64 * 40;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-40
	ctx.r11.s64 = ctx.r11.s64 + -40;
	// bge cr6,0x82d2d5cc
	if (!ctx.cr6.lt) goto loc_82D2D5CC;
	// subf r31,r9,r10
	ctx.r31.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f13,-28552(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f0.f64 = double(temp.f32);
loc_82D2D414:
	// rlwinm r9,r8,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f11,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// add r30,r9,r3
	ctx.r30.u64 = ctx.r9.u64 + ctx.r3.u64;
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// add r29,r10,r5
	ctx.r29.u64 = ctx.r10.u64 + ctx.r5.u64;
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// add r28,r9,r4
	ctx.r28.u64 = ctx.r9.u64 + ctx.r4.u64;
	// add r27,r9,r5
	ctx.r27.u64 = ctx.r9.u64 + ctx.r5.u64;
	// lfsx f7,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// add r9,r9,r6
	ctx.r9.u64 = ctx.r9.u64 + ctx.r6.u64;
	// lfs f8,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// lfs f6,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fadds f31,f12,f8
	ctx.f31.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// fsubs f12,f8,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 - ctx.f12.f64));
	// lfsx f4,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fadds f8,f7,f6
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f6.f64));
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f7.f64));
	// fsubs f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfs f2,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f30,f3,f11
	ctx.f30.f64 = double(float(ctx.f3.f64 - ctx.f11.f64));
	// lfs f1,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fadds f11,f11,f3
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f3.f64));
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fadds f4,f2,f10
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f10.f64));
	// fsubs f10,f10,f2
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f2.f64));
	// fsubs f3,f9,f1
	ctx.f3.f64 = double(float(ctx.f9.f64 - ctx.f1.f64));
	// fadds f9,f1,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 + ctx.f9.f64));
	// fadds f2,f8,f31
	ctx.f2.f64 = double(float(ctx.f8.f64 + ctx.f31.f64));
	// fsubs f31,f31,f8
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f8.f64));
	// fadds f1,f7,f12
	ctx.f1.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fadds f8,f6,f30
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f30.f64));
	// fsubs f30,f6,f30
	ctx.f30.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// fsubs f6,f5,f11
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f11.f64));
	// fsubs f7,f12,f7
	ctx.f7.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// fadds f5,f5,f11
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f11.f64));
	// fmuls f12,f31,f0
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fadds f31,f2,f4
	ctx.f31.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// stfs f31,0(r3)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f31,f1,f10
	ctx.f31.f64 = double(float(ctx.f1.f64 + ctx.f10.f64));
	// fnmsubs f4,f2,f13,f4
	ctx.f4.f64 = double(float(-(ctx.f2.f64 * ctx.f13.f64 - ctx.f4.f64)));
	// fsubs f28,f9,f6
	ctx.f28.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// fmuls f11,f30,f0
	ctx.f11.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fadds f30,f8,f3
	ctx.f30.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// stfs f30,0(r5)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fnmsubs f8,f8,f13,f3
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f13.f64 - ctx.f3.f64)));
	// lfs f29,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f29.f64 = double(temp.f32);
	// lfs f30,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fnmsubs f10,f1,f13,f10
	ctx.f10.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// subf r5,r7,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r7.s64;
	// fmadds f9,f6,f13,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f9.f64));
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f2,f29,f28
	ctx.f2.f64 = double(float(ctx.f29.f64 * ctx.f28.f64));
	// fmuls f29,f29,f31
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f31.f64));
	// fsubs f3,f4,f11
	ctx.f3.f64 = double(float(ctx.f4.f64 - ctx.f11.f64));
	// fadds f11,f4,f11
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f11.f64));
	// fsubs f4,f8,f12
	ctx.f4.f64 = double(float(ctx.f8.f64 - ctx.f12.f64));
	// fadds f12,f8,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fsubs f6,f10,f5
	ctx.f6.f64 = double(float(ctx.f10.f64 - ctx.f5.f64));
	// fmsubs f2,f30,f31,f2
	ctx.f2.f64 = double(float(ctx.f30.f64 * ctx.f31.f64 - ctx.f2.f64));
	// stfsx f2,r10,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f8,f30,f28,f29
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f28.f64 + ctx.f29.f64));
	// stfsx f8,r10,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f2,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f2.f64 = double(temp.f32);
	// lfs f8,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f31,f2,f4
	ctx.f31.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// fmsubs f31,f8,f3,f31
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f3.f64 - ctx.f31.f64));
	// stfsx f31,r10,r3
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmuls f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// add r3,r7,r3
	ctx.r3.u64 = ctx.r7.u64 + ctx.r3.u64;
	// fmadds f8,f8,f4,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f4.f64 + ctx.f3.f64));
	// stfs f8,0(r29)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// lfs f4,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f4.f64 = double(temp.f32);
	// lfs f8,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f3,f4,f12
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// fmuls f2,f4,f11
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fadds f4,f9,f7
	ctx.f4.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// fmsubs f11,f8,f11,f3
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f11.f64 - ctx.f3.f64));
	// stfs f11,0(r30)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fmadds f12,f8,f12,f2
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 + ctx.f2.f64));
	// stfs f12,0(r27)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f9,f9,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// fadds f10,f10,f5
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f5.f64));
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f8,f11,f4
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// fmuls f11,f11,f6
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// fmsubs f8,f12,f6,f8
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f6.f64 - ctx.f8.f64));
	// stfs f8,0(r4)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmadds f12,f12,f4,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f4.f64 + ctx.f11.f64));
	// stfs f12,0(r6)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f11,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f11.f64 = double(temp.f32);
	// add r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fmuls f8,f11,f9
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f12,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// subf r6,r7,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r7.s64;
	// addi r11,r11,40
	ctx.r11.s64 = ctx.r11.s64 + 40;
	// fmsubs f10,f12,f10,f8
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 - ctx.f8.f64));
	// stfs f10,0(r28)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fmadds f12,f12,f9,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 + ctx.f11.f64));
	// stfs f12,0(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lwz r10,3532(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d2d414
	if (!ctx.cr0.eq) goto loc_82D2D414;
loc_82D2D5CC:
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28f64
	ctx.lr = 0x82D2D5D4;
	__restfpr_28(ctx, base);
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2D5D8"))) PPC_WEAK_FUNC(sub_82D2D5D8);
PPC_FUNC_IMPL(__imp__sub_82D2D5D8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-6792
	ctx.r5.s64 = ctx.r11.s64 + -6792;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-11312
	ctx.r4.s64 = ctx.r11.s64 + -11312;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2D5F0"))) PPC_WEAK_FUNC(sub_82D2D5F0);
PPC_FUNC_IMPL(__imp__sub_82D2D5F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D2D5F8;
	__savegprlr_28(ctx, base);
	// mulli r11,r9,24
	ctx.r11.s64 = ctx.r9.s64 * 24;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-24
	ctx.r11.s64 = ctx.r11.s64 + -24;
	// bge cr6,0x82d2d71c
	if (!ctx.cr6.lt) goto loc_82D2D71C;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r9,r9,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D2D61C:
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// add r31,r10,r5
	ctx.r31.u64 = ctx.r10.u64 + ctx.r5.u64;
	// lfs f12,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// add r30,r10,r3
	ctx.r30.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lfs f11,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// add r29,r10,r6
	ctx.r29.u64 = ctx.r10.u64 + ctx.r6.u64;
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lfs f10,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fadds f6,f10,f0
	ctx.f6.f64 = double(float(ctx.f10.f64 + ctx.f0.f64));
	// lfs f8,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fadds f5,f13,f9
	ctx.f5.f64 = double(float(ctx.f13.f64 + ctx.f9.f64));
	// lfs f7,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f4,f12,f8
	ctx.f4.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// fsubs f3,f7,f11
	ctx.f3.f64 = double(float(ctx.f7.f64 - ctx.f11.f64));
	// fadds f12,f8,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fsubs f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// fsubs f0,f0,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f10.f64));
	// fadds f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f7.f64));
	// fadds f10,f5,f6
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// stfs f10,0(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f10,f6,f5
	ctx.f10.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// add r3,r7,r3
	ctx.r3.u64 = ctx.r7.u64 + ctx.r3.u64;
	// fsubs f8,f4,f3
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fadds f9,f3,f4
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// stfs f9,0(r5)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lfs f7,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f7.f64 = double(temp.f32);
	// fadds f6,f13,f12
	ctx.f6.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// fsubs f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// lfs f9,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f5,f0,f11
	ctx.f5.f64 = double(float(ctx.f0.f64 - ctx.f11.f64));
	// subf r5,r7,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r7.s64;
	// fadds f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// fmuls f11,f7,f10
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// fmuls f12,f7,f8
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// fmsubs f12,f9,f10,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f10.f64 - ctx.f12.f64));
	// stfs f12,0(r30)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fmadds f12,f9,f8,f11
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 + ctx.f11.f64));
	// stfs f12,0(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f11,f6
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// fmsubs f10,f12,f5,f10
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f5.f64 - ctx.f10.f64));
	// stfs f10,0(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmadds f12,f12,f6,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f6.f64 + ctx.f11.f64));
	// stfs f12,0(r6)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// add r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fmuls f10,f11,f13
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// subf r6,r7,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r7.s64;
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// fmsubs f0,f12,f0,f10
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 - ctx.f10.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// fmadds f0,f12,f13,f11
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + ctx.f11.f64));
	// stfs f0,0(r29)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// lwz r10,3532(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d2d61c
	if (!ctx.cr0.eq) goto loc_82D2D61C;
loc_82D2D71C:
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2D720"))) PPC_WEAK_FUNC(sub_82D2D720);
PPC_FUNC_IMPL(__imp__sub_82D2D720) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-6736
	ctx.r5.s64 = ctx.r11.s64 + -6736;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-10768
	ctx.r4.s64 = ctx.r11.s64 + -10768;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2D738"))) PPC_WEAK_FUNC(sub_82D2D738);
PPC_FUNC_IMPL(__imp__sub_82D2D738) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// addi r11,r11,-8
	ctx.r11.s64 = ctx.r11.s64 + -8;
	// bgelr cr6
	if (!ctx.cr6.lt) return;
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D2D758:
	// lfs f13,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lfs f0,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fadds f10,f13,f0
	ctx.f10.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// lfs f12,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// fsubs f13,f12,f11
	ctx.f13.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// stfs f10,0(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// stfs f13,0(r5)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// add r3,r8,r3
	ctx.r3.u64 = ctx.r8.u64 + ctx.r3.u64;
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// subf r5,r8,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r8.s64;
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// fmuls f10,f11,f12
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmsubs f0,f13,f0,f10
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 - ctx.f10.f64));
	// stfs f0,0(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmadds f0,f13,f12,f11
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f11.f64));
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// add r4,r8,r4
	ctx.r4.u64 = ctx.r8.u64 + ctx.r4.u64;
	// subf r6,r8,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r8.s64;
	// bne 0x82d2d758
	if (!ctx.cr0.eq) goto loc_82D2D758;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D2D7C0"))) PPC_WEAK_FUNC(sub_82D2D7C0);
PPC_FUNC_IMPL(__imp__sub_82D2D7C0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-6680
	ctx.r5.s64 = ctx.r11.s64 + -6680;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-10440
	ctx.r4.s64 = ctx.r11.s64 + -10440;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2D7D8"))) PPC_WEAK_FUNC(sub_82D2D7D8);
PPC_FUNC_IMPL(__imp__sub_82D2D7D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D2D7E0;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D2D7E8;
	__savefpr_14(ctx, base);
	// stwu r1,-656(r1)
	ea = -656 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d2f140
	if (!ctx.cr6.gt) goto loc_82D2F140;
	// lwz r11,748(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	// lis r30,-32229
	ctx.r30.s64 = -2112159744;
	// lis r29,-32236
	ctx.r29.s64 = -2112618496;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lfs f11,-13884(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -13884);
	ctx.f11.f64 = double(temp.f32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// stfs f11,328(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// stw r11,332(r1)
	PPC_STORE_U32(ctx.r1.u32 + 332, ctx.r11.u32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lwz r11,740(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f11,120(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 120);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f31,-6500(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -6500);
	ctx.f31.f64 = double(temp.f32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f1,-6504(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -6504);
	ctx.f1.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f2,-8144(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -8144);
	ctx.f2.f64 = double(temp.f32);
	// lis r28,-32236
	ctx.r28.s64 = -2112618496;
	// lfs f3,-8140(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -8140);
	ctx.f3.f64 = double(temp.f32);
	// lis r31,-32236
	ctx.r31.s64 = -2112618496;
	// lfs f4,-8136(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -8136);
	ctx.f4.f64 = double(temp.f32);
	// stw r11,340(r1)
	PPC_STORE_U32(ctx.r1.u32 + 340, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f5,-8132(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -8132);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,-8128(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -8128);
	ctx.f6.f64 = double(temp.f32);
	// lis r14,-32234
	ctx.r14.s64 = -2112487424;
	// lfs f7,124(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 124);
	ctx.f7.f64 = double(temp.f32);
	// lis r15,-32234
	ctx.r15.s64 = -2112487424;
	// lfs f12,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lis r16,-32234
	ctx.r16.s64 = -2112487424;
	// stw r11,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f13,-8016(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lis r17,-32234
	ctx.r17.s64 = -2112487424;
	// lfs f30,-6496(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -6496);
	ctx.f30.f64 = double(temp.f32);
	// lis r18,-32234
	ctx.r18.s64 = -2112487424;
	// lfs f29,-6492(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -6492);
	ctx.f29.f64 = double(temp.f32);
	// stfs f11,344(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// stw r11,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,236(r1)
	PPC_STORE_U32(ctx.r1.u32 + 236, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,252(r1)
	PPC_STORE_U32(ctx.r1.u32 + 252, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,68(r1)
	PPC_STORE_U32(ctx.r1.u32 + 68, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,216(r1)
	PPC_STORE_U32(ctx.r1.u32 + 216, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,240(r1)
	PPC_STORE_U32(ctx.r1.u32 + 240, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,56(r1)
	PPC_STORE_U32(ctx.r1.u32 + 56, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,72(r1)
	PPC_STORE_U32(ctx.r1.u32 + 72, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,16(r1)
	PPC_STORE_U32(ctx.r1.u32 + 16, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,232(r1)
	PPC_STORE_U32(ctx.r1.u32 + 232, ctx.r11.u32);
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f0,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
	// lwz r11,232(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	// lfs f28,-6528(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + -6528);
	ctx.f28.f64 = double(temp.f32);
	// lfs f27,-6524(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + -6524);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,-6516(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + -6516);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,-6512(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + -6512);
	ctx.f25.f64 = double(temp.f32);
	// lfs f11,-8004(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -8004);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,-8000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -8000);
	ctx.f10.f64 = double(temp.f32);
	// lwz r11,16(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// lfs f24,-6584(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6584);
	ctx.f24.f64 = double(temp.f32);
	// lwz r11,72(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	// lfs f9,-6580(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6580);
	ctx.f9.f64 = double(temp.f32);
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stfs f9,260(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f23,-6576(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6576);
	ctx.f23.f64 = double(temp.f32);
	// lwz r11,160(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// stfs f23,348(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// lfs f9,-6572(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6572);
	ctx.f9.f64 = double(temp.f32);
	// lwz r11,224(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	// stfs f9,300(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f9,-6568(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6568);
	ctx.f9.f64 = double(temp.f32);
	// lwz r11,56(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	// stfs f9,288(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f9,-6564(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6564);
	ctx.f9.f64 = double(temp.f32);
	// lwz r11,240(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	// stfs f9,232(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f9,-6560(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6560);
	ctx.f9.f64 = double(temp.f32);
	// lwz r11,216(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	// stfs f9,284(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f9,-6556(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6556);
	ctx.f9.f64 = double(temp.f32);
	// lwz r11,68(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	// stfs f9,280(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f9,-8012(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -8012);
	ctx.f9.f64 = double(temp.f32);
	// lwz r11,116(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lfs f8,-8008(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -8008);
	ctx.f8.f64 = double(temp.f32);
	// lwz r11,164(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// lfs f22,-6552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6552);
	ctx.f22.f64 = double(temp.f32);
	// lwz r11,252(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// stfs f22,248(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f22,-6548(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6548);
	ctx.f22.f64 = double(temp.f32);
	// lwz r11,244(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// stfs f22,228(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f22,-6544(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6544);
	ctx.f22.f64 = double(temp.f32);
	// lwz r11,136(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// stfs f22,216(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f22,-6540(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6540);
	ctx.f22.f64 = double(temp.f32);
	// lwz r11,236(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// stfs f22,272(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f22,-6536(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6536);
	ctx.f22.f64 = double(temp.f32);
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// stfs f22,220(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f22,-6532(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6532);
	ctx.f22.f64 = double(temp.f32);
	// lwz r11,212(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// stfs f22,204(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f22,-6520(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6520);
	ctx.f22.f64 = double(temp.f32);
	// lwz r11,208(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	// stfs f22,336(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f22,-6508(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6508);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,240(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
loc_82D2DA24:
	// rlwinm r11,r8,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f22,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// mulli r10,r8,92
	ctx.r10.s64 = ctx.r8.s64 * 92;
	// lfs f21,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f20,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f19,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f19.f64 = double(temp.f32);
	// rlwinm r11,r9,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// mulli r10,r9,92
	ctx.r10.s64 = ctx.r9.s64 * 92;
	// lfsx f18,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f17,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// lfsx f16,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r8,96
	ctx.r11.s64 = ctx.r8.s64 * 96;
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r9,28
	ctx.r11.s64 = ctx.r9.s64 * 28;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// mulli r11,r9,96
	ctx.r11.s64 = ctx.r9.s64 * 96;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// mulli r11,r8,124
	ctx.r11.s64 = ctx.r8.s64 * 124;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fsubs f14,f20,f19
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// mulli r11,r9,124
	ctx.r11.s64 = ctx.r9.s64 * 124;
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfsx f19,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,52(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fadds f19,f17,f18
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// rlwinm r11,r8,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 6) & 0xFFFFFFC0;
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// mulli r10,r8,60
	ctx.r10.s64 = ctx.r8.s64 * 60;
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,72(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f17,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// rlwinm r11,r9,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 6) & 0xFFFFFFC0;
	// stfs f17,48(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// mulli r10,r9,60
	ctx.r10.s64 = ctx.r9.s64 * 60;
	// lfsx f17,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,44(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f17,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,88(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// mulli r10,r8,108
	ctx.r10.s64 = ctx.r8.s64 * 108;
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f16,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f21
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// stfs f15,160(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fadds f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// fsubs f15,f14,f19
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,56(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f19,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfs f19,48(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// rlwinm r11,r9,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// fadds f14,f16,f18
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f18,68(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f18
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f21
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// stfs f16,224(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// stfs f21,136(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f21,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f21.f64 = double(temp.f32);
	// lfs f16,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f21,f16
	ctx.f16.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfs f16,116(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f16,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// fsubs f16,f22,f19
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f16,172(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f22,244(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// fadds f19,f22,f15
	ctx.f19.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// fsubs f16,f15,f22
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f15,f22,f17
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f19,320(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// fmuls f19,f16,f0
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f19,160(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fmuls f19,f15,f0
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f19,236(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f19,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f22,252(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fadds f22,f19,f17
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// lfs f17,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f17,f18
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f16,80(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// stfs f18,316(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fadds f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,120(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f17,f21,f20
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f17,196(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// lfsx f20,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r11,r8,80
	ctx.r11.s64 = ctx.r8.s64 * 80;
	// stfs f21,112(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfsx f21,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f16,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r8,44
	ctx.r11.s64 = ctx.r8.s64 * 44;
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r9,80
	ctx.r11.s64 = ctx.r9.s64 * 80;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// mulli r11,r9,44
	ctx.r11.s64 = ctx.r9.s64 * 44;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// mulli r10,r9,108
	ctx.r10.s64 = ctx.r9.s64 * 108;
	// lfsx f17,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r8,12
	ctx.r11.s64 = ctx.r8.s64 * 12;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r8,112
	ctx.r11.s64 = ctx.r8.s64 * 112;
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fadds f14,f17,f20
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f20,36(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f20,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r11,r9,112
	ctx.r11.s64 = ctx.r9.s64 * 112;
	// lfsx f17,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,32(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// mulli r11,r8,48
	ctx.r11.s64 = ctx.r8.s64 * 48;
	// stfs f17,64(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fadds f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f16,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r8,76
	ctx.r11.s64 = ctx.r8.s64 * 76;
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,44(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r9,48
	ctx.r11.s64 = ctx.r9.s64 * 48;
	// fadds f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f17,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// mulli r11,r9,76
	ctx.r11.s64 = ctx.r9.s64 * 76;
	// lfsx f17,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f15,88(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f15,72(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f20,56(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f20,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f16,f15
	ctx.f15.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,116(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f16,f20,f12
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// lfs f20,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f15,72(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// mulli r10,r8,116
	ctx.r10.s64 = ctx.r8.s64 * 116;
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f20,164(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f20,f20,f13,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f20,208(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// stfs f17,68(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fadds f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f20,f20,f13,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f20,124(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f20,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f17,f20,f16
	ctx.f17.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f17,32(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// fsubs f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f20,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f20,f12
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f21
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f17,f20
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f15,184(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f20,108(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f20,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f20,f12
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// lfs f20,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f15,304(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f20,192(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f20,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f15,176(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,168(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f20,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f13,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f20,324(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f20,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f20,f20,f13,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f17.f64));
	// fsubs f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfs f20,212(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// lfs f20,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f17.f64 = double(temp.f32);
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// lfs f16,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f16.f64 = double(temp.f32);
	// stfs f15,88(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmuls f14,f16,f13
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// lfsx f15,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// mulli r10,r9,116
	ctx.r10.s64 = ctx.r9.s64 * 116;
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmsubs f14,f15,f12,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f14.f64));
	// mulli r11,r8,72
	ctx.r11.s64 = ctx.r8.s64 * 72;
	// stfs f14,116(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfsx f16,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f15,f13,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f15,72(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r8,52
	ctx.r11.s64 = ctx.r8.s64 * 52;
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// mulli r11,r9,72
	ctx.r11.s64 = ctx.r9.s64 * 72;
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// mulli r11,r9,52
	ctx.r11.s64 = ctx.r9.s64 * 52;
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,68(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fmuls f15,f17,f13
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// mulli r11,r8,20
	ctx.r11.s64 = ctx.r8.s64 * 20;
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r8,104
	ctx.r11.s64 = ctx.r8.s64 * 104;
	// fsubs f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f14,312(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f21,308(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f21,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f21,60(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fmsubs f21,f20,f12,f15
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 - ctx.f15.f64));
	// stfs f21,164(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfsx f21,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f20,f20,f13,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f17.f64));
	// mulli r11,r8,40
	ctx.r11.s64 = ctx.r8.s64 * 40;
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// stfs f20,88(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fsubs f20,f17,f16
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,92(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r8,84
	ctx.r11.s64 = ctx.r8.s64 * 84;
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f16,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// mulli r11,r9,20
	ctx.r11.s64 = ctx.r9.s64 * 20;
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// mulli r11,r9,104
	ctx.r11.s64 = ctx.r9.s64 * 104;
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r9,40
	ctx.r11.s64 = ctx.r9.s64 * 40;
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r9,84
	ctx.r11.s64 = ctx.r9.s64 * 84;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r8,120
	ctx.r10.s64 = ctx.r8.s64 * 120;
	// fadds f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// stfs f14,256(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// fadds f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,24(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,36(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f17,f20,f16
	ctx.f17.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f20,64(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f16,f15
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfs f15,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f15.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f16,f14,f15
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f16,f14
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f14,292(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,296(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fadds f16,f17,f15
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f16,156(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,132(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fsubs f14,f20,f21
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// lfs f20,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// stfs f21,16(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,56(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f20,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r11,r8,56
	ctx.r11.s64 = ctx.r8.s64 * 56;
	// stfs f20,68(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// lfs f17,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f17.f64 = double(temp.f32);
	// fmr f21,f17
	ctx.f21.f64 = ctx.f17.f64;
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f20,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,36(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f20,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f21
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f20,24(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f20,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,92(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f20,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f17,f14,f0
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,32(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f20,f15,f0
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r8,68
	ctx.r11.s64 = ctx.r8.s64 * 68;
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r8,36
	ctx.r11.s64 = ctx.r8.s64 * 36;
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// mulli r11,r8,88
	ctx.r11.s64 = ctx.r8.s64 * 88;
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,152(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// mulli r11,r9,36
	ctx.r11.s64 = ctx.r9.s64 * 36;
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,148(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// mulli r11,r9,88
	ctx.r11.s64 = ctx.r9.s64 * 88;
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r8,24
	ctx.r11.s64 = ctx.r8.s64 * 24;
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,268(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,264(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// stfs f14,104(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f14,128(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,96(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f17,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,144(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f20,256(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fsubs f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// lfsx f20,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r11,r8,100
	ctx.r11.s64 = ctx.r8.s64 * 100;
	// stfs f21,140(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f17,f16,f21
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f16.f64));
	// stfs f21,76(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f21,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// mulli r11,r9,24
	ctx.r11.s64 = ctx.r9.s64 * 24;
	// lfs f16,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f17.f64 = double(temp.f32);
	// mulli r10,r9,120
	ctx.r10.s64 = ctx.r9.s64 * 120;
	// fadds f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,32(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f17,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r9,100
	ctx.r11.s64 = ctx.r9.s64 * 100;
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,92(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f16,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r9,56
	ctx.r11.s64 = ctx.r9.s64 * 56;
	// stfs f16,84(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfsx f16,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,40(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r9,68
	ctx.r11.s64 = ctx.r9.s64 * 68;
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,100(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fsubs f14,f20,f21
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f21,24(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f21,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r11,r7,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f20,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f20.f64 = double(temp.f32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f21,148(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f20,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f20.f64 = double(temp.f32);
	// fadds f21,f20,f17
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f20,60(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f20,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f20
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f17,188(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f20,28(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f17,f17,f20
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f17,200(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,64(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,36(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f17,f14,f21
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,100(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,84(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r10,r7,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// mulli r31,r7,96
	ctx.r31.s64 = ctx.r7.s64 * 96;
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,152(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f16,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f22
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f16,276(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f16,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,92(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// rlwinm r30,r7,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,184(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f22,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f21,f20
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f22,180(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f22,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f22.f64 = double(temp.f32);
	// mulli r29,r7,112
	ctx.r29.s64 = ctx.r7.s64 * 112;
	// fadds f16,f17,f22
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// fadds f22,f21,f20
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,200(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f21,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f20.f64 = double(temp.f32);
	// mulli r28,r7,80
	ctx.r28.s64 = ctx.r7.s64 * 80;
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// lfs f20,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f20.f64 = double(temp.f32);
	// stfs f22,188(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmr f22,f20
	ctx.f22.f64 = ctx.f20.f64;
	// stfs f21,120(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fmuls f20,f14,f0
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f21,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// stfs f21,168(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f21,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f21,28(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f21,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f22,24(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fmuls f21,f16,f0
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f16,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f14,f0
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f15,188(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f15,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f15,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,148(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,292(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f14,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f21,f15
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fsubs f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// stfs f21,120(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f21,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f21.f64 = double(temp.f32);
	// fadds f15,f21,f20
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,168(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f15,f20,f21
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f21,20(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f21,f17,f22
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f21,152(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,200(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f22,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f21,f16,f22
	ctx.f21.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// stfs f21,40(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fadds f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// lfs f20,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// stfs f22,28(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f22,f20,f21
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// lfs f15,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f16,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f20,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f15,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// stfs f14,84(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// stfs f21,180(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmuls f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// stfs f16,0(r3)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f22
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// fmuls f14,f17,f6
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// fmuls f21,f21,f7
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f7.f64));
	// fmuls f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f15.f64));
	// stfsx f22,r11,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fadds f15,f16,f20
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// fsubs f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// lfs f22,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f22,f6
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// lfs f22,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f22.f64));
	// stfsx f15,r10,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmuls f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f22.f64));
	// stfsx f22,r31,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f7,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 + ctx.f14.f64));
	// stfsx f22,r30,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f6,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 - ctx.f21.f64));
	// stfsx f22,r29,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f20,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f22,f17,f7,f16
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 - ctx.f16.f64));
	// stfsx f22,r28,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f17,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f17.f64 = double(temp.f32);
	// mulli r27,r7,48
	ctx.r27.s64 = ctx.r7.s64 * 48;
	// fadds f22,f17,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f15,f16
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// fadds f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f18,f14
	ctx.f15.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// rlwinm r26,r7,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f19
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfs f19,176(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f14,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f14.f64 = double(temp.f32);
	// mulli r25,r7,72
	ctx.r25.s64 = ctx.r7.s64 * 72;
	// lfs f19,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f14,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f6
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f6.f64));
	// mulli r24,r7,56
	ctx.r24.s64 = ctx.r7.s64 * 56;
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f19,92(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f19,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f7,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 + ctx.f14.f64));
	// stfsx f19,r27,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fadds f19,f21,f22
	ctx.f19.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// mulli r23,r7,120
	ctx.r23.s64 = ctx.r7.s64 * 120;
	// fsubs f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// fadds f14,f17,f20
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// fsubs f17,f20,f17
	ctx.f17.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// mulli r22,r7,40
	ctx.r22.s64 = ctx.r7.s64 * 40;
	// fmuls f22,f19,f0
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fmuls f21,f21,f0
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fmuls f20,f14,f0
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmuls f19,f17,f0
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f17,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f17.f64 = double(temp.f32);
	// mulli r21,r7,104
	ctx.r21.s64 = ctx.r7.s64 * 104;
	// mulli r20,r7,24
	ctx.r20.s64 = ctx.r7.s64 * 24;
	// mulli r19,r7,88
	ctx.r19.s64 = ctx.r7.s64 * 88;
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// stfs f14,268(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fadds f14,f20,f16
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// stfs f14,108(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fadds f14,f19,f18
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f14,296(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fsubs f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// stfs f17,84(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fsubs f17,f15,f22
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f20,180(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fadds f16,f22,f15
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// lfs f22,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f16,276(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fsubs f21,f18,f19
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f21,264(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fmuls f20,f20,f2
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f2.f64));
	// fmuls f16,f16,f2
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// fmuls f14,f22,f2
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// fmuls f22,f22,f3
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f3.f64));
	// lfs f21,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f21,f4
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f4.f64));
	// stfs f22,108(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmuls f18,f21,f5
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// lfs f21,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f15,f21,f5
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// fmuls f21,f21,f4
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f4.f64));
	// fmadds f19,f17,f5,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f5.f64 + ctx.f19.f64));
	// stfsx f19,r26,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f19,f17,f4,f18
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 - ctx.f18.f64));
	// stfsx f19,r25,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// lfs f19,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f19.f64 = double(temp.f32);
	// fmr f22,f19
	ctx.f22.f64 = ctx.f19.f64;
	// fmadds f19,f22,f4,f15
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f4.f64 + ctx.f15.f64));
	// stfsx f19,r24,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f22,f22,f5,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64 - ctx.f21.f64));
	// stfsx f22,r23,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f22.f64 = double(temp.f32);
	// mulli r18,r7,12
	ctx.r18.s64 = ctx.r7.s64 * 12;
	// fmadds f22,f22,f3,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f16.f64));
	// stfsx f22,r22,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f22.f64 = double(temp.f32);
	// mulli r17,r7,76
	ctx.r17.s64 = ctx.r7.s64 * 76;
	// fmsubs f22,f22,f3,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 - ctx.f20.f64));
	// stfsx f22,r21,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f21,f22,f3,f14
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f14.f64));
	// stfsx f21,r20,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f22,f22,f2,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f2.f64 - ctx.f21.f64));
	// stfsx f22,r19,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f20,f22,f21
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f22,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f19,f22,f13
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f21,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f21,f12
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f22,f12
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f21,f13
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// mulli r16,r7,60
	ctx.r16.s64 = ctx.r7.s64 * 60;
	// fmuls f22,f20,f0
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f20,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f21,f18,f12,f19
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 - ctx.f19.f64));
	// lfs f19,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fmadds f19,f17,f13,f16
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f16.f64));
	// mulli r15,r7,124
	ctx.r15.s64 = ctx.r7.s64 * 124;
	// fmsubs f17,f17,f12,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f14.f64));
	// fmadds f18,f18,f13,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f15.f64));
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f15,f22
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// mulli r14,r7,44
	ctx.r14.s64 = ctx.r7.s64 * 44;
	// fadds f15,f19,f21
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// fadds f19,f17,f18
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// fadds f14,f21,f22
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f14,112(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,132(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fsubs f22,f16,f19
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f19.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// stfs f19,140(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// fsubs f21,f20,f18
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// fmuls f19,f17,f31
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f31.f64));
	// fmuls f18,f17,f1
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f1.f64));
	// fmuls f17,f15,f27
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f27.f64));
	// fmuls f16,f15,f28
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// fmuls f15,f21,f29
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f29.f64));
	// fmuls f21,f21,f30
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// fmuls f14,f20,f25
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// fmadds f19,f22,f1,f19
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f1.f64 + ctx.f19.f64));
	// stfsx f19,r18,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f22,f22,f31,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f31.f64 - ctx.f18.f64));
	// stfsx f22,r17,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// fmuls f20,f20,f26
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// lfs f22,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f19,f22,f30,f15
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f30.f64 + ctx.f15.f64));
	// stfsx f19,r16,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f22,f22,f29,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f29.f64 - ctx.f21.f64));
	// stfsx f22,r15,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f21,f22,f28,f17
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 + ctx.f17.f64));
	// stfsx f21,r14,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,108
	ctx.r14.s64 = ctx.r7.s64 * 108;
	// fmsubs f22,f22,f27,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f27.f64 - ctx.f16.f64));
	// stfsx f22,r14,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,28
	ctx.r14.s64 = ctx.r7.s64 * 28;
	// lfs f22,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f21,f22,f26,f14
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f26.f64 + ctx.f14.f64));
	// lfs f18,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f22,f22,f25,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f25.f64 - ctx.f20.f64));
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f19,f18,f12
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// lfs f20,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f17,f12
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f21,r14,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,92
	ctx.r14.s64 = ctx.r7.s64 * 92;
	// lfs f21,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f14,f12
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// stfsx f22,r14,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f21,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfs f20,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f20,f12
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// rlwinm r14,r7,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fmsubs f20,f20,f13,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f19.f64));
	// lfs f19,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f13,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f16.f64));
	// fmsubs f17,f17,f13,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f14.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmuls f21,f21,f0
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fmadds f18,f18,f13,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f15.f64));
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f22,f14
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// fadds f14,f19,f20
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfs f14,80(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f21
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// fadds f19,f17,f18
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f16
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// fadds f14,f20,f21
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f14,104(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,112(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fsubs f20,f15,f19
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f20,196(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fsubs f20,f22,f18
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f20,80(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,192(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f19,156(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmuls f22,f17,f29
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f29.f64));
	// fmuls f15,f16,f25
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// fmuls f18,f14,f31
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f31.f64));
	// fmuls f21,f21,f27
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f27.f64));
	// fmuls f20,f20,f31
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f31.f64));
	// fmuls f19,f19,f25
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f25.f64));
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f29
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f29.f64));
	// fmadds f17,f17,f30,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 + ctx.f14.f64));
	// stfsx f17,r14,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,68
	ctx.r14.s64 = ctx.r7.s64 * 68;
	// lfs f17,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f22,f17,f30,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 - ctx.f22.f64));
	// stfsx f22,r14,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f22.f64 = double(temp.f32);
	// mulli r14,r7,52
	ctx.r14.s64 = ctx.r7.s64 * 52;
	// fmadds f22,f22,f1,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f1.f64 + ctx.f18.f64));
	// stfsx f22,r14,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f22.f64 = double(temp.f32);
	// mulli r14,r7,116
	ctx.r14.s64 = ctx.r7.s64 * 116;
	// fmsubs f22,f22,f1,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f1.f64 - ctx.f20.f64));
	// stfsx f22,r14,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fmadds f22,f16,f26,f19
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f26.f64 + ctx.f19.f64));
	// mulli r14,r7,36
	ctx.r14.s64 = ctx.r7.s64 * 36;
	// stfsx f22,r14,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,100
	ctx.r14.s64 = ctx.r7.s64 * 100;
	// lfs f22,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f26,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f26.f64 - ctx.f15.f64));
	// lfs f20,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f20,f10
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// fmuls f15,f19,f10
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f22,r14,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,20
	ctx.r14.s64 = ctx.r7.s64 * 20;
	// lfs f22,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f28,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 + ctx.f21.f64));
	// lfs f21,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f22,r14,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f22,f10
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// lfs f22,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f22,f10
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// lfs f22,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f21,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r7,84
	ctx.r14.s64 = ctx.r7.s64 * 84;
	// fmadds f20,f20,f11,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64 + ctx.f18.f64));
	// lfs f18,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f19,f19,f11,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 - ctx.f17.f64));
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f17,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// lfs f14,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f14,f11,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 - ctx.f16.f64));
	// stfs f16,96(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f16,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f16,f27
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f27.f64));
	// lfs f16,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f11,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 + ctx.f15.f64));
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f15,f15,f28,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f28.f64 - ctx.f14.f64));
	// stfsx f15,r14,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,132(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,108(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fadds f15,f21,f22
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f21,f19,f20
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// fsubs f19,f18,f17
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f16,f14
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// fsubs f14,f22,f20
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f14,96(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fsubs f14,f19,f21
	ctx.f14.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// stfs f14,80(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fadds f19,f19,f21
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfs f19,112(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// fadds f21,f17,f15
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// fadds f20,f18,f16
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f20,104(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,140(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fsubs f20,f15,f17
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// lfs f17,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f15.f64 = double(temp.f32);
	// stfs f20,156(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmuls f15,f21,f15
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f15.f64));
	// fmuls f21,f21,f24
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f24.f64));
	// lfs f18,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f18,f17
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// fmuls f16,f18,f23
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f23.f64));
	// lfs f18,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// fmuls f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f18.f64));
	// lfs f14,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f14.f64));
	// fmuls f18,f22,f18
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f22,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f15,f22,f24,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f24.f64 + ctx.f15.f64));
	// stfsx f15,r26,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f15,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f22,f22,f15,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f15.f64 - ctx.f21.f64));
	// stfsx f22,r25,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f23,f22,f23,f17
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 + ctx.f17.f64));
	// stfsx f23,r24,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f22,f23,f16
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 - ctx.f16.f64));
	// stfsx f23,r23,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f22,f22,f23,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 + ctx.f19.f64));
	// stfsx f22,r22,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f23,f22,f23,f20
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 - ctx.f20.f64));
	// stfsx f23,r21,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f23,f22,f18
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 + ctx.f18.f64));
	// stfsx f22,r20,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f23,f23,f22,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 - ctx.f14.f64));
	// stfsx f23,r19,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f21,f23,f8
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f20,f22,f8
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// fmuls f15,f23,f9
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// lfs f19,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f22,f9
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f9.f64));
	// lfs f22,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f22.f64 = double(temp.f32);
	// lfs f16,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f23,f17,f9,f21
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 + ctx.f21.f64));
	// lfs f21,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f21,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// lfs f19,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f20,f19,f9,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f9.f64 + ctx.f20.f64));
	// fsubs f19,f18,f16
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// fmsubs f17,f17,f8,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f8.f64 - ctx.f15.f64));
	// lfs f15,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// lfs f16,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,172(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f15,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f15,f15,f8,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f8.f64 - ctx.f14.f64));
	// stfs f15,76(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,124(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,136(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fsubs f15,f22,f21
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f14,f23,f20
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// fadds f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// lfs f21,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// stfs f21,156(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f20,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f20.f64 = double(temp.f32);
	// fadds f21,f20,f17
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// lfs f17,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,140(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f16,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f16.f64 = double(temp.f32);
	// mulli r26,r7,44
	ctx.r26.s64 = ctx.r7.s64 * 44;
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,112(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fadds f16,f23,f18
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f16,76(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fsubs f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfs f18,80(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f23,f21,f19
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fadds f15,f22,f20
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// lfs f14,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// stfs f15,144(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// lfs f20,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f20.f64 = double(temp.f32);
	// stfs f22,104(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmuls f19,f16,f20
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f20.f64));
	// lfs f16,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f23,f16
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// fmuls f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f14.f64));
	// lfs f23,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f20.f64));
	// fmuls f15,f21,f23
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f23.f64));
	// lfs f23,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f21,f21,f23
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f23.f64));
	// lfs f23,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f22,f23
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// fmuls f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f23.f64));
	// lfs f23,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f17,f23,f16
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f23.f64 + ctx.f16.f64));
	// stfsx f23,r18,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f17,f23,f14
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f23.f64 - ctx.f14.f64));
	// stfsx f23,r17,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// lfs f17,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f17.f64 = double(temp.f32);
	// lfs f23,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f23.f64 = double(temp.f32);
	// stfs f22,76(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fmr f22,f17
	ctx.f22.f64 = ctx.f17.f64;
	// lfs f17,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f23,f23,f22,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 + ctx.f20.f64));
	// stfsx f23,r16,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f23,f22,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 - ctx.f19.f64));
	// stfsx f23,r15,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f23,f20,f15
	ctx.f20.f64 = double(float(ctx.f23.f64 * ctx.f20.f64 + ctx.f15.f64));
	// stfsx f20,r26,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// mulli r26,r7,108
	ctx.r26.s64 = ctx.r7.s64 * 108;
	// lfs f20,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f23,f23,f20,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f20.f64 - ctx.f21.f64));
	// lfs f21,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f23,r26,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f23.f64 = double(temp.f32);
	// mulli r26,r7,28
	ctx.r26.s64 = ctx.r7.s64 * 28;
	// lfs f20,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f21,f21,f23,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f23.f64 + ctx.f20.f64));
	// stfsx f21,r26,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// mulli r26,r7,92
	ctx.r26.s64 = ctx.r7.s64 * 92;
	// lfs f21,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f21,f21,f23,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f23.f64 - ctx.f18.f64));
	// lfs f20,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f20,f9
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f9.f64));
	// fmuls f15,f20,f8
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// lfs f20,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f20.f64 = double(temp.f32);
	// stfsx f21,r26,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f21,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f21,f8
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f8.f64));
	// lfs f21,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f21,f8
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f8.f64));
	// fmsubs f21,f21,f9,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64 - ctx.f19.f64));
	// lfs f19,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// lfs f19,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f18,f17,f8,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f8.f64 + ctx.f18.f64));
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f16,f14,f9,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f9.f64 + ctx.f16.f64));
	// stfs f16,76(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f9,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f9.f64 - ctx.f15.f64));
	// stfs f16,128(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f10
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f11
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f16,f14,f11,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 + ctx.f16.f64));
	// stfs f16,104(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f10,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 - ctx.f15.f64));
	// stfs f16,80(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fadds f16,f18,f21
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// lfs f15,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// fadds f18,f17,f19
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f18,108(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f19,132(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fadds f14,f21,f20
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfs f21,96(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f18,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f17,f18
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f14,128(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// fsubs f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f16.f64 = double(temp.f32);
	// fadds f21,f19,f15
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// fsubs f15,f19,f15
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// stfs f15,144(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fsubs f20,f16,f18
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// fadds f19,f18,f16
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// lfs f16,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f18,f14,f23
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f23.f64));
	// lfs f14,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f22.f64));
	// fmuls f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f16.f64));
	// lfs f16,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f23.f64));
	// lfs f23,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f20,f16
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f16.f64));
	// fmuls f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f14.f64));
	// fmuls f14,f19,f23
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// lfs f23,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f19,f19,f23
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// lfs f23,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f17,f23,f22
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f23.f64 - ctx.f22.f64));
	// stfs f23,0(r4)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f23,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f23.f64 = double(temp.f32);
	// fnmadds f23,f17,f23,f21
	ctx.f23.f64 = double(float(-(ctx.f17.f64 * ctx.f23.f64 + ctx.f21.f64)));
	// stfsx f23,r11,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f22,f23,f22,f16
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 + ctx.f16.f64));
	// stfsx f22,r27,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f23,f23,f22,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 - ctx.f20.f64));
	// stfsx f23,r29,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f23,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 + ctx.f15.f64));
	// stfsx f22,r10,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f23,f22,f23,f18
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 - ctx.f18.f64));
	// stfsx f23,r31,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f23,f22,f14
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 + ctx.f14.f64));
	// stfsx f22,r30,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f22.f64 = double(temp.f32);
	// lwz r11,340(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// fmsubs f23,f23,f22,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 - ctx.f19.f64));
	// stfsx f23,r28,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f23.f64 = double(temp.f32);
	// add r5,r11,r5
	ctx.r5.u64 = ctx.r11.u64 + ctx.r5.u64;
	// fmuls f18,f23,f11
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// lfs f23,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f17,f23,f10
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// lfs f22,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f23.f64 = double(temp.f32);
	// add r6,r11,r6
	ctx.r6.u64 = ctx.r11.u64 + ctx.r6.u64;
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfs f21,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f22.f64 = double(temp.f32);
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f19,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f20.f64 = double(temp.f32);
	// lwz r10,332(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// fadds f21,f19,f20
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f16,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fmsubs f19,f19,f10,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 - ctx.f18.f64));
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f11,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 + ctx.f17.f64));
	// fsubs f17,f23,f22
	ctx.f17.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f22,f16,f20
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// fadds f16,f20,f16
	ctx.f16.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// stfs f16,96(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fadds f20,f18,f19
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fsubs f18,f17,f21
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// stfs f18,128(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fadds f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// stfs f21,16(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f21,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f15,f22,f21
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f21.f64));
	// lfs f21,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f17,f22,f24
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f24.f64));
	// lfs f22,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f16,f22
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f22.f64));
	// fadds f22,f20,f21
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fadds f14,f23,f19
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,144(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fsubs f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// lfs f20,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f18,f20
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// lfs f19,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f19.f64 = double(temp.f32);
	// stfs f23,80(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f20,f22,f20
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// fmuls f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f19.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f19.f64));
	// lfs f19,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f23,f19
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f19.f64));
	// lfs f23,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f22,f22,f23,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 + ctx.f18.f64));
	// stfsx f22,r11,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,68
	ctx.r11.s64 = ctx.r7.s64 * 68;
	// lfs f22,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f23,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 - ctx.f20.f64));
	// lfs f20,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f20.f64 = double(temp.f32);
	// stfsx f22,r11,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// mulli r11,r7,52
	ctx.r11.s64 = ctx.r7.s64 * 52;
	// fmadds f20,f22,f20,f17
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f20.f64 + ctx.f17.f64));
	// fmsubs f22,f22,f24,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f24.f64 - ctx.f15.f64));
	// stfsx f20,r11,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f20,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f20.f64 = double(temp.f32);
	// mulli r11,r7,116
	ctx.r11.s64 = ctx.r7.s64 * 116;
	// stfsx f22,r11,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f20,f20,f22,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f22.f64 + ctx.f14.f64));
	// mulli r11,r7,36
	ctx.r11.s64 = ctx.r7.s64 * 36;
	// stfsx f20,r11,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,100
	ctx.r11.s64 = ctx.r7.s64 * 100;
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f22,f20,f22,f21
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f22.f64 - ctx.f21.f64));
	// lfs f21,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f22,r11,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f22.f64 = double(temp.f32);
	// mulli r11,r7,20
	ctx.r11.s64 = ctx.r7.s64 * 20;
	// fmadds f21,f21,f22,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f22.f64 + ctx.f19.f64));
	// stfsx f21,r11,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f21,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f21.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// fmsubs f22,f21,f22,f16
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f22.f64 - ctx.f16.f64));
	// stfsx f22,r14,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lwz r11,3532(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 3532);
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d2da24
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D2DA24;
loc_82D2F140:
	// addi r1,r1,656
	ctx.r1.s64 = ctx.r1.s64 + 656;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D2F14C;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2F150"))) PPC_WEAK_FUNC(sub_82D2F150);
PPC_FUNC_IMPL(__imp__sub_82D2F150) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-6632
	ctx.r5.s64 = ctx.r11.s64 + -6632;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-10280
	ctx.r4.s64 = ctx.r11.s64 + -10280;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2F168"))) PPC_WEAK_FUNC(sub_82D2F168);
PPC_FUNC_IMPL(__imp__sub_82D2F168) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D2F170;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D2F178;
	__savefpr_14(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d2faf4
	if (!ctx.cr6.gt) goto loc_82D2FAF4;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r30,-32229
	ctx.r30.s64 = -2112159744;
	// lis r29,-32236
	ctx.r29.s64 = -2112618496;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r14,-32234
	ctx.r14.s64 = -2112487424;
	// lis r15,-32234
	ctx.r15.s64 = -2112487424;
	// lis r16,-32234
	ctx.r16.s64 = -2112487424;
	// lfs f11,-13884(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -13884);
	ctx.f11.f64 = double(temp.f32);
	// lis r17,-32234
	ctx.r17.s64 = -2112487424;
	// stfs f11,-328(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// stw r11,-316(r1)
	PPC_STORE_U32(ctx.r1.u32 + -316, ctx.r11.u32);
	// lis r18,-32234
	ctx.r18.s64 = -2112487424;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// lfs f11,120(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 120);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f11,-324(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lfs f1,-6524(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + -6524);
	ctx.f1.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f2,-6512(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + -6512);
	ctx.f2.f64 = double(temp.f32);
	// lis r24,-32236
	ctx.r24.s64 = -2112618496;
	// lfs f3,-6516(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -6516);
	ctx.f3.f64 = double(temp.f32);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f4,-6492(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -6492);
	ctx.f4.f64 = double(temp.f32);
	// stw r11,-312(r1)
	PPC_STORE_U32(ctx.r1.u32 + -312, ctx.r11.u32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f5,-6496(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -6496);
	ctx.f5.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f6,-8128(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -8128);
	ctx.f6.f64 = double(temp.f32);
	// lis r31,-32236
	ctx.r31.s64 = -2112618496;
	// lfs f7,124(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 124);
	ctx.f7.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f8,-8136(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -8136);
	ctx.f8.f64 = double(temp.f32);
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f9,-8132(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -8132);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-8144(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -8144);
	ctx.f10.f64 = double(temp.f32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f11,-8140(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8140);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-8016(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
	// lfs f31,-6528(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + -6528);
	ctx.f31.f64 = double(temp.f32);
	// lfs f30,-6504(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + -6504);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,-6500(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -6500);
	ctx.f29.f64 = double(temp.f32);
loc_82D2F240:
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f28,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// mulli r10,r8,44
	ctx.r10.s64 = ctx.r8.s64 * 44;
	// lfs f27,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f26,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f25,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f17,f26,f25
	ctx.f17.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// rlwinm r11,r9,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// mulli r10,r9,44
	ctx.r10.s64 = ctx.r9.s64 * 44;
	// lfsx f24,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f23,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f16,f23,f24
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// mulli r11,r8,12
	ctx.r11.s64 = ctx.r8.s64 * 12;
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfsx f22,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r11,r8,48
	ctx.r11.s64 = ctx.r8.s64 * 48;
	// lfsx f21,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// lfsx f20,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r11,r9,48
	ctx.r11.s64 = ctx.r9.s64 * 48;
	// lfsx f19,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r11,r8,60
	ctx.r11.s64 = ctx.r8.s64 * 60;
	// lfsx f18,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r9,60
	ctx.r11.s64 = ctx.r9.s64 * 60;
	// lfsx f25,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f25.f64 = double(temp.f32);
	// rlwinm r11,r8,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// mulli r10,r8,28
	ctx.r10.s64 = ctx.r8.s64 * 28;
	// lfsx f23,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f15,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// rlwinm r11,r9,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// mulli r10,r9,28
	ctx.r10.s64 = ctx.r9.s64 * 28;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-344(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfsx f14,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-432(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r10,r8,52
	ctx.r10.s64 = ctx.r8.s64 * 52;
	// fsubs f14,f22,f21
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfsx f21,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,-348(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfsx f21,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// stfs f21,-428(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// mulli r10,r9,52
	ctx.r10.s64 = ctx.r9.s64 * 52;
	// lfsx f21,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,-412(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfsx f21,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,-416(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// fadds f21,f19,f20
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// fadds f19,f18,f28
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// fsubs f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// fadds f18,f25,f27
	ctx.f18.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// fadds f25,f16,f17
	ctx.f25.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f16,f15,f23
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f23,-424(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f23,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f23.f64 = double(temp.f32);
	// lfs f15,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// stfs f15,-420(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f15,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// fadds f15,f22,f26
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// fsubs f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// stfs f26,-360(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f26,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f26.f64 = double(temp.f32);
	// lfs f22,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f26
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// stfs f22,-368(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f22,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// stfs f26,-392(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f22,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f22.f64 = double(temp.f32);
	// lfs f26,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// fadds f22,f21,f14
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// fsubs f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// mulli r11,r8,40
	ctx.r11.s64 = ctx.r8.s64 * 40;
	// fsubs f14,f20,f24
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// mulli r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 * 20;
	// fadds f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// fadds f20,f16,f19
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfs f20,-400(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f20,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// stfs f20,-372(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f20,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f20.f64 = double(temp.f32);
	// fadds f16,f23,f27
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// lfs f18,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f27,f27,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// lfs f23,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f18,f28,f18
	ctx.f18.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// fadds f28,f23,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// fsubs f23,f25,f22
	ctx.f23.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// fadds f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// fadds f22,f21,f17
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// fsubs f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f23,-376(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// stfs f25,-356(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fmuls f25,f22,f0
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f25,-320(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fmuls f25,f21,f0
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// stfs f25,-348(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f23,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f23.f64 = double(temp.f32);
	// lfs f25,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f25.f64));
	// lfsx f23,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f23.f64 = double(temp.f32);
	// mulli r11,r9,40
	ctx.r11.s64 = ctx.r9.s64 * 40;
	// lfsx f22,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f21,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// mulli r11,r9,20
	ctx.r11.s64 = ctx.r9.s64 * 20;
	// lfsx f17,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-412(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r10,r8,56
	ctx.r10.s64 = ctx.r8.s64 * 56;
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-416(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfsx f17,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-344(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r10,r9,56
	ctx.r10.s64 = ctx.r9.s64 * 56;
	// lfsx f17,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-352(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfsx f17,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r8,24
	ctx.r11.s64 = ctx.r8.s64 * 24;
	// stfs f17,-420(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-424(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// mulli r11,r8,36
	ctx.r11.s64 = ctx.r8.s64 * 36;
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-364(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fsubs f17,f23,f22
	ctx.f17.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// mulli r11,r9,24
	ctx.r11.s64 = ctx.r9.s64 * 24;
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfsx f22,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-384(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// mulli r11,r9,36
	ctx.r11.s64 = ctx.r9.s64 * 36;
	// lfsx f22,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-380(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f22,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfs f22,-396(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f22,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f22,-340(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f21,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f21,-336(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f21,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfs f22,-428(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f22,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f21,-352(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f21,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f22,-404(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f22,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f21,-344(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f21,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfs f22,-432(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fadds f22,f17,f26
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// stfs f22,-420(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f22,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// fsubs f21,f22,f23
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// lfs f17,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f17.f64 = double(temp.f32);
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// lfs f22,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f22.f64 = double(temp.f32);
	// stfs f23,-388(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fadds f23,f17,f22
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,-408(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f17,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f22.f64 = double(temp.f32);
	// stfs f21,-412(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fsubs f21,f22,f17
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,-332(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f22,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f22.f64 = double(temp.f32);
	// stfs f21,-416(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// fsubs f21,f25,f22
	ctx.f21.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// stfs f21,-340(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fadds f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// stfs f25,-396(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f25,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f25.f64 = double(temp.f32);
	// lfs f22,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f21,f22,f25
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// stfs f21,-424(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// fadds f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// stfs f25,-384(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fmuls f22,f26,f13
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// lfs f17,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f21,f26,f12
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lfs f26,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// stfs f26,-392(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f26,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f17,f26,f23
	ctx.f17.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// stfs f17,-336(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f26,-380(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f25,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f12
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f17,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f17.f64 = double(temp.f32);
	// lfs f26,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f26,f12
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lfs f26,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f17,f17,f26
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f26.f64));
	// stfs f17,-368(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f17,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f17.f64 = double(temp.f32);
	// fadds f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// stfs f26,-364(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f17,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f17.f64 = double(temp.f32);
	// lfs f26,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// lfs f17,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f25,f17,f13,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f25.f64));
	// lfs f17,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f23,f17,f13,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f23.f64));
	// stfs f23,-416(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f23,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f22,f23,f12,f22
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 - ctx.f22.f64));
	// stfs f22,-352(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fmadds f23,f23,f13,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f21.f64));
	// stfs f23,-344(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f23,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f23,f12
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// lfs f23,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f21,f23,f13
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// lfs f23,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f17,f23,f12
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// fmadds f23,f23,f13,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f22.f64));
	// lfs f22,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f22.f64 = double(temp.f32);
	// rlwinm r10,r7,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r31,r7,48
	ctx.r31.s64 = ctx.r7.s64 * 48;
	// fmsubs f22,f22,f13,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f17.f64));
	// stfs f22,-412(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f22,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f22.f64 = double(temp.f32);
	// mulli r30,r7,12
	ctx.r30.s64 = ctx.r7.s64 * 12;
	// fmsubs f22,f22,f12,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 - ctx.f21.f64));
	// stfs f22,-420(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f21,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f17,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f17.f64 = double(temp.f32);
	// lfs f21,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// stfs f21,-332(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f21,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f21.f64 = double(temp.f32);
	// mulli r29,r7,60
	ctx.r29.s64 = ctx.r7.s64 * 60;
	// fadds f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// stfs f21,-336(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f17,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f17.f64 = double(temp.f32);
	// lfs f21,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// lfs f17,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f26,f17
	ctx.f17.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// stfs f17,-340(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fsubs f17,f27,f24
	ctx.f17.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// stfs f17,-404(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f17,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f17.f64 = double(temp.f32);
	// fadds f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,-408(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f17,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f17.f64 = double(temp.f32);
	// mulli r28,r7,44
	ctx.r28.s64 = ctx.r7.s64 * 44;
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f26,f26,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f15.f64));
	// lfs f15,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f15.f64 = double(temp.f32);
	// lfs f24,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f15,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 - ctx.f24.f64));
	// stfs f24,-396(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f24,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f12
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// lfs f15,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f15.f64 = double(temp.f32);
	// mulli r27,r7,28
	ctx.r27.s64 = ctx.r7.s64 * 28;
	// rlwinm r26,r7,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fmadds f24,f15,f13,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f24.f64));
	// stfs f24,-392(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// mulli r25,r7,56
	ctx.r25.s64 = ctx.r7.s64 * 56;
	// lfs f24,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f24.f64 = double(temp.f32);
	// fadds f15,f24,f22
	ctx.f15.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// stfs f15,-384(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// lfs f22,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f22.f64 = double(temp.f32);
	// stfs f24,-388(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fadds f15,f21,f22
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f24,f22,f21
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f22,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f21,-336(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f21,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f22,-332(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fadds f21,f26,f17
	ctx.f21.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// stfs f21,-380(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fsubs f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f26.f64));
	// stfs f26,-340(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f21,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f27,f21
	ctx.f22.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// stfs f22,-400(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fadds f27,f21,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// stfs f27,-396(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f27,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f21,f15,f27
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f27.f64));
	// stfs f21,0(r3)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f15,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f26,f26,f7
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// fmuls f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 * ctx.f27.f64));
	// stfsx f27,r11,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// lfs f27,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f22,f22,f6
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// lfs f21,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f21.f64 = double(temp.f32);
	// mulli r24,r7,40
	ctx.r24.s64 = ctx.r7.s64 * 40;
	// fsubs f21,f27,f21
	ctx.f21.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// lfs f27,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f27.f64 = double(temp.f32);
	// lfs f17,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f17.f64 = double(temp.f32);
	// mulli r23,r7,24
	ctx.r23.s64 = ctx.r7.s64 * 24;
	// fsubs f17,f17,f27
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f27.f64));
	// lfs f27,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f27.f64 = double(temp.f32);
	// fadds f15,f27,f24
	ctx.f15.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// stfs f26,-336(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fsubs f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// stfs f27,-332(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f24,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f27,f21,f0
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fmuls f26,f17,f0
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fmuls f21,f15,f24
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f24.f64));
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f24.f64));
	// stfsx f24,r31,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fsubs f21,f19,f14
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f24,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f17,f24,f7,f22
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 + ctx.f22.f64));
	// lfs f24,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// fadds f22,f26,f21
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// fsubs f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// lfs f21,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f21.f64 = double(temp.f32);
	// fadds f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f21.f64));
	// stfs f27,-332(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fmuls f27,f22,f10
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// fmuls f21,f26,f8
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmuls f26,f26,f9
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// fmadds f27,f24,f11,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f11.f64 + ctx.f27.f64));
	// stfsx f27,r30,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f24,f24,f10,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f22.f64));
	// lfs f22,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f22.f64 = double(temp.f32);
	// lfs f27,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f21,f27,f9,f21
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 - ctx.f21.f64));
	// stfsx f21,r29,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// stfsx f24,r28,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fmadds f27,f27,f8,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f8.f64 + ctx.f26.f64));
	// lfs f24,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f24.f64 = double(temp.f32);
	// fadds f26,f23,f25
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// stfsx f27,r27,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fadds f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// lfs f21,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// stfsx f17,r26,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f27,f21,f18
	ctx.f27.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// lfs f17,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// lfs f22,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f25,-332(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f17,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f18.f64 = double(temp.f32);
	// lfs f23,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f25,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f25.f64 = double(temp.f32);
	// lfs f17,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f17.f64 = double(temp.f32);
	// fadds f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f23.f64));
	// stfs f25,-372(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f23,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f23.f64 = double(temp.f32);
	// lfs f25,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f25.f64 = double(temp.f32);
	// stfs f18,-320(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// lfs f18,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f18.f64 = double(temp.f32);
	// stfs f25,-376(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f25,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f25,f6
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// lfs f25,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f25,f6
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// lfs f25,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f15,f25,f6,f15
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 - ctx.f15.f64));
	// stfsx f15,r25,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f23,f15,f7,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f7.f64 - ctx.f23.f64));
	// stfsx f23,r24,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fmadds f15,f25,f7,f17
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 + ctx.f17.f64));
	// lfs f23,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f23.f64 = double(temp.f32);
	// fadds f25,f26,f27
	ctx.f25.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// stfsx f15,r23,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fsubs f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// fsubs f17,f24,f22
	ctx.f17.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfs f17,-336(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f26,f22,f24
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fadds f24,f23,f21
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// fsubs f21,f21,f23
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// lfs f23,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f22,f18,f23
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfs f22,-320(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fadds f18,f23,f18
	ctx.f18.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// lfs f23,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f28
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// lfs f22,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f22.f64 = double(temp.f32);
	// stfs f18,-332(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// stfs f21,-380(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fmuls f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// fmuls f21,f21,f29
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f29.f64));
	// fmuls f18,f18,f29
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f29.f64));
	// fsubs f15,f23,f22
	ctx.f15.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f15,-340(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f23,-372(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f23,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// lfs f22,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f15,f23,f22
	ctx.f15.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f15,-396(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f23,-376(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fmuls f22,f26,f4
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// fmuls f23,f27,f2
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// fmuls f26,f26,f5
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fmadds f27,f27,f3,f17
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64 + ctx.f17.f64));
	// fmuls f15,f24,f31
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// fmuls f24,f24,f1
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// fmsubs f22,f25,f5,f22
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 - ctx.f22.f64));
	// stfs f22,0(r4)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fnmadds f26,f25,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f25.f64 * ctx.f4.f64 + ctx.f26.f64)));
	// lfs f22,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f23,f22,f3,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 - ctx.f23.f64));
	// stfsx f23,r31,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// stfsx f26,r11,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// stfsx f27,r10,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r7,52
	ctx.r10.s64 = ctx.r7.s64 * 52;
	// lfs f27,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f27.f64 = double(temp.f32);
	// stfs f18,-320(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fmadds f26,f27,f1,f15
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f15.f64));
	// stfsx f26,r26,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f27,f27,f31,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64 - ctx.f24.f64));
	// lfs f26,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f26,f26,f30,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f30.f64 - ctx.f21.f64));
	// stfsx f26,r25,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// stfsx f27,r24,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lfs f27,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f27.f64 = double(temp.f32);
	// fmr f18,f27
	ctx.f18.f64 = ctx.f27.f64;
	// lfs f27,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f18,f2
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f2.f64));
	// lfs f26,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f27,f27,f30,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f30.f64 + ctx.f26.f64));
	// stfsx f27,r23,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// lfs f27,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f26.f64 = double(temp.f32);
	// fadds f22,f27,f26
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// lfs f27,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f26.f64 = double(temp.f32);
	// fadds f21,f27,f26
	ctx.f21.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// lfs f26,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f26.f64 = double(temp.f32);
	// fadds f27,f14,f19
	ctx.f27.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// fsubs f26,f16,f26
	ctx.f26.f64 = double(float(ctx.f16.f64 - ctx.f26.f64));
	// lfs f25,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f15,f18,f3
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// fsubs f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// lfs f24,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// lfs f24,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// lfs f20,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f21,f21,f0
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// lfs f20,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f20,f5
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f5.f64));
	// fmuls f14,f18,f5
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f5.f64));
	// lfs f19,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f17,f19,f3,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f3.f64 + ctx.f17.f64));
	// stfsx f17,r30,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f19,f19,f2,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f2.f64 - ctx.f15.f64));
	// mulli r31,r7,36
	ctx.r31.s64 = ctx.r7.s64 * 36;
	// mulli r26,r7,20
	ctx.r26.s64 = ctx.r7.s64 * 20;
	// fmsubs f18,f18,f4,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 - ctx.f16.f64));
	// stfsx f18,r29,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// stfsx f19,r28,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fmadds f20,f20,f4,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f4.f64 + ctx.f14.f64));
	// stfsx f20,r27,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fadds f20,f25,f28
	ctx.f20.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// fsubs f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// fsubs f25,f24,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fadds f23,f22,f27
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// fsubs f27,f27,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f22.f64));
	// fsubs f19,f26,f21
	ctx.f19.f64 = double(float(ctx.f26.f64 - ctx.f21.f64));
	// fadds f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// fmuls f22,f20,f29
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f29.f64));
	// fmuls f21,f28,f31
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// fmuls f20,f20,f30
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f30.f64));
	// fmuls f15,f24,f31
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// fmuls f18,f23,f8
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fmuls f17,f27,f10
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fmuls f23,f23,f9
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// fmuls f16,f26,f10
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// fmadds f22,f25,f30,f22
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f30.f64 + ctx.f22.f64));
	// fmadds f28,f28,f1,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f1.f64 + ctx.f15.f64));
	// fmadds f18,f19,f9,f18
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f9.f64 + ctx.f18.f64));
	// stfsx f18,r11,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f26,f26,f11,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f11.f64 - ctx.f17.f64));
	// stfsx f26,r10,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f26,f24,f1,f21
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f1.f64 - ctx.f21.f64));
	// fmsubs f24,f19,f8,f23
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f8.f64 - ctx.f23.f64));
	// stfsx f24,r31,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmadds f27,f27,f11,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f16.f64));
	// stfsx f27,r26,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// stfsx f22,r11,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,-316(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	// stfsx f26,r10,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f27,f25,f29,f20
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f29.f64 - ctx.f20.f64));
	// stfsx f27,r31,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// add r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
	// stfsx f28,r26,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// add r4,r11,r4
	ctx.r4.u64 = ctx.r11.u64 + ctx.r4.u64;
	// lwz r11,-312(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	// add r5,r11,r5
	ctx.r5.u64 = ctx.r11.u64 + ctx.r5.u64;
	// add r6,r11,r6
	ctx.r6.u64 = ctx.r11.u64 + ctx.r6.u64;
	// lwz r11,3532(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 3532);
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d2f240
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D2F240;
loc_82D2FAF4:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D2FAFC;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2FB00"))) PPC_WEAK_FUNC(sub_82D2FB00);
PPC_FUNC_IMPL(__imp__sub_82D2FB00) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-6488
	ctx.r5.s64 = ctx.r11.s64 + -6488;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-3736
	ctx.r4.s64 = ctx.r11.s64 + -3736;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2FB18"))) PPC_WEAK_FUNC(sub_82D2FB18);
PPC_FUNC_IMPL(__imp__sub_82D2FB18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e50
	ctx.lr = 0x82D2FB20;
	__savegprlr_22(ctx, base);
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82e28ee8
	ctx.lr = 0x82D2FB28;
	__savefpr_16(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d2fde0
	if (!ctx.cr6.gt) goto loc_82D2FDE0;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// rlwinm r26,r11,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// rlwinm r25,r11,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f8,-8136(r22)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -8136);
	ctx.f8.f64 = double(temp.f32);
	// lis r29,-32236
	ctx.r29.s64 = -2112618496;
	// lfs f9,-8132(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -8132);
	ctx.f9.f64 = double(temp.f32);
	// lis r30,-32236
	ctx.r30.s64 = -2112618496;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f10,-8144(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -8144);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f11,-8140(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8140);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,140(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 140);
	ctx.f12.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f19,120(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 120);
	ctx.f19.f64 = double(temp.f32);
	// lfs f13,-8128(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8128);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,124(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 124);
	ctx.f0.f64 = double(temp.f32);
	// lfs f20,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f20.f64 = double(temp.f32);
loc_82D2FB90:
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// lfs f6,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// mulli r10,r9,28
	ctx.r10.s64 = ctx.r9.s64 * 28;
	// lfs f7,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f5,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f24,f5,f7
	ctx.f24.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fsubs f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// lfsx f4,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f22,f4,f6
	ctx.f22.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// lfsx f3,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f2,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f4,f2,f3
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// rlwinm r11,r9,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// mulli r10,r9,12
	ctx.r10.s64 = ctx.r9.s64 * 12;
	// lfsx f1,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f2,f1,f31
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// mulli r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 * 20;
	// lfsx f30,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f29,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f31,f29,f30
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// mulli r10,r9,20
	ctx.r10.s64 = ctx.r9.s64 * 20;
	// lfsx f28,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f27,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f29,f28,f27
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// mulli r10,r8,24
	ctx.r10.s64 = ctx.r8.s64 * 24;
	// lfsx f26,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f25,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f25.f64 = double(temp.f32);
	// fadds f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// mulli r10,r9,24
	ctx.r10.s64 = ctx.r9.s64 * 24;
	// lfsx f5,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f23,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f25,f23,f5
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f5.f64));
	// fadds f5,f23,f5
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f23,f24,f4
	ctx.f23.f64 = double(float(ctx.f24.f64 - ctx.f4.f64));
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f4,f4,f24
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f24.f64));
	// mulli r31,r7,20
	ctx.r31.s64 = ctx.r7.s64 * 20;
	// fadds f24,f3,f6
	ctx.f24.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// fsubs f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// fadds f3,f2,f22
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f22.f64));
	// fsubs f2,f22,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 - ctx.f2.f64));
	// fsubs f22,f7,f1
	ctx.f22.f64 = double(float(ctx.f7.f64 - ctx.f1.f64));
	// fadds f7,f1,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 + ctx.f7.f64));
	// fsubs f1,f30,f28
	ctx.f1.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// rlwinm r30,r7,3,0,28
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f28,f31,f27
	ctx.f28.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// mulli r29,r7,24
	ctx.r29.s64 = ctx.r7.s64 * 24;
	// fadds f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// fsubs f27,f25,f29
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f29.f64));
	// fadds f29,f25,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// fsubs f25,f26,f5
	ctx.f25.f64 = double(float(ctx.f26.f64 - ctx.f5.f64));
	// fadds f5,f5,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f26.f64));
	// fsubs f26,f3,f28
	ctx.f26.f64 = double(float(ctx.f3.f64 - ctx.f28.f64));
	// fadds f18,f31,f4
	ctx.f18.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// fadds f21,f27,f23
	ctx.f21.f64 = double(float(ctx.f27.f64 + ctx.f23.f64));
	// fsubs f17,f2,f29
	ctx.f17.f64 = double(float(ctx.f2.f64 - ctx.f29.f64));
	// fmuls f18,f18,f20
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// stfs f18,0(r3)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f18,f17,f20
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f20.f64));
	// stfsx f18,r11,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fmuls f18,f26,f13
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmuls f17,f21,f13
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmadds f21,f21,f0,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f18.f64));
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f21,f30,f5
	ctx.f21.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// fsubs f18,f1,f25
	ctx.f18.f64 = double(float(ctx.f1.f64 - ctx.f25.f64));
	// fsubs f16,f30,f5
	ctx.f16.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// mulli r28,r7,12
	ctx.r28.s64 = ctx.r7.s64 * 12;
	// fsubs f5,f4,f31
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// mulli r27,r7,28
	ctx.r27.s64 = ctx.r7.s64 * 28;
	// fadds f4,f29,f2
	ctx.f4.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fadds f25,f25,f1
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f1.f64));
	// fsubs f2,f23,f27
	ctx.f2.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// fmuls f1,f21,f12
	ctx.f1.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fadds f3,f28,f3
	ctx.f3.f64 = double(float(ctx.f28.f64 + ctx.f3.f64));
	// fmsubs f28,f26,f0,f17
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 - ctx.f17.f64));
	// stfsx f28,r31,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmuls f31,f18,f12
	ctx.f31.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// fmuls f29,f16,f12
	ctx.f29.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fadds f28,f4,f5
	ctx.f28.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f27,f4,f5
	ctx.f27.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// fmuls f30,f25,f12
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// fmuls f26,f2,f13
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// add r5,r25,r5
	ctx.r5.u64 = ctx.r25.u64 + ctx.r5.u64;
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// add r6,r25,r6
	ctx.r6.u64 = ctx.r25.u64 + ctx.r6.u64;
	// fsubs f5,f7,f1
	ctx.f5.f64 = double(float(ctx.f7.f64 - ctx.f1.f64));
	// fadds f7,f1,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 + ctx.f7.f64));
	// fsubs f4,f6,f31
	ctx.f4.f64 = double(float(ctx.f6.f64 - ctx.f31.f64));
	// fadds f6,f31,f6
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// fadds f31,f29,f24
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f24.f64));
	// fmuls f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// stfsx f28,r30,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmuls f28,f27,f19
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// stfsx f28,r29,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fadds f1,f30,f22
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// fmadds f28,f3,f0,f26
	ctx.f28.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f26.f64));
	// stfsx f28,r28,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fsubs f30,f22,f30
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f30.f64));
	// fmsubs f3,f3,f13,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 - ctx.f2.f64));
	// stfsx f3,r27,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fmuls f3,f5,f10
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// add r3,r26,r3
	ctx.r3.u64 = ctx.r26.u64 + ctx.r3.u64;
	// fsubs f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f24.f64));
	// fmuls f2,f7,f8
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// fmuls f5,f5,f11
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fmuls f7,f7,f9
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// fmuls f28,f31,f9
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f9.f64));
	// fmuls f26,f1,f9
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// fmuls f27,f30,f10
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// fmadds f3,f4,f11,f3
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 + ctx.f3.f64));
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmuls f25,f29,f10
	ctx.f25.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// fmsubs f3,f6,f9,f2
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 - ctx.f2.f64));
	// stfsx f3,r27,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f5,f4,f10,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f10.f64 - ctx.f5.f64));
	// stfsx f5,r31,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fmadds f7,f6,f8,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f8.f64 + ctx.f7.f64));
	// stfsx f7,r28,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f7,f1,f8,f28
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f8.f64 - ctx.f28.f64));
	// stfs f7,0(r4)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmsubs f7,f29,f11,f27
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f11.f64 - ctx.f27.f64));
	// stfsx f7,r29,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fnmadds f7,f31,f8,f26
	ctx.f7.f64 = double(float(-(ctx.f31.f64 * ctx.f8.f64 + ctx.f26.f64)));
	// stfsx f7,r11,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fmadds f7,f30,f11,f25
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f11.f64 + ctx.f25.f64));
	// stfsx f7,r30,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,3532(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 3532);
	// add r4,r26,r4
	ctx.r4.u64 = ctx.r26.u64 + ctx.r4.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d2fb90
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D2FB90;
loc_82D2FDE0:
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82e28f34
	ctx.lr = 0x82D2FDE8;
	__restfpr_16(ctx, base);
	// b 0x82e28ea0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2FDF0"))) PPC_WEAK_FUNC(sub_82D2FDF0);
PPC_FUNC_IMPL(__imp__sub_82D2FDF0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-6440
	ctx.r5.s64 = ctx.r11.s64 + -6440;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-1256
	ctx.r4.s64 = ctx.r11.s64 + -1256;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D2FE08"))) PPC_WEAK_FUNC(sub_82D2FE08);
PPC_FUNC_IMPL(__imp__sub_82D2FE08) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e3c
	ctx.lr = 0x82D2FE10;
	__savegprlr_17(ctx, base);
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82e28ee0
	ctx.lr = 0x82D2FE18;
	__savefpr_14(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d300d4
	if (!ctx.cr6.gt) goto loc_82D300D4;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// rlwinm r18,r11,2,0,29
	ctx.r18.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// rlwinm r17,r11,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f13,-6316(r20)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -6316);
	ctx.f13.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f19,-6320(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -6320);
	ctx.f19.f64 = double(temp.f32);
	// lis r24,-32255
	ctx.r24.s64 = -2113863680;
	// stfs f13,-284(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f14,-6324(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -6324);
	ctx.f14.f64 = double(temp.f32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f20,-7588(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -7588);
	ctx.f20.f64 = double(temp.f32);
	// lis r29,-32255
	ctx.r29.s64 = -2113863680;
	// lfs f21,-7584(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -7584);
	ctx.f21.f64 = double(temp.f32);
	// lis r30,-32229
	ctx.r30.s64 = -2112159744;
	// lfs f15,-12288(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -12288);
	ctx.f15.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f22,-6328(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -6328);
	ctx.f22.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f23,-6332(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -6332);
	ctx.f23.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f16,-7592(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -7592);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-28552(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -28552);
	ctx.f17.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f0,-13884(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -13884);
	ctx.f0.f64 = double(temp.f32);
	// lfs f18,-6336(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -6336);
	ctx.f18.f64 = double(temp.f32);
	// lfs f24,-6340(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6340);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,-6344(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6344);
	ctx.f25.f64 = double(temp.f32);
loc_82D2FEAC:
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f13,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// mulli r31,r8,12
	ctx.r31.s64 = ctx.r8.s64 * 12;
	// lfs f12,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f11,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f9,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f9.f64 = double(temp.f32);
	// mulli r11,r8,24
	ctx.r11.s64 = ctx.r8.s64 * 24;
	// lfsx f8,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f8.f64 = double(temp.f32);
	// fadds f1,f8,f9
	ctx.f1.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// mulli r11,r8,20
	ctx.r11.s64 = ctx.r8.s64 * 20;
	// lfsx f7,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f29,f7,f13
	ctx.f29.f64 = double(float(ctx.f7.f64 + ctx.f13.f64));
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// fsubs f13,f13,f7
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
	// fmuls f26,f9,f22
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f22.f64));
	// fmuls f9,f9,f23
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// stfs f9,-288(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfsx f6,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f6.f64 = double(temp.f32);
	// mulli r11,r9,24
	ctx.r11.s64 = ctx.r9.s64 * 24;
	// lfsx f5,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f7,f5,f6
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// mulli r11,r9,20
	ctx.r11.s64 = ctx.r9.s64 * 20;
	// lfsx f10,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f4,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f2,f10,f11
	ctx.f2.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fsubs f5,f12,f4
	ctx.f5.f64 = double(float(ctx.f12.f64 - ctx.f4.f64));
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f12,f4,f12
	ctx.f12.f64 = double(float(ctx.f4.f64 + ctx.f12.f64));
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// fsubs f30,f11,f10
	ctx.f30.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// lfsx f10,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f3,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f10,f24
	ctx.f28.f64 = double(float(ctx.f10.f64 * ctx.f24.f64));
	// fnmsubs f4,f2,f17,f3
	ctx.f4.f64 = double(float(-(ctx.f2.f64 * ctx.f17.f64 - ctx.f3.f64)));
	// fmadds f9,f2,f0,f3
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f3.f64));
	// rlwinm r11,r9,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f3,f29,f1
	ctx.f3.f64 = double(float(ctx.f29.f64 + ctx.f1.f64));
	// rlwinm r31,r8,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f2,f29,f1
	ctx.f2.f64 = double(float(ctx.f29.f64 - ctx.f1.f64));
	// rlwinm r30,r9,3,0,28
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f29,f5,f7
	ctx.f29.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f7,f5,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// mulli r29,r7,12
	ctx.r29.s64 = ctx.r7.s64 * 12;
	// fmuls f5,f12,f20
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f20.f64));
	// fmuls f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f18.f64));
	// lfsx f11,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f27,f11,f24
	ctx.f27.f64 = double(float(ctx.f11.f64 * ctx.f24.f64));
	// lfsx f31,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f31.f64 = double(temp.f32);
	// fmadds f11,f11,f25,f28
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f25.f64 + ctx.f28.f64));
	// lfsx f8,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f1,f13,f23,f26
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f23.f64 - ctx.f26.f64));
	// fmuls f2,f2,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// mulli r11,r7,20
	ctx.r11.s64 = ctx.r7.s64 * 20;
	// fmuls f7,f7,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f14.f64));
	// fmsubs f10,f10,f25,f27
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f25.f64 - ctx.f27.f64));
	// fmuls f27,f8,f19
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f19.f64));
	// lfs f28,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f13,f13,f22,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f22.f64 + ctx.f28.f64));
	// mulli r31,r7,24
	ctx.r31.s64 = ctx.r7.s64 * 24;
	// fmuls f28,f6,f20
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// fmsubs f6,f6,f21,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f21.f64 - ctx.f5.f64));
	// fadds f5,f4,f30
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f30.f64));
	// fsubs f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// fnmsubs f30,f3,f15,f31
	ctx.f30.f64 = double(float(-(ctx.f3.f64 * ctx.f15.f64 - ctx.f31.f64)));
	// fadds f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f31.f64));
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fmadds f12,f12,f21,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f21.f64 + ctx.f28.f64));
	// fsubs f28,f30,f2
	ctx.f28.f64 = double(float(ctx.f30.f64 - ctx.f2.f64));
	// fadds f2,f30,f2
	ctx.f2.f64 = double(float(ctx.f30.f64 + ctx.f2.f64));
	// fadds f30,f4,f10
	ctx.f30.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fsubs f10,f4,f10
	ctx.f10.f64 = double(float(ctx.f4.f64 - ctx.f10.f64));
	// fadds f4,f5,f11
	ctx.f4.f64 = double(float(ctx.f5.f64 + ctx.f11.f64));
	// fsubs f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 - ctx.f11.f64));
	// fsubs f5,f8,f29
	ctx.f5.f64 = double(float(ctx.f8.f64 - ctx.f29.f64));
	// lfs f8,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f8,f29,f8,f27
	ctx.f8.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 + ctx.f27.f64));
	// fmuls f5,f5,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// fsubs f29,f2,f12
	ctx.f29.f64 = double(float(ctx.f2.f64 - ctx.f12.f64));
	// rlwinm r28,r7,4,0,27
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f12,f2,f12
	ctx.f12.f64 = double(float(ctx.f2.f64 + ctx.f12.f64));
	// mulli r26,r7,28
	ctx.r26.s64 = ctx.r7.s64 * 28;
	// fsubs f2,f3,f9
	ctx.f2.f64 = double(float(ctx.f3.f64 - ctx.f9.f64));
	// fsubs f31,f6,f28
	ctx.f31.f64 = double(float(ctx.f6.f64 - ctx.f28.f64));
	// fadds f6,f28,f6
	ctx.f6.f64 = double(float(ctx.f28.f64 + ctx.f6.f64));
	// fadds f28,f8,f7
	ctx.f28.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// fsubs f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// fmadds f9,f3,f0,f9
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f9.f64));
	// stfs f9,0(r3)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// add r5,r17,r5
	ctx.r5.u64 = ctx.r17.u64 + ctx.r5.u64;
	// add r6,r17,r6
	ctx.r6.u64 = ctx.r17.u64 + ctx.r6.u64;
	// fsubs f3,f29,f4
	ctx.f3.f64 = double(float(ctx.f29.f64 - ctx.f4.f64));
	// fsubs f27,f11,f12
	ctx.f27.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// fsubs f26,f5,f2
	ctx.f26.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// stfsx f26,r11,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f31,f30
	ctx.f9.f64 = double(float(ctx.f31.f64 + ctx.f30.f64));
	// fsubs f7,f10,f6
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fadds f26,f28,f1
	ctx.f26.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// fsubs f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// fadds f28,f8,f13
	ctx.f28.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// fsubs f13,f8,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 - ctx.f13.f64));
	// fadds f8,f2,f5
	ctx.f8.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// stfsx f8,r10,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f10,f6,f0,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f10.f64));
	// stfsx f10,r31,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f10,f31,f0,f30
	ctx.f10.f64 = double(float(ctx.f31.f64 * ctx.f0.f64 - ctx.f30.f64));
	// stfsx f10,r30,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fnmadds f12,f12,f0,f11
	ctx.f12.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 + ctx.f11.f64)));
	// fmadds f11,f29,f0,f4
	ctx.f11.f64 = double(float(ctx.f29.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fadds f10,f9,f26
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f26.f64));
	// fadds f8,f7,f1
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// stfsx f8,r30,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fsubs f8,f1,f7
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfsx f8,r29,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f9,f26
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f26.f64));
	// stfsx f9,r28,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fsubs f9,f3,f28
	ctx.f9.f64 = double(float(ctx.f3.f64 - ctx.f28.f64));
	// fadds f8,f3,f28
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f28.f64));
	// fsubs f7,f27,f13
	ctx.f7.f64 = double(float(ctx.f27.f64 - ctx.f13.f64));
	// fadds f13,f27,f13
	ctx.f13.f64 = double(float(ctx.f27.f64 + ctx.f13.f64));
	// fneg f10,f10
	ctx.f10.u64 = ctx.f10.u64 ^ 0x8000000000000000;
	// stfsx f10,r31,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// stfsx f12,r28,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// stfsx f11,r29,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// stfsx f9,r11,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// stfs f8,0(r4)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// add r4,r18,r4
	ctx.r4.u64 = ctx.r18.u64 + ctx.r4.u64;
	// stfsx f7,r10,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f13,r26,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// lwz r11,3532(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 3532);
	// add r3,r18,r3
	ctx.r3.u64 = ctx.r18.u64 + ctx.r3.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d2feac
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D2FEAC;
loc_82D300D4:
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82e28f2c
	ctx.lr = 0x82D300DC;
	__restfpr_14(ctx, base);
	// b 0x82e28e8c
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D300E0"))) PPC_WEAK_FUNC(sub_82D300E0);
PPC_FUNC_IMPL(__imp__sub_82D300E0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-6392
	ctx.r5.s64 = ctx.r11.s64 + -6392;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,-504
	ctx.r4.s64 = ctx.r11.s64 + -504;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D300F8"))) PPC_WEAK_FUNC(sub_82D300F8);
PPC_FUNC_IMPL(__imp__sub_82D300F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D30100;
	__savegprlr_26(ctx, base);
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28f10
	ctx.lr = 0x82D30108;
	__savefpr_26(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d302f4
	if (!ctx.cr6.gt) goto loc_82D302F4;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r30,-32236
	ctx.r30.s64 = -2112618496;
	// lis r31,-32229
	ctx.r31.s64 = -2112159744;
	// rlwinm r28,r11,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// rlwinm r27,r11,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f13,120(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 120);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-13884(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -13884);
	ctx.f0.f64 = double(temp.f32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f11,-28552(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28552);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-7656(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -7656);
	ctx.f12.f64 = double(temp.f32);
loc_82D30148:
	// mulli r11,r8,20
	ctx.r11.s64 = ctx.r8.s64 * 20;
	// lfs f10,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f9,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f8.f64 = double(temp.f32);
	// mulli r11,r8,12
	ctx.r11.s64 = ctx.r8.s64 * 12;
	// lfsx f7,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f6.f64 = double(temp.f32);
	// fadds f29,f7,f8
	ctx.f29.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// mulli r11,r9,20
	ctx.r11.s64 = ctx.r9.s64 * 20;
	// fsubs f7,f10,f6
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fadds f28,f6,f10
	ctx.f28.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// lfsx f5,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f5.f64 = double(temp.f32);
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r10,r9,12
	ctx.r10.s64 = ctx.r9.s64 * 12;
	// fmuls f10,f8,f12
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmuls f8,f7,f12
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// lfsx f4,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f7,f4,f5
	ctx.f7.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fadds f4,f3,f9
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f9.f64));
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f6,f3,f9
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f9.f64));
	// rlwinm r31,r8,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r30,r9,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r29,r9,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r11,r7,12
	ctx.r11.s64 = ctx.r7.s64 * 12;
	// lfsx f2,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f1.f64 = double(temp.f32);
	// fadds f3,f28,f1
	ctx.f3.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// lfsx f31,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f9,f5,f12
	ctx.f9.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfsx f30,r29,r6
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r6.u32);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f5,f4,f12
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// fadds f4,f29,f2
	ctx.f4.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fnmsubs f2,f29,f11,f2
	ctx.f2.f64 = double(float(-(ctx.f29.f64 * ctx.f11.f64 - ctx.f2.f64)));
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmsubs f1,f28,f11,f1
	ctx.f1.f64 = double(float(-(ctx.f28.f64 * ctx.f11.f64 - ctx.f1.f64)));
	// rlwinm r31,r7,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f29,f31,f7
	ctx.f29.f64 = double(float(ctx.f31.f64 - ctx.f7.f64));
	// rlwinm r30,r7,3,0,28
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f28,f6,f30
	ctx.f28.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// mulli r29,r7,20
	ctx.r29.s64 = ctx.r7.s64 * 20;
	// fmadds f6,f6,f11,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f11.f64 + ctx.f30.f64));
	// fmadds f7,f7,f11,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f11.f64 + ctx.f31.f64));
	// fadds f30,f3,f4
	ctx.f30.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fsubs f31,f4,f3
	ctx.f31.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fadds f3,f5,f1
	ctx.f3.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// add r5,r27,r5
	ctx.r5.u64 = ctx.r27.u64 + ctx.r5.u64;
	// fsubs f4,f2,f9
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f9.f64));
	// add r6,r27,r6
	ctx.r6.u64 = ctx.r27.u64 + ctx.r6.u64;
	// fadds f27,f28,f29
	ctx.f27.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fadds f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// fsubs f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// fmuls f30,f30,f0
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// stfs f30,0(r3)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f30,f28,f29
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// fadds f29,f7,f10
	ctx.f29.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fsubs f28,f6,f8
	ctx.f28.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// fmuls f27,f27,f0
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// stfsx f27,r11,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fadds f27,f3,f4
	ctx.f27.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fsubs f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fsubs f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// fsubs f26,f30,f31
	ctx.f26.f64 = double(float(ctx.f30.f64 - ctx.f31.f64));
	// fadds f31,f31,f30
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f30.f64));
	// fadds f3,f28,f29
	ctx.f3.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fmuls f30,f27,f0
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fsubs f27,f28,f29
	ctx.f27.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// fmuls f29,f26,f13
	ctx.f29.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// stfsx f29,r10,r4
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmuls f31,f31,f13
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// stfsx f31,r31,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f7,f4,f3
	ctx.f7.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fneg f31,f30
	ctx.f31.u64 = ctx.f30.u64 ^ 0x8000000000000000;
	// stfsx f31,r30,r3
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmuls f31,f27,f0
	ctx.f31.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// stfsx f31,r29,r3
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f3,f4
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fmuls f7,f7,f13
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// stfs f7,0(r4)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmuls f7,f6,f13
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// stfsx f7,r11,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fadds f6,f5,f9
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// fsubs f7,f5,f9
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// fadds f9,f10,f8
	ctx.f9.f64 = double(float(ctx.f10.f64 + ctx.f8.f64));
	// fsubs f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 - ctx.f10.f64));
	// fmuls f8,f6,f0
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// stfsx f8,r31,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f9,f7
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// fsubs f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// stfsx f8,r30,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// stfsx f10,r10,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmuls f10,f9,f13
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// stfsx f10,r29,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,3532(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 3532);
	// add r3,r28,r3
	ctx.r3.u64 = ctx.r28.u64 + ctx.r3.u64;
	// add r4,r28,r4
	ctx.r4.u64 = ctx.r28.u64 + ctx.r4.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d30148
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D30148;
loc_82D302F4:
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28f5c
	ctx.lr = 0x82D302FC;
	__restfpr_26(ctx, base);
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D30300"))) PPC_WEAK_FUNC(sub_82D30300);
PPC_FUNC_IMPL(__imp__sub_82D30300) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-6312
	ctx.r5.s64 = ctx.r11.s64 + -6312;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,248
	ctx.r4.s64 = ctx.r11.s64 + 248;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D30318"))) PPC_WEAK_FUNC(sub_82D30318);
PPC_FUNC_IMPL(__imp__sub_82D30318) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82D30320;
	__savegprlr_25(ctx, base);
	// addi r12,r1,-64
	ctx.r12.s64 = ctx.r1.s64 + -64;
	// bl 0x82e28f10
	ctx.lr = 0x82D30328;
	__savefpr_26(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d304c0
	if (!ctx.cr6.gt) goto loc_82D304C0;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r26,-32255
	ctx.r26.s64 = -2113863680;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// rlwinm r29,r11,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// rlwinm r28,r11,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-32229
	ctx.r10.s64 = -2112159744;
	// lfs f30,-28552(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -28552);
	ctx.f30.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f12,-6344(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -6344);
	ctx.f12.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f13,-6340(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -6340);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-13884(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -13884);
	ctx.f0.f64 = double(temp.f32);
	// lfs f31,-6336(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6336);
	ctx.f31.f64 = double(temp.f32);
loc_82D30370:
	// rlwinm r11,r9,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f11,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f10,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// mulli r31,r9,12
	ctx.r31.s64 = ctx.r9.s64 * 12;
	// lfsx f9,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f8.f64 = double(temp.f32);
	// fadds f1,f11,f9
	ctx.f1.f64 = double(float(ctx.f11.f64 + ctx.f9.f64));
	// lfsx f7,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// fadds f9,f7,f8
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// lfsx f6,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f7,f10,f6
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f6.f64));
	// fsubs f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 - ctx.f10.f64));
	// rlwinm r30,r8,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r26,r9,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f27,f8,f13
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// rlwinm r25,r8,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r31,r7,12
	ctx.r31.s64 = ctx.r7.s64 * 12;
	// lfsx f4,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f6,f4,f5
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// lfsx f3,r26,r6
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r6.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfsx f2,r25,r5
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r5.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f4,f9,f1
	ctx.f4.f64 = double(float(ctx.f9.f64 - ctx.f1.f64));
	// fadds f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// fmuls f1,f8,f12
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmuls f26,f10,f13
	ctx.f26.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmuls f29,f3,f0
	ctx.f29.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// rlwinm r30,r7,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f28,f2,f0
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// add r5,r28,r5
	ctx.r5.u64 = ctx.r28.u64 + ctx.r5.u64;
	// add r6,r28,r6
	ctx.r6.u64 = ctx.r28.u64 + ctx.r6.u64;
	// fsubs f3,f4,f3
	ctx.f3.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fmuls f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmsubs f8,f11,f13,f1
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 - ctx.f1.f64));
	// fadds f1,f6,f7
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// fsubs f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f7.f64));
	// fmuls f6,f5,f13
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmadds f11,f11,f12,f27
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f12.f64 + ctx.f27.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fadds f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmadds f10,f10,f12,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + ctx.f6.f64));
	// fmsubs f6,f5,f12,f26
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 - ctx.f26.f64));
	// fmadds f5,f4,f30,f29
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f30.f64 + ctx.f29.f64));
	// fmsubs f4,f1,f30,f28
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f30.f64 - ctx.f28.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f2,0(r3)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfsx f3,r11,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fadds f3,f5,f9
	ctx.f3.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// fsubs f9,f5,f9
	ctx.f9.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// fsubs f5,f4,f7
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f7.f64));
	// fadds f7,f4,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// fadds f4,f3,f10
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f10.f64));
	// fadds f2,f5,f8
	ctx.f2.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// stfsx f2,r10,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f2,f7,f11
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// stfsx f2,r31,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fsubs f8,f8,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// stfsx f8,r30,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fsubs f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// stfsx f11,r11,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fsubs f11,f9,f6
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// fneg f4,f4
	ctx.f4.u64 = ctx.f4.u64 ^ 0x8000000000000000;
	// stfs f4,0(r4)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfsx f11,r31,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f11,f10,f3
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f3.f64));
	// stfsx f11,r30,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fadds f11,f9,f6
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f6.f64));
	// stfsx f11,r10,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,3532(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 3532);
	// add r4,r29,r4
	ctx.r4.u64 = ctx.r29.u64 + ctx.r4.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d30370
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D30370;
loc_82D304C0:
	// addi r12,r1,-64
	ctx.r12.s64 = ctx.r1.s64 + -64;
	// bl 0x82e28f5c
	ctx.lr = 0x82D304C8;
	__restfpr_26(ctx, base);
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D304D0"))) PPC_WEAK_FUNC(sub_82D304D0);
PPC_FUNC_IMPL(__imp__sub_82D304D0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-6264
	ctx.r5.s64 = ctx.r11.s64 + -6264;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,792
	ctx.r4.s64 = ctx.r11.s64 + 792;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D304E8"))) PPC_WEAK_FUNC(sub_82D304E8);
PPC_FUNC_IMPL(__imp__sub_82D304E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e44
	ctx.lr = 0x82D304F0;
	__savegprlr_19(ctx, base);
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28f00
	ctx.lr = 0x82D304F8;
	__savefpr_22(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d306b0
	if (!ctx.cr6.gt) goto loc_82D306B0;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// rlwinm r20,r11,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// rlwinm r19,r11,2,0,29
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f22,-6140(r21)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -6140);
	ctx.f22.f64 = double(temp.f32);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f23,-6144(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -6144);
	ctx.f23.f64 = double(temp.f32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f24,-6148(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -6148);
	ctx.f24.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lis r29,-32255
	ctx.r29.s64 = -2113863680;
	// lfs f25,-6152(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -6152);
	ctx.f25.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f26,-6156(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -6156);
	ctx.f26.f64 = double(temp.f32);
	// lis r10,-32229
	ctx.r10.s64 = -2112159744;
	// lfs f27,-6160(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -6160);
	ctx.f27.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f28,-6164(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -6164);
	ctx.f28.f64 = double(temp.f32);
	// lfs f29,-6168(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -6168);
	ctx.f29.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f30,-28552(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -28552);
	ctx.f30.f64 = double(temp.f32);
	// lfs f31,-7656(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -7656);
	ctx.f31.f64 = double(temp.f32);
	// lfs f0,-13884(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -13884);
	ctx.f0.f64 = double(temp.f32);
	// lfs f1,-6320(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6320);
	ctx.f1.f64 = double(temp.f32);
loc_82D30578:
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f13,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r10,r9,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mulli r31,r8,12
	ctx.r31.s64 = ctx.r8.s64 * 12;
	// lfsx f11,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f10.f64 = double(temp.f32);
	// fadds f4,f11,f13
	ctx.f4.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// lfsx f9,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f3,f10,f12
	ctx.f3.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// fsubs f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// rlwinm r31,r8,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// rlwinm r29,r8,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// lfsx f7,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r29,r5
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r5.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r28,r6
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r6.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f11,f6,f7
	ctx.f11.f64 = double(float(ctx.f6.f64 - ctx.f7.f64));
	// lfsx f8,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// fmadds f10,f6,f0,f7
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f7.f64));
	// fadds f7,f4,f9
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f9.f64));
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f6,f3,f8
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f8.f64));
	// mulli r10,r7,12
	ctx.r10.s64 = ctx.r7.s64 * 12;
	// fmadds f8,f3,f30,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f30.f64 + ctx.f8.f64));
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fmsubs f9,f4,f30,f9
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f30.f64 - ctx.f9.f64));
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fadds f4,f11,f5
	ctx.f4.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// fsubs f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// rlwinm r29,r7,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f5,f7,f10
	ctx.f5.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// rlwinm r31,r7,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f6,f6,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// add r5,r19,r5
	ctx.r5.u64 = ctx.r19.u64 + ctx.r5.u64;
	// fmadds f10,f7,f0,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 + ctx.f10.f64));
	// stfs f10,0(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f2,f13,f8
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// add r6,r19,r6
	ctx.r6.u64 = ctx.r19.u64 + ctx.r6.u64;
	// fadds f13,f8,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// fadds f3,f9,f12
	ctx.f3.f64 = double(float(ctx.f9.f64 + ctx.f12.f64));
	// fsubs f12,f9,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 - ctx.f12.f64));
	// fadds f10,f6,f5
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f5.f64));
	// stfsx f10,r11,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fsubs f10,f6,f5
	ctx.f10.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// stfsx f10,r10,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmuls f10,f2,f26
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// fmuls f8,f13,f22
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f22.f64));
	// fmuls f9,f3,f28
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// fmuls f7,f12,f24
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f24.f64));
	// fmadds f10,f3,f27,f10
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f27.f64 + ctx.f10.f64));
	// fmsubs f12,f12,f23,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f23.f64 - ctx.f8.f64));
	// fmsubs f9,f2,f29,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f29.f64 - ctx.f9.f64));
	// fmadds f13,f13,f25,f7
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f25.f64 + ctx.f7.f64));
	// fsubs f8,f4,f10
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f10.f64));
	// fsubs f7,f12,f11
	ctx.f7.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// fnmadds f10,f10,f0,f4
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f0.f64 + ctx.f4.f64)));
	// stfsx f10,r11,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fmadds f12,f12,f0,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f11.f64));
	// fsubs f10,f9,f8
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// stfsx f10,r29,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f8,f9
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// stfsx f10,r31,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// stfs f12,0(r4)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f10,f13,f7
	ctx.f10.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
	// stfsx f10,r10,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f13,f7,f13
	ctx.f13.f64 = double(float(ctx.f7.f64 + ctx.f13.f64));
	// stfsx f13,r31,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// lwz r11,3532(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// add r4,r20,r4
	ctx.r4.u64 = ctx.r20.u64 + ctx.r4.u64;
	// add r3,r20,r3
	ctx.r3.u64 = ctx.r20.u64 + ctx.r3.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d30578
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D30578;
loc_82D306B0:
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28f4c
	ctx.lr = 0x82D306B8;
	__restfpr_22(ctx, base);
	// b 0x82e28e94
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D306C0"))) PPC_WEAK_FUNC(sub_82D306C0);
PPC_FUNC_IMPL(__imp__sub_82D306C0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-6216
	ctx.r5.s64 = ctx.r11.s64 + -6216;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,1256
	ctx.r4.s64 = ctx.r11.s64 + 1256;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D306D8"))) PPC_WEAK_FUNC(sub_82D306D8);
PPC_FUNC_IMPL(__imp__sub_82D306D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82D306E0;
	__savegprlr_25(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d30820
	if (!ctx.cr6.gt) goto loc_82D30820;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r27,-32236
	ctx.r27.s64 = -2112618496;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// rlwinm r29,r11,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f1,120(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 120);
	ctx.f1.f64 = double(temp.f32);
	// lfs f13,-8128(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8128);
	ctx.f13.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f0,124(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 124);
	ctx.f0.f64 = double(temp.f32);
	// lfs f2,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f2.f64 = double(temp.f32);
loc_82D30720:
	// mulli r11,r8,12
	ctx.r11.s64 = ctx.r8.s64 * 12;
	// lfs f12,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mulli r10,r9,12
	ctx.r10.s64 = ctx.r9.s64 * 12;
	// lfs f11,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f4,f12,f10
	ctx.f4.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// lfsx f9,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f10,f9,f11
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// rlwinm r31,r8,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// rlwinm r27,r8,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r26,r9,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r25,r9,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f8,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f8.f64 = double(temp.f32);
	// mulli r31,r7,12
	ctx.r31.s64 = ctx.r7.s64 * 12;
	// lfsx f7,r27,r5
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r5.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r26,r6
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r6.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f9,f8,f7
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// lfsx f5,r25,r6
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r6.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fadds f7,f5,f6
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// add r5,r29,r5
	ctx.r5.u64 = ctx.r29.u64 + ctx.r5.u64;
	// add r6,r29,r6
	ctx.r6.u64 = ctx.r29.u64 + ctx.r6.u64;
	// fadds f5,f9,f10
	ctx.f5.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// fsubs f9,f4,f7
	ctx.f9.f64 = double(float(ctx.f4.f64 - ctx.f7.f64));
	// fadds f7,f7,f4
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// fsubs f4,f12,f8
	ctx.f4.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// fadds f12,f8,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fadds f3,f6,f11
	ctx.f3.f64 = double(float(ctx.f6.f64 + ctx.f11.f64));
	// fsubs f11,f11,f6
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f6.f64));
	// fmuls f8,f7,f13
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f12,f12,f2
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// stfs f12,0(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f6,f3,f4
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fmuls f12,f11,f2
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f2.f64));
	// stfsx f12,r11,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fmuls f12,f5,f13
	ctx.f12.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmuls f11,f9,f13
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fsubs f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// fmsubs f12,f9,f0,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 - ctx.f12.f64));
	// stfs f12,0(r4)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fnmadds f12,f5,f0,f11
	ctx.f12.f64 = double(float(-(ctx.f5.f64 * ctx.f0.f64 + ctx.f11.f64)));
	// stfsx f12,r11,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f10,f0,f8
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f8.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f12,f10,f13,f7
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 - ctx.f7.f64));
	// stfsx f12,r31,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fmuls f12,f6,f1
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmuls f12,f4,f1
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// stfsx f12,r31,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// lwz r11,3532(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3532);
	// add r3,r30,r3
	ctx.r3.u64 = ctx.r30.u64 + ctx.r3.u64;
	// add r4,r30,r4
	ctx.r4.u64 = ctx.r30.u64 + ctx.r4.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d30720
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D30720;
loc_82D30820:
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D30828"))) PPC_WEAK_FUNC(sub_82D30828);
PPC_FUNC_IMPL(__imp__sub_82D30828) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-6136
	ctx.r5.s64 = ctx.r11.s64 + -6136;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,1752
	ctx.r4.s64 = ctx.r11.s64 + 1752;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D30840"))) PPC_WEAK_FUNC(sub_82D30840);
PPC_FUNC_IMPL(__imp__sub_82D30840) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D30848;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f08
	ctx.lr = 0x82D30850;
	__savefpr_24(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d309a0
	if (!ctx.cr6.gt) goto loc_82D309A0;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r24,-32229
	ctx.r24.s64 = -2112159744;
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// rlwinm r29,r11,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f31,-13884(r24)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -13884);
	ctx.f31.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f2,-6020(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -6020);
	ctx.f2.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f3,-6024(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -6024);
	ctx.f3.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f4,-6028(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -6028);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,-6032(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -6032);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,-6036(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6036);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,-6040(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6040);
	ctx.f7.f64 = double(temp.f32);
loc_82D308A8:
	// lfs f0,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f1,f0,f3
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// rlwinm r28,r8,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r27,r8,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f10,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// mulli r26,r8,12
	ctx.r26.s64 = ctx.r8.s64 * 12;
	// fmuls f30,f10,f7
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// fmuls f29,f10,f6
	ctx.f29.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// lfsx f9,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f13,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f28,f9,f6
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// lfsx f12,r27,r5
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r5.u32);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f27,f13,f3
	ctx.f27.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// lfsx f11,r26,r5
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r5.u32);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f26,f12,f3
	ctx.f26.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fnmadds f25,f13,f2,f11
	ctx.f25.f64 = double(float(-(ctx.f13.f64 * ctx.f2.f64 + ctx.f11.f64)));
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmadds f24,f12,f2,f11
	ctx.f24.f64 = double(float(-(ctx.f12.f64 * ctx.f2.f64 + ctx.f11.f64)));
	// fmadds f1,f12,f4,f1
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f4.f64 + ctx.f1.f64));
	// mulli r28,r7,12
	ctx.r28.s64 = ctx.r7.s64 * 12;
	// fmsubs f29,f9,f7,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f7.f64 - ctx.f29.f64));
	// lfsx f8,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f28,f8,f7,f28
	ctx.f28.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 + ctx.f28.f64));
	// fmadds f27,f0,f4,f27
	ctx.f27.f64 = double(float(ctx.f0.f64 * ctx.f4.f64 + ctx.f27.f64));
	// fmsubs f30,f8,f6,f30
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f6.f64 - ctx.f30.f64));
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fnmadds f26,f13,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f13.f64 * ctx.f4.f64 + ctx.f26.f64)));
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f25.f64));
	// add r5,r29,r5
	ctx.r5.u64 = ctx.r29.u64 + ctx.r5.u64;
	// fadds f25,f12,f13
	ctx.f25.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// add r6,r29,r6
	ctx.r6.u64 = ctx.r29.u64 + ctx.r6.u64;
	// fmadds f10,f10,f5,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f5.f64 + ctx.f28.f64));
	// fmadds f28,f0,f2,f11
	ctx.f28.f64 = double(float(ctx.f0.f64 * ctx.f2.f64 + ctx.f11.f64));
	// fnmsubs f13,f9,f5,f30
	ctx.f13.f64 = double(float(-(ctx.f9.f64 * ctx.f5.f64 - ctx.f30.f64)));
	// fadds f12,f27,f24
	ctx.f12.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// fnmsubs f9,f8,f5,f29
	ctx.f9.f64 = double(float(-(ctx.f8.f64 * ctx.f5.f64 - ctx.f29.f64)));
	// fadds f0,f25,f0
	ctx.f0.f64 = double(float(ctx.f25.f64 + ctx.f0.f64));
	// fadds f8,f26,f28
	ctx.f8.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fmadds f0,f0,f31,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f31.f64 + ctx.f11.f64));
	// fadds f11,f1,f10
	ctx.f11.f64 = double(float(ctx.f1.f64 + ctx.f10.f64));
	// fsubs f10,f1,f10
	ctx.f10.f64 = double(float(ctx.f1.f64 - ctx.f10.f64));
	// stfs f10,0(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f10,f13,f12
	ctx.f10.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fsubs f12,f9,f8
	ctx.f12.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fneg f11,f11
	ctx.f11.u64 = ctx.f11.u64 ^ 0x8000000000000000;
	// stfsx f11,r28,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// stfsx f10,r11,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fadds f11,f8,f9
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// stfsx f13,r10,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfsx f12,r11,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// add r4,r30,r4
	ctx.r4.u64 = ctx.r30.u64 + ctx.r4.u64;
	// stfsx f11,r10,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfs f0,0(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lwz r11,3532(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 3532);
	// add r3,r30,r3
	ctx.r3.u64 = ctx.r30.u64 + ctx.r3.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d308a8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D308A8;
loc_82D309A0:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f54
	ctx.lr = 0x82D309A8;
	__restfpr_24(ctx, base);
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D309B0"))) PPC_WEAK_FUNC(sub_82D309B0);
PPC_FUNC_IMPL(__imp__sub_82D309B0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-6088
	ctx.r5.s64 = ctx.r11.s64 + -6088;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,2112
	ctx.r4.s64 = ctx.r11.s64 + 2112;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D309C8"))) PPC_WEAK_FUNC(sub_82D309C8);
PPC_FUNC_IMPL(__imp__sub_82D309C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D309D0;
	__savegprlr_26(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d30ab0
	if (!ctx.cr6.gt) goto loc_82D30AB0;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r10,-32229
	ctx.r10.s64 = -2112159744;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f0,-13884(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -13884);
	ctx.f0.f64 = double(temp.f32);
	// lfs f5,-6320(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6320);
	ctx.f5.f64 = double(temp.f32);
loc_82D30A00:
	// rlwinm r28,r8,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r9,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f13,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r26,r8,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r27,r9,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f10,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f11,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f11.f64 = double(temp.f32);
	// fadds f6,f12,f10
	ctx.f6.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// fadds f7,f13,f11
	ctx.f7.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
	// lfsx f8,r26,r5
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r5.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// lfsx f9,r27,r6
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r6.u32);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// add r6,r30,r6
	ctx.r6.u64 = ctx.r30.u64 + ctx.r6.u64;
	// add r5,r30,r5
	ctx.r5.u64 = ctx.r30.u64 + ctx.r5.u64;
	// fmsubs f10,f8,f0,f6
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f6.f64));
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// fmuls f13,f12,f5
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f5.f64));
	// fmuls f12,f11,f5
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// fmadds f11,f9,f0,f7
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 + ctx.f7.f64));
	// fsubs f9,f9,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// stfs f8,0(r3)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// stfsx f9,r11,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fadds f9,f11,f13
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// fsubs f11,f12,f10
	ctx.f11.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fneg f10,f9
	ctx.f10.u64 = ctx.f9.u64 ^ 0x8000000000000000;
	// stfs f10,0(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfsx f13,r10,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// stfsx f11,r11,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lwz r11,3532(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3532);
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d30a00
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D30A00;
loc_82D30AB0:
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D30AB8"))) PPC_WEAK_FUNC(sub_82D30AB8);
PPC_FUNC_IMPL(__imp__sub_82D30AB8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-6016
	ctx.r5.s64 = ctx.r11.s64 + -6016;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,2504
	ctx.r4.s64 = ctx.r11.s64 + 2504;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D30AD0"))) PPC_WEAK_FUNC(sub_82D30AD0);
PPC_FUNC_IMPL(__imp__sub_82D30AD0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D30AD8;
	__savegprlr_26(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d30bc0
	if (!ctx.cr6.gt) goto loc_82D30BC0;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r26,-32229
	ctx.r26.s64 = -2112159744;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r28,-32255
	ctx.r28.s64 = -2113863680;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f4,-13884(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -13884);
	ctx.f4.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f5,-6336(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -6336);
	ctx.f5.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f6,-28552(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -28552);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,-6340(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -6340);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,-6344(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6344);
	ctx.f8.f64 = double(temp.f32);
loc_82D30B20:
	// rlwinm r29,r8,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f9,f13,f7
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fmuls f3,f13,f8
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// rlwinm r27,r9,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r28,r8,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f12,r29,r5
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r5.u32);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r26,r7,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// lfsx f10,r27,r6
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r6.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f11,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f11.f64 = double(temp.f32);
	// add r6,r31,r6
	ctx.r6.u64 = ctx.r31.u64 + ctx.r6.u64;
	// add r5,r31,r5
	ctx.r5.u64 = ctx.r31.u64 + ctx.r5.u64;
	// fmadds f12,f10,f8,f9
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f8.f64 + ctx.f9.f64));
	// fmsubs f10,f10,f7,f3
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f7.f64 - ctx.f3.f64));
	// fmsubs f9,f13,f6,f11
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f6.f64 - ctx.f11.f64));
	// fmuls f0,f0,f5
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// fmadds f13,f13,f4,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f4.f64 + ctx.f11.f64));
	// stfs f13,0(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f13,f0,f9
	ctx.f13.f64 = double(float(ctx.f0.f64 + ctx.f9.f64));
	// fsubs f0,f0,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f9.f64));
	// fadds f11,f13,f12
	ctx.f11.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// fadds f9,f0,f10
	ctx.f9.f64 = double(float(ctx.f0.f64 + ctx.f10.f64));
	// stfsx f9,r11,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fsubs f0,f10,f0
	ctx.f0.f64 = double(float(ctx.f10.f64 - ctx.f0.f64));
	// stfsx f0,r11,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f13,f12
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// stfs f0,0(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// fneg f0,f11
	ctx.f0.u64 = ctx.f11.u64 ^ 0x8000000000000000;
	// stfsx f0,r26,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// lwz r11,3532(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d30b20
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D30B20;
loc_82D30BC0:
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D30BC8"))) PPC_WEAK_FUNC(sub_82D30BC8);
PPC_FUNC_IMPL(__imp__sub_82D30BC8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-5968
	ctx.r5.s64 = ctx.r11.s64 + -5968;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,2768
	ctx.r4.s64 = ctx.r11.s64 + 2768;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D30BE0"))) PPC_WEAK_FUNC(sub_82D30BE0);
PPC_FUNC_IMPL(__imp__sub_82D30BE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D30BE8;
	__savegprlr_28(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d30c94
	if (!ctx.cr6.gt) goto loc_82D30C94;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r29,-32236
	ctx.r29.s64 = -2112618496;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f7,120(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f8.f64 = double(temp.f32);
loc_82D30C18:
	// rlwinm r29,r8,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f12,r29,r5
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r5.u32);
	ctx.f12.f64 = double(temp.f32);
	// add r5,r31,r5
	ctx.r5.u64 = ctx.r31.u64 + ctx.r5.u64;
	// lfsx f11,r28,r6
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r6.u32);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f10,f0,f12
	ctx.f10.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fadds f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// add r6,r31,r6
	ctx.r6.u64 = ctx.r31.u64 + ctx.r6.u64;
	// fadds f9,f11,f13
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// fmuls f0,f0,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// stfs f0,0(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f0,f13,f8
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// stfsx f0,r11,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f9,f10
	ctx.f0.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fsubs f13,f10,f9
	ctx.f13.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fmuls f0,f0,f7
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fmuls f13,f13,f7
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// stfs f13,0(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fneg f0,f0
	ctx.f0.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// stfsx f0,r11,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,3532(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d30c18
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D30C18;
loc_82D30C94:
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D30C98"))) PPC_WEAK_FUNC(sub_82D30C98);
PPC_FUNC_IMPL(__imp__sub_82D30C98) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-5920
	ctx.r5.s64 = ctx.r11.s64 + -5920;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,3040
	ctx.r4.s64 = ctx.r11.s64 + 3040;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D30CB0"))) PPC_WEAK_FUNC(sub_82D30CB0);
PPC_FUNC_IMPL(__imp__sub_82D30CB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d30d40
	if (!ctx.cr6.gt) goto loc_82D30D40;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r30,-32229
	ctx.r30.s64 = -2112159744;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f9,-13884(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -13884);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-6320(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6320);
	ctx.f10.f64 = double(temp.f32);
loc_82D30CE8:
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// add r6,r9,r6
	ctx.r6.u64 = ctx.r9.u64 + ctx.r6.u64;
	// lfsx f12,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f12.f64 = double(temp.f32);
	// add r5,r9,r5
	ctx.r5.u64 = ctx.r9.u64 + ctx.r5.u64;
	// fsubs f11,f0,f12
	ctx.f11.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fmadds f0,f0,f9,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f9.f64 + ctx.f12.f64));
	// stfs f0,0(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f0,f11,f13
	ctx.f0.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// fneg f0,f0
	ctx.f0.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// stfsx f0,r30,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// stfs f13,0(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lwz r11,3532(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 3532);
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d30ce8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D30CE8;
loc_82D30D40:
	// ld r30,-16(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D30D50"))) PPC_WEAK_FUNC(sub_82D30D50);
PPC_FUNC_IMPL(__imp__sub_82D30D50) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-5872
	ctx.r5.s64 = ctx.r11.s64 + -5872;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,3248
	ctx.r4.s64 = ctx.r11.s64 + 3248;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D30D68"))) PPC_WEAK_FUNC(sub_82D30D68);
PPC_FUNC_IMPL(__imp__sub_82D30D68) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// blelr cr6
	if (!ctx.cr6.gt) return;
	// lis r9,-32229
	ctx.r9.s64 = -2112159744;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,-13884(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -13884);
	ctx.f0.f64 = double(temp.f32);
loc_82D30D8C:
	// lfs f13,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// add r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 + ctx.r6.u64;
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f12,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f12,0(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// add r5,r10,r5
	ctx.r5.u64 = ctx.r10.u64 + ctx.r5.u64;
	// add r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
	// fneg f13,f13
	ctx.f13.u64 = ctx.f13.u64 ^ 0x8000000000000000;
	// stfs f13,0(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// add r4,r11,r4
	ctx.r4.u64 = ctx.r11.u64 + ctx.r4.u64;
	// bdnz 0x82d30d8c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D30D8C;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D30DC0"))) PPC_WEAK_FUNC(sub_82D30DC0);
PPC_FUNC_IMPL(__imp__sub_82D30DC0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-5824
	ctx.r5.s64 = ctx.r11.s64 + -5824;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,3432
	ctx.r4.s64 = ctx.r11.s64 + 3432;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D30DD8"))) PPC_WEAK_FUNC(sub_82D30DD8);
PPC_FUNC_IMPL(__imp__sub_82D30DD8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D30DE0;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D30DE8;
	__savefpr_14(ctx, base);
	// stwu r1,-800(r1)
	ea = -800 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// addi r11,r11,-32
	ctx.r11.s64 = ctx.r11.s64 + -32;
	// bge cr6,0x82d326cc
	if (!ctx.cr6.lt) goto loc_82D326CC;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lis r9,-32236
	ctx.r9.s64 = -2112618496;
	// stw r10,440(r1)
	PPC_STORE_U32(ctx.r1.u32 + 440, ctx.r10.u32);
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lfs f31,-8000(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8000);
	ctx.f31.f64 = double(temp.f32);
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lfs f1,-8004(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8004);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,-8008(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -8008);
	ctx.f2.f64 = double(temp.f32);
	// lfs f11,136(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 136);
	ctx.f11.f64 = double(temp.f32);
	// stw r10,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, ctx.r10.u32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f3,-8012(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -8012);
	ctx.f3.f64 = double(temp.f32);
	// lfs f10,-8016(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -8016);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f12.f64 = double(temp.f32);
loc_82D30E48:
	// lfs f0,24(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// lfs f9,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f30,f0,f9
	ctx.f30.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f25,f0,f8
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f4,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f24,f9,f5
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// lfs f7,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f22,f8,f4
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// lfs f6,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f29,f5,f7
	ctx.f29.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// fmuls f28,f4,f6
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f13,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f26,f4,f7
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// fmuls f27,f5,f6
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fmuls f20,f0,f7
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fmuls f16,f13,f6
	ctx.f16.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fmadds f30,f13,f8,f30
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 + ctx.f30.f64));
	// stfs f30,340(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fmuls f19,f0,f4
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// fmuls f15,f13,f5
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// fmsubs f30,f13,f9,f25
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 - ctx.f25.f64));
	// stfs f30,348(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fmuls f21,f8,f5
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// fadds f30,f28,f29
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fsubs f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fadds f28,f26,f27
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fsubs f26,f24,f22
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f22,f20,f16
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f22,380(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fsubs f22,f15,f19
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f22,124(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fmuls f23,f9,f4
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// fmuls f18,f0,f6
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// fmuls f22,f13,f7
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fmuls f17,f0,f5
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// fadds f25,f21,f23
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// fadds f21,f22,f18
	ctx.f21.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// stfs f21,324(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fmuls f21,f13,f4
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f22,436(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// fadds f22,f15,f19
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f22,360(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// fmuls f19,f13,f27
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f27.f64));
	// fmuls f18,f0,f27
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f27.f64));
	// fmuls f15,f25,f0
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fadds f22,f21,f17
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// stfs f22,260(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fadds f22,f16,f20
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f22,388(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fmuls f16,f26,f0
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fsubs f14,f17,f21
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// stfs f14,296(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fmuls f14,f24,f0
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f22,f0,f30
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmuls f21,f13,f30
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// fmuls f20,f0,f29
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// fmuls f17,f13,f28
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// fmadds f16,f25,f13,f16
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f16,400(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// fmsubs f16,f26,f13,f15
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f16,392(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fmadds f16,f23,f13,f14
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f16,416(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fsubs f16,f22,f19
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f16,432(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f22,428(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// fadds f22,f18,f21
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f22,424(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// fsubs f22,f21,f18
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f22,352(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// fadds f22,f17,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f22,376(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fsubs f22,f20,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f22,384(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fmuls f21,f0,f28
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// mulli r10,r6,60
	ctx.r10.s64 = ctx.r6.s64 * 60;
	// fmuls f22,f13,f29
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// mulli r8,r6,108
	ctx.r8.s64 = ctx.r6.s64 * 108;
	// fmuls f18,f8,f7
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fmuls f19,f9,f6
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f16,f9,f30
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fmuls f15,f8,f27
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmuls f17,f8,f6
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// fmuls f14,f8,f30
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fsubs f20,f22,f21
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f20,372(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f22,332(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fmuls f22,f9,f27
	ctx.f22.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f21,f18,f19
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f21,184(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// add r25,r8,r4
	ctx.r25.u64 = ctx.r8.u64 + ctx.r4.u64;
	// fmuls f18,f23,f0
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f19,308(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fmuls f20,f9,f7
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// stw r8,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r8.u32);
	// mulli r9,r6,80
	ctx.r9.s64 = ctx.r6.s64 * 80;
	// stw r25,456(r1)
	PPC_STORE_U32(ctx.r1.u32 + 456, ctx.r25.u32);
	// fmsubs f18,f24,f13,f18
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f18,408(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// fadds f22,f17,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f22,268(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fadds f18,f15,f16
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f18,208(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f20,300(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fsubs f18,f16,f15
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f18,264(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fmuls f16,f8,f28
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f14,f17
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f18,356(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,236(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fmuls f17,f9,f29
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// fmuls f14,f19,f0
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fsubs f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f15,216(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,232(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fmuls f16,f9,f28
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f17,f8,f29
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// fadds f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f15,224(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,220(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fmuls f16,f21,f0
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fmuls f15,f20,f0
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmuls f17,f22,f0
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmsubs f22,f22,f13,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f22,448(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// fmadds f22,f19,f13,f15
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f22,484(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 484, temp.u32);
	// fmsubs f22,f20,f13,f14
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f22,312(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfsx f22,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f21,f21,f13,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f21,480(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// fmuls f20,f18,f0
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f22,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f21,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f0
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// lfs f17,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f15,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmadds f22,f18,f13,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f22.f64));
	// stfs f22,344(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// lfs f22,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmsubs f21,f22,f13,f21
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f21.f64));
	// lfs f22,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f13,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f20.f64));
	// stfs f22,288(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f22,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f22.f64 = double(temp.f32);
	// rlwinm r7,r6,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fmadds f20,f22,f13,f19
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f19.f64));
	// lfs f22,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f13,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f22,272(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f22,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f22.f64 = double(temp.f32);
	// mulli r5,r6,48
	ctx.r5.s64 = ctx.r6.s64 * 48;
	// fmsubs f22,f22,f13,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f22,468(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// lfs f22,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f13,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f22,336(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f22,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f13,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f22,412(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// rlwinm r31,r6,5,0,26
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f19,f18,f22
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// mulli r30,r6,28
	ctx.r30.s64 = ctx.r6.s64 * 28;
	// fsubs f18,f22,f18
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// lfsx f22,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f22,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f22,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,76(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f22,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r29,r6,124
	ctx.r29.s64 = ctx.r6.s64 * 124;
	// stfs f22,68(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f17,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f22,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,28(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// rlwinm r28,r6,6,0,25
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 6) & 0xFFFFFFC0;
	// mulli r27,r6,92
	ctx.r27.s64 = ctx.r6.s64 * 92;
	// lfsx f22,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,100(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfsx f22,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r26,r6,96
	ctx.r26.s64 = ctx.r6.s64 * 96;
	// stfs f22,24(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f22,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,192(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// mulli r24,r6,76
	ctx.r24.s64 = ctx.r6.s64 * 76;
	// lfs f22,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// add r24,r24,r4
	ctx.r24.u64 = ctx.r24.u64 + ctx.r4.u64;
	// mulli r8,r6,112
	ctx.r8.s64 = ctx.r6.s64 * 112;
	// lfs f16,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// stw r24,488(r1)
	PPC_STORE_U32(ctx.r1.u32 + 488, ctx.r24.u32);
	// lfsx f15,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f15,f16
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f22,148(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// mulli r23,r6,44
	ctx.r23.s64 = ctx.r6.s64 * 44;
	// fsubs f22,f16,f15
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f22,140(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// add r23,r23,r4
	ctx.r23.u64 = ctx.r23.u64 + ctx.r4.u64;
	// mulli r22,r6,12
	ctx.r22.s64 = ctx.r6.s64 * 12;
	// lfs f22,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// stw r23,472(r1)
	PPC_STORE_U32(ctx.r1.u32 + 472, ctx.r23.u32);
	// fsubs f16,f15,f22
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// add r22,r22,r4
	ctx.r22.u64 = ctx.r22.u64 + ctx.r4.u64;
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// stw r22,464(r1)
	PPC_STORE_U32(ctx.r1.u32 + 464, ctx.r22.u32);
	// fsubs f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f15,76(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,212(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f22,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f15,68(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,28(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f22,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// fadds f15,f16,f14
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,228(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,148(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,144(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// stfs f16,96(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fadds f16,f14,f19
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfs f19,152(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f19,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f14,192(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f19,304(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f19,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,76(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fsubs f19,f18,f22
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// stfs f19,320(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// stfs f22,316(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f22,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f18,f15,f22
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfs f19,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f19.f64 = double(temp.f32);
	// fadds f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// lfs f22,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f19,f22
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// fmuls f22,f22,f12
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// stfs f22,148(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// stfs f19,196(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 - ctx.f19.f64));
	// stfs f19,188(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f19,f18,f12
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// stfs f19,276(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fmuls f19,f15,f12
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// stfs f19,228(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f19,f14,f12
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// stfs f19,284(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// mulli r19,r6,40
	ctx.r19.s64 = ctx.r6.s64 * 40;
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// mulli r18,r6,20
	ctx.r18.s64 = ctx.r6.s64 * 20;
	// lfs f22,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f18,f19,f22
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// stfs f18,248(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fadds f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// lfs f19,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f19.f64 = double(temp.f32);
	// stfs f22,256(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fadds f22,f19,f17
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// lfsx f14,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f18,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f14,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f16,f18,f22
	ctx.f16.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// rlwinm r17,r6,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// mulli r16,r6,56
	ctx.r16.s64 = ctx.r6.s64 * 56;
	// stfs f22,80(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f22,f19,f17
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfs f19,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f19.f64 = double(temp.f32);
	// stfs f16,176(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfsx f14,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f14,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// mulli r15,r6,24
	ctx.r15.s64 = ctx.r6.s64 * 24;
	// fsubs f18,f19,f22
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// stfs f18,444(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// fadds f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// stfs f22,460(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// lfsx f14,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,100(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// mulli r14,r6,36
	ctx.r14.s64 = ctx.r6.s64 * 36;
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// rlwinm r25,r6,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r24,r6,52
	ctx.r24.s64 = ctx.r6.s64 * 52;
	// lfsx f22,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f19,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f14,f22,f19
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// mulli r23,r6,116
	ctx.r23.s64 = ctx.r6.s64 * 116;
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// lfsx f18,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r22,r6,72
	ctx.r22.s64 = ctx.r6.s64 * 72;
	// lfsx f17,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f17,f18
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// mulli r21,r6,84
	ctx.r21.s64 = ctx.r6.s64 * 84;
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfsx f16,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r20,r6,104
	ctx.r20.s64 = ctx.r6.s64 * 104;
	// lfsx f15,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// mulli r14,r6,68
	ctx.r14.s64 = ctx.r6.s64 * 68;
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r6,120
	ctx.r14.s64 = ctx.r6.s64 * 120;
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,68(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,100
	ctx.r14.s64 = ctx.r6.s64 * 100;
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,36(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,88
	ctx.r14.s64 = ctx.r6.s64 * 88;
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,60(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,72(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,144(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f19,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f17,76(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f17,f10
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fmsubs f15,f16,f11,f15
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 - ctx.f15.f64));
	// stfs f15,212(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fmadds f17,f16,f10,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f17.f64));
	// stfs f17,100(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f15,136(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,168(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f16,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f19,44(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f19,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// lfs f15,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,96(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,140(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,152(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f16,204(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// stfs f19,200(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// stfs f22,88(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfsx f15,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,36
	ctx.r14.s64 = ctx.r6.s64 * 36;
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmuls f16,f16,f11
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// lfsx f15,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,156(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfsx f15,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,128(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f15,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,88
	ctx.r14.s64 = ctx.r6.s64 * 88;
	// stfs f22,48(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f22,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,160(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfsx f22,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// mulli r14,r6,100
	ctx.r14.s64 = ctx.r6.s64 * 100;
	// stfs f22,164(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f22,f10
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// stfs f15,116(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// lfsx f15,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f15,f11
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// stfs f14,104(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmuls f14,f19,f11
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// mulli r14,r6,120
	ctx.r14.s64 = ctx.r6.s64 * 120;
	// fmsubs f18,f17,f11,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 - ctx.f18.f64));
	// stfs f18,144(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmadds f22,f17,f10,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f22.f64));
	// stfs f22,76(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,60(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// mulli r14,r6,68
	ctx.r14.s64 = ctx.r6.s64 * 68;
	// lfs f22,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,28(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f19,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmr f19,f22
	ctx.f19.f64 = ctx.f22.f64;
	// fsubs f22,f19,f18
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f19,56(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f19,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f19
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f18,364(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f19,328(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f19,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f19,f19,f10,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 - ctx.f16.f64));
	// stfs f19,292(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f19,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f10,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 + ctx.f15.f64));
	// stfs f19,96(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f19,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f10,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 + ctx.f14.f64));
	// stfs f19,152(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f19,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f19,f19,f10,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 - ctx.f16.f64));
	// stfs f19,140(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f19,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f19.f64 = double(temp.f32);
	// fadds f17,f18,f19
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f17,200(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f17,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f18.f64 = double(temp.f32);
	// stfs f19,204(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fsubs f19,f18,f17
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f15,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f16,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,44
	ctx.r14.s64 = ctx.r6.s64 * 44;
	// fadds f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// stw r14,72(r1)
	PPC_STORE_U32(ctx.r1.u32 + 72, ctx.r14.u32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,132(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fadds f14,f17,f19
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f19,112(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfsx f19,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,52(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f19,180(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f19,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f19,120(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f19,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f19,104(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// stw r14,16(r1)
	PPC_STORE_U32(ctx.r1.u32 + 16, ctx.r14.u32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f19
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// stfs f19,68(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f19,92(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f19,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// lfsx f15,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f19,64(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f15,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfsx f15,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f19,24(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// stfs f15,132(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfsx f19,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f17,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f15,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,60(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lwz r14,72(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	// lfsx f15,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f15,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f15,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f15,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,172(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfsx f15,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,116(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfsx f15,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,128(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f15,108(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,32(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f17,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f15,160(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,156(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f17,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f15,88(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,164(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f17,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f15,60(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,44(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f17,48(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fadds f17,f19,f18
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f17,52(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f17,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// stfs f19,172(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// fsubs f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 - ctx.f19.f64));
	// stfs f19,132(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f18,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,108(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f19,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f19,180(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f19,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f19.f64 = double(temp.f32);
	// fadds f16,f19,f14
	ctx.f16.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// lfs f19,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f15,f17,f19
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// stfs f15,112(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fadds f17,f17,f19
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// lfs f19,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,12
	ctx.r14.s64 = ctx.r6.s64 * 12;
	// fsubs f14,f19,f14
	ctx.f14.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f19,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f19,252(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f19,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f19.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f19
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f18,244(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f19,108(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f19,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fsubs f18,f18,f19
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f18,476(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// lfs f18,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// lfs f18,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f18.f64 = double(temp.f32);
	// fmr f15,f18
	ctx.f15.f64 = ctx.f18.f64;
	// stfs f19,404(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// lfs f19,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f19.f64 = double(temp.f32);
	// stw r14,28(r1)
	PPC_STORE_U32(ctx.r1.u32 + 28, ctx.r14.u32);
	// lwz r14,72(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// stfs f19,396(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// fmuls f19,f16,f12
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f16,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f18,f16,f12
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fmuls f16,f14,f12
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,368(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f18,f15
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f18,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f19,104(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f19,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f18,f19,f17
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f18,52(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f19,452(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// lfs f19,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f18,f19,f16
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// lfs f17,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfs f19,420(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// lfs f19,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// lfs f16,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f18,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// lfs f15,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,76
	ctx.r14.s64 = ctx.r6.s64 * 76;
	// lfs f16,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f18.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,92(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stw r14,64(r1)
	PPC_STORE_U32(ctx.r1.u32 + 64, ctx.r14.u32);
	// stfs f15,68(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lwz r14,28(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,240(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f15,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,128(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,116(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,172(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f15,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,132(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,88(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,196(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,164(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f15,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,64(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	// stfs f15,120(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfsx f15,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f15,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,80(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f15,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f15,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f14,136(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,112(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f15,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,92(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f19,120(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f19,48(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fadds f19,f15,f14
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,92(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f18,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f18,f17
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f18,160(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f18,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,80(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// fadds f17,f19,f18
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// lfs f18,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f14,f15,f18
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// fadds f15,f15,f18
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f19,64(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f18,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// lfs f16,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f16.f64 = double(temp.f32);
	// fmr f19,f16
	ctx.f19.f64 = ctx.f16.f64;
	// stfs f18,112(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f18,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f19
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f18,60(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f18,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f19,156(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f18,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f18,f18,f19
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f18,84(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f18,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f19,136(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f19,f17,f12
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmuls f17,f15,f12
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fmuls f18,f14,f12
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f15,f12
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfs f15,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,120(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f15,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,92(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,88(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f18,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f19,80(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f19,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f18,f19,f17
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f18,48(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f19,180(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f19,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f18,f19,f16
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f18,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfs f19,108(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f17,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f19,f18,f17
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f17,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f17.f64 = double(temp.f32);
	// stfs f18,0(r3)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,0(r4)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f17,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f17,f15
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f16,240(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fadds f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fmuls f17,f19,f21
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// fmuls f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f21.f64));
	// fmsubs f21,f19,f20,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f20.f64 - ctx.f21.f64));
	// stfsx f21,r28,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fmadds f21,f18,f20,f17
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f20.f64 + ctx.f17.f64));
	// lfs f18,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f21,r28,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fadds f21,f18,f19
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f17,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f18,f14,f17
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// fsubs f20,f14,f17
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// lfs f17,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f17,252(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f17,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,176(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f14,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,244(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f17,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f22,168(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f17,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f22,f17
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f14,188(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fmuls f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f20,f21
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f20,f20,f21
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// fadds f21,f18,f19
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f21,124(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fmuls f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// fmuls f21,f14,f12
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmuls f19,f19,f12
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f18,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f17,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f17.f64 = double(temp.f32);
	// stfs f19,184(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fmuls f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// lfs f19,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f12
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// stfs f14,124(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f14,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f18,f14,f19,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f19.f64 - ctx.f18.f64));
	// stfsx f18,r26,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// lfs f18,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f19,f18,f19,f16
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 + ctx.f16.f64));
	// stfsx f19,r26,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f19,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f22,f22,f19,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 + ctx.f15.f64));
	// fmsubs f18,f18,f19,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 - ctx.f17.f64));
	// lfs f19,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f19.f64 = double(temp.f32);
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fadds f19,f20,f19
	ctx.f19.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// stfsx f18,r31,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// stfsx f22,r31,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f22,f16,f21
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// lfs f17,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f17.f64 = double(temp.f32);
	// stfs f19,268(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f17,f14
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// lfs f15,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,260(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f17,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f17.f64 = double(temp.f32);
	// fadds f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f16.f64));
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f20,124(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f18,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f18.f64 = double(temp.f32);
	// lfs f20,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f20.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// fsubs f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// lfs f17,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// stfs f20,176(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f16,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f21,f28
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f28.f64));
	// fmuls f21,f21,f29
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f29.f64));
	// fmuls f16,f18,f25
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// fmuls f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f14.f64));
	// lfs f14,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f18,f18,f26
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f26.f64));
	// fmsubs f17,f19,f14,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f14.f64 - ctx.f17.f64));
	// stfsx f17,r9,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f17,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f22,f19,f17,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f22.f64));
	// stfsx f22,r9,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f26,f22,f26,f16
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f26.f64 - ctx.f16.f64));
	// stfsx f26,r5,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fmadds f26,f22,f25,f18
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f25.f64 + ctx.f18.f64));
	// stfsx f26,r5,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f22,f11
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// lfs f25,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f16,f25,f11
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// fmadds f25,f25,f10,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 + ctx.f17.f64));
	// lfs f17,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f22,f22,f10,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f16.f64));
	// lfs f26,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f29,f26,f29,f15
	ctx.f29.f64 = double(float(ctx.f26.f64 * ctx.f29.f64 - ctx.f15.f64));
	// stfsx f29,r7,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fmadds f29,f26,f28,f21
	ctx.f29.f64 = double(float(ctx.f26.f64 * ctx.f28.f64 + ctx.f21.f64));
	// lfs f19,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f29,r7,r4
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f29,f19,f21,f20
	ctx.f29.f64 = double(float(ctx.f19.f64 * ctx.f21.f64 - ctx.f20.f64));
	// stfsx f29,r8,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// lfs f29,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f29.f64 = double(temp.f32);
	// lfs f28,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f29,f28
	ctx.f28.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// lfs f29,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f29.f64 = double(temp.f32);
	// lfs f26,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f29
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// lfs f29,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f18,f29,f11
	ctx.f18.f64 = double(float(ctx.f29.f64 * ctx.f11.f64));
	// lfs f20,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f29,f10
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// fmuls f29,f28,f12
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fmuls f28,f26,f12
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// fmsubs f26,f20,f10,f18
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 - ctx.f18.f64));
	// lfs f18,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f21
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f21.f64));
	// fmadds f21,f20,f11,f15
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f11.f64 + ctx.f15.f64));
	// lfs f20,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f19,f20,f18
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f20.f64 + ctx.f18.f64));
	// lfs f18,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f18.f64 = double(temp.f32);
	// stfsx f20,r8,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fsubs f20,f18,f29
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f29.f64));
	// fadds f29,f29,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f18.f64));
	// fsubs f18,f26,f25
	ctx.f18.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fsubs f19,f17,f28
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fadds f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// fsubs f25,f22,f21
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f21,f20,f18
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// fadds f18,f26,f28
	ctx.f18.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fadds f17,f22,f29
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f29.f64));
	// fsubs f29,f29,f22
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f22.f64));
	// stfs f29,256(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fsubs f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// lfs f29,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f26,f19,f25
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f25.f64));
	// fadds f25,f25,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f19.f64));
	// fmuls f22,f21,f29
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f29.f64));
	// fmuls f19,f18,f27
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f27.f64));
	// fmuls f18,f18,f30
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// fmuls f16,f26,f29
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// lfs f29,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f15,f25,f29
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f29.f64));
	// lfs f29,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f25,f25,f29
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f29.f64));
	// lfs f29,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f14,f28,f29
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f29.f64));
	// lfs f29,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f28,f29
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f29.f64));
	// lfs f29,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f30,f17,f30,f19
	ctx.f30.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 - ctx.f19.f64));
	// fmsubs f21,f21,f29,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f29.f64 - ctx.f16.f64));
	// stfsx f21,r20,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// fmadds f29,f26,f29,f22
	ctx.f29.f64 = double(float(ctx.f26.f64 * ctx.f29.f64 + ctx.f22.f64));
	// stfsx f29,r20,r4
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// stfsx f30,r25,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f17,f27,f18
	ctx.f30.f64 = double(float(ctx.f17.f64 * ctx.f27.f64 + ctx.f18.f64));
	// stfsx f30,r25,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f20,f30,f15
	ctx.f30.f64 = double(float(ctx.f20.f64 * ctx.f30.f64 - ctx.f15.f64));
	// stfsx f30,r19,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f20,f30,f25
	ctx.f30.f64 = double(float(ctx.f20.f64 * ctx.f30.f64 + ctx.f25.f64));
	// stfsx f30,r19,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// lfs f29,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f29.f64 = double(temp.f32);
	// lfs f21,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f26,f21,f10
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// lfs f22,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f17.f64 = double(temp.f32);
	// lfs f30,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f29,f30,f29,f14
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 - ctx.f14.f64));
	// stfsx f29,r22,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// lfs f29,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f30,f30,f29,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 + ctx.f28.f64));
	// stfsx f30,r22,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f30,f29
	ctx.f29.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// lfs f28,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f27,f30,f28
	ctx.f27.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// lfs f30,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f25,f30,f11
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// lfs f28,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f20,f30,f10
	ctx.f20.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// fmuls f19,f28,f10
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f10.f64));
	// fmsubs f28,f28,f11,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f11.f64 - ctx.f26.f64));
	// lfs f26,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f30,f29,f12
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// fmuls f29,f27,f12
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fmadds f27,f22,f10,f25
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 + ctx.f25.f64));
	// lfs f25,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f25.f64 = double(temp.f32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfs f25,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f18,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// lfs f18,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f22,f22,f11,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 - ctx.f20.f64));
	// fmadds f21,f21,f11,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 + ctx.f19.f64));
	// fsubs f20,f18,f30
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f30.f64));
	// fadds f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f18.f64));
	// fsubs f19,f17,f29
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f29.f64));
	// fsubs f18,f28,f27
	ctx.f18.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fadds f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fsubs f25,f22,f21
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fadds f29,f29,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f17.f64));
	// fsubs f21,f20,f18
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// fadds f17,f22,f30
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// mulli r9,r6,120
	ctx.r9.s64 = ctx.r6.s64 * 120;
	// fsubs f22,f30,f22
	ctx.f22.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// stfs f22,248(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fadds f18,f28,f29
	ctx.f18.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// lfs f30,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fsubs f28,f19,f25
	ctx.f28.f64 = double(float(ctx.f19.f64 - ctx.f25.f64));
	// fadds f25,f25,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f19.f64));
	// fmuls f19,f18,f23
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f23.f64));
	// fmuls f18,f18,f24
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f24.f64));
	// fmuls f16,f28,f30
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// lfs f30,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f28,f28,f30
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// lfs f30,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f25,f30
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f30.f64));
	// lfs f30,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f25,f25,f30
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f30.f64));
	// lfs f30,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f29,f30
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f30.f64));
	// fmuls f22,f22,f30
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// lfs f30,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f21,f30,f16
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f30.f64 - ctx.f16.f64));
	// stfsx f30,r9,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f21,f30,f28
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f30.f64 + ctx.f28.f64));
	// stfsx f30,r9,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f30,f17,f24,f19
	ctx.f30.f64 = double(float(ctx.f17.f64 * ctx.f24.f64 - ctx.f19.f64));
	// stfsx f30,r15,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f17,f23,f18
	ctx.f30.f64 = double(float(ctx.f17.f64 * ctx.f23.f64 + ctx.f18.f64));
	// stfsx f30,r15,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f30.f64 = double(temp.f32);
	// mulli r9,r6,88
	ctx.r9.s64 = ctx.r6.s64 * 88;
	// fmsubs f30,f20,f30,f15
	ctx.f30.f64 = double(float(ctx.f20.f64 * ctx.f30.f64 - ctx.f15.f64));
	// stfsx f30,r16,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f20,f30,f25
	ctx.f30.f64 = double(float(ctx.f20.f64 * ctx.f30.f64 + ctx.f25.f64));
	// stfsx f30,r16,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f30.f64 = double(temp.f32);
	// lfs f24,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f24.f64 = double(temp.f32);
	// lfs f21,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f18.f64 = double(temp.f32);
	// lfs f28,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f28,f30,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f30.f64 - ctx.f14.f64));
	// stfsx f28,r9,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f29,f30,f22
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f30.f64 + ctx.f22.f64));
	// lfs f22,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f30,r9,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmuls f28,f22,f2
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// lfs f30,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f20,f30,f2
	ctx.f20.f64 = double(float(ctx.f30.f64 * ctx.f2.f64));
	// lfs f29,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f25,f29,f2
	ctx.f25.f64 = double(float(ctx.f29.f64 * ctx.f2.f64));
	// fmuls f19,f29,f3
	ctx.f19.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// lfs f29,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f30,f30,f3,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f3.f64 + ctx.f28.f64));
	// lfs f28,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f28.f64 = double(temp.f32);
	// fadds f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// lfs f28,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f22,f22,f3,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 - ctx.f20.f64));
	// lfs f20,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f2
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f2.f64));
	// fadds f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f24.f64));
	// lfs f24,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f25,f21,f3,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 - ctx.f25.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfs f23,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f21,f21,f2,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f2.f64 + ctx.f19.f64));
	// lfs f19,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f19.f64 = double(temp.f32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// fmadds f20,f19,f3,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f3.f64 + ctx.f20.f64));
	// fadds f19,f28,f29
	ctx.f19.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fadds f18,f25,f30
	ctx.f18.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// fsubs f30,f25,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 - ctx.f30.f64));
	// fsubs f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fsubs f28,f24,f23
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f25,f23,f24
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fadds f24,f21,f22
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f23,f22,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fsubs f22,f19,f18
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f21,f30,f26
	ctx.f21.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// mulli r9,r6,68
	ctx.r9.s64 = ctx.r6.s64 * 68;
	// fsubs f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f30.f64));
	// fsubs f26,f27,f24
	ctx.f26.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// fadds f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// lfs f24,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f24.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// fadds f18,f29,f23
	ctx.f18.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// fmuls f17,f22,f24
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f24.f64));
	// lfs f24,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// lfs f23,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f22,f23
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// fmuls f16,f19,f6
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f6.f64));
	// fmuls f15,f18,f8
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// fmsubs f23,f26,f23,f17
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f23.f64 - ctx.f17.f64));
	// stfsx f23,r9,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmuls f18,f18,f9
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// lfs f23,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f26,f26,f23,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f23.f64 + ctx.f22.f64));
	// stfsx f26,r9,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r9,r6,36
	ctx.r9.s64 = ctx.r6.s64 * 36;
	// fmuls f19,f19,f7
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f7.f64));
	// fmuls f14,f29,f24
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f24.f64));
	// lfs f24,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f24.f64));
	// lfs f26,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f26.f64 = double(temp.f32);
	// lfs f23,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f9,f21,f9,f15
	ctx.f9.f64 = double(float(ctx.f21.f64 * ctx.f9.f64 - ctx.f15.f64));
	// stfsx f9,r9,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmadds f9,f21,f8,f18
	ctx.f9.f64 = double(float(ctx.f21.f64 * ctx.f8.f64 + ctx.f18.f64));
	// stfsx f9,r9,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r9,r6,100
	ctx.r9.s64 = ctx.r6.s64 * 100;
	// fmsubs f9,f27,f7,f16
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 - ctx.f16.f64));
	// stfsx f9,r17,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// fmadds f9,f27,f6,f19
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f6.f64 + ctx.f19.f64));
	// stfsx f9,r17,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f9,f30,f24,f14
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f24.f64 - ctx.f14.f64));
	// lfs f7,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f27,f7,f3
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// stfsx f9,r9,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f9,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f9,f30,f9,f29
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 + ctx.f29.f64));
	// lfs f30,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f6,f30,f3
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f3.f64));
	// stfsx f9,r9,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f9,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f29,f9,f3
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// lfs f9,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// lfs f8,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f26,f8
	ctx.f8.f64 = double(float(ctx.f26.f64 - ctx.f8.f64));
	// fmsubs f30,f30,f2,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f2.f64 - ctx.f27.f64));
	// lfs f27,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f7,f7,f2,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f2.f64 + ctx.f6.f64));
	// lfs f6,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f26,f6,f31
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// lfs f6,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f6,f6,f2,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 - ctx.f29.f64));
	// lfs f29,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f24,f29,f31
	ctx.f24.f64 = double(float(ctx.f29.f64 * ctx.f31.f64));
	// lfs f29,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// lfs f27,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// lfs f23,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f26,f23,f1,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f26.f64));
	// lfs f23,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f23.f64 = double(temp.f32);
	// fadds f22,f30,f6
	ctx.f22.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// fmsubs f24,f23,f1,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 - ctx.f24.f64));
	// fadds f23,f8,f9
	ctx.f23.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fsubs f8,f20,f7
	ctx.f8.f64 = double(float(ctx.f20.f64 - ctx.f7.f64));
	// fsubs f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// fadds f30,f27,f29
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// fsubs f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// fadds f7,f7,f20
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f20.f64));
	// fadds f27,f24,f26
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// fsubs f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// fsubs f24,f23,f8
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f8.f64));
	// fadds f8,f23,f8
	ctx.f8.f64 = double(float(ctx.f23.f64 + ctx.f8.f64));
	// lfs f20,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f23,f9,f6
	ctx.f23.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// fadds f9,f9,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f6.f64));
	// lfs f6,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f6.f64 = double(temp.f32);
	// fadds f21,f7,f25
	ctx.f21.f64 = double(float(ctx.f7.f64 + ctx.f25.f64));
	// fsubs f7,f25,f7
	ctx.f7.f64 = double(float(ctx.f25.f64 - ctx.f7.f64));
	// fsubs f25,f28,f22
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// lfs f22,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f19,f24,f20
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f20.f64));
	// fmuls f18,f24,f22
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// lfs f24,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f17,f8,f6
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// lfs f6,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f8,f6
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// lfs f8,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f15,f23,f8
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// lfs f6,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f23,f24
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f24.f64));
	// lfs f8,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f14,f9,f6
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// fmsubs f22,f25,f22,f19
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f22.f64 - ctx.f19.f64));
	// stfsx f22,r27,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fmadds f25,f25,f20,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f20.f64 + ctx.f18.f64));
	// stfsx f25,r27,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f25,f21,f24,f15
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f24.f64 - ctx.f15.f64));
	// stfsx f25,r29,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f25,f21,f25,f23
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f25.f64 + ctx.f23.f64));
	// stfsx f25,r29,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// lfs f25,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f8,f7,f8,f14
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 - ctx.f14.f64));
	// fmsubs f25,f28,f25,f17
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f25.f64 - ctx.f17.f64));
	// stfsx f25,r30,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f9,f7,f6,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f6.f64 + ctx.f9.f64));
	// fmadds f28,f28,f25,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f25.f64 + ctx.f16.f64));
	// stfsx f28,r30,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// stfsx f8,r10,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f6,f29,f26
	ctx.f6.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmuls f23,f22,f31
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f31.f64));
	// lfs f9,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f22,f22,f1
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fmuls f28,f9,f31
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// lfs f9,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f25,f9,f1
	ctx.f25.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// lfs f8,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// lfs f7,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// lfs f21,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f21.f64 = double(temp.f32);
	// fadds f7,f26,f29
	ctx.f7.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// lfs f29,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f29.f64 = double(temp.f32);
	// lfs f26,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f29,f29,f1,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f1.f64 - ctx.f28.f64));
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f24,f28,f1
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f1.f64));
	// lfs f28,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f31,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f31.f64 + ctx.f25.f64));
	// lfs f25,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfs f25,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f21.f64));
	// lfs f21,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f24,f21,f31,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f31.f64 - ctx.f24.f64));
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f23,f21,f1,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 + ctx.f23.f64));
	// fmsubs f22,f21,f31,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f31.f64 - ctx.f22.f64));
	// fadds f21,f8,f9
	ctx.f21.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fadds f8,f28,f29
	ctx.f8.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fsubs f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fsubs f28,f26,f25
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f25,f24,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfs f19,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f23,f21,f27
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f27.f64));
	// lwz r10,280(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// fadds f27,f21,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// lwz r9,440(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	// fadds f20,f9,f29
	ctx.f20.f64 = double(float(ctx.f9.f64 + ctx.f29.f64));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fsubs f9,f9,f29
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f29.f64));
	// lfs f29,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f21,f30,f8
	ctx.f21.f64 = double(float(ctx.f30.f64 - ctx.f8.f64));
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// fadds f8,f8,f30
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f30.f64));
	// lfs f30,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f30.f64 = double(temp.f32);
	// stw r10,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, ctx.r10.u32);
	// fmuls f18,f23,f19
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f19.f64));
	// fmuls f17,f27,f29
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f29.f64));
	// lfs f29,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// fmuls f16,f27,f29
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f29.f64));
	// lfs f29,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f15,f20,f29
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f29.f64));
	// lfs f29,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f20,f20,f29
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f29.f64));
	// lfs f27,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f27.f64 = double(temp.f32);
	// lfs f29,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f14,f9,f27
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// fmuls f9,f9,f29
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// fmsubs f30,f21,f30,f18
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f30.f64 - ctx.f18.f64));
	// stfsx f30,r21,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f21,f19,f23
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f19.f64 + ctx.f23.f64));
	// stfsx f30,r21,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f7,f30,f15
	ctx.f30.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 - ctx.f15.f64));
	// stfsx f30,r24,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f7,f7,f30,f20
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 + ctx.f20.f64));
	// stfsx f7,r24,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f9,f6,f27,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f27.f64 + ctx.f9.f64));
	// fmsubs f7,f8,f7,f17
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 - ctx.f17.f64));
	// stfsx f7,r18,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// lfs f7,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f8,f8,f7,f16
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 + ctx.f16.f64));
	// stfsx f8,r18,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f8,f6,f29,f14
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f29.f64 - ctx.f14.f64));
	// stfsx f8,r23,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// stfsx f9,r23,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f26,f24
	ctx.f6.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// lfs f9,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fmuls f30,f9,f31
	ctx.f30.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// lfs f8,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f9.f64 = double(temp.f32);
	// subf r4,r9,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r9.s64;
	// fadds f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// lfs f7,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f8.f64 = double(temp.f32);
	// lfs f29,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// fadds f7,f24,f26
	ctx.f7.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfs f24,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f24,f6
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmadds f30,f29,f1,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f1.f64 + ctx.f30.f64));
	// fsubs f29,f9,f8
	ctx.f29.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fadds f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fsubs f8,f22,f30
	ctx.f8.f64 = double(float(ctx.f22.f64 - ctx.f30.f64));
	// fadds f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// fsubs f27,f29,f25
	ctx.f27.f64 = double(float(ctx.f29.f64 - ctx.f25.f64));
	// fadds f29,f29,f25
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f25.f64));
	// fsubs f26,f28,f8
	ctx.f26.f64 = double(float(ctx.f28.f64 - ctx.f8.f64));
	// fadds f25,f9,f30
	ctx.f25.f64 = double(float(ctx.f9.f64 + ctx.f30.f64));
	// fadds f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f28.f64));
	// lfs f28,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f30.f64));
	// lfs f30,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f22,f27,f13
	ctx.f22.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// fmuls f21,f28,f29
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f29.f64));
	// fmuls f27,f27,f0
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f29,f30,f29
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f29.f64));
	// fmuls f20,f25,f4
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// lwz r10,16(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// fmsubs f0,f26,f0,f22
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 - ctx.f22.f64));
	// fmuls f25,f25,f5
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f5.f64));
	// fmuls f24,f24,f9
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,456(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	// fmadds f0,f26,f13,f27
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 + ctx.f27.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,28(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// fmsubs f0,f7,f5,f20
	ctx.f0.f64 = double(float(ctx.f7.f64 * ctx.f5.f64 - ctx.f20.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,464(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	// fmadds f0,f7,f4,f25
	ctx.f0.f64 = double(float(ctx.f7.f64 * ctx.f4.f64 + ctx.f25.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,72(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	// fmsubs f0,f30,f8,f21
	ctx.f0.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 - ctx.f21.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,472(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	// fmadds f0,f28,f8,f29
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f8.f64 + ctx.f29.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,488(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	// lfs f0,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f13,f0,f6,f24
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f6.f64 - ctx.f24.f64));
	// stfs f13,0(r14)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fmadds f0,f0,f9,f23
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f9.f64 + ctx.f23.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d30e48
	if (!ctx.cr0.eq) goto loc_82D30E48;
loc_82D326CC:
	// addi r1,r1,800
	ctx.r1.s64 = ctx.r1.s64 + 800;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D326D8;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D326E0"))) PPC_WEAK_FUNC(sub_82D326E0);
PPC_FUNC_IMPL(__imp__sub_82D326E0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-5752
	ctx.r5.s64 = ctx.r11.s64 + -5752;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,3544
	ctx.r4.s64 = ctx.r11.s64 + 3544;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D326F8"))) PPC_WEAK_FUNC(sub_82D326F8);
PPC_FUNC_IMPL(__imp__sub_82D326F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e34
	ctx.lr = 0x82D32700;
	__savegprlr_15(ctx, base);
	// addi r12,r1,-144
	ctx.r12.s64 = ctx.r1.s64 + -144;
	// bl 0x82e28ee0
	ctx.lr = 0x82D32708;
	__savefpr_14(ctx, base);
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// addi r11,r11,-32
	ctx.r11.s64 = ctx.r11.s64 + -32;
	// bge cr6,0x82d330cc
	if (!ctx.cr6.lt) goto loc_82D330CC;
	// rlwinm r16,r9,2,0,29
	ctx.r16.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r25,r7,r8
	ctx.r25.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lis r15,-32234
	ctx.r15.s64 = -2112487424;
	// lfs f8,136(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 136);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
loc_82D32740:
	// lfs f12,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mulli r24,r6,48
	ctx.r24.s64 = ctx.r6.s64 * 48;
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// mulli r10,r6,28
	ctx.r10.s64 = ctx.r6.s64 * 28;
	// lfs f5,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f5.f64 = double(temp.f32);
	// lfs f7,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f5,f12
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f6,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f2,f5,f11
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fmuls f29,f6,f11
	ctx.f29.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f0,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f28,f6,f12
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f31,f7,f12
	ctx.f31.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// lfs f4,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f1,f7,f11
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// lfs f30,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f21,f13,f11
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// fmuls f20,f13,f7
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fmuls f25,f0,f12
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// fmuls f24,f0,f6
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// fmadds f19,f4,f11,f3
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 + ctx.f3.f64));
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f18,f4,f12,f2
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 - ctx.f2.f64));
	// fmuls f22,f13,f6
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// rlwinm r23,r6,4,0,27
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f26,f0,f7
	ctx.f26.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// mulli r9,r6,44
	ctx.r9.s64 = ctx.r6.s64 * 44;
	// fadds f3,f29,f31
	ctx.f3.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// fsubs f2,f28,f1
	ctx.f2.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// fmuls f23,f13,f12
	ctx.f23.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// fmuls f27,f0,f11
	ctx.f27.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// fsubs f15,f25,f21
	ctx.f15.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// fadds f14,f20,f24
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// fadds f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// stfs f25,-344(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fsubs f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// add r22,r24,r3
	ctx.r22.u64 = ctx.r24.u64 + ctx.r3.u64;
	// mulli r8,r6,12
	ctx.r8.s64 = ctx.r6.s64 * 12;
	// fadds f1,f28,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// fadds f16,f22,f26
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// fmuls f21,f0,f3
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// fmuls f20,f13,f2
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fsubs f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// stfs f26,-360(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fsubs f31,f31,f29
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f29.f64));
	// lfs f25,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f28,f23,f27
	ctx.f28.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// lfsx f29,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// stfs f27,-296(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// add r21,r23,r3
	ctx.r21.u64 = ctx.r23.u64 + ctx.r3.u64;
	// fadds f22,f17,f30
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// fsubs f30,f30,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f17.f64));
	// lfsx f26,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f17,f29,f25
	ctx.f17.f64 = double(float(ctx.f29.f64 - ctx.f25.f64));
	// mulli r7,r6,60
	ctx.r7.s64 = ctx.r6.s64 * 60;
	// fadds f29,f25,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// lfs f27,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fadds f25,f26,f27
	ctx.f25.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// lfsx f23,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// fadds f26,f20,f21
	ctx.f26.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f26,-320(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fsubs f26,f21,f20
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f26,-312(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fmuls f21,f0,f31
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fmuls f26,f13,f1
	ctx.f26.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// fadds f20,f26,f21
	ctx.f20.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// stfs f20,-316(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fsubs f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// stfs f26,-368(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fmuls f21,f0,f1
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// fmuls f26,f13,f31
	ctx.f26.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fsubs f20,f26,f21
	ctx.f20.f64 = double(float(ctx.f26.f64 - ctx.f21.f64));
	// stfs f20,-300(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fadds f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// stfs f26,-292(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fmuls f26,f13,f3
	ctx.f26.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fmuls f21,f0,f2
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// fsubs f20,f26,f21
	ctx.f20.f64 = double(float(ctx.f26.f64 - ctx.f21.f64));
	// mulli r29,r6,40
	ctx.r29.s64 = ctx.r6.s64 * 40;
	// stfs f20,-304(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// mulli r28,r6,24
	ctx.r28.s64 = ctx.r6.s64 * 24;
	// fadds f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// stfs f26,-392(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fadds f26,f25,f22
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// stfs f26,-348(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fadds f26,f29,f30
	ctx.f26.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// stfs f26,-428(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfsx f20,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f26,f22,f25
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// stfs f20,-456(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfsx f20,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-444(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// stfs f30,-372(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// stfs f26,-364(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfsx f20,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-476(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfsx f20,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r27,r6,56
	ctx.r27.s64 = ctx.r6.s64 * 56;
	// stfs f20,-472(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfsx f20,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-452(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// rlwinm r26,r6,5,0,26
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// lfsx f20,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-468(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// rlwinm r5,r6,3,0,28
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r31,r6,20
	ctx.r31.s64 = ctx.r6.s64 * 20;
	// lfsx f20,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-464(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfsx f29,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f30,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// mulli r30,r6,52
	ctx.r30.s64 = ctx.r6.s64 * 52;
	// lfsx f25,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f26,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f20,f30,f29
	ctx.f20.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fadds f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fadds f29,f25,f26
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfsx f22,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f21,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// rlwinm r20,r6,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r19,r6,36
	ctx.r19.s64 = ctx.r6.s64 * 36;
	// add r18,r20,r4
	ctx.r18.u64 = ctx.r20.u64 + ctx.r4.u64;
	// add r20,r20,r3
	ctx.r20.u64 = ctx.r20.u64 + ctx.r3.u64;
	// add r17,r19,r4
	ctx.r17.u64 = ctx.r19.u64 + ctx.r4.u64;
	// lfs f25,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// stfs f25,-480(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f25,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// lfs f22,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,-456(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f22,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f22,-440(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f22,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f22,f21
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f21,-460(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f21,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f22,-476(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f22,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f21,-436(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f21,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,-432(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f22,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f21,-472(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f21,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f23,f21
	ctx.f21.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfs f21,-400(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// add r19,r19,r3
	ctx.r19.u64 = ctx.r19.u64 + ctx.r3.u64;
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// lfs f21,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f21,-404(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f21,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f21.f64 = double(temp.f32);
	// add r24,r24,r4
	ctx.r24.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// lfs f20,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f30
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f30.f64));
	// stfs f20,-340(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f20,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f20.f64 = double(temp.f32);
	// add r23,r23,r4
	ctx.r23.u64 = ctx.r23.u64 + ctx.r4.u64;
	// fsubs f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// stfs f30,-324(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f30,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f30.f64 = double(temp.f32);
	// lfs f20,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f30
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f30.f64));
	// stfs f20,-460(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f20,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// fsubs f20,f22,f25
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// stfs f20,-356(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fadds f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// stfs f25,-352(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f25,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f22,f25,f17
	ctx.f22.f64 = double(float(ctx.f25.f64 - ctx.f17.f64));
	// stfs f22,-332(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f22,f23,f27
	ctx.f22.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// lfsx f20,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// stfs f27,-380(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fadds f27,f25,f17
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f17.f64));
	// stfs f27,-328(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// stfs f22,-444(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfsx f22,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f27,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f27.f64 = double(temp.f32);
	// lfs f25,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f23,f27,f25
	ctx.f23.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// stfs f20,-460(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fadds f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// lfsx f20,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f25,f30,f21
	ctx.f25.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// stfs f20,-480(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fsubs f30,f21,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 - ctx.f30.f64));
	// lfs f20,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f23,f23,f10
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// stfs f23,-376(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fmuls f27,f27,f10
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// stfs f27,-476(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fmuls f27,f25,f10
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// stfs f27,-336(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f23,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f30,f30,f10
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// lfs f27,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f25,f23,f27
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// stfs f25,-412(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fadds f27,f27,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f23.f64));
	// stfs f27,-408(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f27,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f23,f27,f29
	ctx.f23.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// stfs f30,-448(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// fadds f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f27.f64));
	// stfs f29,-400(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f27,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f27.f64 = double(temp.f32);
	// lfs f29,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfs f29,-420(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f29,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// lfs f30,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fadds f20,f29,f20
	ctx.f20.f64 = double(float(ctx.f29.f64 + ctx.f20.f64));
	// lfsx f27,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f25,f25,f8
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// stfs f23,-472(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// stfs f25,-436(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// stfs f20,-464(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fsubs f20,f30,f27
	ctx.f20.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// lfs f25,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f23,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// stfs f20,-452(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fadds f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// lfs f20,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f27,f22,f21
	ctx.f27.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fsubs f29,f20,f29
	ctx.f29.f64 = double(float(ctx.f20.f64 - ctx.f29.f64));
	// lfs f17,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f23,f25
	ctx.f20.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// stfs f25,-432(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fadds f23,f21,f22
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f26
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// stfs f21,-468(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// lfs f21,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f21.f64 = double(temp.f32);
	// lfs f25,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f25.f64 = double(temp.f32);
	// lfs f22,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f22.f64 = double(temp.f32);
	// fadds f25,f25,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f17.f64));
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// fsubs f21,f29,f21
	ctx.f21.f64 = double(float(ctx.f29.f64 - ctx.f21.f64));
	// stfs f21,-440(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f21,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,-480(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f21,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f21,-424(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f21,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f21.f64 = double(temp.f32);
	// fadds f29,f29,f21
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f21.f64));
	// stfs f29,-404(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// fsubs f21,f27,f25
	ctx.f21.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// stfs f21,-416(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// fadds f29,f25,f27
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f27,f30,f23
	ctx.f27.f64 = double(float(ctx.f30.f64 - ctx.f23.f64));
	// stfs f27,-388(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f27,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f27.f64 = double(temp.f32);
	// fadds f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// fsubs f25,f22,f27
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f27.f64));
	// stfs f25,-464(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// stfs f30,-460(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fadds f30,f22,f27
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// stfs f30,-432(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fmuls f25,f26,f9
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// lfs f30,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f26,f26,f8
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// fmuls f27,f30,f8
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// fmuls f22,f21,f8
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f8.f64));
	// fmuls f21,f29,f9
	ctx.f21.f64 = double(float(ctx.f29.f64 * ctx.f9.f64));
	// fmuls f20,f29,f8
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// lfs f29,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f29.f64 = double(temp.f32);
	// lfs f30,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f23,f30,f8
	ctx.f23.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// lfs f30,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f29,f29,f30
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f30.f64));
	// stfs f29,-456(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f29,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f29.f64 = double(temp.f32);
	// fadds f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f29.f64));
	// stfs f30,-452(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f29,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f29.f64 = double(temp.f32);
	// lfs f30,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f9,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 + ctx.f29.f64));
	// stfs f30,-440(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f30,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f30,f9,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 - ctx.f27.f64));
	// lfs f29,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f29.f64 = double(temp.f32);
	// stfs f30,-412(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fmsubs f30,f29,f8,f25
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 - ctx.f25.f64));
	// fmadds f29,f29,f9,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 + ctx.f26.f64));
	// lfs f26,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f26.f64 = double(temp.f32);
	// lfs f27,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f27.f64 = double(temp.f32);
	// fadds f25,f26,f27
	ctx.f25.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// stfs f25,-472(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fsubs f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// stfs f27,-464(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f27,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f27,f27,f9,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 - ctx.f23.f64));
	// stfs f27,-436(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f27,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f9,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 + ctx.f22.f64));
	// stfs f27,-408(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f26,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f26.f64 = double(temp.f32);
	// lfs f23,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f27,f26,f8,f21
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f8.f64 - ctx.f21.f64));
	// lfs f25,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f26,f26,f9,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f9.f64 + ctx.f20.f64));
	// fadds f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f23.f64));
	// lfs f22,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// lfs f21,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f20,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// lfs f17,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f27,f30
	ctx.f20.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f20,-424(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f20,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,-468(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fsubs f20,f29,f26
	ctx.f20.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// stfs f20,-416(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f17,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f17.f64 = double(temp.f32);
	// fadds f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// lfs f20,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// lfs f17,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f17.f64 = double(temp.f32);
	// stfs f30,-448(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f30,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// stfs f30,-428(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f26,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f26.f64 = double(temp.f32);
	// lfs f30,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// lfs f27,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// lfs f17,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f17.f64 = double(temp.f32);
	// lfs f30,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f17.f64));
	// lfs f17,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f17.f64 = double(temp.f32);
	// fadds f25,f25,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f17.f64));
	// stfs f25,0(r3)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f17,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f17.f64 = double(temp.f32);
	// lfs f25,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f17.f64));
	// stfs f25,-396(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f25,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f25.f64 = double(temp.f32);
	// lfs f17,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f25,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 + ctx.f17.f64));
	// fsubs f25,f23,f22
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f25,-388(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f23,0(r4)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmuls f27,f27,f10
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f22,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f23,f21,f22
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f23,-424(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfs f22,-480(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f22,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f21,-420(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f21,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfs f22,-416(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// fsubs f21,f20,f29
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f29.f64));
	// stfs f21,-444(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fadds f29,f29,f20
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f20.f64));
	// lfs f20,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f26
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f26.f64));
	// stfs f20,-468(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f20,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f20.f64));
	// stfs f26,-448(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f26,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f20,f30,f27
	ctx.f20.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfs f29,-384(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fmuls f26,f26,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f15.f64));
	// fadds f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f30,-476(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f30,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f27,f25,f15
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f15.f64));
	// fmuls f25,f23,f30
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// lfs f23,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// stfs f20,-308(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fmuls f23,f22,f6
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// lfs f22,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f6
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// lfs f6,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f6.f64 = double(temp.f32);
	// lfs f20,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// fmuls f20,f20,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// lfs f6,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f15,f6,f4
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// lfs f6,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f4,f29,f4
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f4.f64));
	// lfs f29,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f29,f29,f6,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f6.f64 - ctx.f27.f64));
	// stfsx f29,r26,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// lfs f29,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f6,f29,f6,f26
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f6.f64 + ctx.f26.f64));
	// stfsx f6,r26,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f29,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f29.f64 = double(temp.f32);
	// lfs f6,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f30,f29,f6,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f6.f64 - ctx.f30.f64));
	// stfsx f30,r9,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f6,f30,f6,f25
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f6.f64 + ctx.f25.f64));
	// stfsx f6,r9,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f6,f6,f7,f23
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f7.f64 - ctx.f23.f64));
	// stfsx f6,r8,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// lfs f6,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f7,f6,f7,f22
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f7.f64 + ctx.f22.f64));
	// stfsx f7,r8,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f6,f6,f7,f20
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f7.f64 - ctx.f20.f64));
	// stfsx f6,r10,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f6,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f7,f6,f7,f21
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f7.f64 + ctx.f21.f64));
	// stfsx f7,r10,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f7,f7,f5,f15
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f5.f64 - ctx.f15.f64));
	// stfsx f7,r7,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// lfs f7,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f7,f7,f5,f4
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f5.f64 + ctx.f4.f64));
	// stfsx f7,r7,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f26,f7,f6
	ctx.f26.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// lfs f7,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f25,f7,f6
	ctx.f25.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// lfs f5,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f7,f17,f10
	ctx.f7.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// lfs f4,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfs f30,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f30.f64 = double(temp.f32);
	// lfs f4,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 - ctx.f4.f64));
	// lfs f29,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f29.f64 = double(temp.f32);
	// lfs f30,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f30.f64));
	// lfs f27,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f27.f64 = double(temp.f32);
	// lfs f29,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f26,f26,f10
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// fsubs f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// lfs f23,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f23.f64 = double(temp.f32);
	// lfs f27,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f25,f25,f10
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// fsubs f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// lfs f22,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f20,f23,f2
	ctx.f20.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// fsubs f23,f22,f7
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f7.f64));
	// addic. r25,r25,-1
	ctx.xer.ca = ctx.r25.u32 > 0;
	ctx.r25.s64 = ctx.r25.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// fadds f7,f7,f22
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f22.f64));
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// fsubs f22,f4,f30
	ctx.f22.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// fadds f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// fsubs f30,f29,f27
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// fsubs f27,f6,f26
	ctx.f27.f64 = double(float(ctx.f6.f64 - ctx.f26.f64));
	// stfs f27,-396(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fsubs f21,f5,f25
	ctx.f21.f64 = double(float(ctx.f5.f64 - ctx.f25.f64));
	// stfs f21,-384(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fadds f6,f26,f6
	ctx.f6.f64 = double(float(ctx.f26.f64 + ctx.f6.f64));
	// stfs f6,-392(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fadds f6,f25,f5
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// lfs f5,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f26,f23,f5
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// lfs f5,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f25,f23,f28
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// fmuls f2,f7,f2
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f2.f64));
	// fmadds f7,f7,f3,f20
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f3.f64 + ctx.f20.f64));
	// fmuls f23,f22,f5
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// fmuls f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f5.f64));
	// fmuls f27,f27,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// fmuls f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f18.f64));
	// lfs f18,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f6,f14
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// fmuls f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// lfs f6,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f15,f29,f6
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f6.f64));
	// lfs f6,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f28,f6,f28,f26
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f28.f64 - ctx.f26.f64));
	// lfs f26,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f26.f64 = double(temp.f32);
	// stfsx f28,r29,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fmadds f6,f6,f26,f25
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f26.f64 + ctx.f25.f64));
	// stfsx f6,r29,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f6,f6,f3,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 - ctx.f2.f64));
	// stfsx f6,r5,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// stfsx f7,r5,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f4,f28
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// lfs f3,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f2.f64 = double(temp.f32);
	// lfs f7,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f7,f7,f19,f21
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f19.f64 - ctx.f21.f64));
	// stfsx f7,r27,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// lfs f7,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f7,f7,f19,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f19.f64 + ctx.f27.f64));
	// stfsx f7,r27,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f6,f7,f14,f18
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f14.f64 - ctx.f18.f64));
	// stfsx f6,r28,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f6,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f7,f7,f6,f17
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64 + ctx.f17.f64));
	// stfsx f7,r28,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f6,f22,f7,f5
	ctx.f6.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 - ctx.f5.f64));
	// stfsx f6,r30,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmadds f7,f30,f7,f23
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f7.f64 + ctx.f23.f64));
	// stfsx f7,r30,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f6,f4,f7,f15
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f7.f64 - ctx.f15.f64));
	// stfsx f6,r31,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmadds f7,f29,f7,f28
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f7.f64 + ctx.f28.f64));
	// stfsx f7,r31,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f6.f64 = double(temp.f32);
	// add r3,r16,r3
	ctx.r3.u64 = ctx.r16.u64 + ctx.r3.u64;
	// lfs f7,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f7.f64 = double(temp.f32);
	// subf r4,r16,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r16.s64;
	// fadds f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f6.f64));
	// lfs f5,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f6.f64 = double(temp.f32);
	// fadds f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f5.f64));
	// lfs f4,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// lfs f4,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// lfs f3,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// lfs f30,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f30.f64 = double(temp.f32);
	// lfs f2,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f30.f64));
	// lfs f29,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f29.f64 = double(temp.f32);
	// lfs f30,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// lfs f28,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f28.f64 = double(temp.f32);
	// lfs f29,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fsubs f28,f7,f6
	ctx.f28.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// fadds f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// fsubs f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f4,f3,f2
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// fadds f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fsubs f2,f30,f29
	ctx.f2.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fadds f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fmuls f29,f28,f0
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f0,f6,f0
	ctx.f0.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f27,f5,f11
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fmuls f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// fmuls f25,f4,f16
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f16.f64));
	// fmuls f26,f2,f16
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// fmuls f23,f30,f1
	ctx.f23.f64 = double(float(ctx.f30.f64 * ctx.f1.f64));
	// fmuls f1,f3,f1
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// fmsubs f0,f28,f13,f0
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 - ctx.f0.f64));
	// stfs f0,0(r19)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// fmadds f0,f6,f13,f29
	ctx.f0.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f29.f64));
	// stfs f0,0(r17)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r17.u32 + 0, temp.u32);
	// fmsubs f0,f7,f12,f27
	ctx.f0.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 - ctx.f27.f64));
	// stfs f0,0(r20)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// fmadds f0,f5,f12,f11
	ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 + ctx.f11.f64));
	// stfs f0,0(r18)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// fmsubs f0,f4,f24,f26
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f24.f64 - ctx.f26.f64));
	// stfs f0,0(r22)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// fmadds f0,f2,f24,f25
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f24.f64 + ctx.f25.f64));
	// stfs f0,0(r24)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fmsubs f0,f3,f31,f23
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f31.f64 - ctx.f23.f64));
	// stfs f0,0(r21)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// fmadds f0,f30,f31,f1
	ctx.f0.f64 = double(float(ctx.f30.f64 * ctx.f31.f64 + ctx.f1.f64));
	// stfs f0,0(r23)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// lwz r10,3532(r15)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r15.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d32740
	if (!ctx.cr0.eq) goto loc_82D32740;
loc_82D330CC:
	// addi r12,r1,-144
	ctx.r12.s64 = ctx.r1.s64 + -144;
	// bl 0x82e28f2c
	ctx.lr = 0x82D330D4;
	__restfpr_14(ctx, base);
	// b 0x82e28e84
	__restgprlr_15(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D330D8"))) PPC_WEAK_FUNC(sub_82D330D8);
PPC_FUNC_IMPL(__imp__sub_82D330D8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-5680
	ctx.r5.s64 = ctx.r11.s64 + -5680;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,9976
	ctx.r4.s64 = ctx.r11.s64 + 9976;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D330F0"))) PPC_WEAK_FUNC(sub_82D330F0);
PPC_FUNC_IMPL(__imp__sub_82D330F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D330F8;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28ee0
	ctx.lr = 0x82D33100;
	__savefpr_14(ctx, base);
	// mulli r11,r7,24
	ctx.r11.s64 = ctx.r7.s64 * 24;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-24
	ctx.r11.s64 = ctx.r11.s64 + -24;
	// bge cr6,0x82d333dc
	if (!ctx.cr6.lt) goto loc_82D333DC;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// rlwinm r25,r9,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r31,r7,r8
	ctx.r31.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f6,140(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f6.f64 = double(temp.f32);
loc_82D33128:
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r30,r6,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f8,f12,f0
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f7,f12,f13
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f9,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f3,f10,f0
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f1,f9,f13
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f31,f9,f0
	ctx.f31.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// add r28,r30,r4
	ctx.r28.u64 = ctx.r30.u64 + ctx.r4.u64;
	// fmuls f2,f10,f13
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// add r30,r30,r3
	ctx.r30.u64 = ctx.r30.u64 + ctx.r3.u64;
	// mulli r5,r6,28
	ctx.r5.s64 = ctx.r6.s64 * 28;
	// lfsx f28,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f24,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfs f5,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// lfs f27,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f30,f11,f13,f8
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f8.f64));
	// lfs f25,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f29,f11,f0,f7
	ctx.f29.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f7.f64));
	// lfsx f23,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f19,f27,f28
	ctx.f19.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// lfs f4,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fadds f8,f1,f3
	ctx.f8.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// mulli r8,r6,12
	ctx.r8.s64 = ctx.r6.s64 * 12;
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fsubs f7,f31,f2
	ctx.f7.f64 = double(float(ctx.f31.f64 - ctx.f2.f64));
	// fsubs f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// fadds f27,f24,f25
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fsubs f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// lfsx f1,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fadds f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// fadds f24,f1,f5
	ctx.f24.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// rlwinm r9,r6,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// add r27,r5,r4
	ctx.r27.u64 = ctx.r5.u64 + ctx.r4.u64;
	// fmuls f17,f12,f8
	ctx.f17.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// mulli r29,r6,20
	ctx.r29.s64 = ctx.r6.s64 * 20;
	// fmuls f18,f12,f7
	ctx.f18.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// lfsx f31,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfs f26,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f22,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f1,f26,f31
	ctx.f1.f64 = double(float(ctx.f26.f64 - ctx.f31.f64));
	// fadds f31,f31,f26
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f26.f64));
	// mulli r7,r6,24
	ctx.r7.s64 = ctx.r6.s64 * 24;
	// fsubs f26,f22,f23
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// fmadds f22,f11,f7,f17
	ctx.f22.f64 = double(float(ctx.f11.f64 * ctx.f7.f64 + ctx.f17.f64));
	// fmsubs f18,f11,f8,f18
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 - ctx.f18.f64));
	// lfsx f20,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// add r26,r29,r4
	ctx.r26.u64 = ctx.r29.u64 + ctx.r4.u64;
	// add r29,r29,r3
	ctx.r29.u64 = ctx.r29.u64 + ctx.r3.u64;
	// lfs f21,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f17,f21,f20
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// lfs f15,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fadds f20,f19,f24
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// fsubs f19,f31,f28
	ctx.f19.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// fadds f31,f31,f28
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f28.f64));
	// fadds f28,f1,f17
	ctx.f28.f64 = double(float(ctx.f1.f64 + ctx.f17.f64));
	// fadds f16,f21,f5
	ctx.f16.f64 = double(float(ctx.f21.f64 + ctx.f5.f64));
	// fsubs f5,f5,f21
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f21.f64));
	// lfsx f21,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f17.f64));
	// lfsx f17,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f4,f21
	ctx.f14.f64 = double(float(ctx.f4.f64 - ctx.f21.f64));
	// fadds f4,f21,f4
	ctx.f4.f64 = double(float(ctx.f21.f64 + ctx.f4.f64));
	// fadds f21,f15,f17
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// fadds f15,f14,f23
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// fsubs f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// fadds f14,f21,f25
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// fsubs f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// fadds f21,f4,f27
	ctx.f21.f64 = double(float(ctx.f4.f64 + ctx.f27.f64));
	// stfs f21,-236(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// fadds f21,f17,f26
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// fsubs f4,f27,f4
	ctx.f4.f64 = double(float(ctx.f27.f64 - ctx.f4.f64));
	// stfs f4,-240(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// lfs f27,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f4,f25,f23
	ctx.f4.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// stfs f4,-232(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -232, temp.u32);
	// fsubs f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 - ctx.f27.f64));
	// stfs f27,-224(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -224, temp.u32);
	// fsubs f27,f28,f21
	ctx.f27.f64 = double(float(ctx.f28.f64 - ctx.f21.f64));
	// stfs f27,-228(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -228, temp.u32);
	// fsubs f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// fadds f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// fadds f28,f21,f28
	ctx.f28.f64 = double(float(ctx.f21.f64 + ctx.f28.f64));
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// fadds f27,f26,f24
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// stfs f27,-220(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -220, temp.u32);
	// lfs f27,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f27.f64 = double(temp.f32);
	// fadds f4,f27,f1
	ctx.f4.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// fsubs f27,f24,f26
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// lfs f26,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f26.f64));
	// lfs f26,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f20.f64));
	// stfs f26,0(r3)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f28,0(r4)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmuls f28,f17,f6
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// lfs f17,-232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -232);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f26,f17,f6
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// lfs f24,-228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -228);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f21,f24,f2
	ctx.f21.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// fmuls f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// fmuls f17,f4,f8
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// fmuls f20,f4,f7
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// fsubs f4,f16,f28
	ctx.f4.f64 = double(float(ctx.f16.f64 - ctx.f28.f64));
	// stfs f4,-228(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -228, temp.u32);
	// fadds f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f16.f64));
	// fadds f4,f26,f19
	ctx.f4.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// fsubs f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// fmuls f19,f1,f29
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f29.f64));
	// fmuls f16,f1,f30
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lfs f1,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f3,f1,f3,f21
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f3.f64 - ctx.f21.f64));
	// stfsx f3,r9,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmadds f3,f1,f2,f24
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 + ctx.f24.f64));
	// stfsx f3,r9,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f3,-220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -220);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f8,f3,f8,f20
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f8.f64 - ctx.f20.f64));
	// stfsx f8,r10,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f8,f3,f7,f17
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f7.f64 + ctx.f17.f64));
	// stfsx f8,r10,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmuls f7,f4,f9
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f9.f64));
	// fmuls f3,f26,f11
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// fmsubs f8,f27,f30,f19
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f30.f64 - ctx.f19.f64));
	// stfsx f8,r7,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fmadds f8,f27,f29,f16
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f29.f64 + ctx.f16.f64));
	// stfsx f8,r7,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,-228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -228);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// fmsubs f8,f8,f10,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f10.f64 - ctx.f7.f64));
	// stfsx f8,r8,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fmuls f8,f28,f11
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// fmadds f10,f4,f10,f9
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f10.f64 + ctx.f9.f64));
	// stfsx f10,r8,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f10,f28,f12,f3
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 - ctx.f3.f64));
	// stfsx f10,r5,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f23,f25
	ctx.f10.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// add r3,r25,r3
	ctx.r3.u64 = ctx.r25.u64 + ctx.r3.u64;
	// fsubs f9,f14,f15
	ctx.f9.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// subf r4,r25,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r25.s64;
	// fmadds f12,f26,f12,f8
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f8.f64));
	// stfs f12,0(r27)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fmuls f11,f10,f6
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// fmuls f10,f9,f6
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fsubs f12,f5,f11
	ctx.f12.f64 = double(float(ctx.f5.f64 - ctx.f11.f64));
	// fsubs f9,f31,f10
	ctx.f9.f64 = double(float(ctx.f31.f64 - ctx.f10.f64));
	// fadds f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f31.f64));
	// fadds f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// fmuls f7,f12,f18
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f18.f64));
	// fmuls f8,f9,f18
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f18.f64));
	// fmuls f5,f10,f13
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmuls f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmsubs f12,f12,f22,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f22.f64 - ctx.f8.f64));
	// stfs f12,0(r29)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fmadds f12,f9,f22,f7
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f22.f64 + ctx.f7.f64));
	// stfs f12,0(r26)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fmsubs f12,f11,f0,f5
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f5.f64));
	// stfs f12,0(r30)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fmadds f0,f10,f0,f13
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f13.f64));
	// stfs f0,0(r28)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// lwz r10,3532(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d33128
	if (!ctx.cr0.eq) goto loc_82D33128;
loc_82D333DC:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f2c
	ctx.lr = 0x82D333E4;
	__restfpr_14(ctx, base);
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D333E8"))) PPC_WEAK_FUNC(sub_82D333E8);
PPC_FUNC_IMPL(__imp__sub_82D333E8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-5616
	ctx.r5.s64 = ctx.r11.s64 + -5616;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,12528
	ctx.r4.s64 = ctx.r11.s64 + 12528;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D33400"))) PPC_WEAK_FUNC(sub_82D33400);
PPC_FUNC_IMPL(__imp__sub_82D33400) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D33408;
	__savegprlr_28(ctx, base);
	// stfd f30,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f30.u64);
	// stfd f31,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f31.u64);
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// addi r11,r11,-16
	ctx.r11.s64 = ctx.r11.s64 + -16;
	// bge cr6,0x82d33540
	if (!ctx.cr6.lt) goto loc_82D33540;
	// rlwinm r29,r9,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
loc_82D33430:
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f10,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// mulli r8,r6,12
	ctx.r8.s64 = ctx.r6.s64 * 12;
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f7,f12,f13
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f8,f12,f0
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// rlwinm r7,r6,3,0,28
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// add r5,r9,r4
	ctx.r5.u64 = ctx.r9.u64 + ctx.r4.u64;
	// add r9,r9,r3
	ctx.r9.u64 = ctx.r9.u64 + ctx.r3.u64;
	// add r31,r8,r4
	ctx.r31.u64 = ctx.r8.u64 + ctx.r4.u64;
	// add r30,r7,r3
	ctx.r30.u64 = ctx.r7.u64 + ctx.r3.u64;
	// add r8,r8,r3
	ctx.r8.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fmsubs f7,f11,f0,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f7.f64));
	// lfs f6,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f8,f11,f13,f8
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f8.f64));
	// lfs f5,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fadds f31,f6,f10
	ctx.f31.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// lfs f4,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fadds f30,f9,f5
	ctx.f30.f64 = double(float(ctx.f9.f64 + ctx.f5.f64));
	// lfs f2,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// lfs f3,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f9,f5,f9
	ctx.f9.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// lfs f1,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f6,f4,f2
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f5,f1,f3
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// fadds f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fadds f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// fadds f1,f30,f31
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// stfs f1,0(r3)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f2,f31,f30
	ctx.f2.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// fsubs f1,f6,f5
	ctx.f1.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fadds f31,f4,f9
	ctx.f31.f64 = double(float(ctx.f4.f64 + ctx.f9.f64));
	// fsubs f9,f4,f9
	ctx.f9.f64 = double(float(ctx.f4.f64 - ctx.f9.f64));
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// stfs f6,0(r4)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f30,f10,f3
	ctx.f30.f64 = double(float(ctx.f10.f64 - ctx.f3.f64));
	// subf r4,r29,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r29.s64;
	// fadds f10,f3,f10
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f10.f64));
	// fmuls f6,f2,f7
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// fmuls f7,f1,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// fmuls f5,f31,f13
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// fmuls f4,f31,f0
	ctx.f4.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f3,f9,f11
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// fmuls f9,f9,f12
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// fmsubs f7,f2,f8,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f8.f64 - ctx.f7.f64));
	// stfs f7,0(r30)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fmadds f8,f1,f8,f6
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f8.f64 + ctx.f6.f64));
	// stfs f8,0(r7)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// fmsubs f0,f30,f0,f5
	ctx.f0.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 - ctx.f5.f64));
	// stfs f0,0(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// fmadds f0,f30,f13,f4
	ctx.f0.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 + ctx.f4.f64));
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fmsubs f0,f10,f12,f3
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 - ctx.f3.f64));
	// stfs f0,0(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// fmadds f0,f10,f11,f9
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 + ctx.f9.f64));
	// stfs f0,0(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// lwz r9,3532(r28)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3532);
	// xor r6,r9,r6
	ctx.r6.u64 = ctx.r9.u64 ^ ctx.r6.u64;
	// bne 0x82d33430
	if (!ctx.cr0.eq) goto loc_82D33430;
loc_82D33540:
	// lfd f30,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f31,-48(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D33550"))) PPC_WEAK_FUNC(sub_82D33550);
PPC_FUNC_IMPL(__imp__sub_82D33550) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-5552
	ctx.r5.s64 = ctx.r11.s64 + -5552;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,13312
	ctx.r4.s64 = ctx.r11.s64 + 13312;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D33568"))) PPC_WEAK_FUNC(sub_82D33568);
PPC_FUNC_IMPL(__imp__sub_82D33568) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D33570;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D33578;
	__savefpr_14(ctx, base);
	// stwu r1,-976(r1)
	ea = -976 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mulli r11,r7,504
	ctx.r11.s64 = ctx.r7.s64 * 504;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-504
	ctx.r11.s64 = ctx.r11.s64 + -504;
	// bge cr6,0x82d36a6c
	if (!ctx.cr6.lt) goto loc_82D36A6C;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// stw r10,652(r1)
	PPC_STORE_U32(ctx.r1.u32 + 652, ctx.r10.u32);
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f31,-5420(r22)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -5420);
	ctx.f31.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f1,-5424(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -5424);
	ctx.f1.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f2,-5428(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -5428);
	ctx.f2.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f3,-5432(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -5432);
	ctx.f3.f64 = double(temp.f32);
	// stw r10,556(r1)
	PPC_STORE_U32(ctx.r1.u32 + 556, ctx.r10.u32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f4,-5436(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -5436);
	ctx.f4.f64 = double(temp.f32);
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lfs f5,-5440(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -5440);
	ctx.f5.f64 = double(temp.f32);
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lfs f6,-5444(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -5444);
	ctx.f6.f64 = double(temp.f32);
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lfs f7,-5448(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -5448);
	ctx.f7.f64 = double(temp.f32);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lfs f8,-8008(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8008);
	ctx.f8.f64 = double(temp.f32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f9,-8012(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8012);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-8004(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -8004);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,-8000(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -8000);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,136(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D33618:
	// mulli r31,r6,28
	ctx.r31.s64 = ctx.r6.s64 * 28;
	// lfs f30,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// mulli r30,r6,156
	ctx.r30.s64 = ctx.r6.s64 * 156;
	// stw r31,24(r1)
	PPC_STORE_U32(ctx.r1.u32 + 24, ctx.r31.u32);
	// stw r30,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r30.u32);
	// add r26,r31,r4
	ctx.r26.u64 = ctx.r31.u64 + ctx.r4.u64;
	// add r25,r30,r4
	ctx.r25.u64 = ctx.r30.u64 + ctx.r4.u64;
	// mulli r10,r6,96
	ctx.r10.s64 = ctx.r6.s64 * 96;
	// lfs f29,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// stw r26,672(r1)
	PPC_STORE_U32(ctx.r1.u32 + 672, ctx.r26.u32);
	// lfs f27,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// stw r25,668(r1)
	PPC_STORE_U32(ctx.r1.u32 + 668, ctx.r25.u32);
	// lfsx f28,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f20,f29,f28
	ctx.f20.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// mulli r9,r6,224
	ctx.r9.s64 = ctx.r6.s64 * 224;
	// fadds f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// lfsx f26,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f18,f26,f27
	ctx.f18.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// mulli r29,r6,92
	ctx.r29.s64 = ctx.r6.s64 * 92;
	// fsubs f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// stw r29,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, ctx.r29.u32);
	// add r22,r29,r4
	ctx.r22.u64 = ctx.r29.u64 + ctx.r4.u64;
	// rlwinm r8,r6,5,0,26
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// mulli r7,r6,220
	ctx.r7.s64 = ctx.r6.s64 * 220;
	// lfs f24,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// stw r22,660(r1)
	PPC_STORE_U32(ctx.r1.u32 + 660, ctx.r22.u32);
	// lfsx f25,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f23,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f26,f25,f24
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// mulli r5,r6,160
	ctx.r5.s64 = ctx.r6.s64 * 160;
	// lfsx f22,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f15,f22,f23
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// mulli r24,r6,60
	ctx.r24.s64 = ctx.r6.s64 * 60;
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// mulli r31,r6,124
	ctx.r31.s64 = ctx.r6.s64 * 124;
	// lfsx f21,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f21,f30
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// add r26,r24,r4
	ctx.r26.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fsubs f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// rlwinm r30,r6,6,0,25
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 6) & 0xFFFFFFC0;
	// mulli r23,r6,188
	ctx.r23.s64 = ctx.r6.s64 * 188;
	// lfs f19,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// stw r26,664(r1)
	PPC_STORE_U32(ctx.r1.u32 + 664, ctx.r26.u32);
	// lfsx f28,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f21,f19,f28
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// fsubs f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// add r25,r23,r4
	ctx.r25.u64 = ctx.r23.u64 + ctx.r4.u64;
	// fadds f19,f18,f20
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// mulli r29,r6,192
	ctx.r29.s64 = ctx.r6.s64 * 192;
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// lfs f17,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// stw r25,656(r1)
	PPC_STORE_U32(ctx.r1.u32 + 656, ctx.r25.u32);
	// lfsx f16,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f16,f17
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f18,64(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// mulli r28,r6,252
	ctx.r28.s64 = ctx.r6.s64 * 252;
	// fadds f16,f15,f26
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f26.f64));
	// fsubs f26,f26,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f15.f64));
	// fadds f18,f25,f29
	ctx.f18.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// lfsx f24,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// rlwinm r27,r6,7,0,24
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 7) & 0xFFFFFF80;
	// lfsx f14,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f24
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// fsubs f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// fadds f14,f21,f22
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,32(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f21,f26,f20
	ctx.f21.f64 = double(float(ctx.f26.f64 - ctx.f20.f64));
	// stfs f21,16(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f22,f16,f19
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// fsubs f21,f15,f28
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f28.f64));
	// fmuls f14,f22,f0
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f22,188(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f22,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,584(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 584, temp.u32);
	// mulli r14,r6,20
	ctx.r14.s64 = ctx.r6.s64 * 20;
	// lfs f22,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f22.f64 = double(temp.f32);
	// fadds f20,f26,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 + ctx.f20.f64));
	// mulli r24,r6,72
	ctx.r24.s64 = ctx.r6.s64 * 72;
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f22,612(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 612, temp.u32);
	// fsubs f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 - ctx.f19.f64));
	// lfs f22,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f26,f27,f23
	ctx.f26.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// stw r14,544(r1)
	PPC_STORE_U32(ctx.r1.u32 + 544, ctx.r14.u32);
	// fsubs f29,f25,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 - ctx.f29.f64));
	// fadds f22,f22,f30
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// fsubs f25,f24,f17
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f17.f64));
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// fadds f24,f24,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f17.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f30,f30,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f16.f64));
	// fmuls f23,f20,f0
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fadds f28,f15,f28
	ctx.f28.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// fmuls f20,f19,f0
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fadds f19,f26,f17
	ctx.f19.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// fsubs f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f26.f64));
	// mulli r23,r6,52
	ctx.r23.s64 = ctx.r6.s64 * 52;
	// fsubs f18,f22,f14
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// fadds f17,f25,f29
	ctx.f17.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f29,f25,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 - ctx.f29.f64));
	// fadds f25,f27,f24
	ctx.f25.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// stfs f25,76(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fsubs f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// stfs f27,460(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,168(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// mulli r14,r6,104
	ctx.r14.s64 = ctx.r6.s64 * 104;
	// fsubs f27,f30,f23
	ctx.f27.f64 = double(float(ctx.f30.f64 - ctx.f23.f64));
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// fadds f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// stfs f27,404(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// lfsx f25,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f27,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f30,264(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fsubs f30,f28,f20
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f20.f64));
	// stw r14,492(r1)
	PPC_STORE_U32(ctx.r1.u32 + 492, ctx.r14.u32);
	// fadds f14,f25,f27
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stfs f30,52(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fadds f30,f20,f28
	ctx.f30.f64 = double(float(ctx.f20.f64 + ctx.f28.f64));
	// mulli r22,r6,244
	ctx.r22.s64 = ctx.r6.s64 * 244;
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// stfs f30,212(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f24,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// mulli r21,r6,136
	ctx.r21.s64 = ctx.r6.s64 * 136;
	// lfsx f23,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// mulli r16,r6,212
	ctx.r16.s64 = ctx.r6.s64 * 212;
	// lfsx f25,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,188(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f25,f24,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// rlwinm r26,r6,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lwz r14,544(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	// mulli r25,r6,116
	ctx.r25.s64 = ctx.r6.s64 * 116;
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f25,64(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfsx f23,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f30,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f28,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f15,f28,f30
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f23,192(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// mulli r20,r6,180
	ctx.r20.s64 = ctx.r6.s64 * 180;
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// lfsx f20,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r19,r6,200
	ctx.r19.s64 = ctx.r6.s64 * 200;
	// lfsx f16,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r18,r6,40
	ctx.r18.s64 = ctx.r6.s64 * 40;
	// lfsx f28,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// mulli r17,r6,84
	ctx.r17.s64 = ctx.r6.s64 * 84;
	// lfsx f14,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r15,r6,168
	ctx.r15.s64 = ctx.r6.s64 * 168;
	// lfsx f25,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f23,f20,f16
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f23,16(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,96(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// lwz r14,492(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// fadds f15,f14,f28
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// fsubs f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f14.f64));
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f25
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// stfs f14,244(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// fadds f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// stfs f25,40(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f23,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// rlwinm r14,r6,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r14,520(r1)
	PPC_STORE_U32(ctx.r1.u32 + 520, ctx.r14.u32);
	// mulli r14,r6,120
	ctx.r14.s64 = ctx.r6.s64 * 120;
	// stw r14,548(r1)
	PPC_STORE_U32(ctx.r1.u32 + 548, ctx.r14.u32);
	// mulli r14,r6,68
	ctx.r14.s64 = ctx.r6.s64 * 68;
	// lfs f25,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f14,f14,f25
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// fadds f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfs f14,188(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f28
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// stfs f14,228(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f14.f64));
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stw r14,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, ctx.r14.u32);
	// fadds f14,f20,f30
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f30.f64));
	// mulli r14,r6,132
	ctx.r14.s64 = ctx.r6.s64 * 132;
	// fsubs f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// stfs f30,136(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fsubs f30,f24,f27
	ctx.f30.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// stfs f30,172(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fadds f30,f24,f27
	ctx.f30.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// stfs f30,236(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f30,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f30.f64 = double(temp.f32);
	// stw r14,516(r1)
	PPC_STORE_U32(ctx.r1.u32 + 516, ctx.r14.u32);
	// mulli r14,r6,148
	ctx.r14.s64 = ctx.r6.s64 * 148;
	// lfs f27,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f24,f27,f30
	ctx.f24.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f24,320(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// lfs f27,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f20,f27,f15
	ctx.f20.f64 = double(float(ctx.f27.f64 - ctx.f15.f64));
	// stfs f20,96(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fadds f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 + ctx.f27.f64));
	// stfs f27,208(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfsx f27,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// mulli r14,r6,232
	ctx.r14.s64 = ctx.r6.s64 * 232;
	// stfs f27,40(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmuls f24,f24,f12
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fmuls f20,f30,f12
	ctx.f20.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// fmuls f15,f30,f13
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// lfsx f30,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lwz r14,520(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	// lfsx f27,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// lwz r14,548(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	// stfs f27,16(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f27,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// mulli r14,r6,56
	ctx.r14.s64 = ctx.r6.s64 * 56;
	// stfs f27,64(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfsx f27,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,32(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lwz r14,188(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lfsx f27,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,192(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f27,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f30.f64));
	// stfs f27,108(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f27,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f27.f64 = double(temp.f32);
	// fadds f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// stfs f30,40(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f30,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f30.f64 = double(temp.f32);
	// lfs f27,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f27,16(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f27,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfs f30,196(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f30,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f30.f64 = double(temp.f32);
	// lfs f27,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f27,64(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f27,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfs f30,340(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// lfs f30,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f30.f64 = double(temp.f32);
	// lfs f27,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 - ctx.f30.f64));
	// lfs f27,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f23.f64));
	// stfs f27,192(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f27,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// stfs f27,32(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f27,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f27.f64 = double(temp.f32);
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// stfs f27,40(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f27,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f27.f64 = double(temp.f32);
	// lfs f23,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f27
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// stfs f23,368(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// lfs f23,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f27,f27,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// stfs f27,328(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fadds f27,f30,f16
	ctx.f27.f64 = double(float(ctx.f30.f64 + ctx.f16.f64));
	// stfs f27,244(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fsubs f30,f16,f30
	ctx.f30.f64 = double(float(ctx.f16.f64 - ctx.f30.f64));
	// stfs f30,180(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f30,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f30.f64 = double(temp.f32);
	// lfs f27,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f27.f64 = double(temp.f32);
	// fadds f23,f27,f30
	ctx.f23.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// lfs f27,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f16,f27,f28
	ctx.f16.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fsubs f27,f28,f27
	ctx.f27.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// lfs f28,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f28,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f28.f64));
	// stfs f28,64(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f28,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f25.f64));
	// stfs f28,140(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fmuls f30,f23,f0
	ctx.f30.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f28,f16,f0
	ctx.f28.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f27,f27,f0
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// lfs f23,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f25,f23,f0
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f25,16(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f25,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f25,f12
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f25,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f25.f64 = double(temp.f32);
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f25
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f25.f64));
	// stfs f16,636(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 636, temp.u32);
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f16.f64));
	// stfs f25,604(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 604, temp.u32);
	// lfs f25,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f25,f25,f13,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f23.f64));
	// stfs f25,268(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f25,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f25.f64 = double(temp.f32);
	// mulli r14,r6,248
	ctx.r14.s64 = ctx.r6.s64 * 248;
	// fmsubs f25,f25,f13,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 - ctx.f24.f64));
	// stfs f25,564(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 564, temp.u32);
	// fsubs f25,f14,f30
	ctx.f25.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// fadds f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// stfs f30,476(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// lfs f30,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f30.f64 = double(temp.f32);
	// stfs f25,632(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 632, temp.u32);
	// fmadds f25,f30,f13,f20
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 + ctx.f20.f64));
	// stw r14,508(r1)
	PPC_STORE_U32(ctx.r1.u32 + 508, ctx.r14.u32);
	// mulli r14,r6,196
	ctx.r14.s64 = ctx.r6.s64 * 196;
	// fmsubs f30,f30,f12,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f12.f64 - ctx.f15.f64));
	// stfs f30,588(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 588, temp.u32);
	// lfs f30,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f30.f64 = double(temp.f32);
	// stfs f25,380(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fsubs f25,f30,f28
	ctx.f25.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f30,448(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// lfs f30,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f30.f64 = double(temp.f32);
	// fadds f28,f27,f30
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f28,560(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 560, temp.u32);
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfs f30,428(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// stw r14,64(r1)
	PPC_STORE_U32(ctx.r1.u32 + 64, ctx.r14.u32);
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f30.f64 = double(temp.f32);
	// mulli r14,r6,184
	ctx.r14.s64 = ctx.r6.s64 * 184;
	// fsubs f27,f30,f28
	ctx.f27.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f30,372(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// stfs f27,388(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// stfs f25,436(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// stw r14,496(r1)
	PPC_STORE_U32(ctx.r1.u32 + 496, ctx.r14.u32);
	// mulli r14,r6,24
	ctx.r14.s64 = ctx.r6.s64 * 24;
	// stw r14,484(r1)
	PPC_STORE_U32(ctx.r1.u32 + 484, ctx.r14.u32);
	// mulli r14,r6,100
	ctx.r14.s64 = ctx.r6.s64 * 100;
	// stw r14,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r14.u32);
	// mulli r14,r6,228
	ctx.r14.s64 = ctx.r6.s64 * 228;
	// stw r14,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, ctx.r14.u32);
	// mulli r14,r6,152
	ctx.r14.s64 = ctx.r6.s64 * 152;
	// stw r14,512(r1)
	PPC_STORE_U32(ctx.r1.u32 + 512, ctx.r14.u32);
	// mulli r14,r6,36
	ctx.r14.s64 = ctx.r6.s64 * 36;
	// stw r14,40(r1)
	PPC_STORE_U32(ctx.r1.u32 + 40, ctx.r14.u32);
	// mulli r14,r6,88
	ctx.r14.s64 = ctx.r6.s64 * 88;
	// stw r14,528(r1)
	PPC_STORE_U32(ctx.r1.u32 + 528, ctx.r14.u32);
	// lwz r14,516(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// lfsx f30,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// lwz r14,508(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	// lfsx f28,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,64(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	// lfsx f27,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// lwz r14,496(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	// lfsx f25,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lwz r14,484(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	// lfsx f24,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lwz r14,192(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// lfsx f23,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// lwz r14,244(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// lfsx f20,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lwz r14,512(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lwz r14,40(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,528(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,164
	ctx.r14.s64 = ctx.r6.s64 * 164;
	// stfs f14,108(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,248(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// mulli r14,r6,216
	ctx.r14.s64 = ctx.r6.s64 * 216;
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f14,f30,f28
	ctx.f14.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// fsubs f28,f27,f25
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// fadds f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fadds f25,f23,f24
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fsubs f23,f20,f16
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// lfs f16,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,260(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f16,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r14,r6,4,0,27
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,364(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,108(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f15,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f15.f64 = double(temp.f32);
	// stw r14,488(r1)
	PPC_STORE_U32(ctx.r1.u32 + 488, ctx.r14.u32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// mulli r14,r6,108
	ctx.r14.s64 = ctx.r6.s64 * 108;
	// fsubs f15,f14,f28
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f20,f24
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// fsubs f24,f24,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f20.f64));
	// fadds f15,f27,f15
	ctx.f15.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// lfs f20,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f25,f20
	ctx.f20.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// stfs f20,32(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f20,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f20.f64 = double(temp.f32);
	// fadds f25,f20,f25
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// stfs f25,184(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f20,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f20,248(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f25,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f25.f64 = double(temp.f32);
	// lfs f20,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// fadds f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfs f23,260(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f23,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// stfs f23,96(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f23,f16,f20
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// fsubs f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f20,32(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f16.f64 = double(temp.f32);
	// lfs f20,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f20,112(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f20,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f20.f64 = double(temp.f32);
	// fadds f16,f25,f20
	ctx.f16.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// stfs f16,108(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f16,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f25,f20,f25
	ctx.f25.f64 = double(float(ctx.f20.f64 - ctx.f25.f64));
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f20,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f28
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f28.f64));
	// stfs f20,608(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 608, temp.u32);
	// stfs f25,228(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fmuls f20,f16,f0
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f20,f23,f12
	ctx.f20.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// lfs f16,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fmsubs f23,f23,f13,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f23,384(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f23,f13,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f20.f64));
	// stfs f23,616(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 616, temp.u32);
	// lfs f23,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f23.f64 = double(temp.f32);
	// stfs f25,16(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmr f25,f23
	ctx.f25.f64 = ctx.f23.f64;
	// fsubs f23,f15,f25
	ctx.f23.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// stfs f23,624(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 624, temp.u32);
	// fadds f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f25,456(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f25,f15,f12,f20
	ctx.f25.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f20.f64));
	// stfs f25,648(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 648, temp.u32);
	// lfs f25,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f23,f14,f25
	ctx.f23.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// lfs f25,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f25.f64 = double(temp.f32);
	// stw r14,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r14.u32);
	// fsubs f20,f24,f25
	ctx.f20.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// mulli r14,r6,172
	ctx.r14.s64 = ctx.r6.s64 * 172;
	// fadds f16,f25,f24
	ctx.f16.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// lfs f24,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f25,f24,f30
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f30.f64));
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// fadds f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f24.f64));
	// lfs f24,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// lfs f24,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f24.f64 = double(temp.f32);
	// stw r14,368(r1)
	PPC_STORE_U32(ctx.r1.u32 + 368, ctx.r14.u32);
	// mulli r14,r6,208
	ctx.r14.s64 = ctx.r6.s64 * 208;
	// fsubs f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 - ctx.f27.f64));
	// lfs f14,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f12
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stw r14,504(r1)
	PPC_STORE_U32(ctx.r1.u32 + 504, ctx.r14.u32);
	// mulli r14,r6,80
	ctx.r14.s64 = ctx.r6.s64 * 80;
	// fmadds f15,f15,f13,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f15,432(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// fsubs f15,f28,f24
	ctx.f15.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// stfs f15,596(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// fadds f28,f24,f28
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// stfs f28,644(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 644, temp.u32);
	// stw r14,500(r1)
	PPC_STORE_U32(ctx.r1.u32 + 500, ctx.r14.u32);
	// fsubs f28,f25,f23
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// stfs f28,104(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fadds f28,f23,f25
	ctx.f28.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// mulli r14,r6,44
	ctx.r14.s64 = ctx.r6.s64 * 44;
	// stfs f28,540(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 540, temp.u32);
	// fsubs f28,f20,f30
	ctx.f28.f64 = double(float(ctx.f20.f64 - ctx.f30.f64));
	// stfs f28,272(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fadds f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f20.f64));
	// stfs f30,568(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 568, temp.u32);
	// fsubs f30,f27,f16
	ctx.f30.f64 = double(float(ctx.f27.f64 - ctx.f16.f64));
	// stfs f30,396(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// fadds f30,f16,f27
	ctx.f30.f64 = double(float(ctx.f16.f64 + ctx.f27.f64));
	// stfs f30,420(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// stw r14,260(r1)
	PPC_STORE_U32(ctx.r1.u32 + 260, ctx.r14.u32);
	// mulli r14,r6,236
	ctx.r14.s64 = ctx.r6.s64 * 236;
	// stw r14,248(r1)
	PPC_STORE_U32(ctx.r1.u32 + 248, ctx.r14.u32);
	// mulli r14,r6,144
	ctx.r14.s64 = ctx.r6.s64 * 144;
	// stw r14,536(r1)
	PPC_STORE_U32(ctx.r1.u32 + 536, ctx.r14.u32);
	// mulli r14,r6,76
	ctx.r14.s64 = ctx.r6.s64 * 76;
	// stw r14,364(r1)
	PPC_STORE_U32(ctx.r1.u32 + 364, ctx.r14.u32);
	// lwz r14,488(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	// lfsx f30,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lwz r14,108(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lfsx f28,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,368(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	// fsubs f15,f30,f28
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// lfsx f27,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// lwz r14,504(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	// lfsx f25,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lwz r14,500(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	// fadds f14,f25,f27
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stfs f14,184(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// lfsx f24,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lwz r14,260(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// lfsx f23,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// lwz r14,248(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	// lfsx f20,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lwz r14,536(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,12
	ctx.r14.s64 = ctx.r6.s64 * 12;
	// lfsx f28,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,112
	ctx.r14.s64 = ctx.r6.s64 * 112;
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,204
	ctx.r14.s64 = ctx.r6.s64 * 204;
	// lfsx f25,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,196(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fsubs f25,f24,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// stfs f25,88(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// mulli r14,r6,176
	ctx.r14.s64 = ctx.r6.s64 * 176;
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfsx f25,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// mulli r14,r6,48
	ctx.r14.s64 = ctx.r6.s64 * 48;
	// lfsx f23,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lwz r14,364(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	// stfs f23,228(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fadds f23,f16,f20
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// fsubs f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// lfs f16,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// fadds f15,f14,f28
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// fsubs f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f14.f64));
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f25
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// stfs f14,184(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fadds f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,320(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// mulli r14,r6,140
	ctx.r14.s64 = ctx.r6.s64 * 140;
	// stfs f23,96(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fadds f14,f25,f28
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// stfs f14,180(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fsubs f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// stfs f28,224(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fsubs f25,f20,f27
	ctx.f25.f64 = double(float(ctx.f20.f64 - ctx.f27.f64));
	// fsubs f28,f30,f24
	ctx.f28.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// fadds f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// fmuls f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fadds f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// fsubs f14,f28,f25
	ctx.f14.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// stfs f14,136(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fadds f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// stfs f28,172(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fmuls f25,f16,f12
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fmsubs f23,f16,f13,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f23.f64));
	// lfs f16,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f16.f64 = double(temp.f32);
	// lfs f24,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f24.f64 = double(temp.f32);
	// stfs f25,32(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmr f25,f24
	ctx.f25.f64 = ctx.f24.f64;
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f28,f13
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// fmuls f28,f28,f12
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f24,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f28,f25,f12,f14
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f12.f64 - ctx.f14.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f25,f25,f13,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f14.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f24,f24,f13,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f14.f64));
	// lfs f14,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f14,f16
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,88(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f16,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f16,f12
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfsx f16,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,60(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,240
	ctx.r14.s64 = ctx.r6.s64 * 240;
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f16,f15,f20
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f20,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,96(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f20,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f20,116(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// fadds f15,f20,f30
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f30.f64));
	// fsubs f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// stfs f15,600(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// lfs f15,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,60
	ctx.r14.s64 = ctx.r6.s64 * 60;
	// lfs f20,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stfs f30,468(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// fsubs f30,f20,f15
	ctx.f30.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// fadds f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// lfs f15,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f30,f15
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// stfs f15,196(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f20,f15
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// lfs f15,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f15.f64 = double(temp.f32);
	// fadds f30,f30,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f15.f64));
	// stfs f30,32(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// stfs f20,96(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fadds f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// stfs f30,36(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,228(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,320(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f16,f13
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// lfs f30,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// lfs f27,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f27.f64 = double(temp.f32);
	// stfs f30,452(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// fmsubs f30,f27,f12,f15
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f12.f64 - ctx.f15.f64));
	// fmadds f27,f27,f13,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f27,16(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f27,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f27,f27,f13,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f27,32(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f27,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f13,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 + ctx.f20.f64));
	// stfs f27,96(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f27,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f27.f64 = double(temp.f32);
	// lfs f20,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f20.f64 = double(temp.f32);
	// fadds f16,f20,f27
	ctx.f16.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// fsubs f15,f27,f20
	ctx.f15.f64 = double(float(ctx.f27.f64 - ctx.f20.f64));
	// lfs f20,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f20.f64 = double(temp.f32);
	// lfs f27,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f27.f64 = double(temp.f32);
	// fadds f14,f20,f27
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// fsubs f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 - ctx.f27.f64));
	// fmuls f20,f16,f0
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f20,196(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fmuls f20,f15,f0
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f20,184(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fadds f20,f30,f28
	ctx.f20.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// stfs f20,472(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// fsubs f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// stfs f30,340(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// lfs f30,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f28,f25,f30
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f30.f64));
	// stfs f28,640(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 640, temp.u32);
	// fadds f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// stfs f30,328(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fmuls f30,f14,f0
	ctx.f30.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f30,300(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fmuls f30,f27,f0
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// stfs f30,444(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// lfs f30,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f28,f30,f24
	ctx.f28.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// stfs f28,440(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fadds f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// stfs f30,464(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// lfs f30,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f28,f23,f30
	ctx.f28.f64 = double(float(ctx.f23.f64 - ctx.f30.f64));
	// stfs f28,284(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fadds f30,f30,f23
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f23.f64));
	// stfs f30,288(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// stw r14,32(r1)
	PPC_STORE_U32(ctx.r1.u32 + 32, ctx.r14.u32);
	// mulli r14,r6,188
	ctx.r14.s64 = ctx.r6.s64 * 188;
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// lfs f28,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// lfsx f14,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,180(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfsx f14,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f14,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,136(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfsx f14,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,224(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfsx f27,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f24,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// stw r14,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r14.u32);
	// lfsx f25,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// lwz r14,24(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// lfsx f23,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f15,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,16(r1)
	PPC_STORE_U32(ctx.r1.u32 + 16, ctx.r14.u32);
	// lwz r14,204(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, ctx.r14.u32);
	// lwz r14,280(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,320(r1)
	PPC_STORE_U32(ctx.r1.u32 + 320, ctx.r14.u32);
	// lwz r14,32(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// lfs f28,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,96(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lfs f20,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// lfs f16,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,12
	ctx.r14.s64 = ctx.r6.s64 * 12;
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,172(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// mulli r14,r6,112
	ctx.r14.s64 = ctx.r6.s64 * 112;
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// mulli r14,r6,176
	ctx.r14.s64 = ctx.r6.s64 * 176;
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,132(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// mulli r14,r6,204
	ctx.r14.s64 = ctx.r6.s64 * 204;
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,364(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	// stfs f14,236(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,48
	ctx.r14.s64 = ctx.r6.s64 * 48;
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,144(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// mulli r14,r6,240
	ctx.r14.s64 = ctx.r6.s64 * 240;
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,204(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// mulli r14,r6,140
	ctx.r14.s64 = ctx.r6.s64 * 140;
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,228(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	// stfs f14,120(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fadds f14,f27,f28
	ctx.f14.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fsubs f27,f25,f24
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfs f25,44(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f24,f20,f23
	ctx.f24.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfs f24,216(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fsubs f25,f23,f20
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// fsubs f23,f16,f15
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f20,f15,f16
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f16,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// lwz r14,320(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	// lfs f15,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f15.f64 = double(temp.f32);
	// fadds f24,f16,f15
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,124(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,80(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,84(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f16,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,60(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f15,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,156(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f16,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,180(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,88(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f15,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,224(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f15,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,48(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,132(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f15,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,136(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f16,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,144(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f15,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,92(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fadds f15,f25,f27
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stfs f15,148(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fadds f15,f24,f23
	ctx.f15.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// stfs f15,256(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fsubs f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// stfs f24,252(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f23,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// stfs f23,56(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f23,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f23.f64 = double(temp.f32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// stfs f23,332(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// lfs f23,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// stfs f23,220(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// lfs f23,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f23,128(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// lfs f23,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// stfs f23,80(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f23,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f23.f64 = double(temp.f32);
	// lfs f15,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// stfs f15,164(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f15,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f23,60(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f23,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f23.f64 = double(temp.f32);
	// lfs f15,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// stfs f15,120(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f15,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f16,f15
	ctx.f15.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f15,132(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f15,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f15.f64 = double(temp.f32);
	// fadds f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// stfs f23,100(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f23,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// fadds f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// stfs f23,144(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f16,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f16.f64 = double(temp.f32);
	// lwz r14,488(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	// lfs f23,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f23.f64 = double(temp.f32);
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// fsubs f15,f24,f15
	ctx.f15.f64 = double(float(ctx.f24.f64 - ctx.f15.f64));
	// stfs f23,280(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f23,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fsubs f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// stfs f24,116(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// lfs f24,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f28
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// stfs f14,180(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f16,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// lfs f25,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f23,f14,f12,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 * ctx.f12.f64 - ctx.f23.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fadds f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// stfs f25,304(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f25,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// lfs f14,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f25,f25,f12,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f12.f64 + ctx.f16.f64));
	// lfs f16,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,312(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fmuls f16,f15,f0
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,120(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,480(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,108(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,504(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	// stfs f14,136(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,368(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	// stfs f14,172(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,260(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// stfs f14,236(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,500(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,536(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,248(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	// stfs f14,84(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,204(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f24,f14
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// stfs f14,552(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 552, temp.u32);
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// stfs f24,580(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 580, temp.u32);
	// fadds f24,f27,f20
	ctx.f24.f64 = double(float(ctx.f27.f64 + ctx.f20.f64));
	// stfs f24,376(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fsubs f27,f27,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f20.f64));
	// stfs f27,576(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 576, temp.u32);
	// lfs f27,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f24,f16,f27
	ctx.f24.f64 = double(float(ctx.f16.f64 - ctx.f27.f64));
	// stfs f24,292(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fadds f27,f27,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f16.f64));
	// lfs f24,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f24.f64 = double(temp.f32);
	// stfs f27,180(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fadds f27,f24,f15
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// fsubs f24,f15,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 - ctx.f24.f64));
	// lfs f15,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f16,f15
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,124(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,156(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f15,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fadds f14,f16,f24
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// stfs f14,116(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fsubs f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f27,f14
	ctx.f14.f64 = double(float(ctx.f27.f64 - ctx.f14.f64));
	// stfs f14,84(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fadds f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 + ctx.f27.f64));
	// stfs f27,80(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f14,124(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f27,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f27.f64 = double(temp.f32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f27,f27,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f20.f64));
	// fadds f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// lfs f14,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f15,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// stfs f20,236(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,224(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f27,f15
	ctx.f15.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// stfs f15,136(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f27,f27,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f14.f64));
	// stfs f27,348(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// lfs f27,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f27.f64 = double(temp.f32);
	// stfs f20,152(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmsubs f27,f27,f12,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f12.f64 - ctx.f15.f64));
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f16,f15,f12,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f16.f64));
	// stfs f16,172(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f16,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f20,572(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 572, temp.u32);
	// fmuls f20,f14,f0
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f20,592(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 592, temp.u32);
	// fadds f20,f27,f23
	ctx.f20.f64 = double(float(ctx.f27.f64 + ctx.f23.f64));
	// stfs f20,316(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fsubs f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// stfs f27,136(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lwz r14,520(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	// lfs f27,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f23,f25,f27
	ctx.f23.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// stfs f23,308(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fadds f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f25.f64));
	// stfs f27,172(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fmuls f27,f16,f0
	ctx.f27.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f27,620(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 620, temp.u32);
	// lfs f27,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f16,f24,f12
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// lfs f25,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f24,f13
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// fadds f20,f27,f25
	ctx.f20.f64 = double(float(ctx.f27.f64 + ctx.f25.f64));
	// lfs f27,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f27.f64 = double(temp.f32);
	// lfs f25,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f25.f64 = double(temp.f32);
	// lfs f23,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f23.f64 = double(temp.f32);
	// fadds f14,f27,f25
	ctx.f14.f64 = double(float(ctx.f27.f64 + ctx.f25.f64));
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// stfs f27,24(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmuls f25,f23,f12
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// stfs f25,204(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// stfs f24,280(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// fmuls f15,f23,f13
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// lfs f23,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f27,f30,f23
	ctx.f27.f64 = double(float(ctx.f30.f64 - ctx.f23.f64));
	// fmuls f23,f20,f0
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// stfs f23,128(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f23,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f25,f23,f13,f16
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f16.f64));
	// lfs f23,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f24,f23,f12,f15
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 + ctx.f15.f64));
	// lfs f23,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f23.f64 = double(temp.f32);
	// fadds f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// fmuls f23,f14,f0
	ctx.f23.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f23,252(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f23,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f23,100(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f20,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f23,256(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f20,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f23,232(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f20,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f28,f28,f20
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f20.f64));
	// lfs f20,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmsubs f16,f16,f13,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f12,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f15.f64));
	// stfs f16,204(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f15,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// fmuls f15,f14,f0
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f15,628(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f16,480(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lwz r14,548(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,188(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,56
	ctx.r14.s64 = ctx.r6.s64 * 56;
	// stfs f14,176(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,508(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,516(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// stfs f14,356(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,496(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	// stfs f14,200(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,64(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	// stfs f14,240(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,40(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,528(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	// stfs f14,164(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,216
	ctx.r14.s64 = ctx.r6.s64 * 216;
	// stfs f14,92(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f27,f14
	ctx.f14.f64 = double(float(ctx.f27.f64 - ctx.f14.f64));
	// stfs f14,348(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// fadds f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 + ctx.f27.f64));
	// stfs f27,532(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// fsubs f27,f25,f24
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfs f27,332(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fadds f27,f24,f25
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfs f27,524(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// lfs f27,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f25,f30,f27
	ctx.f25.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfs f25,252(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fadds f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f30,236(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f27,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f27.f64 = double(temp.f32);
	// lfs f30,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f25,f30,f27
	ctx.f25.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfs f25,412(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fadds f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f30,296(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f30,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f27,f30,f23
	ctx.f27.f64 = double(float(ctx.f30.f64 - ctx.f23.f64));
	// stfs f27,232(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fadds f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// stfs f30,28(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f30,f28,f20
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f20.f64));
	// stfs f30,100(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fadds f30,f20,f28
	ctx.f30.f64 = double(float(ctx.f20.f64 + ctx.f28.f64));
	// stfs f30,280(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f28,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f27,f30,f28
	ctx.f27.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfs f27,256(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// lfs f27,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f28,f16,f15
	ctx.f28.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f28,120(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f28,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f28.f64 = double(temp.f32);
	// fadds f23,f27,f28
	ctx.f23.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// lfs f25,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// stfs f28,276(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f28,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f27,f28,f25
	ctx.f27.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// stfs f30,204(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fadds f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// stfs f28,356(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f28,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f28.f64 = double(temp.f32);
	// fadds f30,f15,f16
	ctx.f30.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f23,336(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// stfs f27,416(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// lfs f24,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f25,f28,f24
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// stfs f25,424(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// fadds f28,f24,f28
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// stfs f28,144(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f28,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f28.f64 = double(temp.f32);
	// lfs f24,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f24.f64 = double(temp.f32);
	// fadds f20,f24,f28
	ctx.f20.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// stfs f20,116(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// mulli r14,r6,164
	ctx.r14.s64 = ctx.r6.s64 * 164;
	// fadds f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stfs f27,132(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fsubs f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// fadds f24,f23,f30
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// stfs f24,344(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// lfsx f14,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f27,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// lwz r14,484(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	// lfsx f14,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f14,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,176(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfsx f25,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// lwz r14,192(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// lfsx f14,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f24,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lwz r14,512(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	// lfsx f23,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// lwz r14,244(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// lfsx f20,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lwz r14,544(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lwz r14,492(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,232
	ctx.r14.s64 = ctx.r6.s64 * 232;
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,92(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// mulli r14,r6,148
	ctx.r14.s64 = ctx.r6.s64 * 148;
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,200(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfsx f14,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,240(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfsx f14,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,164(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfsx f14,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f14,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,220(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfsx f14,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f14,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,148(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfsx f14,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfsx f14,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,216(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f27,f14
	ctx.f14.f64 = double(float(ctx.f27.f64 + ctx.f14.f64));
	// stfs f14,128(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 - ctx.f27.f64));
	// stfs f27,156(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fsubs f27,f25,f24
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfs f25,80(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f24,f23,f20
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f24,124(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fadds f25,f20,f23
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// fadds f24,f15,f16
	ctx.f24.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f23,f16,f15
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f16,f15
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f15,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,68(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,400(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,392(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,92(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f14,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,164(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,220(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f14,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f28
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f14.f64));
	// stfs f28,408(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// lfs f28,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// stfs f28,60(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fadds f28,f25,f27
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stfs f28,240(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f14,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f14.f64 = double(temp.f32);
	// lfs f28,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// stfs f28,128(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f28,f27,f25
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f27,f16,f23
	ctx.f27.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// stfs f27,148(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f27,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f27.f64 = double(temp.f32);
	// fadds f25,f27,f24
	ctx.f25.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// stfs f25,24(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fsubs f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// lfs f24,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f14,f14,f24
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// stfs f14,216(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f24
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// lfs f25,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f24,f23,f16
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// stfs f24,176(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f24,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// fadds f24,f24,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// stfs f24,200(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// stfs f14,160(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f23,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f20.f64 = double(temp.f32);
	// lfs f24,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// stfs f24,44(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f24,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// stfs f24,56(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f24,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f24.f64 = double(temp.f32);
	// lfs f16,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f16.f64 = double(temp.f32);
	// fadds f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// stfs f23,392(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f23,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// stfs f23,400(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// lfs f16,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f14,f13
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// lfs f23,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// stfs f23,220(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f23,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// stfs f23,68(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f23,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// stfs f23,48(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fsubs f23,f27,f25
	ctx.f23.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// stfs f23,352(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// fadds f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stfs f27,360(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f27,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f23,f24,f13
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// fmuls f25,f27,f13
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// lfs f27,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f27,f13
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// lfs f27,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f16,f27,f28
	ctx.f16.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// fadds f15,f27,f28
	ctx.f15.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// lfs f27,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f27.f64 = double(temp.f32);
	// lfs f28,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f24,f24,f12
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fadds f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// lfs f27,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f27.f64 = double(temp.f32);
	// stfs f28,336(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfs f30,92(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f27,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f27.f64 = double(temp.f32);
	// lfs f30,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// lfs f27,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f28,f27,f12,f25
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f12.f64 - ctx.f25.f64));
	// lfs f27,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f27,f27,f12,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f12.f64 - ctx.f23.f64));
	// lfs f23,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f23.f64 = double(temp.f32);
	// lfs f25,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f24,f23,f13,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f24.f64));
	// stfs f24,408(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// lfs f23,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f25,f25,f12,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f12.f64 + ctx.f20.f64));
	// lfs f24,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f20,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f23,f16,f0
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f23,148(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f23,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f23,84(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f20,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f23,424(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// lfs f20,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// fmadds f16,f16,f12,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f14.f64));
	// stfs f16,80(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f20,f15,f0
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,416(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f16,336(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f16,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,156(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f16,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,164(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,72(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f15,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f14,344(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,400(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f16,f12
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f14,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f14,f13,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 - ctx.f15.f64));
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f30,f14
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// stfs f14,216(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f30,f14,f30
	ctx.f30.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// fadds f14,f27,f28
	ctx.f14.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// stfs f28,392(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f28,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f27,f25,f28
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f28.f64));
	// stfs f27,132(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fadds f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f25.f64));
	// stfs f28,324(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f28,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f28.f64 = double(temp.f32);
	// fadds f27,f28,f24
	ctx.f27.f64 = double(float(ctx.f28.f64 + ctx.f24.f64));
	// stfs f27,144(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fsubs f28,f24,f28
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f28.f64));
	// stfs f28,408(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// lfs f27,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f27.f64 = double(temp.f32);
	// lfs f28,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f28.f64 = double(temp.f32);
	// fadds f25,f27,f28
	ctx.f25.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// stfs f25,84(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fsubs f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// stfs f28,124(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f28,f23,f20
	ctx.f28.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f28,120(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fadds f28,f20,f23
	ctx.f28.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfs f28,60(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f27,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f27.f64 = double(temp.f32);
	// lfs f28,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f25,f28,f27
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// stfs f25,416(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// lfs f25,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f25.f64 = double(temp.f32);
	// lfs f27,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f27.f64 = double(temp.f32);
	// stfs f28,336(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// fsubs f28,f27,f25
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// fadds f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stfs f27,92(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f25,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f25.f64 = double(temp.f32);
	// lfs f27,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// stfs f27,424(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// lfs f27,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f27.f64 = double(temp.f32);
	// lfs f25,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f25.f64 = double(temp.f32);
	// fadds f24,f25,f27
	ctx.f24.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f23,f27,f25
	ctx.f23.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// lfs f25,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f25.f64 = double(temp.f32);
	// lfs f27,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f27.f64 = double(temp.f32);
	// fadds f20,f25,f27
	ctx.f20.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// lfs f25,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f16.f64));
	// stfs f25,344(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// fmuls f25,f24,f0
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// stfs f25,148(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmuls f25,f23,f0
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f27,f27,f0
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// stfs f25,156(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// stfs f27,116(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmuls f25,f20,f0
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f27,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f27.f64 = double(temp.f32);
	// stfs f25,128(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f25,f15,f27
	ctx.f25.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// fadds f27,f27,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// stfs f25,80(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f27,24(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f25,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f25.f64 = double(temp.f32);
	// lfs f27,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f25.f64));
	// lfs f24,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// lfs f23,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// stfs f24,360(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f23,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// stfs f24,304(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f24,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// stfs f24,352(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfs f23,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// stfs f24,312(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f23,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// stfs f24,152(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f23,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f24,44(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f23,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f24.f64 = double(temp.f32);
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// lfs f23,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,200(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fmuls f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// lfs f15,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f15.f64 = double(temp.f32);
	// lfs f20,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,160(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f15,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,240(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f24,f24,f0
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmsubs f23,f16,f13,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f23.f64));
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f20,f16,f13,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 + ctx.f20.f64));
	// fadds f16,f25,f27
	ctx.f16.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// lfs f25,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f25
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// stfs f15,360(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f15,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f25,276(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f25,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f25
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// stfs f15,352(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfs f15,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// stfs f25,68(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f25,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f25
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// stfs f15,152(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f25,176(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f25,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f25,f15
	ctx.f15.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f15,312(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// fadds f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// stfs f25,356(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f25,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f15,f25,f24
	ctx.f15.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfs f15,200(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfs f25,56(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f25,f23,f20
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f25,304(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fadds f25,f20,f23
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfs f25,44(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f25,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f25.f64 = double(temp.f32);
	// fadds f24,f25,f16
	ctx.f24.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// lfs f20,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f25,f16,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 - ctx.f25.f64));
	// lfs f15,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f15.f64 = double(temp.f32);
	// stfs f24,0(r3)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f24,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f27,f24
	ctx.f24.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// lfs f16,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f16.f64 = double(temp.f32);
	// fadds f23,f16,f20
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f23,0(r4)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fadds f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 + ctx.f27.f64));
	// stfs f27,160(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f15,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f15.f64 = double(temp.f32);
	// lfs f27,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// stfs f27,72(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f27,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f27.f64 = double(temp.f32);
	// lfs f23,248(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f27,f20
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// fmuls f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// fmsubs f25,f23,f25,f15
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f25.f64 - ctx.f15.f64));
	// stfsx f25,r27,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fmadds f27,f23,f20,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f20.f64 + ctx.f27.f64));
	// stfsx f27,r27,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f25,380(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 380);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f25,f16
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f16.f64));
	// lfs f27,376(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 376);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// fmsubs f24,f27,f24,f23
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f24.f64 - ctx.f23.f64));
	// stfsx f24,r29,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fmadds f27,f27,f16,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f16.f64 + ctx.f25.f64));
	// stfsx f27,r29,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// lfs f25,124(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 124);
	ctx.f25.f64 = double(temp.f32);
	// lfs f27,120(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 120);
	ctx.f27.f64 = double(temp.f32);
	// lfs f24,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f20,f25,f23
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f23.f64));
	// fmuls f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// fmsubs f24,f27,f24,f20
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f24.f64 - ctx.f20.f64));
	// stfsx f24,r30,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmadds f27,f27,f23,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f23.f64 + ctx.f25.f64));
	// stfsx f27,r30,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f27,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f27.f64 = double(temp.f32);
	// lfs f25,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f27
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// lfs f27,408(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 408);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,72(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f27,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f27,f12
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// lfs f27,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f23,f27,f13
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// fmuls f20,f27,f12
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// lfs f27,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f16,f27,f12
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// lfs f27,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f27.f64 = double(temp.f32);
	// lfs f15,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f15.f64 = double(temp.f32);
	// lwz r30,504(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	// fadds f15,f27,f15
	ctx.f15.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// fmuls f27,f25,f0
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// lfs f25,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f25,f25,f13,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 - ctx.f24.f64));
	// lfs f24,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f24,f12,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 + ctx.f23.f64));
	// stfs f24,68(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f23,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfs f23,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f23,f13,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f20.f64));
	// lfs f20,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f13,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f16.f64));
	// fmuls f16,f15,f0
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f27
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f15.f64 = double(temp.f32);
	// fadds f27,f27,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f25,f15
	ctx.f15.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f15,176(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fadds f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// fsubs f15,f23,f20
	ctx.f15.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f15,296(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fsubs f15,f24,f16
	ctx.f15.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// fadds f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// fadds f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// fadds f20,f25,f27
	ctx.f20.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// stfs f27,276(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f25,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f25.f64 = double(temp.f32);
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,68(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f27,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f27.f64 = double(temp.f32);
	// lfs f16,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// fadds f25,f16,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 + ctx.f25.f64));
	// fadds f16,f24,f23
	ctx.f16.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// stfs f24,296(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f24,412(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 412);
	ctx.f24.f64 = double(temp.f32);
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fmuls f15,f24,f27
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// lfs f23,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f24,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f24,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f27,f24,f27,f23
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f27.f64 - ctx.f23.f64));
	// stfsx f27,r30,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f27,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f24,f27,f15
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f27.f64 + ctx.f15.f64));
	// stfsx f27,r30,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f24,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f24.f64 = double(temp.f32);
	// lwz r30,488(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	// lfs f23,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f24,f23
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f27,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f24,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f20.f64));
	// fmsubs f20,f27,f20,f15
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 - ctx.f15.f64));
	// stfsx f20,r30,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmadds f27,f27,f23,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f23.f64 + ctx.f24.f64));
	// stfsx f27,r30,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f24,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f24.f64 = double(temp.f32);
	// lwz r30,500(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	// fmuls f23,f24,f16
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f16.f64));
	// lfs f27,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f24,f25
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// fmsubs f25,f27,f25,f23
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f25.f64 - ctx.f23.f64));
	// stfsx f25,r30,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmadds f27,f27,f16,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f16.f64 + ctx.f24.f64));
	// stfsx f27,r30,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f27,280(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	ctx.f27.f64 = double(temp.f32);
	// lfs f25,284(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 284);
	ctx.f25.f64 = double(temp.f32);
	// stfs f27,72(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// stfs f25,28(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lwz r30,536(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	// lfs f24,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f20,f28,f12
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fmuls f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// lfs f24,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f24.f64 = double(temp.f32);
	// lfs f16,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f15.f64 = double(temp.f32);
	// lfs f23,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fmsubs f27,f27,f24,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f24.f64 - ctx.f25.f64));
	// stfsx f27,r30,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f25.f64 = double(temp.f32);
	// lfs f27,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// lfs f24,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f25,f28,f13
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f24,f24,f13
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// fsubs f16,f28,f16
	ctx.f16.f64 = double(float(ctx.f28.f64 - ctx.f16.f64));
	// lfs f28,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// lfs f15,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f27,f27,f0
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmsubs f25,f15,f12,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f25.f64));
	// lfs f15,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f24,f15,f12,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f24.f64));
	// stfs f24,232(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f15,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f15.f64 = double(temp.f32);
	// lfs f24,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f15.f64));
	// lfs f15,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f23,f15,f12,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f23.f64));
	// stfs f23,412(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// lfs f15,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f15.f64 = double(temp.f32);
	// lfs f23,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f15.f64));
	// lfs f23,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f23,f13,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f20.f64));
	// fmuls f20,f16,f0
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f20,468(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// lfs f20,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f20,f20,f16,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f16.f64 + ctx.f15.f64));
	// stfsx f20,r30,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f15,f28,f27
	ctx.f15.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// lfs f20,472(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 472);
	ctx.f20.f64 = double(temp.f32);
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// lfs f16,476(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 476);
	ctx.f16.f64 = double(temp.f32);
	// lfs f27,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// stfs f27,452(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// lfs f27,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f25.f64));
	// lfs f25,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// stfs f25,460(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// lfs f25,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// stfs f25,232(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f25,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// lfs f23,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f23.f64 = double(temp.f32);
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fadds f23,f27,f28
	ctx.f23.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// stfs f28,152(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f27,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f27.f64 = double(temp.f32);
	// lfs f28,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f15,f28
	ctx.f28.f64 = double(float(ctx.f15.f64 - ctx.f28.f64));
	// stfs f28,28(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f28,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// lfs f27,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// stfs f27,160(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fadds f27,f24,f25
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfs f27,72(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f27,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f27.f64 = double(temp.f32);
	// lfs f15,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f15.f64 = double(temp.f32);
	// fadds f27,f27,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// fsubs f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// lfs f24,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f15,f16,f28
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// mulli r30,r6,240
	ctx.r30.s64 = ctx.r6.s64 * 240;
	// fmuls f16,f16,f24
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f24.f64));
	// fmsubs f24,f20,f24,f15
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f24.f64 - ctx.f15.f64));
	// stfsx f24,r30,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmadds f28,f20,f28,f16
	ctx.f28.f64 = double(float(ctx.f20.f64 * ctx.f28.f64 + ctx.f16.f64));
	// stfsx f28,r30,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f24,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f24.f64 = double(temp.f32);
	// mulli r30,r6,48
	ctx.r30.s64 = ctx.r6.s64 * 48;
	// lfs f20,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f24,f20
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f20.f64));
	// lfs f28,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f15,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f23,f28,f23,f16
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f23.f64 - ctx.f16.f64));
	// stfsx f23,r30,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmadds f28,f28,f20,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f20.f64 + ctx.f24.f64));
	// stfsx f28,r30,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f24,220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f24.f64 = double(temp.f32);
	// mulli r30,r6,112
	ctx.r30.s64 = ctx.r6.s64 * 112;
	// fmuls f20,f24,f27
	ctx.f20.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// lfs f23,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f28,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f28.f64 = double(temp.f32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f23,f28,f23,f20
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f23.f64 - ctx.f20.f64));
	// lfs f20,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f28,f28,f27,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f27.f64 + ctx.f24.f64));
	// stfsx f23,r30,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f24,f15,f20
	ctx.f24.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// lfs f23,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// lfs f15,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// stfsx f28,r30,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f15.f64 = double(temp.f32);
	// mulli r30,r6,176
	ctx.r30.s64 = ctx.r6.s64 * 176;
	// lfs f16,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,140(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f16,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,72(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f27,348(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 348);
	ctx.f27.f64 = double(temp.f32);
	// stfs f16,36(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fmuls f15,f27,f25
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// lfs f16,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f27,f27,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f16.f64));
	// lfs f28,344(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 344);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f16,f28,f16,f15
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f16.f64 - ctx.f15.f64));
	// stfsx f16,r30,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f16,f23,f24
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fmadds f28,f28,f25,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f25.f64 + ctx.f27.f64));
	// stfsx f28,r30,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f23,f23,f24
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// lfs f28,312(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 312);
	ctx.f28.f64 = double(temp.f32);
	// lfs f27,316(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 316);
	ctx.f27.f64 = double(temp.f32);
	// lfs f25,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f25.f64 = double(temp.f32);
	// fadds f15,f25,f20
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// fsubs f25,f20,f25
	ctx.f25.f64 = double(float(ctx.f20.f64 - ctx.f25.f64));
	// stfs f25,20(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f24,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f24.f64 = double(temp.f32);
	// fmr f25,f24
	ctx.f25.f64 = ctx.f24.f64;
	// lfs f24,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f25
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfs f24,76(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f24,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfs f25,208(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f24,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// lfs f25,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f20,f15,f0
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fadds f24,f24,f25
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfs f24,112(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f24,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// fmuls f24,f16,f0
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f24
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f24.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f15,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f15,f25,f16
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// stfs f15,140(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f16.f64));
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fadds f24,f15,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 + ctx.f24.f64));
	// lfs f15,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f27,f16
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f16.f64));
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f27,f27,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f16.f64));
	// fmsubs f16,f28,f16,f15
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f16.f64 - ctx.f15.f64));
	// stfsx f16,r5,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f28,f28,f16,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f16.f64 + ctx.f27.f64));
	// stfsx f28,r5,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f27,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f27.f64 = double(temp.f32);
	// lfs f16,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f27,f16
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f16.f64));
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f27,f27,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f16.f64));
	// lfs f28,184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f16,f28,f16,f15
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f16.f64 - ctx.f15.f64));
	// stfsx f16,r10,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f16,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f28,f28,f16,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f16.f64 + ctx.f27.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f27,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f16,f27,f24
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f24.f64));
	// lfs f28,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f27,f27,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f20,f28,f20,f16
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f20.f64 - ctx.f16.f64));
	// stfsx f20,r8,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fmadds f28,f28,f24,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f24.f64 + ctx.f27.f64));
	// stfsx f28,r8,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f27,444(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 444);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f27,f25
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// lfs f28,440(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 440);
	ctx.f28.f64 = double(temp.f32);
	// lfs f20,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f27,f27,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// lfs f16,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f24,f28,f23,f24
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f23.f64 - ctx.f24.f64));
	// stfsx f24,r9,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f24,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f28,f28,f25,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f25.f64 + ctx.f27.f64));
	// fadds f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// lfs f20,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// lfs f16,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,36(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f16,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfsx f28,r9,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmuls f23,f20,f11
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// lfs f28,424(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 424);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f27,f20,f10
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// stfs f28,72(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// mulli r10,r6,216
	ctx.r10.s64 = ctx.r6.s64 * 216;
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f10
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f10.f64));
	// lfs f25,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f20,f28,f11
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// lfs f28,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// fmsubs f27,f24,f11,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f11.f64 - ctx.f27.f64));
	// fmadds f24,f24,f10,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f23.f64));
	// lfs f23,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f29
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// fsubs f25,f28,f25
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// stfs f25,76(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f25,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f25.f64 = double(temp.f32);
	// fadds f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// lfs f25,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f29
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// fadds f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// fsubs f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f16.f64));
	// lfs f16,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f30.f64));
	// fmadds f20,f16,f10,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f20.f64));
	// fmsubs f16,f16,f11,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 - ctx.f15.f64));
	// fsubs f15,f27,f20
	ctx.f15.f64 = double(float(ctx.f27.f64 - ctx.f20.f64));
	// fadds f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// fsubs f20,f16,f24
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f24.f64));
	// fadds f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f16,f27,f23
	ctx.f16.f64 = double(float(ctx.f27.f64 + ctx.f23.f64));
	// stfs f16,160(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fsubs f16,f25,f20
	ctx.f16.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f16,f24,f28
	ctx.f16.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// stfs f16,152(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// stfs f27,208(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// lfs f27,428(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 428);
	ctx.f27.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fadds f25,f20,f25
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// lfs f24,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f20,f27,f24
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f24.f64));
	// lfs f23,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f27,f23
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// lfs f27,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f24,f27,f24,f15
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f24.f64 - ctx.f15.f64));
	// stfsx f24,r10,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f27,f27,f23,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f23.f64 + ctx.f20.f64));
	// stfsx f27,r10,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f24,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f24.f64 = double(temp.f32);
	// lwz r10,484(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	// lfs f23,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f24,f23
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// fmuls f24,f24,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f20.f64));
	// lfs f27,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f20,f27,f20,f15
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 - ctx.f15.f64));
	// stfsx f20,r10,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f27,f27,f23,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f23.f64 + ctx.f24.f64));
	// stfsx f27,r10,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f24,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f24.f64 = double(temp.f32);
	// lwz r10,528(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	// fmuls f23,f24,f25
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// lfs f27,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f16.f64));
	// fmsubs f23,f27,f16,f23
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f16.f64 - ctx.f23.f64));
	// stfsx f23,r10,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f27,f27,f25,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f25.f64 + ctx.f24.f64));
	// stfsx f27,r10,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f27,296(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 296);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,352(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfs f27,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f27.f64 = double(temp.f32);
	// lfs f25,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f25.f64 = double(temp.f32);
	// lfs f23,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// lfs f24,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f24.f64 = double(temp.f32);
	// lwz r10,512(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f20,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// lfs f16,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f16.f64 = double(temp.f32);
	// lfs f20,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// lfs f16,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f19,f16
	ctx.f16.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,36(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f16,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f17,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f16,112(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f27,72(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f25,300(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 300);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f16.f64 = double(temp.f32);
	// stfs f25,28(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,76(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fmuls f16,f27,f11
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// stfs f24,160(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fmuls f24,f24,f11
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// stfs f23,152(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmuls f23,f23,f11
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// lfs f27,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f25,f27
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// stfs f20,360(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// fmuls f20,f20,f11
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// lfs f25,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f25.f64 = double(temp.f32);
	// lfs f27,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f25.f64));
	// stfs f27,344(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// lfs f25,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f25,f25,f10,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 - ctx.f24.f64));
	// lfs f24,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f24.f64 = double(temp.f32);
	// lfs f27,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f27.f64 = double(temp.f32);
	// stfs f25,28(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f27,f27,f28
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// lfs f25,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f25.f64 = double(temp.f32);
	// stfs f27,20(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f27,f25,f24
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// lfs f25,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f25,f25,f10,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 + ctx.f16.f64));
	// stfs f25,140(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f25,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f19,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 - ctx.f25.f64));
	// lfs f24,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// lfs f24,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f24,f10,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f20.f64));
	// stfs f24,36(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f24,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f24.f64 = double(temp.f32);
	// lfs f20,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// lfs f20,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f23,f20,f10,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 - ctx.f23.f64));
	// lfs f20,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f28,f20,f28,f15
	ctx.f28.f64 = double(float(ctx.f20.f64 * ctx.f28.f64 - ctx.f15.f64));
	// stfsx f28,r10,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f28.f64 = double(temp.f32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f28,f20,f28,f16
	ctx.f28.f64 = double(float(ctx.f20.f64 * ctx.f28.f64 + ctx.f16.f64));
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,328(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 328);
	ctx.f28.f64 = double(temp.f32);
	// lfs f20,332(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 332);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,76(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// lwz r10,492(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f23,140(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f23,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f23.f64 = double(temp.f32);
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f15,112(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f27,f15
	ctx.f15.f64 = double(float(ctx.f27.f64 - ctx.f15.f64));
	// stfs f15,208(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// fadds f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 + ctx.f27.f64));
	// stfs f27,36(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f27,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f27.f64));
	// lfs f15,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f15.f64));
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f20,f28,f15,f20
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f15.f64 - ctx.f20.f64));
	// stfsx f20,r15,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// lfs f20,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f28,f28,f20,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f20.f64 + ctx.f27.f64));
	// stfsx f28,r15,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// fadds f20,f16,f24
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// lfs f27,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f27.f64 = double(temp.f32);
	// lfs f28,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f27,f20
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// lfs f20,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f25
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// fmuls f27,f27,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// stfs f27,20(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f27,f16,f24
	ctx.f27.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// fmsubs f20,f28,f20,f15
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f20.f64 - ctx.f15.f64));
	// stfsx f20,r10,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f20,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f28,f28,f27,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f27.f64 + ctx.f15.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f27,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f27,f20
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// lfs f28,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f28.f64 = double(temp.f32);
	// lfs f15,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f20,f28,f23,f20
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f23.f64 - ctx.f20.f64));
	// stfsx f20,r18,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// lfs f20,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f23,f27,f23
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,76(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// lfs f20,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,112(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f15,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f15.f64 = double(temp.f32);
	// lfs f20,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,20(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f15.f64 = double(temp.f32);
	// lfs f20,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f19,376(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// lfs f15,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// lfs f15,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f15.f64 = double(temp.f32);
	// lfs f27,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f27.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// fsubs f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// stfs f17,300(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fsubs f25,f24,f16
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// lfs f17,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f15.f64 = double(temp.f32);
	// lfs f24,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f24.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// fmadds f28,f28,f24,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f24.f64 + ctx.f23.f64));
	// stfsx f28,r18,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,232
	ctx.r10.s64 = ctx.r6.s64 * 232;
	// lfs f28,456(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 456);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,28(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f28,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f24,f28,f8
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// lfs f28,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f23,f28,f8
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f28,f9
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f9.f64));
	// fmuls f15,f28,f8
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// lfs f28,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f19,f28
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// stfs f28,268(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f28,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// lfs f19,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f24,f19,f9,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f9.f64 - ctx.f24.f64));
	// lfs f19,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f19,384(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// lfs f19,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f23,f19,f9,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f9.f64 + ctx.f23.f64));
	// fmadds f19,f20,f8,f16
	ctx.f19.f64 = double(float(ctx.f20.f64 * ctx.f8.f64 + ctx.f16.f64));
	// lfs f16,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,300(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f17,460(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 460);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f20,f20,f9,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 - ctx.f15.f64));
	// fmuls f16,f17,f25
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// fmuls f15,f17,f27
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f27.f64));
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f27,f17,f27,f16
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f27.f64 - ctx.f16.f64));
	// stfsx f27,r10,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f27,f17,f25,f15
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f25.f64 + ctx.f15.f64));
	// stfsx f27,r10,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f17,f19,f24
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// lfs f25,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// lfs f27,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f27.f64 = double(temp.f32);
	// fadds f19,f20,f23
	ctx.f19.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// fsubs f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// lfs f20,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fsubs f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f15,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f19,268(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f16,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f24,f16
	ctx.f16.f64 = double(float(ctx.f24.f64 + ctx.f16.f64));
	// fmuls f15,f25,f20
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f20.f64));
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f25,f25,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// fmsubs f25,f27,f20,f25
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 - ctx.f25.f64));
	// stfsx f25,r21,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fadds f20,f23,f28
	ctx.f20.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// fmadds f27,f27,f19,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f19.f64 + ctx.f15.f64));
	// stfsx f27,r21,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// lfs f25,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f19,f25,f16
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f16.f64));
	// lfs f27,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f27.f64 = double(temp.f32);
	// lfs f15,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f20.f64));
	// fmsubs f20,f27,f20,f19
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 - ctx.f19.f64));
	// lfs f19,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f20,r24,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// lfs f20,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f27,f27,f16,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f16.f64 + ctx.f25.f64));
	// lfs f16,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f16.f64 = double(temp.f32);
	// lfs f25,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// lfs f16,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// stfsx f27,r24,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f27,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f27.f64 = double(temp.f32);
	// lfs f20,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// lwz r10,508(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	// fsubs f30,f30,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// lfs f15,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f26,f26,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f15.f64));
	// stfs f26,444(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// lfs f15,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f15.f64 = double(temp.f32);
	// lfs f26,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f15.f64));
	// lfs f15,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f29,f29,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f15.f64));
	// stfs f29,380(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// lfs f15,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f15.f64 = double(temp.f32);
	// lfs f29,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f29,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f15.f64));
	// stfs f29,20(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f29,f28,f23
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// stfs f29,152(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmuls f28,f19,f9
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f9.f64));
	// lfs f29,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f24.f64));
	// stfs f29,160(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f29,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f24,f25,f9
	ctx.f24.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// fmuls f15,f20,f29
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f29.f64));
	// fmuls f29,f20,f17
	ctx.f29.f64 = double(float(ctx.f20.f64 * ctx.f17.f64));
	// stfs f29,28(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f23,f16,f8
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f8.f64));
	// fmuls f16,f16,f9
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// fmsubs f28,f25,f8,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f8.f64 - ctx.f28.f64));
	// stfs f28,72(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fmadds f25,f19,f8,f24
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f8.f64 + ctx.f24.f64));
	// lfs f20,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f20.f64 = double(temp.f32);
	// lfs f24,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f29,f20,f26
	ctx.f29.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// fadds f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// fmadds f24,f30,f9,f23
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 + ctx.f23.f64));
	// fmsubs f30,f30,f8,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 - ctx.f16.f64));
	// lfs f28,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f23,f27,f17,f15
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f19,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f23,r26,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f28,f28,f20
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f20.f64));
	// lfs f23,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f23.f64 = double(temp.f32);
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f27,f27,f23,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f23.f64 + ctx.f16.f64));
	// stfsx f27,r26,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,396(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 396);
	ctx.f23.f64 = double(temp.f32);
	// lfs f16,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f23,f16
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// lfs f27,392(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 392);
	ctx.f27.f64 = double(temp.f32);
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f19,f17,f24
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f24.f64));
	// fadds f24,f24,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f17.f64));
	// fsubs f17,f30,f25
	ctx.f17.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// fadds f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// lfs f25,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f23,f25
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f25.f64));
	// fmsubs f25,f27,f25,f15
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f25.f64 - ctx.f15.f64));
	// stfsx f25,r19,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// fmadds f27,f27,f16,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f16.f64 + ctx.f23.f64));
	// stfsx f27,r19,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// fsubs f23,f29,f19
	ctx.f23.f64 = double(float(ctx.f29.f64 - ctx.f19.f64));
	// lfs f25,492(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 492);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f16,f28,f17
	ctx.f16.f64 = double(float(ctx.f28.f64 - ctx.f17.f64));
	// lfs f27,488(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 488);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f25,f23
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f23.f64));
	// fmuls f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f16.f64));
	// fmsubs f25,f27,f23,f25
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f23.f64 - ctx.f25.f64));
	// stfsx f25,r10,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f23,f24,f20
	ctx.f23.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// fmadds f27,f27,f16,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f16.f64 + ctx.f15.f64));
	// stfsx f27,r10,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f25,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f25.f64 = double(temp.f32);
	// fadds f16,f30,f26
	ctx.f16.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// lfs f27,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f27.f64 = double(temp.f32);
	// mulli r10,r6,56
	ctx.r10.s64 = ctx.r6.s64 * 56;
	// fmuls f15,f25,f23
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f23.f64));
	// fmsubs f15,f27,f16,f15
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f16.f64 - ctx.f15.f64));
	// fmuls f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f16.f64));
	// stfsx f15,r10,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f29,f19,f29
	ctx.f29.f64 = double(float(ctx.f19.f64 + ctx.f29.f64));
	// lfs f19,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f19.f64 = double(temp.f32);
	// fadds f28,f17,f28
	ctx.f28.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// lfs f17,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fsubs f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f30.f64));
	// lfs f26,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// lfs f20,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f27,f27,f23,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f23.f64 + ctx.f25.f64));
	// lfs f23,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f23,f11
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// lfs f23,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f23,f11
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// stfsx f27,r10,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f23,f23,f10,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 - ctx.f19.f64));
	// lfs f19,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f26,f26,f10,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f10.f64 + ctx.f17.f64));
	// lfs f17,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// lfs f19,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfs f17,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f17.f64 = double(temp.f32);
	// lfs f25,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f25.f64 = double(temp.f32);
	// lwz r10,548(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	// lfs f27,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f17,f17,f10,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 - ctx.f16.f64));
	// stfs f17,104(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f16,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,388(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// lfs f16,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f10,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f15.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,396(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,436(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// lfs f15,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,284(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f15,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,440(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fmuls f16,f25,f28
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f28.f64));
	// fmuls f15,f25,f29
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f29.f64));
	// fsubs f25,f23,f26
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// fadds f26,f26,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f23.f64));
	// fmsubs f29,f27,f29,f16
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f29.f64 - ctx.f16.f64));
	// stfsx f29,r10,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmuls f29,f19,f6
	ctx.f29.f64 = double(float(ctx.f19.f64 * ctx.f6.f64));
	// stfs f29,52(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fmadds f28,f27,f28,f15
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f28.f64 + ctx.f15.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f29,360(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 360);
	ctx.f29.f64 = double(temp.f32);
	// lfs f27,364(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 364);
	ctx.f27.f64 = double(temp.f32);
	// lfs f23,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f23.f64 = double(temp.f32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f28,f23,f16
	ctx.f28.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// fadds f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// stfs f23,404(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// lfs f23,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f20,f6
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// fmuls f15,f23,f6
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// lfs f23,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f20,f7,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 - ctx.f23.f64));
	// fmadds f20,f19,f7,f16
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 + ctx.f16.f64));
	// lfs f16,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f19,f17,f7,f15
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f15.f64));
	// lfs f15,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f25,f16
	ctx.f16.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// fsubs f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f26.f64));
	// stfs f15,432(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// lfs f15,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f15.f64 = double(temp.f32);
	// lwz r10,496(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	// fsubs f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// stfs f25,20(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f25,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f17,f6
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// stfs f26,28(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f26,f27,f24
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f24.f64));
	// lfs f15,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f25,f27,f30
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// lfs f27,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f28,f27
	ctx.f27.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// stfs f27,104(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f27,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// lfs f15,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f28,f15,f28
	ctx.f28.f64 = double(float(ctx.f15.f64 - ctx.f28.f64));
	// stfs f28,284(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f15,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f15.f64 = double(temp.f32);
	// lfs f28,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// lfs f15,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f30,f29,f30,f26
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f30.f64 - ctx.f26.f64));
	// stfsx f30,r10,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f29,f24,f25
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f24.f64 + ctx.f25.f64));
	// lfs f25,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// lfs f24,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// lfs f24,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f15,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 + ctx.f24.f64));
	// stfs f24,52(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// lfs f24,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f15,f19,f23
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f15,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// fmsubs f17,f15,f7,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f7.f64 - ctx.f17.f64));
	// stfs f17,256(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// stfs f23,348(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// lfs f29,356(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 356);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f19,f25,f5
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f5.f64));
	// lfs f30,352(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 352);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f23,f25,f4
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// fmsubs f23,f26,f5,f23
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f5.f64 - ctx.f23.f64));
	// fmadds f26,f26,f4,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f4.f64 + ctx.f19.f64));
	// lfs f25,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f25,f5
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f5.f64));
	// fmuls f15,f25,f4
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// lfs f25,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f16,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 - ctx.f25.f64));
	// stfs f25,332(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f25,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// stfs f25,52(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f25,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// lfs f16,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// fmadds f19,f24,f4,f17
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f17.f64));
	// lfs f17,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f24,f24,f5,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 - ctx.f15.f64));
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f15,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f23,f19
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// fadds f23,f19,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// fmuls f15,f29,f15
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f15.f64));
	// fsubs f19,f24,f26
	ctx.f19.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// fadds f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfs f24,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f24.f64));
	// stfs f29,52(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f24,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// stfs f24,104(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f24,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f24.f64 = double(temp.f32);
	// fadds f29,f16,f24
	ctx.f29.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// fsubs f24,f27,f19
	ctx.f24.f64 = double(float(ctx.f27.f64 - ctx.f19.f64));
	// fadds f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 + ctx.f27.f64));
	// lfs f19,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f19.f64 = double(temp.f32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f19,f30,f19,f16
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f19.f64 - ctx.f16.f64));
	// stfsx f19,r20,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// lfs f19,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f30,f30,f19,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f19.f64 + ctx.f15.f64));
	// stfsx f30,r20,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// lfs f19,420(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 420);
	ctx.f19.f64 = double(temp.f32);
	// lfs f16,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f19,f16
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfs f30,416(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 416);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f19,f19,f24
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f24.f64));
	// fmsubs f24,f30,f24,f15
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f24.f64 - ctx.f15.f64));
	// stfsx f24,r16,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f30,f16,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f16.f64 + ctx.f19.f64));
	// stfsx f30,r16,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// lfs f24,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f19,f24,f29
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f29.f64));
	// lfs f30,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f27,f30,f27,f19
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f27.f64 - ctx.f19.f64));
	// stfsx f27,r17,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f30,f29,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 + ctx.f24.f64));
	// stfsx f30,r17,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// lfs f29,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f24,f16,f26
	ctx.f24.f64 = double(float(ctx.f16.f64 - ctx.f26.f64));
	// fmuls f27,f29,f17
	ctx.f27.f64 = double(float(ctx.f29.f64 * ctx.f17.f64));
	// lfs f30,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f29,f25
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f25.f64));
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f29,f19,f20
	ctx.f29.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// lfs f19,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f19.f64 = double(temp.f32);
	// fadds f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f16.f64));
	// fmsubs f27,f30,f25,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f25.f64 - ctx.f27.f64));
	// stfsx f27,r23,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f30,f17,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f17.f64 + ctx.f15.f64));
	// lfs f17,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f17,f11
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// lfs f25,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f25.f64 = double(temp.f32);
	// lfs f27,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f27.f64 = double(temp.f32);
	// lfs f17,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfs f19,104(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f25,f28,f23
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// lfs f19,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f19.f64 = double(temp.f32);
	// fadds f28,f23,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// lfs f23,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f23,f10
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// lfs f17,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f19,52(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f19,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f19.f64 = double(temp.f32);
	// fadds f17,f17,f19
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f17,100(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f17,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfs f17,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f30,r23,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,484(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	ctx.f23.f64 = double(temp.f32);
	// lfs f30,480(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f17,f17,f11,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 - ctx.f16.f64));
	// lfs f16,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// lfs f16,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f10,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f15.f64));
	// fmuls f15,f23,f27
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f27.f64));
	// fmuls f23,f23,f29
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f29.f64));
	// fmsubs f29,f30,f29,f15
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 - ctx.f15.f64));
	// stfsx f29,r22,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fsubs f29,f17,f16
	ctx.f29.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lwz r10,544(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	// fmadds f30,f30,f27,f23
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f27.f64 + ctx.f23.f64));
	// stfsx f30,r22,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// fadds f27,f16,f17
	ctx.f27.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// lfs f23,292(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 292);
	ctx.f23.f64 = double(temp.f32);
	// lfs f30,288(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 288);
	ctx.f30.f64 = double(temp.f32);
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f29,f16
	ctx.f17.f64 = double(float(ctx.f29.f64 + ctx.f16.f64));
	// fsubs f29,f16,f29
	ctx.f29.f64 = double(float(ctx.f16.f64 - ctx.f29.f64));
	// fmuls f16,f23,f24
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f24.f64));
	// fmuls f23,f23,f25
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f25.f64));
	// fsubs f15,f15,f27
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// stfs f15,472(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// fadds f27,f27,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// lfs f15,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f11
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// fmsubs f25,f30,f25,f16
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f25.f64 - ctx.f16.f64));
	// stfsx f25,r14,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f30,f24,f23
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f24.f64 + ctx.f23.f64));
	// stfsx f30,r14,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// lfs f25,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f25,f26
	ctx.f24.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// lfs f30,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f25,f25,f28
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f28.f64));
	// lfs f23,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f23.f64 = double(temp.f32);
	// lfs f16,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f28,f30,f28,f24
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f28.f64 - ctx.f24.f64));
	// stfsx f28,r10,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f30,f26,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f26.f64 + ctx.f25.f64));
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f28.f64 = double(temp.f32);
	// lfs f26,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f28,f26
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f26.f64));
	// lfs f24,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f28,f28,f20
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f20.f64));
	// lfs f30,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f23,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// lfs f16,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f10
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// fmsubs f25,f30,f20,f25
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f20.f64 - ctx.f25.f64));
	// lfs f20,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f30,f30,f26,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f26.f64 + ctx.f28.f64));
	// stfsx f25,r25,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// stfsx f30,r25,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// fsubs f30,f20,f14
	ctx.f30.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// fadds f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f20,20(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// lfs f14,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f14,f11,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 - ctx.f16.f64));
	// lfs f25,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f26.f64 = double(temp.f32);
	// stfs f16,52(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// lfs f14,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,316(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f14,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f14,f10,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 + ctx.f15.f64));
	// stfs f15,104(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f28,336(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 336);
	ctx.f28.f64 = double(temp.f32);
	// lfs f25,340(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 340);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f15,f26,f5
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fmuls f14,f26,f4
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// fmuls f26,f24,f4
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f4.f64));
	// stfs f26,168(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fmuls f24,f24,f5
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// fmsubs f26,f30,f4,f15
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f4.f64 - ctx.f15.f64));
	// lfs f15,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f24,f23,f4,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 - ctx.f24.f64));
	// fmadds f15,f23,f5,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f15.f64));
	// stfs f24,308(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f24,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f30,f30,f5,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f5.f64 + ctx.f14.f64));
	// lfs f23,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f23.f64 = double(temp.f32);
	// lwz r10,368(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	// fsubs f14,f24,f23
	ctx.f14.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f24,292(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fmuls f24,f20,f7
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// lfs f23,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f23.f64 = double(temp.f32);
	// stfs f24,168(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fmuls f23,f23,f6
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// stfs f23,52(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fmuls f15,f20,f6
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// stfs f14,272(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f14,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f7
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f7.f64));
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f24,f20,f7,f15
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f15.f64));
	// fmsubs f23,f16,f6,f14
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 - ctx.f14.f64));
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f20,f20,f6,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 - ctx.f15.f64));
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f16,f16,f7,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f7.f64 + ctx.f15.f64));
	// fadds f15,f14,f26
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f26.f64));
	// fsubs f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// lfs f14,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f30
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f30.f64));
	// stfs f14,316(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f14,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f14,252(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f14,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f14,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f30,f14,f30
	ctx.f30.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// lfs f14,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f14,308(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f14,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// fsubs f14,f23,f24
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f23,f20,f16
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f20,292(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fsubs f20,f17,f15
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f20,272(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f20,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// stfs f20,168(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f16,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f25,f16
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f16.f64));
	// fmuls f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f20.f64));
	// lfs f20,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f25,f28,f20,f25
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f20.f64 - ctx.f25.f64));
	// lfs f20,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f23
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// stfsx f25,r10,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfs f20,52(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f25,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f28,f28,f25,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f25.f64 + ctx.f16.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f25,404(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 404);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f16,f25,f20
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f20.f64));
	// lfs f20,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// stfs f20,168(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f28,400(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 400);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f20.f64));
	// lfs f20,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f20.f64 = double(temp.f32);
	// stfs f25,104(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fadds f25,f14,f20
	ctx.f25.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// lfs f20,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f20.f64 = double(temp.f32);
	// fadds f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// fadds f20,f15,f17
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f15,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f17.f64 = double(temp.f32);
	// mulli r10,r6,204
	ctx.r10.s64 = ctx.r6.s64 * 204;
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f29,f30
	ctx.f15.f64 = double(float(ctx.f29.f64 - ctx.f30.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f15,f19,f26
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f15.f64 = double(temp.f32);
	// fadds f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f29.f64));
	// fmsubs f16,f28,f15,f16
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f15.f64 - ctx.f16.f64));
	// stfsx f16,r10,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f15,f27,f24
	ctx.f15.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// stfs f15,168(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fadds f29,f26,f19
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// fmadds f28,f28,f15,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f15.f64 + ctx.f14.f64));
	// lfs f16,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f18,f16
	ctx.f16.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// lfs f15,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f15.f64 = double(temp.f32);
	// fadds f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// fmuls f26,f15,f23
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f23.f64));
	// lwz r10,364(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	// fmuls f24,f15,f25
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f25.f64));
	// lfs f28,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f28.f64 = double(temp.f32);
	// lfs f19,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f26,f28,f25,f26
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f25.f64 - ctx.f26.f64));
	// stfsx f26,r10,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f28,f28,f23,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f23.f64 + ctx.f24.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f26.f64 = double(temp.f32);
	// lwz r10,260(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// fmuls f25,f26,f17
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// lfs f28,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// fmsubs f25,f28,f20,f25
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f20.f64 - ctx.f25.f64));
	// stfsx f25,r10,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f28,f28,f17,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f17.f64 + ctx.f26.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,468(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 468);
	ctx.f26.f64 = double(temp.f32);
	// lwz r10,248(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	// lfs f28,464(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 464);
	ctx.f28.f64 = double(temp.f32);
	// lfs f25,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f26,f24
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// fmuls f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmsubs f25,f28,f25,f23
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f25.f64 - ctx.f23.f64));
	// stfsx f25,r10,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f28,f28,f24,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f24.f64 + ctx.f26.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,276(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 276);
	ctx.f26.f64 = double(temp.f32);
	// mulli r10,r6,140
	ctx.r10.s64 = ctx.r6.s64 * 140;
	// lfs f25,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f26,f25
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// lfs f28,272(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 272);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// fmsubs f24,f28,f16,f24
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f16.f64 - ctx.f24.f64));
	// stfsx f24,r10,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f28,f28,f25,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f25.f64 + ctx.f26.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f26.f64 = double(temp.f32);
	// mulli r10,r6,12
	ctx.r10.s64 = ctx.r6.s64 * 12;
	// fmuls f25,f26,f27
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// lfs f28,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f26,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f18.f64));
	// fmsubs f25,f28,f18,f25
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f18.f64 - ctx.f25.f64));
	// stfsx f25,r10,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f28,f28,f27,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f27.f64 + ctx.f26.f64));
	// lfs f18,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f18.f64 = double(temp.f32);
	// lfs f27,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f27.f64 = double(temp.f32);
	// lfs f25,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f27,f27,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f19.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f18,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 - ctx.f25.f64));
	// lfs f28,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f28.f64 = double(temp.f32);
	// lfs f26,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f26.f64 = double(temp.f32);
	// lfs f23,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f23.f64 = double(temp.f32);
	// lwz r10,108(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lfs f24,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// lfs f20,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f20,f8
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// lfs f20,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f20,f8
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// lfs f20,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f20,f8
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// lfs f20,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f14,f20,f8
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// fmsubs f20,f20,f9,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 - ctx.f17.f64));
	// lfs f17,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// lfs f17,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f17.f64 = double(temp.f32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f17,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f9,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 + ctx.f16.f64));
	// lfs f16,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f9,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f9.f64 - ctx.f15.f64));
	// stfs f16,540(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 540, temp.u32);
	// lfs f16,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f9,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f9.f64 + ctx.f14.f64));
	// stfs f16,532(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// lfs f16,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f16,f15
	ctx.f15.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f15,264(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f15,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,524(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// lfs f14,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,168(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fmuls f14,f26,f29
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// lfs f15,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f26,f26,f30
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// stfs f26,212(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,288(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,104(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,52(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fmuls f16,f25,f2
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// fmuls f25,f25,f3
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// fmuls f15,f24,f3
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// fmuls f24,f24,f2
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// fmsubs f30,f28,f30,f14
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f30.f64 - ctx.f14.f64));
	// stfsx f30,r10,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f26,f27,f3,f16
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f3.f64 - ctx.f16.f64));
	// fmadds f27,f27,f2,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f2.f64 + ctx.f25.f64));
	// fmadds f25,f23,f2,f15
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f15.f64));
	// fmuls f16,f18,f31
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f31.f64));
	// fmuls f15,f18,f1
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// fmsubs f24,f23,f3,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 - ctx.f24.f64));
	// fsubs f23,f20,f17
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f18,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f30,f18,f17
	ctx.f30.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f14,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f29,f28,f29,f14
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f29.f64 + ctx.f14.f64));
	// stfsx f29,r10,r4
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f29,f19,f1,f16
	ctx.f29.f64 = double(float(ctx.f19.f64 * ctx.f1.f64 - ctx.f16.f64));
	// lfs f16,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f28,f19,f31,f15
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f31.f64 + ctx.f15.f64));
	// fsubs f19,f26,f25
	ctx.f19.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f25,f24,f27
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// fadds f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// fsubs f24,f16,f23
	ctx.f24.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// lfs f14,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f16.f64));
	// lfs f15,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f14,f30
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// lwz r10,244(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// fadds f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// stfs f30,372(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f30,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f30.f64 = double(temp.f32);
	// fadds f17,f20,f15
	ctx.f17.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// fsubs f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// stfs f30,448(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// lfs f30,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// fmuls f14,f30,f1
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f1.f64));
	// lfs f15,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f30,f30,f31
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// stfs f30,212(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fadds f15,f18,f15
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// lfs f18,448(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 448);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,264(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fsubs f18,f24,f19
	ctx.f18.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// stfs f18,288(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fadds f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// fsubs f30,f16,f25
	ctx.f30.f64 = double(float(ctx.f16.f64 - ctx.f25.f64));
	// lfs f18,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f18.f64 = double(temp.f32);
	// fadds f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// fsubs f19,f23,f27
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// fmadds f16,f18,f31,f14
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f31.f64 + ctx.f14.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f18,f18,f1,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f1.f64 - ctx.f14.f64));
	// stfs f18,464(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// lfs f18,452(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 452);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f16,f18,f30
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// fmuls f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f29
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// stfs f18,212(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f29,f29,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// stfs f29,420(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// lfs f18,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f30,f18,f30,f14
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 + ctx.f14.f64));
	// lfs f14,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f14.f64 = double(temp.f32);
	// lfs f29,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// stfs f29,24(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f29,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f29,f18,f29,f16
	ctx.f29.f64 = double(float(ctx.f18.f64 * ctx.f29.f64 - ctx.f16.f64));
	// stfsx f29,r10,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f29,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f29.f64 = double(temp.f32);
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// lfs f28,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f28.f64 = double(temp.f32);
	// lwz r10,516(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// lfs f30,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f30.f64 = double(temp.f32);
	// lfs f16,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f16,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f14,212(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,264(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fmuls f14,f28,f18
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfs f15,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f15.f64));
	// fmsubs f15,f30,f15,f14
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f15.f64 - ctx.f14.f64));
	// stfsx f15,r10,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f30,f18,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f18.f64 + ctx.f28.f64));
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f28.f64 = double(temp.f32);
	// lfs f18,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f28,f17
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// lfs f30,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lwz r10,520(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	// fmsubs f18,f30,f18,f15
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f18.f64 - ctx.f15.f64));
	// fmadds f30,f30,f17,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f17.f64 + ctx.f28.f64));
	// fadds f27,f27,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f23.f64));
	// lfs f23,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f18,r10,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,192(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// lfs f28,196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 196);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f28,f25
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// lfs f30,192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 192);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f24.f64));
	// fmsubs f24,f30,f24,f18
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f24.f64 - ctx.f18.f64));
	// stfsx f24,r10,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f30,f25,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f25.f64 + ctx.f28.f64));
	// lfs f25,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f26
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,324(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 324);
	ctx.f28.f64 = double(temp.f32);
	// mulli r10,r6,164
	ctx.r10.s64 = ctx.r6.s64 * 164;
	// lfs f30,320(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 320);
	ctx.f30.f64 = double(temp.f32);
	// fadds f26,f26,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f23.f64));
	// fmuls f24,f28,f25
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fmsubs f24,f30,f19,f24
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f19.f64 - ctx.f24.f64));
	// stfsx f24,r10,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f30,f25,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f25.f64 + ctx.f28.f64));
	// lfs f19,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f28,f20,f29
	ctx.f28.f64 = double(float(ctx.f20.f64 - ctx.f29.f64));
	// lfs f24,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f24.f64 = double(temp.f32);
	// fadds f29,f29,f20
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f20.f64));
	// lfs f20,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f20,f9
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f9.f64));
	// lfs f20,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f20,f9
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f9.f64));
	// lfs f20,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f20.f64 = double(temp.f32);
	// fadds f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f19.f64));
	// lfs f19,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f20,f9
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f9.f64));
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmuls f14,f19,f9
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f9.f64));
	// lfs f25,388(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 388);
	ctx.f25.f64 = double(temp.f32);
	// lwz r10,64(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	// lfs f30,384(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 384);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f20,f20,f8,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64 - ctx.f18.f64));
	// lfs f18,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f23,f19,f8,f17
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f8.f64 - ctx.f17.f64));
	// lfs f19,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// lfs f17,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f17,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f8,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f8.f64 + ctx.f15.f64));
	// lfs f15,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f15,428(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// lfs f15,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f21,f15
	ctx.f15.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f15,f15,f8,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f8.f64 + ctx.f14.f64));
	// lfs f14,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// lfs f14,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// fmuls f14,f25,f28
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f28.f64));
	// fmuls f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f16.f64));
	// fmsubs f16,f30,f16,f14
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f16.f64 - ctx.f14.f64));
	// stfsx f16,r10,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmuls f16,f19,f3
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fmadds f30,f30,f28,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f28.f64 + ctx.f25.f64));
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f25,f23,f20
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// lfs f28,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// lfs f30,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f20,f17,f15
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// fmuls f15,f28,f29
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f29.f64));
	// fmsubs f16,f18,f2,f16
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f2.f64 - ctx.f16.f64));
	// fmuls f14,f28,f24
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f24.f64));
	// lfs f28,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// stfs f28,340(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// lfs f28,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f28.f64 = double(temp.f32);
	// lwz r10,188(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// fsubs f28,f28,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// stfs f28,328(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f28,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f24,f30,f24,f15
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f24.f64 - ctx.f15.f64));
	// fadds f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// lfs f25,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// lfs f15,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f15.f64 = double(temp.f32);
	// stfsx f24,r10,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f23,f21,f20
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fmuls f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// fadds f24,f17,f22
	ctx.f24.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fmadds f30,f30,f29,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 + ctx.f14.f64));
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f29,f20,f21
	ctx.f29.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// lfs f21,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f21,f26
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f26.f64));
	// lfs f30,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f21,f21,f27
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f27.f64));
	// lwz r10,40(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// lfs f17,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f27,f30,f27,f20
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f27.f64 - ctx.f20.f64));
	// lfs f20,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f20.f64 = double(temp.f32);
	// stfs f18,324(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fmadds f30,f30,f26,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f26.f64 + ctx.f21.f64));
	// stfsx f27,r10,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f18,f15,f17
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f30,f15,f17
	ctx.f30.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f15,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f26,f14,f20
	ctx.f26.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// lfs f17,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,456(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// lfs f15,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f18,476(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// stfs f17,212(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f27,432(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 432);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f14,f18,f1
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// lfs f21,436(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 436);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f20,f1
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f1.f64));
	// fmuls f17,f17,f1
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f1.f64));
	// fmsubs f20,f20,f31,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f31.f64 - ctx.f14.f64));
	// lfs f15,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f15.f64 = double(temp.f32);
	// stfs f18,324(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fmadds f19,f19,f2,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f2.f64 + ctx.f15.f64));
	// stfs f19,264(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fmuls f19,f26,f3
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// fmuls f15,f30,f3
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f3.f64));
	// fmadds f30,f30,f2,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f2.f64 + ctx.f19.f64));
	// lfs f19,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f19.f64 = double(temp.f32);
	// fmr f18,f19
	ctx.f18.f64 = ctx.f19.f64;
	// lfs f19,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f26,f26,f2,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 - ctx.f15.f64));
	// fmuls f15,f18,f1
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// fmsubs f18,f18,f31,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f31.f64 - ctx.f17.f64));
	// lfs f17,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f31,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f31.f64 + ctx.f15.f64));
	// fsubs f15,f16,f30
	ctx.f15.f64 = double(float(ctx.f16.f64 - ctx.f30.f64));
	// fadds f30,f30,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f16.f64));
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f19,f19,f31,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f31.f64 + ctx.f14.f64));
	// lfs f14,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f26,f14
	ctx.f16.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// fadds f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f14.f64));
	// fsubs f14,f20,f18
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// fadds f18,f17,f19
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfs f17,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,456(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// lfs f17,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f17.f64 = double(temp.f32);
	// lwz r10,556(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// lwz r9,652(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	// fsubs f14,f24,f18
	ctx.f14.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fadds f24,f18,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// stfs f24,476(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// lfs f24,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f15.f64));
	// stfs f24,324(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// stw r10,556(r1)
	PPC_STORE_U32(ctx.r1.u32 + 556, ctx.r10.u32);
	// lwz r10,320(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	// fmuls f18,f21,f24
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f24.f64));
	// fsubs f24,f23,f16
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// fmuls f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f24.f64));
	// lfs f21,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f24,f27,f21,f24
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f21.f64 - ctx.f24.f64));
	// stfsx f24,r7,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fsubs f24,f23,f16
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// lfs f21,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f21.f64 = double(temp.f32);
	// fadds f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// fsubs f16,f22,f20
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// fmadds f27,f27,f24,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f24.f64 + ctx.f18.f64));
	// stfsx f27,r7,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f24,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f18,f24,f21
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f21.f64));
	// lfs f27,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f14.f64));
	// fmsubs f18,f27,f14,f18
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f14.f64 - ctx.f18.f64));
	// stfsx f18,r31,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmadds f27,f27,f21,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f21.f64 + ctx.f24.f64));
	// stfsx f27,r31,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f24,500(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 500);
	ctx.f24.f64 = double(temp.f32);
	// lfs f21,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f24,f17
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f17.f64));
	// fmuls f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f21.f64));
	// lfs f27,496(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f21,f27,f21,f18
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f21.f64 - ctx.f18.f64));
	// stfsx f21,r28,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fmadds f27,f27,f17,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f17.f64 + ctx.f24.f64));
	// stfsx f27,r28,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f27,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f17,f29,f30
	ctx.f17.f64 = double(float(ctx.f29.f64 - ctx.f30.f64));
	// fadds f27,f27,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// lfs f21,180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 180);
	ctx.f21.f64 = double(temp.f32);
	// fadds f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f29.f64));
	// lfs f24,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f29,f21,f23
	ctx.f29.f64 = double(float(ctx.f21.f64 * ctx.f23.f64));
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fsubs f18,f28,f26
	ctx.f18.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// subf r4,r9,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r9.s64;
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fsubs f15,f25,f19
	ctx.f15.f64 = double(float(ctx.f25.f64 - ctx.f19.f64));
	// fadds f25,f19,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 + ctx.f25.f64));
	// fmuls f26,f21,f27
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f27.f64));
	// fmsubs f29,f24,f27,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 * ctx.f27.f64 - ctx.f29.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,660(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 660);
	// fmadds f29,f24,f23,f26
	ctx.f29.f64 = double(float(ctx.f24.f64 * ctx.f23.f64 + ctx.f26.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lfs f27,308(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 308);
	ctx.f27.f64 = double(temp.f32);
	// lwz r10,228(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	// fmuls f26,f27,f17
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f17.f64));
	// lfs f29,304(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 304);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f27,f27,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// fmsubs f26,f29,f18,f26
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f18.f64 - ctx.f26.f64));
	// stfs f26,0(r10)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,668(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	// fmadds f29,f29,f17,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f17.f64 + ctx.f27.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lfs f27,372(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 372);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f26,f27,f15
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f15.f64));
	// lfs f29,368(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 368);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f27,f27,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f16.f64));
	// fmsubs f26,f29,f16,f26
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f16.f64 - ctx.f26.f64));
	// stfs f26,0(r10)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,656(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	// fmadds f29,f29,f15,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f15.f64 + ctx.f27.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,32(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// lfs f27,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f26,f27,f25
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// lfs f29,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f27,f27,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f22.f64));
	// fmsubs f26,f29,f22,f26
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f22.f64 - ctx.f26.f64));
	// stfs f26,0(r10)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,664(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	// fmadds f29,f29,f25,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f25.f64 + ctx.f27.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,16(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// lfs f27,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f26,f27,f30
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// lfs f29,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f27,f27,f28
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// addi r11,r11,504
	ctx.r11.s64 = ctx.r11.s64 + 504;
	// fmsubs f28,f29,f28,f26
	ctx.f28.f64 = double(float(ctx.f29.f64 * ctx.f28.f64 - ctx.f26.f64));
	// stfs f28,0(r10)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,672(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	// fmadds f30,f29,f30,f27
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f30.f64 + ctx.f27.f64));
	// stfs f30,0(r10)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d33618
	if (!ctx.cr0.eq) goto loc_82D33618;
loc_82D36A6C:
	// addi r1,r1,976
	ctx.r1.s64 = ctx.r1.s64 + 976;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D36A78;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D36A80"))) PPC_WEAK_FUNC(sub_82D36A80);
PPC_FUNC_IMPL(__imp__sub_82D36A80) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-5496
	ctx.r5.s64 = ctx.r11.s64 + -5496;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,13672
	ctx.r4.s64 = ctx.r11.s64 + 13672;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D36A98"))) PPC_WEAK_FUNC(sub_82D36A98);
PPC_FUNC_IMPL(__imp__sub_82D36A98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D36AA0;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D36AA8;
	__savefpr_14(ctx, base);
	// mulli r11,r7,248
	ctx.r11.s64 = ctx.r7.s64 * 248;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-248
	ctx.r11.s64 = ctx.r11.s64 + -248;
	// bge cr6,0x82d37fe0
	if (!ctx.cr6.lt) goto loc_82D37FE0;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lis r9,-32236
	ctx.r9.s64 = -2112618496;
	// stw r10,-336(r1)
	PPC_STORE_U32(ctx.r1.u32 + -336, ctx.r10.u32);
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lfs f8,-8000(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8000);
	ctx.f8.f64 = double(temp.f32);
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lfs f9,-8004(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8004);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-8008(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -8008);
	ctx.f10.f64 = double(temp.f32);
	// lfs f13,136(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// stw r10,-356(r1)
	PPC_STORE_U32(ctx.r1.u32 + -356, ctx.r10.u32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f11,-8012(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -8012);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-8016(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -8016);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D36B04:
	// mulli r25,r6,108
	ctx.r25.s64 = ctx.r6.s64 * 108;
	// lfs f7,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// mulli r24,r6,76
	ctx.r24.s64 = ctx.r6.s64 * 76;
	// add r25,r25,r4
	ctx.r25.u64 = ctx.r25.u64 + ctx.r4.u64;
	// mulli r10,r6,80
	ctx.r10.s64 = ctx.r6.s64 * 80;
	// lfs f6,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// stw r25,-332(r1)
	PPC_STORE_U32(ctx.r1.u32 + -332, ctx.r25.u32);
	// lfsx f5,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f22,f5,f6
	ctx.f22.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// mulli r23,r6,44
	ctx.r23.s64 = ctx.r6.s64 * 44;
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// add r24,r24,r4
	ctx.r24.u64 = ctx.r24.u64 + ctx.r4.u64;
	// mulli r9,r6,112
	ctx.r9.s64 = ctx.r6.s64 * 112;
	// lfs f4,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// stw r24,-308(r1)
	PPC_STORE_U32(ctx.r1.u32 + -308, ctx.r24.u32);
	// lfsx f3,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f5,f3,f4
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// mulli r22,r6,12
	ctx.r22.s64 = ctx.r6.s64 * 12;
	// fsubs f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// add r23,r23,r4
	ctx.r23.u64 = ctx.r23.u64 + ctx.r4.u64;
	// rlwinm r8,r6,4,0,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// add r22,r22,r4
	ctx.r22.u64 = ctx.r22.u64 + ctx.r4.u64;
	// mulli r7,r6,48
	ctx.r7.s64 = ctx.r6.s64 * 48;
	// lfs f1,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// stw r23,-316(r1)
	PPC_STORE_U32(ctx.r1.u32 + -316, ctx.r23.u32);
	// lfsx f2,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f3,f2,f1
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// lfs f31,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f30,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fsubs f1,f31,f30
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// stw r22,-324(r1)
	PPC_STORE_U32(ctx.r1.u32 + -324, ctx.r22.u32);
	// mulli r5,r6,60
	ctx.r5.s64 = ctx.r6.s64 * 60;
	// fadds f31,f30,f31
	ctx.f31.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// lfsx f29,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f30,f29,f7
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// rlwinm r31,r6,5,0,26
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// fsubs f7,f7,f29
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// mulli r30,r6,28
	ctx.r30.s64 = ctx.r6.s64 * 28;
	// fadds f21,f1,f5
	ctx.f21.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fadds f20,f31,f2
	ctx.f20.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// fsubs f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// fsubs f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// fadds f1,f4,f6
	ctx.f1.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// lfsx f28,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// lfsx f27,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f29,f27,f28
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// mulli r29,r6,124
	ctx.r29.s64 = ctx.r6.s64 * 124;
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// lfsx f26,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// rlwinm r28,r6,6,0,25
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 6) & 0xFFFFFFC0;
	// mulli r27,r6,92
	ctx.r27.s64 = ctx.r6.s64 * 92;
	// fadds f31,f29,f30
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// lfsx f25,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f24,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f27,f26,f25
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// mulli r26,r6,96
	ctx.r26.s64 = ctx.r6.s64 * 96;
	// lfsx f23,r3,r26
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r26.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f25,f24,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// rlwinm r25,r6,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f23,f3,f22
	ctx.f23.f64 = double(float(ctx.f3.f64 + ctx.f22.f64));
	// mulli r24,r6,52
	ctx.r24.s64 = ctx.r6.s64 * 52;
	// fsubs f19,f26,f28
	ctx.f19.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fsubs f3,f3,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f22.f64));
	// fsubs f26,f27,f25
	ctx.f26.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// fsubs f18,f7,f24
	ctx.f18.f64 = double(float(ctx.f7.f64 - ctx.f24.f64));
	// fadds f7,f24,f7
	ctx.f7.f64 = double(float(ctx.f24.f64 + ctx.f7.f64));
	// fadds f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f25,f23,f21
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// fadds f24,f21,f23
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fadds f23,f20,f31
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f31.f64));
	// fsubs f31,f31,f20
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f20.f64));
	// fsubs f21,f26,f2
	ctx.f21.f64 = double(float(ctx.f26.f64 - ctx.f2.f64));
	// fadds f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f26.f64));
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmuls f24,f24,f0
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fadds f29,f5,f3
	ctx.f29.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// mulli r23,r6,40
	ctx.r23.s64 = ctx.r6.s64 * 40;
	// fsubs f26,f3,f5
	ctx.f26.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// mulli r22,r6,20
	ctx.r22.s64 = ctx.r6.s64 * 20;
	// fsubs f5,f27,f1
	ctx.f5.f64 = double(float(ctx.f27.f64 - ctx.f1.f64));
	// fadds f4,f1,f27
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// lfsx f27,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f3,f30,f6
	ctx.f3.f64 = double(float(ctx.f30.f64 - ctx.f6.f64));
	// fadds f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f30.f64));
	// fmuls f1,f29,f0
	ctx.f1.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// lfsx f29,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f30,f26,f0
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// lfsx f26,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f14,f27,f29
	ctx.f14.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// lfsx f22,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// fadds f27,f22,f26
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// mulli r17,r6,116
	ctx.r17.s64 = ctx.r6.s64 * 116;
	// fsubs f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// lfsx f22,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-496(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// mulli r16,r6,72
	ctx.r16.s64 = ctx.r6.s64 * 72;
	// lfsx f22,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-508(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// rlwinm r21,r6,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r20,r6,56
	ctx.r20.s64 = ctx.r6.s64 * 56;
	// lfsx f20,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f17,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r15,r6,84
	ctx.r15.s64 = ctx.r6.s64 * 84;
	// lfsx f22,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-484(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fadds f22,f17,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// mulli r14,r6,104
	ctx.r14.s64 = ctx.r6.s64 * 104;
	// stfs f22,-512(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// lfsx f22,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r14,r6,68
	ctx.r14.s64 = ctx.r6.s64 * 68;
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-480(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// mulli r19,r6,24
	ctx.r19.s64 = ctx.r6.s64 * 24;
	// lfsx f16,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r18,r6,36
	ctx.r18.s64 = ctx.r6.s64 * 36;
	// lfsx f15,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f17,-476(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// mulli r14,r6,120
	ctx.r14.s64 = ctx.r6.s64 * 120;
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,-392(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f17,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r6,100
	ctx.r14.s64 = ctx.r6.s64 * 100;
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-520(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// mulli r14,r6,88
	ctx.r14.s64 = ctx.r6.s64 * 88;
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-468(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f16,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,-436(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f15,-516(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f15,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,-484(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f22.f64 = double(temp.f32);
	// fadds f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// lfs f22,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,-508(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f22,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,-480(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f17,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f17,-496(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f17,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f17.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f22,-520(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fadds f22,f27,f14
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f14.f64));
	// fsubs f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 - ctx.f27.f64));
	// stfs f27,-416(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f27,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f27.f64 = double(temp.f32);
	// fadds f17,f15,f22
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f17,-380(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fsubs f17,f16,f26
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f26.f64));
	// stfs f17,-468(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// lfs f15,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f15.f64 = double(temp.f32);
	// stfs f22,-452(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fadds f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f16.f64));
	// lfs f22,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f22.f64 = double(temp.f32);
	// lfs f16,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f16.f64 = double(temp.f32);
	// fadds f22,f22,f29
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f29.f64));
	// fsubs f29,f29,f16
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f16.f64));
	// stfs f29,-484(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f16,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f16.f64 = double(temp.f32);
	// lfs f29,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f16
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f16.f64));
	// stfs f26,-372(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f17,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f20
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f17,-368(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f17,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f15,-392(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f15,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f15.f64 = double(temp.f32);
	// stfs f29,-520(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fsubs f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// lfs f29,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f29.f64 = double(temp.f32);
	// lfs f15,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f29
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f29.f64));
	// stfs f15,-508(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,-480(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f16.f64 = double(temp.f32);
	// stfs f29,-364(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfsx f29,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-500(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// stfs f16,-436(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfsx f29,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f16,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f29,-424(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// stfs f16,-440(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f29,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f16,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f27,f29,f12
	ctx.f27.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// stfs f16,-400(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fmuls f16,f29,f13
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// lfsx f29,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r14,r6,100
	ctx.r14.s64 = ctx.r6.s64 * 100;
	// stfs f29,-516(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// stfs f17,-376(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// stfs f20,-396(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// lfsx f29,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r14,r6,120
	ctx.r14.s64 = ctx.r6.s64 * 120;
	// stfs f29,-444(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-512(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// mulli r14,r6,68
	ctx.r14.s64 = ctx.r6.s64 * 68;
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-472(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f29,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f15,f29,f12
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// fmuls f14,f29,f13
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// lfsx f29,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-476(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfsx f29,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-528(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f29,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f29,f13
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// stfs f29,-468(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fmuls f26,f26,f13
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// stfs f26,-388(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fmsubs f29,f22,f13,f27
	ctx.f29.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f27.f64));
	// fmadds f27,f22,f12,f16
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f16.f64));
	// lfs f22,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f26,f22,f13,f15
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f15.f64));
	// lfs f16,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f22,f22,f12,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f14.f64));
	// stfs f22,-392(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f22,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f16,f22
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// stfs f16,-488(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f16,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f16.f64 = double(temp.f32);
	// fadds f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// stfs f22,-428(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f22,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f22.f64 = double(temp.f32);
	// lfs f16,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f22
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// stfs f16,-344(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f16,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f16.f64 = double(temp.f32);
	// fadds f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// stfs f22,-384(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f22,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f12,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 - ctx.f20.f64));
	// stfs f22,-352(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f22,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f12,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f17.f64));
	// stfs f22,-368(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f22,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f22,f22,f12,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f20.f64));
	// stfs f22,-372(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f20,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f12,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 - ctx.f20.f64));
	// stfs f22,-376(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f20,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f22.f64 = double(temp.f32);
	// fadds f17,f20,f22
	ctx.f17.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f17,-348(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// lfs f17,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f20.f64 = double(temp.f32);
	// stfs f22,-360(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fadds f22,f17,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fadds f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,-508(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f14,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-520(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f15,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,-516(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f14,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-512(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f15,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,-436(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f14,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-484(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fadds f15,f17,f22
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f15,-396(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,-388(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f15,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f15,-408(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f14,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// lfs f15,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,104
	ctx.r14.s64 = ctx.r6.s64 * 104;
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,-496(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f14,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfsx f14,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-516(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// stfs f15,-404(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f15,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// stfs f20,-416(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f20,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f14,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// stfs f14,-512(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-508(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-476(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfsx f14,r4,r26
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r26.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-520(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfsx f14,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-468(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-448(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-432(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// stfs f20,-424(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// stfs f22,-412(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfsx f20,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f22,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f16,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f20,f22
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// lfsx f17,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// fsubs f20,f17,f16
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f16,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,-480(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f16,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,-516(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f16,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,-504(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,-472(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f16,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,-492(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f15,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,-528(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f16,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,-500(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f15,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,-456(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f15,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// stfs f16,-520(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fadds f16,f14,f15
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,-476(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f14,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// stfs f14,-512(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f14,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,44
	ctx.r14.s64 = ctx.r6.s64 * 44;
	// fsubs f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// lfs f14,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,-508(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-468(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f17,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,-436(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f22,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f17,-480(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f17,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f20,f15
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfs f15,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,-476(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f22,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f22.f64 = double(temp.f32);
	// stfs f20,-508(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fsubs f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f15,-484(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fmuls f20,f14,f0
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,-512(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f22,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f22.f64 = double(temp.f32);
	// stw r14,-468(r1)
	PPC_STORE_U32(ctx.r1.u32 + -468, ctx.r14.u32);
	// lfs f15,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f15,-420(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f15,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,-444(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,-400(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fmuls f22,f17,f0
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f14,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-440(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f15,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f15,-340(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f15,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f20,f15
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f14,-328(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fsubs f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f20,-364(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f20,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f20.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f22,-388(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f22,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fsubs f20,f22,f17
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f20,-436(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,-416(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f22,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f22,f16
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f20,-396(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f22,-424(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f20,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// lfs f16,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f16.f64 = double(temp.f32);
	// lfs f20,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// mulli r14,r6,12
	ctx.r14.s64 = ctx.r6.s64 * 12;
	// lfs f17,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f17.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// lfs f15,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f15,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,-404(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f14,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-516(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfsx f14,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-492(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfsx f14,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stw r14,-496(r1)
	PPC_STORE_U32(ctx.r1.u32 + -496, ctx.r14.u32);
	// mulli r14,r6,76
	ctx.r14.s64 = ctx.r6.s64 * 76;
	// stfs f14,-504(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,-412(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// stfs f15,-408(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfsx f15,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,-508(r1)
	PPC_STORE_U32(ctx.r1.u32 + -508, ctx.r14.u32);
	// mulli r14,r6,108
	ctx.r14.s64 = ctx.r6.s64 * 108;
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-472(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,-524(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfsx f17,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lwz r14,-508(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	// lfs f14,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,-468(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	// stfs f14,-528(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f14,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,-496(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	// stfs f14,-500(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,-432(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f14,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-448(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f15,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,-456(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-500(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f15,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,-492(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f14,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f14,-504(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,-528(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f17,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,-432(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,-472(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f17,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,-496(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f17,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,-460(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,-456(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-528(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f14,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,-448(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f14,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,-520(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f22,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f16,f22
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// stfs f14,-500(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// fadds f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// stfs f22,-472(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fadds f22,f17,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f22,-504(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fsubs f22,f20,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f22,-432(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f22,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f20.f64 = double(temp.f32);
	// fadds f16,f20,f22
	ctx.f16.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// lfs f20,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f17,f20
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f17,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f22,-528(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// stfs f20,-460(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f17,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,-456(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f17,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f17.f64 = double(temp.f32);
	// fadds f22,f15,f17
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// fmuls f20,f16,f0
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f17,f14,f0
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f14,f0
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f15,-528(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,-492(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f14,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f14,-320(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f16,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fsubs f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f14,-312(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f14,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// lfs f14,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// lfs f14,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,-404(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f14,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,-464(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f16,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f16,f14
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f14,-412(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,-408(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f16,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f23
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,0(r3)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// lfs f14,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f4
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f4.f64));
	// stfs f14,-524(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// fadds f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f14,0(r4)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f14,120(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 120);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-528(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f14,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,124(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-524(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// stfs f15,-460(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fmuls f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f15.f64));
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f14,f16,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f16.f64 - ctx.f15.f64));
	// lfs f14,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfsx f15,r28,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f4,f4,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f14.f64));
	// stfs f4,-428(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// lfs f4,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f4,f4,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f14.f64));
	// stfs f4,-504(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// lfs f4,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f16,f4,f16
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f16.f64));
	// lfs f4,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f14,f4
	ctx.f4.f64 = double(float(ctx.f14.f64 + ctx.f4.f64));
	// stfs f4,-448(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f14,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f14.f64 = double(temp.f32);
	// lfs f4,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f4,f14,f4
	ctx.f4.f64 = double(float(ctx.f14.f64 - ctx.f4.f64));
	// stfs f4,-524(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// lfs f4,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f4,f4,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f14.f64));
	// stfs f4,-516(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f14,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f14.f64 = double(temp.f32);
	// lfs f4,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f14.f64));
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f31
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f31.f64));
	// stfs f14,-380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f5
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f5.f64));
	// stfs f14,-496(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f5,f5,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f14.f64));
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f31,f31,f14
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f14.f64));
	// stfs f31,-492(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f31,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f31.f64 = double(temp.f32);
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f31,f14,f31,f16
	ctx.f31.f64 = double(float(ctx.f14.f64 * ctx.f31.f64 + ctx.f16.f64));
	// stfsx f31,r28,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fsubs f16,f23,f15
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f16,-488(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// fadds f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// stfs f23,-460(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f31,184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	ctx.f31.f64 = double(temp.f32);
	// lfs f23,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f23.f64 = double(temp.f32);
	// lfs f16,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f23,f16
	ctx.f15.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// stfs f15,-452(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fadds f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// stfs f23,-428(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f23,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f23.f64 = double(temp.f32);
	// lfs f16,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f16,f23
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// fsubs f16,f16,f23
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// lfs f23,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f23.f64 = double(temp.f32);
	// fadds f14,f4,f23
	ctx.f14.f64 = double(float(ctx.f4.f64 + ctx.f23.f64));
	// fsubs f4,f23,f4
	ctx.f4.f64 = double(float(ctx.f23.f64 - ctx.f4.f64));
	// stfs f4,-524(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// fmuls f4,f15,f0
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f16,-528(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// fmuls f23,f14,f0
	ctx.f23.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f16,-504(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f16,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f16,f15
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// fmuls f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f14.f64));
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f31,f14,f16
	ctx.f16.f64 = double(float(ctx.f31.f64 * ctx.f14.f64 - ctx.f16.f64));
	// stfsx f16,r3,r26
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r3.u32 + ctx.r26.u32, temp.u32);
	// lfs f16,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f31,f31,f16,f15
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,-452(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// stfsx f31,r4,r26
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r4.u32 + ctx.r26.u32, temp.u32);
	// lfs f16,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// lfs f31,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f31.f64 = double(temp.f32);
	// lfs f15,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f5
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f5.f64));
	// stfs f15,-488(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f15,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f16,f15
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// lfs f15,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// fmsubs f15,f31,f15,f14
	ctx.f15.f64 = double(float(ctx.f31.f64 * ctx.f15.f64 - ctx.f14.f64));
	// stfsx f15,r31,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f31,f31,f15,f16
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f15.f64 + ctx.f16.f64));
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f4
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f4.f64));
	// stfsx f31,r31,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f16,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f16.f64 = double(temp.f32);
	// lfs f31,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f14,f16,f15
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// lfs f15,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// fmuls f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// stfs f16,-524(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// fmsubs f15,f31,f15,f14
	ctx.f15.f64 = double(float(ctx.f31.f64 * ctx.f15.f64 - ctx.f14.f64));
	// stfsx f15,r10,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f15,f4
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f4.f64));
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f31,f31,f16,f14
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f16.f64 + ctx.f14.f64));
	// stfsx f31,r10,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f16,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f16,f15
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// lfs f15,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// lfs f31,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f31.f64 = double(temp.f32);
	// fmsubs f15,f31,f15,f14
	ctx.f15.f64 = double(float(ctx.f31.f64 * ctx.f15.f64 - ctx.f14.f64));
	// stfsx f15,r7,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f31,f31,f15,f16
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f15.f64 + ctx.f16.f64));
	// stfsx f31,r7,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f31,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f31.f64 = double(temp.f32);
	// fadds f31,f23,f31
	ctx.f31.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// stfs f31,-524(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f31,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f31.f64 = double(temp.f32);
	// stfs f31,-460(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f31,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f31.f64 = double(temp.f32);
	// fadds f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f31.f64));
	// stfs f4,-488(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f31,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f31.f64 = double(temp.f32);
	// lfs f4,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f31,f4
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// lfs f23,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f23.f64 = double(temp.f32);
	// lfs f31,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f31.f64 = double(temp.f32);
	// fadds f31,f31,f23
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f23.f64));
	// lfs f16,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f23,f22,f13
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f15,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// lfs f14,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// mulli r10,r6,104
	ctx.r10.s64 = ctx.r6.s64 * 104;
	// fmuls f14,f14,f13
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f31,f31,f0
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// stfs f31,-452(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f31,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f31.f64 = double(temp.f32);
	// fmsubs f31,f31,f12,f23
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f12.f64 - ctx.f23.f64));
	// lfs f23,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f23,f12,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 + ctx.f16.f64));
	// stfs f23,-444(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f16,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f22,f22,f12,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f14.f64));
	// lfs f23,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// lfs f16,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f5,f5,f16
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f16.f64));
	// lfs f16,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f12,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 - ctx.f15.f64));
	// stfs f16,-440(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// stfs f22,-428(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f22,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// lfs f16,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f22,f16
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// lfs f16,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f22,f16
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// lfs f22,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f16,f22,f16,f15
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f16.f64 - ctx.f15.f64));
	// stfsx f16,r8,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// lfs f16,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f22,f22,f16,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f16.f64 + ctx.f14.f64));
	// stfsx f22,r8,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fsubs f16,f6,f4
	ctx.f16.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// lfs f15,220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f15.f64 = double(temp.f32);
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// lfs f22,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f2,f14
	ctx.f14.f64 = double(float(ctx.f2.f64 - ctx.f14.f64));
	// lfs f4,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f4,f31,f4
	ctx.f4.f64 = double(float(ctx.f31.f64 - ctx.f4.f64));
	// stfs f4,-472(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f4,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f2.f64));
	// lfs f2,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f31.f64));
	// stfs f2,-488(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f31,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f31.f64 = double(temp.f32);
	// lfs f2,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f31,f31,f2
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f2.f64));
	// stfs f31,-444(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f31,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f31.f64 = double(temp.f32);
	// fadds f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f31.f64));
	// stfs f2,-440(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fmuls f31,f15,f5
	ctx.f31.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// fmuls f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f23.f64));
	// fmsubs f31,f22,f23,f31
	ctx.f31.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 - ctx.f31.f64));
	// stfsx f31,r9,r3
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmadds f5,f22,f5,f15
	ctx.f5.f64 = double(float(ctx.f22.f64 * ctx.f5.f64 + ctx.f15.f64));
	// stfsx f5,r9,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f31,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f31.f64 = double(temp.f32);
	// lfs f5,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f4
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// stfs f2,-524(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f23,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f22,f14,f23
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// lfs f23,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// lfs f2,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f6
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f6.f64));
	// fmuls f15,f31,f22
	ctx.f15.f64 = double(float(ctx.f31.f64 * ctx.f22.f64));
	// fmuls f31,f31,f23
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// fmsubs f23,f5,f23,f15
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 - ctx.f15.f64));
	// stfsx f23,r10,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f5,f5,f22,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 + ctx.f31.f64));
	// stfsx f5,r10,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f31,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f31.f64 = double(temp.f32);
	// lfs f23,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f31,f23
	ctx.f22.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// lfs f15,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f22,f5,f2,f22
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f2.f64 - ctx.f22.f64));
	// stfsx f22,r25,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fmuls f22,f31,f2
	ctx.f22.f64 = double(float(ctx.f31.f64 * ctx.f2.f64));
	// lfs f2,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f16.f64));
	// lfs f31,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f31.f64 = double(temp.f32);
	// lfs f16,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f16.f64 = double(temp.f32);
	// fadds f31,f31,f14
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f14.f64));
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f12
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// fmadds f5,f5,f23,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 + ctx.f22.f64));
	// stfsx f5,r25,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lfs f5,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f5.f64 = double(temp.f32);
	// stfs f5,-460(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f5,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f5,f13
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f23,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// stfs f5,-420(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// stfs f23,-524(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// fmuls f5,f16,f0
	ctx.f5.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f16,f15,f0
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f16,-384(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f16,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f23,f16,f13,f14
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f14.f64));
	// lfs f16,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f22,f16,f12,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f22.f64));
	// lfs f16,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f6,f6,f16
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f16.f64));
	// lfs f16,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f4,f4,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f16.f64));
	// lfs f16,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f16,f16,f13,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f16,-420(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f15,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f12,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f15.f64));
	// stfs f16,-524(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f16,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f16,f2
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// fmuls f15,f16,f31
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f31.f64));
	// fsubs f16,f3,f5
	ctx.f16.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// stfs f16,-400(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fadds f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// lfs f16,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f3,f23,f22
	ctx.f3.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f3,-500(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f3,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f3.f64 = double(temp.f32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f16,f21,f16
	ctx.f16.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// fmsubs f2,f3,f2,f15
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f2.f64 - ctx.f15.f64));
	// stfsx f2,r23,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fmadds f3,f3,f31,f14
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64 + ctx.f14.f64));
	// lfs f31,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f31.f64 = double(temp.f32);
	// fadds f31,f31,f21
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f21.f64));
	// stfsx f3,r23,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// lfs f2,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f3.f64 = double(temp.f32);
	// lfs f15,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f15,f14
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f22,f14,f15
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f15,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-420(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// fmuls f15,f2,f4
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// fmuls f14,f2,f6
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// fadds f2,f23,f31
	ctx.f2.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// fmsubs f6,f3,f6,f15
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f6.f64 - ctx.f15.f64));
	// stfsx f6,r16,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// fmadds f6,f3,f4,f14
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f4.f64 + ctx.f14.f64));
	// stfsx f6,r16,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// fsubs f3,f16,f21
	ctx.f3.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// lfs f4,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f4.f64 = double(temp.f32);
	// lfs f15,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f15.f64 = double(temp.f32);
	// mulli r10,r6,120
	ctx.r10.s64 = ctx.r6.s64 * 120;
	// lfs f6,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f31,f31,f23
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f23.f64));
	// lfs f23,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f4,f3
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// fmuls f4,f4,f15
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f15.f64));
	// fmsubs f15,f6,f15,f14
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f15.f64 - ctx.f14.f64));
	// stfsx f15,r10,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f6,f6,f3,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 + ctx.f4.f64));
	// stfsx f6,r10,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f3,f22,f5
	ctx.f3.f64 = double(float(ctx.f22.f64 + ctx.f5.f64));
	// lfs f4,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f15,f4,f2
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// lfs f6,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f5,f5,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f22.f64));
	// fmuls f14,f4,f3
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// fmsubs f4,f6,f3,f15
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 - ctx.f15.f64));
	// stfsx f4,r19,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// lfs f4,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f3.f64 = double(temp.f32);
	// fadds f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// fadds f3,f21,f16
	ctx.f3.f64 = double(float(ctx.f21.f64 + ctx.f16.f64));
	// lfs f21,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f21,f10
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f15,f21,f10
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// fmadds f6,f6,f2,f14
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 + ctx.f14.f64));
	// stfsx f6,r19,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f6.f64 = double(temp.f32);
	// stfs f6,-420(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f6,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f14,f6,f10
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// lfs f2,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f6,f21,f11
	ctx.f6.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// stfs f6,-464(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f21,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f21.f64 = double(temp.f32);
	// fadds f6,f2,f21
	ctx.f6.f64 = double(float(ctx.f2.f64 + ctx.f21.f64));
	// lfs f21,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f21,f21,f11,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 - ctx.f15.f64));
	// lfs f22,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f22.f64 = double(temp.f32);
	// lfs f2,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f2.f64 = double(temp.f32);
	// stfs f21,-424(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// fmadds f2,f2,f11,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f16.f64));
	// lfs f16,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f16.f64 = double(temp.f32);
	// lfs f21,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f16.f64));
	// lfs f16,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f11,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 - ctx.f14.f64));
	// fadds f14,f25,f28
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// lfs f15,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f23,f23,f10,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 + ctx.f15.f64));
	// fmuls f15,f22,f3
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f3.f64));
	// fmuls f22,f22,f4
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f4.f64));
	// stfs f22,-524(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// fadds f22,f1,f18
	ctx.f22.f64 = double(float(ctx.f1.f64 + ctx.f18.f64));
	// stfs f22,-464(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fadds f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 + ctx.f22.f64));
	// stfs f22,-416(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f22,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f6,f22,f6
	ctx.f6.f64 = double(float(ctx.f22.f64 - ctx.f6.f64));
	// lfs f22,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f2.f64));
	// stfs f22,-500(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f22,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f2,f22,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 - ctx.f2.f64));
	// lfs f22,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f4,f22,f4,f15
	ctx.f4.f64 = double(float(ctx.f22.f64 * ctx.f4.f64 - ctx.f15.f64));
	// lfs f15,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f15.f64 = double(temp.f32);
	// stfsx f4,r20,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// fmadds f3,f22,f3,f15
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f15.f64));
	// stfsx f3,r20,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// fadds f4,f21,f14
	ctx.f4.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// lfs f3,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f3.f64 = double(temp.f32);
	// lfs f22,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f22.f64 = double(temp.f32);
	// fadds f15,f23,f16
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f16.f64));
	// mulli r10,r6,88
	ctx.r10.s64 = ctx.r6.s64 * 88;
	// fsubs f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// fmuls f16,f22,f31
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f31.f64));
	// fsubs f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// fmuls f14,f22,f5
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// fmsubs f5,f3,f5,f16
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f5.f64 - ctx.f16.f64));
	// stfsx f5,r10,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f16,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f16.f64 = double(temp.f32);
	// fadds f22,f21,f23
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fmadds f5,f3,f31,f14
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f31.f64 + ctx.f14.f64));
	// lfs f31,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f31,f4,f31
	ctx.f31.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// stfsx f5,r10,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f3,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f3.f64 = double(temp.f32);
	// lfs f5,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f5.f64 = double(temp.f32);
	// mulli r10,r6,68
	ctx.r10.s64 = ctx.r6.s64 * 68;
	// fmuls f14,f3,f31
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f3,f3,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f16.f64));
	// fmsubs f16,f5,f16,f14
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f16.f64 - ctx.f14.f64));
	// stfsx f16,r10,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f5,f5,f31,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64 + ctx.f3.f64));
	// stfsx f5,r10,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f31,f2,f6
	ctx.f31.f64 = double(float(ctx.f2.f64 + ctx.f6.f64));
	// lfs f3,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f3,f22
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// lfs f5,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f2.f64));
	// fsubs f2,f21,f23
	ctx.f2.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// fadds f21,f24,f7
	ctx.f21.f64 = double(float(ctx.f24.f64 + ctx.f7.f64));
	// fmuls f14,f3,f31
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// lfs f3,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f31,f5,f31,f16
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f31.f64 - ctx.f16.f64));
	// stfsx f31,r18,r3
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// fadds f3,f15,f3
	ctx.f3.f64 = double(float(ctx.f15.f64 + ctx.f3.f64));
	// lfs f15,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f15.f64 = double(temp.f32);
	// fadds f4,f4,f15
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f15.f64));
	// lfs f15,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f10
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// fmuls f16,f17,f10
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// fmadds f5,f5,f22,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 + ctx.f14.f64));
	// lfs f22,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f11
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// stfsx f5,r18,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// fmuls f22,f17,f11
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// stfs f22,-464(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f17,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f22,f17,f11,f15
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f15.f64));
	// lfs f31,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f31.f64 = double(temp.f32);
	// fmadds f17,f20,f11,f16
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f11.f64 + ctx.f16.f64));
	// lfs f16,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f16.f64 = double(temp.f32);
	// lfs f5,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f16,f16,f10,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 - ctx.f14.f64));
	// fsubs f14,f29,f26
	ctx.f14.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// lfs f15,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f23,f20,f10,f15
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 - ctx.f15.f64));
	// lfs f20,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f31,f4
	ctx.f15.f64 = double(float(ctx.f31.f64 * ctx.f4.f64));
	// fmuls f31,f31,f3
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// stfs f31,-464(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fadds f20,f20,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// fmsubs f3,f5,f3,f15
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f3.f64 - ctx.f15.f64));
	// stfsx f3,r21,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fsubs f15,f19,f30
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f30.f64));
	// fsubs f31,f21,f20
	ctx.f31.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f20,f22,f17
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fadds f3,f14,f15
	ctx.f3.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f17,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f5,f5,f4,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f4.f64 + ctx.f17.f64));
	// stfsx f5,r21,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// fadds f17,f23,f16
	ctx.f17.f64 = double(float(ctx.f23.f64 + ctx.f16.f64));
	// lfs f4,196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 196);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// lfs f5,192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 192);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f15,f22,f21
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfs f15,-464(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fmuls f15,f4,f2
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// fmuls f14,f4,f6
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// mulli r10,r6,100
	ctx.r10.s64 = ctx.r6.s64 * 100;
	// fmsubs f6,f5,f6,f15
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f6.f64 - ctx.f15.f64));
	// fsubs f4,f31,f17
	ctx.f4.f64 = double(float(ctx.f31.f64 - ctx.f17.f64));
	// fsubs f1,f18,f1
	ctx.f1.f64 = double(float(ctx.f18.f64 - ctx.f1.f64));
	// lfs f18,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// lfs f25,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f25.f64 = double(temp.f32);
	// stfsx f6,r10,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// lfs f21,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f6,f5,f2,f14
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f2.f64 + ctx.f14.f64));
	// stfsx f6,r10,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f2,f3,f20
	ctx.f2.f64 = double(float(ctx.f3.f64 - ctx.f20.f64));
	// lfs f5,180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 180);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f6.f64 = double(temp.f32);
	// fadds f3,f3,f20
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f20.f64));
	// fmuls f15,f5,f2
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// fmuls f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// fmsubs f4,f6,f4,f15
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f4.f64 - ctx.f15.f64));
	// stfsx f4,r27,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fmadds f6,f6,f2,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 + ctx.f5.f64));
	// stfsx f6,r27,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fadds f2,f17,f31
	ctx.f2.f64 = double(float(ctx.f17.f64 + ctx.f31.f64));
	// lfs f31,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f20,f31,f8
	ctx.f20.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// lfs f31,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f17,f31,f8
	ctx.f17.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// lfs f31,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f15,f31,f8
	ctx.f15.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// lfs f31,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f14,f31,f8
	ctx.f14.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// lfs f31,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f31,f18,f31
	ctx.f31.f64 = double(float(ctx.f18.f64 - ctx.f31.f64));
	// lfs f18,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f5,f16,f23
	ctx.f5.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// lfs f4,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f4.f64 = double(temp.f32);
	// fadds f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// lfs f16,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f16.f64 = double(temp.f32);
	// lfs f6,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f20,f18,f9,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f9.f64 + ctx.f20.f64));
	// lfs f18,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f9,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f9.f64 - ctx.f17.f64));
	// lfs f17,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f25,f25,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f17.f64));
	// lfs f17,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f9,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 - ctx.f15.f64));
	// fmadds f21,f21,f9,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64 + ctx.f14.f64));
	// fmuls f15,f4,f5
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// fmuls f4,f4,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f16.f64));
	// fmsubs f16,f6,f16,f15
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f16.f64 - ctx.f15.f64));
	// stfsx f16,r29,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fmadds f6,f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f5.f64 + ctx.f4.f64));
	// stfsx f6,r29,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// lfs f5,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f5.f64 = double(temp.f32);
	// fadds f4,f31,f1
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fmuls f16,f5,f3
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f6,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f15,f5,f2
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// fsubs f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// fadds f31,f18,f20
	ctx.f31.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// fsubs f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// fadds f18,f25,f28
	ctx.f18.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// fsubs f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// fadds f25,f21,f17
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// fsubs f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// fmsubs f2,f6,f2,f16
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 - ctx.f16.f64));
	// stfsx f2,r30,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmadds f6,f6,f3,f15
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 + ctx.f15.f64));
	// stfsx f6,r30,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f3,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f3,f23
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfs f6,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f3,f3,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// fsubs f5,f18,f31
	ctx.f5.f64 = double(float(ctx.f18.f64 - ctx.f31.f64));
	// fsubs f17,f4,f25
	ctx.f17.f64 = double(float(ctx.f4.f64 - ctx.f25.f64));
	// fmsubs f2,f6,f22,f2
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f22.f64 - ctx.f2.f64));
	// stfsx f2,r5,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fmadds f6,f6,f23,f3
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f23.f64 + ctx.f3.f64));
	// stfsx f6,r5,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f6.f64 = double(temp.f32);
	// lfs f3,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f3.f64 = double(temp.f32);
	// fadds f4,f25,f4
	ctx.f4.f64 = double(float(ctx.f25.f64 + ctx.f4.f64));
	// fmuls f2,f3,f5
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f25,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f3,f3,f17
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// lfs f23,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f25,f9
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// mulli r10,r6,108
	ctx.r10.s64 = ctx.r6.s64 * 108;
	// fadds f31,f18,f31
	ctx.f31.f64 = double(float(ctx.f18.f64 + ctx.f31.f64));
	// lwz r9,-336(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	// fmuls f18,f23,f8
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fadds f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fmuls f16,f25,f8
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// fsubs f7,f7,f24
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f24.f64));
	// lfs f24,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f24.f64 = double(temp.f32);
	// fadds f30,f30,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f19.f64));
	// fmsubs f2,f6,f17,f2
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f17.f64 - ctx.f2.f64));
	// stfsx f2,r15,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// fmadds f6,f6,f5,f3
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f5.f64 + ctx.f3.f64));
	// stfsx f6,r15,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// fadds f2,f28,f21
	ctx.f2.f64 = double(float(ctx.f28.f64 + ctx.f21.f64));
	// lfs f3,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f3.f64 = double(temp.f32);
	// fadds f5,f20,f1
	ctx.f5.f64 = double(float(ctx.f20.f64 + ctx.f1.f64));
	// lfs f6,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f17,f23,f9
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// lfs f23,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f26,f23,f8,f22
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f8.f64 - ctx.f22.f64));
	// lfs f22,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f27,f27,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f22.f64));
	// fmadds f25,f24,f9,f18
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 + ctx.f18.f64));
	// fmadds f23,f23,f9,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f9.f64 + ctx.f16.f64));
	// fsubs f28,f28,f21
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f21.f64));
	// fsubs f1,f1,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f20.f64));
	// fmuls f22,f3,f2
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// fmsubs f24,f24,f8,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f8.f64 - ctx.f17.f64));
	// fmsubs f5,f6,f5,f22
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f5.f64 - ctx.f22.f64));
	// stfsx f5,r24,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fmadds f6,f6,f2,f3
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 + ctx.f3.f64));
	// stfsx f6,r24,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// fsubs f3,f7,f29
	ctx.f3.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// lfs f5,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f5.f64 = double(temp.f32);
	// fadds f7,f29,f7
	ctx.f7.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// lfs f6,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f2,f26,f25
	ctx.f2.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fadds f29,f25,f26
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f26,f30,f27
	ctx.f26.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// fadds f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// fsubs f27,f24,f23
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f25,f23,f24
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fmuls f23,f5,f31
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fmuls f22,f5,f4
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// fsubs f5,f26,f2
	ctx.f5.f64 = double(float(ctx.f26.f64 - ctx.f2.f64));
	// fadds f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// fsubs f24,f3,f27
	ctx.f24.f64 = double(float(ctx.f3.f64 - ctx.f27.f64));
	// fadds f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// fmsubs f4,f6,f4,f23
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f4.f64 - ctx.f23.f64));
	// stfsx f4,r22,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fmadds f6,f6,f31,f22
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64 + ctx.f22.f64));
	// stfsx f6,r22,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f31,f4,f28
	ctx.f31.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// lfs f6,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f4,f4,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// fmsubs f1,f6,f1,f31
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f1.f64 - ctx.f31.f64));
	// stfsx f1,r17,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// fmadds f6,f6,f28,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64 + ctx.f4.f64));
	// stfsx f6,r17,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f4.f64 = double(temp.f32);
	// subf r4,r9,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r9.s64;
	// fmuls f1,f4,f5
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// lfs f6,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f28,f4,f24
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f24.f64));
	// fadds f4,f29,f7
	ctx.f4.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// fmsubs f1,f6,f24,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 - ctx.f1.f64));
	// stfsx f1,r10,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,-356(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fadds f1,f30,f25
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stw r10,-356(r1)
	PPC_STORE_U32(ctx.r1.u32 + -356, ctx.r10.u32);
	// lwz r9,-332(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	// fmadds f6,f6,f5,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f5.f64 + ctx.f28.f64));
	// fsubs f31,f30,f25
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// lwz r10,-324(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	// fsubs f7,f7,f29
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// stfs f6,0(r9)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lfs f5,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f30,f5,f1
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f6,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// fmsubs f4,f6,f4,f30
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f4.f64 - ctx.f30.f64));
	// stfs f4,0(r14)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fmadds f6,f6,f1,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f1.f64 + ctx.f5.f64));
	// stfs f6,0(r10)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lfs f5,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f5.f64 = double(temp.f32);
	// lwz r10,-468(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	// fmuls f4,f5,f2
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// lfs f6,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// fmsubs f4,f6,f3,f4
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 - ctx.f4.f64));
	// stfs f4,0(r10)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-316(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	// fmadds f6,f6,f2,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 + ctx.f5.f64));
	// stfs f6,0(r10)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-508(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	// lfs f5,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f31
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// lfs f6,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f5,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// addi r11,r11,248
	ctx.r11.s64 = ctx.r11.s64 + 248;
	// fmsubs f7,f6,f7,f4
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f7.f64 - ctx.f4.f64));
	// stfs f7,0(r10)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-308(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	// fmadds f7,f6,f31,f5
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f31.f64 + ctx.f5.f64));
	// stfs f7,0(r10)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d36b04
	if (!ctx.cr0.eq) goto loc_82D36B04;
loc_82D37FE0:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D37FE8;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D37FF0"))) PPC_WEAK_FUNC(sub_82D37FF0);
PPC_FUNC_IMPL(__imp__sub_82D37FF0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-5408
	ctx.r5.s64 = ctx.r11.s64 + -5408;
	// lis r11,-32045
	ctx.r11.s64 = -2100101120;
	// addi r4,r11,27288
	ctx.r4.s64 = ctx.r11.s64 + 27288;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D38008"))) PPC_WEAK_FUNC(sub_82D38008);
PPC_FUNC_IMPL(__imp__sub_82D38008) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e3c
	ctx.lr = 0x82D38010;
	__savegprlr_17(ctx, base);
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82e28ee0
	ctx.lr = 0x82D38018;
	__savefpr_14(ctx, base);
	// mulli r11,r7,120
	ctx.r11.s64 = ctx.r7.s64 * 120;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-120
	ctx.r11.s64 = ctx.r11.s64 + -120;
	// bge cr6,0x82d3867c
	if (!ctx.cr6.lt) goto loc_82D3867C;
	// rlwinm r18,r9,2,0,29
	ctx.r18.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r23,r7,r8
	ctx.r23.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lis r17,-32234
	ctx.r17.s64 = -2112487424;
	// lfs f12,136(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D38050:
	// mulli r8,r6,52
	ctx.r8.s64 = ctx.r6.s64 * 52;
	// lfs f11,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// mulli r7,r6,40
	ctx.r7.s64 = ctx.r6.s64 * 40;
	// lfsx f8,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f31,f7,f8
	ctx.f31.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// mulli r9,r6,20
	ctx.r9.s64 = ctx.r6.s64 * 20;
	// lfsx f10,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f1,f10,f9
	ctx.f1.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// lfsx f22,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// rlwinm r5,r6,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// mulli r31,r6,24
	ctx.r31.s64 = ctx.r6.s64 * 24;
	// lfsx f6,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f7,f6,f5
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// mulli r29,r6,56
	ctx.r29.s64 = ctx.r6.s64 * 56;
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// lfsx f3,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f21,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// mulli r30,r6,36
	ctx.r30.s64 = ctx.r6.s64 * 36;
	// lfsx f4,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f27,f3,f4
	ctx.f27.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// mulli r28,r6,28
	ctx.r28.s64 = ctx.r6.s64 * 28;
	// fsubs f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// lfsx f2,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f3,f2,f11
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f11.f64));
	// mulli r22,r6,48
	ctx.r22.s64 = ctx.r6.s64 * 48;
	// fsubs f11,f11,f2
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f2.f64));
	// fadds f2,f31,f1
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fsubs f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// fadds f31,f6,f10
	ctx.f31.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fadds f6,f27,f7
	ctx.f6.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fsubs f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// lfsx f27,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// rlwinm r21,r6,4,0,27
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// add r20,r22,r3
	ctx.r20.u64 = ctx.r22.u64 + ctx.r3.u64;
	// mulli r27,r6,44
	ctx.r27.s64 = ctx.r6.s64 * 44;
	// lfs f30,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f24,f2,f6
	ctx.f24.f64 = double(float(ctx.f2.f64 - ctx.f6.f64));
	// lfsx f9,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f23,f6,f2
	ctx.f23.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fsubs f25,f9,f30
	ctx.f25.f64 = double(float(ctx.f9.f64 - ctx.f30.f64));
	// add r19,r21,r3
	ctx.r19.u64 = ctx.r21.u64 + ctx.r3.u64;
	// fadds f9,f30,f9
	ctx.f9.f64 = double(float(ctx.f30.f64 + ctx.f9.f64));
	// mulli r26,r6,12
	ctx.r26.s64 = ctx.r6.s64 * 12;
	// fadds f15,f7,f1
	ctx.f15.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// fsubs f14,f1,f7
	ctx.f14.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// lfsx f7,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f1,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfs f29,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f5,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f30,f5,f29
	ctx.f30.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// mulli r25,r6,60
	ctx.r25.s64 = ctx.r6.s64 * 60;
	// fsubs f5,f29,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// lfsx f28,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// rlwinm r24,r6,5,0,26
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// add r22,r22,r4
	ctx.r22.u64 = ctx.r22.u64 + ctx.r4.u64;
	// add r21,r21,r4
	ctx.r21.u64 = ctx.r21.u64 + ctx.r4.u64;
	// lfsx f26,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f29,f28,f26
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fsubs f26,f4,f8
	ctx.f26.f64 = double(float(ctx.f4.f64 - ctx.f8.f64));
	// fadds f8,f4,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fadds f4,f9,f11
	ctx.f4.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fsubs f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// fadds f9,f30,f3
	ctx.f9.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// fsubs f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f30.f64));
	// fsubs f2,f29,f25
	ctx.f2.f64 = double(float(ctx.f29.f64 - ctx.f25.f64));
	// fsubs f6,f28,f5
	ctx.f6.f64 = double(float(ctx.f28.f64 - ctx.f5.f64));
	// fadds f30,f29,f25
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f25.f64));
	// lfs f25,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fadds f5,f28,f5
	ctx.f5.f64 = double(float(ctx.f28.f64 + ctx.f5.f64));
	// fmuls f29,f24,f0
	ctx.f29.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// lfsx f24,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f28,f23,f0
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// lfsx f23,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f14,-320(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfsx f14,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f14,-336(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfsx f14,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-304(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fsubs f14,f27,f24
	ctx.f14.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// fadds f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// lfsx f20,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f24,f7,f23
	ctx.f24.f64 = double(float(ctx.f7.f64 + ctx.f23.f64));
	// lfsx f19,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f7,f23,f7
	ctx.f7.f64 = double(float(ctx.f23.f64 - ctx.f7.f64));
	// lfsx f17,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f23,f1,f22
	ctx.f23.f64 = double(float(ctx.f1.f64 - ctx.f22.f64));
	// lfs f18,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// fadds f1,f22,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 + ctx.f1.f64));
	// stfs f15,-288(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fadds f22,f20,f21
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// lfs f15,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// lfsx f16,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f19,f25
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f25.f64));
	// stfs f20,-312(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fsubs f20,f18,f17
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f18,-332(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f25,f25,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f19.f64));
	// fadds f19,f15,f16
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f18,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// fsubs f15,f14,f24
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// fadds f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// fsubs f14,f27,f1
	ctx.f14.f64 = double(float(ctx.f27.f64 - ctx.f1.f64));
	// stfs f14,-336(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f14,f22,f23
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// fsubs f22,f21,f7
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f7.f64));
	// fadds f7,f21,f7
	ctx.f7.f64 = double(float(ctx.f21.f64 + ctx.f7.f64));
	// stfs f7,-308(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f7,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f7.f64 = double(temp.f32);
	// fadds f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// fadds f27,f19,f7
	ctx.f27.f64 = double(float(ctx.f19.f64 + ctx.f7.f64));
	// stfs f27,-304(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fsubs f7,f7,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f19.f64));
	// stfs f7,-300(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fmuls f7,f15,f12
	ctx.f7.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fmuls f21,f14,f12
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// fmuls f27,f23,f12
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// stfs f27,-312(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fmuls f19,f23,f13
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// lfs f23,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f23,-292(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f23,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f23.f64 = double(temp.f32);
	// fadds f27,f22,f23
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fmadds f23,f14,f13,f7
	ctx.f23.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 + ctx.f7.f64));
	// fmsubs f22,f15,f13,f21
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 - ctx.f21.f64));
	// fmsubs f21,f24,f12,f19
	ctx.f21.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 - ctx.f19.f64));
	// fadds f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// lfs f16,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f4,f28
	ctx.f14.f64 = double(float(ctx.f4.f64 - ctx.f28.f64));
	// stfs f14,-296(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// fadds f4,f28,f4
	ctx.f4.f64 = double(float(ctx.f28.f64 + ctx.f4.f64));
	// stfs f4,-324(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fadds f14,f14,f6
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f6.f64));
	// lfs f7,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f24,f24,f13,f7
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f7.f64));
	// lfs f7,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f7.f64 = double(temp.f32);
	// fadds f19,f7,f25
	ctx.f19.f64 = double(float(ctx.f7.f64 + ctx.f25.f64));
	// fsubs f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f16.f64));
	// stfs f25,-336(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fsubs f25,f18,f20
	ctx.f25.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// stfs f25,-332(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fadds f7,f18,f20
	ctx.f7.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// lfs f28,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f28.f64 = double(temp.f32);
	// fadds f4,f31,f9
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f9.f64));
	// fadds f28,f28,f1
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// lfs f20,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f7,f20
	ctx.f20.f64 = double(float(ctx.f7.f64 + ctx.f20.f64));
	// fmuls f16,f15,f13
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fmuls f15,f15,f12
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fadds f25,f28,f4
	ctx.f25.f64 = double(float(ctx.f28.f64 + ctx.f4.f64));
	// stfs f25,0(r3)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f25,f8,f30
	ctx.f25.f64 = double(float(ctx.f8.f64 + ctx.f30.f64));
	// fsubs f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f28.f64));
	// fadds f18,f20,f25
	ctx.f18.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// stfs f18,0(r4)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// lfs f28,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f20,f19,f12,f16
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 - ctx.f16.f64));
	// stfs f20,-316(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f20,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f20,f12
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// lfs f18,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f20,f19,f13,f15
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f20,-328(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fmuls f15,f17,f12
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f20,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f20
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfs f19,-312(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f19,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// fmsubs f19,f17,f13,f16
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f16.f64));
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f28,f25
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmadds f17,f17,f13,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f15.f64));
	// fmuls f15,f28,f4
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f4.f64));
	// fmsubs f4,f18,f4,f16
	ctx.f4.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 - ctx.f16.f64));
	// stfsx f4,r24,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// lfs f16,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f4,f18,f25,f15
	ctx.f4.f64 = double(float(ctx.f18.f64 * ctx.f25.f64 + ctx.f15.f64));
	// stfsx f4,r24,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lfs f25,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f25.f64 = double(temp.f32);
	// lfs f4,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f4.f64 = double(temp.f32);
	// lfs f28,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f24,f28
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f28.f64));
	// stfs f28,-300(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f28,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f24.f64));
	// lfs f24,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f24.f64 = double(temp.f32);
	// fadds f18,f24,f21
	ctx.f18.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// fsubs f24,f16,f18
	ctx.f24.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// lfs f15,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f14,f15
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f28
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// stfs f14,-328(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f14,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f14.f64 = double(temp.f32);
	// fadds f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// fmuls f14,f25,f24
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// fmuls f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f16.f64));
	// fmsubs f25,f4,f24,f25
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f24.f64 - ctx.f25.f64));
	// stfsx f25,r27,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fmadds f4,f4,f16,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f16.f64 + ctx.f14.f64));
	// stfsx f4,r27,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f25,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f25,f15
	ctx.f24.f64 = double(float(ctx.f25.f64 * ctx.f15.f64));
	// lfs f4,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f18.f64));
	// lfs f16,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f24,f4,f18,f24
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f18.f64 - ctx.f24.f64));
	// stfsx f24,r26,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fmadds f4,f4,f15,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f15.f64 + ctx.f25.f64));
	// lfs f25,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f25.f64 = double(temp.f32);
	// stfsx f4,r26,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// lfs f4,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f4.f64 = double(temp.f32);
	// lfs f21,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// lfs f4,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f4.f64 = double(temp.f32);
	// fadds f15,f21,f16
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f16.f64));
	// lfs f24,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f24.f64 = double(temp.f32);
	// fadds f14,f20,f27
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// fsubs f20,f20,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f27.f64));
	// lfs f27,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f16,f16,f27
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f27.f64));
	// fadds f18,f10,f2
	ctx.f18.f64 = double(float(ctx.f10.f64 + ctx.f2.f64));
	// fsubs f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 - ctx.f10.f64));
	// fadds f21,f26,f3
	ctx.f21.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// fmuls f2,f15,f0
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f3,f3,f26
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f26.f64));
	// fsubs f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f31.f64));
	// lfs f31,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f31.f64));
	// fmuls f27,f14,f0
	ctx.f27.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmuls f26,f20,f0
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmuls f20,f16,f0
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fadds f16,f25,f6
	ctx.f16.f64 = double(float(ctx.f25.f64 + ctx.f6.f64));
	// fsubs f6,f6,f25
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f25.f64));
	// fmuls f14,f24,f15
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f15.f64));
	// fsubs f25,f21,f2
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f2.f64));
	// fadds f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f21.f64));
	// fsubs f15,f18,f27
	ctx.f15.f64 = double(float(ctx.f18.f64 - ctx.f27.f64));
	// fsubs f21,f3,f26
	ctx.f21.f64 = double(float(ctx.f3.f64 - ctx.f26.f64));
	// fadds f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// fmuls f26,f24,f16
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f16.f64));
	// lfs f24,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f24.f64 = double(temp.f32);
	// fadds f27,f27,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f18.f64));
	// fsubs f18,f10,f20
	ctx.f18.f64 = double(float(ctx.f10.f64 - ctx.f20.f64));
	// fadds f10,f20,f10
	ctx.f10.f64 = double(float(ctx.f20.f64 + ctx.f10.f64));
	// fmsubs f26,f4,f24,f26
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f24.f64 - ctx.f26.f64));
	// stfsx f26,r28,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fmadds f4,f4,f16,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f16.f64 + ctx.f14.f64));
	// stfsx f4,r28,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f24,f26,f6
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// lfs f4,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f26,f26,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmsubs f28,f4,f28,f24
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f28.f64 - ctx.f24.f64));
	// stfsx f28,r25,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fmadds f6,f4,f6,f26
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f6.f64 + ctx.f26.f64));
	// stfsx f6,r25,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f28,f4,f15
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f15.f64));
	// lfs f6,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f25.f64));
	// lfs f26,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f28,f6,f25,f28
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f25.f64 - ctx.f28.f64));
	// stfsx f28,r7,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fmadds f6,f6,f15,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f15.f64 + ctx.f4.f64));
	// stfsx f6,r7,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f28,f4,f27
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// lfs f6,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// fmsubs f2,f6,f2,f28
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 - ctx.f28.f64));
	// stfsx f2,r10,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f6,f6,f27,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f27.f64 + ctx.f4.f64));
	// stfsx f6,r10,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f28,f5,f29
	ctx.f28.f64 = double(float(ctx.f5.f64 - ctx.f29.f64));
	// fmuls f2,f4,f18
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f18.f64));
	// lfs f6,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f25,f4,f21
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// fsubs f4,f11,f26
	ctx.f4.f64 = double(float(ctx.f11.f64 - ctx.f26.f64));
	// fsubs f27,f22,f17
	ctx.f27.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f11,f26,f11
	ctx.f11.f64 = double(float(ctx.f26.f64 + ctx.f11.f64));
	// fadds f26,f17,f22
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fadds f5,f29,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 + ctx.f5.f64));
	// fadds f29,f19,f23
	ctx.f29.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// fmsubs f2,f6,f21,f2
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f21.f64 - ctx.f2.f64));
	// stfsx f2,r29,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fsubs f2,f19,f23
	ctx.f2.f64 = double(float(ctx.f19.f64 - ctx.f23.f64));
	// fmadds f6,f6,f18,f25
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f18.f64 + ctx.f25.f64));
	// stfsx f6,r29,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f6.f64 = double(temp.f32);
	// lfs f25,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f31,f4,f2
	ctx.f31.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fadds f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fsubs f2,f28,f27
	ctx.f2.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fsubs f27,f11,f26
	ctx.f27.f64 = double(float(ctx.f11.f64 - ctx.f26.f64));
	// fmuls f24,f25,f10
	ctx.f24.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// addic. r23,r23,-1
	ctx.xer.ca = ctx.r23.u32 > 0;
	ctx.r23.s64 = ctx.r23.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// fmuls f25,f25,f3
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// fadds f11,f26,f11
	ctx.f11.f64 = double(float(ctx.f26.f64 + ctx.f11.f64));
	// fsubs f26,f5,f29
	ctx.f26.f64 = double(float(ctx.f5.f64 - ctx.f29.f64));
	// fadds f5,f29,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 + ctx.f5.f64));
	// fmsubs f3,f6,f3,f24
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 - ctx.f24.f64));
	// stfsx f3,r31,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmadds f10,f6,f10,f25
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f10.f64 + ctx.f25.f64));
	// stfsx f10,r31,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f3,f6,f2
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// lfs f10,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmsubs f3,f10,f31,f3
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f31.f64 - ctx.f3.f64));
	// stfsx f3,r8,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fmadds f10,f10,f2,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f2.f64 + ctx.f6.f64));
	// stfsx f10,r8,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f3,f6,f28
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f10,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// fmsubs f4,f10,f4,f3
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 - ctx.f3.f64));
	// stfsx f4,r9,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmadds f10,f10,f28,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 + ctx.f6.f64));
	// stfsx f10,r9,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f4,f6,f26
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// lfs f10,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// fmsubs f4,f10,f27,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f27.f64 - ctx.f4.f64));
	// stfsx f4,r30,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmadds f10,f10,f26,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f26.f64 + ctx.f6.f64));
	// stfsx f10,r30,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f4,f6,f5
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f10,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f6,f11
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// fmsubs f11,f10,f11,f4
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 - ctx.f4.f64));
	// stfsx f11,r5,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fmadds f11,f10,f5,f6
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f5.f64 + ctx.f6.f64));
	// stfsx f11,r5,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// fsubs f11,f30,f8
	ctx.f11.f64 = double(float(ctx.f30.f64 - ctx.f8.f64));
	// lfs f8,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f1,f8
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f8.f64));
	// lfs f6,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f5,f9,f7
	ctx.f5.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// lfs f10,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// fadds f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// add r3,r18,r3
	ctx.r3.u64 = ctx.r18.u64 + ctx.r3.u64;
	// subf r4,r18,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r18.s64;
	// fsubs f7,f11,f8
	ctx.f7.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// fadds f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// fmuls f4,f6,f5
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// fmuls f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// fmsubs f8,f10,f5,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f5.f64 - ctx.f8.f64));
	// stfs f8,0(r20)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// fmadds f10,f10,f7,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f7.f64 + ctx.f4.f64));
	// stfs f10,0(r22)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// lfs f8,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f8,f11
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// lfs f10,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f8,f9
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// addi r11,r11,120
	ctx.r11.s64 = ctx.r11.s64 + 120;
	// fmsubs f9,f10,f9,f7
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 - ctx.f7.f64));
	// stfs f9,0(r19)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// fmadds f11,f10,f11,f8
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 + ctx.f8.f64));
	// stfs f11,0(r21)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// lwz r10,3532(r17)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r17.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d38050
	if (!ctx.cr0.eq) goto loc_82D38050;
loc_82D3867C:
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82e28f2c
	ctx.lr = 0x82D38684;
	__restfpr_14(ctx, base);
	// b 0x82e28e8c
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D38688"))) PPC_WEAK_FUNC(sub_82D38688);
PPC_FUNC_IMPL(__imp__sub_82D38688) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-5352
	ctx.r5.s64 = ctx.r11.s64 + -5352;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,-32760
	ctx.r4.s64 = ctx.r11.s64 + -32760;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D386A0"))) PPC_WEAK_FUNC(sub_82D386A0);
PPC_FUNC_IMPL(__imp__sub_82D386A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e34
	ctx.lr = 0x82D386A8;
	__savegprlr_15(ctx, base);
	// addi r12,r1,-144
	ctx.r12.s64 = ctx.r1.s64 + -144;
	// bl 0x82e28ee0
	ctx.lr = 0x82D386B0;
	__savefpr_14(ctx, base);
	// mulli r11,r7,112
	ctx.r11.s64 = ctx.r7.s64 * 112;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-112
	ctx.r11.s64 = ctx.r11.s64 + -112;
	// bge cr6,0x82d38e00
	if (!ctx.cr6.lt) goto loc_82D38E00;
	// subf r17,r7,r8
	ctx.r17.s64 = ctx.r8.s64 - ctx.r7.s64;
	// rlwinm r16,r9,2,0,29
	ctx.r16.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r5,-32255
	ctx.r5.s64 = -2113863680;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f9,-7592(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -7592);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-12288(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -12288);
	ctx.f10.f64 = double(temp.f32);
	// lis r15,-32234
	ctx.r15.s64 = -2112487424;
	// lfs f13,-7584(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -7584);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7588(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -7588);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,-28552(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f12.f64 = double(temp.f32);
loc_82D38700:
	// mulli r27,r6,20
	ctx.r27.s64 = ctx.r6.s64 * 20;
	// lfs f8,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// add r25,r27,r3
	ctx.r25.u64 = ctx.r27.u64 + ctx.r3.u64;
	// rlwinm r10,r6,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r9,r6,36
	ctx.r9.s64 = ctx.r6.s64 * 36;
	// lfs f7,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f23,f7,f6
	ctx.f23.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// lfsx f5,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f24,f6,f7
	ctx.f24.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// lfsx f18,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r8,r6,40
	ctx.r8.s64 = ctx.r6.s64 * 40;
	// lfsx f16,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f4,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfsx f20,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// rlwinm r28,r6,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f4,f4,f5
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// mulli r5,r6,24
	ctx.r5.s64 = ctx.r6.s64 * 24;
	// fmuls f5,f23,f12
	ctx.f5.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// lfsx f1,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// rlwinm r31,r6,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r7,r6,12
	ctx.r7.s64 = ctx.r6.s64 * 12;
	// fmuls f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// lfsx f30,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f3,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f23,f30,f1
	ctx.f23.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// lfsx f29,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f30,f1,f30
	ctx.f30.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// mulli r30,r6,28
	ctx.r30.s64 = ctx.r6.s64 * 28;
	// fadds f22,f29,f3
	ctx.f22.f64 = double(float(ctx.f29.f64 + ctx.f3.f64));
	// fsubs f29,f3,f29
	ctx.f29.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// lfsx f2,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f27,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// add r24,r28,r3
	ctx.r24.u64 = ctx.r28.u64 + ctx.r3.u64;
	// mulli r26,r6,56
	ctx.r26.s64 = ctx.r6.s64 * 56;
	// fmuls f3,f30,f12
	ctx.f3.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// fmuls f30,f29,f12
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// lfs f28,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// fadds f1,f27,f28
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// add r22,r26,r4
	ctx.r22.u64 = ctx.r26.u64 + ctx.r4.u64;
	// add r23,r28,r4
	ctx.r23.u64 = ctx.r28.u64 + ctx.r4.u64;
	// rlwinm r21,r6,5,0,26
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// mulli r29,r6,48
	ctx.r29.s64 = ctx.r6.s64 * 48;
	// lfs f25,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fadds f27,f6,f25
	ctx.f27.f64 = double(float(ctx.f6.f64 + ctx.f25.f64));
	// fnmsubs f6,f6,f11,f25
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 - ctx.f25.f64)));
	// fmuls f29,f28,f12
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// lfsx f7,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f28,f24,f8
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f8.f64));
	// fnmsubs f8,f24,f11,f8
	ctx.f8.f64 = double(float(-(ctx.f24.f64 * ctx.f11.f64 - ctx.f8.f64)));
	// add r19,r21,r3
	ctx.r19.u64 = ctx.r21.u64 + ctx.r3.u64;
	// fadds f21,f1,f26
	ctx.f21.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// mulli r28,r6,52
	ctx.r28.s64 = ctx.r6.s64 * 52;
	// fadds f25,f23,f2
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f2.f64));
	// fnmsubs f1,f1,f11,f26
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f26.f64)));
	// fnmsubs f2,f23,f11,f2
	ctx.f2.f64 = double(float(-(ctx.f23.f64 * ctx.f11.f64 - ctx.f2.f64)));
	// fadds f24,f22,f31
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f31.f64));
	// fnmsubs f31,f22,f11,f31
	ctx.f31.f64 = double(float(-(ctx.f22.f64 * ctx.f11.f64 - ctx.f31.f64)));
	// lfs f15,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f22,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// add r26,r26,r3
	ctx.r26.u64 = ctx.r26.u64 + ctx.r3.u64;
	// add r27,r27,r4
	ctx.r27.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fsubs f26,f8,f4
	ctx.f26.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// mulli r20,r6,44
	ctx.r20.s64 = ctx.r6.s64 * 44;
	// fadds f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// fadds f4,f6,f5
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f5.f64));
	// fadds f23,f21,f25
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// lfs f5,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// lfs f19,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f21,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfs f17,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// add r18,r20,r3
	ctx.r18.u64 = ctx.r20.u64 + ctx.r3.u64;
	// add r21,r21,r4
	ctx.r21.u64 = ctx.r21.u64 + ctx.r4.u64;
	// add r20,r20,r4
	ctx.r20.u64 = ctx.r20.u64 + ctx.r4.u64;
	// stfs f14,-352(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfsx f14,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-316(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fadds f14,f21,f22
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// fsubs f22,f20,f19
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfs f22,-348(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fadds f22,f18,f5
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f5.f64));
	// fsubs f5,f5,f18
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f18.f64));
	// fadds f19,f19,f20
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fmuls f21,f21,f12
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmuls f20,f5,f12
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f19,f19,f12
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f5,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f5.f64 = double(temp.f32);
	// fadds f18,f5,f15
	ctx.f18.f64 = double(float(ctx.f5.f64 + ctx.f15.f64));
	// stfs f18,-344(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fsubs f18,f15,f5
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f5.f64));
	// lfs f15,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f15.f64 = double(temp.f32);
	// lfs f5,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f15,f15,f5
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f5.f64));
	// stfs f15,-340(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f15,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f15.f64 = double(temp.f32);
	// fadds f5,f5,f15
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f15.f64));
	// fsubs f15,f14,f7
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f7.f64));
	// stfs f15,-316(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fadds f15,f22,f17
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f15,-352(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f15,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f14,f14,f11,f7
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 + ctx.f7.f64));
	// lfs f7,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// fmadds f16,f7,f11,f16
	ctx.f16.f64 = double(float(ctx.f7.f64 * ctx.f11.f64 + ctx.f16.f64));
	// fnmsubs f22,f22,f11,f17
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f11.f64 - ctx.f17.f64)));
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// stfs f5,-312(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f5,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// lfs f7,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f7,f5,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// stfs f7,-348(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f7,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f17,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f7
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f7.f64));
	// stfs f17,-332(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f17,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f5,f17,f11,f5
	ctx.f5.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f5.f64));
	// lfs f17,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f7,f17,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f17.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// lfs f17,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f24
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f24.f64));
	// stfs f17,-344(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f17,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f24,f24,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f17.f64));
	// stfs f24,-336(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f24,f14,f29
	ctx.f24.f64 = double(float(ctx.f14.f64 + ctx.f29.f64));
	// stfs f24,-324(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fadds f24,f16,f20
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f24,-320(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f24,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f24.f64 = double(temp.f32);
	// lfs f17,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f24
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f24.f64));
	// stfs f17,-340(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f17,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f24,f17,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 - ctx.f24.f64));
	// lfs f17,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f17.f64 = double(temp.f32);
	// stfs f24,-328(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fadds f24,f15,f17
	ctx.f24.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,-332(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f15,f7,f30
	ctx.f15.f64 = double(float(ctx.f7.f64 - ctx.f30.f64));
	// stfs f15,-316(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fsubs f17,f5,f3
	ctx.f17.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// lfs f15,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// stfs f15,-348(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// stfs f17,-304(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f15,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f24,f15
	ctx.f15.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// stfs f15,-352(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f15,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,-300(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fadds f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f30.f64));
	// lfs f15,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f30,f20,f16
	ctx.f30.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// lfs f17,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f19,f22
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f17,-296(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f17,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f17.f64 = double(temp.f32);
	// fadds f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// fsubs f24,f17,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 - ctx.f24.f64));
	// lfs f17,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f23,f23,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f17.f64));
	// lfs f15,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f15,f15,f10,f27
	ctx.f15.f64 = double(float(-(ctx.f15.f64 * ctx.f10.f64 - ctx.f27.f64)));
	// stfs f15,-340(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f17,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f16,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f14.f64));
	// fmuls f24,f24,f9
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// stfs f24,-344(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fmuls f23,f23,f9
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// stfs f23,-308(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f24,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f15,f24,f13
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// lfs f24,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f24,f24,f10,f28
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f10.f64 - ctx.f28.f64)));
	// fadds f28,f23,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// stfs f28,0(r3)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f28,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// stfs f28,0(r4)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f28,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f28.f64 = double(temp.f32);
	// lfs f23,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f28,f28,f0,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 - ctx.f17.f64));
	// fmuls f17,f23,f0
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// lfs f27,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f23,f25,f0,f15
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 - ctx.f15.f64));
	// stfs f23,-352(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f23,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f23,f0
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fadds f23,f18,f2
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f2.f64));
	// stfs f23,-332(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f2,f2,f18
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f18.f64));
	// fadds f23,f21,f1
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// fsubs f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// fmadds f3,f25,f13,f17
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f17.f64));
	// lfs f17,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f17.f64 = double(temp.f32);
	// fadds f25,f16,f31
	ctx.f25.f64 = double(float(ctx.f16.f64 + ctx.f31.f64));
	// fsubs f31,f31,f16
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f16.f64));
	// fmadds f17,f17,f13,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f15.f64));
	// fadds f15,f30,f7
	ctx.f15.f64 = double(float(ctx.f30.f64 + ctx.f7.f64));
	// lfs f19,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f21,f19,f18
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fsubs f18,f24,f16
	ctx.f18.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// fadds f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// fadds f14,f18,f28
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// stfs f14,-308(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fsubs f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// lfs f18,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f21,f18
	ctx.f18.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f28,-328(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f28,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// lfs f16,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f23,f16
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f16.f64));
	// fmuls f14,f28,f18
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfs f18,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// stfs f28,-308(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fmsubs f18,f27,f18,f14
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f18.f64 - ctx.f14.f64));
	// stfsx f18,r7,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// lfs f18,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f28,f21,f18
	ctx.f28.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// lfs f14,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f28,f27,f28,f14
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f28.f64 + ctx.f14.f64));
	// fsubs f18,f19,f3
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f3.f64));
	// stfsx f28,r7,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f27,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f30.f64));
	// lfs f28,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f23
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f23.f64));
	// fmuls f14,f27,f18
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// fadds f18,f24,f17
	ctx.f18.f64 = double(float(ctx.f24.f64 + ctx.f17.f64));
	// fsubs f24,f24,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f17.f64));
	// fmuls f27,f27,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// stfs f27,-308(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fmsubs f18,f28,f18,f14
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f18.f64 - ctx.f14.f64));
	// stfsx f18,r9,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f18,f20,f25
	ctx.f18.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// fsubs f27,f19,f3
	ctx.f27.f64 = double(float(ctx.f19.f64 - ctx.f3.f64));
	// fadds f3,f19,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 + ctx.f3.f64));
	// lfs f19,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f14.f64 = double(temp.f32);
	// stfs f18,-308(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fmadds f28,f28,f27,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f27.f64 + ctx.f14.f64));
	// fadds f14,f29,f5
	ctx.f14.f64 = double(float(ctx.f29.f64 + ctx.f5.f64));
	// stfs f14,-312(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f27,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f5,f5,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f29.f64));
	// fadds f27,f21,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// stfsx f28,r9,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f29,f25,f20
	ctx.f29.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// lfs f21,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// lfs f28,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f28.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// fmuls f17,f21,f27
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f27.f64));
	// fadds f20,f14,f4
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f4.f64));
	// fnmsubs f4,f14,f10,f4
	ctx.f4.f64 = double(float(-(ctx.f14.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f25,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f16,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 - ctx.f25.f64));
	// lfs f23,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f21,f19
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f19.f64));
	// fmsubs f19,f28,f19,f17
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f19.f64 - ctx.f17.f64));
	// stfsx f19,r29,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fadds f21,f18,f26
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f26.f64));
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// fmuls f19,f7,f13
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmuls f17,f7,f0
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f25,f25,f9
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// fmadds f28,f28,f27,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f27.f64 + ctx.f16.f64));
	// stfsx f28,r29,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fnmsubs f27,f18,f10,f26
	ctx.f27.f64 = double(float(-(ctx.f18.f64 * ctx.f10.f64 - ctx.f26.f64)));
	// lfs f26,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f18,f29,f13
	ctx.f18.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// lfs f28,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f29,f0
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f23,f23,f9
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// fmsubs f7,f5,f0,f19
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 - ctx.f19.f64));
	// fmadds f5,f5,f13,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fmuls f17,f26,f24
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// fmsubs f29,f30,f0,f18
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 - ctx.f18.f64));
	// fmuls f18,f26,f3
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// fsubs f26,f27,f25
	ctx.f26.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// fsubs f19,f4,f23
	ctx.f19.f64 = double(float(ctx.f4.f64 - ctx.f23.f64));
	// fadds f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f25.f64));
	// fmadds f3,f28,f3,f17
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f3.f64 + ctx.f17.f64));
	// fadds f4,f4,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f23.f64));
	// fmadds f30,f30,f13,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 + ctx.f16.f64));
	// fmsubs f25,f28,f24,f18
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f24.f64 - ctx.f18.f64));
	// stfsx f25,r5,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// stfsx f3,r5,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// fadds f25,f26,f7
	ctx.f25.f64 = double(float(ctx.f26.f64 + ctx.f7.f64));
	// lfs f28,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f24,f19,f29
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f29.f64));
	// fmuls f23,f28,f20
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f20.f64));
	// lfs f3,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f28,f21
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// fmsubs f23,f3,f21,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f21.f64 - ctx.f23.f64));
	// stfsx f23,r8,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fmadds f3,f3,f20,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f20.f64 + ctx.f28.f64));
	// stfsx f3,r8,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f28.f64 = double(temp.f32);
	// lfs f3,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f28,f24
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f24.f64));
	// fadds f20,f1,f2
	ctx.f20.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fadds f21,f22,f31
	ctx.f21.f64 = double(float(ctx.f22.f64 + ctx.f31.f64));
	// fmuls f17,f28,f25
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fsubs f28,f27,f5
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f5.f64));
	// fadds f5,f27,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 + ctx.f5.f64));
	// fmsubs f27,f3,f25,f18
	ctx.f27.f64 = double(float(ctx.f3.f64 * ctx.f25.f64 - ctx.f18.f64));
	// stfsx f27,r28,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fsubs f7,f26,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 - ctx.f7.f64));
	// lfs f26,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f26.f64 = double(temp.f32);
	// lfs f27,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f27.f64 = double(temp.f32);
	// fadds f23,f4,f30
	ctx.f23.f64 = double(float(ctx.f4.f64 + ctx.f30.f64));
	// fsubs f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// lfs f25,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f25.f64 = double(temp.f32);
	// fadds f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// lfs f26,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fadds f30,f20,f21
	ctx.f30.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// fsubs f1,f31,f22
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f22.f64));
	// fsubs f31,f20,f21
	ctx.f31.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// fmadds f3,f3,f24,f17
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f24.f64 + ctx.f17.f64));
	// stfsx f3,r28,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f25,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f25.f64 = double(temp.f32);
	// fadds f29,f19,f29
	ctx.f29.f64 = double(float(ctx.f19.f64 + ctx.f29.f64));
	// fmuls f22,f25,f23
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f23.f64));
	// lfs f3,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f25,f25,f28
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f28.f64));
	// fadds f24,f30,f8
	ctx.f24.f64 = double(float(ctx.f30.f64 + ctx.f8.f64));
	// fnmsubs f8,f30,f10,f8
	ctx.f8.f64 = double(float(-(ctx.f30.f64 * ctx.f10.f64 - ctx.f8.f64)));
	// fmuls f30,f26,f13
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmuls f26,f26,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmuls f31,f31,f9
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f9.f64));
	// fmuls f21,f1,f13
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fmuls f20,f1,f0
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmsubs f1,f3,f28,f22
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f28.f64 - ctx.f22.f64));
	// stfsx f1,r31,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmadds f3,f3,f23,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f23.f64 + ctx.f25.f64));
	// stfsx f3,r31,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f1,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f30,f27,f0,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 - ctx.f30.f64));
	// fmadds f28,f27,f13,f26
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 + ctx.f26.f64));
	// fadds f26,f8,f31
	ctx.f26.f64 = double(float(ctx.f8.f64 + ctx.f31.f64));
	// fsubs f8,f8,f31
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f31.f64));
	// fmuls f31,f1,f4
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmsubs f27,f2,f0,f21
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f21.f64));
	// fmadds f2,f2,f13,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f20.f64));
	// fmsubs f5,f3,f5,f31
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f5.f64 - ctx.f31.f64));
	// stfsx f5,r10,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f5,f3,f4,f1
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f4.f64 + ctx.f1.f64));
	// stfsx f5,r10,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f1,f8,f30
	ctx.f1.f64 = double(float(ctx.f8.f64 - ctx.f30.f64));
	// fmuls f3,f4,f29
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// lfs f5,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f4,f7
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// fadds f8,f8,f30
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f30.f64));
	// fsubs f31,f26,f28
	ctx.f31.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// fmsubs f7,f5,f7,f3
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 - ctx.f3.f64));
	// stfsx f7,r30,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmadds f7,f5,f29,f4
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f29.f64 + ctx.f4.f64));
	// lfs f3,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f4.f64 = double(temp.f32);
	// add r3,r16,r3
	ctx.r3.u64 = ctx.r16.u64 + ctx.r3.u64;
	// stfsx f7,r30,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f29,f4,f3
	ctx.f29.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fadds f7,f4,f3
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// lfs f4,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f4.f64 = double(temp.f32);
	// fadds f3,f26,f28
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// lfs f5,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f28,f4,f24
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f24.f64));
	// subf r4,r16,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r16.s64;
	// fmuls f30,f29,f9
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f9.f64));
	// fadds f29,f7,f6
	ctx.f29.f64 = double(float(ctx.f7.f64 + ctx.f6.f64));
	// fnmsubs f7,f7,f10,f6
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f10.f64 - ctx.f6.f64)));
	// fmuls f4,f4,f29
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// fadds f6,f7,f30
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f30.f64));
	// fmsubs f4,f5,f24,f4
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 - ctx.f4.f64));
	// stfs f4,0(r25)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fmadds f5,f5,f29,f28
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f29.f64 + ctx.f28.f64));
	// fsubs f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f30.f64));
	// stfs f5,0(r27)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fsubs f30,f6,f2
	ctx.f30.f64 = double(float(ctx.f6.f64 - ctx.f2.f64));
	// lfs f4,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f29,f4,f3
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f5,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f5.f64 = double(temp.f32);
	// fadds f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// addic. r17,r17,-1
	ctx.xer.ca = ctx.r17.u32 > 0;
	ctx.r17.s64 = ctx.r17.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r17.s32, 0, ctx.xer);
	// fadds f2,f7,f27
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f27.f64));
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fsubs f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// fmsubs f4,f5,f3,f4
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f3.f64 - ctx.f4.f64));
	// stfs f4,0(r26)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fmadds f5,f5,f30,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64 + ctx.f29.f64));
	// stfs f5,0(r22)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// lfs f4,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f4,f2
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f4,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// fmsubs f3,f5,f1,f3
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 - ctx.f3.f64));
	// stfs f3,0(r24)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fmadds f5,f5,f2,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f2.f64 + ctx.f4.f64));
	// stfs f5,0(r23)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// lfs f4,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f4,f7
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// lfs f5,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f4,f8
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// fmsubs f8,f5,f8,f3
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f8.f64 - ctx.f3.f64));
	// stfs f8,0(r19)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// fmadds f8,f5,f7,f4
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 + ctx.f4.f64));
	// stfs f8,0(r21)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// lfs f7,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f5,f7,f6
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// lfs f8,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// addi r11,r11,112
	ctx.r11.s64 = ctx.r11.s64 + 112;
	// fmsubs f5,f8,f31,f5
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f31.f64 - ctx.f5.f64));
	// stfs f5,0(r18)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// fmadds f8,f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f6.f64 + ctx.f7.f64));
	// stfs f8,0(r20)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// lwz r10,3532(r15)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r15.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d38700
	if (!ctx.cr0.eq) goto loc_82D38700;
loc_82D38E00:
	// addi r12,r1,-144
	ctx.r12.s64 = ctx.r1.s64 + -144;
	// bl 0x82e28f2c
	ctx.lr = 0x82D38E08;
	__restfpr_14(ctx, base);
	// b 0x82e28e84
	__restgprlr_15(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D38E10"))) PPC_WEAK_FUNC(sub_82D38E10);
PPC_FUNC_IMPL(__imp__sub_82D38E10) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-5296
	ctx.r5.s64 = ctx.r11.s64 + -5296;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,-31072
	ctx.r4.s64 = ctx.r11.s64 + -31072;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D38E28"))) PPC_WEAK_FUNC(sub_82D38E28);
PPC_FUNC_IMPL(__imp__sub_82D38E28) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e40
	ctx.lr = 0x82D38E30;
	__savegprlr_18(ctx, base);
	// addi r12,r1,-120
	ctx.r12.s64 = ctx.r1.s64 + -120;
	// bl 0x82e28eec
	ctx.lr = 0x82D38E38;
	__savefpr_17(ctx, base);
	// mulli r11,r7,88
	ctx.r11.s64 = ctx.r7.s64 * 88;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-88
	ctx.r11.s64 = ctx.r11.s64 + -88;
	// bge cr6,0x82d3923c
	if (!ctx.cr6.lt) goto loc_82D3923C;
	// rlwinm r19,r9,2,0,29
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// subf r29,r7,r8
	ctx.r29.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r18,-32234
	ctx.r18.s64 = -2112487424;
	// lfs f13,-28552(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f0.f64 = double(temp.f32);
loc_82D38E68:
	// rlwinm r28,r6,4,0,27
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f12,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mulli r9,r6,12
	ctx.r9.s64 = ctx.r6.s64 * 12;
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f7,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f5,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// add r25,r28,r3
	ctx.r25.u64 = ctx.r28.u64 + ctx.r3.u64;
	// add r28,r28,r4
	ctx.r28.u64 = ctx.r28.u64 + ctx.r4.u64;
	// mulli r27,r6,28
	ctx.r27.s64 = ctx.r6.s64 * 28;
	// lfs f8,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fadds f26,f7,f8
	ctx.f26.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// lfs f6,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// fsubs f7,f6,f12
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// add r24,r27,r4
	ctx.r24.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fadds f25,f12,f6
	ctx.f25.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
	// mulli r10,r6,44
	ctx.r10.s64 = ctx.r6.s64 * 44;
	// lfs f4,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f10,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// add r27,r27,r3
	ctx.r27.u64 = ctx.r27.u64 + ctx.r3.u64;
	// rlwinm r30,r6,5,0,26
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r26,r6,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r6,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// add r22,r26,r4
	ctx.r22.u64 = ctx.r26.u64 + ctx.r4.u64;
	// add r23,r30,r4
	ctx.r23.u64 = ctx.r30.u64 + ctx.r4.u64;
	// lfs f3,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// mulli r7,r6,20
	ctx.r7.s64 = ctx.r6.s64 * 20;
	// lfsx f2,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f12,f10,f3
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f3.f64));
	// fsubs f6,f3,f10
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// fadds f3,f2,f4
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// lfsx f30,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f10,f8,f0
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// lfs f31,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f8,f7,f0
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f1,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f7,f4,f2
	ctx.f7.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// lfsx f29,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f4,f30,f31
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// lfsx f23,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f2,f31,f30
	ctx.f2.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// mulli r21,r6,40
	ctx.r21.s64 = ctx.r6.s64 * 40;
	// fadds f31,f26,f11
	ctx.f31.f64 = double(float(ctx.f26.f64 + ctx.f11.f64));
	// fnmsubs f11,f26,f13,f11
	ctx.f11.f64 = double(float(-(ctx.f26.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// fadds f30,f25,f5
	ctx.f30.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// fnmsubs f5,f25,f13,f5
	ctx.f5.f64 = double(float(-(ctx.f25.f64 * ctx.f13.f64 - ctx.f5.f64)));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fsubs f24,f1,f12
	ctx.f24.f64 = double(float(ctx.f1.f64 - ctx.f12.f64));
	// fmadds f12,f12,f13,f1
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + ctx.f1.f64));
	// add r26,r26,r3
	ctx.r26.u64 = ctx.r26.u64 + ctx.r3.u64;
	// fadds f26,f7,f9
	ctx.f26.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// add r20,r21,r3
	ctx.r20.u64 = ctx.r21.u64 + ctx.r3.u64;
	// fnmsubs f9,f7,f13,f9
	ctx.f9.f64 = double(float(-(ctx.f7.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// mulli r5,r6,24
	ctx.r5.s64 = ctx.r6.s64 * 24;
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fsubs f7,f11,f3
	ctx.f7.f64 = double(float(ctx.f11.f64 - ctx.f3.f64));
	// lfs f21,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fadds f11,f11,f3
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f3.f64));
	// lfsx f28,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f3,f5,f6
	ctx.f3.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// lfsx f25,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f6.f64));
	// mulli r31,r6,36
	ctx.r31.s64 = ctx.r6.s64 * 36;
	// fadds f5,f12,f8
	ctx.f5.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// fsubs f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// fadds f8,f9,f10
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// fadds f9,f4,f29
	ctx.f9.f64 = double(float(ctx.f4.f64 + ctx.f29.f64));
	// fnmsubs f4,f4,f13,f29
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f29.f64)));
	// lfsx f29,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f27,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// add r21,r21,r4
	ctx.r21.u64 = ctx.r21.u64 + ctx.r4.u64;
	// lfsx f22,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fadds f1,f9,f31
	ctx.f1.f64 = double(float(ctx.f9.f64 + ctx.f31.f64));
	// fsubs f9,f31,f9
	ctx.f9.f64 = double(float(ctx.f31.f64 - ctx.f9.f64));
	// lfs f31,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fadds f19,f29,f31
	ctx.f19.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// fsubs f31,f31,f29
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f29.f64));
	// fsubs f29,f27,f21
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// fadds f21,f21,f27
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// fadds f18,f25,f20
	ctx.f18.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// fsubs f20,f25,f20
	ctx.f20.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// fadds f27,f19,f23
	ctx.f27.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// fnmsubs f23,f19,f13,f23
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f13.f64 - ctx.f23.f64)));
	// fmuls f31,f31,f0
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f25,f21,f0
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fsubs f19,f18,f22
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// fmuls f21,f20,f0
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fsubs f20,f29,f28
	ctx.f20.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fadds f17,f27,f30
	ctx.f17.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// fmadds f29,f29,f13,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f13.f64 + ctx.f28.f64));
	// fmadds f28,f18,f13,f22
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f22.f64));
	// fadds f27,f4,f25
	ctx.f27.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// fsubs f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f25.f64));
	// fadds f25,f23,f21
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// fadds f22,f20,f26
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f26.f64));
	// fadds f21,f19,f24
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// fsubs f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f20.f64));
	// fadds f20,f17,f1
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f1.f64));
	// stfs f20,0(r3)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f20,f2,f29
	ctx.f20.f64 = double(float(ctx.f2.f64 - ctx.f29.f64));
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// fadds f2,f29,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fsubs f29,f31,f28
	ctx.f29.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// fadds f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// fsubs f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f17.f64));
	// fadds f28,f21,f22
	ctx.f28.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f28,0(r4)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f21,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// lfs f28,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f19,f9,f24
	ctx.f19.f64 = double(float(ctx.f9.f64 - ctx.f24.f64));
	// fadds f9,f24,f9
	ctx.f9.f64 = double(float(ctx.f24.f64 + ctx.f9.f64));
	// fadds f24,f26,f30
	ctx.f24.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// fsubs f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f30.f64));
	// fmuls f26,f21,f22
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f22.f64));
	// fmuls f21,f21,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64));
	// fmsubs f1,f28,f1,f26
	ctx.f1.f64 = double(float(ctx.f28.f64 * ctx.f1.f64 - ctx.f26.f64));
	// stfsx f1,r5,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fmadds f1,f28,f22,f21
	ctx.f1.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 + ctx.f21.f64));
	// stfsx f1,r5,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f28.f64 = double(temp.f32);
	// fadds f26,f31,f12
	ctx.f26.f64 = double(float(ctx.f31.f64 + ctx.f12.f64));
	// fmuls f18,f28,f24
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f24.f64));
	// lfs f1,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f17,f28,f19
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fsubs f28,f11,f4
	ctx.f28.f64 = double(float(ctx.f11.f64 - ctx.f4.f64));
	// fadds f22,f2,f10
	ctx.f22.f64 = double(float(ctx.f2.f64 + ctx.f10.f64));
	// fsubs f21,f6,f23
	ctx.f21.f64 = double(float(ctx.f6.f64 - ctx.f23.f64));
	// fadds f11,f4,f11
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f11.f64));
	// fadds f6,f23,f6
	ctx.f6.f64 = double(float(ctx.f23.f64 + ctx.f6.f64));
	// fsubs f10,f10,f2
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f2.f64));
	// fsubs f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f31.f64));
	// fmsubs f19,f1,f19,f18
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f19.f64 - ctx.f18.f64));
	// stfsx f19,r31,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmadds f4,f1,f24,f17
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f24.f64 + ctx.f17.f64));
	// stfsx f4,r31,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f2,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f1,f28,f26
	ctx.f1.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// fmuls f23,f2,f30
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// lfs f4,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f2,f2,f9
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// fadds f31,f26,f28
	ctx.f31.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fadds f28,f21,f22
	ctx.f28.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f24,f11,f6
	ctx.f24.f64 = double(float(ctx.f11.f64 - ctx.f6.f64));
	// fadds f11,f6,f11
	ctx.f11.f64 = double(float(ctx.f6.f64 + ctx.f11.f64));
	// fsubs f6,f10,f12
	ctx.f6.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// fadds f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// fsubs f26,f22,f21
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fmsubs f10,f4,f9,f23
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 - ctx.f23.f64));
	// stfsx f10,r9,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmadds f10,f4,f30,f2
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f30.f64 + ctx.f2.f64));
	// stfsx f10,r9,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f9,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f4,f9,f28
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// lfs f10,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// fmsubs f4,f10,f1,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f1.f64 - ctx.f4.f64));
	// stfsx f4,r7,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fmadds f10,f10,f28,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 + ctx.f9.f64));
	// stfsx f10,r7,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f9,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f9.f64 = double(temp.f32);
	// fadds f2,f20,f8
	ctx.f2.f64 = double(float(ctx.f20.f64 + ctx.f8.f64));
	// fmuls f4,f9,f26
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// lfs f10,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// fadds f1,f29,f5
	ctx.f1.f64 = double(float(ctx.f29.f64 + ctx.f5.f64));
	// fsubs f8,f8,f20
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f20.f64));
	// fmsubs f4,f10,f31,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f31.f64 - ctx.f4.f64));
	// stfsx f4,r10,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f10,f10,f26,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f26.f64 + ctx.f9.f64));
	// stfsx f10,r10,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f9,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f4,f9,f6
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f9,f24
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f24.f64));
	// fmsubs f4,f10,f24,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f24.f64 - ctx.f4.f64));
	// stfsx f4,r8,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fmadds f10,f10,f6,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f6.f64 + ctx.f9.f64));
	// stfsx f10,r8,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f9,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f9.f64 = double(temp.f32);
	// fadds f4,f25,f3
	ctx.f4.f64 = double(float(ctx.f25.f64 + ctx.f3.f64));
	// fmuls f6,f9,f12
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// lfs f10,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f31,f9,f11
	ctx.f31.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// subf r4,r19,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r19.s64;
	// fsubs f9,f5,f29
	ctx.f9.f64 = double(float(ctx.f5.f64 - ctx.f29.f64));
	// fmsubs f6,f10,f11,f6
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 - ctx.f6.f64));
	// stfsx f6,r30,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f27,f7
	ctx.f6.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// add r3,r19,r3
	ctx.r3.u64 = ctx.r19.u64 + ctx.r3.u64;
	// fsubs f11,f7,f27
	ctx.f11.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// fsubs f7,f3,f25
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f25.f64));
	// fadds f3,f1,f2
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fmadds f12,f10,f12,f31
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + ctx.f31.f64));
	// stfs f12,0(r23)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// lfs f10,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f5,f6,f4
	ctx.f5.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fsubs f4,f2,f1
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fsubs f2,f11,f9
	ctx.f2.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// fadds f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fadds f9,f7,f8
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// fmuls f7,f10,f5
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f5.f64));
	// fmuls f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// fmsubs f10,f12,f5,f10
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f5.f64 - ctx.f10.f64));
	// stfs f10,0(r20)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// fmadds f12,f12,f4,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f4.f64 + ctx.f7.f64));
	// stfs f12,0(r21)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// lfs f10,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f7,f10,f3
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f12,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// fmsubs f7,f12,f6,f7
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f6.f64 - ctx.f7.f64));
	// stfs f7,0(r25)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fmadds f12,f12,f3,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 + ctx.f10.f64));
	// stfs f12,0(r28)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// lfs f10,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f7,f10,f9
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f2
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// fmsubs f7,f12,f2,f7
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 - ctx.f7.f64));
	// stfs f7,0(r26)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fmadds f12,f12,f9,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 + ctx.f10.f64));
	// stfs f12,0(r22)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// lfs f10,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f10,f8
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f12,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f11
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// addi r11,r11,88
	ctx.r11.s64 = ctx.r11.s64 + 88;
	// fmsubs f11,f12,f11,f9
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 - ctx.f9.f64));
	// stfs f11,0(r27)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fmadds f12,f12,f8,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 + ctx.f10.f64));
	// stfs f12,0(r24)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// lwz r10,3532(r18)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r18.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d38e68
	if (!ctx.cr0.eq) goto loc_82D38E68;
loc_82D3923C:
	// addi r12,r1,-120
	ctx.r12.s64 = ctx.r1.s64 + -120;
	// bl 0x82e28f38
	ctx.lr = 0x82D39244;
	__restfpr_17(ctx, base);
	// b 0x82e28e90
	__restgprlr_18(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D39248"))) PPC_WEAK_FUNC(sub_82D39248);
PPC_FUNC_IMPL(__imp__sub_82D39248) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-5240
	ctx.r5.s64 = ctx.r11.s64 + -5240;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,-29144
	ctx.r4.s64 = ctx.r11.s64 + -29144;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D39260"))) PPC_WEAK_FUNC(sub_82D39260);
PPC_FUNC_IMPL(__imp__sub_82D39260) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e50
	ctx.lr = 0x82D39268;
	__savegprlr_22(ctx, base);
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82e28ee8
	ctx.lr = 0x82D39270;
	__savefpr_16(ctx, base);
	// mulli r11,r7,72
	ctx.r11.s64 = ctx.r7.s64 * 72;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-72
	ctx.r11.s64 = ctx.r11.s64 + -72;
	// bge cr6,0x82d395fc
	if (!ctx.cr6.lt) goto loc_82D395FC;
	// subf r24,r7,r8
	ctx.r24.s64 = ctx.r8.s64 - ctx.r7.s64;
	// rlwinm r23,r9,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32255
	ctx.r7.s64 = -2113863680;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f11,-12288(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -12288);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,-7584(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -7584);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7588(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -7588);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,-7592(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7592);
	ctx.f12.f64 = double(temp.f32);
loc_82D392B0:
	// rlwinm r10,r6,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f10,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// rlwinm r9,r6,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f9,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// mulli r29,r6,12
	ctx.r29.s64 = ctx.r6.s64 * 12;
	// lfsx f8,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f6,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fadds f21,f10,f8
	ctx.f21.f64 = double(float(ctx.f10.f64 + ctx.f8.f64));
	// lfsx f7,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 - ctx.f10.f64));
	// lfsx f3,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// rlwinm r28,r6,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// add r27,r29,r4
	ctx.r27.u64 = ctx.r29.u64 + ctx.r4.u64;
	// fadds f6,f3,f9
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f9.f64));
	// add r26,r28,r3
	ctx.r26.u64 = ctx.r28.u64 + ctx.r3.u64;
	// fsubs f9,f9,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f3.f64));
	// mulli r30,r6,36
	ctx.r30.s64 = ctx.r6.s64 * 36;
	// lfs f5,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fadds f3,f2,f5
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// lfsx f30,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// add r29,r29,r3
	ctx.r29.u64 = ctx.r29.u64 + ctx.r3.u64;
	// add r28,r28,r4
	ctx.r28.u64 = ctx.r28.u64 + ctx.r4.u64;
	// mulli r8,r6,20
	ctx.r8.s64 = ctx.r6.s64 * 20;
	// lfs f4,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f1,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fadds f2,f4,f1
	ctx.f2.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// lfsx f29,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// lfsx f28,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// add r25,r30,r4
	ctx.r25.u64 = ctx.r30.u64 + ctx.r4.u64;
	// fadds f20,f10,f5
	ctx.f20.f64 = double(float(ctx.f10.f64 + ctx.f5.f64));
	// mulli r7,r6,28
	ctx.r7.s64 = ctx.r6.s64 * 28;
	// fsubs f10,f10,f5
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f5.f64));
	// lfs f31,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f1,f31,f29
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f29.f64));
	// lfsx f26,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f31,f29,f31
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// lfsx f27,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// rlwinm r5,r6,5,0,26
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// fsubs f29,f28,f30
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// mulli r31,r6,24
	ctx.r31.s64 = ctx.r6.s64 * 24;
	// fadds f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// fsubs f28,f27,f26
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// fadds f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fadds f18,f4,f7
	ctx.f18.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// fadds f19,f2,f8
	ctx.f19.f64 = double(float(ctx.f2.f64 + ctx.f8.f64));
	// lfsx f25,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f7,f7,f4
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// lfsx f24,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f8,f8,f2
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f2.f64));
	// lfsx f22,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f26,f25,f24
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// lfsx f23,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fsubs f24,f23,f22
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fadds f22,f21,f3
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f3.f64));
	// fsubs f3,f21,f3
	ctx.f3.f64 = double(float(ctx.f21.f64 - ctx.f3.f64));
	// fsubs f21,f18,f20
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// fadds f5,f20,f18
	ctx.f5.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// fadds f20,f29,f26
	ctx.f20.f64 = double(float(ctx.f29.f64 + ctx.f26.f64));
	// fsubs f29,f29,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// fsubs f18,f30,f25
	ctx.f18.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// fadds f4,f22,f19
	ctx.f4.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// fsubs f2,f19,f22
	ctx.f2.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// fmuls f22,f21,f12
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fadds f21,f24,f28
	ctx.f21.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// fsubs f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// fsubs f19,f27,f23
	ctx.f19.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// fmuls f24,f3,f13
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f17,f3,f0
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fadds f26,f4,f6
	ctx.f26.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// stfs f26,0(r3)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fnmsubs f6,f4,f11,f6
	ctx.f6.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 - ctx.f6.f64)));
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fadds f26,f5,f9
	ctx.f26.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// fadds f4,f30,f25
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// fmsubs f30,f8,f0,f24
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f24.f64));
	// fadds f3,f23,f27
	ctx.f3.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// fsubs f24,f21,f20
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fmuls f23,f29,f13
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// fadds f27,f20,f21
	ctx.f27.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f20,f19,f18
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f25,f18,f19
	ctx.f25.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fmuls f21,f29,f0
	ctx.f21.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmadds f8,f8,f13,f17
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fnmsubs f9,f5,f11,f9
	ctx.f9.f64 = double(float(-(ctx.f5.f64 * ctx.f11.f64 - ctx.f9.f64)));
	// fmuls f5,f10,f13
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmuls f29,f24,f12
	ctx.f29.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fmsubs f24,f28,f0,f23
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 - ctx.f23.f64));
	// fsubs f23,f6,f2
	ctx.f23.f64 = double(float(ctx.f6.f64 - ctx.f2.f64));
	// fadds f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fmuls f2,f20,f12
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fadds f20,f25,f31
	ctx.f20.f64 = double(float(ctx.f25.f64 + ctx.f31.f64));
	// fmadds f28,f28,f13,f21
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 + ctx.f21.f64));
	// fadds f21,f27,f1
	ctx.f21.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// stfs f21,0(r4)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fnmsubs f1,f27,f11,f1
	ctx.f1.f64 = double(float(-(ctx.f27.f64 * ctx.f11.f64 - ctx.f1.f64)));
	// lfs f19,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f19,f26
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f26.f64));
	// lfs f21,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f31,f25,f11,f31
	ctx.f31.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f31.f64)));
	// fmsubs f5,f7,f0,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 - ctx.f5.f64));
	// fsubs f27,f23,f24
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// fmuls f17,f19,f20
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f20.f64));
	// fsubs f18,f6,f28
	ctx.f18.f64 = double(float(ctx.f6.f64 - ctx.f28.f64));
	// fadds f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f28.f64));
	// fsubs f19,f1,f29
	ctx.f19.f64 = double(float(ctx.f1.f64 - ctx.f29.f64));
	// fadds f1,f1,f29
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f29.f64));
	// fmuls f28,f4,f13
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmsubs f29,f21,f26,f17
	ctx.f29.f64 = double(float(ctx.f21.f64 * ctx.f26.f64 - ctx.f17.f64));
	// stfsx f29,r8,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fmadds f29,f21,f20,f16
	ctx.f29.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f16.f64));
	// stfsx f29,r8,r4
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f26.f64 = double(temp.f32);
	// fadds f21,f19,f30
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f30.f64));
	// lfs f29,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f17,f26,f27
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fadds f20,f1,f8
	ctx.f20.f64 = double(float(ctx.f1.f64 + ctx.f8.f64));
	// fsubs f8,f1,f8
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f8.f64));
	// fsubs f30,f19,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 - ctx.f30.f64));
	// fmadds f4,f3,f13,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f4.f64));
	// fmuls f26,f26,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// fmsubs f27,f29,f27,f26
	ctx.f27.f64 = double(float(ctx.f29.f64 * ctx.f27.f64 - ctx.f26.f64));
	// stfsx f27,r9,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmadds f29,f29,f21,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f21.f64 + ctx.f17.f64));
	// stfsx f29,r9,r4
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f27,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f26,f27,f20
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// lfs f29,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f26,f29,f18,f26
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f18.f64 - ctx.f26.f64));
	// stfsx f26,r31,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmuls f26,f27,f18
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// fadds f27,f23,f24
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fmadds f1,f29,f20,f26
	ctx.f1.f64 = double(float(ctx.f29.f64 * ctx.f20.f64 + ctx.f26.f64));
	// stfsx f1,r31,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fmuls f26,f10,f0
	ctx.f26.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f29,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f10,f3,f0,f28
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f28.f64));
	// lfs f1,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f28,f29,f30
	ctx.f28.f64 = double(float(ctx.f29.f64 * ctx.f30.f64));
	// fsubs f3,f31,f2
	ctx.f3.f64 = double(float(ctx.f31.f64 - ctx.f2.f64));
	// fadds f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// fmadds f7,f7,f13,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 + ctx.f26.f64));
	// fmuls f26,f29,f27
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f27.f64));
	// fsubs f29,f9,f22
	ctx.f29.f64 = double(float(ctx.f9.f64 - ctx.f22.f64));
	// fadds f9,f9,f22
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f22.f64));
	// fmsubs f31,f1,f27,f28
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f27.f64 - ctx.f28.f64));
	// stfsx f31,r5,r3
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fsubs f27,f2,f7
	ctx.f27.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// fmadds f1,f1,f30,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64 + ctx.f26.f64));
	// stfsx f1,r5,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f1,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f1.f64 = double(temp.f32);
	// fadds f30,f3,f5
	ctx.f30.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// lfs f31,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f28,f29,f10
	ctx.f28.f64 = double(float(ctx.f29.f64 - ctx.f10.f64));
	// fadds f26,f9,f4
	ctx.f26.f64 = double(float(ctx.f9.f64 + ctx.f4.f64));
	// fmuls f25,f31,f8
	ctx.f25.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// addic. r24,r24,-1
	ctx.xer.ca = ctx.r24.u32 > 0;
	ctx.r24.s64 = ctx.r24.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// fmuls f31,f31,f6
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fsubs f9,f9,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f4.f64));
	// fadds f10,f29,f10
	ctx.f10.f64 = double(float(ctx.f29.f64 + ctx.f10.f64));
	// fadds f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// fmsubs f6,f1,f6,f25
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f6.f64 - ctx.f25.f64));
	// stfsx f6,r10,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f8,f1,f8,f31
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f8.f64 + ctx.f31.f64));
	// stfsx f8,r10,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f1,f6,f30
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f8,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fmsubs f1,f8,f28,f1
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f28.f64 - ctx.f1.f64));
	// stfsx f1,r7,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fmadds f8,f8,f30,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f30.f64 + ctx.f6.f64));
	// stfsx f8,r7,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f6.f64 = double(temp.f32);
	// subf r4,r23,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r23.s64;
	// fmuls f1,f6,f27
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f8,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f1,f8,f26,f1
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f26.f64 - ctx.f1.f64));
	// stfsx f1,r30,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmuls f1,f6,f26
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// add r3,r23,r3
	ctx.r3.u64 = ctx.r23.u64 + ctx.r3.u64;
	// fsubs f6,f3,f5
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// fmadds f8,f8,f27,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f27.f64 + ctx.f1.f64));
	// stfs f8,0(r25)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// lfs f5,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f5.f64 = double(temp.f32);
	// lfs f8,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f5,f6
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fmuls f6,f8,f6
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// fmsubs f8,f8,f10,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f10.f64 - ctx.f4.f64));
	// stfs f8,0(r29)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fmadds f10,f5,f10,f6
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 + ctx.f6.f64));
	// stfs f10,0(r27)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// lfs f8,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f8,f7
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// lfs f10,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f8,f9
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// addi r11,r11,72
	ctx.r11.s64 = ctx.r11.s64 + 72;
	// fmsubs f9,f10,f9,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 - ctx.f6.f64));
	// stfs f9,0(r26)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fmadds f10,f10,f7,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f7.f64 + ctx.f8.f64));
	// stfs f10,0(r28)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// lwz r10,3532(r22)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r22.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d392b0
	if (!ctx.cr0.eq) goto loc_82D392B0;
loc_82D395FC:
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82e28f34
	ctx.lr = 0x82D39604;
	__restfpr_16(ctx, base);
	// b 0x82e28ea0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D39608"))) PPC_WEAK_FUNC(sub_82D39608);
PPC_FUNC_IMPL(__imp__sub_82D39608) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-5184
	ctx.r5.s64 = ctx.r11.s64 + -5184;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,-28064
	ctx.r4.s64 = ctx.r11.s64 + -28064;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D39620"))) PPC_WEAK_FUNC(sub_82D39620);
PPC_FUNC_IMPL(__imp__sub_82D39620) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82D39628;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28ee4
	ctx.lr = 0x82D39630;
	__savefpr_15(ctx, base);
	// rlwinm r11,r7,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xFFFFFFC0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// addi r11,r11,-64
	ctx.r11.s64 = ctx.r11.s64 + -64;
	// bge cr6,0x82d399c4
	if (!ctx.cr6.lt) goto loc_82D399C4;
	// subf r25,r7,r8
	ctx.r25.s64 = ctx.r8.s64 - ctx.r7.s64;
	// rlwinm r24,r9,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lfs f11,-6156(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -6156);
	ctx.f11.f64 = double(temp.f32);
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lfs f12,-6160(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -6160);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f16,-5076(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -5076);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-5080(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -5080);
	ctx.f17.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f18,-6140(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -6140);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,-6144(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -6144);
	ctx.f19.f64 = double(temp.f32);
	// lfs f13,-28552(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f0.f64 = double(temp.f32);
loc_82D39690:
	// mulli r10,r6,12
	ctx.r10.s64 = ctx.r6.s64 * 12;
	// lfs f10,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// rlwinm r31,r6,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f9,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f7,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f23,f10,f7
	ctx.f23.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// lfsx f8,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// mulli r30,r6,20
	ctx.r30.s64 = ctx.r6.s64 * 20;
	// add r28,r31,r4
	ctx.r28.u64 = ctx.r31.u64 + ctx.r4.u64;
	// mulli r9,r6,24
	ctx.r9.s64 = ctx.r6.s64 * 24;
	// lfs f6,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f2,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f10,f6,f8
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// fsubs f6,f8,f6
	ctx.f6.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// lfsx f1,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// add r27,r30,r4
	ctx.r27.u64 = ctx.r30.u64 + ctx.r4.u64;
	// fmuls f8,f7,f0
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// rlwinm r29,r6,5,0,26
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r7,r6,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r5,r6,28
	ctx.r5.s64 = ctx.r6.s64 * 28;
	// lfs f5,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fadds f22,f2,f5
	ctx.f22.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// fsubs f7,f5,f2
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// lfsx f29,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f28,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fsubs f2,f29,f28
	ctx.f2.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// lfsx f31,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// add r26,r29,r4
	ctx.r26.u64 = ctx.r29.u64 + ctx.r4.u64;
	// fadds f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// add r30,r30,r3
	ctx.r30.u64 = ctx.r30.u64 + ctx.r3.u64;
	// lfsx f26,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// add r29,r29,r3
	ctx.r29.u64 = ctx.r29.u64 + ctx.r3.u64;
	// rlwinm r8,r6,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// add r31,r31,r3
	ctx.r31.u64 = ctx.r31.u64 + ctx.r3.u64;
	// lfs f25,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// lfs f4,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fadds f21,f7,f25
	ctx.f21.f64 = double(float(ctx.f7.f64 + ctx.f25.f64));
	// lfs f24,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f30,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f28,f4,f24
	ctx.f28.f64 = double(float(ctx.f4.f64 - ctx.f24.f64));
	// fadds f5,f30,f31
	ctx.f5.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// lfsx f27,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f4,f24,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f4.f64));
	// lfs f3,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f30,f31,f30
	ctx.f30.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// fadds f24,f10,f9
	ctx.f24.f64 = double(float(ctx.f10.f64 + ctx.f9.f64));
	// fmuls f31,f22,f0
	ctx.f31.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fnmsubs f10,f10,f13,f9
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// fnmsubs f9,f7,f13,f25
	ctx.f9.f64 = double(float(-(ctx.f7.f64 * ctx.f13.f64 - ctx.f25.f64)));
	// fnmsubs f22,f23,f13,f3
	ctx.f22.f64 = double(float(-(ctx.f23.f64 * ctx.f13.f64 - ctx.f3.f64)));
	// fnmsubs f25,f2,f13,f26
	ctx.f25.f64 = double(float(-(ctx.f2.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// fmuls f29,f29,f0
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fnmsubs f7,f5,f13,f27
	ctx.f7.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f27.f64)));
	// fmuls f28,f28,f0
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f30,f30,f0
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fsubs f20,f10,f31
	ctx.f20.f64 = double(float(ctx.f10.f64 - ctx.f31.f64));
	// fadds f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f31.f64));
	// fadds f31,f9,f6
	ctx.f31.f64 = double(float(ctx.f9.f64 + ctx.f6.f64));
	// fsubs f9,f9,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// fadds f6,f5,f27
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f27.f64));
	// fadds f5,f23,f3
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// fadds f3,f2,f26
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f26.f64));
	// fsubs f2,f1,f4
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// fmadds f4,f4,f13,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f1.f64));
	// fadds f26,f25,f30
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// fsubs f27,f7,f29
	ctx.f27.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// fadds f7,f29,f7
	ctx.f7.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// fsubs f23,f22,f28
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// fadds f29,f28,f22
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// fsubs f30,f25,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 - ctx.f30.f64));
	// fadds f1,f5,f6
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fsubs f5,f6,f5
	ctx.f5.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fadds f6,f2,f3
	ctx.f6.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fsubs f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f3.f64));
	// fmuls f28,f26,f18
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f18.f64));
	// fmuls f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// fsubs f2,f4,f8
	ctx.f2.f64 = double(float(ctx.f4.f64 - ctx.f8.f64));
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f25,f30,f11
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fadds f8,f4,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fmsubs f4,f27,f19,f28
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f19.f64 - ctx.f28.f64));
	// fmadds f28,f27,f18,f26
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f18.f64 + ctx.f26.f64));
	// fmuls f22,f7,f11
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// fadds f27,f1,f24
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f24.f64));
	// stfs f27,0(r3)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fnmsubs f1,f1,f13,f24
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f24.f64)));
	// fmuls f24,f2,f17
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// fadds f27,f6,f21
	ctx.f27.f64 = double(float(ctx.f6.f64 + ctx.f21.f64));
	// stfs f27,0(r4)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fnmsubs f6,f6,f13,f21
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f13.f64 - ctx.f21.f64)));
	// lfs f26,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f7,f7,f12,f25
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 - ctx.f25.f64));
	// lfs f27,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f25,f2,f16
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// fmuls f15,f29,f11
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f11.f64));
	// fmadds f30,f30,f12,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f12.f64 + ctx.f22.f64));
	// fmuls f22,f8,f11
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// fmadds f2,f23,f17,f25
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f17.f64 + ctx.f25.f64));
	// fmsubs f25,f23,f16,f24
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f16.f64 - ctx.f24.f64));
	// fsubs f24,f1,f3
	ctx.f24.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// fadds f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// fsubs f1,f6,f5
	ctx.f1.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fmsubs f29,f29,f12,f22
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f12.f64 - ctx.f22.f64));
	// fmadds f8,f8,f12,f15
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 + ctx.f15.f64));
	// fmuls f5,f26,f24
	ctx.f5.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// fmuls f26,f26,f1
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// fmadds f5,f27,f1,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f5.f64));
	// fmsubs f26,f27,f24,f26
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f24.f64 - ctx.f26.f64));
	// stfsx f26,r9,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f5,r9,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f27,f29,f4
	ctx.f27.f64 = double(float(ctx.f29.f64 + ctx.f4.f64));
	// lfs f1,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f29,f4,f29
	ctx.f29.f64 = double(float(ctx.f4.f64 - ctx.f29.f64));
	// fmuls f24,f1,f6
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// lfs f5,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f5.f64 = double(temp.f32);
	// fadds f4,f30,f25
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// fadds f26,f8,f28
	ctx.f26.f64 = double(float(ctx.f8.f64 + ctx.f28.f64));
	// fsubs f30,f25,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 - ctx.f30.f64));
	// fmuls f1,f1,f3
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// fsubs f28,f8,f28
	ctx.f28.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// fsubs f8,f7,f2
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f2.f64));
	// fadds f25,f7,f2
	ctx.f25.f64 = double(float(ctx.f7.f64 + ctx.f2.f64));
	// fmsubs f3,f5,f3,f24
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f3.f64 - ctx.f24.f64));
	// stfsx f3,r10,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmuls f3,f29,f0
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fadds f29,f26,f31
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f31.f64));
	// fmuls f2,f30,f0
	ctx.f2.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fadds f30,f27,f20
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f20.f64));
	// fmadds f7,f5,f6,f1
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f6.f64 + ctx.f1.f64));
	// stfsx f7,r10,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmuls f6,f28,f0
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// lfs f5,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f28,f27,f13,f20
	ctx.f28.f64 = double(float(-(ctx.f27.f64 * ctx.f13.f64 - ctx.f20.f64)));
	// lfs f7,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fadds f27,f8,f10
	ctx.f27.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fnmsubs f10,f8,f13,f10
	ctx.f10.f64 = double(float(-(ctx.f8.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// fnmsubs f31,f26,f13,f31
	ctx.f31.f64 = double(float(-(ctx.f26.f64 * ctx.f13.f64 - ctx.f31.f64)));
	// fadds f26,f4,f9
	ctx.f26.f64 = double(float(ctx.f4.f64 + ctx.f9.f64));
	// fmuls f8,f5,f29
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f29.f64));
	// fnmsubs f9,f4,f13,f9
	ctx.f9.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fmuls f1,f25,f0
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmsubs f8,f7,f30,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 - ctx.f8.f64));
	// stfsx f8,r8,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f28,f6
	ctx.f8.f64 = double(float(ctx.f28.f64 + ctx.f6.f64));
	// fmadds f7,f7,f29,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f29.f64 + ctx.f5.f64));
	// stfsx f7,r8,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fadds f5,f31,f3
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// lfs f4,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 - ctx.f3.f64));
	// lfs f7,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f6,f28,f6
	ctx.f6.f64 = double(float(ctx.f28.f64 - ctx.f6.f64));
	// fmuls f31,f4,f5
	ctx.f31.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// fmuls f4,f4,f8
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// fmsubs f8,f7,f8,f31
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 - ctx.f31.f64));
	// stfsx f8,r7,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fmadds f8,f7,f5,f4
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f5.f64 + ctx.f4.f64));
	// stfsx f8,r7,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f7.f64 = double(temp.f32);
	// addic. r25,r25,-1
	ctx.xer.ca = ctx.r25.u32 > 0;
	ctx.r25.s64 = ctx.r25.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// fmuls f5,f7,f3
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// lfs f8,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// fmsubs f6,f8,f6,f5
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f6.f64 - ctx.f5.f64));
	// stfsx f6,r5,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fmadds f8,f8,f3,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f3.f64 + ctx.f7.f64));
	// stfsx f8,r5,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f7.f64 = double(temp.f32);
	// fadds f6,f9,f1
	ctx.f6.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// fmuls f5,f7,f26
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// lfs f8,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f7,f27
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// fadds f7,f10,f2
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f2.f64));
	// subf r4,r24,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r24.s64;
	// fsubs f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f1.f64));
	// fsubs f10,f10,f2
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f2.f64));
	// fmsubs f5,f8,f27,f5
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f27.f64 - ctx.f5.f64));
	// stfs f5,0(r31)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fmadds f8,f8,f26,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f26.f64 + ctx.f4.f64));
	// stfs f8,0(r28)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// lfs f5,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f6
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f8,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f5,f5,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// fmsubs f7,f8,f7,f4
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 - ctx.f4.f64));
	// stfs f7,0(r30)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fmadds f8,f8,f6,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f6.f64 + ctx.f5.f64));
	// stfs f8,0(r27)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// lfs f7,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f7,f9
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// fmuls f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// addi r11,r11,64
	ctx.r11.s64 = ctx.r11.s64 + 64;
	// fmsubs f8,f8,f10,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f10.f64 - ctx.f6.f64));
	// stfs f8,0(r29)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fmadds f10,f7,f10,f9
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f10.f64 + ctx.f9.f64));
	// stfs f10,0(r26)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// lwz r10,3532(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d39690
	if (!ctx.cr0.eq) goto loc_82D39690;
loc_82D399C4:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28f30
	ctx.lr = 0x82D399CC;
	__restfpr_15(ctx, base);
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D399D0"))) PPC_WEAK_FUNC(sub_82D399D0);
PPC_FUNC_IMPL(__imp__sub_82D399D0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-5128
	ctx.r5.s64 = ctx.r11.s64 + -5128;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,-27104
	ctx.r4.s64 = ctx.r11.s64 + -27104;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D399E8"))) PPC_WEAK_FUNC(sub_82D399E8);
PPC_FUNC_IMPL(__imp__sub_82D399E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82D399F0;
	__savegprlr_25(ctx, base);
	// addi r12,r1,-64
	ctx.r12.s64 = ctx.r1.s64 + -64;
	// bl 0x82e28f10
	ctx.lr = 0x82D399F8;
	__savefpr_26(ctx, base);
	// mulli r11,r7,56
	ctx.r11.s64 = ctx.r7.s64 * 56;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-56
	ctx.r11.s64 = ctx.r11.s64 + -56;
	// bge cr6,0x82d39c6c
	if (!ctx.cr6.lt) goto loc_82D39C6C;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// rlwinm r26,r9,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r30,r7,r8
	ctx.r30.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f0,140(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D39A20:
	// rlwinm r29,r6,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// mulli r10,r6,12
	ctx.r10.s64 = ctx.r6.s64 * 12;
	// lfs f12,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f11,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// fadds f28,f11,f13
	ctx.f28.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// mulli r31,r6,20
	ctx.r31.s64 = ctx.r6.s64 * 20;
	// fadds f27,f10,f12
	ctx.f27.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// lfsx f4,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// rlwinm r9,r6,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// add r28,r29,r4
	ctx.r28.u64 = ctx.r29.u64 + ctx.r4.u64;
	// add r29,r29,r3
	ctx.r29.u64 = ctx.r29.u64 + ctx.r3.u64;
	// mulli r8,r6,24
	ctx.r8.s64 = ctx.r6.s64 * 24;
	// lfsx f9,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fadds f11,f8,f9
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// lfsx f6,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f10,f9,f8
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// lfsx f3,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f9,f6,f7
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// add r27,r31,r4
	ctx.r27.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fsubs f8,f7,f6
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// rlwinm r5,r6,4,0,27
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f2,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// mulli r7,r6,28
	ctx.r7.s64 = ctx.r6.s64 * 28;
	// fsubs f6,f2,f4
	ctx.f6.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// fadds f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f2.f64));
	// lfs f5,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f7,f5,f3
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// lfsx f30,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// lfsx f29,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f1,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f3,f1,f30
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// fsubs f2,f29,f31
	ctx.f2.f64 = double(float(ctx.f29.f64 - ctx.f31.f64));
	// fadds f1,f30,f1
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fadds f30,f11,f28
	ctx.f30.f64 = double(float(ctx.f11.f64 + ctx.f28.f64));
	// fsubs f11,f28,f11
	ctx.f11.f64 = double(float(ctx.f28.f64 - ctx.f11.f64));
	// fadds f31,f31,f29
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f29.f64));
	// fadds f29,f27,f9
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f9.f64));
	// fsubs f9,f9,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f27.f64));
	// fadds f28,f5,f13
	ctx.f28.f64 = double(float(ctx.f5.f64 + ctx.f13.f64));
	// fsubs f13,f13,f5
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f5.f64));
	// fadds f5,f4,f8
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fsubs f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// fadds f27,f6,f2
	ctx.f27.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fadds f4,f3,f7
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// fsubs f26,f1,f10
	ctx.f26.f64 = double(float(ctx.f1.f64 - ctx.f10.f64));
	// fadds f10,f1,f10
	ctx.f10.f64 = double(float(ctx.f1.f64 + ctx.f10.f64));
	// fsubs f6,f2,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 - ctx.f6.f64));
	// fadds f2,f29,f30
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// stfs f2,0(r3)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// fadds f3,f12,f31
	ctx.f3.f64 = double(float(ctx.f12.f64 + ctx.f31.f64));
	// fsubs f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f31.f64));
	// fsubs f2,f30,f29
	ctx.f2.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fadds f1,f27,f4
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f4.f64));
	// stfs f1,0(r4)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f4,f4,f27
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f27.f64));
	// lfs f31,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f1.f64 = double(temp.f32);
	// fadds f29,f12,f8
	ctx.f29.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// fmuls f30,f31,f4
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f4.f64));
	// fmsubs f30,f1,f2,f30
	ctx.f30.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 - ctx.f30.f64));
	// stfsx f30,r5,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fmuls f30,f31,f2
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f2.f64));
	// fadds f2,f6,f11
	ctx.f2.f64 = double(float(ctx.f6.f64 + ctx.f11.f64));
	// fsubs f11,f11,f6
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f6.f64));
	// fadds f31,f9,f7
	ctx.f31.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// fsubs f6,f8,f12
	ctx.f6.f64 = double(float(ctx.f8.f64 - ctx.f12.f64));
	// fsubs f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// fadds f7,f3,f5
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f3,f5,f3
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fmadds f12,f1,f4,f30
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f4.f64 + ctx.f30.f64));
	// stfsx f12,r5,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f8,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f5,f29,f0
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f29,f8,f31
	ctx.f29.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// fmuls f27,f8,f2
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f2.f64));
	// fmuls f4,f3,f0
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fsubs f1,f13,f5
	ctx.f1.f64 = double(float(ctx.f13.f64 - ctx.f5.f64));
	// fadds f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 + ctx.f13.f64));
	// fmsubs f5,f12,f2,f29
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 - ctx.f29.f64));
	// stfsx f5,r9,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmadds f12,f12,f31,f27
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64 + ctx.f27.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f5,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f30,f10,f4
	ctx.f30.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// fadds f10,f4,f10
	ctx.f10.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// lfs f12,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f4,f5,f9
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// fmuls f5,f5,f11
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fadds f3,f6,f26
	ctx.f3.f64 = double(float(ctx.f6.f64 + ctx.f26.f64));
	// fsubs f8,f28,f7
	ctx.f8.f64 = double(float(ctx.f28.f64 - ctx.f7.f64));
	// fsubs f6,f26,f6
	ctx.f6.f64 = double(float(ctx.f26.f64 - ctx.f6.f64));
	// fadds f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f28.f64));
	// fmsubs f11,f12,f11,f4
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 - ctx.f4.f64));
	// stfsx f11,r8,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fmadds f12,f12,f9,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 + ctx.f5.f64));
	// stfsx f12,r8,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f9,f11,f3
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// fmsubs f9,f12,f8,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 - ctx.f9.f64));
	// stfsx f9,r10,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f12,f12,f3,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 + ctx.f11.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f11,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f9,f11,f6
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// lfs f12,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fmsubs f9,f12,f7,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f7.f64 - ctx.f9.f64));
	// stfsx f9,r7,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fmadds f12,f12,f6,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f6.f64 + ctx.f11.f64));
	// stfsx f12,r7,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f11,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f11.f64 = double(temp.f32);
	// subf r4,r26,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r26.s64;
	// fmuls f9,f11,f30
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfs f12,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// fmsubs f9,f12,f1,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f1.f64 - ctx.f9.f64));
	// stfsx f9,r31,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmadds f12,f12,f30,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 + ctx.f11.f64));
	// stfs f12,0(r27)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// add r3,r26,r3
	ctx.r3.u64 = ctx.r26.u64 + ctx.r3.u64;
	// fmuls f9,f11,f10
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// addi r11,r11,56
	ctx.r11.s64 = ctx.r11.s64 + 56;
	// fmsubs f13,f12,f13,f9
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 - ctx.f9.f64));
	// stfs f13,0(r29)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fmadds f13,f12,f10,f11
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 + ctx.f11.f64));
	// stfs f13,0(r28)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// lwz r10,3532(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d39a20
	if (!ctx.cr0.eq) goto loc_82D39A20;
loc_82D39C6C:
	// addi r12,r1,-64
	ctx.r12.s64 = ctx.r1.s64 + -64;
	// bl 0x82e28f5c
	ctx.lr = 0x82D39C74;
	__restfpr_26(ctx, base);
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D39C78"))) PPC_WEAK_FUNC(sub_82D39C78);
PPC_FUNC_IMPL(__imp__sub_82D39C78) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-5064
	ctx.r5.s64 = ctx.r11.s64 + -5064;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,-26136
	ctx.r4.s64 = ctx.r11.s64 + -26136;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D39C90"))) PPC_WEAK_FUNC(sub_82D39C90);
PPC_FUNC_IMPL(__imp__sub_82D39C90) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82D39C98;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28ef0
	ctx.lr = 0x82D39CA0;
	__savefpr_18(ctx, base);
	// mulli r11,r7,48
	ctx.r11.s64 = ctx.r7.s64 * 48;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-48
	ctx.r11.s64 = ctx.r11.s64 + -48;
	// bge cr6,0x82d39f6c
	if (!ctx.cr6.lt) goto loc_82D39F6C;
	// subf r25,r7,r8
	ctx.r25.s64 = ctx.r8.s64 - ctx.r7.s64;
	// rlwinm r24,r9,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f9,-4940(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -4940);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-4944(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -4944);
	ctx.f10.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f11,-4948(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -4948);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-4952(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -4952);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-4956(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -4956);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-4960(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4960);
	ctx.f0.f64 = double(temp.f32);
loc_82D39CF0:
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f5,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// rlwinm r8,r6,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f8,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// mulli r7,r6,12
	ctx.r7.s64 = ctx.r6.s64 * 12;
	// add r30,r9,r3
	ctx.r30.u64 = ctx.r9.u64 + ctx.r3.u64;
	// add r29,r8,r3
	ctx.r29.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r28,r7,r3
	ctx.r28.u64 = ctx.r7.u64 + ctx.r3.u64;
	// add r8,r8,r4
	ctx.r8.u64 = ctx.r8.u64 + ctx.r4.u64;
	// mulli r5,r6,24
	ctx.r5.s64 = ctx.r6.s64 * 24;
	// lfs f4,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fadds f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// lfs f3,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfs f31,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f2,f4,f5
	ctx.f2.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// lfs f30,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fadds f4,f30,f31
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// fsubs f31,f31,f30
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// mulli r31,r6,20
	ctx.r31.s64 = ctx.r6.s64 * 20;
	// fmadds f20,f6,f9,f8
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fmuls f22,f6,f10
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// add r9,r9,r4
	ctx.r9.u64 = ctx.r9.u64 + ctx.r4.u64;
	// fmuls f23,f4,f10
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// add r27,r5,r3
	ctx.r27.u64 = ctx.r5.u64 + ctx.r3.u64;
	// fmuls f25,f31,f12
	ctx.f25.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// add r26,r31,r4
	ctx.r26.u64 = ctx.r31.u64 + ctx.r4.u64;
	// rlwinm r10,r6,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// add r31,r31,r3
	ctx.r31.u64 = ctx.r31.u64 + ctx.r3.u64;
	// add r5,r5,r4
	ctx.r5.u64 = ctx.r5.u64 + ctx.r4.u64;
	// lfs f1,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// lfs f29,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fadds f5,f1,f3
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// lfs f28,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f1,f3,f1
	ctx.f1.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// fsubs f3,f28,f29
	ctx.f3.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// lfsx f26,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f30,f29,f28
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// lfs f27,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f28,f31,f13
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// lfs f7,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f29,f2,f12
	ctx.f29.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fnmadds f22,f4,f11,f22
	ctx.f22.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 + ctx.f22.f64)));
	// fmadds f19,f5,f9,f8
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fmuls f24,f5,f10
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// fnmadds f23,f5,f11,f23
	ctx.f23.f64 = double(float(-(ctx.f5.f64 * ctx.f11.f64 + ctx.f23.f64)));
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fmadds f28,f2,f0,f28
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f28.f64));
	// fmsubs f2,f2,f13,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 - ctx.f25.f64));
	// fmadds f21,f1,f13,f29
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 + ctx.f29.f64));
	// fnmadds f25,f6,f11,f24
	ctx.f25.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 + ctx.f24.f64)));
	// fmadds f24,f4,f9,f8
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// lfs f5,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f29,f1,f12,f28
	ctx.f29.f64 = double(float(-(ctx.f1.f64 * ctx.f12.f64 - ctx.f28.f64)));
	// fnmsubs f28,f1,f0,f2
	ctx.f28.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fsubs f2,f26,f27
	ctx.f2.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fmadds f31,f31,f0,f21
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f0.f64 + ctx.f21.f64));
	// fadds f1,f27,f26
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// fmuls f27,f3,f10
	ctx.f27.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmuls f4,f30,f12
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// fmadds f26,f3,f9,f7
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// lfsx f6,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// stfs f8,0(r3)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f24,f23,f20
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// fadds f23,f22,f19
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// fmuls f8,f2,f10
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmadds f22,f2,f9,f7
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fmadds f4,f1,f13,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 + ctx.f4.f64));
	// fnmadds f21,f3,f11,f8
	ctx.f21.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 + ctx.f8.f64)));
	// fsubs f8,f5,f6
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f6.f64));
	// fadds f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f5.f64));
	// fadds f20,f8,f2
	ctx.f20.f64 = double(float(ctx.f8.f64 + ctx.f2.f64));
	// fmuls f5,f6,f13
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmuls f19,f6,f12
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// fmuls f18,f8,f10
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// fnmadds f27,f8,f11,f27
	ctx.f27.f64 = double(float(-(ctx.f8.f64 * ctx.f11.f64 + ctx.f27.f64)));
	// fadds f3,f20,f3
	ctx.f3.f64 = double(float(ctx.f20.f64 + ctx.f3.f64));
	// fmsubs f5,f1,f12,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 - ctx.f5.f64));
	// fmadds f20,f8,f9,f7
	ctx.f20.f64 = double(float(ctx.f8.f64 * ctx.f9.f64 + ctx.f7.f64));
	// addic. r25,r25,-1
	ctx.xer.ca = ctx.r25.u32 > 0;
	ctx.r25.s64 = ctx.r25.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// fmadds f8,f6,f0,f4
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fmadds f1,f1,f0,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f19.f64));
	// fadds f6,f27,f22
	ctx.f6.f64 = double(float(ctx.f27.f64 + ctx.f22.f64));
	// fnmsubs f5,f30,f0,f5
	ctx.f5.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f5.f64)));
	// fnmadds f19,f2,f11,f18
	ctx.f19.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 + ctx.f18.f64)));
	// fadds f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// stfs f7,0(r4)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f3,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f3.f64 = double(temp.f32);
	// lfs f7,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f7.f64 = double(temp.f32);
	// fadds f2,f21,f20
	ctx.f2.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// fnmsubs f4,f30,f13,f1
	ctx.f4.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// fsubs f30,f6,f29
	ctx.f30.f64 = double(float(ctx.f6.f64 - ctx.f29.f64));
	// fsubs f27,f23,f5
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f5.f64));
	// fadds f1,f19,f26
	ctx.f1.f64 = double(float(ctx.f19.f64 + ctx.f26.f64));
	// fadds f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// fadds f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f23.f64));
	// fadds f22,f2,f28
	ctx.f22.f64 = double(float(ctx.f2.f64 + ctx.f28.f64));
	// fsubs f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f28.f64));
	// fadds f26,f4,f25
	ctx.f26.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// fmuls f21,f3,f30
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// fmuls f3,f3,f27
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// fsubs f4,f25,f4
	ctx.f4.f64 = double(float(ctx.f25.f64 - ctx.f4.f64));
	// fmsubs f27,f7,f27,f21
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f27.f64 - ctx.f21.f64));
	// stfsx f27,r10,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f7,f7,f30,f3
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 + ctx.f3.f64));
	// stfsx f7,r10,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f3,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f30,f1,f31
	ctx.f30.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// fmuls f27,f3,f22
	ctx.f27.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// lfs f7,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f21,f3,f26
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f26.f64));
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// fadds f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f31.f64));
	// subf r4,r24,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r24.s64;
	// fadds f3,f8,f24
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f24.f64));
	// fsubs f8,f24,f8
	ctx.f8.f64 = double(float(ctx.f24.f64 - ctx.f8.f64));
	// fmsubs f29,f7,f26,f27
	ctx.f29.f64 = double(float(ctx.f7.f64 * ctx.f26.f64 - ctx.f27.f64));
	// stfs f29,0(r29)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fmadds f7,f7,f22,f21
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f22.f64 + ctx.f21.f64));
	// stfs f7,0(r8)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// lfs f31,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f31.f64 = double(temp.f32);
	// lfs f7,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f29,f31,f6
	ctx.f29.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fmuls f6,f7,f6
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// fmsubs f7,f7,f5,f29
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f5.f64 - ctx.f29.f64));
	// stfs f7,0(r28)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fmadds f7,f31,f5,f6
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f5.f64 + ctx.f6.f64));
	// stfs f7,0(r7)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// lfs f6,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f6,f30
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f7,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f6,f3
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// fmsubs f5,f7,f3,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f3.f64 - ctx.f5.f64));
	// stfs f5,0(r27)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fmadds f7,f7,f30,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 + ctx.f6.f64));
	// stfs f7,0(r5)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lfs f6,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f6,f2
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// lfs f7,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// fmsubs f5,f7,f4,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f4.f64 - ctx.f5.f64));
	// stfs f5,0(r31)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fmadds f7,f7,f2,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f2.f64 + ctx.f6.f64));
	// stfs f7,0(r26)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// lfs f6,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f6,f1
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f7,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f6,f8
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// addi r11,r11,48
	ctx.r11.s64 = ctx.r11.s64 + 48;
	// fmsubs f8,f7,f8,f5
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 - ctx.f5.f64));
	// stfs f8,0(r30)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fmadds f8,f7,f1,f6
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f1.f64 + ctx.f6.f64));
	// stfs f8,0(r9)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lwz r10,3532(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d39cf0
	if (!ctx.cr0.eq) goto loc_82D39CF0;
loc_82D39F6C:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28f3c
	ctx.lr = 0x82D39F74;
	__restfpr_18(ctx, base);
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D39F78"))) PPC_WEAK_FUNC(sub_82D39F78);
PPC_FUNC_IMPL(__imp__sub_82D39F78) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-5008
	ctx.r5.s64 = ctx.r11.s64 + -5008;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,-25456
	ctx.r4.s64 = ctx.r11.s64 + -25456;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D39F90"))) PPC_WEAK_FUNC(sub_82D39F90);
PPC_FUNC_IMPL(__imp__sub_82D39F90) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82D39F98;
	__savegprlr_25(ctx, base);
	// stfd f29,-88(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -88, ctx.f29.u64);
	// stfd f30,-80(r1)
	PPC_STORE_U64(ctx.r1.u32 + -80, ctx.f30.u64);
	// stfd f31,-72(r1)
	PPC_STORE_U64(ctx.r1.u32 + -72, ctx.f31.u64);
	// mulli r11,r7,40
	ctx.r11.s64 = ctx.r7.s64 * 40;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-40
	ctx.r11.s64 = ctx.r11.s64 + -40;
	// bge cr6,0x82d3a19c
	if (!ctx.cr6.lt) goto loc_82D3A19C;
	// rlwinm r26,r9,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r9,r7,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32255
	ctx.r8.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f13,-28552(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -28552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f0.f64 = double(temp.f32);
loc_82D39FD4:
	// rlwinm r8,r6,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r7,r6,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// add r30,r8,r3
	ctx.r30.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r29,r7,r4
	ctx.r29.u64 = ctx.r7.u64 + ctx.r4.u64;
	// add r7,r7,r3
	ctx.r7.u64 = ctx.r7.u64 + ctx.r3.u64;
	// mulli r5,r6,20
	ctx.r5.s64 = ctx.r6.s64 * 20;
	// lfs f10,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fadds f31,f12,f10
	ctx.f31.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// lfs f8,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// fadds f10,f8,f9
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// add r8,r8,r4
	ctx.r8.u64 = ctx.r8.u64 + ctx.r4.u64;
	// mulli r10,r6,12
	ctx.r10.s64 = ctx.r6.s64 * 12;
	// lfs f6,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f4,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f8,f6,f11
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f11.f64));
	// fsubs f11,f11,f6
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f6.f64));
	// lfsx f3,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// add r28,r5,r3
	ctx.r28.u64 = ctx.r5.u64 + ctx.r3.u64;
	// fadds f30,f9,f12
	ctx.f30.f64 = double(float(ctx.f9.f64 + ctx.f12.f64));
	// rlwinm r31,r6,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f9,f12,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// add r5,r5,r4
	ctx.r5.u64 = ctx.r5.u64 + ctx.r4.u64;
	// add r27,r31,r4
	ctx.r27.u64 = ctx.r31.u64 + ctx.r4.u64;
	// add r31,r31,r3
	ctx.r31.u64 = ctx.r31.u64 + ctx.r3.u64;
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// lfs f7,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f6,f4,f7
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f7.f64));
	// lfs f5,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fadds f7,f7,f4
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// lfs f2,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f4,f5,f3
	ctx.f4.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// lfs f1,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f3,f2,f1
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fadds f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fadds f1,f10,f31
	ctx.f1.f64 = double(float(ctx.f10.f64 + ctx.f31.f64));
	// fsubs f10,f31,f10
	ctx.f10.f64 = double(float(ctx.f31.f64 - ctx.f10.f64));
	// fsubs f31,f2,f7
	ctx.f31.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// fmuls f12,f10,f0
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f10,f9,f0
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fadds f9,f3,f6
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// fsubs f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// fadds f3,f2,f7
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// fadds f2,f9,f4
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f4.f64));
	// fmuls f7,f6,f0
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f6,f3,f0
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fadds f3,f1,f8
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f8.f64));
	// stfs f3,0(r3)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fnmsubs f8,f1,f13,f8
	ctx.f8.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// stfs f2,0(r4)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f1,f5,f31
	ctx.f1.f64 = double(float(ctx.f5.f64 - ctx.f31.f64));
	// lfs f29,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f29.f64 = double(temp.f32);
	// fnmsubs f9,f9,f13,f4
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f4.f64)));
	// lfs f2,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f2.f64 = double(temp.f32);
	// fadds f3,f30,f11
	ctx.f3.f64 = double(float(ctx.f30.f64 + ctx.f11.f64));
	// fsubs f4,f8,f7
	ctx.f4.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// fadds f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// fmuls f7,f29,f1
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f1.f64));
	// fmuls f29,f29,f3
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// fmsubs f7,f2,f3,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 - ctx.f7.f64));
	// stfsx f7,r10,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f7,f9,f12
	ctx.f7.f64 = double(float(ctx.f9.f64 - ctx.f12.f64));
	// add r3,r26,r3
	ctx.r3.u64 = ctx.r26.u64 + ctx.r3.u64;
	// fadds f12,f9,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f12.f64));
	// fmadds f9,f2,f1,f29
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f1.f64 + ctx.f29.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f3,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// subf r4,r26,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r26.s64;
	// lfs f9,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f2,f3,f7
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// fmuls f3,f3,f4
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// fmsubs f4,f9,f4,f2
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f4.f64 - ctx.f2.f64));
	// stfs f4,0(r30)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fmadds f9,f9,f7,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f7.f64 + ctx.f3.f64));
	// stfs f9,0(r8)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// lfs f9,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f5,f31,f13,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f13.f64 + ctx.f5.f64));
	// lfs f7,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f7,f12
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// fmuls f2,f7,f8
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// fnmsubs f11,f30,f13,f11
	ctx.f11.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// fadds f4,f5,f10
	ctx.f4.f64 = double(float(ctx.f5.f64 + ctx.f10.f64));
	// fmsubs f8,f9,f8,f3
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 - ctx.f3.f64));
	// stfs f8,0(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fmadds f12,f9,f12,f2
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 + ctx.f2.f64));
	// stfs f12,0(r27)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// lfs f9,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f7,f11,f6
	ctx.f7.f64 = double(float(ctx.f11.f64 - ctx.f6.f64));
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fadds f11,f11,f6
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f6.f64));
	// fsubs f10,f5,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 - ctx.f10.f64));
	// fmuls f8,f9,f4
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// fmuls f6,f12,f4
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// fmsubs f12,f12,f7,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64 - ctx.f8.f64));
	// stfs f12,0(r7)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// fmadds f12,f9,f7,f6
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f7.f64 + ctx.f6.f64));
	// stfs f12,0(r29)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// lfs f9,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f9,f10
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f12,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f9,f9,f11
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// addi r11,r11,40
	ctx.r11.s64 = ctx.r11.s64 + 40;
	// fmsubs f11,f12,f11,f8
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 - ctx.f8.f64));
	// stfs f11,0(r28)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fmadds f12,f12,f10,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 + ctx.f9.f64));
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r10,3532(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d39fd4
	if (!ctx.cr0.eq) goto loc_82D39FD4;
loc_82D3A19C:
	// lfd f29,-88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// lfd f30,-80(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// lfd f31,-72(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D3A1B0"))) PPC_WEAK_FUNC(sub_82D3A1B0);
PPC_FUNC_IMPL(__imp__sub_82D3A1B0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-4928
	ctx.r5.s64 = ctx.r11.s64 + -4928;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,-24688
	ctx.r4.s64 = ctx.r11.s64 + -24688;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D3A1C8"))) PPC_WEAK_FUNC(sub_82D3A1C8);
PPC_FUNC_IMPL(__imp__sub_82D3A1C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82D3A1D0;
	__savegprlr_27(ctx, base);
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82e28f18
	ctx.lr = 0x82D3A1D8;
	__savefpr_28(ctx, base);
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// addi r11,r11,-32
	ctx.r11.s64 = ctx.r11.s64 + -32;
	// bge cr6,0x82d3a3a4
	if (!ctx.cr6.lt) goto loc_82D3A3A4;
	// subf r29,r7,r8
	ctx.r29.s64 = ctx.r8.s64 - ctx.r7.s64;
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32255
	ctx.r7.s64 = -2113863680;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f29,-12288(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -12288);
	ctx.f29.f64 = double(temp.f32);
	// lfs f13,-7588(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -7588);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7584(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -7584);
	ctx.f0.f64 = double(temp.f32);
	// lfs f30,-7592(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7592);
	ctx.f30.f64 = double(temp.f32);
loc_82D3A218:
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f12,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// add r5,r9,r3
	ctx.r5.u64 = ctx.r9.u64 + ctx.r3.u64;
	// mulli r7,r6,12
	ctx.r7.s64 = ctx.r6.s64 * 12;
	// lfsx f9,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fadds f2,f12,f10
	ctx.f2.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// lfsx f8,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// add r9,r9,r4
	ctx.r9.u64 = ctx.r9.u64 + ctx.r4.u64;
	// rlwinm r8,r6,4,0,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// add r31,r7,r4
	ctx.r31.u64 = ctx.r7.u64 + ctx.r4.u64;
	// add r7,r7,r3
	ctx.r7.u64 = ctx.r7.u64 + ctx.r3.u64;
	// add r30,r8,r3
	ctx.r30.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r8,r8,r4
	ctx.r8.u64 = ctx.r8.u64 + ctx.r4.u64;
	// lfs f7,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// fadds f10,f7,f9
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fsubs f9,f9,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// lfs f6,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfs f4,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f1,f8,f4
	ctx.f1.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// fsubs f7,f6,f5
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// lfs f3,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fadds f8,f4,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fadds f5,f10,f2
	ctx.f5.f64 = double(float(ctx.f10.f64 + ctx.f2.f64));
	// fsubs f4,f2,f10
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f10.f64));
	// fmuls f2,f9,f0
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f31,f9,f13
	ctx.f31.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fadds f10,f1,f7
	ctx.f10.f64 = double(float(ctx.f1.f64 + ctx.f7.f64));
	// fsubs f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f1.f64));
	// fmuls f1,f8,f0
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f28,f8,f13
	ctx.f28.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fmuls f9,f4,f30
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fmsubs f8,f12,f13,f2
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 - ctx.f2.f64));
	// fadds f2,f5,f11
	ctx.f2.f64 = double(float(ctx.f5.f64 + ctx.f11.f64));
	// stfs f2,0(r3)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fnmsubs f11,f5,f29,f11
	ctx.f11.f64 = double(float(-(ctx.f5.f64 * ctx.f29.f64 - ctx.f11.f64)));
	// fadds f2,f10,f3
	ctx.f2.f64 = double(float(ctx.f10.f64 + ctx.f3.f64));
	// stfs f2,0(r4)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fnmsubs f10,f10,f29,f3
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f29.f64 - ctx.f3.f64)));
	// lfs f2,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// fmsubs f4,f6,f13,f1
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 - ctx.f1.f64));
	// lfs f1,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f12,f12,f0,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f31.f64));
	// fmadds f6,f6,f0,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f28.f64));
	// fsubs f5,f11,f9
	ctx.f5.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// fadds f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f9.f64));
	// fsubs f3,f10,f7
	ctx.f3.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// fadds f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// fsubs f31,f5,f4
	ctx.f31.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fadds f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// fsubs f9,f11,f6
	ctx.f9.f64 = double(float(ctx.f11.f64 - ctx.f6.f64));
	// fadds f4,f3,f8
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f8.f64));
	// fsubs f8,f3,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f8.f64));
	// fadds f7,f10,f12
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// fadds f11,f11,f6
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f6.f64));
	// fmuls f3,f1,f31
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmuls f1,f1,f4
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// fmadds f4,f2,f4,f3
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f4.f64 + ctx.f3.f64));
	// fmsubs f1,f2,f31,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f31.f64 - ctx.f1.f64));
	// stfsx f1,r10,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f4,r10,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// add r3,r28,r3
	ctx.r3.u64 = ctx.r28.u64 + ctx.r3.u64;
	// lfs f3,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f3.f64 = double(temp.f32);
	// subf r4,r28,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r28.s64;
	// fmuls f2,f3,f8
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// lfs f4,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// fmsubs f10,f4,f5,f2
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f5.f64 - ctx.f2.f64));
	// stfs f10,0(r7)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// fmadds f10,f4,f8,f3
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f3.f64));
	// stfs f10,0(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// lfs f10,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f8,f7
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fmuls f8,f8,f9
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// fmsubs f9,f10,f9,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 - ctx.f6.f64));
	// stfs f9,0(r5)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fmadds f10,f10,f7,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f7.f64 + ctx.f8.f64));
	// stfs f10,0(r9)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lfs f9,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f9,f12
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// lfs f10,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f9,f11
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// fmsubs f11,f10,f11,f8
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 - ctx.f8.f64));
	// stfs f11,0(r30)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fmadds f12,f10,f12,f9
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + ctx.f9.f64));
	// stfs f12,0(r8)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// lwz r10,3532(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d3a218
	if (!ctx.cr0.eq) goto loc_82D3A218;
loc_82D3A3A4:
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82e28f64
	ctx.lr = 0x82D3A3AC;
	__restfpr_28(ctx, base);
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D3A3B0"))) PPC_WEAK_FUNC(sub_82D3A3B0);
PPC_FUNC_IMPL(__imp__sub_82D3A3B0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-4872
	ctx.r5.s64 = ctx.r11.s64 + -4872;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,-24120
	ctx.r4.s64 = ctx.r11.s64 + -24120;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D3A3C8"))) PPC_WEAK_FUNC(sub_82D3A3C8);
PPC_FUNC_IMPL(__imp__sub_82D3A3C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D3A3D0;
	__savegprlr_28(ctx, base);
	// mulli r11,r7,24
	ctx.r11.s64 = ctx.r7.s64 * 24;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-24
	ctx.r11.s64 = ctx.r11.s64 + -24;
	// bge cr6,0x82d3a4f8
	if (!ctx.cr6.lt) goto loc_82D3A4F8;
	// rlwinm r29,r9,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
loc_82D3A3F0:
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// mulli r8,r6,12
	ctx.r8.s64 = ctx.r6.s64 * 12;
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r7,r6,3,0,28
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// add r5,r9,r4
	ctx.r5.u64 = ctx.r9.u64 + ctx.r4.u64;
	// add r9,r9,r3
	ctx.r9.u64 = ctx.r9.u64 + ctx.r3.u64;
	// add r31,r8,r4
	ctx.r31.u64 = ctx.r8.u64 + ctx.r4.u64;
	// add r30,r7,r3
	ctx.r30.u64 = ctx.r7.u64 + ctx.r3.u64;
	// add r8,r8,r3
	ctx.r8.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// lfs f12,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lfs f11,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fadds f6,f12,f0
	ctx.f6.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// lfs f10,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fadds f5,f13,f11
	ctx.f5.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
	// lfs f8,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// lfs f9,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// lfs f7,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f12,f10,f8
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// fsubs f11,f7,f9
	ctx.f11.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// fadds f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fadds f9,f9,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// fadds f8,f5,f6
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// stfs f8,0(r3)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f8,f6,f5
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// fadds f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// stfs f7,0(r4)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// lfs f11,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fadds f5,f10,f13
	ctx.f5.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// lfs f7,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 - ctx.f13.f64));
	// subf r4,r29,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r29.s64;
	// fsubs f6,f0,f9
	ctx.f6.f64 = double(float(ctx.f0.f64 - ctx.f9.f64));
	// fadds f0,f9,f0
	ctx.f0.f64 = double(float(ctx.f9.f64 + ctx.f0.f64));
	// fmuls f10,f11,f12
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// fmuls f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// fmsubs f10,f7,f8,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 - ctx.f10.f64));
	// stfs f10,0(r30)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fmadds f12,f7,f12,f11
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + ctx.f11.f64));
	// stfs f12,0(r7)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f11,f5
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// fmuls f9,f12,f5
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f5.f64));
	// fmsubs f12,f12,f6,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f6.f64 - ctx.f10.f64));
	// stfs f12,0(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// fmadds f12,f11,f6,f9
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f6.f64 + ctx.f9.f64));
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f11,f13
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// fmsubs f0,f12,f0,f10
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 - ctx.f10.f64));
	// stfs f0,0(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// fmadds f0,f12,f13,f11
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + ctx.f11.f64));
	// stfs f0,0(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// lwz r9,3532(r28)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3532);
	// xor r6,r9,r6
	ctx.r6.u64 = ctx.r9.u64 ^ ctx.r6.u64;
	// bne 0x82d3a3f0
	if (!ctx.cr0.eq) goto loc_82D3A3F0;
loc_82D3A4F8:
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D3A500"))) PPC_WEAK_FUNC(sub_82D3A500);
PPC_FUNC_IMPL(__imp__sub_82D3A500) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-4816
	ctx.r5.s64 = ctx.r11.s64 + -4816;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,-23608
	ctx.r4.s64 = ctx.r11.s64 + -23608;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D3A518"))) PPC_WEAK_FUNC(sub_82D3A518);
PPC_FUNC_IMPL(__imp__sub_82D3A518) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// addi r11,r11,-16
	ctx.r11.s64 = ctx.r11.s64 + -16;
	// bge cr6,0x82d3a61c
	if (!ctx.cr6.lt) goto loc_82D3A61C;
	// rlwinm r31,r9,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f5,-7656(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -7656);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,-28552(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f6.f64 = double(temp.f32);
loc_82D3A550:
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r8,r6,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f13,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// add r7,r9,r3
	ctx.r7.u64 = ctx.r9.u64 + ctx.r3.u64;
	// add r9,r9,r4
	ctx.r9.u64 = ctx.r9.u64 + ctx.r4.u64;
	// add r5,r8,r3
	ctx.r5.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r8,r8,r4
	ctx.r8.u64 = ctx.r8.u64 + ctx.r4.u64;
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lfs f12,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fadds f8,f0,f12
	ctx.f8.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
	// lfs f10,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// fsubs f0,f11,f10
	ctx.f0.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// lfs f9,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fadds f10,f8,f13
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// stfs f10,0(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fnmsubs f13,f8,f6,f13
	ctx.f13.f64 = double(float(-(ctx.f8.f64 * ctx.f6.f64 - ctx.f13.f64)));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fadds f10,f0,f9
	ctx.f10.f64 = double(float(ctx.f0.f64 + ctx.f9.f64));
	// stfs f10,0(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmuls f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// lfs f7,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f12,f12,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f5.f64));
	// lfs f10,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f0,f0,f6,f9
	ctx.f0.f64 = double(float(-(ctx.f0.f64 * ctx.f6.f64 - ctx.f9.f64)));
	// subf r4,r31,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r31.s64;
	// fsubs f9,f13,f11
	ctx.f9.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// fadds f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fadds f11,f0,f12
	ctx.f11.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fmuls f12,f7,f9
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// fmuls f8,f7,f11
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// fmadds f12,f10,f11,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 + ctx.f12.f64));
	// fmsubs f9,f10,f9,f8
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 - ctx.f8.f64));
	// stfs f9,0(r7)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// stfs f12,0(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lfs f11,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f11,f0
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// fmsubs f13,f12,f13,f10
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 - ctx.f10.f64));
	// stfs f13,0(r5)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fmadds f0,f12,f0,f11
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f11.f64));
	// stfs f0,0(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// lwz r9,3532(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// xor r6,r9,r6
	ctx.r6.u64 = ctx.r9.u64 ^ ctx.r6.u64;
	// bne 0x82d3a550
	if (!ctx.cr0.eq) goto loc_82D3A550;
loc_82D3A61C:
	// ld r30,-16(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D3A628"))) PPC_WEAK_FUNC(sub_82D3A628);
PPC_FUNC_IMPL(__imp__sub_82D3A628) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-4760
	ctx.r5.s64 = ctx.r11.s64 + -4760;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,-23272
	ctx.r4.s64 = ctx.r11.s64 + -23272;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D3A640"))) PPC_WEAK_FUNC(sub_82D3A640);
PPC_FUNC_IMPL(__imp__sub_82D3A640) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// addi r11,r11,-8
	ctx.r11.s64 = ctx.r11.s64 + -8;
	// bgelr cr6
	if (!ctx.cr6.lt) return;
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// rlwinm r5,r9,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
loc_82D3A660:
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// add r8,r9,r4
	ctx.r8.u64 = ctx.r9.u64 + ctx.r4.u64;
	// fadds f11,f13,f0
	ctx.f11.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// add r9,r9,r3
	ctx.r9.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f13,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f11,0(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f11,f13,f12
	ctx.f11.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f12,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// add r3,r5,r3
	ctx.r3.u64 = ctx.r5.u64 + ctx.r3.u64;
	// lfs f11,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// subf r4,r5,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r5.s64;
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// fmuls f10,f12,f13
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fmsubs f0,f11,f0,f10
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f10.f64));
	// stfs f0,0(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// fmadds f0,f11,f13,f12
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f12.f64));
	// stfs f0,0(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// lwz r9,3532(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 3532);
	// xor r6,r9,r6
	ctx.r6.u64 = ctx.r9.u64 ^ ctx.r6.u64;
	// bne 0x82d3a660
	if (!ctx.cr0.eq) goto loc_82D3A660;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D3A6D8"))) PPC_WEAK_FUNC(sub_82D3A6D8);
PPC_FUNC_IMPL(__imp__sub_82D3A6D8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-4704
	ctx.r5.s64 = ctx.r11.s64 + -4704;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,-22976
	ctx.r4.s64 = ctx.r11.s64 + -22976;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D3A6F0"))) PPC_WEAK_FUNC(sub_82D3A6F0);
PPC_FUNC_IMPL(__imp__sub_82D3A6F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D3A6F8;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D3A700;
	__savefpr_14(ctx, base);
	// stwu r1,-912(r1)
	ea = -912 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d3de10
	if (!ctx.cr6.gt) goto loc_82D3DE10;
	// lwz r11,1004(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1004);
	// lis r17,-32234
	ctx.r17.s64 = -2112487424;
	// lis r18,-32234
	ctx.r18.s64 = -2112487424;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lfs f29,-6524(r17)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + -6524);
	ctx.f29.f64 = double(temp.f32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f30,-6528(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + -6528);
	ctx.f30.f64 = double(temp.f32);
	// stw r11,592(r1)
	PPC_STORE_U32(ctx.r1.u32 + 592, ctx.r11.u32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lwz r11,996(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 996);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f6,-8140(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -8140);
	ctx.f6.f64 = double(temp.f32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f31,-6516(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -6516);
	ctx.f31.f64 = double(temp.f32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f1,-6512(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -6512);
	ctx.f1.f64 = double(temp.f32);
	// lis r27,-32236
	ctx.r27.s64 = -2112618496;
	// lfs f2,-6492(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -6492);
	ctx.f2.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f3,-6496(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -6496);
	ctx.f3.f64 = double(temp.f32);
	// lis r29,-32236
	ctx.r29.s64 = -2112618496;
	// lfs f7,-8132(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -8132);
	ctx.f7.f64 = double(temp.f32);
	// stw r11,600(r1)
	PPC_STORE_U32(ctx.r1.u32 + 600, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f8,-8136(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -8136);
	ctx.f8.f64 = double(temp.f32);
	// lis r31,-32236
	ctx.r31.s64 = -2112618496;
	// lfs f12,136(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f13,-8016(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
	// lis r14,-32234
	ctx.r14.s64 = -2112487424;
	// stw r11,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f10,-8128(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8128);
	ctx.f10.f64 = double(temp.f32);
	// lis r15,-32234
	ctx.r15.s64 = -2112487424;
	// lfs f11,124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 124);
	ctx.f11.f64 = double(temp.f32);
	// lis r16,-32234
	ctx.r16.s64 = -2112487424;
	// lfs f4,120(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 120);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,-8144(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -8144);
	ctx.f5.f64 = double(temp.f32);
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,368(r1)
	PPC_STORE_U32(ctx.r1.u32 + 368, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,360(r1)
	PPC_STORE_U32(ctx.r1.u32 + 360, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,348(r1)
	PPC_STORE_U32(ctx.r1.u32 + 348, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,232(r1)
	PPC_STORE_U32(ctx.r1.u32 + 232, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,220(r1)
	PPC_STORE_U32(ctx.r1.u32 + 220, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,64(r1)
	PPC_STORE_U32(ctx.r1.u32 + 64, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,40(r1)
	PPC_STORE_U32(ctx.r1.u32 + 40, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,240(r1)
	PPC_STORE_U32(ctx.r1.u32 + 240, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,248(r1)
	PPC_STORE_U32(ctx.r1.u32 + 248, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,236(r1)
	PPC_STORE_U32(ctx.r1.u32 + 236, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,48(r1)
	PPC_STORE_U32(ctx.r1.u32 + 48, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,32(r1)
	PPC_STORE_U32(ctx.r1.u32 + 32, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,52(r1)
	PPC_STORE_U32(ctx.r1.u32 + 52, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,24(r1)
	PPC_STORE_U32(ctx.r1.u32 + 24, ctx.r11.u32);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f9,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f9.f64 = double(temp.f32);
	// lwz r11,24(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// lfs f28,-6500(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + -6500);
	ctx.f28.f64 = double(temp.f32);
	// lfs f27,-6504(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + -6504);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,-8008(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -8008);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,-8012(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -8012);
	ctx.f25.f64 = double(temp.f32);
	// lwz r11,52(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	// lfs f24,-6540(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6540);
	ctx.f24.f64 = double(temp.f32);
	// lwz r11,32(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// stfs f24,596(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// lfs f24,-6544(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6544);
	ctx.f24.f64 = double(temp.f32);
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stfs f24,580(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 580, temp.u32);
	// lfs f24,-6552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6552);
	ctx.f24.f64 = double(temp.f32);
	// lwz r11,48(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	// stfs f24,480(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// lfs f24,-6548(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6548);
	ctx.f24.f64 = double(temp.f32);
	// lwz r11,236(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// stfs f24,476(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// lfs f24,-6508(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6508);
	ctx.f24.f64 = double(temp.f32);
	// lwz r11,248(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	// stfs f24,496(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 496, temp.u32);
	// lfs f24,-6520(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6520);
	ctx.f24.f64 = double(temp.f32);
	// lwz r11,240(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	// stfs f24,484(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 484, temp.u32);
	// lfs f24,-6536(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6536);
	ctx.f24.f64 = double(temp.f32);
	// lwz r11,40(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// stfs f24,456(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// lfs f24,-6532(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6532);
	ctx.f24.f64 = double(temp.f32);
	// lwz r11,164(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// stfs f24,488(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// lfs f24,-8004(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -8004);
	ctx.f24.f64 = double(temp.f32);
	// lwz r11,196(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// lfs f23,-8000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -8000);
	ctx.f23.f64 = double(temp.f32);
	// lwz r11,64(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	// stfs f23,588(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 588, temp.u32);
	// lfs f23,-6576(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6576);
	ctx.f23.f64 = double(temp.f32);
	// lwz r11,220(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// stfs f23,544(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// lfs f23,-6572(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6572);
	ctx.f23.f64 = double(temp.f32);
	// lwz r11,232(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	// stfs f23,468(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// lfs f23,-6584(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6584);
	ctx.f23.f64 = double(temp.f32);
	// lwz r11,348(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// stfs f23,464(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// lfs f23,-6580(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6580);
	ctx.f23.f64 = double(temp.f32);
	// lwz r11,360(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	// stfs f23,492(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// lfs f23,-6560(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6560);
	ctx.f23.f64 = double(temp.f32);
	// lwz r11,368(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	// stfs f23,472(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// lfs f23,-6556(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6556);
	ctx.f23.f64 = double(temp.f32);
	// lwz r11,120(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// stfs f23,452(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// lfs f23,-6564(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6564);
	ctx.f23.f64 = double(temp.f32);
	// lwz r11,132(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// stfs f23,584(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 584, temp.u32);
	// lfs f23,-6568(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6568);
	ctx.f23.f64 = double(temp.f32);
	// stfs f23,460(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
loc_82D3A93C:
	// rlwinm r11,r8,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f23,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// mulli r10,r8,192
	ctx.r10.s64 = ctx.r8.s64 * 192;
	// lfsx f22,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f21,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// rlwinm r11,r9,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 6) & 0xFFFFFFC0;
	// mulli r10,r9,192
	ctx.r10.s64 = ctx.r9.s64 * 192;
	// lfsx f20,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f19,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// rlwinm r11,r8,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// mulli r10,r8,224
	ctx.r10.s64 = ctx.r8.s64 * 224;
	// lfsx f18,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f17,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// rlwinm r11,r9,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// mulli r10,r9,224
	ctx.r10.s64 = ctx.r9.s64 * 224;
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f15,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r8,160
	ctx.r11.s64 = ctx.r8.s64 * 160;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// mulli r11,r8,96
	ctx.r11.s64 = ctx.r8.s64 * 96;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,112(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// mulli r11,r9,160
	ctx.r11.s64 = ctx.r9.s64 * 160;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,128(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f14,f22,f21
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// mulli r11,r9,96
	ctx.r11.s64 = ctx.r9.s64 * 96;
	// fadds f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfsx f22,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,32(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f22,f19,f20
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfs f20,24(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// rlwinm r11,r8,8,0,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFFFF00;
	// fsubs f20,f18,f17
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// rlwinm r10,r8,7,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 7) & 0xFFFFFF80;
	// fmuls f21,f21,f9
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// stfs f21,60(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// rlwinm r31,r9,7,0,24
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 7) & 0xFFFFFF80;
	// lfsx f21,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,96(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfsx f21,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f9
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// stfs f21,88(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f21,f17,f18
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfsx f19,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fmuls f19,f19,f9
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f9.f64));
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,76(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,112(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmuls f18,f18,f9
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// fsubs f15,f14,f22
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// fadds f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// lfs f22,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f23
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f22,128(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f22,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fmuls f22,f15,f4
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// fmuls f15,f14,f4
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f4.f64));
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f21,f15
	ctx.f15.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// mulli r11,r8,48
	ctx.r11.s64 = ctx.r8.s64 * 48;
	// mulli r10,r8,208
	ctx.r10.s64 = ctx.r8.s64 * 208;
	// fmuls f21,f21,f9
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// stfs f21,124(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f21,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f14,f17,f21
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fadds f17,f21,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// lfs f21,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// stfs f21,76(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fsubs f21,f23,f19
	ctx.f21.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// stfs f21,88(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// stfs f23,236(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fmuls f23,f17,f9
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// stfs f23,308(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f23,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f17,f15,f10
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// lfs f21,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f19,f23,f21
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// fadds f14,f21,f23
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// lfs f21,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f21,f23,f21
	ctx.f21.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// stfs f21,140(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f21,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// lfs f21,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f21,560(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 560, temp.u32);
	// lfs f21,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfs f21,524(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// lfs f21,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f21.f64 = double(temp.f32);
	// fadds f18,f22,f21
	ctx.f18.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfs f18,244(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f22,232(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f21,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f18,f21,f22
	ctx.f18.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f18,172(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfs f22,364(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fmuls f22,f19,f4
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// stfs f22,416(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fsubs f19,f20,f16
	ctx.f19.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// lfs f21,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f22,f14,f4
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f4.f64));
	// stfs f22,564(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 564, temp.u32);
	// fmsubs f22,f19,f11,f17
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 - ctx.f17.f64));
	// stfs f22,432(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// fmuls f18,f19,f10
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// lfsx f19,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f22,f16,f20
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// lfsx f20,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r11,r9,208
	ctx.r11.s64 = ctx.r9.s64 * 208;
	// fmadds f18,f15,f11,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 + ctx.f18.f64));
	// stfs f18,348(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// lfsx f18,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r9,48
	ctx.r11.s64 = ctx.r9.s64 * 48;
	// lfsx f17,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r8,80
	ctx.r11.s64 = ctx.r8.s64 * 80;
	// lfsx f16,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r8,176
	ctx.r11.s64 = ctx.r8.s64 * 176;
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fmuls f15,f21,f11
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// mulli r11,r9,80
	ctx.r11.s64 = ctx.r9.s64 * 80;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fmuls f14,f21,f10
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// mulli r11,r9,176
	ctx.r11.s64 = ctx.r9.s64 * 176;
	// fmsubs f15,f22,f10,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f15.f64));
	// mulli r10,r8,240
	ctx.r10.s64 = ctx.r8.s64 * 240;
	// stfs f15,344(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// fsubs f15,f20,f19
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfsx f21,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f22,f22,f11,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 + ctx.f14.f64));
	// stfs f22,372(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfsx f19,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f19.f64 = double(temp.f32);
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r10,r9,240
	ctx.r10.s64 = ctx.r9.s64 * 240;
	// lfsx f22,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r11,r8,144
	ctx.r11.s64 = ctx.r8.s64 * 144;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fadds f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// mulli r11,r8,112
	ctx.r11.s64 = ctx.r8.s64 * 112;
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,52(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// rlwinm r11,r9,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f17,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r9,144
	ctx.r11.s64 = ctx.r9.s64 * 144;
	// stfs f17,88(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfsx f17,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,32(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,248(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r9,112
	ctx.r11.s64 = ctx.r9.s64 * 112;
	// stfs f16,236(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,48(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f16,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f21,f16
	ctx.f16.f64 = double(float(ctx.f21.f64 + ctx.f16.f64));
	// stfs f16,240(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f16,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// fadds f16,f19,f22
	ctx.f16.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// fadds f19,f14,f15
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f19,76(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fsubs f19,f15,f14
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f19,60(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f14,f15
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f19,96(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fsubs f19,f15,f14
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f19,28(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f19,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f15,f19
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// stfs f19,128(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f19,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f15,f19
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// stfs f19,112(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f15,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f19.f64 = double(temp.f32);
	// fadds f14,f15,f19
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// stfs f19,44(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f19,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f19,52(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f19,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f19,24(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// mulli r10,r8,252
	ctx.r10.s64 = ctx.r8.s64 * 252;
	// fmuls f19,f15,f0
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f19,32(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f19,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f19.f64 = double(temp.f32);
	// fadds f15,f19,f16
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// fadds f19,f17,f20
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// lfs f17,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f19,f15
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f19,408(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// fmuls f19,f14,f9
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f9.f64));
	// stfs f19,100(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f19,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f22
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f19,f15
	ctx.f14.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// stfs f14,144(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fadds f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f19,240(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f19,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f19,f15
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f14,280(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// stfs f19,248(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f19,52(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fadds f19,f21,f18
	ctx.f19.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfs f19,24(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f19,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f19,f15
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// lfs f19,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// stfs f20,32(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f14,f19,f14
	ctx.f14.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f20,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,88(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fsubs f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 - ctx.f19.f64));
	// lfsx f16,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r8,132
	ctx.r11.s64 = ctx.r8.s64 * 132;
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// lfsx f18,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f15,f0
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f17,48(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fmuls f17,f14,f0
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f17,236(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r8,124
	ctx.r11.s64 = ctx.r8.s64 * 124;
	// stfs f17,164(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// mulli r11,r8,60
	ctx.r11.s64 = ctx.r8.s64 * 60;
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// mulli r11,r8,196
	ctx.r11.s64 = ctx.r8.s64 * 196;
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,196(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// mulli r11,r9,196
	ctx.r11.s64 = ctx.r9.s64 * 196;
	// lfsx f17,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r9,60
	ctx.r11.s64 = ctx.r9.s64 * 60;
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f15,f17
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,400(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// fadds f15,f21,f19
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// lfsx f17,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// stfs f21,320(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfs f21,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// mulli r11,r8,68
	ctx.r11.s64 = ctx.r8.s64 * 68;
	// fadds f19,f20,f21
	ctx.f19.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f19,436(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfs f15,536(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 536, temp.u32);
	// fadds f15,f18,f16
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f21,540(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 540, temp.u32);
	// lfs f20,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f14,f9
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f9.f64));
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// fadds f16,f19,f20
	ctx.f16.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfs f21,72(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f21,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfs f20,360(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// mulli r11,r8,188
	ctx.r11.s64 = ctx.r8.s64 * 188;
	// lfs f20,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f20.f64 = double(temp.f32);
	// fadds f19,f22,f20
	ctx.f19.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f16,284(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f22,220(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// stfs f19,376(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// lfsx f22,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r9,68
	ctx.r11.s64 = ctx.r9.s64 * 68;
	// lfs f19,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f16,f19
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// mulli r11,r9,188
	ctx.r11.s64 = ctx.r9.s64 * 188;
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,36(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f16,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r9,132
	ctx.r11.s64 = ctx.r9.s64 * 132;
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,60(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r9,124
	ctx.r11.s64 = ctx.r9.s64 * 124;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r9,252
	ctx.r10.s64 = ctx.r9.s64 * 252;
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f14,f21,f22
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfs f22,44(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f17,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f21,28(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f21,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,112(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f22,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f22.f64 = double(temp.f32);
	// fadds f21,f22,f16
	ctx.f21.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// stfs f21,36(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// lfs f21,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// lfs f16,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// stfs f22,128(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fadds f22,f16,f21
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// fsubs f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// mulli r10,r8,200
	ctx.r10.s64 = ctx.r8.s64 * 200;
	// fsubs f16,f17,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f16,96(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r8,56
	ctx.r11.s64 = ctx.r8.s64 * 56;
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,76(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f14,f20,f15
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fsubs f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f20,52(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,200(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,420(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// fsubs f14,f16,f21
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f16,f21
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// fadds f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f22,24(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f21,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfs f21,88(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfsx f21,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// mulli r11,r9,200
	ctx.r11.s64 = ctx.r9.s64 * 200;
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f22,f17,f0
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f17,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f20,20(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f20,32(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f17,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fmuls f17,f14,f0
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f14,f0
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfsx f14,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,48(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f19,40(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r9,56
	ctx.r11.s64 = ctx.r9.s64 * 56;
	// stfs f14,164(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// mulli r11,r8,72
	ctx.r11.s64 = ctx.r8.s64 * 72;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// mulli r11,r8,184
	ctx.r11.s64 = ctx.r8.s64 * 184;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,196(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// mulli r11,r9,72
	ctx.r11.s64 = ctx.r9.s64 * 72;
	// mulli r10,r8,248
	ctx.r10.s64 = ctx.r8.s64 * 248;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,136(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,236(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f22,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,504(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,384(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r11,r9,184
	ctx.r11.s64 = ctx.r9.s64 * 184;
	// fadds f14,f20,f22
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f14,500(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// fsubs f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// lfs f20,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f20.f64 = double(temp.f32);
	// stfs f22,292(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fadds f22,f20,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f20,88(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f20,f16,f18
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f22,180(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,424(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// lfs f18,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// fadds f16,f18,f15
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// lfsx f22,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// stfs f18,368(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// stfs f16,300(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fsubs f16,f18,f19
	ctx.f16.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f19,208(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfsx f19,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f19.f64 = double(temp.f32);
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// stfs f20,288(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fsubs f20,f21,f17
	ctx.f20.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// lfs f15,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f15.f64 = double(temp.f32);
	// fadds f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f17,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// mulli r11,r8,136
	ctx.r11.s64 = ctx.r8.s64 * 136;
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,76(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f18,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// mulli r11,r8,120
	ctx.r11.s64 = ctx.r8.s64 * 120;
	// stfs f16,404(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r9,136
	ctx.r11.s64 = ctx.r9.s64 * 136;
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// mulli r11,r9,120
	ctx.r11.s64 = ctx.r9.s64 * 120;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// mulli r10,r9,248
	ctx.r10.s64 = ctx.r9.s64 * 248;
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f16,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r8,20
	ctx.r11.s64 = ctx.r8.s64 * 20;
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// mulli r10,r8,236
	ctx.r10.s64 = ctx.r8.s64 * 236;
	// fadds f14,f18,f19
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fsubs f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f18,44(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f18,f16,f17
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fadds f18,f17,f20
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f20,164(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f16,f17,f20
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f16,60(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,52(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f17,f18
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f18,24(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,32(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f17,f15,f21
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// mulli r11,r8,148
	ctx.r11.s64 = ctx.r8.s64 * 148;
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// stfs f21,64(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fadds f17,f17,f19
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f17,48(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fsubs f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f20
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// stfs f17,96(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f15,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f14,f17
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f15,120(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,24(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f20,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f20.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f22,132(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfsx f22,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r11,r8,108
	ctx.r11.s64 = ctx.r8.s64 * 108;
	// stfs f22,104(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfsx f22,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r11,r9,20
	ctx.r11.s64 = ctx.r9.s64 * 20;
	// stfs f22,36(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f20,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f22,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r11,r9,236
	ctx.r11.s64 = ctx.r9.s64 * 236;
	// stfs f22,44(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f22,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,80(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// mulli r11,r9,148
	ctx.r11.s64 = ctx.r9.s64 * 148;
	// lfs f22,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f20,f22
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// fsubs f15,f20,f22
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f22,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,60(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r11,r9,108
	ctx.r11.s64 = ctx.r9.s64 * 108;
	// fadds f20,f20,f22
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f20,92(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f22,412(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fadds f22,f17,f18
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f22,572(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 572, temp.u32);
	// fsubs f22,f18,f17
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f22,528(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 528, temp.u32);
	// fmuls f18,f14,f0
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f16
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfsx f20,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,196(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r8,84
	ctx.r11.s64 = ctx.r8.s64 * 84;
	// fadds f14,f21,f16
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f16.f64));
	// stfs f14,448(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// fsubs f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfs f21,576(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 576, temp.u32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f22,f15,f0
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f21,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f21.f64 = double(temp.f32);
	// fadds f14,f16,f21
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// stfs f14,380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fsubs f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,444(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// stfs f21,548(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 548, temp.u32);
	// lfsx f21,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// mulli r11,r8,172
	ctx.r11.s64 = ctx.r8.s64 * 172;
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f17,264(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// stfs f16,56(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// mulli r11,r9,84
	ctx.r11.s64 = ctx.r9.s64 * 84;
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r9,172
	ctx.r11.s64 = ctx.r9.s64 * 172;
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r8,44
	ctx.r11.s64 = ctx.r8.s64 * 44;
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r9,44
	ctx.r10.s64 = ctx.r9.s64 * 44;
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r8,212
	ctx.r11.s64 = ctx.r8.s64 * 212;
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r9,212
	ctx.r11.s64 = ctx.r9.s64 * 212;
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,272(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f22,164(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f22,f18,f19
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f22,252(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fsubs f22,f19,f18
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f22,552(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 552, temp.u32);
	// lfs f22,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f19.f64 = double(temp.f32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// lfs f18,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f19,f21
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f18,f17
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,44(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r8,12
	ctx.r11.s64 = ctx.r8.s64 * 12;
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f14,f16,f22
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// fadds f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// stfs f22,120(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f22,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfsx f16,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f22,132(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// mulli r11,r8,244
	ctx.r11.s64 = ctx.r8.s64 * 244;
	// lfsx f22,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r8,116
	ctx.r11.s64 = ctx.r8.s64 * 116;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// mulli r11,r8,140
	ctx.r11.s64 = ctx.r8.s64 * 140;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// mulli r11,r9,244
	ctx.r11.s64 = ctx.r9.s64 * 244;
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// fadds f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,96(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,176(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fsubs f15,f19,f20
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// stfs f20,216(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f20,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfs f20,36(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fadds f19,f22,f17
	ctx.f19.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,52(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fsubs f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f17,f14
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f15,104(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,80(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f15,f16,f13
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fadds f14,f20,f18
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// stfs f20,32(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f18,f22,f21
	ctx.f18.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// fsubs f20,f21,f22
	ctx.f20.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f19,f22
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f19,f22,f19
	ctx.f19.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f19,48(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f22,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f21,24(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// fmuls f21,f20,f0
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmuls f20,f18,f0
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fmuls f18,f14,f0
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f18,52(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f19,f12
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f19,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f14,516(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r9,116
	ctx.r11.s64 = ctx.r9.s64 * 116;
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f17,f14,f13,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 - ctx.f17.f64));
	// stfs f17,532(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// mulli r10,r9,140
	ctx.r10.s64 = ctx.r9.s64 * 140;
	// fmadds f18,f17,f13,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f18.f64));
	// stfs f18,396(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fadds f17,f18,f21
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f17,352(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// fsubs f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// stfs f21,388(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// lfs f21,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f18,f21,f12,f15
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 - ctx.f15.f64));
	// stfs f18,168(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fmadds f21,f21,f13,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f21,312(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f21,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f21.f64 = double(temp.f32);
	// fadds f18,f20,f21
	ctx.f18.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f18,328(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,568(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 568, temp.u32);
	// lfs f20,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f21,f20
	ctx.f18.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f18,336(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f21,52(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f20,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f21.f64 = double(temp.f32);
	// fadds f18,f21,f20
	ctx.f18.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f18,440(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,276(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f20,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfsx f20,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r11,r8,52
	ctx.r11.s64 = ctx.r8.s64 * 52;
	// lfsx f18,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r8,204
	ctx.r11.s64 = ctx.r8.s64 * 204;
	// lfsx f16,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r9,52
	ctx.r11.s64 = ctx.r9.s64 * 52;
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r9,204
	ctx.r11.s64 = ctx.r9.s64 * 204;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// mulli r11,r8,76
	ctx.r11.s64 = ctx.r8.s64 * 76;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// mulli r11,r8,180
	ctx.r11.s64 = ctx.r8.s64 * 180;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f14,f20,f18
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// mulli r11,r9,180
	ctx.r11.s64 = ctx.r9.s64 * 180;
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// lfsx f18,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,28(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// mulli r11,r9,76
	ctx.r11.s64 = ctx.r9.s64 * 76;
	// lfsx f18,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f18,f16,f17
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,60(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f20,120(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f20,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f17,f18,f14
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// fsubs f14,f16,f20
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// fadds f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// stfs f20,36(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// lfs f16,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f17,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f16,48(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f16,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f17,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f17,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,224(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f18,f17
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f17,f18,f14
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// fadds f16,f14,f18
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// fsubs f18,f15,f20
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f18,104(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,152(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmuls f20,f17,f0
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f20,32(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmuls f20,f16,f0
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmuls f20,f14,f0
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f20,132(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f20,f13
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// lfs f20,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f20,f13
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// fmuls f15,f20,f12
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f14,f20,f13
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f20,508(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// lfs f20,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f18,f20,f12,f17
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f17.f64));
	// stfs f18,556(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 556, temp.u32);
	// fmsubs f20,f20,f13,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f15.f64));
	// lfs f18,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f18.f64 = double(temp.f32);
	// stfs f20,512(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// fadds f20,f21,f18
	ctx.f20.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r8,36
	ctx.r11.s64 = ctx.r8.s64 * 36;
	// fsubs f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// lfs f18,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// mulli r10,r8,220
	ctx.r10.s64 = ctx.r8.s64 * 220;
	// fsubs f15,f17,f20
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f15,304(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfs f20,356(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f12,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f16.f64));
	// stfs f20,268(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f20,f20,f12,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 - ctx.f14.f64));
	// stfs f20,296(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f20.f64 = double(temp.f32);
	// fadds f16,f17,f20
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f16,332(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f20,184(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f17,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f16,f20,f17
	ctx.f16.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f16,212(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,24(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f20,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f20,f17
	ctx.f17.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// lfs f20,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f20,520(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// lfsx f20,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r11,r9,36
	ctx.r11.s64 = ctx.r9.s64 * 36;
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r9,220
	ctx.r11.s64 = ctx.r9.s64 * 220;
	// fmuls f18,f17,f0
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfsx f17,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r8,164
	ctx.r11.s64 = ctx.r8.s64 * 164;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// mulli r11,r8,92
	ctx.r11.s64 = ctx.r8.s64 * 92;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// mulli r11,r9,164
	ctx.r11.s64 = ctx.r9.s64 * 164;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f14,f21,f18
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// mulli r11,r9,92
	ctx.r11.s64 = ctx.r9.s64 * 92;
	// stfs f14,192(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f21,132(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fsubs f21,f20,f17
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// lfsx f18,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r8,228
	ctx.r11.s64 = ctx.r8.s64 * 228;
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// mulli r11,r9,228
	ctx.r11.s64 = ctx.r9.s64 * 228;
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,68(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,48(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// mulli r11,r9,28
	ctx.r11.s64 = ctx.r9.s64 * 28;
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,36(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// mulli r11,r8,100
	ctx.r11.s64 = ctx.r8.s64 * 100;
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r8,156
	ctx.r11.s64 = ctx.r8.s64 * 156;
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r9,100
	ctx.r11.s64 = ctx.r9.s64 * 100;
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r9,156
	ctx.r11.s64 = ctx.r9.s64 * 156;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,120(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f18,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f18,116(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fsubs f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f18,96(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fadds f18,f16,f20
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// fsubs f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f21
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// stfs f16,76(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f21,104(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f21,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f21.f64 = double(temp.f32);
	// fadds f14,f21,f15
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// stfs f21,112(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// lfs f21,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f15,f21,f13
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// stfs f21,128(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f21,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f21,48(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f21,16(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f21,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f21,f21,f12,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 - ctx.f15.f64));
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r8,40
	ctx.r11.s64 = ctx.r8.s64 * 40;
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r8,216
	ctx.r10.s64 = ctx.r8.s64 * 216;
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f15,f13
	ctx.f14.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f18
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// stfs f15,156(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f18,428(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// fmsubs f18,f15,f12,f14
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f14.f64));
	// fadds f14,f18,f21
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f14,188(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f21,32(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f21,f20,f16
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f21,120(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f21,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f21.f64 = double(temp.f32);
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f20,80(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f16,f17,f12
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f18,f21
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fsubs f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// stfs f21,40(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f21,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// mulli r11,r9,40
	ctx.r11.s64 = ctx.r9.s64 * 40;
	// stfs f21,20(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f18,f15,f13
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// lfs f21,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f21,f13
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfsx f21,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,176(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f21,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f15,f21,f13
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmuls f14,f21,f12
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfsx f21,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,260(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// mulli r11,r9,216
	ctx.r11.s64 = ctx.r9.s64 * 216;
	// lfs f21,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f12,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f20.f64));
	// lfs f20,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f12,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f18.f64));
	// lfs f18,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f16,f18,f13,f16
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f16,104(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f18,f18,f12,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 + ctx.f17.f64));
	// fmadds f16,f16,f12,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f15.f64));
	// stfs f16,64(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f16.f64 = double(temp.f32);
	// stfs f18,256(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfsx f18,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r8,168
	ctx.r11.s64 = ctx.r8.s64 * 168;
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// stfs f18,68(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// stfs f16,108(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmsubs f18,f18,f13,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 - ctx.f14.f64));
	// lfs f16,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f16.f64 = double(temp.f32);
	// stfs f18,84(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfsx f18,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r8,88
	ctx.r11.s64 = ctx.r8.s64 * 88;
	// stfs f18,116(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f16,228(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfsx f18,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// mulli r11,r9,168
	ctx.r11.s64 = ctx.r9.s64 * 168;
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f18.f64 = double(temp.f32);
	// fadds f16,f17,f18
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fsubs f15,f18,f17
	ctx.f15.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfsx f18,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// mulli r11,r9,88
	ctx.r11.s64 = ctx.r9.s64 * 88;
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f18,48(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f18,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r8,24
	ctx.r11.s64 = ctx.r8.s64 * 24;
	// fmuls f17,f16,f0
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f17,76(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fmuls f17,f15,f0
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f17,392(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f17,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fmuls f16,f14,f0
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fsubs f14,f21,f20
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f14,160(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// lfs f20,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// stfs f21,48(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f21,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f21.f64 = double(temp.f32);
	// fadds f14,f20,f21
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f14,324(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// lfs f14,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f20.f64 = double(temp.f32);
	// stfs f21,120(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f21,f20,f14
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// fadds f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// stfs f20,60(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f20,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// stfs f20,44(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f20,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// stfs f14,228(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f20,104(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f20,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// stfs f15,316(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fadds f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r8,232
	ctx.r11.s64 = ctx.r8.s64 * 232;
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// stfs f21,128(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// lfsx f21,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fadds f18,f21,f15
	ctx.f18.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// fsubs f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f21,176(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fsubs f18,f17,f20
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f15,f14
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r9,232
	ctx.r11.s64 = ctx.r9.s64 * 232;
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r9,24
	ctx.r10.s64 = ctx.r9.s64 * 24;
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,68(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f18,f15
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f14,108(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// stfs f18,260(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fmuls f15,f21,f13
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfsx f18,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f21,f12
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfs f21,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f21.f64 = double(temp.f32);
	// stfs f18,116(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmuls f21,f21,f12
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfsx f18,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r8,104
	ctx.r11.s64 = ctx.r8.s64 * 104;
	// stfs f18,80(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f21,40(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fadds f21,f20,f17
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// lfs f18,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f18.f64 = double(temp.f32);
	// lfs f20,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// stfs f18,64(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fmr f18,f20
	ctx.f18.f64 = ctx.f20.f64;
	// lfs f17,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f20,f18,f12,f15
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 - ctx.f15.f64));
	// fmadds f18,f18,f13,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f18,256(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfsx f18,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r8,152
	ctx.r11.s64 = ctx.r8.s64 * 152;
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f17,f17,f13,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f17,204(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f17,f17,f13,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f17,148(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r9,104
	ctx.r11.s64 = ctx.r9.s64 * 104;
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,68(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// mulli r11,r9,152
	ctx.r11.s64 = ctx.r9.s64 * 152;
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fadds f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f18,84(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f17,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f17,f17,f18
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f17,116(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f17,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f17.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,80(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,68(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,84(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f17,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f18,f17
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f18,28(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f18,f13
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// fmuls f15,f15,f12
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,116(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f21,96(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f21,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// stfs f21,80(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f21,f12
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfs f21,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f17,f21,f12,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 - ctx.f17.f64));
	// stfs f17,64(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fmadds f21,f21,f13,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 + ctx.f18.f64));
	// stfs f21,176(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f13,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f21,68(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f21,f21,f13,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f21,84(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f21,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fadds f17,f18,f21
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// fsubs f15,f21,f18
	ctx.f15.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f21.f64 = double(temp.f32);
	// fadds f14,f18,f21
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// fsubs f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// stfs f21,80(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f21,f17,f0
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fmuls f18,f15,f0
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f18,112(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f18,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f18.f64 = double(temp.f32);
	// fadds f17,f18,f20
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f17,340(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f20,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f17,f20,f18
	ctx.f17.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f17,108(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f20,64(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fmuls f20,f14,f0
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f20,f17,f0
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f20,20(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f20,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f20.f64 = double(temp.f32);
	// fadds f17,f18,f20
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f17,256(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// lfs f18,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f18.f64 = double(temp.f32);
	// stfs f20,80(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f20,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f20.f64 = double(temp.f32);
	// rlwinm r11,r7,7,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 7) & 0xFFFFFF80;
	// fadds f17,f18,f20
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f17,260(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fsubs f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// stfs f20,176(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f20,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f20.f64 = double(temp.f32);
	// rlwinm r10,r7,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f18,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// mulli r31,r7,192
	ctx.r31.s64 = ctx.r7.s64 * 192;
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// lfs f17,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f15,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f14,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,148(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// mulli r30,r7,160
	ctx.r30.s64 = ctx.r7.s64 * 160;
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f15,204(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f14,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,224(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f15,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,208(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// rlwinm r29,r7,5,0,26
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// mulli r28,r7,96
	ctx.r28.s64 = ctx.r7.s64 * 96;
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f14,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f22,156(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f22,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// mulli r27,r7,224
	ctx.r27.s64 = ctx.r7.s64 * 224;
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,152(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,124(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f22,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f14,140(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// mulli r26,r7,144
	ctx.r26.s64 = ctx.r7.s64 * 144;
	// fsubs f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f20,116(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fsubs f20,f18,f17
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f20,84(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fadds f17,f17,f18
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fmuls f22,f22,f9
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f9.f64));
	// rlwinm r25,r7,4,0,27
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f20,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f14,f20,f18
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f14,148(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fadds f18,f18,f20
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// lfs f20,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f14,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f20,208(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f20,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,200(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f20,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f17,f9
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// stfs f14,92(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f20,100(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f17,152(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f20,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,216(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fmuls f20,f18,f9
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// stfs f20,204(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f20,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f20,156(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f20,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f17,f20,f18
	ctx.f17.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f17,72(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fadds f17,f18,f20
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// lfs f18,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f18.f64 = double(temp.f32);
	// lfs f20,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f20.f64 = double(temp.f32);
	// stfs f14,224(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fadds f14,f18,f20
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// fsubs f15,f20,f18
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// lfs f20,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f10
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// stfs f20,56(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f18,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f18,f22
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// fmuls f18,f17,f9
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// stfs f18,124(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f18,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f14,f4
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f4.f64));
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// stfs f17,140(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fmuls f18,f15,f4
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// lfs f17,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f17,f17,f11,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 - ctx.f15.f64));
	// stfs f17,148(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f17,f15
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// fadds f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// fmuls f17,f14,f4
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f4.f64));
	// stfs f17,92(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f17,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f15,f4
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// stfsx f14,r11,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f20,0(r3)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f20,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f14,f22,f20
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfsx f14,r10,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfsx f22,r31,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// lfs f20,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// lfs f20,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f14,f20,f18
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfsx f14,r30,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfsx f20,r29,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f20,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f17,f20
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfsx f18,r28,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f18,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// fsubs f17,f22,f18
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfsx f20,r27,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfsx f17,r26,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// stfsx f22,r25,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// mulli r24,r7,112
	ctx.r24.s64 = ctx.r7.s64 * 112;
	// lfs f18,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f18.f64 = double(temp.f32);
	// mulli r23,r7,240
	ctx.r23.s64 = ctx.r7.s64 * 240;
	// lfs f22,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,56(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,124(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f18,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// stfs f22,100(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f18,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f22,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f10
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// lfs f17,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f18.f64 = double(temp.f32);
	// mulli r22,r7,80
	ctx.r22.s64 = ctx.r7.s64 * 80;
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f18,140(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f18,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f10
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64));
	// lfs f14,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f10
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// lfs f20,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// mulli r21,r7,208
	ctx.r21.s64 = ctx.r7.s64 * 208;
	// fmsubs f22,f14,f11,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 - ctx.f22.f64));
	// stfs f22,152(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f22,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f11
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// lfs f22,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f11,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 + ctx.f18.f64));
	// stfs f22,200(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f22,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// lfs f18,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f18,204(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f18,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f18.f64 = double(temp.f32);
	// mulli r20,r7,176
	ctx.r20.s64 = ctx.r7.s64 * 176;
	// fmadds f18,f18,f11,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 + ctx.f17.f64));
	// stfs f18,148(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f18,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f10,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64 - ctx.f14.f64));
	// stfs f18,216(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f18,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// mulli r19,r7,48
	ctx.r19.s64 = ctx.r7.s64 * 48;
	// mulli r18,r7,132
	ctx.r18.s64 = ctx.r7.s64 * 132;
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f18,f17
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f15,156(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f18,208(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// rlwinm r17,r7,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f14,f15,f7
	ctx.f14.f64 = double(float(ctx.f15.f64 * ctx.f7.f64));
	// mulli r16,r7,100
	ctx.r16.s64 = ctx.r7.s64 * 100;
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f17,f18
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f15,224(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f15,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f21,f15
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fmuls f15,f15,f7
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f7.f64));
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// mulli r15,r7,228
	ctx.r15.s64 = ctx.r7.s64 * 228;
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f8,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f8.f64 - ctx.f14.f64));
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f14,f8,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f8.f64 + ctx.f15.f64));
	// stfs f15,124(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,92(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// stfsx f14,r24,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// stfsx f20,r23,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// lfs f20,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f14,f22,f20
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfsx f14,r22,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfsx f22,r21,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// lfs f20,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f22,f20
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfsx f14,r20,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfsx f22,r19,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// lfs f20,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f14,f20,f31
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f31.f64));
	// lfs f20,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f22,f20,f3,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f3.f64 - ctx.f22.f64));
	// fmadds f14,f18,f1,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f1.f64 + ctx.f14.f64));
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f20,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,56(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f20,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,100(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfsx f14,r18,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfsx f22,r17,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f17,f20,f22
	ctx.f17.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// stfsx f17,r16,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfsx f22,r15,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f22.f64 = double(temp.f32);
	// fadds f20,f22,f19
	ctx.f20.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// lfs f22,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// lfs f14,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,92(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f14,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,68(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f14,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,84(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f14,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,200(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f22,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// stfs f20,152(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmuls f20,f17,f0
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f20,216(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f20,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// fmuls f17,f20,f3
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// lfs f20,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f1
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f1.f64));
	// stfs f20,56(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f22,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f22.f64 = double(temp.f32);
	// mulli r14,r7,68
	ctx.r14.s64 = ctx.r7.s64 * 68;
	// fsubs f22,f23,f22
	ctx.f22.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fmuls f14,f14,f4
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f4.f64));
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f15,f14
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f15,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f17,f15,f2,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f2.f64 + ctx.f17.f64));
	// stfs f17,140(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f15,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f18,f18,f31,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f31.f64 - ctx.f17.f64));
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f18,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f18,f10
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f10.f64));
	// lfs f18,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f18,f10
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f10.f64));
	// lfs f18,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// stfs f18,148(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f18,156(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f18,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f18,204(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f15,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f17,f15,f11,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 - ctx.f17.f64));
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// stfs f17,92(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fadds f17,f15,f22
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f22,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f11,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 + ctx.f14.f64));
	// stfs f22,124(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f22,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f22,f15
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfsx f14,r14,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,196
	ctx.r14.s64 = ctx.r7.s64 * 196;
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfsx f22,r14,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,164
	ctx.r14.s64 = ctx.r7.s64 * 164;
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f15,f20,f22
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// stfsx f15,r14,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,36
	ctx.r14.s64 = ctx.r7.s64 * 36;
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// fmuls f15,f18,f5
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f5.f64));
	// stfsx f22,r14,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f22,f7
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f7.f64));
	// fmuls f14,f22,f8
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// lfs f22,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f22,56(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f22,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f22,100(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f17,72(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f20,f17,f8,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f8.f64 - ctx.f20.f64));
	// stfs f20,92(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f20,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f20.f64 = double(temp.f32);
	// mulli r14,r7,136
	ctx.r14.s64 = ctx.r7.s64 * 136;
	// fmuls f17,f20,f5
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f5.f64));
	// fmadds f20,f20,f6,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 + ctx.f15.f64));
	// lfs f15,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f15,f15,f7,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f7.f64 + ctx.f14.f64));
	// stfs f15,140(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// stfs f17,56(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fmr f17,f15
	ctx.f17.f64 = ctx.f15.f64;
	// lfs f15,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfsx f15,r14,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// rlwinm r14,r7,3,0,28
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f15,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f17,r14,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,104
	ctx.r14.s64 = ctx.r7.s64 * 104;
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f17,f20
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// lfs f17,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f15,r14,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,232
	ctx.r14.s64 = ctx.r7.s64 * 232;
	// stfsx f20,r14,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f20,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f20.f64 = double(temp.f32);
	// mulli r14,r7,72
	ctx.r14.s64 = ctx.r7.s64 * 72;
	// fsubs f15,f20,f17
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f17,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f15,r14,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r7,200
	ctx.r14.s64 = ctx.r7.s64 * 200;
	// stfsx f20,r14,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f20,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// lfs f17,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// stfs f21,100(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f21,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f21.f64 = double(temp.f32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfs f21,448(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// lfs f21,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfs f21,72(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f16,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f16.f64 = double(temp.f32);
	// lfs f21,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfs f21,396(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// lfs f21,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f21,f10
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// lfs f21,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// stfs f21,416(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// lfs f21,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f21,f15
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// fmsubs f21,f18,f6,f14
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f6.f64 - ctx.f14.f64));
	// lfs f18,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f11,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 + ctx.f16.f64));
	// lfs f16,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f16.f64 = double(temp.f32);
	// fadds f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// fmuls f16,f15,f4
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// fadds f15,f17,f20
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f20,56(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f14,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f5
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f5.f64));
	// lfs f20,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f20
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f17,308(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f17,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r7,168
	ctx.r14.s64 = ctx.r7.s64 * 168;
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f20,408(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// lfs f20,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f20,f5
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f5.f64));
	// fmsubs f20,f20,f6,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 - ctx.f14.f64));
	// fsubs f14,f22,f21
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfsx f14,r14,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r7,40
	ctx.r14.s64 = ctx.r7.s64 * 40;
	// fsubs f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfs f14,436(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f14,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f21,f15,f29
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f29.f64));
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// lfs f14,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f22,r14,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fsubs f22,f23,f16
	ctx.f22.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// fadds f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// stfs f23,400(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// lfs f23,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f15,f30
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f30.f64));
	// fmuls f15,f23,f27
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f27.f64));
	// mulli r14,r7,148
	ctx.r14.s64 = ctx.r7.s64 * 148;
	// fmadds f17,f14,f6,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f6.f64 + ctx.f17.f64));
	// fmuls f14,f23,f28
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// lfs f23,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f23,f30,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64 - ctx.f21.f64));
	// lfs f21,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f28,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f28.f64 + ctx.f15.f64));
	// lfs f15,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f16,f15,f29,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f29.f64 + ctx.f16.f64));
	// lfs f15,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f20,f15
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f15,308(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f15,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// fadds f15,f17,f18
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f17,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f27,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f27.f64 - ctx.f14.f64));
	// lfs f14,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f23
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// stfsx f14,r14,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,20
	ctx.r14.s64 = ctx.r7.s64 * 20;
	// lfs f14,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfsx f23,r14,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fsubs f23,f15,f21
	ctx.f23.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// mulli r14,r7,116
	ctx.r14.s64 = ctx.r7.s64 * 116;
	// stfsx f23,r14,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fadds f23,f21,f15
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// lfs f21,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f21.f64 = double(temp.f32);
	// mulli r14,r7,244
	ctx.r14.s64 = ctx.r7.s64 * 244;
	// stfsx f23,r14,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fsubs f23,f20,f16
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// mulli r14,r7,84
	ctx.r14.s64 = ctx.r7.s64 * 84;
	// stfsx f23,r14,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fadds f23,f16,f20
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// lfs f20,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f20.f64 = double(temp.f32);
	// mulli r14,r7,212
	ctx.r14.s64 = ctx.r7.s64 * 212;
	// stfsx f23,r14,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fsubs f23,f18,f17
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// mulli r14,r7,180
	ctx.r14.s64 = ctx.r7.s64 * 180;
	// stfsx f23,r14,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fadds f23,f17,f18
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// mulli r14,r7,52
	ctx.r14.s64 = ctx.r7.s64 * 52;
	// stfsx f23,r14,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f23,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f18,f23,f21
	ctx.f18.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// lfs f23,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f17,f23,f19
	ctx.f17.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// lfs f21,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// lfs f21,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// lfs f19,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// lfs f16,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f18,f0
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fsubs f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// lfs f16,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f16,f11
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,444(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// lfs f14,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r7,152
	ctx.r14.s64 = ctx.r7.s64 * 152;
	// lfs f16,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,420(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// lfs f14,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,72(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f14,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,56(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f14,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f14,f10,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 - ctx.f15.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f15,f20,f11
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// fmuls f14,f20,f10
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// fadds f20,f23,f18
	ctx.f20.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f20,140(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fadds f20,f17,f19
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// fsubs f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// fmsubs f18,f21,f10,f15
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 - ctx.f15.f64));
	// fmadds f21,f21,f11,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 + ctx.f14.f64));
	// lfs f17,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f17,f6
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f14,404(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,428(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f14,100(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,148(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f17,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f5,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f5.f64 - ctx.f15.f64));
	// stfs f17,412(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fmuls f15,f23,f7
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f7.f64));
	// lfs f17,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f23,f23,f8
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// stfs f23,56(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fmuls f16,f17,f6
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// fmuls f14,f17,f5
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f5.f64));
	// fadds f17,f18,f22
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f17,72(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// lfs f17,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f17.f64 = double(temp.f32);
	// fadds f23,f21,f17
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// fsubs f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// fmadds f17,f19,f8,f15
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f8.f64 + ctx.f15.f64));
	// fmsubs f18,f20,f5,f16
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f5.f64 - ctx.f16.f64));
	// fmadds f20,f20,f6,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 + ctx.f14.f64));
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f19,f19,f7,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 - ctx.f16.f64));
	// lfs f16,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f16,f18
	ctx.f15.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfsx f15,r14,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,24
	ctx.r14.s64 = ctx.r7.s64 * 24;
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfsx f18,r14,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fsubs f18,f23,f17
	ctx.f18.f64 = double(float(ctx.f23.f64 - ctx.f17.f64));
	// mulli r14,r7,120
	ctx.r14.s64 = ctx.r7.s64 * 120;
	// stfsx f18,r14,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,248
	ctx.r14.s64 = ctx.r7.s64 * 248;
	// fadds f23,f17,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// lfs f17,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f23,r14,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,88
	ctx.r14.s64 = ctx.r7.s64 * 88;
	// fsubs f23,f22,f20
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfsx f23,r14,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fadds f23,f20,f22
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// mulli r14,r7,216
	ctx.r14.s64 = ctx.r7.s64 * 216;
	// lfs f22,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f23,r14,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fsubs f23,f21,f19
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// mulli r14,r7,184
	ctx.r14.s64 = ctx.r7.s64 * 184;
	// stfsx f23,r14,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fadds f23,f19,f21
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// lfs f21,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f21,f5
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// lfs f21,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f21.f64 = double(temp.f32);
	// mulli r14,r7,56
	ctx.r14.s64 = ctx.r7.s64 * 56;
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// lfs f19,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// lfs f19,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f19,f10
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// lfs f19,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f23,r14,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// lfs f23,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// lfs f14,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f17,f18
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f17,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,292(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f14,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,168(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f17,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f6,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f6.f64 + ctx.f16.f64));
	// stfs f17,316(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f16,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,312(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f17,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f17,f27
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f27.f64));
	// lfs f17,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f11,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f15.f64));
	// stfs f17,320(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfs f17,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f17,f30
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// lfs f17,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// lfs f14,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// fadds f14,f22,f23
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f14,268(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f23,296(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fmuls f22,f20,f8
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// fmuls f14,f21,f8
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f8.f64));
	// lfs f23,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f23,392(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f23,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// stfs f23,292(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f23,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f18,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f20,f20,f7,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f14.f64));
	// lfs f14,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f19,f14
	ctx.f14.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfs f14,316(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f14,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// fadds f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f19,320(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfs f18,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f22,f21,f7,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 - ctx.f22.f64));
	// lfs f19,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r7,140
	ctx.r14.s64 = ctx.r7.s64 * 140;
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// lfs f21,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f21.f64 = double(temp.f32);
	// stfs f19,312(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// lfs f19,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f19,f30
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// lfs f19,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f19,f27
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f27.f64));
	// fmsubs f19,f19,f28,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f28.f64 - ctx.f16.f64));
	// lfs f16,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f18,f16,f29,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f29.f64 + ctx.f18.f64));
	// lfs f16,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f28,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f28.f64 + ctx.f14.f64));
	// lfs f14,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f14,f29,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f29.f64 - ctx.f15.f64));
	// stfs f15,168(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f15,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f31
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// lfs f14,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f14,296(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f14,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfsx f14,r14,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,12
	ctx.r14.s64 = ctx.r7.s64 * 12;
	// lfs f14,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfsx f19,r14,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f19,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r7,108
	ctx.r14.s64 = ctx.r7.s64 * 108;
	// fsubs f14,f19,f18
	ctx.f14.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfsx f14,r14,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r7,236
	ctx.r14.s64 = ctx.r7.s64 * 236;
	// stfsx f19,r14,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fsubs f19,f17,f16
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// mulli r14,r7,76
	ctx.r14.s64 = ctx.r7.s64 * 76;
	// stfsx f19,r14,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fadds f19,f16,f17
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fmuls f17,f21,f31
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f31.f64));
	// mulli r14,r7,204
	ctx.r14.s64 = ctx.r7.s64 * 204;
	// stfsx f19,r14,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f19,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r7,172
	ctx.r14.s64 = ctx.r7.s64 * 172;
	// fsubs f18,f23,f19
	ctx.f18.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// fadds f23,f19,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// lfs f19,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f18,r14,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,44
	ctx.r14.s64 = ctx.r7.s64 * 44;
	// stfsx f23,r14,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f23,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f23,f3
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f23,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f23,f3
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f23,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// stfs f23,56(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f23,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// lfs f14,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfs f19,256(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f14,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfs f19,260(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f19,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f19,f7
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f7.f64));
	// lfs f19,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f21,f21,f1,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 - ctx.f15.f64));
	// fmuls f19,f19,f7
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f7.f64));
	// stfs f19,252(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f15,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r7,188
	ctx.r14.s64 = ctx.r7.s64 * 188;
	// fadds f15,f20,f15
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f15,168(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f15,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f19,f15,f2,f18
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f2.f64 + ctx.f18.f64));
	// lfs f18,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// lfs f18,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f1,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f1.f64 + ctx.f17.f64));
	// lfs f17,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// lfs f17,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f2,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 - ctx.f16.f64));
	// stfs f17,268(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f17,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f17.f64 = double(temp.f32);
	// stw r14,380(r1)
	PPC_STORE_U32(ctx.r1.u32 + 380, ctx.r14.u32);
	// lfs f16,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r7,60
	ctx.r14.s64 = ctx.r7.s64 * 60;
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,244(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f16,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f8,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f8.f64 - ctx.f14.f64));
	// stfs f16,284(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f16,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,72(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f17,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f17.f64 = double(temp.f32);
	// stw r14,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r14.u32);
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r7,156
	ctx.r14.s64 = ctx.r7.s64 * 156;
	// lfs f16,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f17,f8,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f8.f64 + ctx.f16.f64));
	// stfs f17,252(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f17,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f25
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// lfs f16,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,148(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f15,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,204(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f16,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f16,f26,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f26.f64 + ctx.f17.f64));
	// stfs f17,140(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fmuls f17,f23,f2
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// fmuls f16,f23,f3
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f23,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f23,f1
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f1.f64));
	// lfs f23,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f23,f1
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f1.f64));
	// lfs f23,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfsx f23,r14,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,28
	ctx.r14.s64 = ctx.r7.s64 * 28;
	// lfs f23,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfsx f23,r14,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f23,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f23.f64 = double(temp.f32);
	// mulli r14,r7,124
	ctx.r14.s64 = ctx.r7.s64 * 124;
	// fsubs f21,f23,f19
	ctx.f21.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// fadds f23,f19,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// lfs f19,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f21,r14,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fsubs f21,f22,f18
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// mulli r14,r7,252
	ctx.r14.s64 = ctx.r7.s64 * 252;
	// stfsx f23,r14,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fadds f23,f18,f22
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// lfs f22,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f22.f64 = double(temp.f32);
	// stfs f23,168(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fmr f23,f22
	ctx.f23.f64 = ctx.f22.f64;
	// fsubs f22,f20,f23
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// fadds f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// stfs f23,268(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f20,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f20.f64 = double(temp.f32);
	// fmr f23,f19
	ctx.f23.f64 = ctx.f19.f64;
	// stfs f22,244(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fadds f20,f20,f23
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfs f20,432(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// mulli r14,r7,92
	ctx.r14.s64 = ctx.r7.s64 * 92;
	// lfs f20,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f23,f20
	ctx.f20.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// lfs f23,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f23.f64 = double(temp.f32);
	// fmr f22,f23
	ctx.f22.f64 = ctx.f23.f64;
	// lfs f18,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f18.f64 = double(temp.f32);
	// stfsx f21,r14,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,220
	ctx.r14.s64 = ctx.r7.s64 * 220;
	// lfs f21,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f31,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f31.f64 + ctx.f14.f64));
	// lfs f14,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f23,f22,f3,f17
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 - ctx.f17.f64));
	// lfs f17,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f19,f18,f17
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f18,376(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fmadds f22,f22,f2,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f2.f64 + ctx.f16.f64));
	// lfs f16,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f16.f64 = double(temp.f32);
	// stfsx f16,r14,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lwz r14,380(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	// stfs f22,284(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f22,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f22,f22,f31,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f31.f64 - ctx.f15.f64));
	// fmuls f17,f18,f26
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f26.f64));
	// fmuls f15,f18,f25
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// lfs f18,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f18,332(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f14,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f17,f14,f25,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f25.f64 - ctx.f17.f64));
	// lfs f14,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f16.f64 = double(temp.f32);
	// stfsx f16,r14,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lwz r14,100(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lfs f16,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f16.f64 = double(temp.f32);
	// stfsx f16,r14,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f16,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f26
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f26.f64));
	// fmsubs f16,f14,f25,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f25.f64 - ctx.f16.f64));
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f14,f26,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f26.f64 + ctx.f15.f64));
	// lfs f14,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfs f14,328(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f14,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// stfs f14,168(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f14,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f21,268(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f21,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// stfs f23,56(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fadds f23,f19,f22
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f23,72(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fsubs f23,f19,f22
	ctx.f23.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// lfs f22,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f22.f64 = double(temp.f32);
	// stfs f23,324(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fadds f23,f17,f22
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// fadds f21,f15,f16
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f19,f16,f15
	ctx.f19.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f23,f16
	ctx.f17.f64 = double(float(ctx.f23.f64 + ctx.f16.f64));
	// fsubs f16,f16,f23
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// stfs f16,100(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fadds f23,f22,f15
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f23,228(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f23,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f14,f15,f22
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// fadds f22,f21,f23
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfs f14,244(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// stfs f22,192(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfs f23,300(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fadds f23,f19,f18
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f23,288(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fsubs f15,f18,f19
	ctx.f15.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// lfs f21,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f21.f64 = double(temp.f32);
	// stfs f15,332(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fmuls f19,f17,f21
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f21.f64));
	// lfs f23,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f14,f23
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f23.f64));
	// lfs f14,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f14.f64));
	// lfs f22,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f22.f64));
	// fmuls f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f23.f64));
	// lfs f15,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f15.f64));
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f19,f14,f22,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f22.f64 - ctx.f19.f64));
	// stfs f19,252(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f19,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f23,f14,f19,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 * ctx.f19.f64 - ctx.f23.f64));
	// lfs f14,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f19,f14,f19,f18
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f19.f64 + ctx.f18.f64));
	// lfs f18,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f21,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f21.f64 + ctx.f17.f64));
	// lfs f14,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f14,f17,f16
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f17.f64 - ctx.f16.f64));
	// lfs f14,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f14,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f14,r11,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,0(r4)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f15,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f15,f23
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// stfsx f14,r20,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// fadds f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// stfsx f23,r19,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f15,f23,f19
	ctx.f15.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// stfsx f15,r24,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// fadds f23,f19,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// stfsx f23,r23,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f19,f23,f18
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// stfsx f19,r10,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// stfsx f23,r31,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// lfs f14,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f23,f17
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f17.f64));
	// stfsx f19,r30,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fadds f23,f17,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// stfsx f23,r29,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f19,f23,f16
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// stfsx f19,r26,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fadds f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// stfsx f23,r25,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lfs f19,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f19.f64 = double(temp.f32);
	// lfs f23,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f19,f24
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f24.f64));
	// fmuls f18,f19,f23
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// lfs f19,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f19,f24
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f24.f64));
	// lfs f19,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f24
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f24.f64));
	// fmadds f18,f19,f24,f18
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f24.f64 + ctx.f18.f64));
	// stfs f18,352(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfs f18,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f18.f64));
	// lfs f18,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f19,f19,f23,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f23.f64 - ctx.f16.f64));
	// fmsubs f18,f18,f23,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f23.f64 - ctx.f17.f64));
	// stfs f18,336(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// stfs f19,332(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f19,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f18,f19
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// lfs f17,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f19.f64 = double(temp.f32);
	// fadds f18,f17,f19
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f18,244(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f18,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// fmadds f18,f18,f23,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f23.f64 + ctx.f15.f64));
	// stfs f18,264(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// stfs f19,212(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f18,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// lfs f15,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f15.f64 = double(temp.f32);
	// stfs f19,108(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fadds f15,f15,f18
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// lfs f19,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f19.f64 = double(temp.f32);
	// stfs f15,272(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fmuls f15,f19,f6
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f6.f64));
	// fmuls f19,f19,f5
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f5.f64));
	// stfs f19,280(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f18,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f18,f17,f14
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f14.f64));
	// lfs f18,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// lfs f17,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f16.f64));
	// stfs f18,340(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// lfs f17,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f18.f64 = double(temp.f32);
	// fadds f16,f17,f18
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f16,172(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f18,344(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// lfs f16,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,252(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f18,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f17,f18,f5,f15
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f5.f64 - ctx.f15.f64));
	// stfs f17,144(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f15,168(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f15,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,188(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f17,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f18,f18,f6,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f6.f64 + ctx.f15.f64));
	// stfs f18,136(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f18,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f18,192(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f18,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f18.f64 = double(temp.f32);
	// fadds f16,f17,f18
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f16,180(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f18,280(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f17,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f18.f64 = double(temp.f32);
	// fadds f16,f17,f18
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f16,160(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f18,304(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f18,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f18,f27
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f27.f64));
	// lfs f15,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f15,f30
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f30.f64));
	// fsubs f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfsx f14,r22,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfsx f19,r21,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// lfs f19,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f14,f20,f19
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfsx f14,r28,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f19,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f20,r27,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f20,f19,f28,f17
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f28.f64 - ctx.f17.f64));
	// fmadds f19,f19,f27,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f18.f64));
	// stfs f19,288(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f18,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f19.f64 = double(temp.f32);
	// fadds f17,f18,f19
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f17,228(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f19,324(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f19,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f19,f19,f29,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f29.f64 - ctx.f16.f64));
	// stfs f19,264(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f19,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f29,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f29.f64 + ctx.f15.f64));
	// stfs f19,212(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f17,f19,f18
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f14,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f16.f64 = double(temp.f32);
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f17,300(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fsubs f18,f16,f14
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// lfs f15,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// lfs f17,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f17.f64 = double(temp.f32);
	// stfs f19,108(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fadds f19,f15,f17
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f16,440(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// lfs f15,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,328(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// stfs f16,136(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f14,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,160(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f15,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,188(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f15,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f19,f15
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f15.f64));
	// stfs f19,172(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f19,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f19.f64 = double(temp.f32);
	// stfs f18,144(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f17,180(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// stfs f20,272(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f14,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f19.f64));
	// fmuls f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// lfs f18,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f18.f64));
	// lfs f16,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// stfs f20,304(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f20,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f20,f20,f16,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f16.f64 - ctx.f15.f64));
	// stfs f20,136(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f20,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f20,f16
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f16.f64));
	// lfs f16,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f16.f64 = double(temp.f32);
	// lfs f20,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f20,192(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f20,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f20,f20,f16,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f16.f64 - ctx.f14.f64));
	// stfs f20,144(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f20,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f20,f16
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f16.f64));
	// lfs f14,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f20,108(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f14,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f14,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f14.f64 + ctx.f19.f64));
	// stfs f20,180(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f20,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f14,f20,f5
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f5.f64));
	// lfs f19,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfs f20,344(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// lfs f20,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f20,f20,f19,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64 + ctx.f18.f64));
	// stfs f20,212(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f18,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f18.f64 = double(temp.f32);
	// lfs f20,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// stfs f20,172(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f20,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f20,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f20.f64 - ctx.f17.f64));
	// lfs f20,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f20
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f17,264(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f17,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f20,340(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// lfs f17,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfs f20,280(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f20,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f20,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f20.f64 + ctx.f16.f64));
	// lfs f16,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f16.f64 = double(temp.f32);
	// lfs f20,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// stfs f20,272(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f20,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f20,f20,f6,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 - ctx.f14.f64));
	// stfs f20,160(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// lfs f20,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f20,352(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfs f20,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f20
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f20.f64));
	// lfs f14,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f16,f14,f20,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f20.f64 - ctx.f16.f64));
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f14,f20,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f20.f64 + ctx.f15.f64));
	// stfs f15,336(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f14,r18,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfsx f15,r17,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// lfs f15,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r7,180
	ctx.r11.s64 = ctx.r7.s64 * 180;
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f14,r11,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,52
	ctx.r11.s64 = ctx.r7.s64 * 52;
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f15,r11,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f15,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r7,116
	ctx.r11.s64 = ctx.r7.s64 * 116;
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f14,r11,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r7,244
	ctx.r11.s64 = ctx.r7.s64 * 244;
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f15,r11,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f15,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r7,68
	ctx.r11.s64 = ctx.r7.s64 * 68;
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfsx f14,r11,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r7,196
	ctx.r11.s64 = ctx.r7.s64 * 196;
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfsx f15,r11,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f15,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r7,164
	ctx.r11.s64 = ctx.r7.s64 * 164;
	// fsubs f14,f15,f18
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfsx f14,r11,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,36
	ctx.r11.s64 = ctx.r7.s64 * 36;
	// stfsx f18,r11,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f18,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f15,f18,f17
	ctx.f15.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// mulli r11,r7,148
	ctx.r11.s64 = ctx.r7.s64 * 148;
	// fadds f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f18,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f18
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f17,188(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f17,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f18,108(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f18,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f17,f18,f16
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfsx f17,r11,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,20
	ctx.r11.s64 = ctx.r7.s64 * 20;
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// lfs f17,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f18,r11,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f18,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r7,84
	ctx.r11.s64 = ctx.r7.s64 * 84;
	// fsubs f16,f18,f17
	ctx.f16.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f17,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f16,r11,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,212
	ctx.r11.s64 = ctx.r7.s64 * 212;
	// stfsx f18,r11,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f18,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f18,f24
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f24.f64));
	// stfsx f15,r16,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// stfsx f14,r15,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// fmuls f14,f18,f23
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f23.f64));
	// fmuls f18,f17,f24
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f24.f64));
	// stfs f18,184(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fmuls f15,f17,f23
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f23.f64));
	// lfs f17,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f23,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f23.f64 + ctx.f16.f64));
	// stfs f17,136(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f16,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,276(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f16,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,160(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f17,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f18,f17,f24,f15
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f24.f64 - ctx.f15.f64));
	// lfs f16,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,172(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// stfs f17,176(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f16,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,80(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,104(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f16,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f23,f16,f23,f15
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f23.f64 + ctx.f15.f64));
	// stfs f23,132(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f16,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f16.f64 = double(temp.f32);
	// lfs f23,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// stfs f23,368(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// lfs f23,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// lfs f15,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,180(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f16,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f24,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f24.f64 - ctx.f14.f64));
	// fmadds f23,f16,f6,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 + ctx.f23.f64));
	// stfs f23,144(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f23,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f23,f29
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f29.f64));
	// fmuls f15,f23,f30
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// lfs f23,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f23.f64 = double(temp.f32);
	// fadds f14,f18,f23
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// stfs f14,220(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fsubs f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfs f23,232(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f23,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f23,f28
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// lfs f23,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f28
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// stfs f23,184(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f18,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f18,348(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// lfs f18,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f23,f17,f18
	ctx.f23.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// lfs f17,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f18,f17,f30,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 - ctx.f16.f64));
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f17,f29,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f29.f64 + ctx.f15.f64));
	// stfs f17,424(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f27,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f27.f64 + ctx.f14.f64));
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f16,f16,f27,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f27.f64 - ctx.f15.f64));
	// lfs f15,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f15.f64 = double(temp.f32);
	// stfs f16,132(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fadds f16,f14,f15
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,120(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,360(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,276(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,80(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f15,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,104(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// mulli r11,r7,136
	ctx.r11.s64 = ctx.r7.s64 * 136;
	// lfs f15,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,220(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f14,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f23
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// stfs f14,184(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f14,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,232(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f15,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f15.f64 = double(temp.f32);
	// fadds f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// stfs f23,144(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fsubs f23,f16,f17
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f23,136(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fadds f23,f16,f17
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f23,180(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f23,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f23.f64 = double(temp.f32);
	// lfs f17,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f23
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f23.f64));
	// lfs f16,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f16.f64 = double(temp.f32);
	// lfs f23,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f23,f16
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// lfs f16,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f23,f19
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f19.f64));
	// lfs f23,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f23,f16,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f16.f64 - ctx.f17.f64));
	// lfs f16,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f16,f19,f14
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,276(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f19,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f17,f16,f17,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f17.f64 - ctx.f15.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f15,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f19,f23
	ctx.f16.f64 = double(float(ctx.f19.f64 - ctx.f23.f64));
	// stfsx f16,r11,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// lfs f16,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f16.f64 = double(temp.f32);
	// stfsx f23,r11,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,184
	ctx.r11.s64 = ctx.r7.s64 * 184;
	// lfs f23,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f19,f23,f17
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f17.f64));
	// fadds f23,f17,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// stfsx f19,r11,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f19,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f19.f64 = double(temp.f32);
	// mulli r11,r7,56
	ctx.r11.s64 = ctx.r7.s64 * 56;
	// stfsx f23,r11,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f19,f23,f19
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f19.f64));
	// lfs f23,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f17,f23,f20
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f20.f64));
	// lfs f23,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f23,f16
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// fmuls f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f15.f64));
	// lfs f23,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f23,f20
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f20.f64));
	// lfs f20,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f23,336(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfs f23,136(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f20,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// stfs f23,352(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// lfs f20,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f20.f64 = double(temp.f32);
	// stfs f23,144(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// lfs f23,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f23.f64 = double(temp.f32);
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmuls f23,f23,f8
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// stfs f23,184(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// mulli r11,r7,120
	ctx.r11.s64 = ctx.r7.s64 * 120;
	// lfs f20,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f23,f20,f18,f19
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f18.f64 + ctx.f19.f64));
	// lfs f19,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfs f20,172(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f19,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f20,f20,f19,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64 - ctx.f17.f64));
	// lfs f18,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f19,344(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// lfs f18,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f19,f18,f19,f16
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 - ctx.f16.f64));
	// lfs f17,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f18,280(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f17,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f17,f18,f15
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f18.f64 + ctx.f15.f64));
	// stfs f18,272(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f17,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f18,264(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f17,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f14.f64));
	// lfs f16,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f15.f64 = double(temp.f32);
	// stfs f18,340(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fsubs f18,f16,f15
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f18,364(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// lfs f18,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f18,f18,f7,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f7.f64 - ctx.f17.f64));
	// stfs f18,372(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f17,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f14,f18,f17
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfsx f14,r11,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,248
	ctx.r11.s64 = ctx.r7.s64 * 248;
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fadds f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfsx f18,r11,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f18,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f8
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// stfs f17,240(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f17,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r7,72
	ctx.r11.s64 = ctx.r7.s64 * 72;
	// fmadds f18,f17,f7,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f18.f64));
	// stfs f18,248(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f18,f31
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f31.f64));
	// fmuls f16,f18,f1
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// lfs f18,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f18,f3
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// fmuls f14,f18,f2
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f2.f64));
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfsx f18,r11,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,200
	ctx.r11.s64 = ctx.r7.s64 * 200;
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfsx f23,r11,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f23.f64 = double(temp.f32);
	// mulli r11,r7,168
	ctx.r11.s64 = ctx.r7.s64 * 168;
	// fsubs f18,f23,f20
	ctx.f18.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// fadds f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfsx f18,r11,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,40
	ctx.r11.s64 = ctx.r7.s64 * 40;
	// stfsx f23,r11,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f20,f23,f19
	ctx.f20.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// mulli r11,r7,152
	ctx.r11.s64 = ctx.r7.s64 * 152;
	// stfsx f20,r11,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,24
	ctx.r11.s64 = ctx.r7.s64 * 24;
	// fadds f23,f19,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// lfs f20,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f18.f64 = double(temp.f32);
	// stfsx f23,r11,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,88
	ctx.r11.s64 = ctx.r7.s64 * 88;
	// lfs f23,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f19,f23,f20
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// fadds f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// lfs f20,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f20.f64 = double(temp.f32);
	// stfsx f19,r11,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,216
	ctx.r11.s64 = ctx.r7.s64 * 216;
	// stfsx f23,r11,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f23.f64 = double(temp.f32);
	// mulli r11,r7,104
	ctx.r11.s64 = ctx.r7.s64 * 104;
	// fsubs f19,f23,f20
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// fadds f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// lfs f20,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f20.f64 = double(temp.f32);
	// stfsx f19,r11,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f19,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f19.f64 = double(temp.f32);
	// mulli r11,r7,232
	ctx.r11.s64 = ctx.r7.s64 * 232;
	// stfsx f23,r11,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fadds f23,f19,f20
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fmsubs f19,f18,f1,f17
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f1.f64 - ctx.f17.f64));
	// fmadds f18,f18,f31,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f31.f64 + ctx.f16.f64));
	// stfs f18,144(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f18,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f17,f18,f2,f15
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f2.f64 - ctx.f15.f64));
	// stfs f17,196(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fmadds f18,f18,f3,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64 + ctx.f14.f64));
	// stfs f18,164(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f18,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f18,f26
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f26.f64));
	// lfs f17,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f18,f25
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// fmuls f18,f17,f25
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// stfs f18,356(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// fmuls f15,f17,f26
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f26.f64));
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f25,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f25.f64 + ctx.f16.f64));
	// stfs f17,388(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// lfs f16,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,364(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f25,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f25.f64 + ctx.f15.f64));
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f17,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,48(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f26,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f26.f64 - ctx.f14.f64));
	// stfs f16,372(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f15,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f15,f26,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f26.f64 - ctx.f14.f64));
	// fadds f14,f19,f23
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// fsubs f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// stfs f23,136(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f19,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f19.f64 = double(temp.f32);
	// lfs f23,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f19,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 - ctx.f23.f64));
	// stfs f23,88(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f23,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f23,f19
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// stfs f19,24(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f19,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f19.f64 = double(temp.f32);
	// fadds f23,f19,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// lfs f19,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f19.f64 = double(temp.f32);
	// mulli r11,r7,140
	ctx.r11.s64 = ctx.r7.s64 * 140;
	// fsubs f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 - ctx.f19.f64));
	// stfs f19,184(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f19,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// lfs f16,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f16.f64 = double(temp.f32);
	// stfs f19,276(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fadds f19,f15,f16
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,52(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,172(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f16,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,356(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// stfs f23,364(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fadds f23,f19,f18
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f16,180(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f19,388(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// lfs f18,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f19,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfs f19,372(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f15,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f19,f18
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// fmuls f15,f19,f15
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f15.f64));
	// lfs f19,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f19.f64));
	// stfs f19,356(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f22.f64));
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f22
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f22.f64));
	// lfs f22,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f23,f22,f18
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 - ctx.f18.f64));
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f19,f18,f21,f16
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f21.f64 - ctx.f16.f64));
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f21,f18,f21,f17
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f21.f64 + ctx.f17.f64));
	// lfs f18,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f23,f23,f18,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f18.f64 + ctx.f15.f64));
	// lfs f17,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f14,f22
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfsx f15,r11,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,12
	ctx.r11.s64 = ctx.r7.s64 * 12;
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// lfs f16,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f16,f17,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f17.f64 - ctx.f18.f64));
	// stfsx f22,r11,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,380(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	// lfs f22,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f15,f22,f19
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfsx f15,r11,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,124
	ctx.r11.s64 = ctx.r7.s64 * 124;
	// stfsx f22,r14,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f19,f22,f21
	ctx.f19.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfsx f19,r11,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,252
	ctx.r11.s64 = ctx.r7.s64 * 252;
	// stfsx f22,r11,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f21,f22,f23
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// mulli r11,r7,76
	ctx.r11.s64 = ctx.r7.s64 * 76;
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// lfs f22,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f22.f64 = double(temp.f32);
	// lwz r10,592(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	// lfs f19,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f19.f64 = double(temp.f32);
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f21,r11,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,204
	ctx.r11.s64 = ctx.r7.s64 * 204;
	// stfsx f23,r11,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fsubs f23,f20,f22
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// lfs f20,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f20.f64 = double(temp.f32);
	// mulli r11,r7,172
	ctx.r11.s64 = ctx.r7.s64 * 172;
	// fsubs f21,f23,f18
	ctx.f21.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// stfsx f21,r11,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,44
	ctx.r11.s64 = ctx.r7.s64 * 44;
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// lfs f21,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f23,r11,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,600(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	// lfs f23,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f19,f23
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// add r5,r11,r5
	ctx.r5.u64 = ctx.r11.u64 + ctx.r5.u64;
	// fmuls f15,f21,f23
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f23.f64));
	// lfs f23,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f17,f23,f17
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// add r6,r11,r6
	ctx.r6.u64 = ctx.r11.u64 + ctx.r6.u64;
	// mulli r11,r7,156
	ctx.r11.s64 = ctx.r7.s64 * 156;
	// lfs f23,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// fmsubs f21,f21,f20,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 - ctx.f18.f64));
	// lfs f18,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f20,f19,f20,f15
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f20.f64 + ctx.f15.f64));
	// lfs f19,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f16,f19,f17
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f19.f64 + ctx.f17.f64));
	// fsubs f17,f18,f21
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// stfsx f17,r11,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,28
	ctx.r11.s64 = ctx.r7.s64 * 28;
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfsx f21,r11,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fsubs f21,f23,f20
	ctx.f21.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// fadds f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// mulli r11,r7,92
	ctx.r11.s64 = ctx.r7.s64 * 92;
	// stfsx f21,r11,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,220
	ctx.r11.s64 = ctx.r7.s64 * 220;
	// stfsx f23,r11,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fsubs f23,f22,f19
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// mulli r11,r7,108
	ctx.r11.s64 = ctx.r7.s64 * 108;
	// stfsx f23,r11,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fadds f23,f19,f22
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// mulli r11,r7,236
	ctx.r11.s64 = ctx.r7.s64 * 236;
	// stfsx f23,r11,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lwz r11,3532(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 3532);
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d3a93c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D3A93C;
loc_82D3DE10:
	// addi r1,r1,912
	ctx.r1.s64 = ctx.r1.s64 + 912;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D3DE1C;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D3DE20"))) PPC_WEAK_FUNC(sub_82D3DE20);
PPC_FUNC_IMPL(__imp__sub_82D3DE20) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-4656
	ctx.r5.s64 = ctx.r11.s64 + -4656;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,-22800
	ctx.r4.s64 = ctx.r11.s64 + -22800;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D3DE38"))) PPC_WEAK_FUNC(sub_82D3DE38);
PPC_FUNC_IMPL(__imp__sub_82D3DE38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D3DE40;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D3DE48;
	__savefpr_14(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d3f39c
	if (!ctx.cr6.gt) goto loc_82D3F39C;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r15,-32234
	ctx.r15.s64 = -2112487424;
	// lis r16,-32234
	ctx.r16.s64 = -2112487424;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r17,-32234
	ctx.r17.s64 = -2112487424;
	// lis r18,-32234
	ctx.r18.s64 = -2112487424;
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lfs f27,-6512(r15)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + -6512);
	ctx.f27.f64 = double(temp.f32);
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// lfs f28,-6516(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + -6516);
	ctx.f28.f64 = double(temp.f32);
	// stw r11,-312(r1)
	PPC_STORE_U32(ctx.r1.u32 + -312, ctx.r11.u32);
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f30,-6496(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + -6496);
	ctx.f30.f64 = double(temp.f32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f31,-6524(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -6524);
	ctx.f31.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f1,-6528(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -6528);
	ctx.f1.f64 = double(temp.f32);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f2,-6504(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -6504);
	ctx.f2.f64 = double(temp.f32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f3,-6500(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -6500);
	ctx.f3.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f4,-8144(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -8144);
	ctx.f4.f64 = double(temp.f32);
	// stw r11,-308(r1)
	PPC_STORE_U32(ctx.r1.u32 + -308, ctx.r11.u32);
	// lis r28,-32236
	ctx.r28.s64 = -2112618496;
	// lis r29,-32236
	ctx.r29.s64 = -2112618496;
	// lfs f5,-8140(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -8140);
	ctx.f5.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f6,-8132(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -8132);
	ctx.f6.f64 = double(temp.f32);
	// lis r31,-32236
	ctx.r31.s64 = -2112618496;
	// lfs f7,-8136(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -8136);
	ctx.f7.f64 = double(temp.f32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f8,-8016(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -8016);
	ctx.f8.f64 = double(temp.f32);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f9,136(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 136);
	ctx.f9.f64 = double(temp.f32);
	// lfs f12,140(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 140);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-8128(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8128);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 124);
	ctx.f0.f64 = double(temp.f32);
	// lfs f10,120(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 120);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f11.f64 = double(temp.f32);
	// lfs f29,-6492(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + -6492);
	ctx.f29.f64 = double(temp.f32);
loc_82D3DF04:
	// rlwinm r11,r8,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f26,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// mulli r10,r8,96
	ctx.r10.s64 = ctx.r8.s64 * 96;
	// lfsx f25,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f24,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f14,f25,f24
	ctx.f14.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// rlwinm r11,r9,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f24,f24,f25
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// mulli r10,r9,96
	ctx.r10.s64 = ctx.r9.s64 * 96;
	// lfsx f23,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f22,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f24,f24,f11
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// stfs f24,-552(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// mulli r10,r8,112
	ctx.r10.s64 = ctx.r8.s64 * 112;
	// lfsx f21,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f20,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f20.f64 = double(temp.f32);
	// rlwinm r11,r9,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r10,r9,112
	ctx.r10.s64 = ctx.r9.s64 * 112;
	// lfsx f19,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f18,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r8,80
	ctx.r11.s64 = ctx.r8.s64 * 80;
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r8,48
	ctx.r11.s64 = ctx.r8.s64 * 48;
	// lfsx f16,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r9,80
	ctx.r11.s64 = ctx.r9.s64 * 80;
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r9,48
	ctx.r11.s64 = ctx.r9.s64 * 48;
	// lfsx f25,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,-584(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -584, temp.u32);
	// fadds f25,f22,f23
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f23,-588(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -588, temp.u32);
	// rlwinm r11,r8,7,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 7) & 0xFFFFFF80;
	// fsubs f23,f21,f20
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// rlwinm r10,r8,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 6) & 0xFFFFFFC0;
	// rlwinm r31,r9,6,0,25
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 6) & 0xFFFFFFC0;
	// lfsx f24,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f24.f64 = double(temp.f32);
	// stfs f24,-576(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// lfsx f24,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f11
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// stfs f24,-556(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// fadds f24,f20,f21
	ctx.f24.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// lfsx f22,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f19,f18
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fadds f18,f16,f17
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// lfs f16,-584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -584);
	ctx.f16.f64 = double(temp.f32);
	// lfs f21,-588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -588);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,-588(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -588, temp.u32);
	// fmuls f21,f21,f11
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// lfs f16,-584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -584);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// fsubs f15,f14,f25
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// fadds f14,f25,f14
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// lfs f25,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f26
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f25,-584(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -584, temp.u32);
	// lfs f25,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fmuls f25,f15,f10
	ctx.f25.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// fmuls f15,f14,f10
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// fsubs f14,f24,f18
	ctx.f14.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// stfs f14,-532(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fadds f24,f18,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// fadds f14,f17,f19
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fmuls f24,f24,f11
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// stfs f24,-464(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f24,-588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -588);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f18,f20,f24
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// stfs f18,-588(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -588, temp.u32);
	// fadds f20,f24,f20
	ctx.f20.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// lfs f24,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f24.f64 = double(temp.f32);
	// lfs f18,-584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -584);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f24
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// stfs f18,-556(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f18,-584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -584);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f24,f18,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 - ctx.f24.f64));
	// stfs f24,-576(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// fsubs f24,f26,f22
	ctx.f24.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// fadds f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// stfs f26,-592(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -592, temp.u32);
	// fmuls f26,f20,f11
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// stfs f24,-584(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -584, temp.u32);
	// stfs f26,-492(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// fmuls f20,f14,f13
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// lfs f26,-588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -588);
	ctx.f26.f64 = double(temp.f32);
	// mulli r11,r8,40
	ctx.r11.s64 = ctx.r8.s64 * 40;
	// lfs f24,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f24.f64 = double(temp.f32);
	// mulli r10,r8,88
	ctx.r10.s64 = ctx.r8.s64 * 88;
	// fsubs f18,f24,f26
	ctx.f18.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// fadds f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// stfs f26,-588(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -588, temp.u32);
	// lfs f24,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f24.f64 = double(temp.f32);
	// fmr f26,f24
	ctx.f26.f64 = ctx.f24.f64;
	// lfs f24,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f26,f24
	ctx.f24.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// stfs f24,-372(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f24,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// lfs f24,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f21.f64));
	// stfs f24,-384(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f24,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// lfs f22,-584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -584);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f18,f10
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f10.f64));
	// fadds f22,f25,f22
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// stfs f22,-412(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f22,-584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -584);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,-588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -588);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// fmuls f18,f18,f10
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64));
	// stfs f18,-520(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fsubs f18,f23,f16
	ctx.f18.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// lfs f22,-592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -592);
	ctx.f22.f64 = double(temp.f32);
	// fadds f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,-516(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f22,-592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -592);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// fmsubs f20,f18,f0,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 - ctx.f20.f64));
	// stfs f20,-468(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fsubs f20,f19,f17
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfsx f19,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f18,f13
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// mulli r11,r9,40
	ctx.r11.s64 = ctx.r9.s64 * 40;
	// lfsx f18,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r10,r8,120
	ctx.r10.s64 = ctx.r8.s64 * 120;
	// fmadds f17,f14,f0,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 + ctx.f17.f64));
	// stfs f17,-348(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfsx f17,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r9,88
	ctx.r11.s64 = ctx.r9.s64 * 88;
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r8,24
	ctx.r11.s64 = ctx.r8.s64 * 24;
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-592(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -592, temp.u32);
	// mulli r11,r8,104
	ctx.r11.s64 = ctx.r8.s64 * 104;
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-588(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -588, temp.u32);
	// fmuls f15,f20,f0
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// mulli r11,r9,104
	ctx.r11.s64 = ctx.r9.s64 * 104;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-552(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// fmuls f14,f20,f13
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// mulli r11,r9,24
	ctx.r11.s64 = ctx.r9.s64 * 24;
	// fmsubs f15,f23,f13,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f15,-504(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fsubs f15,f19,f18
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfsx f18,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f20,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f20.f64 = double(temp.f32);
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fmadds f23,f23,f0,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f14.f64));
	// stfs f23,-416(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// mulli r10,r9,120
	ctx.r10.s64 = ctx.r9.s64 * 120;
	// lfsx f23,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f23.f64 = double(temp.f32);
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-576(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// mulli r11,r8,72
	ctx.r11.s64 = ctx.r8.s64 * 72;
	// lfsx f14,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-556(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// fadds f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,-568(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// lfs f16,-592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -592);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r8,56
	ctx.r11.s64 = ctx.r8.s64 * 56;
	// stfs f17,-532(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-584(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -584, temp.u32);
	// lfs f17,-588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -588);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r9,72
	ctx.r11.s64 = ctx.r9.s64 * 72;
	// fsubs f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f16,-572(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// lfs f16,-592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -592);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-592(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -592, temp.u32);
	// mulli r11,r9,56
	ctx.r11.s64 = ctx.r9.s64 * 56;
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-588(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -588, temp.u32);
	// lfs f16,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f20,f16
	ctx.f16.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// stfs f16,-564(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// lfs f16,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// fadds f16,f18,f23
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// fsubs f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// stfs f23,-356(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfs f18,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f18.f64 = double(temp.f32);
	// lfs f23,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfs f18,-552(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfs f18,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f18.f64 = double(temp.f32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f23,-352(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f23,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,-584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -584);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// stfs f18,-556(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f18,-584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -584);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// stfs f23,-532(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f18,-592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -592);
	ctx.f18.f64 = double(temp.f32);
	// lfs f23,-588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -588);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfs f18,-576(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// lfs f18,-592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -592);
	ctx.f18.f64 = double(temp.f32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f23,-592(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -592, temp.u32);
	// lfs f18,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f18.f64 = double(temp.f32);
	// lfs f23,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// lfs f18,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f20,f18
	ctx.f18.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// stfs f18,-460(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f18,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f20,-588(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -588, temp.u32);
	// lfs f20,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f20.f64 = double(temp.f32);
	// fadds f18,f20,f16
	ctx.f18.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// stfs f18,-484(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fsubs f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// stfs f20,-568(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// lfs f18,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f18.f64 = double(temp.f32);
	// lfs f20,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f16,f20,f18
	ctx.f16.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f16,-456(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f20,-336(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f18,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f18.f64 = double(temp.f32);
	// lfs f20,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// stfs f20,-408(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f18,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f18.f64 = double(temp.f32);
	// lfs f20,-592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -592);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// stfs f20,-332(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f20,f15,f14
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// mulli r11,r8,36
	ctx.r11.s64 = ctx.r8.s64 * 36;
	// mulli r10,r8,92
	ctx.r10.s64 = ctx.r8.s64 * 92;
	// fadds f16,f23,f20
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// fsubs f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// lfs f20,-592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -592);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// stfs f20,-328(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f18,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f20,f16,f12
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// stfs f20,-320(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fmuls f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// stfs f23,-380(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fadds f23,f17,f19
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// lfs f20,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f20.f64 = double(temp.f32);
	// stfs f23,-452(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfs f16,-588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -588);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// stfs f23,-440(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f23,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// stfs f23,-376(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f20,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// lfs f20,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// lfs f18,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f17,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,-524(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r9,36
	ctx.r11.s64 = ctx.r9.s64 * 36;
	// stfs f23,-488(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// fadds f23,f14,f15
	ctx.f23.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfsx f15,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r9,92
	ctx.r11.s64 = ctx.r9.s64 * 92;
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-572(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// lfsx f16,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-564(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// mulli r11,r8,100
	ctx.r11.s64 = ctx.r8.s64 * 100;
	// lfsx f16,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-588(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -588, temp.u32);
	// fsubs f16,f23,f20
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// fadds f20,f20,f23
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// mulli r11,r9,100
	ctx.r11.s64 = ctx.r9.s64 * 100;
	// lfsx f23,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// stfs f23,-568(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// fadds f23,f18,f19
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// mulli r11,r9,28
	ctx.r11.s64 = ctx.r9.s64 * 28;
	// stfs f23,-540(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// fsubs f23,f18,f19
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f23,-368(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fmuls f19,f16,f12
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// stfs f19,-356(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// stfs f20,-344(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fsubs f20,f17,f15
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// fadds f19,f15,f17
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfsx f23,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// mulli r10,r8,124
	ctx.r10.s64 = ctx.r8.s64 * 124;
	// lfsx f17,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r10,r9,124
	ctx.r10.s64 = ctx.r9.s64 * 124;
	// lfsx f18,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f15,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-592(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -592, temp.u32);
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f15,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-576(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// lfs f15,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfsx f16,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r8,68
	ctx.r11.s64 = ctx.r8.s64 * 68;
	// stfs f15,-552(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r8,60
	ctx.r11.s64 = ctx.r8.s64 * 60;
	// stfs f15,-556(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f14,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r9,68
	ctx.r11.s64 = ctx.r9.s64 * 68;
	// stfs f15,-572(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// lfs f15,-588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -588);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,-512(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f14,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-564(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// mulli r11,r9,60
	ctx.r11.s64 = ctx.r9.s64 * 60;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-588(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -588, temp.u32);
	// lfs f14,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfs f14,-584(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -584, temp.u32);
	// lfs f14,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// fadds f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f17,-592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -592);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,-560(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfs f17,-592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -592);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,-592(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -592, temp.u32);
	// lfs f17,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,-568(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// lfs f16,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,-556(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f16,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -588);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f16,-580(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -580, temp.u32);
	// lfs f16,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,-572(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// lfs f16,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -584);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f23,f16
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f16.f64));
	// stfs f16,-548(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f16,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// lfs f16,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,-532(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f16,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,-528(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f16,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,-592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -592);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,-388(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f14,-592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -592);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,-556(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f16,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,-580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -580);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,-536(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfs f16,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f18,f16
	ctx.f16.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f16,-352(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f16,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f20
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// fsubs f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f18,-396(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fmuls f18,f14,f12
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// stfs f18,-588(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -588, temp.u32);
	// fmuls f18,f17,f12
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// stfs f18,-448(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// fadds f18,f15,f19
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// lfs f17,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r8,20
	ctx.r11.s64 = ctx.r8.s64 * 20;
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// mulli r10,r8,108
	ctx.r10.s64 = ctx.r8.s64 * 108;
	// fadds f16,f18,f17
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f16,-316(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f18,-360(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f18,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f18.f64 = double(temp.f32);
	// fadds f17,f23,f18
	ctx.f17.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f17,-544(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fsubs f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfs f23,-500(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f23,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f17,f18,f23
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfs f17,-404(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f23,-340(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f23,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// lfs f18,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f18.f64 = double(temp.f32);
	// lfs f20,-584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -584);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// lfs f17,-580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -580);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r9,20
	ctx.r11.s64 = ctx.r9.s64 * 20;
	// lfsx f16,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r9,108
	ctx.r11.s64 = ctx.r9.s64 * 108;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-548(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// mulli r11,r8,84
	ctx.r11.s64 = ctx.r8.s64 * 84;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-580(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -580, temp.u32);
	// mulli r11,r8,44
	ctx.r11.s64 = ctx.r8.s64 * 44;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-536(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fadds f14,f20,f23
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// mulli r11,r9,84
	ctx.r11.s64 = ctx.r9.s64 * 84;
	// fsubs f20,f23,f20
	ctx.f20.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// lfsx f23,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// stfs f23,-560(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// fadds f23,f18,f19
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// mulli r11,r9,44
	ctx.r11.s64 = ctx.r9.s64 * 44;
	// stfs f23,-480(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fsubs f23,f18,f19
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f23,-508(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fmuls f19,f14,f12
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// stfs f19,-532(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// stfs f20,-528(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// fsubs f20,f17,f16
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f19,f16,f17
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfsx f23,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// mulli r11,r8,12
	ctx.r11.s64 = ctx.r8.s64 * 12;
	// lfsx f18,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r8,116
	ctx.r11.s64 = ctx.r8.s64 * 116;
	// lfsx f17,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r9,116
	ctx.r11.s64 = ctx.r9.s64 * 116;
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f14,f15
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-576(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-476(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// lfs f14,-580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -580);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f15,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-548(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// mulli r11,r8,52
	ctx.r11.s64 = ctx.r8.s64 * 52;
	// lfs f15,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,-572(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// lfs f14,-580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -580);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-552(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfsx f15,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r8,76
	ctx.r11.s64 = ctx.r8.s64 * 76;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r9,52
	ctx.r11.s64 = ctx.r9.s64 * 52;
	// stfs f14,-580(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -580, temp.u32);
	// lfs f14,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfs f14,-512(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f14,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// stfs f23,-584(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -584, temp.u32);
	// lfsx f23,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// mulli r11,r9,76
	ctx.r11.s64 = ctx.r9.s64 * 76;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-536(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fsubs f14,f18,f17
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f18,-424(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f17,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f17.f64 = double(temp.f32);
	// rlwinm r11,r7,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f18,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f18.f64 = double(temp.f32);
	// stfs f14,-560(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// fadds f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f14,-592(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -592, temp.u32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f18,-432(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f18,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// lfs f17,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f19
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// lfs f14,-580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -580);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f14,-568(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// lfs f14,-580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -580);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,-364(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f15,-548(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f15,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f15,f23
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// stfs f14,-564(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f23,-496(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fmuls f15,f18,f8
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// fmuls f14,f18,f9
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// lfs f18,-592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -592);
	ctx.f18.f64 = double(temp.f32);
	// lfs f23,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f23,-580(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -580, temp.u32);
	// lfs f18,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f18.f64 = double(temp.f32);
	// lfs f23,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// lfs f18,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f15,f18,f9,f15
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f9.f64 - ctx.f15.f64));
	// stfs f15,-536(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fmadds f18,f18,f8,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f8.f64 + ctx.f14.f64));
	// stfs f18,-476(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f15,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f23,f17
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f17.f64));
	// stfs f14,-324(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fsubs f23,f17,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 - ctx.f23.f64));
	// stfs f23,-392(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f18,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f18,-444(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f15,-580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -580);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f8
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f8.f64));
	// lfs f17,-580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -580);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f9
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// fmsubs f18,f18,f9,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f9.f64 - ctx.f15.f64));
	// stfs f18,-548(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f15,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f18,-436(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f18,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,-584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -584);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// stfs f18,-428(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// mulli r10,r7,96
	ctx.r10.s64 = ctx.r7.s64 * 96;
	// lfs f18,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f18.f64 = double(temp.f32);
	// rlwinm r31,r7,5,0,26
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f15,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f18,f15
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// lfs f18,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfs f23,-420(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f23,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f23,f18
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// lfs f23,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f18.f64 = double(temp.f32);
	// mulli r30,r7,88
	ctx.r30.s64 = ctx.r7.s64 * 88;
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f23,-484(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f23,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f26
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f23,-472(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f18,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f18.f64 = double(temp.f32);
	// lfs f23,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// stfs f23,-452(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f18,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f23,f15,f11
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// fsubs f18,f20,f18
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// lfs f20,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// stfs f20,-512(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f16,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f16.f64 = double(temp.f32);
	// mulli r29,r7,120
	ctx.r29.s64 = ctx.r7.s64 * 120;
	// lfs f20,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// lfs f15,-592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -592);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,-572(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// lfs f16,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// stfs f19,-580(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -580, temp.u32);
	// lfs f16,-584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -584);
	ctx.f16.f64 = double(temp.f32);
	// mulli r28,r7,24
	ctx.r28.s64 = ctx.r7.s64 * 24;
	// stfs f20,-560(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// fmuls f20,f14,f10
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// stfs f18,-400(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// mulli r27,r7,56
	ctx.r27.s64 = ctx.r7.s64 * 56;
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// lfs f15,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f19,f15,f11
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// stfs f19,-568(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// lfs f19,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// lfs f15,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,-452(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f15,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,-496(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f16,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f16,f8,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f8.f64 + ctx.f17.f64));
	// stfs f17,-564(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// lfs f16,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,-444(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f16,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f15,-364(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,-432(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f17,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f17,f0
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f14,-464(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fmuls f15,f17,f13
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f17,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f9
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f18,f18,f9
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// fsubs f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// stfs f23,-420(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f23,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f23.f64 = double(temp.f32);
	// mulli r26,r7,80
	ctx.r26.s64 = ctx.r7.s64 * 80;
	// fsubs f14,f23,f20
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f14,-428(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fadds f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfs f23,-436(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f23,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f23.f64 = double(temp.f32);
	// mulli r25,r7,112
	ctx.r25.s64 = ctx.r7.s64 * 112;
	// fmuls f14,f23,f9
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// lfs f23,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f9
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// stfs f23,-472(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f20,-580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -580);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfs f20,-484(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f20,-580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -580);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f19,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f19.f64 = double(temp.f32);
	// fmr f23,f19
	ctx.f23.f64 = ctx.f19.f64;
	// stfs f20,-424(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f20,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f8,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f8.f64 + ctx.f18.f64));
	// lfs f18,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f8,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f8.f64 + ctx.f14.f64));
	// stfs f18,-560(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfs f18,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f20,f23
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfs f20,-580(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -580, temp.u32);
	// lfs f20,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// lfs f20,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f20,f20,f8,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64 - ctx.f17.f64));
	// lfs f17,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f18,f18,f8,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f8.f64 - ctx.f17.f64));
	// stfs f18,-496(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f17,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// lfs f17,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// lfs f14,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// stfs f17,-372(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f17,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfsx f14,r11,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// fmsubs f17,f18,f13,f16
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 - ctx.f16.f64));
	// lfs f16,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f18,f18,f0,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f15.f64));
	// lfs f15,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f16,f15
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfsx f15,r10,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f15.f64 = double(temp.f32);
	// stfs f14,0(r3)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfsx f16,r31,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// lfs f16,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfsx f15,r30,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fadds f14,f18,f15
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfsx f14,r29,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// stfsx f17,r28,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfsx f18,r27,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// lfs f17,-580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -580);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f17,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f23,f17
	ctx.f17.f64 = double(float(ctx.f23.f64 + ctx.f17.f64));
	// lfs f15,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,-400(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f15,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f16,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,-472(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f15,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f15.f64 = double(temp.f32);
	// rlwinm r24,r7,4,0,27
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f16,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f16.f64 = double(temp.f32);
	// mulli r23,r7,48
	ctx.r23.s64 = ctx.r7.s64 * 48;
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f14,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-360(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f14,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-404(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// stfs f17,-408(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// mulli r22,r7,72
	ctx.r22.s64 = ctx.r7.s64 * 72;
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fmuls f14,f17,f13
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f17,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// stfs f26,-440(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fmuls f26,f16,f11
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// stfs f26,-492(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f26,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f26.f64 = double(temp.f32);
	// fadds f17,f21,f26
	ctx.f17.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// stfs f17,-384(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fsubs f26,f26,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f21.f64));
	// stfs f26,-392(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f26,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f26.f64 = double(temp.f32);
	// mulli r21,r7,104
	ctx.r21.s64 = ctx.r7.s64 * 104;
	// fmuls f17,f15,f10
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// stfs f17,-488(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f17,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f16,f17,f0,f14
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 - ctx.f14.f64));
	// stfs f16,-376(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// rlwinm r20,r7,3,0,28
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r19,r7,40
	ctx.r19.s64 = ctx.r7.s64 * 40;
	// fmadds f26,f26,f0,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f17.f64));
	// stfs f26,-420(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// mulli r18,r7,68
	ctx.r18.s64 = ctx.r7.s64 * 68;
	// rlwinm r17,r7,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f26,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f26.f64 = double(temp.f32);
	// lfs f21,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f17,f26,f21
	ctx.f17.f64 = double(float(ctx.f26.f64 - ctx.f21.f64));
	// fadds f16,f21,f26
	ctx.f16.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// lfs f26,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f26,f13
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// lfs f26,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f26,f13
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// lfs f26,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f18,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 + ctx.f26.f64));
	// stfs f26,-460(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f21,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f21.f64 = double(temp.f32);
	// lfs f26,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// lfs f21,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// fmuls f18,f17,f10
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// stfs f18,-400(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f18,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f18,f17
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f17,-544(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f17,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f17.f64 = double(temp.f32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fmuls f17,f16,f10
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// stfs f17,-540(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f17,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f16.f64 = double(temp.f32);
	// mulli r16,r7,52
	ctx.r16.s64 = ctx.r7.s64 * 52;
	// fmsubs f16,f16,f0,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 - ctx.f15.f64));
	// stfs f16,-472(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f15,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f15.f64 = double(temp.f32);
	// mulli r15,r7,116
	ctx.r15.s64 = ctx.r7.s64 * 116;
	// lfs f16,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,-436(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f16,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f0,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 + ctx.f14.f64));
	// stfs f16,-428(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f16,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,-444(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f15,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f14,-376(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,-384(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f16,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f16,f15
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f14,-392(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,-492(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f16,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f26,f6
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfsx f14,r26,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfsx f14,r25,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// stfsx f16,r24,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// lfs f16,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfsx f18,r23,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// lfs f18,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f16,f17,f18
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfsx f16,r22,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fadds f14,f18,f17
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f17,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f16,f17
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfsx f18,r21,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// lfs f18,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fmsubs f18,f18,f7,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f7.f64 - ctx.f15.f64));
	// stfsx f14,r20,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// stfsx f17,r19,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// lfs f17,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f17,f18
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfsx f16,r18,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfsx f18,r17,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// lfs f18,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f17,f23,f18
	ctx.f17.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// lfs f23,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,-580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -580);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f16,f23,f18
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// lfs f23,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f23,f0
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// lfs f18,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f23,f13
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fsubs f23,f24,f18
	ctx.f23.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// fadds f24,f18,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// fmuls f18,f17,f12
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmuls f17,f16,f12
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// stfs f17,-480(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f17,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f16,f17,f13,f15
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f16,-544(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fmadds f17,f17,f0,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f14.f64));
	// stfs f17,-540(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f17,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f21,f4
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f4.f64));
	// fmuls f15,f17,f6
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// lfs f17,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f17,f4
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f4.f64));
	// mulli r14,r7,20
	ctx.r14.s64 = ctx.r7.s64 * 20;
	// fmadds f17,f17,f5,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f5.f64 + ctx.f16.f64));
	// lfs f16,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f18,f16
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stw r14,-488(r1)
	PPC_STORE_U32(ctx.r1.u32 + -488, ctx.r14.u32);
	// mulli r14,r7,36
	ctx.r14.s64 = ctx.r7.s64 * 36;
	// fmadds f26,f26,f7,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 + ctx.f15.f64));
	// lfs f15,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f21,f21,f5,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64 - ctx.f14.f64));
	// lfs f14,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfs f18,-500(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f14,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f23
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// stfs f14,-524(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// lfs f14,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f24
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// stfs f14,-520(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f14,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfsx f14,r16,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfsx f17,r15,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// lfs f17,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f17,f26
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f26.f64));
	// stfsx f14,r14,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,100
	ctx.r14.s64 = ctx.r7.s64 * 100;
	// fadds f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// stfsx f26,r14,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f26,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f26.f64 = double(temp.f32);
	// mulli r14,r7,84
	ctx.r14.s64 = ctx.r7.s64 * 84;
	// fsubs f17,f26,f21
	ctx.f17.f64 = double(float(ctx.f26.f64 - ctx.f21.f64));
	// fadds f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// stfsx f17,r14,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fmuls f17,f16,f5
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f5.f64));
	// fmadds f17,f15,f4,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f4.f64 + ctx.f17.f64));
	// lwz r14,-488(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	// stfsx f26,r14,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fmuls f26,f15,f5
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// mulli r14,r7,76
	ctx.r14.s64 = ctx.r7.s64 * 76;
	// lfs f21,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f7
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f7.f64));
	// fmsubs f26,f16,f4,f26
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f4.f64 - ctx.f26.f64));
	// lfs f16,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f21,f18,f6,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f6.f64 + ctx.f21.f64));
	// fsubs f15,f16,f26
	ctx.f15.f64 = double(float(ctx.f16.f64 - ctx.f26.f64));
	// stfsx f15,r14,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,12
	ctx.r14.s64 = ctx.r7.s64 * 12;
	// fadds f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f16.f64));
	// stfsx f26,r14,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f26,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f26.f64 = double(temp.f32);
	// mulli r14,r7,60
	ctx.r14.s64 = ctx.r7.s64 * 60;
	// fsubs f16,f26,f21
	ctx.f16.f64 = double(float(ctx.f26.f64 - ctx.f21.f64));
	// fadds f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// lfs f21,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f16,r14,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,124
	ctx.r14.s64 = ctx.r7.s64 * 124;
	// stfsx f26,r14,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fsubs f26,f23,f17
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f17.f64));
	// fadds f17,f17,f23
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// lfs f23,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f23.f64 = double(temp.f32);
	// mulli r14,r7,44
	ctx.r14.s64 = ctx.r7.s64 * 44;
	// stfsx f26,r14,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f26,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// lfs f23,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// lfs f21,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f21.f64 = double(temp.f32);
	// mulli r14,r7,108
	ctx.r14.s64 = ctx.r7.s64 * 108;
	// lfs f16,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// lfs f16,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f17,r14,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r14,r7,92
	ctx.r14.s64 = ctx.r7.s64 * 92;
	// lfs f17,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f16,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,-508(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f15,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,-540(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f14,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-524(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// fmuls f15,f18,f7
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f7.f64));
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,-480(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f14,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,-544(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f14,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// lfs f14,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f14,f6,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f6.f64 - ctx.f15.f64));
	// stfs f15,-504(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f14,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,-500(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f14,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,-468(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fadds f15,f17,f21
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// fsubs f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// fmuls f14,f23,f5
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// lfs f17,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,-516(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f17,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fmuls f16,f26,f5
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fmsubs f26,f26,f4,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f4.f64 - ctx.f14.f64));
	// fmadds f23,f23,f4,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f16.f64));
	// stfs f23,-412(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f23,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f23,f23,f6
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// fsubs f14,f24,f14
	ctx.f14.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// stfsx f14,r14,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f16,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r7,28
	ctx.r14.s64 = ctx.r7.s64 * 28;
	// fmuls f16,f16,f6
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// lfs f14,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f14.f64 = double(temp.f32);
	// fadds f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// stfsx f24,r14,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f24,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f24,f24,f7,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 - ctx.f23.f64));
	// stfs f24,-504(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f24,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f24,f7,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 + ctx.f16.f64));
	// stfs f24,-508(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fmuls f16,f17,f31
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f31.f64));
	// lfs f24,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f24,f2
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// fmuls f14,f24,f3
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// fmuls f24,f17,f1
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f1.f64));
	// lfs f17,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f26,f17
	ctx.f17.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// stfs f24,-516(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// fmsubs f24,f15,f3,f23
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f3.f64 - ctx.f23.f64));
	// stfs f17,-520(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fmadds f23,f21,f1,f16
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 + ctx.f16.f64));
	// stfs f23,-368(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f17,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f26.f64));
	// lfs f23,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f17,f15,f2,f14
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f2.f64 + ctx.f14.f64));
	// fadds f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f16.f64));
	// lfs f15,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f14,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f21,f21,f31,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f31.f64 - ctx.f14.f64));
	// fsubs f14,f15,f24
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f24.f64));
	// stfsx f14,r18,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// fadds f24,f24,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// stfsx f24,r17,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// lfs f24,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f24.f64 = double(temp.f32);
	// mulli r18,r7,36
	ctx.r18.s64 = ctx.r7.s64 * 36;
	// fsubs f15,f23,f24
	ctx.f15.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// stfsx f15,r16,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// stfsx f24,r15,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// fsubs f24,f26,f17
	ctx.f24.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// lfs f23,-588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -588);
	ctx.f23.f64 = double(temp.f32);
	// fadds f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// lfs f17,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f24,r18,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// mulli r18,r7,100
	ctx.r18.s64 = ctx.r7.s64 * 100;
	// lfs f24,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfs f23,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f23.f64 = double(temp.f32);
	// lfs f15,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f26,r18,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// fsubs f26,f16,f21
	ctx.f26.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// mulli r18,r7,84
	ctx.r18.s64 = ctx.r7.s64 * 84;
	// stfsx f26,r18,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// fadds f26,f21,f16
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f16.f64));
	// lfs f21,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f21.f64 = double(temp.f32);
	// lwz r18,-488(r1)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// lfs f21,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// lfs f16,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-516(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-528(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f15,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// lfs f14,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f26,r18,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// fadds f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f14,-524(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f14,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f14,-520(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f14,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f22,-448(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f22,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// stfs f22,-548(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f22,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// lfs f14,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,-368(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f14,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// fadds f14,f24,f26
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// stfs f14,-388(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fsubs f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// stfs f26,-416(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// fsubs f26,f17,f16
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f26,-380(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f26,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f26.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f24,f21,f7
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f7.f64));
	// fadds f14,f14,f26
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f26.f64));
	// stfs f17,-456(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// stfs f14,-536(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fmuls f14,f23,f7
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f7.f64));
	// lfs f17,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f26.f64));
	// stfs f26,-476(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fmuls f17,f15,f27
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f27.f64));
	// lfs f26,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f29
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// fmsubs f24,f23,f6,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 - ctx.f24.f64));
	// stfs f24,-528(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// fmadds f24,f21,f6,f14
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 + ctx.f14.f64));
	// stfs f24,-396(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f24,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f24,f24,f29
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f29.f64));
	// fmuls f21,f23,f27
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f27.f64));
	// lfs f23,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f23,f28
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// lfs f23,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f29
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f29.f64));
	// stfs f23,-516(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// fmsubs f26,f26,f30,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f30.f64 - ctx.f24.f64));
	// lfs f24,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f24,f28,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f28.f64 + ctx.f17.f64));
	// lfs f17,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f23,f17,f30,f16
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 + ctx.f16.f64));
	// lfs f17,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f21,f15,f28,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f28.f64 - ctx.f21.f64));
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,-524(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f16,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f27,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f27.f64 - ctx.f14.f64));
	// stfs f16,-520(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f15,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f15,f30,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f30.f64 + ctx.f14.f64));
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f26
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// stfsx f14,r11,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// fadds f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f14.f64));
	// stfs f26,0(r4)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f26,f22,f24
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// stfsx f26,r23,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fadds f26,f24,f22
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// stfsx f26,r25,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f24,f26,f23
	ctx.f24.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// stfsx f24,r31,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fadds f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfsx f26,r10,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f26,f18,f21
	ctx.f26.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// stfsx f26,r26,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fadds f26,f21,f18
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfsx f26,r24,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f26.f64 = double(temp.f32);
	// lfs f24,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f24.f64 = double(temp.f32);
	// mulli r11,r7,76
	ctx.r11.s64 = ctx.r7.s64 * 76;
	// fsubs f23,f26,f24
	ctx.f23.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// fadds f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfs f24,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f24.f64 = double(temp.f32);
	// lfs f22,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f22.f64 = double(temp.f32);
	// lwz r10,-312(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	// lfs f21,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f21.f64 = double(temp.f32);
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// lfs f20,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f20.f64 = double(temp.f32);
	// stfsx f23,r11,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r7,12
	ctx.r11.s64 = ctx.r7.s64 * 12;
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f26,r11,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fsubs f26,f16,f15
	ctx.f26.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// mulli r11,r7,60
	ctx.r11.s64 = ctx.r7.s64 * 60;
	// stfsx f26,r11,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fadds f26,f15,f16
	ctx.f26.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// mulli r11,r7,124
	ctx.r11.s64 = ctx.r7.s64 * 124;
	// stfsx f26,r11,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,-308(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	// lfs f26,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// lfs f24,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f23,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfs f22,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// lfs f19,-588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -588);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// add r5,r11,r5
	ctx.r5.u64 = ctx.r11.u64 + ctx.r5.u64;
	// fsubs f19,f25,f18
	ctx.f19.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// add r6,r11,r6
	ctx.r6.u64 = ctx.r11.u64 + ctx.r6.u64;
	// fadds f25,f18,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// lfs f18,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f18,f27
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f27.f64));
	// lfs f18,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f18,f30
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// lfs f18,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// lfs f14,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r7,44
	ctx.r11.s64 = ctx.r7.s64 * 44;
	// fmadds f16,f14,f28,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f28.f64 + ctx.f16.f64));
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f14,f29,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f29.f64 - ctx.f15.f64));
	// stfs f15,-348(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fadds f15,f22,f23
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f22,f20,f21
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// fmuls f14,f24,f4
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f4.f64));
	// fmuls f20,f24,f5
	ctx.f20.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// fmsubs f24,f26,f5,f14
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f5.f64 - ctx.f14.f64));
	// fmadds f26,f26,f4,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f4.f64 + ctx.f20.f64));
	// fsubs f20,f17,f16
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfsx f20,r11,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,108
	ctx.r11.s64 = ctx.r7.s64 * 108;
	// fadds f20,f16,f17
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fmuls f16,f21,f3
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// stfsx f20,r11,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,92
	ctx.r11.s64 = ctx.r7.s64 * 92;
	// lfs f20,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f17,f18,f20
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// stfsx f17,r11,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// stfsx f20,r14,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// fmuls f20,f22,f31
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f31.f64));
	// fmuls f18,f21,f2
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f2.f64));
	// fadds f21,f24,f19
	ctx.f21.f64 = double(float(ctx.f24.f64 + ctx.f19.f64));
	// fmuls f17,f15,f31
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// fsubs f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f24.f64));
	// fmsubs f20,f15,f1,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f1.f64 - ctx.f20.f64));
	// fmadds f19,f23,f3,f18
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 + ctx.f18.f64));
	// fadds f18,f26,f25
	ctx.f18.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// fmsubs f25,f23,f2,f16
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 - ctx.f16.f64));
	// fmadds f22,f22,f1,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f1.f64 + ctx.f17.f64));
	// fsubs f23,f21,f20
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfsx f23,r22,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// fadds f23,f20,f21
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfsx f23,r20,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// fsubs f23,f18,f19
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfsx f23,r27,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fadds f23,f19,f18
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfsx f23,r29,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fsubs f23,f24,f22
	ctx.f23.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stfsx f23,r19,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfsx f24,r21,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// fsubs f24,f26,f25
	ctx.f24.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfsx f24,r30,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfsx f26,r28,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lwz r11,3532(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 3532);
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d3df04
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D3DF04;
loc_82D3F39C:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D3F3A4;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D3F3A8"))) PPC_WEAK_FUNC(sub_82D3F3A8);
PPC_FUNC_IMPL(__imp__sub_82D3F3A8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-4608
	ctx.r5.s64 = ctx.r11.s64 + -4608;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,-8648
	ctx.r4.s64 = ctx.r11.s64 + -8648;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D3F3C0"))) PPC_WEAK_FUNC(sub_82D3F3C0);
PPC_FUNC_IMPL(__imp__sub_82D3F3C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e38
	ctx.lr = 0x82D3F3C8;
	__savegprlr_16(ctx, base);
	// addi r12,r1,-136
	ctx.r12.s64 = ctx.r1.s64 + -136;
	// bl 0x82e28ee0
	ctx.lr = 0x82D3F3D0;
	__savefpr_14(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d3fae8
	if (!ctx.cr6.gt) goto loc_82D3FAE8;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// rlwinm r18,r11,2,0,29
	ctx.r18.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// rlwinm r17,r11,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f6,-8144(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -8144);
	ctx.f6.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f7,-8140(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -8140);
	ctx.f7.f64 = double(temp.f32);
	// lis r30,-32236
	ctx.r30.s64 = -2112618496;
	// lis r31,-32236
	ctx.r31.s64 = -2112618496;
	// lfs f8,-8136(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -8136);
	ctx.f8.f64 = double(temp.f32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f9,-8132(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8132);
	ctx.f9.f64 = double(temp.f32);
	// lfs f12,-8128(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -8128);
	ctx.f12.f64 = double(temp.f32);
	// lis r16,-32234
	ctx.r16.s64 = -2112487424;
	// lfs f13,124(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 124);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,140(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,120(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 120);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f0.f64 = double(temp.f32);
loc_82D3F438:
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f5,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// mulli r10,r8,48
	ctx.r10.s64 = ctx.r8.s64 * 48;
	// lfsx f4,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f23,f3,f4
	ctx.f23.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// rlwinm r11,r9,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f24,f4,f3
	ctx.f24.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// mulli r10,r9,48
	ctx.r10.s64 = ctx.r9.s64 * 48;
	// lfsx f2,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f18,f2,f1
	ctx.f18.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f3,f1,f2
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// mulli r10,r8,56
	ctx.r10.s64 = ctx.r8.s64 * 56;
	// fmuls f2,f23,f0
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// lfsx f31,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f30,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f22,f30,f31
	ctx.f22.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f31,f31,f30
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// mulli r10,r9,56
	ctx.r10.s64 = ctx.r9.s64 * 56;
	// fmuls f30,f18,f0
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// lfsx f29,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f28,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f18,f29,f28
	ctx.f18.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// mulli r11,r8,40
	ctx.r11.s64 = ctx.r8.s64 * 40;
	// fadds f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// lfsx f27,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f27.f64 = double(temp.f32);
	// mulli r11,r8,24
	ctx.r11.s64 = ctx.r8.s64 * 24;
	// lfsx f26,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f15,f26,f27
	ctx.f15.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// mulli r11,r9,40
	ctx.r11.s64 = ctx.r9.s64 * 40;
	// fsubs f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// lfsx f25,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f25.f64 = double(temp.f32);
	// mulli r11,r9,24
	ctx.r11.s64 = ctx.r9.s64 * 24;
	// fadds f14,f15,f22
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// lfsx f4,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f26,f25,f4
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f4.f64));
	// rlwinm r11,r8,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 6) & 0xFFFFFFC0;
	// fadds f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// rlwinm r10,r8,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f25,f3,f24
	ctx.f25.f64 = double(float(ctx.f3.f64 + ctx.f24.f64));
	// rlwinm r30,r8,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f3.f64));
	// mulli r29,r8,60
	ctx.r29.s64 = ctx.r8.s64 * 60;
	// lfsx f1,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f23,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f3,f1,f5
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// lfsx f21,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// lfsx f20,r29,r5
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r5.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fadds f1,f20,f21
	ctx.f1.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// mulli r10,r9,60
	ctx.r10.s64 = ctx.r9.s64 * 60;
	// fadds f15,f4,f31
	ctx.f15.f64 = double(float(ctx.f4.f64 + ctx.f31.f64));
	// fsubs f4,f31,f4
	ctx.f4.f64 = double(float(ctx.f31.f64 - ctx.f4.f64));
	// fmuls f25,f25,f11
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// fmuls f24,f24,f11
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// lfsx f17,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f16,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f17,f16
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// rlwinm r31,r9,5,0,26
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f16,f29,f27
	ctx.f16.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// mulli r11,r8,36
	ctx.r11.s64 = ctx.r8.s64 * 36;
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// fmuls f27,f14,f0
	ctx.f27.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fadds f14,f26,f18
	ctx.f14.f64 = double(float(ctx.f26.f64 + ctx.f18.f64));
	// fadds f31,f3,f23
	ctx.f31.f64 = double(float(ctx.f3.f64 + ctx.f23.f64));
	// lfsx f19,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f26,f18,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 - ctx.f26.f64));
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfsx f28,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f3,f3,f23
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f23.f64));
	// fmuls f23,f14,f0
	ctx.f23.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fadds f18,f5,f19
	ctx.f18.f64 = double(float(ctx.f5.f64 + ctx.f19.f64));
	// fsubs f5,f5,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f19.f64));
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// fadds f19,f31,f2
	ctx.f19.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// fsubs f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 - ctx.f2.f64));
	// mulli r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 * 20;
	// lfsx f31,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f14,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-320(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// mulli r11,r8,44
	ctx.r11.s64 = ctx.r8.s64 * 44;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-352(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// mulli r11,r8,12
	ctx.r11.s64 = ctx.r8.s64 * 12;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-324(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// mulli r11,r8,52
	ctx.r11.s64 = ctx.r8.s64 * 52;
	// lfsx f14,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-348(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// mulli r11,r9,36
	ctx.r11.s64 = ctx.r9.s64 * 36;
	// lfsx f14,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-344(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fadds f14,f19,f27
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f27.f64));
	// mulli r11,r9,28
	ctx.r11.s64 = ctx.r9.s64 * 28;
	// fsubs f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 - ctx.f27.f64));
	// fsubs f19,f2,f23
	ctx.f19.f64 = double(float(ctx.f2.f64 - ctx.f23.f64));
	// stfs f19,-316(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fadds f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f23.f64));
	// fadds f23,f31,f28
	ctx.f23.f64 = double(float(ctx.f31.f64 + ctx.f28.f64));
	// fsubs f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 - ctx.f31.f64));
	// stfs f31,-340(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfsx f19,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r11,r9,20
	ctx.r11.s64 = ctx.r9.s64 * 20;
	// lfsx f31,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f31.f64 = double(temp.f32);
	// stfs f31,-328(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// mulli r11,r9,44
	ctx.r11.s64 = ctx.r9.s64 * 44;
	// lfsx f31,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f31.f64 = double(temp.f32);
	// stfs f31,-312(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f31,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f31.f64 = double(temp.f32);
	// mulli r11,r9,52
	ctx.r11.s64 = ctx.r9.s64 * 52;
	// lfs f28,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f31
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// stfs f28,-308(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f28,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f31,f31,f28
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// stfs f31,-304(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfsx f31,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f31.f64 = double(temp.f32);
	// stfs f31,-352(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// lfsx f31,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f31.f64 = double(temp.f32);
	// stfs f31,-320(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f31,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f31.f64 = double(temp.f32);
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f28,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f28.f64 = double(temp.f32);
	// mulli r10,r7,48
	ctx.r10.s64 = ctx.r7.s64 * 48;
	// fadds f28,f28,f31
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// stfs f28,-336(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f28,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f31,f31,f28
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// lfs f28,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f28.f64 = double(temp.f32);
	// rlwinm r31,r7,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// stfs f28,-348(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f28,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f19,f28
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// fadds f19,f23,f1
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f1.f64));
	// stfs f19,-332(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f23.f64));
	// stfs f1,-324(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f19,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f19.f64 = double(temp.f32);
	// lfs f1,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// fadds f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f17.f64));
	// stfs f1,-296(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f23,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f23.f64 = double(temp.f32);
	// lfs f17,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f1,f23,f17
	ctx.f1.f64 = double(float(ctx.f23.f64 - ctx.f17.f64));
	// fadds f23,f17,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// stfs f23,-312(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f17,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f17.f64 = double(temp.f32);
	// lfs f23,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f17,f17,f23
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f23.f64));
	// stfs f17,-344(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f17,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f17.f64 = double(temp.f32);
	// fadds f23,f23,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f17.f64));
	// stfs f23,-340(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f23,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f23.f64 = double(temp.f32);
	// mulli r30,r7,40
	ctx.r30.s64 = ctx.r7.s64 * 40;
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f23
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// stfs f17,-328(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f23,f23,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f17.f64));
	// stfs f23,-320(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fadds f17,f28,f21
	ctx.f17.f64 = double(float(ctx.f28.f64 + ctx.f21.f64));
	// stfs f17,-352(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f23,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f28,f21,f28
	ctx.f28.f64 = double(float(ctx.f21.f64 - ctx.f28.f64));
	// lfs f17,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f17.f64 = double(temp.f32);
	// fadds f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f20,-348(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f21,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f20.f64 = double(temp.f32);
	// stfs f28,-300(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fadds f28,f20,f21
	ctx.f28.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// lfs f20,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f1
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f1.f64));
	// stfs f20,-336(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f17,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f31
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f31.f64));
	// stfs f20,-304(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f20,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// lfs f17,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f31,f31,f17
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f17.f64));
	// lfs f17,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f1,f17,f1
	ctx.f1.f64 = double(float(ctx.f17.f64 - ctx.f1.f64));
	// stfs f1,-340(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f17,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f17.f64 = double(temp.f32);
	// lfs f1,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f17.f64));
	// stfs f1,-344(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fmuls f1,f20,f0
	ctx.f1.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// stfs f1,-328(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f1,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f1.f64 = double(temp.f32);
	// fadds f20,f1,f23
	ctx.f20.f64 = double(float(ctx.f1.f64 + ctx.f23.f64));
	// lfs f1,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f17,f28,f1
	ctx.f17.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// fadds f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f28.f64));
	// stfs f1,-304(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fadds f28,f31,f21
	ctx.f28.f64 = double(float(ctx.f31.f64 + ctx.f21.f64));
	// stfs f28,-308(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fsubs f31,f21,f31
	ctx.f31.f64 = double(float(ctx.f21.f64 - ctx.f31.f64));
	// stfs f31,-312(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fmuls f31,f20,f0
	ctx.f31.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f21,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f1,f23,f21
	ctx.f1.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// fmuls f28,f17,f10
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// lfs f23,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// stfsx f23,r11,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// lfs f23,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f23.f64 = double(temp.f32);
	// fadds f17,f14,f23
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// fadds f14,f27,f31
	ctx.f14.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// stfsx f14,r10,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f31.f64));
	// stfs f17,0(r3)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfsx f31,r31,r3
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// lfs f27,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f27.f64 = double(temp.f32);
	// lfs f31,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f31.f64 = double(temp.f32);
	// fadds f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// lfs f27,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f27.f64 = double(temp.f32);
	// lfs f20,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f23,f20,f10
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// lfs f20,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f20.f64 = double(temp.f32);
	// stfs f31,-308(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fmuls f21,f20,f10
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// lfs f31,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f31.f64 = double(temp.f32);
	// lfs f20,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f20.f64 = double(temp.f32);
	// fadds f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// stfs f31,-332(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fmuls f20,f20,f10
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// fsubs f31,f3,f30
	ctx.f31.f64 = double(float(ctx.f3.f64 - ctx.f30.f64));
	// stfs f31,-328(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f31,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f17,f16,f12
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fsubs f14,f31,f1
	ctx.f14.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// mulli r29,r7,56
	ctx.r29.s64 = ctx.r7.s64 * 56;
	// fadds f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f31.f64));
	// stfs f1,-304(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fsubs f27,f22,f26
	ctx.f27.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// rlwinm r28,r7,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f30.f64));
	// mulli r27,r7,24
	ctx.r27.s64 = ctx.r7.s64 * 24;
	// fmadds f31,f15,f13,f17
	ctx.f31.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fmuls f30,f14,f11
	ctx.f30.f64 = double(float(ctx.f14.f64 * ctx.f11.f64));
	// fmuls f1,f27,f11
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// fadds f27,f26,f22
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// lfs f22,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f22.f64 = double(temp.f32);
	// mulli r26,r7,36
	ctx.r26.s64 = ctx.r7.s64 * 36;
	// fmuls f27,f27,f11
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// stfs f27,-312(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f27,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f27.f64 = double(temp.f32);
	// mulli r25,r7,52
	ctx.r25.s64 = ctx.r7.s64 * 52;
	// rlwinm r24,r7,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r23,r7,20
	ctx.r23.s64 = ctx.r7.s64 * 20;
	// mulli r22,r7,44
	ctx.r22.s64 = ctx.r7.s64 * 44;
	// mulli r21,r7,60
	ctx.r21.s64 = ctx.r7.s64 * 60;
	// lfs f17,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f26,f17,f11
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// stfs f26,-336(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f26,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// stfs f26,-344(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f22,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f22.f64 = double(temp.f32);
	// lfs f26,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// stfs f26,-340(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fsubs f26,f19,f20
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// mulli r20,r7,12
	ctx.r20.s64 = ctx.r7.s64 * 12;
	// fmuls f22,f27,f12
	ctx.f22.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// lfs f27,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f27,f12
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// mulli r19,r7,28
	ctx.r19.s64 = ctx.r7.s64 * 28;
	// fmuls f14,f26,f8
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// lfs f26,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fmsubs f27,f27,f13,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 - ctx.f22.f64));
	// lfs f22,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f1,f22
	ctx.f22.f64 = double(float(ctx.f1.f64 + ctx.f22.f64));
	// stfs f22,-320(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f22,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f1,f22,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 - ctx.f1.f64));
	// lfs f22,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f26,f26,f8
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// stfs f26,-308(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fmadds f26,f22,f13,f17
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f17.f64));
	// lfs f22,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f22.f64 = double(temp.f32);
	// fadds f17,f18,f25
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// stfs f17,-304(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fadds f22,f23,f22
	ctx.f22.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// fsubs f17,f17,f31
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f31.f64));
	// stfs f17,-324(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fmsubs f22,f22,f9,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 - ctx.f14.f64));
	// lfs f14,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f17.f64 = double(temp.f32);
	// fadds f31,f31,f17
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f17.f64));
	// fsubs f17,f19,f20
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// fmadds f17,f17,f9,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 + ctx.f14.f64));
	// lfs f14,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f30
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// stfsx f14,r30,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f2
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f2.f64));
	// stfsx f14,r29,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f14.f64 = double(temp.f32);
	// fadds f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// stfsx f30,r28,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f30.f64));
	// lfs f30,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f30.f64 = double(temp.f32);
	// stfsx f2,r27,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fsubs f2,f3,f30
	ctx.f2.f64 = double(float(ctx.f3.f64 - ctx.f30.f64));
	// fadds f3,f30,f3
	ctx.f3.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// lfs f30,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f14,f30,f27
	ctx.f14.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfsx f14,r26,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// lfs f14,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f14.f64 = double(temp.f32);
	// fadds f27,f26,f1
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f1.f64));
	// stfsx f27,r3,r25
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r3.u32 + ctx.r25.u32, temp.u32);
	// stfsx f30,r24,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fsubs f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f26.f64));
	// stfsx f1,r23,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fsubs f25,f18,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 - ctx.f25.f64));
	// lfs f1,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f26,f5,f24
	ctx.f26.f64 = double(float(ctx.f5.f64 - ctx.f24.f64));
	// fsubs f30,f1,f22
	ctx.f30.f64 = double(float(ctx.f1.f64 - ctx.f22.f64));
	// stfsx f30,r22,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// fadds f30,f17,f31
	ctx.f30.f64 = double(float(ctx.f17.f64 + ctx.f31.f64));
	// stfsx f30,r21,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// fadds f1,f22,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 + ctx.f1.f64));
	// stfsx f1,r20,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// fsubs f1,f31,f17
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f17.f64));
	// lfs f17,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f30,f4,f12
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// stfs f30,-296(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f27,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f31,f17,f28
	ctx.f31.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// fsubs f30,f27,f23
	ctx.f30.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// stfsx f1,r19,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// fadds f27,f20,f19
	ctx.f27.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// lfs f22,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f1,f14,f21
	ctx.f1.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// lfs f19,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f20,f16,f13
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fmuls f18,f22,f13
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmuls f16,f22,f12
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// fadds f5,f5,f24
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f24.f64));
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// fadds f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// fmuls f17,f27,f6
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fmuls f24,f1,f6
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmsubs f22,f15,f12,f20
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f20.f64));
	// fmsubs f20,f19,f12,f18
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 - ctx.f18.f64));
	// fmadds f19,f19,f13,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f16.f64));
	// fmuls f18,f27,f7
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// lfs f23,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f29,f13,f23
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f13.f64 + ctx.f23.f64));
	// fmuls f29,f29,f12
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// fadds f27,f23,f26
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fmsubs f4,f4,f13,f29
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 - ctx.f29.f64));
	// fmuls f29,f31,f6
	ctx.f29.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fmadds f31,f31,f7,f24
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f7.f64 + ctx.f24.f64));
	// fadds f24,f22,f25
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// fsubs f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// fadds f22,f19,f3
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f3.f64));
	// fsubs f3,f3,f19
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f19.f64));
	// fmsubs f1,f1,f7,f29
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f7.f64 - ctx.f29.f64));
	// fsubs f29,f26,f23
	ctx.f29.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// fsubs f23,f2,f20
	ctx.f23.f64 = double(float(ctx.f2.f64 - ctx.f20.f64));
	// stfsx f23,r22,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// stfsx f22,r21,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fmuls f22,f21,f9
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// fadds f2,f20,f2
	ctx.f2.f64 = double(float(ctx.f20.f64 + ctx.f2.f64));
	// stfsx f2,r20,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f26,f30,f6,f18
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f6.f64 - ctx.f18.f64));
	// stfsx f3,r19,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// fmuls f23,f28,f9
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f9.f64));
	// fmadds f30,f30,f7,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f7.f64 + ctx.f17.f64));
	// fmadds f2,f28,f8,f22
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f8.f64 + ctx.f22.f64));
	// fadds f28,f4,f5
	ctx.f28.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fsubs f4,f29,f1
	ctx.f4.f64 = double(float(ctx.f29.f64 - ctx.f1.f64));
	// stfsx f4,r30,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fadds f4,f31,f27
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f27.f64));
	// stfsx f4,r29,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fadds f4,f1,f29
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f29.f64));
	// stfsx f4,r28,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fsubs f4,f27,f31
	ctx.f4.f64 = double(float(ctx.f27.f64 - ctx.f31.f64));
	// stfsx f4,r27,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fsubs f4,f24,f26
	ctx.f4.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// stfsx f4,r26,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f3,f21,f8,f23
	ctx.f3.f64 = double(float(ctx.f21.f64 * ctx.f8.f64 - ctx.f23.f64));
	// fadds f4,f30,f25
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// stfsx f4,r4,r25
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r4.u32 + ctx.r25.u32, temp.u32);
	// fadds f4,f26,f24
	ctx.f4.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// stfsx f4,r24,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// fsubs f4,f25,f30
	ctx.f4.f64 = double(float(ctx.f25.f64 - ctx.f30.f64));
	// stfsx f4,r23,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fsubs f4,f28,f3
	ctx.f4.f64 = double(float(ctx.f28.f64 - ctx.f3.f64));
	// stfsx f4,r11,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fadds f4,f2,f5
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// stfsx f4,r10,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f4,f3,f28
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f28.f64));
	// stfs f4,0(r4)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// stfsx f5,r31,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,3532(r16)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r16.u32 + 3532);
	// add r3,r18,r3
	ctx.r3.u64 = ctx.r18.u64 + ctx.r3.u64;
	// add r4,r18,r4
	ctx.r4.u64 = ctx.r18.u64 + ctx.r4.u64;
	// add r5,r17,r5
	ctx.r5.u64 = ctx.r17.u64 + ctx.r5.u64;
	// add r6,r17,r6
	ctx.r6.u64 = ctx.r17.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d3f438
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D3F438;
loc_82D3FAE8:
	// addi r12,r1,-136
	ctx.r12.s64 = ctx.r1.s64 + -136;
	// bl 0x82e28f2c
	ctx.lr = 0x82D3FAF0;
	__restfpr_14(ctx, base);
	// b 0x82e28e88
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D3FAF8"))) PPC_WEAK_FUNC(sub_82D3FAF8);
PPC_FUNC_IMPL(__imp__sub_82D3FAF8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-4560
	ctx.r5.s64 = ctx.r11.s64 + -4560;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,-3136
	ctx.r4.s64 = ctx.r11.s64 + -3136;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D3FB10"))) PPC_WEAK_FUNC(sub_82D3FB10);
PPC_FUNC_IMPL(__imp__sub_82D3FB10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D3FB18;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28efc
	ctx.lr = 0x82D3FB20;
	__savefpr_21(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d3fd7c
	if (!ctx.cr6.gt) goto loc_82D3FD7C;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r30,-32236
	ctx.r30.s64 = -2112618496;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// rlwinm r26,r11,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// rlwinm r25,r11,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f11,124(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 124);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-8128(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8128);
	ctx.f12.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f13,120(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 120);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f0.f64 = double(temp.f32);
loc_82D3FB60:
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f10,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// mulli r10,r8,24
	ctx.r10.s64 = ctx.r8.s64 * 24;
	// lfsx f9,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f29,f9,f8
	ctx.f29.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f28,f8,f9
	ctx.f28.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// mulli r10,r9,24
	ctx.r10.s64 = ctx.r9.s64 * 24;
	// lfsx f7,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f25,f7,f6
	ctx.f25.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// mulli r10,r8,28
	ctx.r10.s64 = ctx.r8.s64 * 28;
	// fmuls f7,f28,f0
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// lfsx f5,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f27,f5,f4
	ctx.f27.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// mulli r10,r9,28
	ctx.r10.s64 = ctx.r9.s64 * 28;
	// fmuls f4,f25,f0
	ctx.f4.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// lfsx f3,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f2,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f25,f2,f3
	ctx.f25.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// mulli r11,r8,20
	ctx.r11.s64 = ctx.r8.s64 * 20;
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// lfsx f1,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f1.f64 = double(temp.f32);
	// mulli r11,r8,12
	ctx.r11.s64 = ctx.r8.s64 * 12;
	// lfsx f31,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f2,f1,f31
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// mulli r11,r9,20
	ctx.r11.s64 = ctx.r9.s64 * 20;
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// lfsx f30,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f30.f64 = double(temp.f32);
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// fadds f24,f1,f5
	ctx.f24.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fsubs f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// lfsx f9,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f31,f9,f30
	ctx.f31.f64 = double(float(ctx.f9.f64 + ctx.f30.f64));
	// fsubs f9,f30,f9
	ctx.f9.f64 = double(float(ctx.f30.f64 - ctx.f9.f64));
	// rlwinm r31,r8,5,0,26
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f30,f8,f29
	ctx.f30.f64 = double(float(ctx.f8.f64 + ctx.f29.f64));
	// rlwinm r30,r8,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f29,f29,f8
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f8.f64));
	// rlwinm r29,r9,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f1,f24,f0
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// mulli r10,r7,20
	ctx.r10.s64 = ctx.r7.s64 * 20;
	// lfsx f6,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f28,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f8,f6,f10
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fmuls f28,f28,f0
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// lfsx f26,r29,r6
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r6.u32);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fmuls f26,f26,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmuls f6,f30,f13
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// fmuls f30,f29,f13
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f29,f25,f2
	ctx.f29.f64 = double(float(ctx.f25.f64 - ctx.f2.f64));
	// mulli r30,r7,12
	ctx.r30.s64 = ctx.r7.s64 * 12;
	// fadds f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f25.f64));
	// fadds f25,f31,f27
	ctx.f25.f64 = double(float(ctx.f31.f64 + ctx.f27.f64));
	// fsubs f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f31.f64));
	// fsubs f24,f3,f9
	ctx.f24.f64 = double(float(ctx.f3.f64 - ctx.f9.f64));
	// fadds f27,f8,f28
	ctx.f27.f64 = double(float(ctx.f8.f64 + ctx.f28.f64));
	// fsubs f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// fadds f23,f10,f26
	ctx.f23.f64 = double(float(ctx.f10.f64 + ctx.f26.f64));
	// fsubs f10,f10,f26
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f26.f64));
	// mulli r29,r7,28
	ctx.r29.s64 = ctx.r7.s64 * 28;
	// fmuls f22,f29,f11
	ctx.f22.f64 = double(float(ctx.f29.f64 * ctx.f11.f64));
	// fadds f28,f27,f7
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fsubs f26,f23,f6
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f6.f64));
	// fmsubs f22,f25,f12,f22
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f12.f64 - ctx.f22.f64));
	// fsubs f21,f28,f1
	ctx.f21.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// stfsx f21,r11,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fadds f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f28.f64));
	// stfs f1,0(r3)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f1,f26,f22
	ctx.f1.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// stfsx f1,r10,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f1,f22,f26
	ctx.f1.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// fmuls f29,f29,f12
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// stfsx f1,r31,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f1,f5,f24
	ctx.f1.f64 = double(float(ctx.f5.f64 - ctx.f24.f64));
	// rlwinm r28,r7,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f28,f24,f5
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f5.f64));
	// mulli r27,r7,24
	ctx.r27.s64 = ctx.r7.s64 * 24;
	// fadds f22,f9,f3
	ctx.f22.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// fadds f9,f23,f6
	ctx.f9.f64 = double(float(ctx.f23.f64 + ctx.f6.f64));
	// fmuls f26,f2,f12
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fsubs f5,f8,f4
	ctx.f5.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// fmuls f24,f31,f12
	ctx.f24.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// fadds f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// fsubs f7,f27,f7
	ctx.f7.f64 = double(float(ctx.f27.f64 - ctx.f7.f64));
	// add r5,r25,r5
	ctx.r5.u64 = ctx.r25.u64 + ctx.r5.u64;
	// fmadds f6,f25,f11,f29
	ctx.f6.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 + ctx.f29.f64));
	// add r6,r25,r6
	ctx.r6.u64 = ctx.r25.u64 + ctx.r6.u64;
	// fmuls f3,f1,f13
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fmuls f4,f28,f13
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// fadds f1,f10,f30
	ctx.f1.f64 = double(float(ctx.f10.f64 + ctx.f30.f64));
	// fsubs f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f30.f64));
	// fmsubs f31,f31,f11,f26
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f11.f64 - ctx.f26.f64));
	// fmuls f30,f22,f0
	ctx.f30.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmadds f2,f2,f11,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f24.f64));
	// fsubs f29,f9,f6
	ctx.f29.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// stfsx f29,r30,r4
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fadds f9,f6,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// stfsx f9,r29,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f5,f3
	ctx.f9.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfsx f9,r10,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f3,f5
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stfsx f9,r31,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fsubs f9,f8,f4
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// stfsx f9,r30,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f4,f8
	ctx.f9.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// stfsx f9,r29,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fsubs f9,f1,f31
	ctx.f9.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// stfsx f9,r11,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fadds f9,f31,f1
	ctx.f9.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// stfs f9,0(r4)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f9,f10,f2
	ctx.f9.f64 = double(float(ctx.f10.f64 - ctx.f2.f64));
	// stfsx f9,r28,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fadds f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 + ctx.f10.f64));
	// stfsx f10,r27,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fsubs f10,f7,f30
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f30.f64));
	// stfsx f10,r28,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f30,f7
	ctx.f10.f64 = double(float(ctx.f30.f64 + ctx.f7.f64));
	// stfsx f10,r27,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// lwz r11,3532(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 3532);
	// add r3,r26,r3
	ctx.r3.u64 = ctx.r26.u64 + ctx.r3.u64;
	// add r4,r26,r4
	ctx.r4.u64 = ctx.r26.u64 + ctx.r4.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d3fb60
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D3FB60;
loc_82D3FD7C:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f48
	ctx.lr = 0x82D3FD84;
	__restfpr_21(ctx, base);
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D3FD88"))) PPC_WEAK_FUNC(sub_82D3FD88);
PPC_FUNC_IMPL(__imp__sub_82D3FD88) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-4512
	ctx.r5.s64 = ctx.r11.s64 + -4512;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,-1264
	ctx.r4.s64 = ctx.r11.s64 + -1264;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D3FDA0"))) PPC_WEAK_FUNC(sub_82D3FDA0);
PPC_FUNC_IMPL(__imp__sub_82D3FDA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D3FDA8;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28ef4
	ctx.lr = 0x82D3FDB0;
	__savefpr_19(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d40030
	if (!ctx.cr6.gt) goto loc_82D40030;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r27,r11,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r26,r11,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32255
	ctx.r30.s64 = -2113863680;
	// lfs f9,-6336(r24)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -6336);
	ctx.f9.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f12,-6344(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -6344);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32229
	ctx.r10.s64 = -2112159744;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f13,-6340(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -6340);
	ctx.f13.f64 = double(temp.f32);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f0,-28552(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
	// lfs f10,-7656(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -7656);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,-13884(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -13884);
	ctx.f11.f64 = double(temp.f32);
	// lfs f21,-6320(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6320);
	ctx.f21.f64 = double(temp.f32);
loc_82D3FE08:
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// lfs f8,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f7,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f7.f64 = double(temp.f32);
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r30,r8,12
	ctx.r30.s64 = ctx.r8.s64 * 12;
	// lfsx f4,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f5,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f6,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f6.f64 = double(temp.f32);
	// fadds f23,f4,f5
	ctx.f23.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fadds f25,f6,f7
	ctx.f25.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// lfsx f3,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// mulli r11,r8,24
	ctx.r11.s64 = ctx.r8.s64 * 24;
	// fsubs f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfsx f2,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f2.f64 = double(temp.f32);
	// rlwinm r11,r9,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r31,r9,28
	ctx.r31.s64 = ctx.r9.s64 * 28;
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// fmuls f6,f6,f10
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// lfsx f1,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f30,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f30.f64 = double(temp.f32);
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r30,r7,12
	ctx.r30.s64 = ctx.r7.s64 * 12;
	// lfsx f29,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f31,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f4,f29,f30
	ctx.f4.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fsubs f5,f1,f31
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// fadds f31,f31,f1
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// fadds f29,f25,f3
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f3.f64));
	// fnmsubs f3,f25,f0,f3
	ctx.f3.f64 = double(float(-(ctx.f25.f64 * ctx.f0.f64 - ctx.f3.f64)));
	// lfsx f27,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f30,f30,f10
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// mulli r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 * 20;
	// fmuls f31,f31,f10
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f10.f64));
	// lfsx f28,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f1,f8,f28
	ctx.f1.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// mulli r11,r9,24
	ctx.r11.s64 = ctx.r9.s64 * 24;
	// fmadds f8,f28,f11,f8
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f11.f64 + ctx.f8.f64));
	// fadds f28,f23,f2
	ctx.f28.f64 = double(float(ctx.f23.f64 + ctx.f2.f64));
	// fnmsubs f2,f23,f0,f2
	ctx.f2.f64 = double(float(-(ctx.f23.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fsubs f23,f27,f4
	ctx.f23.f64 = double(float(ctx.f27.f64 - ctx.f4.f64));
	// fmadds f4,f4,f0,f27
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 + ctx.f27.f64));
	// lfsx f26,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f25,f26,f5
	ctx.f25.f64 = double(float(ctx.f26.f64 - ctx.f5.f64));
	// mulli r11,r9,20
	ctx.r11.s64 = ctx.r9.s64 * 20;
	// fmadds f5,f5,f0,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 + ctx.f26.f64));
	// fsubs f26,f3,f30
	ctx.f26.f64 = double(float(ctx.f3.f64 - ctx.f30.f64));
	// fadds f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f30.f64));
	// fadds f27,f28,f29
	ctx.f27.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fsubs f30,f2,f31
	ctx.f30.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// fadds f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f31.f64));
	// lfsx f24,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f20,f29,f28
	ctx.f20.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fmuls f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f21.f64));
	// fsubs f29,f4,f7
	ctx.f29.f64 = double(float(ctx.f4.f64 - ctx.f7.f64));
	// mulli r11,r7,24
	ctx.r11.s64 = ctx.r7.s64 * 24;
	// fmuls f31,f25,f12
	ctx.f31.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fsubs f28,f5,f6
	ctx.f28.f64 = double(float(ctx.f5.f64 - ctx.f6.f64));
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fadds f7,f4,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// fmuls f5,f20,f9
	ctx.f5.f64 = double(float(ctx.f20.f64 * ctx.f9.f64));
	// rlwinm r10,r7,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f22,f1,f24
	ctx.f22.f64 = double(float(ctx.f1.f64 - ctx.f24.f64));
	// rlwinm r29,r7,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f24.f64));
	// fmadds f24,f27,f11,f8
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f8.f64));
	// stfs f24,0(r3)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmsubs f31,f23,f13,f31
	ctx.f31.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f31.f64));
	// fmadds f25,f23,f12,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 + ctx.f25.f64));
	// fadds f24,f30,f26
	ctx.f24.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// fadds f23,f2,f3
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fsubs f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f30.f64));
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// fnmsubs f8,f27,f0,f8
	ctx.f8.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f8.f64)));
	// fmuls f27,f28,f13
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// mulli r28,r7,20
	ctx.r28.s64 = ctx.r7.s64 * 20;
	// fmuls f26,f28,f12
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// mulli r24,r7,28
	ctx.r24.s64 = ctx.r7.s64 * 28;
	// fmuls f4,f30,f9
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// fnmsubs f2,f24,f0,f1
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// fnmsubs f30,f23,f0,f22
	ctx.f30.f64 = double(float(-(ctx.f23.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// fmuls f3,f3,f9
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// fsubs f28,f8,f5
	ctx.f28.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// fadds f8,f5,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// fmuls f20,f6,f13
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmuls f19,f6,f12
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// fmadds f6,f29,f12,f27
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f12.f64 + ctx.f27.f64));
	// fmsubs f5,f29,f13,f26
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f13.f64 - ctx.f26.f64));
	// fmadds f27,f24,f11,f1
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f11.f64 + ctx.f1.f64));
	// fadds f29,f2,f4
	ctx.f29.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fsubs f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// fadds f2,f30,f3
	ctx.f2.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// add r5,r26,r5
	ctx.r5.u64 = ctx.r26.u64 + ctx.r5.u64;
	// fsubs f3,f30,f3
	ctx.f3.f64 = double(float(ctx.f30.f64 - ctx.f3.f64));
	// add r6,r26,r6
	ctx.r6.u64 = ctx.r26.u64 + ctx.r6.u64;
	// fsubs f30,f28,f31
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f31.f64));
	// stfsx f30,r11,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f8,f25
	ctx.f30.f64 = double(float(ctx.f8.f64 + ctx.f25.f64));
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f1,f7,f12,f20
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + ctx.f20.f64));
	// fadds f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// stfsx f31,r31,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f8,f8,f25
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f25.f64));
	// stfsx f8,r30,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// stfsx f27,r29,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f7,f7,f13,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 - ctx.f19.f64));
	// fsubs f8,f29,f6
	ctx.f8.f64 = double(float(ctx.f29.f64 - ctx.f6.f64));
	// stfsx f8,r28,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fadds f8,f29,f6
	ctx.f8.f64 = double(float(ctx.f29.f64 + ctx.f6.f64));
	// stfsx f8,r24,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fsubs f8,f4,f5
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// stfsx f8,r31,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f4,f5
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// stfsx f8,r10,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f26,f23,f11,f22
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f11.f64 + ctx.f22.f64));
	// stfsx f26,r28,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fsubs f8,f2,f1
	ctx.f8.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// stfs f8,0(r4)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f8,f2,f1
	ctx.f8.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// stfsx f8,r29,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fsubs f8,f3,f7
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// stfsx f8,r30,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fadds f8,f3,f7
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// stfsx f8,r11,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,3532(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 3532);
	// add r4,r27,r4
	ctx.r4.u64 = ctx.r27.u64 + ctx.r4.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d3fe08
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D3FE08;
loc_82D40030:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f40
	ctx.lr = 0x82D40038;
	__restfpr_19(ctx, base);
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D40040"))) PPC_WEAK_FUNC(sub_82D40040);
PPC_FUNC_IMPL(__imp__sub_82D40040) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-4464
	ctx.r5.s64 = ctx.r11.s64 + -4464;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,-608
	ctx.r4.s64 = ctx.r11.s64 + -608;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D40058"))) PPC_WEAK_FUNC(sub_82D40058);
PPC_FUNC_IMPL(__imp__sub_82D40058) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D40060;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28ee0
	ctx.lr = 0x82D40068;
	__savefpr_14(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d402d0
	if (!ctx.cr6.gt) goto loc_82D402D0;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r27,r11,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r26,r11,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f9,-6020(r24)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -6020);
	ctx.f9.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f10,-6024(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -6024);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f11,-6028(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -6028);
	ctx.f11.f64 = double(temp.f32);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f12,-6032(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -6032);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-6040(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -6040);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-6036(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6036);
	ctx.f0.f64 = double(temp.f32);
	// lfs f21,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f21.f64 = double(temp.f32);
loc_82D400C0:
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f1,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// mulli r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 * 20;
	// lfsx f7,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f6.f64 = double(temp.f32);
	// fadds f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// mulli r11,r9,24
	ctx.r11.s64 = ctx.r9.s64 * 24;
	// fsubs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// lfsx f5,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f5.f64 = double(temp.f32);
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r10,r8,24
	ctx.r10.s64 = ctx.r8.s64 * 24;
	// lfsx f4,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f31,f5,f4
	ctx.f31.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fadds f30,f4,f5
	ctx.f30.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r9,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r31,r9,12
	ctx.r31.s64 = ctx.r9.s64 * 12;
	// lfsx f2,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f28,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f6,f2,f3
	ctx.f6.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fsubs f5,f3,f2
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// lfsx f27,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f29,f28,f27
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// lfsx f26,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f25,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f3,f26,f25
	ctx.f3.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// fadds f4,f25,f26
	ctx.f4.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fmuls f25,f8,f10
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// fmuls f17,f5,f10
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// lfsx f24,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f2,f24,f1
	ctx.f2.f64 = double(float(ctx.f24.f64 + ctx.f1.f64));
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f24.f64));
	// mulli r10,r9,20
	ctx.r10.s64 = ctx.r9.s64 * 20;
	// fmuls f24,f31,f13
	ctx.f24.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// fadds f20,f4,f6
	ctx.f20.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fnmadds f25,f6,f11,f25
	ctx.f25.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 + ctx.f25.f64)));
	// lfsx f23,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f22,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f27,f23,f22
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f26,f22,f23
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// mulli r11,r7,12
	ctx.r11.s64 = ctx.r7.s64 * 12;
	// fadds f22,f3,f5
	ctx.f22.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fmsubs f24,f29,f0,f24
	ctx.f24.f64 = double(float(ctx.f29.f64 * ctx.f0.f64 - ctx.f24.f64));
	// fmadds f19,f4,f9,f2
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 + ctx.f2.f64));
	// fadds f20,f20,f8
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f8.f64));
	// fmuls f23,f30,f0
	ctx.f23.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmadds f16,f5,f9,f1
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 + ctx.f1.f64));
	// fmadds f15,f6,f9,f2
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 + ctx.f2.f64));
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r31,r7,20
	ctx.r31.s64 = ctx.r7.s64 * 20;
	// fmuls f18,f26,f0
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fadds f22,f22,f7
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f7.f64));
	// fnmsubs f24,f27,f12,f24
	ctx.f24.f64 = double(float(-(ctx.f27.f64 * ctx.f12.f64 - ctx.f24.f64)));
	// fadds f25,f25,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f19.f64));
	// fmuls f19,f7,f10
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// fmadds f23,f28,f12,f23
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f23.f64));
	// rlwinm r30,r7,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r29,r7,24
	ctx.r29.s64 = ctx.r7.s64 * 24;
	// fmadds f22,f22,f21,f1
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f21.f64 + ctx.f1.f64));
	// stfsx f22,r11,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fmadds f22,f20,f21,f2
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f21.f64 + ctx.f2.f64));
	// stfs f22,0(r3)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f22,f25,f24
	ctx.f22.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfsx f22,r10,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// stfsx f25,r31,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmuls f25,f3,f10
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmuls f24,f31,f0
	ctx.f24.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// rlwinm r28,r7,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f22,f4,f10
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fnmsubs f23,f26,f13,f23
	ctx.f23.f64 = double(float(-(ctx.f26.f64 * ctx.f13.f64 - ctx.f23.f64)));
	// fmuls f20,f30,f13
	ctx.f20.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// fnmadds f25,f7,f11,f25
	ctx.f25.f64 = double(float(-(ctx.f7.f64 * ctx.f11.f64 + ctx.f25.f64)));
	// fmadds f24,f29,f12,f24
	ctx.f24.f64 = double(float(ctx.f29.f64 * ctx.f12.f64 + ctx.f24.f64));
	// fnmadds f22,f8,f11,f22
	ctx.f22.f64 = double(float(-(ctx.f8.f64 * ctx.f11.f64 + ctx.f22.f64)));
	// fmadds f7,f7,f9,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f9.f64 + ctx.f1.f64));
	// stfs f7,-224(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -224, temp.u32);
	// fmsubs f20,f28,f0,f20
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 - ctx.f20.f64));
	// add r5,r26,r5
	ctx.r5.u64 = ctx.r26.u64 + ctx.r5.u64;
	// fmadds f14,f3,f9,f1
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 + ctx.f1.f64));
	// add r6,r26,r6
	ctx.r6.u64 = ctx.r26.u64 + ctx.r6.u64;
	// fnmadds f17,f3,f11,f17
	ctx.f17.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 + ctx.f17.f64)));
	// fadds f7,f25,f16
	ctx.f7.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// fnmadds f19,f5,f11,f19
	ctx.f19.f64 = double(float(-(ctx.f5.f64 * ctx.f11.f64 + ctx.f19.f64)));
	// fnmsubs f5,f27,f13,f24
	ctx.f5.f64 = double(float(-(ctx.f27.f64 * ctx.f13.f64 - ctx.f24.f64)));
	// fmadds f18,f28,f13,f18
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 + ctx.f18.f64));
	// fadds f3,f22,f15
	ctx.f3.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// fmadds f8,f8,f9,f2
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f9.f64 + ctx.f2.f64));
	// fnmsubs f1,f26,f12,f20
	ctx.f1.f64 = double(float(-(ctx.f26.f64 * ctx.f12.f64 - ctx.f20.f64)));
	// fmuls f26,f27,f0
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fadds f28,f19,f14
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// fmadds f30,f30,f12,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f12.f64 + ctx.f18.f64));
	// lfs f25,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f25.f64 = double(temp.f32);
	// fadds f27,f17,f25
	ctx.f27.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// fmuls f25,f6,f10
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmadds f6,f29,f13,f26
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f13.f64 + ctx.f26.f64));
	// fmadds f6,f31,f12,f6
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f12.f64 + ctx.f6.f64));
	// fsubs f31,f7,f23
	ctx.f31.f64 = double(float(ctx.f7.f64 - ctx.f23.f64));
	// stfsx f31,r10,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f7,f7,f23
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f23.f64));
	// stfsx f7,r30,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f7,f3,f5
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// stfsx f7,r29,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f3,f5
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stfsx f7,r28,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fsubs f7,f28,f1
	ctx.f7.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// stfsx f7,r31,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fadds f7,f28,f1
	ctx.f7.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// stfsx f7,r28,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fsubs f7,f27,f30
	ctx.f7.f64 = double(float(ctx.f27.f64 - ctx.f30.f64));
	// stfs f7,0(r4)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f7,f27,f30
	ctx.f7.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfsx f7,r29,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fnmadds f7,f4,f11,f25
	ctx.f7.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 + ctx.f25.f64)));
	// add r4,r27,r4
	ctx.r4.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fsubs f7,f8,f6
	ctx.f7.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfsx f7,r30,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfsx f8,r11,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// lwz r11,3532(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 3532);
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d400c0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D400C0;
loc_82D402D0:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f2c
	ctx.lr = 0x82D402D8;
	__restfpr_14(ctx, base);
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D402E0"))) PPC_WEAK_FUNC(sub_82D402E0);
PPC_FUNC_IMPL(__imp__sub_82D402E0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-4416
	ctx.r5.s64 = ctx.r11.s64 + -4416;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,88
	ctx.r4.s64 = ctx.r11.s64 + 88;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D402F8"))) PPC_WEAK_FUNC(sub_82D402F8);
PPC_FUNC_IMPL(__imp__sub_82D402F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D40300;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D40308;
	__savefpr_14(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d40640
	if (!ctx.cr6.gt) goto loc_82D40640;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r18,-32234
	ctx.r18.s64 = -2112487424;
	// lis r17,-32234
	ctx.r17.s64 = -2112487424;
	// lfs f12,-4264(r21)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -4264);
	ctx.f12.f64 = double(temp.f32);
	// lis r16,-32234
	ctx.r16.s64 = -2112487424;
	// stfs f12,-328(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// stw r11,-332(r1)
	PPC_STORE_U32(ctx.r1.u32 + -332, ctx.r11.u32);
	// lfs f12,-4268(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -4268);
	ctx.f12.f64 = double(temp.f32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stfs f12,-324(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f12,-4272(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + -4272);
	ctx.f12.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f12,-312(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lis r15,-32234
	ctx.r15.s64 = -2112487424;
	// lfs f12,-4276(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + -4276);
	ctx.f12.f64 = double(temp.f32);
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// stfs f12,-320(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f12,-4280(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + -4280);
	ctx.f12.f64 = double(temp.f32);
	// lis r23,-32235
	ctx.r23.s64 = -2112552960;
	// stfs f12,-308(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// stw r11,-336(r1)
	PPC_STORE_U32(ctx.r1.u32 + -336, ctx.r11.u32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lis r25,-32255
	ctx.r25.s64 = -2113863680;
	// lfs f25,-4288(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -4288);
	ctx.f25.f64 = double(temp.f32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f24,-4284(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -4284);
	ctx.f24.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f12,-4292(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + -4292);
	ctx.f12.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f19,-12428(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -12428);
	ctx.f19.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f20,-4304(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -4304);
	ctx.f20.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f21,-28552(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -28552);
	ctx.f21.f64 = double(temp.f32);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f22,-4308(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -4308);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,-4312(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -4312);
	ctx.f23.f64 = double(temp.f32);
	// lis r14,-32234
	ctx.r14.s64 = -2112487424;
	// lfs f26,-4316(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -4316);
	ctx.f26.f64 = double(temp.f32);
	// lfs f27,-4320(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -4320);
	ctx.f27.f64 = double(temp.f32);
	// lfs f13,-6320(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6320);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f0.f64 = double(temp.f32);
	// lfs f18,-4300(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -4300);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,-4296(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -4296);
	ctx.f17.f64 = double(temp.f32);
	// stfs f12,-316(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lwz r29,-332(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	// lwz r28,-336(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + -336);
loc_82D403E8:
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// lfs f12,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r9,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f11,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f11.f64 = double(temp.f32);
	// mulli r11,r9,24
	ctx.r11.s64 = ctx.r9.s64 * 24;
	// lfsx f10,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f30,f11,f10
	ctx.f30.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// fadds f10,f10,f11
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r31,r9,20
	ctx.r31.s64 = ctx.r9.s64 * 20;
	// lfsx f8,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f29,f9,f8
	ctx.f29.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fadds f11,f8,f9
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// lfsx f6,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f10,f10,f13
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r10,r8,24
	ctx.r10.s64 = ctx.r8.s64 * 24;
	// lfsx f5,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f9,f4,f5
	ctx.f9.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// mulli r11,r8,12
	ctx.r11.s64 = ctx.r8.s64 * 12;
	// fsubs f8,f5,f4
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fmuls f5,f29,f13
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// lfsx f3,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f3.f64 = double(temp.f32);
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 * 20;
	// lfsx f2,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f4,f2,f3
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfsx f1,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// fmsubs f2,f7,f0,f30
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 - ctx.f30.f64));
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f7,f30,f7
	ctx.f7.f64 = double(float(ctx.f30.f64 + ctx.f7.f64));
	// rlwinm r10,r7,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fnmsubs f30,f6,f0,f11
	ctx.f30.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// mulli r31,r7,12
	ctx.r31.s64 = ctx.r7.s64 * 12;
	// fadds f11,f11,f6
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f6.f64));
	// fadds f6,f9,f1
	ctx.f6.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// fnmsubs f9,f9,f21,f1
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f21.f64 - ctx.f1.f64)));
	// lfsx f31,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f1,f4,f31
	ctx.f1.f64 = double(float(ctx.f4.f64 + ctx.f31.f64));
	// fnmsubs f4,f4,f21,f31
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f21.f64 - ctx.f31.f64)));
	// fadds f31,f5,f2
	ctx.f31.f64 = double(float(ctx.f5.f64 + ctx.f2.f64));
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 - ctx.f5.f64));
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f2,f30,f10
	ctx.f2.f64 = double(float(ctx.f30.f64 - ctx.f10.f64));
	// mulli r27,r7,24
	ctx.r27.s64 = ctx.r7.s64 * 24;
	// fmuls f29,f7,f24
	ctx.f29.f64 = double(float(ctx.f7.f64 * ctx.f24.f64));
	// fadds f10,f30,f10
	ctx.f10.f64 = double(float(ctx.f30.f64 + ctx.f10.f64));
	// fmuls f30,f11,f24
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f24.f64));
	// fmuls f28,f5,f22
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f22.f64));
	// fmuls f16,f2,f26
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// fmadds f11,f11,f25,f29
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f25.f64 + ctx.f29.f64));
	// fmuls f29,f31,f26
	ctx.f29.f64 = double(float(ctx.f31.f64 * ctx.f26.f64));
	// fmuls f15,f10,f22
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f22.f64));
	// fmsubs f7,f7,f25,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f25.f64 - ctx.f30.f64));
	// fsubs f30,f1,f6
	ctx.f30.f64 = double(float(ctx.f1.f64 - ctx.f6.f64));
	// fadds f6,f1,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 + ctx.f6.f64));
	// fadds f1,f3,f8
	ctx.f1.f64 = double(float(ctx.f3.f64 + ctx.f8.f64));
	// fsubs f8,f3,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f8.f64));
	// fmsubs f10,f10,f23,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f23.f64 - ctx.f28.f64));
	// fmsubs f31,f31,f27,f16
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f27.f64 - ctx.f16.f64));
	// fmadds f2,f2,f27,f29
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64 + ctx.f29.f64));
	// fmadds f5,f5,f23,f15
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 + ctx.f15.f64));
	// fadds f29,f4,f9
	ctx.f29.f64 = double(float(ctx.f4.f64 + ctx.f9.f64));
	// fsubs f9,f4,f9
	ctx.f9.f64 = double(float(ctx.f4.f64 - ctx.f9.f64));
	// fmuls f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f20.f64));
	// fadds f4,f10,f31
	ctx.f4.f64 = double(float(ctx.f10.f64 + ctx.f31.f64));
	// fsubs f3,f2,f5
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f5.f64));
	// fadds f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f2.f64));
	// fsubs f2,f31,f10
	ctx.f2.f64 = double(float(ctx.f31.f64 - ctx.f10.f64));
	// fmuls f10,f5,f13
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmuls f5,f2,f13
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f2,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f28,f1,f2
	ctx.f28.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f2,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f16,f8,f2
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f2.f64));
	// lfs f2,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f31,f7,f4
	ctx.f31.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// fmuls f15,f9,f2
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// lfs f2,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f14,f29,f2
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f2.f64));
	// add r5,r28,r5
	ctx.r5.u64 = ctx.r28.u64 + ctx.r5.u64;
	// fnmsubs f2,f6,f19,f12
	ctx.f2.f64 = double(float(-(ctx.f6.f64 * ctx.f19.f64 - ctx.f12.f64)));
	// add r6,r28,r6
	ctx.r6.u64 = ctx.r28.u64 + ctx.r6.u64;
	// fmsubs f9,f9,f17,f16
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f29,f29,f18,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f18.f64 + ctx.f28.f64));
	// fmadds f12,f6,f0,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f12.f64));
	// stfs f12,0(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmadds f12,f4,f0,f7
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 + ctx.f7.f64));
	// fadds f28,f3,f11
	ctx.f28.f64 = double(float(ctx.f3.f64 + ctx.f11.f64));
	// fmsubs f11,f3,f0,f11
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f11.f64));
	// fmadds f8,f8,f16,f15
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfs f16,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f1,f1,f16,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f16.f64 - ctx.f14.f64));
	// fsubs f6,f30,f9
	ctx.f6.f64 = double(float(ctx.f30.f64 - ctx.f9.f64));
	// fsubs f7,f2,f29
	ctx.f7.f64 = double(float(ctx.f2.f64 - ctx.f29.f64));
	// fmadds f3,f29,f0,f2
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f0.f64 + ctx.f2.f64));
	// fmadds f9,f9,f0,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 + ctx.f30.f64));
	// fsubs f4,f8,f1
	ctx.f4.f64 = double(float(ctx.f8.f64 - ctx.f1.f64));
	// fadds f8,f1,f8
	ctx.f8.f64 = double(float(ctx.f1.f64 + ctx.f8.f64));
	// fsubs f2,f7,f6
	ctx.f2.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// fadds f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// fsubs f30,f3,f9
	ctx.f30.f64 = double(float(ctx.f3.f64 - ctx.f9.f64));
	// fadds f9,f9,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// fsubs f6,f4,f31
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// fadds f1,f8,f5
	ctx.f1.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// fsubs f3,f2,f10
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f10.f64));
	// fsubs f29,f7,f28
	ctx.f29.f64 = double(float(ctx.f7.f64 - ctx.f28.f64));
	// fsubs f16,f30,f12
	ctx.f16.f64 = double(float(ctx.f30.f64 - ctx.f12.f64));
	// stfsx f16,r11,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fsubs f16,f9,f11
	ctx.f16.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// stfsx f16,r27,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fadds f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f12,f30,f12
	ctx.f12.f64 = double(float(ctx.f30.f64 + ctx.f12.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f11,f7,f28
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f28.f64));
	// fadds f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 + ctx.f10.f64));
	// fadds f9,f4,f31
	ctx.f9.f64 = double(float(ctx.f4.f64 + ctx.f31.f64));
	// fsubs f12,f3,f6
	ctx.f12.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// stfsx f12,r31,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fadds f12,f6,f3
	ctx.f12.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// stfsx f12,r30,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fsubs f12,f29,f1
	ctx.f12.f64 = double(float(ctx.f29.f64 - ctx.f1.f64));
	// stfsx f12,r30,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fadds f12,f1,f29
	ctx.f12.f64 = double(float(ctx.f1.f64 + ctx.f29.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f12,f8,f5
	ctx.f12.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// mulli r10,r7,20
	ctx.r10.s64 = ctx.r7.s64 * 20;
	// fadds f8,f11,f12
	ctx.f8.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// stfsx f8,r11,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fsubs f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f12,f10,f9
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// stfsx f12,r31,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f12,f9,f10
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,3532(r14)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r14.u32 + 3532);
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// add r4,r29,r4
	ctx.r4.u64 = ctx.r29.u64 + ctx.r4.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d403e8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D403E8;
loc_82D40640:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D40648;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D40650"))) PPC_WEAK_FUNC(sub_82D40650);
PPC_FUNC_IMPL(__imp__sub_82D40650) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-4368
	ctx.r5.s64 = ctx.r11.s64 + -4368;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,760
	ctx.r4.s64 = ctx.r11.s64 + 760;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D40668"))) PPC_WEAK_FUNC(sub_82D40668);
PPC_FUNC_IMPL(__imp__sub_82D40668) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D40670;
	__savegprlr_26(ctx, base);
	// stfd f29,-80(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -80, ctx.f29.u64);
	// stfd f30,-72(r1)
	PPC_STORE_U64(ctx.r1.u32 + -72, ctx.f30.u64);
	// stfd f31,-64(r1)
	PPC_STORE_U64(ctx.r1.u32 + -64, ctx.f31.u64);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d40820
	if (!ctx.cr6.gt) goto loc_82D40820;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// rlwinm r28,r11,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r27,r11,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f13,-6320(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6320);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f0.f64 = double(temp.f32);
loc_82D406AC:
	// mulli r11,r8,20
	ctx.r11.s64 = ctx.r8.s64 * 20;
	// lfs f12,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f11,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r31,r8,24
	ctx.r31.s64 = ctx.r8.s64 * 24;
	// lfsx f10,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f31,f10,f11
	ctx.f31.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fsubs f30,f12,f9
	ctx.f30.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// lfsx f8,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f12,f9,f0,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 + ctx.f12.f64));
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f10,f11,f10
	ctx.f10.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// mulli r10,r9,20
	ctx.r10.s64 = ctx.r9.s64 * 20;
	// lfsx f7,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f11,f8,f7
	ctx.f11.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// fmadds f8,f7,f0,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 + ctx.f8.f64));
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// fmuls f10,f10,f13
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfsx f5,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f9,f5,f6
	ctx.f9.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// lfsx f4,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// rlwinm r10,r9,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r31,r9,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// lfsx f2,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f13
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfsx f3,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f7,f6,f13
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmsubs f6,f4,f0,f31
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 - ctx.f31.f64));
	// mulli r11,r7,12
	ctx.r11.s64 = ctx.r7.s64 * 12;
	// fadds f31,f31,f4
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// fsubs f29,f3,f9
	ctx.f29.f64 = double(float(ctx.f3.f64 - ctx.f9.f64));
	// fadds f5,f30,f2
	ctx.f5.f64 = double(float(ctx.f30.f64 + ctx.f2.f64));
	// fsubs f4,f11,f1
	ctx.f4.f64 = double(float(ctx.f11.f64 - ctx.f1.f64));
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f1.f64));
	// rlwinm r31,r7,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f2,f30,f2
	ctx.f2.f64 = double(float(ctx.f30.f64 - ctx.f2.f64));
	// rlwinm r30,r7,3,0,28
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f1,f31,f0
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// mulli r29,r7,20
	ctx.r29.s64 = ctx.r7.s64 * 20;
	// fmadds f31,f3,f0,f9
	ctx.f31.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f9.f64));
	// fadds f9,f8,f12
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fsubs f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// fsubs f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f7.f64));
	// fadds f3,f4,f5
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// add r5,r27,r5
	ctx.r5.u64 = ctx.r27.u64 + ctx.r5.u64;
	// fsubs f4,f2,f11
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f11.f64));
	// add r6,r27,r6
	ctx.r6.u64 = ctx.r27.u64 + ctx.r6.u64;
	// fadds f11,f11,f2
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f2.f64));
	// fsubs f30,f31,f10
	ctx.f30.f64 = double(float(ctx.f31.f64 - ctx.f10.f64));
	// fadds f10,f31,f10
	ctx.f10.f64 = double(float(ctx.f31.f64 + ctx.f10.f64));
	// fsubs f31,f9,f1
	ctx.f31.f64 = double(float(ctx.f9.f64 - ctx.f1.f64));
	// stfsx f31,r11,r3
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f1,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 + ctx.f9.f64));
	// stfs f9,0(r3)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f9,f3,f8
	ctx.f9.f64 = double(float(ctx.f3.f64 - ctx.f8.f64));
	// stfsx f9,r10,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f8,f3
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// stfsx f9,r31,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fsubs f9,f5,f30
	ctx.f9.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// stfsx f9,r30,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fadds f9,f30,f5
	ctx.f9.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// stfsx f9,r29,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f4,f10
	ctx.f9.f64 = double(float(ctx.f4.f64 - ctx.f10.f64));
	// stfs f9,0(r4)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f4.f64));
	// stfsx f10,r11,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fmuls f10,f29,f0
	ctx.f10.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fadds f9,f7,f6
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f6.f64));
	// fsubs f8,f12,f10
	ctx.f8.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// stfsx f8,r31,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f12,f11,f9
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// stfsx f12,r29,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fadds f12,f9,f11
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// stfsx f12,r30,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lwz r11,3532(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 3532);
	// add r3,r28,r3
	ctx.r3.u64 = ctx.r28.u64 + ctx.r3.u64;
	// add r4,r28,r4
	ctx.r4.u64 = ctx.r28.u64 + ctx.r4.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d406ac
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D406AC;
loc_82D40820:
	// lfd f29,-80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// lfd f30,-72(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f31,-64(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D40830"))) PPC_WEAK_FUNC(sub_82D40830);
PPC_FUNC_IMPL(__imp__sub_82D40830) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-4256
	ctx.r5.s64 = ctx.r11.s64 + -4256;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,1640
	ctx.r4.s64 = ctx.r11.s64 + 1640;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D40848"))) PPC_WEAK_FUNC(sub_82D40848);
PPC_FUNC_IMPL(__imp__sub_82D40848) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e48
	ctx.lr = 0x82D40850;
	__savegprlr_20(ctx, base);
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82e28ee4
	ctx.lr = 0x82D40858;
	__savefpr_15(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d40ac8
	if (!ctx.cr6.gt) goto loc_82D40AC8;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r22,-32229
	ctx.r22.s64 = -2112159744;
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// rlwinm r21,r11,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// rlwinm r20,r11,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f19,-13884(r22)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -13884);
	ctx.f19.f64 = double(temp.f32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f25,-4124(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -4124);
	ctx.f25.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f26,-4128(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -4128);
	ctx.f26.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f27,-4132(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -4132);
	ctx.f27.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f28,-4136(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -4136);
	ctx.f28.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f29,-4140(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -4140);
	ctx.f29.f64 = double(temp.f32);
	// lfs f30,-4144(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -4144);
	ctx.f30.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f31,-4148(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -4148);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,-4152(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -4152);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,-4156(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4156);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,-4160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4160);
	ctx.f3.f64 = double(temp.f32);
loc_82D408D0:
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f0,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r31,r9,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r30,r9,20
	ctx.r30.s64 = ctx.r9.s64 * 20;
	// lfsx f8,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f6,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f8,f31
	ctx.f24.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// lfsx f5,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f23,f8,f2
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f2.f64));
	// fmuls f21,f6,f30
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fmuls f22,f5,f2
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// fmuls f16,f8,f1
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// fmuls f18,f8,f30
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fmuls f20,f6,f31
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f15,f6,f2
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// fmuls f8,f8,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// lfsx f4,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f17,f4,f2
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// fmadds f24,f6,f1,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f1.f64 + ctx.f24.f64));
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmadds f21,f4,f31,f21
	ctx.f21.f64 = double(float(-(ctx.f4.f64 * ctx.f31.f64 + ctx.f21.f64)));
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmadds f22,f4,f3,f22
	ctx.f22.f64 = double(float(-(ctx.f4.f64 * ctx.f3.f64 + ctx.f22.f64)));
	// rlwinm r31,r7,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fmadds f23,f5,f1,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 + ctx.f23.f64));
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fmadds f18,f4,f1,f18
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f1.f64 + ctx.f18.f64));
	// fnmadds f20,f5,f3,f20
	ctx.f20.f64 = double(float(-(ctx.f5.f64 * ctx.f3.f64 + ctx.f20.f64)));
	// lfsx f7,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f7.f64 = double(temp.f32);
	// mulli r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 * 20;
	// fmadds f4,f4,f30,f15
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64 + ctx.f15.f64));
	// lfsx f13,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f8,f5,f31,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f31.f64 - ctx.f8.f64));
	// fmadds f6,f6,f3,f17
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 + ctx.f17.f64));
	// fmadds f17,f7,f31,f16
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f31.f64 + ctx.f16.f64));
	// lfsx f12,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f12.f64 = double(temp.f32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// fadds f22,f20,f18
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// fadds f20,f4,f8
	ctx.f20.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// lfsx f10,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f10.f64 = double(temp.f32);
	// fadds f21,f6,f17
	ctx.f21.f64 = double(float(ctx.f6.f64 + ctx.f17.f64));
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fnmsubs f8,f7,f30,f24
	ctx.f8.f64 = double(float(-(ctx.f7.f64 * ctx.f30.f64 - ctx.f24.f64)));
	// rlwinm r10,r7,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fnmsubs f6,f7,f3,f23
	ctx.f6.f64 = double(float(-(ctx.f7.f64 * ctx.f3.f64 - ctx.f23.f64)));
	// fmuls f24,f10,f28
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f23,f12,f26
	ctx.f23.f64 = double(float(ctx.f12.f64 * ctx.f26.f64));
	// fnmsubs f4,f7,f2,f22
	ctx.f4.f64 = double(float(-(ctx.f7.f64 * ctx.f2.f64 - ctx.f22.f64)));
	// lfsx f11,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fnmsubs f7,f7,f1,f20
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f1.f64 - ctx.f20.f64)));
	// fmuls f20,f13,f28
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// fmadds f5,f5,f30,f21
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64 + ctx.f21.f64));
	// fmuls f21,f12,f28
	ctx.f21.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// lfsx f9,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f18,f11,f29
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f29.f64));
	// fmuls f22,f9,f29
	ctx.f22.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// mulli r11,r7,12
	ctx.r11.s64 = ctx.r7.s64 * 12;
	// fnmadds f24,f13,f29,f24
	ctx.f24.f64 = double(float(-(ctx.f13.f64 * ctx.f29.f64 + ctx.f24.f64)));
	// fmsubs f23,f11,f27,f23
	ctx.f23.f64 = double(float(ctx.f11.f64 * ctx.f27.f64 - ctx.f23.f64));
	// fmuls f17,f9,f28
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f16,f11,f26
	ctx.f16.f64 = double(float(ctx.f11.f64 * ctx.f26.f64));
	// fmuls f15,f11,f28
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// fnmadds f20,f9,f26,f20
	ctx.f20.f64 = double(float(-(ctx.f9.f64 * ctx.f26.f64 + ctx.f20.f64)));
	// fmsubs f21,f11,f25,f21
	ctx.f21.f64 = double(float(ctx.f11.f64 * ctx.f25.f64 - ctx.f21.f64));
	// fmsubs f18,f12,f27,f18
	ctx.f18.f64 = double(float(ctx.f12.f64 * ctx.f27.f64 - ctx.f18.f64));
	// fnmadds f22,f13,f26,f22
	ctx.f22.f64 = double(float(-(ctx.f13.f64 * ctx.f26.f64 + ctx.f22.f64)));
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// fnmadds f17,f10,f29,f17
	ctx.f17.f64 = double(float(-(ctx.f10.f64 * ctx.f29.f64 + ctx.f17.f64)));
	// fmsubs f16,f12,f25,f16
	ctx.f16.f64 = double(float(ctx.f12.f64 * ctx.f25.f64 - ctx.f16.f64));
	// fmadds f23,f9,f25,f0
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f25.f64 + ctx.f0.f64));
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// fmadds f21,f10,f27,f0
	ctx.f21.f64 = double(float(ctx.f10.f64 * ctx.f27.f64 + ctx.f0.f64));
	// fmadds f18,f10,f25,f0
	ctx.f18.f64 = double(float(ctx.f10.f64 * ctx.f25.f64 + ctx.f0.f64));
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fmadds f16,f13,f27,f0
	ctx.f16.f64 = double(float(ctx.f13.f64 * ctx.f27.f64 + ctx.f0.f64));
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// fadds f23,f22,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// add r5,r20,r5
	ctx.r5.u64 = ctx.r20.u64 + ctx.r5.u64;
	// fadds f22,f20,f18
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// add r6,r20,r6
	ctx.r6.u64 = ctx.r20.u64 + ctx.r6.u64;
	// fmuls f20,f12,f29
	ctx.f20.f64 = double(float(ctx.f12.f64 * ctx.f29.f64));
	// fnmadds f18,f10,f26,f15
	ctx.f18.f64 = double(float(-(ctx.f10.f64 * ctx.f26.f64 + ctx.f15.f64)));
	// fadds f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fadds f21,f17,f16
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fmadds f17,f13,f25,f0
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f25.f64 + ctx.f0.f64));
	// fmsubs f20,f9,f27,f20
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f27.f64 - ctx.f20.f64));
	// fadds f9,f23,f4
	ctx.f9.f64 = double(float(ctx.f23.f64 + ctx.f4.f64));
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// fsubs f18,f24,f8
	ctx.f18.f64 = double(float(ctx.f24.f64 - ctx.f8.f64));
	// stfsx f18,r11,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fadds f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// fadds f8,f24,f8
	ctx.f8.f64 = double(float(ctx.f24.f64 + ctx.f8.f64));
	// fsubs f24,f23,f4
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f4.f64));
	// stfsx f24,r10,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f24,f22,f6
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f6.f64));
	// stfsx f24,r31,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// stfsx f8,r31,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f8,f22,f6
	ctx.f8.f64 = double(float(ctx.f22.f64 - ctx.f6.f64));
	// stfsx f8,r11,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// mulli r11,r7,20
	ctx.r11.s64 = ctx.r7.s64 * 20;
	// fadds f8,f21,f7
	ctx.f8.f64 = double(float(ctx.f21.f64 + ctx.f7.f64));
	// stfsx f8,r30,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// stfsx f9,r30,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fadds f9,f20,f5
	ctx.f9.f64 = double(float(ctx.f20.f64 + ctx.f5.f64));
	// stfsx f9,r11,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fsubs f8,f20,f5
	ctx.f8.f64 = double(float(ctx.f20.f64 - ctx.f5.f64));
	// stfs f8,0(r4)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f9,f21,f7
	ctx.f9.f64 = double(float(ctx.f21.f64 - ctx.f7.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f0,f13,f19,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f19.f64 + ctx.f0.f64));
	// stfs f0,0(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lwz r11,3532(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3532);
	// add r4,r21,r4
	ctx.r4.u64 = ctx.r21.u64 + ctx.r4.u64;
	// add r3,r21,r3
	ctx.r3.u64 = ctx.r21.u64 + ctx.r3.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d408d0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D408D0;
loc_82D40AC8:
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82e28f30
	ctx.lr = 0x82D40AD0;
	__restfpr_15(ctx, base);
	// b 0x82e28e98
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D40AD8"))) PPC_WEAK_FUNC(sub_82D40AD8);
PPC_FUNC_IMPL(__imp__sub_82D40AD8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-4208
	ctx.r5.s64 = ctx.r11.s64 + -4208;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,2120
	ctx.r4.s64 = ctx.r11.s64 + 2120;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D40AF0"))) PPC_WEAK_FUNC(sub_82D40AF0);
PPC_FUNC_IMPL(__imp__sub_82D40AF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D40AF8;
	__savegprlr_26(ctx, base);
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28f14
	ctx.lr = 0x82D40B00;
	__savefpr_27(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d40c90
	if (!ctx.cr6.gt) goto loc_82D40C90;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r26,-32255
	ctx.r26.s64 = -2113863680;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// rlwinm r29,r11,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// rlwinm r28,r11,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-32229
	ctx.r10.s64 = -2112159744;
	// lfs f30,-28552(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -28552);
	ctx.f30.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f13,-6344(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -6344);
	ctx.f13.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f0,-6340(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -6340);
	ctx.f0.f64 = double(temp.f32);
	// lfs f31,-13884(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -13884);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,-6336(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6336);
	ctx.f1.f64 = double(temp.f32);
loc_82D40B48:
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// lfsx f11,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f10.f64 = double(temp.f32);
	// fadds f2,f10,f11
	ctx.f2.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r31,r8,20
	ctx.r31.s64 = ctx.r8.s64 * 20;
	// lfsx f9,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f10,f8,f9
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// rlwinm r11,r9,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f8,f7,f12
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// rlwinm r31,r9,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r30,r9,12
	ctx.r30.s64 = ctx.r9.s64 * 12;
	// lfsx f6,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f7,f6,f5
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// lfsx f3,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fsubs f5,f4,f3
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f3,f10,f2
	ctx.f3.f64 = double(float(ctx.f10.f64 + ctx.f2.f64));
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f2,f2,f10
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f10.f64));
	// rlwinm r31,r7,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f10,f9,f11
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// mulli r30,r7,12
	ctx.r30.s64 = ctx.r7.s64 * 12;
	// fsubs f9,f11,f9
	ctx.f9.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// fmuls f28,f7,f0
	ctx.f28.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f29,f7,f13
	ctx.f29.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmuls f27,f6,f0
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// add r5,r28,r5
	ctx.r5.u64 = ctx.r28.u64 + ctx.r5.u64;
	// fmuls f11,f2,f1
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// add r6,r28,r6
	ctx.r6.u64 = ctx.r28.u64 + ctx.r6.u64;
	// fmuls f2,f6,f13
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmuls f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// fmadds f6,f5,f13,f28
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 + ctx.f28.f64));
	// fmsubs f7,f5,f0,f29
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 - ctx.f29.f64));
	// fmsubs f5,f4,f0,f2
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 - ctx.f2.f64));
	// fnmsubs f2,f3,f30,f8
	ctx.f2.f64 = double(float(-(ctx.f3.f64 * ctx.f30.f64 - ctx.f8.f64)));
	// fmadds f3,f3,f31,f8
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64 + ctx.f8.f64));
	// fnmsubs f8,f10,f30,f12
	ctx.f8.f64 = double(float(-(ctx.f10.f64 * ctx.f30.f64 - ctx.f12.f64)));
	// fmadds f12,f10,f31,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f31.f64 + ctx.f12.f64));
	// stfsx f12,r11,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fmadds f4,f4,f13,f27
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f27.f64));
	// stfs f3,0(r3)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f12,f2,f11
	ctx.f12.f64 = double(float(ctx.f2.f64 - ctx.f11.f64));
	// fadds f11,f2,f11
	ctx.f11.f64 = double(float(ctx.f2.f64 + ctx.f11.f64));
	// fsubs f10,f8,f9
	ctx.f10.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// fadds f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fsubs f8,f12,f7
	ctx.f8.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// stfsx f8,r10,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f11,f6
	ctx.f8.f64 = double(float(ctx.f11.f64 + ctx.f6.f64));
	// stfsx f8,r11,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fadds f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f7.f64));
	// stfsx f12,r31,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fsubs f12,f11,f6
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f6.f64));
	// stfsx f12,r30,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fsubs f12,f10,f5
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f5.f64));
	// stfsx f12,r30,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fadds f12,f9,f4
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f4.f64));
	// stfsx f12,r31,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fadds f12,f10,f5
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f5.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f12,f9,f4
	ctx.f12.f64 = double(float(ctx.f9.f64 - ctx.f4.f64));
	// stfs f12,0(r4)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lwz r11,3532(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 3532);
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// add r4,r29,r4
	ctx.r4.u64 = ctx.r29.u64 + ctx.r4.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d40b48
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D40B48;
loc_82D40C90:
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28f60
	ctx.lr = 0x82D40C98;
	__restfpr_27(ctx, base);
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D40CA0"))) PPC_WEAK_FUNC(sub_82D40CA0);
PPC_FUNC_IMPL(__imp__sub_82D40CA0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-4120
	ctx.r5.s64 = ctx.r11.s64 + -4120;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,2800
	ctx.r4.s64 = ctx.r11.s64 + 2800;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D40CB8"))) PPC_WEAK_FUNC(sub_82D40CB8);
PPC_FUNC_IMPL(__imp__sub_82D40CB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e44
	ctx.lr = 0x82D40CC0;
	__savegprlr_19(ctx, base);
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28f00
	ctx.lr = 0x82D40CC8;
	__savefpr_22(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d40e84
	if (!ctx.cr6.gt) goto loc_82D40E84;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// rlwinm r20,r11,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// rlwinm r19,r11,2,0,29
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f23,-6156(r21)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -6156);
	ctx.f23.f64 = double(temp.f32);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f24,-6160(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -6160);
	ctx.f24.f64 = double(temp.f32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f25,-6164(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -6164);
	ctx.f25.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lis r29,-32255
	ctx.r29.s64 = -2113863680;
	// lfs f26,-6168(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -6168);
	ctx.f26.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f27,-6140(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -6140);
	ctx.f27.f64 = double(temp.f32);
	// lis r10,-32229
	ctx.r10.s64 = -2112159744;
	// lfs f28,-6144(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -6144);
	ctx.f28.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f29,-6148(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -6148);
	ctx.f29.f64 = double(temp.f32);
	// lfs f30,-6152(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -6152);
	ctx.f30.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f31,-28552(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -28552);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,-7656(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -7656);
	ctx.f1.f64 = double(temp.f32);
	// lfs f0,-13884(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -13884);
	ctx.f0.f64 = double(temp.f32);
	// lfs f2,-6320(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6320);
	ctx.f2.f64 = double(temp.f32);
loc_82D40D48:
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f13,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r31,r9,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r29,r9,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r28,r8,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f12,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f11,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f11.f64 = double(temp.f32);
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// lfsx f10,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f10.f64 = double(temp.f32);
	// fadds f4,f11,f12
	ctx.f4.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// lfsx f9,r29,r6
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r6.u32);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f3,f12,f11
	ctx.f3.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// fsubs f12,f9,f10
	ctx.f12.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// lfsx f8,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// lfsx f6,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f11,f13,f6
	ctx.f11.f64 = double(float(ctx.f13.f64 - ctx.f6.f64));
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// fmadds f13,f6,f0,f13
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f13.f64));
	// fadds f6,f4,f8
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fnmsubs f8,f4,f31,f8
	ctx.f8.f64 = double(float(-(ctx.f4.f64 * ctx.f31.f64 - ctx.f8.f64)));
	// lfsx f5,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f22,f7,f12
	ctx.f22.f64 = double(float(ctx.f7.f64 - ctx.f12.f64));
	// fmuls f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// fmuls f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fmadds f12,f12,f31,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64 + ctx.f7.f64));
	// mulli r10,r7,12
	ctx.r10.s64 = ctx.r7.s64 * 12;
	// fmuls f10,f3,f1
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// fmuls f7,f22,f2
	ctx.f7.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// fsubs f3,f11,f5
	ctx.f3.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// rlwinm r31,r7,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// add r5,r19,r5
	ctx.r5.u64 = ctx.r19.u64 + ctx.r5.u64;
	// fsubs f5,f13,f6
	ctx.f5.f64 = double(float(ctx.f13.f64 - ctx.f6.f64));
	// add r6,r19,r6
	ctx.r6.u64 = ctx.r19.u64 + ctx.r6.u64;
	// fsubs f4,f8,f9
	ctx.f4.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// fadds f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fadds f8,f12,f10
	ctx.f8.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// fmadds f13,f6,f0,f13
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f13.f64));
	// stfs f13,0(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fsubs f13,f5,f7
	ctx.f13.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// stfsx f13,r11,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fadds f13,f7,f5
	ctx.f13.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// stfsx f13,r10,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmuls f10,f4,f29
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// fmuls f13,f8,f27
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmuls f6,f9,f25
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// fmuls f7,f12,f23
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f23.f64));
	// fmadds f10,f8,f30,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f30.f64 + ctx.f10.f64));
	// fmsubs f13,f4,f28,f13
	ctx.f13.f64 = double(float(ctx.f4.f64 * ctx.f28.f64 - ctx.f13.f64));
	// fmadds f12,f12,f26,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f26.f64 + ctx.f6.f64));
	// fmsubs f9,f9,f24,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f24.f64 - ctx.f7.f64));
	// fsubs f8,f3,f13
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f13.f64));
	// fmadds f13,f13,f0,f3
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f3.f64));
	// stfs f13,0(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f7,f11,f9
	ctx.f7.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// fmadds f11,f9,f0,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 + ctx.f11.f64));
	// fadds f13,f8,f10
	ctx.f13.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// stfsx f13,r10,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// rlwinm r10,r7,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f13,f8,f10
	ctx.f13.f64 = double(float(ctx.f8.f64 - ctx.f10.f64));
	// stfsx f13,r31,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f7,f12
	ctx.f13.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// stfsx f11,r11,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fsubs f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 - ctx.f12.f64));
	// stfsx f13,r10,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// add r3,r20,r3
	ctx.r3.u64 = ctx.r20.u64 + ctx.r3.u64;
	// stfsx f12,r31,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,3532(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// add r4,r20,r4
	ctx.r4.u64 = ctx.r20.u64 + ctx.r4.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d40d48
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D40D48;
loc_82D40E84:
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28f4c
	ctx.lr = 0x82D40E8C;
	__restfpr_22(ctx, base);
	// b 0x82e28e94
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D40E90"))) PPC_WEAK_FUNC(sub_82D40E90);
PPC_FUNC_IMPL(__imp__sub_82D40E90) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-4072
	ctx.r5.s64 = ctx.r11.s64 + -4072;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,3256
	ctx.r4.s64 = ctx.r11.s64 + 3256;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D40EA8"))) PPC_WEAK_FUNC(sub_82D40EA8);
PPC_FUNC_IMPL(__imp__sub_82D40EA8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82D40EB0;
	__savegprlr_25(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d40fd4
	if (!ctx.cr6.gt) goto loc_82D40FD4;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r29,r11,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f4,120(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 120);
	ctx.f4.f64 = double(temp.f32);
	// lfs f0,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f0.f64 = double(temp.f32);
loc_82D40EE0:
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// lfsx f12,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f11,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f5,f12,f11
	ctx.f5.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f11,f11,f12
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// mulli r10,r9,12
	ctx.r10.s64 = ctx.r9.s64 * 12;
	// lfsx f10,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f12,f9,f10
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// rlwinm r27,r8,4,0,27
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f9,f10,f9
	ctx.f9.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// rlwinm r26,r8,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// rlwinm r25,r9,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r31,r7,12
	ctx.r31.s64 = ctx.r7.s64 * 12;
	// lfsx f8,r27,r5
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r5.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r26,r5
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r5.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f10,f8,f13
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfsx f6,r25,r6
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r6.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f3,f5,f12
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f12.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fsubs f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// fadds f5,f12,f5
	ctx.f5.f64 = double(float(ctx.f12.f64 + ctx.f5.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// add r5,r29,r5
	ctx.r5.u64 = ctx.r29.u64 + ctx.r5.u64;
	// add r6,r29,r6
	ctx.r6.u64 = ctx.r29.u64 + ctx.r6.u64;
	// fadds f12,f10,f7
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// fsubs f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// fmuls f7,f3,f4
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// fsubs f8,f13,f6
	ctx.f8.f64 = double(float(ctx.f13.f64 - ctx.f6.f64));
	// fadds f13,f13,f6
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f6.f64));
	// fmuls f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// fsubs f5,f12,f11
	ctx.f5.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// stfsx f5,r11,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fadds f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// stfs f12,0(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f12,f10,f9
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f12,f10,f9
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f9.f64));
	// stfsx f12,r31,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fsubs f12,f8,f7
	ctx.f12.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// stfsx f12,r11,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fadds f12,f7,f8
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfs f12,0(r4)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f12,f13,f6
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f6.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f13,f6,f13
	ctx.f13.f64 = double(float(ctx.f6.f64 + ctx.f13.f64));
	// stfsx f13,r31,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,3532(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3532);
	// add r3,r30,r3
	ctx.r3.u64 = ctx.r30.u64 + ctx.r3.u64;
	// add r4,r30,r4
	ctx.r4.u64 = ctx.r30.u64 + ctx.r4.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d40ee0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D40EE0;
loc_82D40FD4:
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D40FD8"))) PPC_WEAK_FUNC(sub_82D40FD8);
PPC_FUNC_IMPL(__imp__sub_82D40FD8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-4024
	ctx.r5.s64 = ctx.r11.s64 + -4024;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,3752
	ctx.r4.s64 = ctx.r11.s64 + 3752;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D40FF0"))) PPC_WEAK_FUNC(sub_82D40FF0);
PPC_FUNC_IMPL(__imp__sub_82D40FF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D40FF8;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f04
	ctx.lr = 0x82D41000;
	__savefpr_23(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d41150
	if (!ctx.cr6.gt) goto loc_82D41150;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r24,-32229
	ctx.r24.s64 = -2112159744;
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// rlwinm r29,r11,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f1,-13884(r24)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -13884);
	ctx.f1.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f2,-6020(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -6020);
	ctx.f2.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f3,-6024(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -6024);
	ctx.f3.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f4,-6028(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -6028);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,-6032(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -6032);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,-6040(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6040);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,-6036(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6036);
	ctx.f7.f64 = double(temp.f32);
loc_82D41058:
	// mulli r10,r9,12
	ctx.r10.s64 = ctx.r9.s64 * 12;
	// lfs f0,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f9,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f31,f9,f6
	ctx.f31.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f30,f9,f7
	ctx.f30.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// rlwinm r28,r8,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r27,r8,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r26,r9,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r25,r7,12
	ctx.r25.s64 = ctx.r7.s64 * 12;
	// lfsx f10,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f12,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f29,f10,f6
	ctx.f29.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// lfsx f11,r27,r5
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r5.u32);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f23,f12,f2,f0
	ctx.f23.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 + ctx.f0.f64));
	// fmsubs f31,f10,f7,f31
	ctx.f31.f64 = double(float(ctx.f10.f64 * ctx.f7.f64 - ctx.f31.f64));
	// lfsx f8,r26,r6
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r6.u32);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f10,f10,f5,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f5.f64 + ctx.f30.f64));
	// fmuls f30,f12,f3
	ctx.f30.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fmuls f27,f11,f3
	ctx.f27.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// mulli r11,r8,12
	ctx.r11.s64 = ctx.r8.s64 * 12;
	// fadds f24,f11,f12
	ctx.f24.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// fmadds f25,f11,f2,f0
	ctx.f25.f64 = double(float(ctx.f11.f64 * ctx.f2.f64 + ctx.f0.f64));
	// fmadds f29,f8,f7,f29
	ctx.f29.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 + ctx.f29.f64));
	// lfsx f13,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f28,f13,f3
	ctx.f28.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fnmadds f30,f13,f4,f30
	ctx.f30.f64 = double(float(-(ctx.f13.f64 * ctx.f4.f64 + ctx.f30.f64)));
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fmadds f26,f13,f2,f0
	ctx.f26.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 + ctx.f0.f64));
	// add r5,r29,r5
	ctx.r5.u64 = ctx.r29.u64 + ctx.r5.u64;
	// fnmadds f27,f12,f4,f27
	ctx.f27.f64 = double(float(-(ctx.f12.f64 * ctx.f4.f64 + ctx.f27.f64)));
	// add r6,r29,r6
	ctx.r6.u64 = ctx.r29.u64 + ctx.r6.u64;
	// fnmsubs f12,f8,f5,f31
	ctx.f12.f64 = double(float(-(ctx.f8.f64 * ctx.f5.f64 - ctx.f31.f64)));
	// fadds f31,f24,f13
	ctx.f31.f64 = double(float(ctx.f24.f64 + ctx.f13.f64));
	// fmadds f9,f9,f5,f29
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f5.f64 + ctx.f29.f64));
	// fnmadds f28,f11,f4,f28
	ctx.f28.f64 = double(float(-(ctx.f11.f64 * ctx.f4.f64 + ctx.f28.f64)));
	// fnmsubs f11,f8,f6,f10
	ctx.f11.f64 = double(float(-(ctx.f8.f64 * ctx.f6.f64 - ctx.f10.f64)));
	// fadds f10,f30,f25
	ctx.f10.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// fadds f13,f27,f26
	ctx.f13.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// fmadds f0,f31,f1,f0
	ctx.f0.f64 = double(float(ctx.f31.f64 * ctx.f1.f64 + ctx.f0.f64));
	// fadds f8,f28,f23
	ctx.f8.f64 = double(float(ctx.f28.f64 + ctx.f23.f64));
	// fsubs f31,f10,f12
	ctx.f31.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// stfsx f31,r11,r3
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f12,f13,f11
	ctx.f12.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// stfsx f13,r11,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fadds f13,f8,f9
	ctx.f13.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// stfsx f13,r25,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fsubs f13,f8,f9
	ctx.f13.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// stfs f13,0(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfs f0,0(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lwz r11,3532(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 3532);
	// add r4,r30,r4
	ctx.r4.u64 = ctx.r30.u64 + ctx.r4.u64;
	// add r3,r30,r3
	ctx.r3.u64 = ctx.r30.u64 + ctx.r3.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d41058
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D41058;
loc_82D41150:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f50
	ctx.lr = 0x82D41158;
	__restfpr_23(ctx, base);
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D41160"))) PPC_WEAK_FUNC(sub_82D41160);
PPC_FUNC_IMPL(__imp__sub_82D41160) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-3976
	ctx.r5.s64 = ctx.r11.s64 + -3976;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,4080
	ctx.r4.s64 = ctx.r11.s64 + 4080;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D41178"))) PPC_WEAK_FUNC(sub_82D41178);
PPC_FUNC_IMPL(__imp__sub_82D41178) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82D41180;
	__savegprlr_25(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d41260
	if (!ctx.cr6.gt) goto loc_82D41260;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r10,-32229
	ctx.r10.s64 = -2112159744;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f5,-13884(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -13884);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,-6320(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6320);
	ctx.f6.f64 = double(temp.f32);
loc_82D411B0:
	// mulli r11,r8,12
	ctx.r11.s64 = ctx.r8.s64 * 12;
	// lfs f0,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r28,r8,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f13,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f13.f64 = double(temp.f32);
	// fadds f8,f13,f0
	ctx.f8.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// rlwinm r27,r8,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r26,r9,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r25,r9,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f12,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f11,r27,r5
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r5.u32);
	ctx.f11.f64 = double(temp.f32);
	// add r5,r30,r5
	ctx.r5.u64 = ctx.r30.u64 + ctx.r5.u64;
	// lfsx f10,r26,r6
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r6.u32);
	ctx.f10.f64 = double(temp.f32);
	// fadds f13,f11,f12
	ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// lfsx f9,r25,r6
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r6.u32);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// fsubs f11,f10,f9
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// add r6,r30,r6
	ctx.r6.u64 = ctx.r30.u64 + ctx.r6.u64;
	// fadds f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f9,f8,f13
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f13.f64));
	// fsubs f7,f0,f12
	ctx.f7.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fmuls f11,f11,f6
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// fmuls f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// fmadds f0,f12,f5,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f5.f64 + ctx.f0.f64));
	// stfsx f0,r11,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fmadds f0,f13,f5,f8
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f5.f64 + ctx.f8.f64));
	// stfs f0,0(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f0,f9,f11
	ctx.f0.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// stfsx f0,r10,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f9,f11
	ctx.f0.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// stfsx f0,r11,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fsubs f0,f7,f10
	ctx.f0.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// stfs f0,0(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f0,f7,f10
	ctx.f0.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// stfsx f0,r10,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,3532(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3532);
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d411b0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D411B0;
loc_82D41260:
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D41268"))) PPC_WEAK_FUNC(sub_82D41268);
PPC_FUNC_IMPL(__imp__sub_82D41268) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-3928
	ctx.r5.s64 = ctx.r11.s64 + -3928;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,4472
	ctx.r4.s64 = ctx.r11.s64 + 4472;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D41280"))) PPC_WEAK_FUNC(sub_82D41280);
PPC_FUNC_IMPL(__imp__sub_82D41280) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D41288;
	__savegprlr_26(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d41370
	if (!ctx.cr6.gt) goto loc_82D41370;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r26,-32229
	ctx.r26.s64 = -2112159744;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r28,-32255
	ctx.r28.s64 = -2113863680;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f4,-13884(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -13884);
	ctx.f4.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f5,-6336(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -6336);
	ctx.f5.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f6,-28552(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -28552);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,-6344(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -6344);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,-6340(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6340);
	ctx.f8.f64 = double(temp.f32);
loc_82D412D0:
	// rlwinm r29,r8,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r28,r8,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r26,r9,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r27,r9,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f13,r29,r5
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r5.u32);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r29,r7,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f12,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f12.f64 = double(temp.f32);
	// add r5,r31,r5
	ctx.r5.u64 = ctx.r31.u64 + ctx.r5.u64;
	// lfsx f10,r26,r6
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r6.u32);
	ctx.f10.f64 = double(temp.f32);
	// fadds f9,f12,f13
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfsx f11,r27,r6
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r6.u32);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f10,f8
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// add r6,r31,r6
	ctx.r6.u64 = ctx.r31.u64 + ctx.r6.u64;
	// fmuls f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// fmuls f13,f13,f5
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// fmadds f12,f11,f7,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f7.f64 + ctx.f12.f64));
	// fmsubs f11,f11,f8,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 - ctx.f10.f64));
	// fnmsubs f10,f9,f6,f0
	ctx.f10.f64 = double(float(-(ctx.f9.f64 * ctx.f6.f64 - ctx.f0.f64)));
	// fmadds f0,f9,f4,f0
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f4.f64 + ctx.f0.f64));
	// stfs f0,0(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f0,f13,f10
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f10.f64));
	// fsubs f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 - ctx.f13.f64));
	// fsubs f10,f0,f12
	ctx.f10.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// stfs f10,0(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
	// stfsx f0,r29,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fsubs f0,f13,f11
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// stfsx f0,r11,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f13,f11
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
	// stfsx f0,r11,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,3532(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d412d0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D412D0;
loc_82D41370:
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D41378"))) PPC_WEAK_FUNC(sub_82D41378);
PPC_FUNC_IMPL(__imp__sub_82D41378) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-3880
	ctx.r5.s64 = ctx.r11.s64 + -3880;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,4736
	ctx.r4.s64 = ctx.r11.s64 + 4736;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D41390"))) PPC_WEAK_FUNC(sub_82D41390);
PPC_FUNC_IMPL(__imp__sub_82D41390) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82D41398;
	__savegprlr_27(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d41434
	if (!ctx.cr6.gt) goto loc_82D41434;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f9,-13884(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f9.f64 = double(temp.f32);
loc_82D413C0:
	// rlwinm r29,r8,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f0,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r28,r8,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r27,r9,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f13,r29,r5
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r5.u32);
	ctx.f13.f64 = double(temp.f32);
	// lfsx f12,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f12.f64 = double(temp.f32);
	// fadds f10,f13,f0
	ctx.f10.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// lfsx f11,r27,r6
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r6.u32);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f12,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// add r5,r31,r5
	ctx.r5.u64 = ctx.r31.u64 + ctx.r5.u64;
	// fmuls f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// add r6,r31,r6
	ctx.r6.u64 = ctx.r31.u64 + ctx.r6.u64;
	// fsubs f13,f10,f12
	ctx.f13.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// stfsx f13,r11,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f0,f11
	ctx.f13.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// stfsx f13,r11,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fadds f13,f10,f12
	ctx.f13.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// stfs f13,0(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f11.f64));
	// stfs f0,0(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lwz r11,3532(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d413c0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D413C0;
loc_82D41434:
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D41438"))) PPC_WEAK_FUNC(sub_82D41438);
PPC_FUNC_IMPL(__imp__sub_82D41438) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-3832
	ctx.r5.s64 = ctx.r11.s64 + -3832;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,5008
	ctx.r4.s64 = ctx.r11.s64 + 5008;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D41450"))) PPC_WEAK_FUNC(sub_82D41450);
PPC_FUNC_IMPL(__imp__sub_82D41450) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D41458;
	__savegprlr_28(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d414e4
	if (!ctx.cr6.gt) goto loc_82D414E4;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r29,-32229
	ctx.r29.s64 = -2112159744;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f9,-13884(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -13884);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-6320(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6320);
	ctx.f10.f64 = double(temp.f32);
loc_82D41488:
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r29,r9,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r28,r7,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f13,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f13.f64 = double(temp.f32);
	// add r5,r31,r5
	ctx.r5.u64 = ctx.r31.u64 + ctx.r5.u64;
	// lfsx f12,r29,r6
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r6.u32);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f11,f0,f13
	ctx.f11.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// fmuls f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// add r6,r31,r6
	ctx.r6.u64 = ctx.r31.u64 + ctx.r6.u64;
	// fmadds f0,f13,f9,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 + ctx.f0.f64));
	// stfs f0,0(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f0,f11,f12
	ctx.f0.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// stfsx f0,r28,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fsubs f0,f11,f12
	ctx.f0.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// stfs f0,0(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lwz r11,3532(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d41488
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D41488;
loc_82D414E4:
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D414E8"))) PPC_WEAK_FUNC(sub_82D414E8);
PPC_FUNC_IMPL(__imp__sub_82D414E8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-3784
	ctx.r5.s64 = ctx.r11.s64 + -3784;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,5200
	ctx.r4.s64 = ctx.r11.s64 + 5200;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D41500"))) PPC_WEAK_FUNC(sub_82D41500);
PPC_FUNC_IMPL(__imp__sub_82D41500) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D41508;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D41510;
	__savefpr_14(ctx, base);
	// rlwinm r11,r9,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// addi r11,r11,-32
	ctx.r11.s64 = ctx.r11.s64 + -32;
	// bge cr6,0x82d42e4c
	if (!ctx.cr6.lt) goto loc_82D42E4C;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// rlwinm r19,r7,2,0,29
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// stw r10,-324(r1)
	PPC_STORE_U32(ctx.r1.u32 + -324, ctx.r10.u32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lis r30,-32236
	ctx.r30.s64 = -2112618496;
	// lfs f29,-3640(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -3640);
	ctx.f29.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lfs f30,-3644(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -3644);
	ctx.f30.f64 = double(temp.f32);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lfs f31,-3648(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -3648);
	ctx.f31.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfs f1,-3652(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -3652);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,140(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 140);
	ctx.f2.f64 = double(temp.f32);
	// lfs f10,-3656(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -3656);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,-3660(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -3660);
	ctx.f11.f64 = double(temp.f32);
	// lfs f7,-3664(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -3664);
	ctx.f7.f64 = double(temp.f32);
	// lfs f12,-28552(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28552);
	ctx.f12.f64 = double(temp.f32);
loc_82D4157C:
	// lfs f13,28(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// lfs f5,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f28,f13,f5
	ctx.f28.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// stfs f28,-372(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f6,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f28,f13,f6
	ctx.f28.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// stfs f28,-436(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f0,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// lfs f9,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f16,f0,f6
	ctx.f16.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// lfs f8,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f28,f0,f9
	ctx.f28.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// fmuls f14,f0,f8
	ctx.f14.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f4,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f27,f4,f6
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// fmuls f26,f3,f5
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// fmuls f15,f0,f3
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// fmuls f24,f3,f6
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// fmuls f25,f4,f5
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// fmuls f23,f8,f5
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// fmuls f18,f9,f6
	ctx.f18.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f22,f8,f4
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fmadds f28,f13,f8,f28
	ctx.f28.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 + ctx.f28.f64));
	// stfs f28,-420(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// fmsubs f28,f13,f9,f14
	ctx.f28.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 - ctx.f14.f64));
	// stfs f28,-408(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// fmuls f19,f9,f3
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// fmuls f21,f8,f6
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// fmuls f17,f9,f5
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fadds f28,f26,f27
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// fadds f26,f24,f25
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fsubs f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// fsubs f24,f18,f23
	ctx.f24.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// fmuls f20,f9,f4
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// fadds f23,f22,f19
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// fadds f22,f21,f17
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// stfs f22,-568(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// fmuls f21,f8,f3
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfs f21,-508(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f14,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,-432(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f14,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,-396(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fmuls f16,f0,f5
	ctx.f16.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// lfs f14,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,-464(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fmuls f14,f13,f4
	ctx.f14.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// stfs f14,-572(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,-564(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// lfs f14,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,-456(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,-576(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// fmuls f15,f13,f3
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fmuls f16,f0,f4
	ctx.f16.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// fsubs f14,f16,f15
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f14,-356(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,-504(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fmuls f16,f24,f0
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f15,f22,f0
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmuls f14,f21,f0
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fmadds f22,f22,f13,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f22,-536(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fmsubs f22,f24,f13,f15
	ctx.f22.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f22,-440(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fmadds f22,f23,f13,f14
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f22,-500(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// fmuls f22,f0,f28
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// fmuls f16,f13,f25
	ctx.f16.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// fadds f15,f16,f22
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f15,-472(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fmuls f14,f8,f3
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// rlwinm r10,r8,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f22,-444(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fmuls f16,f0,f25
	ctx.f16.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmuls f22,f13,f28
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// fadds f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// stfs f20,-548(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// fmuls f14,f8,f4
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fsubs f15,f22,f16
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f15,-556(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f22,-368(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fmuls f16,f13,f26
	ctx.f16.f64 = double(float(ctx.f13.f64 * ctx.f26.f64));
	// fmuls f22,f0,f27
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f27.f64));
	// fsubs f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f19,-532(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fmuls f14,f8,f5
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// fsubs f15,f22,f16
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f15,-348(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f22,-404(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// fmuls f16,f0,f26
	ctx.f16.f64 = double(float(ctx.f0.f64 * ctx.f26.f64));
	// fmuls f22,f13,f27
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f27.f64));
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,-416(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// fmuls f14,f8,f6
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// fadds f15,f16,f22
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f15,-364(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fsubs f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f22,-496(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fmuls f16,f8,f26
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f26.f64));
	// fmuls f22,f9,f27
	ctx.f22.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,-400(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fmuls f14,f23,f0
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f15,f8,f27
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmsubs f21,f21,f13,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f21,-492(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// fsubs f21,f22,f16
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f21,-468(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fmuls f21,f9,f26
	ctx.f21.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f22,-388(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fmuls f16,f8,f25
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// fmuls f14,f17,f0
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fadds f22,f21,f15
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// fsubs f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// stfs f21,-484(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fmuls f21,f9,f28
	ctx.f21.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fadds f15,f16,f21
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// stfs f15,-452(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fsubs f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfs f21,-384(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fmuls f16,f9,f25
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// fmuls f21,f8,f28
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// fsubs f15,f21,f16
	ctx.f15.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfs f15,-372(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// stfs f21,-436(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fmuls f21,f20,f0
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmuls f16,f19,f0
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fmuls f15,f18,f0
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fmadds f21,f19,f13,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f21.f64));
	// stfs f21,-360(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fmsubs f21,f20,f13,f16
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f21,-488(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// fmadds f21,f17,f13,f15
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f21,-428(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fmsubs f21,f18,f13,f14
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f21,-392(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfsx f21,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,-560(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfsx f21,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f20,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f21,-412(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f21,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f21.f64 = double(temp.f32);
	// stfs f20,-516(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// fmuls f21,f21,f0
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// lfsx f20,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-424(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f20,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f21,f22,f13,f21
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f21.f64));
	// fmuls f19,f20,f0
	ctx.f19.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f20,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f20,f0
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f20,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f20,f0
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f20,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f20,f0
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f20,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f14,f20,f0
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f20,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// stfs f20,-572(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// stfs f21,-552(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// fmuls f18,f22,f0
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// lfs f21,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f21.f64 = double(temp.f32);
	// mulli r9,r8,48
	ctx.r9.s64 = ctx.r8.s64 * 48;
	// fmr f20,f21
	ctx.f20.f64 = ctx.f21.f64;
	// rlwinm r7,r8,5,0,26
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fmsubs f21,f20,f13,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f19.f64));
	// stfs f21,-448(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f21,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f19,f21,f13,f18
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f19,-528(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f19,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f18,f19,f13,f17
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f18,-460(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f18,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f13,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f18,-544(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f18,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f13,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f18,-388(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f18,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f17,f18,f13,f14
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f15,-468(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f15,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,-452(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f14,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-484(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// stfs f17,-480(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f17,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f17,f13,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f17,-520(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f16,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,-572(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,-476(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f16,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,-540(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f17,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,-560(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfs f16,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f16,f8
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f8.f64));
	// lfs f16,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,-424(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f16,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f16,f9
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// lfs f16,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,-524(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f16,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f9,f16,f9,f15
	ctx.f9.f64 = double(float(ctx.f16.f64 * ctx.f9.f64 - ctx.f15.f64));
	// stfs f9,-452(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fmadds f9,f16,f8,f14
	ctx.f9.f64 = double(float(ctx.f16.f64 * ctx.f8.f64 + ctx.f14.f64));
	// lfs f16,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f14,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f16,f5
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f5.f64));
	// stfs f14,-572(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// fmuls f14,f16,f6
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// lfsx f16,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-560(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfsx f16,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-352(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfsx f16,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-376(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfsx f16,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-344(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfsx f16,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-340(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f16,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f16.f64 = double(temp.f32);
	// stfs f9,-516(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// fmadds f5,f16,f5,f14
	ctx.f5.f64 = double(float(ctx.f16.f64 * ctx.f5.f64 + ctx.f14.f64));
	// lfsx f8,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f6,f16,f6,f15
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 - ctx.f15.f64));
	// lfsx f9,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// stfs f5,-484(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fadds f5,f8,f9
	ctx.f5.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// stfs f9,-468(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f8,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f8.f64 = double(temp.f32);
	// lfs f16,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f9,f8,f16
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f16.f64));
	// fadds f8,f16,f8
	ctx.f8.f64 = double(float(ctx.f16.f64 + ctx.f8.f64));
	// stfs f8,-512(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f8,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f8.f64 = double(temp.f32);
	// lfs f16,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f16,f8
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f8.f64));
	// stfs f15,-560(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// fsubs f8,f8,f16
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f16.f64));
	// stfs f8,-424(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f8,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f8.f64 = double(temp.f32);
	// lfs f16,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f8,f16
	ctx.f14.f64 = double(float(ctx.f8.f64 - ctx.f16.f64));
	// stfs f14,-572(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// fadds f8,f16,f8
	ctx.f8.f64 = double(float(ctx.f16.f64 + ctx.f8.f64));
	// stfs f8,-412(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f8,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f8,f9,f8
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// lfs f16,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f9,f16
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f16.f64));
	// lfs f9,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f15,f15,f9
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f9.f64));
	// fmuls f14,f14,f9
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f9.f64));
	// lfs f9,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f9,f5,f9,f8
	ctx.f9.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 - ctx.f8.f64));
	// stfs f9,-472(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f8,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f9,f8
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// lfs f9,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f5,f5,f9,f16
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 + ctx.f16.f64));
	// lfs f9,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f9.f64 = double(temp.f32);
	// lfs f16,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f9,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f9.f64 + ctx.f15.f64));
	// stfs f16,-556(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f16,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f9,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f9.f64 - ctx.f14.f64));
	// lfs f15,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f15.f64 = double(temp.f32);
	// lfs f9,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f9.f64 = double(temp.f32);
	// stfs f5,-376(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// stfs f16,-572(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// fmsubs f9,f15,f9,f8
	ctx.f9.f64 = double(float(ctx.f15.f64 * ctx.f9.f64 - ctx.f8.f64));
	// lfs f8,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f8.f64 = double(temp.f32);
	// lfs f14,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f8,f8,f14
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f14.f64));
	// lfs f14,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f5,f5,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f14.f64));
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// stfs f5,-560(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,-536(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfs f16,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f9,f16
	ctx.f14.f64 = double(float(ctx.f9.f64 + ctx.f16.f64));
	// lfs f5,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f5,f6
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fsubs f9,f16,f9
	ctx.f9.f64 = double(float(ctx.f16.f64 - ctx.f9.f64));
	// stfs f9,-352(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fsubs f9,f5,f8
	ctx.f9.f64 = double(float(ctx.f5.f64 - ctx.f8.f64));
	// stfs f9,-336(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f9,f8,f5
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// stfs f9,-320(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f9,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f9.f64 = double(temp.f32);
	// rlwinm r31,r8,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f5,f15,f9
	ctx.f5.f64 = double(float(ctx.f15.f64 * ctx.f9.f64));
	// stfs f14,-440(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f8,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f8.f64 = double(temp.f32);
	// mulli r30,r8,24
	ctx.r30.s64 = ctx.r8.s64 * 24;
	// lfs f9,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f9.f64 = double(temp.f32);
	// lfs f14,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f16,f8,f9
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// fmuls f14,f8,f14
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f14.f64));
	// lfs f9,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f9.f64 = double(temp.f32);
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// lfs f8,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f15,f15,f9
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f9.f64));
	// fmuls f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// stfs f9,-564(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// lfs f8,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// stfs f8,-556(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f8,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f8.f64 = double(temp.f32);
	// lfs f6,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f6.f64 = double(temp.f32);
	// fadds f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfs f8,-540(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f8,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f8.f64 = double(temp.f32);
	// lfs f6,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f9,f8,f6,f5
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f6.f64 + ctx.f5.f64));
	// lfs f6,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f6.f64 = double(temp.f32);
	// lfs f8,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f8.f64 = double(temp.f32);
	// fadds f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfs f8,-524(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f6,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f6.f64 = double(temp.f32);
	// lfs f8,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f8.f64 = double(temp.f32);
	// fadds f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfs f8,-520(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f6,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f6.f64 = double(temp.f32);
	// lfs f8,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f8,f6,f8,f16
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64 - ctx.f16.f64));
	// lfs f5,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f6,f6,f5,f15
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f5.f64 - ctx.f15.f64));
	// lfs f16,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f16.f64 = double(temp.f32);
	// lfs f5,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f5,f16,f5,f14
	ctx.f5.f64 = double(float(ctx.f16.f64 * ctx.f5.f64 + ctx.f14.f64));
	// lfs f15,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f16,f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 + ctx.f14.f64));
	// lfs f15,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,-332(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f14,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,-312(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f15,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,-412(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fadds f14,f9,f17
	ctx.f14.f64 = double(float(ctx.f9.f64 + ctx.f17.f64));
	// fsubs f9,f17,f9
	ctx.f9.f64 = double(float(ctx.f17.f64 - ctx.f9.f64));
	// stfs f9,-376(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f9,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f9.f64 = double(temp.f32);
	// lfs f17,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f9
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f9.f64));
	// stfs f17,-452(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f17,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f9,f17,f9
	ctx.f9.f64 = double(float(ctx.f17.f64 - ctx.f9.f64));
	// fadds f17,f6,f8
	ctx.f17.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// fsubs f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f8,-424(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// fadds f8,f16,f5
	ctx.f8.f64 = double(float(ctx.f16.f64 + ctx.f5.f64));
	// stfs f8,-484(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fsubs f8,f5,f16
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f16.f64));
	// lfsx f16,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r29,r8,40
	ctx.r29.s64 = ctx.r8.s64 * 40;
	// stfs f16,-564(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// mulli r28,r8,56
	ctx.r28.s64 = ctx.r8.s64 * 56;
	// lfsx f16,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-540(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfsx f16,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-524(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfsx f16,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-560(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfsx f16,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-572(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// stfs f8,-344(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfsx f6,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f8,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f16,f8,f6
	ctx.f16.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// lfsx f5,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f8,-536(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfs f8,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f8.f64 = double(temp.f32);
	// fadds f6,f8,f5
	ctx.f6.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// stfs f6,-512(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fsubs f8,f5,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f8.f64));
	// stfs f8,-504(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f8,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f8.f64 = double(temp.f32);
	// lfs f5,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f6,f8,f5
	ctx.f6.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// stfs f6,-540(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// fadds f8,f5,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// stfs f8,-524(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f8,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f8.f64 = double(temp.f32);
	// lfs f6,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f6.f64 = double(temp.f32);
	// fadds f5,f6,f8
	ctx.f5.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f5,-476(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fsubs f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f8,-564(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// lfs f5,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// lfs f8,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f8,f8,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f26.f64));
	// lfs f6,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f19
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// fmuls f26,f16,f26
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f26.f64));
	// lfs f19,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f23
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// fmsubs f8,f16,f27,f8
	ctx.f8.f64 = double(float(ctx.f16.f64 * ctx.f27.f64 - ctx.f8.f64));
	// lfs f16,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f6,f16,f20,f6
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f20.f64 - ctx.f6.f64));
	// lfs f16,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f5,f16,f20,f5
	ctx.f5.f64 = double(float(ctx.f16.f64 * ctx.f20.f64 + ctx.f5.f64));
	// stfs f5,-472(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f5,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f5,f5,f27,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f27.f64 + ctx.f26.f64));
	// stfs f5,-516(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f5,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f20,f5,f21
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f21.f64));
	// lfs f27,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f16,f5,f22
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f22.f64));
	// lfs f26,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f27,f23
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// fmadds f5,f26,f22,f20
	ctx.f5.f64 = double(float(ctx.f26.f64 * ctx.f22.f64 + ctx.f20.f64));
	// stfs f5,-400(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f5,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f27,f27,f5,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 - ctx.f19.f64));
	// stfs f27,-416(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// fmsubs f27,f26,f21,f16
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f21.f64 - ctx.f16.f64));
	// stfs f27,-520(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f27,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f5,f27,f5,f23
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f23.f64));
	// stfs f5,-476(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfsx f5,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f27,r29,r6
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r6.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f16,f27,f5
	ctx.f16.f64 = double(float(ctx.f27.f64 + ctx.f5.f64));
	// lfsx f26,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f23,r29,r5
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r5.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f5,f5,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f27.f64));
	// lfsx f22,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f21,r28,r6
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f20,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f19,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f16,-540(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// fsubs f27,f26,f23
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// rlwinm r27,r8,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f26,-536(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fadds f26,f21,f22
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f26,-504(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fsubs f26,f22,f21
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f26,-512(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fsubs f22,f20,f19
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfs f22,-508(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fadds f21,f19,f20
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfs f21,-564(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// lfs f26,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f26.f64 = double(temp.f32);
	// mulli r26,r8,52
	ctx.r26.s64 = ctx.r8.s64 * 52;
	// fmuls f20,f16,f26
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f26.f64));
	// lfs f16,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f16.f64 = double(temp.f32);
	// lfs f23,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f26,f27,f26
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// fmuls f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// lfs f16,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f16.f64));
	// lfs f16,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f27,f27,f16,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f16.f64 + ctx.f20.f64));
	// stfs f27,-556(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f27,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f27.f64 = double(temp.f32);
	// lfs f19,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f23
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// fmuls f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// lfs f20,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f27.f64));
	// lfs f27,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f27.f64 = double(temp.f32);
	// lfs f16,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f27
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f27.f64));
	// lfs f27,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f5,f5,f27,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f27.f64 - ctx.f19.f64));
	// lfs f19,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f27,f19,f27,f23
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f23.f64));
	// lfs f23,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f26,f23,f19,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f19.f64 - ctx.f26.f64));
	// lfs f19,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f19.f64 = double(temp.f32);
	// lfs f23,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f19,f23,f22
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f23.f64 + ctx.f22.f64));
	// lfs f19,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f19,f22,f21
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 - ctx.f21.f64));
	// lfs f19,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f21,f19,f21,f20
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f21.f64 - ctx.f20.f64));
	// lfs f19,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f19,f20,f16
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f20.f64 + ctx.f16.f64));
	// lfs f16,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// fadds f16,f5,f8
	ctx.f16.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// stfs f16,-512(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f16,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f27,f16
	ctx.f16.f64 = double(float(ctx.f27.f64 + ctx.f16.f64));
	// stfs f16,-504(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f16,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f23,f16
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f16.f64));
	// stfs f16,-576(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// lfs f16,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f22,f16
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// stfs f16,-468(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f16,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// lfs f16,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f21,f16
	ctx.f16.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfs f16,-544(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f16,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f20,f16
	ctx.f16.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// stfs f16,-536(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfs f16,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f19
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfs f16,-368(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f16,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 - ctx.f19.f64));
	// lfs f16,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// lfs f16,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f8,f8,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// fsubs f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// lfs f5,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f5.f64 = double(temp.f32);
	// fadds f16,f26,f6
	ctx.f16.f64 = double(float(ctx.f26.f64 + ctx.f6.f64));
	// stfs f16,-488(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f16,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f6,f6,f26
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f26.f64));
	// fadds f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f16.f64));
	// stfs f21,-480(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f26,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f5,f5,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f27.f64));
	// lfs f16,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f16.f64 = double(temp.f32);
	// fadds f27,f23,f26
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// lfs f21,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f26,f26,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// fsubs f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// lfsx f16,r26,r5
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-544(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// mulli r25,r8,36
	ctx.r25.s64 = ctx.r8.s64 * 36;
	// fadds f23,f22,f20
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f23,-572(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// fsubs f23,f20,f22
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// stfs f23,-388(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfsx f16,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-576(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// lfsx f16,r25,r6
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-444(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f23,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f22.f64 = double(temp.f32);
	// fadds f20,f22,f23
	ctx.f20.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f20,-360(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fsubs f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfs f23,-380(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fsubs f23,f21,f6
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f6.f64));
	// stfs f23,-416(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// fadds f6,f6,f21
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f21.f64));
	// stfs f6,-400(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fsubs f6,f8,f5
	ctx.f6.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// stfs f6,-560(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// fadds f8,f5,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// stfs f8,-340(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfsx f8,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f6,r27,r6
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r6.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f16,f8,f6
	ctx.f16.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f16,-480(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fadds f16,f6,f8
	ctx.f16.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// lfsx f23,r27,r5
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r5.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f5,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// stfs f16,-488(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// fadds f8,f23,f5
	ctx.f8.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// fsubs f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f23.f64));
	// stfs f5,-508(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfsx f22,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f21,r26,r6
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// fadds f6,f21,f22
	ctx.f6.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f6,-540(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfsx f20,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f23,f22,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f6,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f6.f64 = double(temp.f32);
	// fadds f22,f6,f20
	ctx.f22.f64 = double(float(ctx.f6.f64 + ctx.f20.f64));
	// stfs f23,-564(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// fsubs f6,f20,f6
	ctx.f6.f64 = double(float(ctx.f20.f64 - ctx.f6.f64));
	// stfs f22,-524(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// fmuls f20,f16,f3
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// fmuls f16,f8,f28
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// fmuls f21,f8,f25
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// lfs f8,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// fmuls f23,f23,f8
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fmuls f22,f22,f8
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// fmuls f3,f6,f13
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// stfs f3,-464(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// stfs f6,-544(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f8,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f8.f64 = double(temp.f32);
	// fmr f3,f8
	ctx.f3.f64 = ctx.f8.f64;
	// fmsubs f8,f3,f28,f21
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f28.f64 - ctx.f21.f64));
	// lfs f28,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f6,f28,f4,f5
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f4.f64 - ctx.f5.f64));
	// lfs f5,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f5.f64 = double(temp.f32);
	// mulli r24,r8,20
	ctx.r24.s64 = ctx.r8.s64 * 20;
	// fmadds f5,f5,f4,f20
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f4.f64 + ctx.f20.f64));
	// fmadds f4,f3,f25,f16
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f25.f64 + ctx.f16.f64));
	// lfs f28,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f28.f64 = double(temp.f32);
	// lfs f3,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f3,f3,f28,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64 - ctx.f22.f64));
	// lfs f22,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f22.f64 = double(temp.f32);
	// lfs f25,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f16,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f0,f25,f0,f22
	ctx.f0.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 - ctx.f22.f64));
	// stfs f16,-432(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfsx f16,r24,r6
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-464(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfsx f16,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-480(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f22,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f16,r24,r5
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f13,f25,f13,f22
	ctx.f13.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f22.f64));
	// stfs f16,-544(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f25,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f28,f25,f28,f23
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f28.f64 + ctx.f23.f64));
	// lfs f22,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f25,f23,f22
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfs f22,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f22.f64 = double(temp.f32);
	// stfs f23,-488(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// fmuls f21,f23,f22
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// lfs f23,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f20,f25,f23
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f23.f64));
	// lfsx f22,r25,r5
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r5.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f23,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f16,f22,f23
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f16,-444(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f23,-576(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// lfs f23,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f23,f22
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f16,-464(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f23,-508(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f23,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f22.f64 = double(temp.f32);
	// fadds f16,f22,f23
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f16,-396(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f23,-432(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f23,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// lfs f16,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f22.f64));
	// lfs f16,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f25,f25,f16,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f16.f64 - ctx.f23.f64));
	// lfs f23,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f23.f64 = double(temp.f32);
	// lfs f16,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f22,f16,f23,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f23.f64 - ctx.f22.f64));
	// stfs f22,-408(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f22,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f23,f22,f23,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 + ctx.f21.f64));
	// stfs f23,-392(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f22,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f23,f22,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 + ctx.f20.f64));
	// stfs f23,-420(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f23,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f22,f23
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// lfs f22,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f22,f20
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// fmuls f16,f22,f16
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// lfs f22,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// fmsubs f22,f22,f24,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f24.f64 - ctx.f21.f64));
	// stfs f22,-576(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// lfs f22,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f21.f64 = double(temp.f32);
	// stfs f23,-568(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// fmsubs f23,f22,f21,f20
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f21.f64 - ctx.f20.f64));
	// lfs f21,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f21.f64 = double(temp.f32);
	// mulli r22,r8,60
	ctx.r22.s64 = ctx.r8.s64 * 60;
	// fmadds f22,f22,f21,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f21.f64 + ctx.f16.f64));
	// lfs f16,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f5
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f5.f64));
	// stfs f16,-428(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f16,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f16.f64 = double(temp.f32);
	// mulli r21,r8,44
	ctx.r21.s64 = ctx.r8.s64 * 44;
	// fsubs f16,f4,f16
	ctx.f16.f64 = double(float(ctx.f4.f64 - ctx.f16.f64));
	// lfs f21,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f21.f64 = double(temp.f32);
	// mulli r20,r8,28
	ctx.r20.s64 = ctx.r8.s64 * 28;
	// add r18,r22,r4
	ctx.r18.u64 = ctx.r22.u64 + ctx.r4.u64;
	// add r17,r22,r3
	ctx.r17.u64 = ctx.r22.u64 + ctx.r3.u64;
	// add r16,r21,r4
	ctx.r16.u64 = ctx.r21.u64 + ctx.r4.u64;
	// add r23,r20,r4
	ctx.r23.u64 = ctx.r20.u64 + ctx.r4.u64;
	// add r14,r20,r3
	ctx.r14.u64 = ctx.r20.u64 + ctx.r3.u64;
	// add r15,r21,r3
	ctx.r15.u64 = ctx.r21.u64 + ctx.r3.u64;
	// stw r23,-316(r1)
	PPC_STORE_U32(ctx.r1.u32 + -316, ctx.r23.u32);
	// stw r14,-308(r1)
	PPC_STORE_U32(ctx.r1.u32 + -308, ctx.r14.u32);
	// lfs f20,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f20.f64 = double(temp.f32);
	// stfs f16,-568(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// fmadds f24,f21,f24,f20
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f24.f64 + ctx.f20.f64));
	// lfs f16,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f16.f64 = double(temp.f32);
	// fadds f21,f25,f8
	ctx.f21.f64 = double(float(ctx.f25.f64 + ctx.f8.f64));
	// fsubs f5,f16,f5
	ctx.f5.f64 = double(float(ctx.f16.f64 - ctx.f5.f64));
	// lfs f20,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f20,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f6.f64));
	// fsubs f6,f6,f16
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f16.f64));
	// lfs f16,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f16.f64 = double(temp.f32);
	// fadds f4,f16,f4
	ctx.f4.f64 = double(float(ctx.f16.f64 + ctx.f4.f64));
	// fsubs f16,f0,f23
	ctx.f16.f64 = double(float(ctx.f0.f64 - ctx.f23.f64));
	// fsubs f8,f8,f25
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f25.f64));
	// lfs f25,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f25.f64 = double(temp.f32);
	// fadds f0,f23,f0
	ctx.f0.f64 = double(float(ctx.f23.f64 + ctx.f0.f64));
	// fadds f23,f22,f13
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f13.f64));
	// fsubs f13,f22,f13
	ctx.f13.f64 = double(float(ctx.f22.f64 - ctx.f13.f64));
	// lfs f22,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f25,f25,f3
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f3.f64));
	// fadds f3,f22,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 + ctx.f3.f64));
	// fadds f22,f24,f28
	ctx.f22.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// stfs f22,-540(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// fsubs f28,f24,f28
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f28.f64));
	// fsubs f24,f5,f6
	ctx.f24.f64 = double(float(ctx.f5.f64 - ctx.f6.f64));
	// stfs f24,-472(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fadds f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f5.f64));
	// stfs f6,-556(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f6,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f6.f64 = double(temp.f32);
	// fadds f5,f25,f6
	ctx.f5.f64 = double(float(ctx.f25.f64 + ctx.f6.f64));
	// stfs f5,-524(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// fsubs f6,f6,f25
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f25.f64));
	// stfs f6,-384(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fadds f6,f0,f20
	ctx.f6.f64 = double(float(ctx.f0.f64 + ctx.f20.f64));
	// stfs f6,-408(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f6,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f0,f0,f20
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f20.f64));
	// fadds f5,f23,f6
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f6.f64));
	// stfs f0,-476(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fsubs f6,f23,f6
	ctx.f6.f64 = double(float(ctx.f23.f64 - ctx.f6.f64));
	// stfs f6,-396(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fsubs f6,f21,f3
	ctx.f6.f64 = double(float(ctx.f21.f64 - ctx.f3.f64));
	// stfs f6,-444(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fsubs f6,f4,f22
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f22.f64));
	// stfs f6,-576(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// fsubs f0,f8,f28
	ctx.f0.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// stfs f0,-328(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fadds f6,f13,f16
	ctx.f6.f64 = double(float(ctx.f13.f64 + ctx.f16.f64));
	// stfs f5,-392(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fadds f0,f28,f8
	ctx.f0.f64 = double(float(ctx.f28.f64 + ctx.f8.f64));
	// stfs f6,-516(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// fsubs f13,f16,f13
	ctx.f13.f64 = double(float(ctx.f16.f64 - ctx.f13.f64));
	// stfs f0,-436(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// stfs f13,-520(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f0,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfsx f13,r22,r6
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r6.u32);
	ctx.f13.f64 = double(temp.f32);
	// lfs f8,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f6,r22,r5
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r5.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f28,r21,r6
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r6.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f16,r20,r5
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-568(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// fsubs f16,f0,f13
	ctx.f16.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,-428(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fsubs f0,f8,f6
	ctx.f0.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// lfs f25,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fadds f13,f6,f8
	ctx.f13.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// lfsx f24,r21,r5
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r5.u32);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f8,f5,f28
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f28.f64));
	// stfs f8,-420(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// fadds f8,f28,f5
	ctx.f8.f64 = double(float(ctx.f28.f64 + ctx.f5.f64));
	// lfs f23,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f22,r20,r6
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f5,f24,f25
	ctx.f5.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfs f8,-464(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fsubs f8,f25,f24
	ctx.f8.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// fsubs f6,f23,f22
	ctx.f6.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f6,-480(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fadds f6,f22,f23
	ctx.f6.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f13,-432(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// stfs f6,-488(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f20,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// lfs f24,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f24,f0,f24
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f24.f64));
	// lfs f22,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f23,f0,f23
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// lfs f0,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f0.f64 = double(temp.f32);
	// stfs f5,-544(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f22,f8,f22
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f22.f64));
	// lfs f6,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f6.f64 = double(temp.f32);
	// fadds f28,f6,f20
	ctx.f28.f64 = double(float(ctx.f6.f64 + ctx.f20.f64));
	// stfs f28,-564(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// fsubs f25,f20,f6
	ctx.f25.f64 = double(float(ctx.f20.f64 - ctx.f6.f64));
	// lfs f20,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f8,f20
	ctx.f20.f64 = double(float(ctx.f8.f64 * ctx.f20.f64));
	// lfs f6,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f6.f64 = double(temp.f32);
	// lfs f8,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f13,f13,f6
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fmuls f0,f8,f0
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// lfs f8,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f8.f64 = double(temp.f32);
	// stfs f0,-448(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// fmuls f6,f16,f6
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// stfs f25,-508(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fmuls f8,f28,f8
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// stfs f8,-456(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f28,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f28.f64));
	// lfs f25,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f0,f16,f25,f13
	ctx.f0.f64 = double(float(ctx.f16.f64 * ctx.f25.f64 - ctx.f13.f64));
	// lfs f13,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f13.f64 = double(temp.f32);
	// fmr f8,f13
	ctx.f8.f64 = ctx.f13.f64;
	// lfs f13,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f13.f64 = double(temp.f32);
	// lfs f25,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f25.f64 = double(temp.f32);
	// stfs f28,-568(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// fmsubs f13,f8,f13,f24
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 - ctx.f24.f64));
	// lfs f24,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f8,f8,f25,f23
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f25.f64 + ctx.f23.f64));
	// lfs f25,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f6,f25,f24,f6
	ctx.f6.f64 = double(float(ctx.f25.f64 * ctx.f24.f64 + ctx.f6.f64));
	// lfs f25,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f5,f25,f24,f5
	ctx.f5.f64 = double(float(ctx.f25.f64 * ctx.f24.f64 - ctx.f5.f64));
	// lfs f25,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f28,f25,f24,f22
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f24.f64 - ctx.f22.f64));
	// lfs f24,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f25,f25,f24,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f24.f64 + ctx.f20.f64));
	// lfs f23,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f24.f64 = double(temp.f32);
	// lfs f22,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f24,f24,f23,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f23.f64 + ctx.f22.f64));
	// lfs f22,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f23,f22,f23,f20
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 - ctx.f20.f64));
	// stfs f23,-496(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f23,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f16.f64 = double(temp.f32);
	// fadds f3,f3,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f21.f64));
	// fmsubs f16,f20,f23,f16
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f23.f64 - ctx.f16.f64));
	// stfs f16,-460(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f16,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f16.f64 = double(temp.f32);
	// mulli r23,r8,12
	ctx.r23.s64 = ctx.r8.s64 * 12;
	// fmuls f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f16.f64));
	// lfs f21,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f21.f64 = double(temp.f32);
	// add r14,r23,r3
	ctx.r14.u64 = ctx.r23.u64 + ctx.r3.u64;
	// lfs f16,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f13.f64));
	// stfs f16,-492(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f16,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f22,f16
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// lfs f22,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f0.f64));
	// stfs f22,-528(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f22,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f23,f22,f23,f20
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 + ctx.f20.f64));
	// lfs f22,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f13,f13,f22
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f22.f64));
	// lfs f22,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f0,f0,f22
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f22.f64));
	// lfs f22,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f20,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfs f21,-500(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f20,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f21,-356(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfs f20,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f20,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f16.f64));
	// lfs f20,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f20.f64 = double(temp.f32);
	// fadds f16,f23,f8
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f8.f64));
	// fsubs f8,f23,f8
	ctx.f8.f64 = double(float(ctx.f23.f64 - ctx.f8.f64));
	// stfs f8,-496(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f8,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f23,f22,f8
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f8.f64));
	// stfs f23,-568(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// fadds f8,f8,f22
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f22.f64));
	// stfs f8,-428(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fsubs f8,f6,f21
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f21.f64));
	// stfs f8,-460(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fadds f8,f21,f6
	ctx.f8.f64 = double(float(ctx.f21.f64 + ctx.f6.f64));
	// stfs f8,-404(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfsx f8,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f6,r23,r6
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r6.u32);
	ctx.f6.f64 = double(temp.f32);
	// fadds f21,f6,f8
	ctx.f21.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// lfsx f22,r23,r5
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r5.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f6,f8,f6
	ctx.f6.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// fsubs f8,f23,f22
	ctx.f8.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f8,-552(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfs f8,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f8.f64 = double(temp.f32);
	// stfs f21,-500(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// stfs f6,-448(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// stfs f23,-456(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// fmuls f22,f21,f8
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f8.f64));
	// lfs f21,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f8
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f8.f64));
	// lfs f8,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f23,f23,f8
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// stfs f8,-532(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f6,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f8,f6,f18,f21
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f18.f64 - ctx.f21.f64));
	// lfs f6,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f6,f6,f18,f22
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f18.f64 + ctx.f22.f64));
	// lfs f21,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f23,f21,f22,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f22.f64 - ctx.f23.f64));
	// lfs f21,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f22,f21,f22,f18
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f22.f64 + ctx.f18.f64));
	// fadds f21,f8,f28
	ctx.f21.f64 = double(float(ctx.f8.f64 + ctx.f28.f64));
	// fadds f18,f6,f25
	ctx.f18.f64 = double(float(ctx.f6.f64 + ctx.f25.f64));
	// fsubs f6,f25,f6
	ctx.f6.f64 = double(float(ctx.f25.f64 - ctx.f6.f64));
	// fadds f25,f23,f5
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// fsubs f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// fsubs f28,f22,f24
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f5,f23,f5
	ctx.f5.f64 = double(float(ctx.f23.f64 - ctx.f5.f64));
	// lfs f23,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fadds f22,f18,f16
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f16,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f25,f16
	ctx.f16.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// stfs f16,-548(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f16,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f25,f16,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 - ctx.f25.f64));
	// fadds f16,f6,f13
	ctx.f16.f64 = double(float(ctx.f6.f64 + ctx.f13.f64));
	// fsubs f13,f13,f6
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f6.f64));
	// lfs f6,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f6,f6,f24
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f24.f64));
	// stfs f6,-364(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f6,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f6,f6,f21
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f21.f64));
	// lfs f21,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f5,f21
	ctx.f21.f64 = double(float(ctx.f5.f64 + ctx.f21.f64));
	// stfs f21,-488(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f21,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f5,f21,f5
	ctx.f5.f64 = double(float(ctx.f21.f64 - ctx.f5.f64));
	// lfs f21,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f8
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f8.f64));
	// stfs f21,-508(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f21,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f21.f64 = double(temp.f32);
	// fadds f8,f8,f21
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f21.f64));
	// stfs f8,-348(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fsubs f8,f0,f28
	ctx.f8.f64 = double(float(ctx.f0.f64 - ctx.f28.f64));
	// stfs f8,-480(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fadds f0,f28,f0
	ctx.f0.f64 = double(float(ctx.f28.f64 + ctx.f0.f64));
	// stfs f0,-564(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// lfs f0,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f0.f64 = double(temp.f32);
	// lfs f8,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f0,f23,f0
	ctx.f0.f64 = double(float(ctx.f23.f64 - ctx.f0.f64));
	// fsubs f8,f8,f22
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f22.f64));
	// lfs f21,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f21.f64 = double(temp.f32);
	// fadds f28,f21,f3
	ctx.f28.f64 = double(float(ctx.f21.f64 + ctx.f3.f64));
	// fsubs f3,f3,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f21.f64));
	// fadds f21,f8,f0
	ctx.f21.f64 = double(float(ctx.f8.f64 + ctx.f0.f64));
	// fsubs f0,f0,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f8.f64));
	// lfs f8,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f8.f64 = double(temp.f32);
	// fadds f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// lfs f4,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f24,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f4.f64));
	// stfs f4,-548(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f4,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f14.f64));
	// stfs f4,-500(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f24,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f24.f64 = double(temp.f32);
	// lfs f4,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f24,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f4.f64));
	// stfs f4,-532(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f4,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f20,f4
	ctx.f4.f64 = double(float(ctx.f20.f64 + ctx.f4.f64));
	// stfs f4,-528(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f24,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f24.f64 = double(temp.f32);
	// lfs f4,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f4,f4,f24
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f24.f64));
	// lfs f24,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f24,-448(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f24,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f24,-456(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f23,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// stfs f24,-552(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfs f24,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// stfs f24,-492(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f24,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f23.f64 = double(temp.f32);
	// fadds f22,f24,f21
	ctx.f22.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// fadds f20,f23,f0
	ctx.f20.f64 = double(float(ctx.f23.f64 + ctx.f0.f64));
	// fsubs f0,f0,f23
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f23.f64));
	// lfs f23,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f21.f64));
	// lfs f21,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfs f23,-496(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f23,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f25
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// stfs f23,-404(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// fmuls f23,f22,f7
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f7.f64));
	// stfs f23,-460(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f22,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f23,f20,f7
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// lfs f20,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f21,f4,f20
	ctx.f21.f64 = double(float(ctx.f4.f64 - ctx.f20.f64));
	// stfs f23,-428(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fadds f4,f20,f4
	ctx.f4.f64 = double(float(ctx.f20.f64 + ctx.f4.f64));
	// stfs f4,-568(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// lfs f4,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f24,f24,f7
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// lfs f20,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f0,f0,f7
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fadds f20,f20,f4
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f4.f64));
	// stfs f20,-448(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f20,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f4,f4,f20
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f20.f64));
	// stfs f4,-532(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f4,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f4.f64 = double(temp.f32);
	// stfs f24,-432(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fsubs f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f28.f64));
	// lfs f24,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f24.f64 = double(temp.f32);
	// stfs f4,-548(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// stfs f0,-464(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fadds f0,f24,f8
	ctx.f0.f64 = double(float(ctx.f24.f64 + ctx.f8.f64));
	// lfs f23,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f8,f24,f8
	ctx.f8.f64 = double(float(ctx.f24.f64 - ctx.f8.f64));
	// fadds f24,f22,f23
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfs f22,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f28
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// lfs f28,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f28.f64 = double(temp.f32);
	// lfs f4,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f4.f64 = double(temp.f32);
	// fadds f20,f4,f28
	ctx.f20.f64 = double(float(ctx.f4.f64 + ctx.f28.f64));
	// lfs f4,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f4.f64 = double(temp.f32);
	// fadds f28,f24,f0
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f0.f64));
	// stfs f28,-500(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// fsubs f0,f24,f0
	ctx.f0.f64 = double(float(ctx.f24.f64 - ctx.f0.f64));
	// stfs f0,-456(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f0,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f0.f64 = double(temp.f32);
	// fadds f28,f23,f3
	ctx.f28.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// fadds f4,f8,f4
	ctx.f4.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// fsubs f24,f0,f8
	ctx.f24.f64 = double(float(ctx.f0.f64 - ctx.f8.f64));
	// fsubs f3,f23,f3
	ctx.f3.f64 = double(float(ctx.f23.f64 - ctx.f3.f64));
	// fadds f23,f22,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// lfs f0,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f0.f64 = double(temp.f32);
	// lfs f8,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f8.f64 = double(temp.f32);
	// fadds f21,f8,f0
	ctx.f21.f64 = double(float(ctx.f8.f64 + ctx.f0.f64));
	// fsubs f0,f0,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f8.f64));
	// stfs f0,-548(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// fmuls f0,f4,f12
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// fmuls f4,f3,f12
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// stfs f4,-532(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fmuls f4,f24,f12
	ctx.f4.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// stfs f4,-544(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fmuls f4,f23,f12
	ctx.f4.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// stfs f4,0(r4)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmuls f4,f22,f12
	ctx.f4.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// stfsx f4,r22,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// fmuls f8,f28,f12
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fmuls f28,f21,f12
	ctx.f28.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfs f3,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f24,f4,f12
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// lfs f4,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f23,f3,f4
	ctx.f23.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// fadds f22,f3,f4
	ctx.f22.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// lfs f3,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f21,f3,f4
	ctx.f21.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// lfs f3,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// stfsx f23,r22,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r5.u32, temp.u32);
	// fmuls f23,f22,f12
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// stfs f23,0(r3)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f23,f21,f12
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// stfsx f23,r20,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r5.u32, temp.u32);
	// fadds f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f0.f64));
	// lfs f21,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f20,f20,f7
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// lfs f22,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f14,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f14.f64 = double(temp.f32);
	// lfs f21,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// lfs f14,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// stfsx f4,r7,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// lfs f4,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f25,f14,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// stfsx f28,r7,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f0.f64));
	// stfsx f24,r20,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r6.u32, temp.u32);
	// fadds f24,f19,f9
	ctx.f24.f64 = double(float(ctx.f19.f64 + ctx.f9.f64));
	// lfs f0,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f9,f9,f19
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f19.f64));
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f8,f0
	ctx.f28.f64 = double(float(ctx.f8.f64 - ctx.f0.f64));
	// fadds f3,f0,f8
	ctx.f3.f64 = double(float(ctx.f0.f64 + ctx.f8.f64));
	// stfsx f4,r21,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r6.u32, temp.u32);
	// lfs f0,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f0.f64 = double(temp.f32);
	// lfs f8,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f8.f64 = double(temp.f32);
	// stfsx f28,r21,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r5.u32, temp.u32);
	// fsubs f4,f8,f0
	ctx.f4.f64 = double(float(ctx.f8.f64 - ctx.f0.f64));
	// fadds f28,f0,f8
	ctx.f28.f64 = double(float(ctx.f0.f64 + ctx.f8.f64));
	// stfsx f3,r10,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f8,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f8.f64 = double(temp.f32);
	// lfs f0,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f0.f64 = double(temp.f32);
	// stfsx f4,r23,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fadds f3,f0,f8
	ctx.f3.f64 = double(float(ctx.f0.f64 + ctx.f8.f64));
	// stfsx f28,r9,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f0,f0,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f8.f64));
	// stfsx f3,r9,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmuls f19,f24,f11
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// stfsx f0,r23,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// lfs f8,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f8.f64 = double(temp.f32);
	// lfs f0,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f0,f0,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f8.f64));
	// lfs f8,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f8.f64 = double(temp.f32);
	// lfs f4,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f8,f8,f17
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f17.f64));
	// lfs f14,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f14.f64 = double(temp.f32);
	// fadds f4,f6,f4
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// lfs f17,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f6,f6,f14
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f14.f64));
	// stfs f6,-380(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fadds f28,f17,f15
	ctx.f28.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f6,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f6,f18,f6
	ctx.f6.f64 = double(float(ctx.f18.f64 - ctx.f6.f64));
	// stfs f6,-440(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fsubs f6,f15,f17
	ctx.f6.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f9,-528(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// stfs f6,-552(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// fadds f17,f22,f23
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfs f6,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f6.f64 = double(temp.f32);
	// fadds f15,f25,f21
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f21.f64));
	// lfs f9,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f9,f9,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// lfs f3,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f18,f3
	ctx.f3.f64 = double(float(ctx.f18.f64 + ctx.f3.f64));
	// fmuls f6,f4,f11
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmuls f14,f28,f11
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// fmuls f9,f9,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// stfs f9,-492(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// fadds f9,f8,f0
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f0.f64));
	// fmuls f18,f3,f11
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// fmadds f6,f3,f10,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 + ctx.f6.f64));
	// fmuls f9,f9,f12
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// fsubs f0,f8,f0
	ctx.f0.f64 = double(float(ctx.f8.f64 - ctx.f0.f64));
	// stfs f0,-548(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// fmsubs f0,f28,f10,f19
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 - ctx.f19.f64));
	// lfs f19,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f28,f24,f10,f14
	ctx.f28.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f14.f64));
	// lfs f24,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f8,f4,f10,f18
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f10.f64 - ctx.f18.f64));
	// fmuls f4,f17,f12
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmuls f17,f24,f10
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// lfs f24,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f3,f15,f7
	ctx.f3.f64 = double(float(ctx.f15.f64 * ctx.f7.f64));
	// fmuls f15,f24,f10
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// lfs f24,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f24,f10
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fsubs f24,f23,f22
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f24,-380(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fsubs f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// stfs f25,-532(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fmuls f18,f19,f10
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// lfs f23,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f22,f22,f11,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 - ctx.f15.f64));
	// lfs f15,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f21,f21,f11,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 + ctx.f14.f64));
	// lfs f14,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f25,f23,f11,f18
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f11.f64 + ctx.f18.f64));
	// fmsubs f23,f19,f11,f17
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 - ctx.f17.f64));
	// fadds f17,f9,f20
	ctx.f17.f64 = double(float(ctx.f9.f64 + ctx.f20.f64));
	// fsubs f9,f9,f20
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f20.f64));
	// fadds f20,f0,f6
	ctx.f20.f64 = double(float(ctx.f0.f64 + ctx.f6.f64));
	// fsubs f0,f0,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f6.f64));
	// fadds f6,f3,f4
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fsubs f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fadds f3,f28,f8
	ctx.f3.f64 = double(float(ctx.f28.f64 + ctx.f8.f64));
	// fsubs f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// fadds f28,f20,f17
	ctx.f28.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfsx f28,r31,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f20,f17
	ctx.f28.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfsx f28,r26,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// lfs f17,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f28,f4,f0
	ctx.f28.f64 = double(float(ctx.f4.f64 - ctx.f0.f64));
	// fsubs f20,f6,f3
	ctx.f20.f64 = double(float(ctx.f6.f64 - ctx.f3.f64));
	// stfsx f20,r26,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fadds f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// stfsx f6,r31,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f0,f4
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f4.f64));
	// stfsx f28,r24,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// stfsx f0,r29,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f0,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f0.f64 = double(temp.f32);
	// fadds f4,f0,f27
	ctx.f4.f64 = double(float(ctx.f0.f64 + ctx.f27.f64));
	// lfs f0,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f0.f64 = double(temp.f32);
	// fadds f3,f0,f26
	ctx.f3.f64 = double(float(ctx.f0.f64 + ctx.f26.f64));
	// lfs f15,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f15.f64 = double(temp.f32);
	// lfs f0,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f6,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f28,f0,f11
	ctx.f28.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// fmuls f14,f0,f10
	ctx.f14.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// fmuls f20,f6,f10
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// lfs f18,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f0,f6,f11
	ctx.f0.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// fmuls f24,f18,f12
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// lfs f6,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// stfs f4,-500(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// fmuls f4,f3,f2
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// stfs f4,-448(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f4,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f4.f64 = double(temp.f32);
	// fadds f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// lfs f3,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f4.f64 = double(temp.f32);
	// lfs f18,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f18.f64 = double(temp.f32);
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fmuls f19,f18,f12
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// lfs f18,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f7
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f7.f64));
	// fadds f3,f18,f24
	ctx.f3.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// stfs f3,-456(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// fadds f3,f22,f25
	ctx.f3.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// stfs f4,-532(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fsubs f4,f24,f18
	ctx.f4.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// stfs f3,-440(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fadds f18,f8,f9
	ctx.f18.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// lfs f3,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f24,f17,f7
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f7.f64));
	// fadds f3,f19,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 + ctx.f3.f64));
	// stfs f3,-552(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// fadds f3,f21,f23
	ctx.f3.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfs f3,-568(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// stfs f0,-380(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fsubs f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// stfs f6,-548(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// fsubs f6,f22,f25
	ctx.f6.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// lfs f3,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f3.f64 = double(temp.f32);
	// stfsx f18,r29,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f19,f3
	ctx.f0.f64 = double(float(ctx.f19.f64 - ctx.f3.f64));
	// fsubs f3,f23,f21
	ctx.f3.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// lfs f18,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f18.f64 = double(temp.f32);
	// lfs f8,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f23,f15,f12
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// stfsx f9,r24,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fadds f9,f18,f8
	ctx.f9.f64 = double(float(ctx.f18.f64 + ctx.f8.f64));
	// lfs f15,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f8,f8,f18
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f18.f64));
	// lfs f22,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f28,f22,f10,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f28.f64));
	// lfs f21,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f22,f22,f11,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 + ctx.f14.f64));
	// fmadds f25,f21,f11,f20
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 + ctx.f20.f64));
	// lfs f17,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f19,f17,f7
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f7.f64));
	// lfs f17,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f17.f64 = double(temp.f32);
	// fadds f18,f15,f17
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f14,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfsx f14,r30,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f15,r25,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// lfs f15,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// fmsubs f21,f21,f10,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 - ctx.f20.f64));
	// stfsx f14,r25,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// lfs f20,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfsx f15,r30,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fsubs f15,f0,f6
	ctx.f15.f64 = double(float(ctx.f0.f64 - ctx.f6.f64));
	// stfsx f15,r27,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f0,f6,f0
	ctx.f0.f64 = double(float(ctx.f6.f64 + ctx.f0.f64));
	// stfsx f0,r28,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f3,f4
	ctx.f0.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// stfsx f0,r28,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f3,f4
	ctx.f0.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// stfsx f0,r27,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fadds f0,f25,f28
	ctx.f0.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// fsubs f6,f28,f25
	ctx.f6.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// fadds f28,f21,f22
	ctx.f28.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f25,f21,f22
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// fadds f4,f23,f24
	ctx.f4.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f3,f23,f24
	ctx.f3.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// fadds f24,f19,f20
	ctx.f24.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f23,f20,f19
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// lfs f19,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f21,f18,f31
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f31.f64));
	// fmuls f20,f9,f31
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f22,f8,f29
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// fmsubs f9,f9,f1,f21
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f1.f64 - ctx.f21.f64));
	// fmadds f21,f18,f1,f20
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f1.f64 + ctx.f20.f64));
	// lfs f20,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f20.f64 = double(temp.f32);
	// fadds f18,f19,f20
	ctx.f18.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f20,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f22,f17,f30,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 + ctx.f22.f64));
	// fadds f15,f19,f20
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fadds f20,f4,f0
	ctx.f20.f64 = double(float(ctx.f4.f64 + ctx.f0.f64));
	// fsubs f0,f4,f0
	ctx.f0.f64 = double(float(ctx.f4.f64 - ctx.f0.f64));
	// fadds f4,f25,f3
	ctx.f4.f64 = double(float(ctx.f25.f64 + ctx.f3.f64));
	// fsubs f3,f3,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f25.f64));
	// lfs f25,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f14,f17,f29
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f29.f64));
	// fmuls f25,f25,f10
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// fmuls f18,f18,f2
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f2.f64));
	// fmuls f17,f15,f2
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// fadds f19,f24,f28
	ctx.f19.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// fsubs f28,f24,f28
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f28.f64));
	// fadds f24,f23,f6
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f6.f64));
	// fsubs f6,f23,f6
	ctx.f6.f64 = double(float(ctx.f23.f64 - ctx.f6.f64));
	// lfs f23,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f8,f8,f30,f14
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f30.f64 - ctx.f14.f64));
	// lfs f14,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f25,f23,f11,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f11.f64 - ctx.f25.f64));
	// fadds f23,f18,f14
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// fadds f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,-336(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// fmuls f14,f23,f31
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f31.f64));
	// fmuls f16,f23,f1
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f1.f64));
	// fmuls f23,f17,f29
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f29.f64));
	// stfs f23,-332(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fmuls f17,f18,f29
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f29.f64));
	// stfs f17,-328(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fmsubs f17,f15,f1,f14
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f1.f64 - ctx.f14.f64));
	// fmadds f23,f15,f31,f16
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f31.f64 + ctx.f16.f64));
	// fadds f15,f23,f9
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f9.f64));
	// fsubs f9,f9,f23
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f23.f64));
	// fadds f23,f17,f21
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// fsubs f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// lfs f16,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f18,f18,f30,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 + ctx.f16.f64));
	// lfs f14,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f30,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64 - ctx.f14.f64));
	// fadds f17,f18,f8
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f8.f64));
	// fsubs f8,f8,f18
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f18.f64));
	// fadds f18,f16,f22
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// fsubs f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// fadds f16,f15,f20
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfsx f16,r27,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fsubs f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfsx f20,r28,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f20,f19,f23
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f23.f64));
	// stfsx f20,r28,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// stfsx f23,r27,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fsubs f23,f28,f9
	ctx.f23.f64 = double(float(ctx.f28.f64 - ctx.f9.f64));
	// stfsx f23,r30,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f9,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f28.f64));
	// stfsx f9,r25,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f21,f0
	ctx.f9.f64 = double(float(ctx.f21.f64 + ctx.f0.f64));
	// stfsx f9,r25,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f21,f0
	ctx.f0.f64 = double(float(ctx.f21.f64 - ctx.f0.f64));
	// stfsx f0,r30,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f0,f17,f4
	ctx.f0.f64 = double(float(ctx.f17.f64 + ctx.f4.f64));
	// stfsx f0,r24,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f17,f4
	ctx.f0.f64 = double(float(ctx.f17.f64 - ctx.f4.f64));
	// stfsx f0,r29,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f0,f24,f18
	ctx.f0.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// stfsx f0,r29,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f0,f18,f24
	ctx.f0.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// stfsx f0,r24,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fsubs f0,f6,f8
	ctx.f0.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// stfsx f0,r31,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f0,f8,f6
	ctx.f0.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfsx f0,r26,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f22,f3
	ctx.f0.f64 = double(float(ctx.f22.f64 + ctx.f3.f64));
	// stfsx f0,r26,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f22,f3
	ctx.f0.f64 = double(float(ctx.f22.f64 - ctx.f3.f64));
	// stfsx f0,r31,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f0,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f0.f64 = double(temp.f32);
	// lfs f9,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f0,f26,f0
	ctx.f0.f64 = double(float(ctx.f26.f64 - ctx.f0.f64));
	// lfs f8,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f9,f9,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f27.f64));
	// lfs f6,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// lfs f4,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f4.f64 = double(temp.f32);
	// lfs f6,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// fsubs f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// lfs f28,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f4,f5,f10
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// lfs f3,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f28.f64));
	// lfs f27,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f27.f64 = double(temp.f32);
	// lfs f28,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f0,f0,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// fadds f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// lfs f27,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f27,f10
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f23,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f23.f64 = double(temp.f32);
	// lfs f26,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f26.f64 = double(temp.f32);
	// lwz r31,-324(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	// fmuls f26,f26,f10
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// lfs f22,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f8,f8,f2
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f2.f64));
	// lfs f17,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f16.f64 = double(temp.f32);
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// fmuls f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// lfs f18,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f4,f27,f11,f4
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f4.f64));
	// lfs f27,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f23,f27,f23
	ctx.f23.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// lfs f27,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f22,f27,f22
	ctx.f22.f64 = double(float(ctx.f27.f64 - ctx.f22.f64));
	// lfs f27,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f3,f3,f7
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// stw r31,-324(r1)
	PPC_STORE_U32(ctx.r1.u32 + -324, ctx.r31.u32);
	// fmuls f28,f28,f12
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// add r3,r19,r3
	ctx.r3.u64 = ctx.r19.u64 + ctx.r3.u64;
	// fmsubs f5,f5,f11,f24
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 - ctx.f24.f64));
	// fmadds f27,f27,f11,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f26.f64));
	// fadds f21,f16,f8
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f8.f64));
	// fsubs f8,f16,f8
	ctx.f8.f64 = double(float(ctx.f16.f64 - ctx.f8.f64));
	// fadds f20,f13,f6
	ctx.f20.f64 = double(float(ctx.f13.f64 + ctx.f6.f64));
	// fsubs f13,f13,f6
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f6.f64));
	// fmuls f26,f23,f12
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fmuls f24,f22,f7
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f7.f64));
	// fadds f22,f17,f9
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f9.f64));
	// fadds f23,f18,f0
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f0.f64));
	// fadds f19,f4,f25
	ctx.f19.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// fsubs f0,f18,f0
	ctx.f0.f64 = double(float(ctx.f18.f64 - ctx.f0.f64));
	// fsubs f6,f25,f4
	ctx.f6.f64 = double(float(ctx.f25.f64 - ctx.f4.f64));
	// fadds f18,f28,f3
	ctx.f18.f64 = double(float(ctx.f28.f64 + ctx.f3.f64));
	// fsubs f4,f28,f3
	ctx.f4.f64 = double(float(ctx.f28.f64 - ctx.f3.f64));
	// fadds f3,f5,f27
	ctx.f3.f64 = double(float(ctx.f5.f64 + ctx.f27.f64));
	// fsubs f5,f5,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f27.f64));
	// fadds f28,f24,f26
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// fsubs f27,f26,f24
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// fmuls f25,f22,f30
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// fmuls f24,f21,f29
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f29.f64));
	// fmuls f21,f21,f30
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// fsubs f9,f17,f9
	ctx.f9.f64 = double(float(ctx.f17.f64 - ctx.f9.f64));
	// fmuls f22,f22,f29
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f29.f64));
	// fmuls f17,f0,f1
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// fadds f26,f18,f19
	ctx.f26.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fmuls f15,f8,f1
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// fmuls f14,f8,f31
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// fmsubs f25,f23,f29,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f29.f64 - ctx.f25.f64));
	// fmadds f24,f20,f30,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f30.f64 + ctx.f24.f64));
	// fmsubs f21,f20,f29,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f29.f64 - ctx.f21.f64));
	// fmuls f16,f9,f1
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// fmadds f8,f23,f30,f22
	ctx.f8.f64 = double(float(ctx.f23.f64 * ctx.f30.f64 + ctx.f22.f64));
	// fmadds f9,f9,f31,f17
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f31.f64 + ctx.f17.f64));
	// fadds f23,f3,f28
	ctx.f23.f64 = double(float(ctx.f3.f64 + ctx.f28.f64));
	// fmsubs f22,f13,f31,f15
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 - ctx.f15.f64));
	// fmadds f13,f13,f1,f14
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 + ctx.f14.f64));
	// fsubs f3,f28,f3
	ctx.f3.f64 = double(float(ctx.f28.f64 - ctx.f3.f64));
	// fadds f20,f24,f25
	ctx.f20.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fmsubs f0,f0,f31,f16
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f31.f64 - ctx.f16.f64));
	// fadds f17,f20,f26
	ctx.f17.f64 = double(float(ctx.f20.f64 + ctx.f26.f64));
	// stfsx f17,r23,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fsubs f26,f20,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// stfsx f26,r9,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f26,f21,f8
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f8.f64));
	// fsubs f28,f25,f24
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// add r4,r19,r4
	ctx.r4.u64 = ctx.r19.u64 + ctx.r4.u64;
	// fsubs f8,f21,f8
	ctx.f8.f64 = double(float(ctx.f21.f64 - ctx.f8.f64));
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// fadds f21,f13,f0
	ctx.f21.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// fsubs f25,f18,f19
	ctx.f25.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// fadds f24,f5,f4
	ctx.f24.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// fsubs f13,f4,f5
	ctx.f13.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// fsubs f5,f23,f26
	ctx.f5.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// stfsx f5,r9,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f26,f23
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f23.f64));
	// stfs f5,0(r14)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fadds f20,f6,f27
	ctx.f20.f64 = double(float(ctx.f6.f64 + ctx.f27.f64));
	// fsubs f5,f3,f28
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f28.f64));
	// stfsx f5,r10,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f28,f3
	ctx.f5.f64 = double(float(ctx.f28.f64 + ctx.f3.f64));
	// stfs f5,0(r15)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r15.u32 + 0, temp.u32);
	// fadds f19,f22,f9
	ctx.f19.f64 = double(float(ctx.f22.f64 + ctx.f9.f64));
	// fadds f5,f8,f25
	ctx.f5.f64 = double(float(ctx.f8.f64 + ctx.f25.f64));
	// stfs f5,0(r16)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fsubs f8,f8,f25
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f25.f64));
	// stfsx f8,r10,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lwz r10,-316(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	// fsubs f6,f27,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 - ctx.f6.f64));
	// fadds f8,f21,f24
	ctx.f8.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// fsubs f9,f22,f9
	ctx.f9.f64 = double(float(ctx.f22.f64 - ctx.f9.f64));
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-308(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	// fsubs f8,f21,f24
	ctx.f8.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// stfsx f8,r7,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// fsubs f8,f20,f19
	ctx.f8.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfsx f8,r7,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f19,f20
	ctx.f8.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// fsubs f8,f6,f0
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f0.f64));
	// stfs f8,0(r5)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f0,f0,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f6.f64));
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// stfs f0,0(r17)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r17.u32 + 0, temp.u32);
	// fadds f0,f9,f13
	ctx.f0.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// stfs f0,0(r18)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// fsubs f0,f9,f13
	ctx.f0.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// subf r5,r19,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r19.s64;
	// subf r6,r19,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r19.s64;
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d4157c
	if (!ctx.cr0.eq) goto loc_82D4157C;
loc_82D42E4C:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D42E54;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D42E58"))) PPC_WEAK_FUNC(sub_82D42E58);
PPC_FUNC_IMPL(__imp__sub_82D42E58) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-3712
	ctx.r5.s64 = ctx.r11.s64 + -3712;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,5376
	ctx.r4.s64 = ctx.r11.s64 + 5376;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D42E70"))) PPC_WEAK_FUNC(sub_82D42E70);
PPC_FUNC_IMPL(__imp__sub_82D42E70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82D42E78;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28ee0
	ctx.lr = 0x82D42E80;
	__savefpr_14(ctx, base);
	// rlwinm r11,r9,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// addi r11,r11,-32
	ctx.r11.s64 = ctx.r11.s64 + -32;
	// bge cr6,0x82d4383c
	if (!ctx.cr6.lt) goto loc_82D4383C;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r24,r9,r10
	ctx.r24.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// rlwinm r27,r7,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfs f7,-3656(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -3656);
	ctx.f7.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f8,-3660(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -3660);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,-3664(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -3664);
	ctx.f9.f64 = double(temp.f32);
	// lfs f0,-28552(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
loc_82D42EC4:
	// lfs f11,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r10,r8,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f4,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f17,f4,f11
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// stfs f17,-280(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfs f10,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f16,f4,f10
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// stfs f16,-284(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lfs f2,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f17,f2,f1
	ctx.f17.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// lfs f3,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f3.f64 = double(temp.f32);
	// fadds f16,f1,f2
	ctx.f16.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// lfs f6,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f28,f6,f10
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmuls f26,f5,f11
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f29,f6,f11
	ctx.f29.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f13,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f27,f5,f10
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// lfs f31,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f24,f13,f11
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f30,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f22,f12,f10
	ctx.f22.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// fmuls f20,f13,f5
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// fmuls f18,f12,f6
	ctx.f18.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// fmuls f25,f13,f10
	ctx.f25.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmuls f23,f12,f11
	ctx.f23.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fmuls f21,f13,f6
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fsubs f1,f26,f28
	ctx.f1.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// fmuls f19,f12,f5
	ctx.f19.f64 = double(float(ctx.f12.f64 * ctx.f5.f64));
	// fsubs f15,f31,f30
	ctx.f15.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// fadds f14,f30,f31
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// fadds f31,f26,f28
	ctx.f31.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fsubs f30,f29,f27
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// fsubs f28,f24,f22
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f26,f22,f24
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fadds f24,f18,f20
	ctx.f24.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// fsubs f22,f18,f20
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// fmuls f18,f12,f1
	ctx.f18.f64 = double(float(ctx.f12.f64 * ctx.f1.f64));
	// stfs f18,-300(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fmuls f18,f12,f31
	ctx.f18.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f18,-276(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// fmuls f18,f13,f30
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f18,-296(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fmuls f18,f12,f30
	ctx.f18.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// stfs f18,-272(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fmuls f18,f13,f31
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// stfs f18,-292(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f2,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f2,f3,f10,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 + ctx.f2.f64));
	// stfs f2,-244(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// lfs f2,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f2,f3,f11,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 - ctx.f2.f64));
	// stfs f2,-248(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lfsx f2,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,-280(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfsx f2,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,-284(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lfsx f2,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,-288(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfsx f2,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,-304(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fadds f2,f27,f29
	ctx.f2.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// fadds f29,f23,f25
	ctx.f29.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// fsubs f27,f23,f25
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f25.f64));
	// fadds f25,f19,f21
	ctx.f25.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f23,f21,f19
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// fmuls f18,f12,f2
	ctx.f18.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// lfs f20,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfs f20,-280(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfs f19,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// stfs f20,-284(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// stfs f18,-288(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fmuls f20,f13,f2
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f18,f13,f1
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// stfs f18,-268(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// lfs f18,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f18.f64 = double(temp.f32);
	// rlwinm r9,r8,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f19,-304(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f18,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f18.f64 = double(temp.f32);
	// mulli r7,r8,24
	ctx.r7.s64 = ctx.r8.s64 * 24;
	// fadds f18,f18,f20
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f18,-256(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// lfs f18,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f20,-240(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// lfs f20,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f20
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// stfs f18,-276(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f19,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f19,f19,f28
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f28.f64));
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// stfs f20,-264(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfs f18,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f28,f21,f28
	ctx.f28.f64 = double(float(ctx.f21.f64 * ctx.f28.f64));
	// lfs f20,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f20.f64 = double(temp.f32);
	// fadds f18,f18,f20
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f18,-296(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f18,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f20,-292(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f18,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f19,f21,f29,f19
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f29.f64 - ctx.f19.f64));
	// fmuls f21,f16,f10
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// fmuls f16,f16,f11
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// fmsubs f11,f15,f11,f21
	ctx.f11.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 - ctx.f21.f64));
	// fmadds f10,f15,f10,f16
	ctx.f10.f64 = double(float(ctx.f15.f64 * ctx.f10.f64 + ctx.f16.f64));
	// lfsx f16,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f15,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f20,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f20.f64 = double(temp.f32);
	// stfs f19,-268(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fsubs f18,f18,f20
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// stfs f18,-252(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// lfs f18,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// lfs f18,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// lfs f13,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f29,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f29.f64 + ctx.f28.f64));
	// lfs f29,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f29.f64 = double(temp.f32);
	// lfs f28,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f29,f29,f12,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f12.f64 + ctx.f19.f64));
	// fmsubs f12,f28,f12,f18
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 - ctx.f18.f64));
	// fadds f19,f13,f14
	ctx.f19.f64 = double(float(ctx.f13.f64 + ctx.f14.f64));
	// fsubs f13,f14,f13
	ctx.f13.f64 = double(float(ctx.f14.f64 - ctx.f13.f64));
	// lfsx f14,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f11,f29
	ctx.f18.f64 = double(float(ctx.f11.f64 - ctx.f29.f64));
	// fadds f11,f29,f11
	ctx.f11.f64 = double(float(ctx.f29.f64 + ctx.f11.f64));
	// stfs f11,-236(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// fadds f11,f10,f12
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// stfs f11,-300(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fsubs f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// stfs f12,-232(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -232, temp.u32);
	// lfsx f11,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f12,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f29,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f10,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfs f21,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f21.f64 = double(temp.f32);
	// stfs f14,-268(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fadds f28,f21,f17
	ctx.f28.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// fadds f14,f11,f12
	ctx.f14.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// fsubs f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// stfs f12,-280(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fsubs f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// lfsx f17,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f11,f10,f29
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f29.f64));
	// stfs f11,-288(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fadds f10,f29,f10
	ctx.f10.f64 = double(float(ctx.f29.f64 + ctx.f10.f64));
	// stfs f10,-304(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fadds f29,f16,f17
	ctx.f29.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f29,-272(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fsubs f12,f17,f16
	ctx.f12.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f12,-284(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// lfs f12,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f12.f64 = double(temp.f32);
	// mulli r30,r8,20
	ctx.r30.s64 = ctx.r8.s64 * 20;
	// fsubs f17,f15,f12
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f12.f64));
	// stfs f17,-268(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fadds f16,f12,f15
	ctx.f16.f64 = double(float(ctx.f12.f64 + ctx.f15.f64));
	// lfs f12,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f15,f11,f12
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f11,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f14,f12
	ctx.f12.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// stfs f12,-264(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// stfs f16,-260(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r28,r8,28
	ctx.r28.s64 = ctx.r8.s64 * 28;
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fmuls f11,f29,f11
	ctx.f11.f64 = double(float(ctx.f29.f64 * ctx.f11.f64));
	// stfs f11,-276(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f29,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f16,f16,f25
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// fmsubs f12,f14,f29,f15
	ctx.f12.f64 = double(float(ctx.f14.f64 * ctx.f29.f64 - ctx.f15.f64));
	// lfs f29,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f11,f29,f30,f10
	ctx.f11.f64 = double(float(ctx.f29.f64 * ctx.f30.f64 - ctx.f10.f64));
	// lfs f29,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f29.f64 = double(temp.f32);
	// add r26,r28,r4
	ctx.r26.u64 = ctx.r28.u64 + ctx.r4.u64;
	// lfs f10,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f10.f64 = double(temp.f32);
	// fmsubs f10,f10,f29,f17
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f29.f64 - ctx.f17.f64));
	// lfs f29,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f29,f29,f22,f16
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f22.f64 - ctx.f16.f64));
	// lfs f16,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f17,f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f15.f64));
	// fadds f16,f10,f12
	ctx.f16.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// lfs f10,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f31,f10,f31
	ctx.f31.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// lfs f10,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f10.f64 = double(temp.f32);
	// fadds f15,f29,f11
	ctx.f15.f64 = double(float(ctx.f29.f64 + ctx.f11.f64));
	// lfs f14,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f11,f11,f29
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f29.f64));
	// fmuls f29,f10,f25
	ctx.f29.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// lfs f10,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f10.f64 = double(temp.f32);
	// lfs f25,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f10,f10,f25,f14
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f25.f64 + ctx.f14.f64));
	// lfs f25,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-264(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfsx f14,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f31,f25,f30,f31
	ctx.f31.f64 = double(float(ctx.f25.f64 * ctx.f30.f64 + ctx.f31.f64));
	// lfs f30,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f30.f64 = double(temp.f32);
	// stfs f14,-260(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfsx f25,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f30,f30,f22,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f22.f64 + ctx.f29.f64));
	// lfsx f22,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f29,f10,f17
	ctx.f29.f64 = double(float(ctx.f10.f64 + ctx.f17.f64));
	// fsubs f10,f10,f17
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f17.f64));
	// stfs f10,-304(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfsx f17,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f10,f30,f31
	ctx.f10.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// stfs f10,-296(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fsubs f10,f31,f30
	ctx.f10.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// stfs f10,-276(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfsx f10,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f31,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f30,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f14,f10,f31
	ctx.f14.f64 = double(float(ctx.f10.f64 - ctx.f31.f64));
	// fadds f31,f31,f10
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f10.f64));
	// stfs f31,-268(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fadds f10,f25,f30
	ctx.f10.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// stfs f10,-284(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fsubs f10,f22,f17
	ctx.f10.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f10,-288(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fadds f10,f17,f22
	ctx.f10.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f10,-280(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fsubs f25,f30,f25
	ctx.f25.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// stfs f25,-272(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f10,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f10.f64 = double(temp.f32);
	// lfs f30,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f30.f64 = double(temp.f32);
	// fadds f22,f30,f10
	ctx.f22.f64 = double(float(ctx.f30.f64 + ctx.f10.f64));
	// stfs f22,-260(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// fsubs f30,f10,f30
	ctx.f30.f64 = double(float(ctx.f10.f64 - ctx.f30.f64));
	// lfs f10,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f17,f10,f1
	ctx.f17.f64 = double(float(ctx.f10.f64 * ctx.f1.f64));
	// lfs f10,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f25,f25,f5
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f5.f64));
	// stfs f30,-264(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fmuls f5,f31,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f5.f64));
	// lfs f31,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f31.f64 = double(temp.f32);
	// stfs f5,-256(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fmuls f1,f14,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 * ctx.f1.f64));
	// mulli r29,r8,12
	ctx.r29.s64 = ctx.r8.s64 * 12;
	// add r25,r28,r3
	ctx.r25.u64 = ctx.r28.u64 + ctx.r3.u64;
	// fmuls f22,f22,f26
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f26.f64));
	// fmuls f30,f30,f10
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// fmuls f10,f31,f10
	ctx.f10.f64 = double(float(ctx.f31.f64 * ctx.f10.f64));
	// lfs f31,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f31.f64 = double(temp.f32);
	// stfs f10,-260(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// fmsubs f10,f14,f2,f17
	ctx.f10.f64 = double(float(ctx.f14.f64 * ctx.f2.f64 - ctx.f17.f64));
	// lfs f17,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f31,f31,f27
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f27.f64));
	// fmsubs f5,f17,f27,f22
	ctx.f5.f64 = double(float(ctx.f17.f64 * ctx.f27.f64 - ctx.f22.f64));
	// lfs f27,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f27.f64 = double(temp.f32);
	// stfs f1,-268(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fmsubs f1,f27,f6,f25
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f6.f64 - ctx.f25.f64));
	// lfs f27,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f27.f64 = double(temp.f32);
	// stfs f30,-252(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fmr f30,f27
	ctx.f30.f64 = ctx.f27.f64;
	// lfs f27,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-280(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfsx f14,r29,r6
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// lfs f25,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f25.f64 = double(temp.f32);
	// stfs f31,-252(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fmsubs f31,f27,f30,f25
	ctx.f31.f64 = double(float(ctx.f27.f64 * ctx.f30.f64 - ctx.f25.f64));
	// lfs f25,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f25.f64 = double(temp.f32);
	// lfs f27,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f6,f27,f6,f25
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f6.f64 + ctx.f25.f64));
	// lfs f27,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f27.f64 = double(temp.f32);
	// lfs f25,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f30,f27,f30,f25
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f30.f64 + ctx.f25.f64));
	// lfs f27,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f27.f64 = double(temp.f32);
	// lfs f25,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f2,f27,f2,f25
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f2.f64 + ctx.f25.f64));
	// fmr f27,f17
	ctx.f27.f64 = ctx.f17.f64;
	// lfsx f17,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfs f25,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f25.f64 = double(temp.f32);
	// stfs f14,-252(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fmadds f27,f27,f26,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f26.f64 + ctx.f25.f64));
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f26,f5,f10
	ctx.f26.f64 = double(float(ctx.f5.f64 + ctx.f10.f64));
	// stfs f14,-256(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fsubs f10,f10,f5
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f5.f64));
	// lfsx f14,r29,r5
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f5,f31,f1
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// stfs f14,-284(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fsubs f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// fadds f31,f30,f6
	ctx.f31.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// lfsx f25,r28,r6
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r6.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f6,f30,f6
	ctx.f6.f64 = double(float(ctx.f30.f64 - ctx.f6.f64));
	// fadds f30,f27,f2
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f2.f64));
	// fsubs f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f27.f64));
	// lfs f27,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f14,f27,f25
	ctx.f14.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// fadds f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stfs f27,-260(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// fadds f25,f17,f22
	ctx.f25.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f25,-264(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,-288(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f17,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f17,-268(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// lfs f17,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f17.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f22,-292(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f22,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f17,-252(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// lfs f17,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,-280(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fmuls f22,f27,f3
	ctx.f22.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// lfs f27,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f25,f27
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f25,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f3,f25,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// lfs f25,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f25.f64 = double(temp.f32);
	// stfs f3,-244(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// fmuls f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 * ctx.f27.f64));
	// stfs f27,-248(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fmsubs f3,f14,f25,f17
	ctx.f3.f64 = double(float(ctx.f14.f64 * ctx.f25.f64 - ctx.f17.f64));
	// lfs f17,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f27,f17,f4,f22
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 + ctx.f22.f64));
	// lfs f22,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f4,f22,f4,f17
	ctx.f4.f64 = double(float(ctx.f22.f64 * ctx.f4.f64 - ctx.f17.f64));
	// stfs f4,-256(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// lfs f22,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f22.f64 = double(temp.f32);
	// lfs f4,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f4,f4,f25,f22
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f25.f64 + ctx.f22.f64));
	// stfs f4,-248(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lfs f4,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f4.f64 = double(temp.f32);
	// lfs f25,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f25.f64 = double(temp.f32);
	// lfs f22,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f25,f4
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// lfs f25,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f4,f22,f4
	ctx.f4.f64 = double(float(ctx.f22.f64 * ctx.f4.f64));
	// stfs f4,-240(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// fmuls f14,f25,f23
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f23.f64));
	// fmuls f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// stfs f25,-244(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// lfs f22,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f4,f22,f24,f14
	ctx.f4.f64 = double(float(ctx.f22.f64 * ctx.f24.f64 - ctx.f14.f64));
	// lfs f24,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f25,f24,f20,f17
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f20.f64 + ctx.f17.f64));
	// lfs f24,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f24.f64 = double(temp.f32);
	// lfs f14,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f24,f24,f20,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f20.f64 - ctx.f17.f64));
	// lfs f17,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f23,f22,f23,f17
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 + ctx.f17.f64));
	// lfs f17,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f25,f27
	ctx.f20.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fadds f22,f4,f3
	ctx.f22.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// fsubs f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// fsubs f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// fadds f3,f24,f17
	ctx.f3.f64 = double(float(ctx.f24.f64 + ctx.f17.f64));
	// fsubs f24,f17,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 - ctx.f24.f64));
	// fadds f17,f23,f14
	ctx.f17.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// fsubs f25,f14,f23
	ctx.f25.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// fadds f23,f20,f31
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f31.f64));
	// stfs f23,-280(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fadds f14,f22,f26
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// stfs f14,-244(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// fadds f23,f15,f28
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// stfs f23,-240(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfs f23,-252(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fsubs f23,f18,f29
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f29.f64));
	// stfs f23,-248(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lfs f14,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfs f23,-284(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lfs f14,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfs f23,-260(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f23,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f23.f64 = double(temp.f32);
	// fadds f14,f16,f23
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// stfs f14,-240(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// fadds f23,f3,f5
	ctx.f23.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfs f14,-288(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f14,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// stfs f23,-244(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// lfs f23,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfs f23,-256(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// lfs f23,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// fadds f14,f23,f19
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// stfs f14,-240(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// fadds f23,f17,f30
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// stfs f26,-264(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fsubs f3,f31,f20
	ctx.f3.f64 = double(float(ctx.f31.f64 - ctx.f20.f64));
	// lfs f20,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f20.f64 = double(temp.f32);
	// lfs f26,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f26.f64 = double(temp.f32);
	// fadds f31,f29,f18
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f18.f64));
	// fsubs f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 - ctx.f30.f64));
	// lfs f29,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f29,f16
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f16.f64));
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// lfs f15,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f14,f23
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// stfs f14,-248(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lfs f14,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfs f23,-240(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// lfs f14,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfs f23,-252(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fsubs f23,f19,f20
	ctx.f23.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// lfs f20,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f20,f14
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// lfs f20,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f22.f64 = double(temp.f32);
	// fadds f19,f22,f26
	ctx.f19.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// fsubs f17,f22,f26
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// lfs f22,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f20,f22
	ctx.f16.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// lfs f26,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f26.f64 = double(temp.f32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// lfs f20,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f26
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f26.f64));
	// fsubs f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f26.f64));
	// lfs f26,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// stfs f26,0(r4)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f26,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f14,f21,f26
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// fadds f26,f26,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// fmuls f21,f19,f0
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f21,0(r3)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f21,f18,f0
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfsx f21,r28,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fmuls f21,f17,f0
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfsx f21,r28,r5
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fmuls f21,f16,f0
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfsx f21,r29,r5
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f19,f11,f13
	ctx.f19.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fmuls f21,f15,f0
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfsx f21,r29,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f21,f13,f11
	ctx.f21.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// fmuls f13,f22,f0
	ctx.f13.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfsx f13,r10,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmuls f13,f20,f0
	ctx.f13.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// stfsx f13,r10,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f20,f28,f30
	ctx.f20.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// fmuls f11,f26,f0
	ctx.f11.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fsubs f28,f28,f30
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// lfs f30,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f13,f14,f0
	ctx.f13.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmuls f22,f19,f0
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fadds f19,f30,f23
	ctx.f19.f64 = double(float(ctx.f30.f64 + ctx.f23.f64));
	// fmuls f26,f21,f0
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fadds f21,f3,f5
	ctx.f21.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fsubs f3,f31,f29
	ctx.f3.f64 = double(float(ctx.f31.f64 - ctx.f29.f64));
	// fadds f31,f29,f31
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// fsubs f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f30.f64));
	// fsubs f30,f10,f2
	ctx.f30.f64 = double(float(ctx.f10.f64 - ctx.f2.f64));
	// fadds f29,f25,f4
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f4.f64));
	// fadds f18,f29,f30
	ctx.f18.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fsubs f17,f30,f29
	ctx.f17.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fmuls f30,f20,f0
	ctx.f30.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmuls f20,f18,f9
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// fadds f18,f3,f21
	ctx.f18.f64 = double(float(ctx.f3.f64 + ctx.f21.f64));
	// fmuls f29,f28,f0
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f28,f19,f0
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fmuls f19,f17,f9
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// fadds f17,f31,f5
	ctx.f17.f64 = double(float(ctx.f31.f64 + ctx.f5.f64));
	// fsubs f21,f3,f21
	ctx.f21.f64 = double(float(ctx.f3.f64 - ctx.f21.f64));
	// fsubs f16,f5,f31
	ctx.f16.f64 = double(float(ctx.f5.f64 - ctx.f31.f64));
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fadds f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 + ctx.f10.f64));
	// fsubs f4,f25,f4
	ctx.f4.f64 = double(float(ctx.f25.f64 - ctx.f4.f64));
	// fmuls f5,f18,f9
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// fmuls f3,f17,f9
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// fmuls f31,f21,f9
	ctx.f31.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// fmuls f21,f16,f9
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// fadds f18,f5,f30
	ctx.f18.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// stfsx f18,r9,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// stfsx f5,r30,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f18,f4,f10
	ctx.f18.f64 = double(float(ctx.f4.f64 - ctx.f10.f64));
	// fsubs f5,f28,f3
	ctx.f5.f64 = double(float(ctx.f28.f64 - ctx.f3.f64));
	// stfsx f5,r30,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f3,f28
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f28.f64));
	// stfsx f5,r9,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f5,f23,f31
	ctx.f5.f64 = double(float(ctx.f23.f64 - ctx.f31.f64));
	// stfsx f5,r31,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f31,f23
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f23.f64));
	// stfsx f5,r7,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f21,f29
	ctx.f5.f64 = double(float(ctx.f21.f64 + ctx.f29.f64));
	// stfsx f5,r7,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f5,f21,f29
	ctx.f5.f64 = double(float(ctx.f21.f64 - ctx.f29.f64));
	// lfs f28,-232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -232);
	ctx.f28.f64 = double(temp.f32);
	// lfs f23,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f3,f27,f1
	ctx.f3.f64 = double(float(ctx.f27.f64 - ctx.f1.f64));
	// stfsx f5,r31,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f30,f23,f28
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// fadds f5,f24,f6
	ctx.f5.f64 = double(float(ctx.f24.f64 + ctx.f6.f64));
	// lfs f29,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f31,f29,f12
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f12.f64));
	// fadds f1,f27,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// fsubs f2,f28,f23
	ctx.f2.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// fsubs f6,f24,f6
	ctx.f6.f64 = double(float(ctx.f24.f64 - ctx.f6.f64));
	// fadds f24,f4,f10
	ctx.f24.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fadds f12,f12,f29
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f29.f64));
	// fadds f29,f20,f13
	ctx.f29.f64 = double(float(ctx.f20.f64 + ctx.f13.f64));
	// fmuls f23,f3,f8
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// fmuls f25,f30,f8
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// fmuls f27,f5,f8
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// fmuls f21,f31,f8
	ctx.f21.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// fsubs f13,f13,f20
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f20.f64));
	// fmuls f20,f2,f7
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// fmuls f16,f2,f8
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// fmuls f17,f1,f8
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fmuls f15,f1,f7
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// fadds f28,f19,f26
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f26.f64));
	// fmsubs f5,f5,f7,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 - ctx.f23.f64));
	// fmsubs f4,f31,f7,f25
	ctx.f4.f64 = double(float(ctx.f31.f64 * ctx.f7.f64 - ctx.f25.f64));
	// fmadds f10,f3,f7,f27
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f7.f64 + ctx.f27.f64));
	// fmadds f2,f30,f7,f21
	ctx.f2.f64 = double(float(ctx.f30.f64 * ctx.f7.f64 + ctx.f21.f64));
	// fmuls f3,f24,f9
	ctx.f3.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// fmsubs f1,f12,f8,f20
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 - ctx.f20.f64));
	// fmuls f31,f18,f9
	ctx.f31.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// fmadds f30,f6,f7,f17
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f7.f64 + ctx.f17.f64));
	// fmadds f12,f12,f7,f16
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64 + ctx.f16.f64));
	// fmsubs f6,f6,f8,f15
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f8.f64 - ctx.f15.f64));
	// fadds f27,f4,f10
	ctx.f27.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fadds f24,f2,f5
	ctx.f24.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// fadds f25,f3,f22
	ctx.f25.f64 = double(float(ctx.f3.f64 + ctx.f22.f64));
	// fsubs f3,f22,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 - ctx.f3.f64));
	// fsubs f10,f4,f10
	ctx.f10.f64 = double(float(ctx.f4.f64 - ctx.f10.f64));
	// fsubs f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// fadds f4,f31,f11
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f11.f64));
	// fadds f2,f30,f1
	ctx.f2.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fadds f23,f6,f12
	ctx.f23.f64 = double(float(ctx.f6.f64 + ctx.f12.f64));
	// fadds f22,f27,f29
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfsx f22,r31,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// stfsx f29,r7,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// fsubs f29,f25,f24
	ctx.f29.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfsx f29,r7,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f24,f25
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfsx f29,r31,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fsubs f29,f3,f10
	ctx.f29.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// stfsx f29,r9,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f10,f10,f3
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f3.f64));
	// stfsx f10,r30,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f5,f13
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f13.f64));
	// stfsx f10,r30,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 - ctx.f13.f64));
	// stfsx f13,r9,r6
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f13,f2,f4
	ctx.f13.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// stfsx f13,r29,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fsubs f13,f2,f4
	ctx.f13.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// stfsx f13,r10,r6
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f13,f28,f23
	ctx.f13.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// stfsx f13,r10,r5
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f13,f26,f19
	ctx.f13.f64 = double(float(ctx.f26.f64 - ctx.f19.f64));
	// addic. r24,r24,-1
	ctx.xer.ca = ctx.r24.u32 > 0;
	ctx.r24.s64 = ctx.r24.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// fsubs f10,f1,f30
	ctx.f10.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// add r4,r27,r4
	ctx.r4.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fsubs f12,f6,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// fsubs f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f31.f64));
	// fadds f5,f23,f28
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// stfsx f5,r29,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fsubs f6,f13,f10
	ctx.f6.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// stfs f6,0(r5)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// stfs f13,0(r25)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fadds f13,f12,f11
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// stfs f13,0(r26)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fsubs f13,f12,f11
	ctx.f13.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// stfs f13,0(r6)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lwz r10,3532(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 3532);
	// subf r5,r27,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r27.s64;
	// subf r6,r27,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r27.s64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d42ec4
	if (!ctx.cr0.eq) goto loc_82D42EC4;
loc_82D4383C:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28f2c
	ctx.lr = 0x82D43844;
	__restfpr_14(ctx, base);
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D43848"))) PPC_WEAK_FUNC(sub_82D43848);
PPC_FUNC_IMPL(__imp__sub_82D43848) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-3608
	ctx.r5.s64 = ctx.r11.s64 + -3608;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,11888
	ctx.r4.s64 = ctx.r11.s64 + 11888;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D43860"))) PPC_WEAK_FUNC(sub_82D43860);
PPC_FUNC_IMPL(__imp__sub_82D43860) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D43868;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28ee0
	ctx.lr = 0x82D43870;
	__savefpr_14(ctx, base);
	// mulli r11,r9,24
	ctx.r11.s64 = ctx.r9.s64 * 24;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-24
	ctx.r11.s64 = ctx.r11.s64 + -24;
	// bge cr6,0x82d43b90
	if (!ctx.cr6.lt) goto loc_82D43B90;
	// subf r30,r9,r10
	ctx.r30.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f5,-3664(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -3664);
	ctx.f5.f64 = double(temp.f32);
	// lfs f0,-28552(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
loc_82D438A4:
	// lfs f13,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f8,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f8.f64 = double(temp.f32);
	// add r29,r10,r4
	ctx.r29.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lfs f9,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f31,f8,f12
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// lfs f7,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f30,f8,f13
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f6,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f2,f9,f13
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f1,f9,f12
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// lfs f11,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// fadds f29,f6,f7
	ctx.f29.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// lfs f3,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f26,f11,f13
	ctx.f26.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f4,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f27,f7,f6
	ctx.f27.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// lfs f10,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f25,f11,f12
	ctx.f25.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfsx f24,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f28,f4,f3
	ctx.f28.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// lfsx f23,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// lfsx f22,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f22.f64 = double(temp.f32);
	// add r28,r9,r6
	ctx.r28.u64 = ctx.r9.u64 + ctx.r6.u64;
	// lfsx f21,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// mulli r7,r8,12
	ctx.r7.s64 = ctx.r8.s64 * 12;
	// fadds f7,f31,f2
	ctx.f7.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// fsubs f6,f30,f1
	ctx.f6.f64 = double(float(ctx.f30.f64 - ctx.f1.f64));
	// fadds f1,f30,f1
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fsubs f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// fmuls f31,f29,f13
	ctx.f31.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// lfsx f19,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f30,f29,f12
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// lfsx f17,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f3,f10,f12,f26
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + ctx.f26.f64));
	// add r27,r9,r5
	ctx.r27.u64 = ctx.r9.u64 + ctx.r5.u64;
	// fmsubs f26,f10,f13,f25
	ctx.f26.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 - ctx.f25.f64));
	// lfs f25,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f29,f23,f22
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// add r26,r7,r6
	ctx.r26.u64 = ctx.r7.u64 + ctx.r6.u64;
	// add r25,r7,r5
	ctx.r25.u64 = ctx.r7.u64 + ctx.r5.u64;
	// lfs f20,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f12,f28,f12,f31
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f31.f64));
	// fmsubs f13,f28,f13,f30
	ctx.f13.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 - ctx.f30.f64));
	// fsubs f30,f25,f24
	ctx.f30.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// fadds f31,f24,f25
	ctx.f31.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fmuls f25,f11,f6
	ctx.f25.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// fadds f28,f22,f23
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fmuls f24,f11,f7
	ctx.f24.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fadds f15,f18,f19
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fmuls f23,f30,f1
	ctx.f23.f64 = double(float(ctx.f30.f64 * ctx.f1.f64));
	// fmsubs f25,f10,f7,f25
	ctx.f25.f64 = double(float(ctx.f10.f64 * ctx.f7.f64 - ctx.f25.f64));
	// fmuls f1,f28,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 * ctx.f1.f64));
	// fmadds f24,f10,f6,f24
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f6.f64 + ctx.f24.f64));
	// fmuls f22,f29,f25
	ctx.f22.f64 = double(float(ctx.f29.f64 * ctx.f25.f64));
	// fmuls f25,f31,f25
	ctx.f25.f64 = double(float(ctx.f31.f64 * ctx.f25.f64));
	// fmsubs f1,f30,f2,f1
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f2.f64 - ctx.f1.f64));
	// fmadds f2,f28,f2,f23
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f2.f64 + ctx.f23.f64));
	// fmsubs f31,f31,f24,f22
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f24.f64 - ctx.f22.f64));
	// fmadds f30,f29,f24,f25
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f24.f64 + ctx.f25.f64));
	// lfs f25,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fadds f22,f25,f21
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f21.f64));
	// fsubs f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// lfsx f21,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f24,f27,f1
	ctx.f24.f64 = double(float(ctx.f27.f64 - ctx.f1.f64));
	// fsubs f29,f12,f31
	ctx.f29.f64 = double(float(ctx.f12.f64 - ctx.f31.f64));
	// fadds f28,f30,f13
	ctx.f28.f64 = double(float(ctx.f30.f64 + ctx.f13.f64));
	// fmuls f14,f22,f8
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// fmuls f16,f25,f6
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// stfs f16,-224(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -224, temp.u32);
	// fsubs f16,f21,f20
	ctx.f16.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f20,f20,f21
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f21,f19,f18
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f21,-220(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -220, temp.u32);
	// fsubs f23,f28,f29
	ctx.f23.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// fadds f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fsubs f28,f4,f2
	ctx.f28.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fmuls f8,f16,f8
	ctx.f8.f64 = double(float(ctx.f16.f64 * ctx.f8.f64));
	// lfs f21,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f20,f6
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// fsubs f19,f17,f21
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// fadds f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// fsubs f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f30.f64));
	// fadds f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f31.f64));
	// fmsubs f8,f22,f9,f8
	ctx.f8.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 - ctx.f8.f64));
	// fmadds f9,f16,f9,f14
	ctx.f9.f64 = double(float(ctx.f16.f64 * ctx.f9.f64 + ctx.f14.f64));
	// lfs f14,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f6,f20,f7,f14
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f14.f64));
	// fmuls f22,f15,f10
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// fmsubs f7,f25,f7,f18
	ctx.f7.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 - ctx.f18.f64));
	// lfs f25,-220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -220);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f10,f19,f10
	ctx.f10.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// fmuls f20,f25,f26
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fmuls f18,f21,f26
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f26.f64));
	// fmsubs f10,f15,f11,f10
	ctx.f10.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 - ctx.f10.f64));
	// fmadds f11,f19,f11,f22
	ctx.f11.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 + ctx.f22.f64));
	// fmadds f26,f21,f3,f20
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 + ctx.f20.f64));
	// fmsubs f3,f25,f3,f18
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 - ctx.f18.f64));
	// fsubs f25,f10,f8
	ctx.f25.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// fsubs f22,f9,f11
	ctx.f22.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// fsubs f21,f6,f26
	ctx.f21.f64 = double(float(ctx.f6.f64 - ctx.f26.f64));
	// fsubs f20,f7,f3
	ctx.f20.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// fadds f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f8.f64));
	// fadds f8,f6,f26
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f26.f64));
	// fadds f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f9.f64));
	// fadds f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// fadds f3,f1,f27
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// fadds f9,f2,f4
	ctx.f9.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fadds f19,f22,f25
	ctx.f19.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// fsubs f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// fsubs f22,f24,f21
	ctx.f22.f64 = double(float(ctx.f24.f64 - ctx.f21.f64));
	// fadds f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// fsubs f21,f28,f20
	ctx.f21.f64 = double(float(ctx.f28.f64 - ctx.f20.f64));
	// fadds f20,f20,f28
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f28.f64));
	// fsubs f4,f13,f11
	ctx.f4.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// fadds f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fadds f11,f12,f10
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// fsubs f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// fadds f10,f8,f9
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fadds f17,f29,f25
	ctx.f17.f64 = double(float(ctx.f29.f64 + ctx.f25.f64));
	// fmuls f28,f22,f0
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fsubs f18,f25,f29
	ctx.f18.f64 = double(float(ctx.f25.f64 - ctx.f29.f64));
	// fmuls f22,f21,f0
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fmuls f21,f20,f0
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fadds f20,f23,f19
	ctx.f20.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// fsubs f19,f23,f19
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// fmuls f24,f24,f0
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fmuls f23,f17,f5
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f5.f64));
	// fmuls f25,f18,f5
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f5.f64));
	// fmuls f29,f20,f5
	ctx.f29.f64 = double(float(ctx.f20.f64 * ctx.f5.f64));
	// fmuls f20,f19,f5
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f5.f64));
	// fadds f6,f21,f23
	ctx.f6.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fadds f19,f29,f28
	ctx.f19.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// stfsx f19,r9,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f6,r9,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f6,f29,f28
	ctx.f6.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// stfsx f6,r10,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f6,f21,f23
	ctx.f6.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// stfsx f6,r10,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f6,f22,f20
	ctx.f6.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f6,0(r5)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f6,f25,f24
	ctx.f6.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfs f6,0(r6)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f6,f22,f20
	ctx.f6.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfsx f6,r7,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f25,f24
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// stfsx f6,r7,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fadds f6,f3,f7
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// fsubs f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// subf r5,r31,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r31.s64;
	// subf r6,r31,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r31.s64;
	// fadds f3,f10,f11
	ctx.f3.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fadds f8,f4,f6
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fsubs f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fsubs f4,f12,f7
	ctx.f4.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// fsubs f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f11.f64));
	// fsubs f10,f9,f13
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// fadds f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// fadds f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f7.f64));
	// fmuls f9,f8,f0
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// stfs f9,0(r4)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmuls f7,f3,f0
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// stfs f7,0(r3)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f9,f6,f0
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// stfs f9,0(r26)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fmuls f8,f4,f0
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// stfs f11,0(r25)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fmuls f11,f10,f0
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// stfs f11,0(r27)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// stfs f8,0(r28)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfsx f13,r10,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f12,0(r29)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// lwz r10,3532(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 3532);
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d438a4
	if (!ctx.cr0.eq) goto loc_82D438A4;
loc_82D43B90:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f2c
	ctx.lr = 0x82D43B98;
	__restfpr_14(ctx, base);
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D43BA0"))) PPC_WEAK_FUNC(sub_82D43BA0);
PPC_FUNC_IMPL(__imp__sub_82D43BA0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-3544
	ctx.r5.s64 = ctx.r11.s64 + -3544;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,14432
	ctx.r4.s64 = ctx.r11.s64 + 14432;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D43BB8"))) PPC_WEAK_FUNC(sub_82D43BB8);
PPC_FUNC_IMPL(__imp__sub_82D43BB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// stfd f29,-40(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -40, ctx.f29.u64);
	// stfd f30,-32(r1)
	PPC_STORE_U64(ctx.r1.u32 + -32, ctx.f30.u64);
	// stfd f31,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.f31.u64);
	// rlwinm r11,r9,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// addi r7,r11,-16
	ctx.r7.s64 = ctx.r11.s64 + -16;
	// bge cr6,0x82d43d34
	if (!ctx.cr6.lt) goto loc_82D43D34;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f0,-28552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
loc_82D43BF8:
	// lfs f8,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fadds f5,f8,f9
	ctx.f5.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// lfs f13,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,8(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// add r9,r11,r4
	ctx.r9.u64 = ctx.r11.u64 + ctx.r4.u64;
	// lfs f12,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f3,f11,f13
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f6,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f2,f11,f12
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f7,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fsubs f4,f7,f6
	ctx.f4.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// lfs f10,12(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// fadds f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// lfs f31,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f1,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f1.f64 = double(temp.f32);
	// addi r7,r7,16
	ctx.r7.s64 = ctx.r7.s64 + 16;
	// fmuls f30,f5,f12
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f5,f5,f13
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmadds f8,f10,f12,f3
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + ctx.f3.f64));
	// lfsx f3,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f6,f10,f13,f2
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 - ctx.f2.f64));
	// lfsx f2,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f13,f4,f13,f30
	ctx.f13.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 - ctx.f30.f64));
	// fmadds f12,f4,f12,f5
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f5.f64));
	// fsubs f4,f31,f3
	ctx.f4.f64 = double(float(ctx.f31.f64 - ctx.f3.f64));
	// fadds f5,f1,f2
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fadds f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f31.f64));
	// fsubs f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fmuls f29,f4,f6
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// fmuls f1,f5,f6
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fmuls f31,f3,f10
	ctx.f31.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmuls f30,f2,f10
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmsubs f10,f4,f8,f1
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 - ctx.f1.f64));
	// fmadds f6,f2,f11,f31
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f31.f64));
	// fmadds f8,f5,f8,f29
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f8.f64 + ctx.f29.f64));
	// fmsubs f11,f3,f11,f30
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 - ctx.f30.f64));
	// fadds f5,f10,f9
	ctx.f5.f64 = double(float(ctx.f10.f64 + ctx.f9.f64));
	// fsubs f4,f13,f6
	ctx.f4.f64 = double(float(ctx.f13.f64 - ctx.f6.f64));
	// fadds f13,f6,f13
	ctx.f13.f64 = double(float(ctx.f6.f64 + ctx.f13.f64));
	// fadds f3,f8,f7
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// fadds f6,f11,f12
	ctx.f6.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// fsubs f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// fsubs f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// fadds f7,f4,f5
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// fsubs f4,f3,f6
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// fadds f6,f6,f3
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// fsubs f3,f8,f13
	ctx.f3.f64 = double(float(ctx.f8.f64 - ctx.f13.f64));
	// fadds f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// fmuls f8,f7,f0
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// stfs f8,0(r4)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmuls f8,f5,f0
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// stfsx f8,r11,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fmuls f8,f4,f0
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// stfsx f8,r11,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fmuls f8,f6,f0
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// stfs f8,0(r3)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f8,f3,f0
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// stfs f8,0(r5)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfsx f13,r11,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fsubs f13,f9,f10
	ctx.f13.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// subf r5,r31,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r31.s64;
	// fadds f11,f12,f13
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fsubs f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// fmuls f12,f11,f0
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// stfs f12,0(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f13,0(r6)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lwz r11,3532(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// subf r6,r31,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r31.s64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bne 0x82d43bf8
	if (!ctx.cr0.eq) goto loc_82D43BF8;
loc_82D43D34:
	// lfd f29,-40(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// lfd f30,-32(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// lfd f31,-24(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r30,-16(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D43D50"))) PPC_WEAK_FUNC(sub_82D43D50);
PPC_FUNC_IMPL(__imp__sub_82D43D50) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-3480
	ctx.r5.s64 = ctx.r11.s64 + -3480;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,15288
	ctx.r4.s64 = ctx.r11.s64 + 15288;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D43D68"))) PPC_WEAK_FUNC(sub_82D43D68);
PPC_FUNC_IMPL(__imp__sub_82D43D68) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D43D70;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D43D78;
	__savefpr_14(ctx, base);
	// mulli r11,r9,248
	ctx.r11.s64 = ctx.r9.s64 * 248;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-248
	ctx.r11.s64 = ctx.r11.s64 + -248;
	// bge cr6,0x82d453ac
	if (!ctx.cr6.lt) goto loc_82D453AC;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// rlwinm r19,r7,2,0,29
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// stw r10,-344(r1)
	PPC_STORE_U32(ctx.r1.u32 + -344, ctx.r10.u32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lis r30,-32236
	ctx.r30.s64 = -2112618496;
	// lfs f6,-3640(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -3640);
	ctx.f6.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lfs f7,-3644(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -3644);
	ctx.f7.f64 = double(temp.f32);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lfs f8,-3648(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -3648);
	ctx.f8.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfs f9,-3652(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -3652);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,140(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,-3656(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -3656);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-3660(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -3660);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,-3664(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -3664);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,-28552(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
loc_82D43DE4:
	// rlwinm r7,r8,5,0,26
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f4,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// rlwinm r10,r8,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f24,f4,f5
	ctx.f24.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// lfs f2,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f29,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfs f3,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// mulli r9,r8,48
	ctx.r9.s64 = ctx.r8.s64 * 48;
	// lfsx f16,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f4,f3,f2
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f16,-544(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fadds f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfsx f16,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-532(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f30,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f23,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f2,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// rlwinm r31,r8,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f15,f29,f24
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f24.f64));
	// lfsx f22,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f30,f24
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f24.f64));
	// lfsx f24,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f20,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f21,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f18,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f19,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f17,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f16,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfs f31,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f31.f64 = double(temp.f32);
	// lfs f27,196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 196);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f30,f30,f4,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f4.f64 - ctx.f15.f64));
	// lfs f1,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f4,f29,f4,f14
	ctx.f4.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 + ctx.f14.f64));
	// lfs f28,192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 192);
	ctx.f28.f64 = double(temp.f32);
	// fadds f29,f23,f2
	ctx.f29.f64 = double(float(ctx.f23.f64 + ctx.f2.f64));
	// lfs f25,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f23.f64));
	// lfs f26,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f23,f22,f24
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// fadds f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// fadds f22,f20,f21
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fsubs f20,f19,f18
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f15,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f17,f15
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f14,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// fadds f15,f16,f14
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,-516(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// fmuls f14,f31,f23
	ctx.f14.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// fmuls f16,f31,f29
	ctx.f16.f64 = double(float(ctx.f31.f64 * ctx.f29.f64));
	// fmuls f31,f27,f22
	ctx.f31.f64 = double(float(ctx.f27.f64 * ctx.f22.f64));
	// stfs f31,-544(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fmuls f27,f27,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// fmadds f31,f1,f23,f16
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f23.f64 + ctx.f16.f64));
	// lfs f23,124(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 124);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f1,f1,f29,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 - ctx.f14.f64));
	// fmuls f14,f25,f18
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f18.f64));
	// lfs f16,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f29,f28,f20,f16
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f20.f64 + ctx.f16.f64));
	// lfs f20,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f25,f15
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f15.f64));
	// lfs f25,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f28,f28,f22,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 - ctx.f27.f64));
	// lfs f27,120(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 120);
	ctx.f27.f64 = double(temp.f32);
	// lfs f22,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f18,f26,f18,f16
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f18.f64 + ctx.f16.f64));
	// fadds f16,f29,f31
	ctx.f16.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// stfs f16,-508(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fadds f16,f28,f1
	ctx.f16.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// fsubs f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfs f1,-420(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f1,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f26,f26,f15,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f15.f64 - ctx.f14.f64));
	// fmuls f15,f23,f17
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// fsubs f31,f29,f31
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f31.f64));
	// fmuls f23,f23,f1
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f1.f64));
	// lfs f1,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f14,f20,f24
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f24.f64));
	// fmuls f29,f1,f19
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// stfs f29,-544(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fmuls f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// stfs f1,-532(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fmuls f20,f20,f2
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f2.f64));
	// mulli r29,r8,40
	ctx.r29.s64 = ctx.r8.s64 * 40;
	// fsubs f1,f30,f18
	ctx.f1.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// mulli r30,r8,24
	ctx.r30.s64 = ctx.r8.s64 * 24;
	// fsubs f28,f4,f26
	ctx.f28.f64 = double(float(ctx.f4.f64 - ctx.f26.f64));
	// fadds f29,f26,f4
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f4.f64));
	// lfs f4,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f4.f64 = double(temp.f32);
	// fmsubs f26,f27,f4,f15
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f4.f64 - ctx.f15.f64));
	// lfs f4,184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f27,f27,f17,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f17.f64 + ctx.f23.f64));
	// lfs f17,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f17.f64 = double(temp.f32);
	// fadds f30,f18,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 + ctx.f30.f64));
	// lfs f15,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f2,f22,f2,f14
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f2.f64 - ctx.f14.f64));
	// fmadds f24,f22,f24,f20
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f24.f64 + ctx.f20.f64));
	// lfsx f22,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f18,f1,f17
	ctx.f18.f64 = double(float(ctx.f1.f64 - ctx.f17.f64));
	// fadds f1,f17,f1
	ctx.f1.f64 = double(float(ctx.f17.f64 + ctx.f1.f64));
	// fadds f17,f29,f16
	ctx.f17.f64 = double(float(ctx.f29.f64 + ctx.f16.f64));
	// fsubs f29,f29,f16
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f16.f64));
	// fadds f16,f28,f31
	ctx.f16.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// mulli r28,r8,56
	ctx.r28.s64 = ctx.r8.s64 * 56;
	// fsubs f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 - ctx.f31.f64));
	// fsubs f28,f30,f15
	ctx.f28.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// fsubs f14,f3,f27
	ctx.f14.f64 = double(float(ctx.f3.f64 - ctx.f27.f64));
	// fadds f30,f15,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 + ctx.f30.f64));
	// fadds f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// fadds f15,f26,f5
	ctx.f15.f64 = double(float(ctx.f26.f64 + ctx.f5.f64));
	// fsubs f27,f5,f26
	ctx.f27.f64 = double(float(ctx.f5.f64 - ctx.f26.f64));
	// lfs f23,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f4,f21,f23
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f21.f64 - ctx.f23.f64));
	// lfs f20,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f4,f4,f19,f20
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f19.f64 + ctx.f20.f64));
	// lfsx f20,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f19,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f21,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f5,f2,f23
	ctx.f5.f64 = double(float(ctx.f2.f64 - ctx.f23.f64));
	// stfs f5,-312(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fadds f5,f4,f24
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f24.f64));
	// stfs f5,-340(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fsubs f5,f24,f4
	ctx.f5.f64 = double(float(ctx.f24.f64 - ctx.f4.f64));
	// stfs f5,-352(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fadds f24,f19,f20
	ctx.f24.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f5,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f4,f22,f21
	ctx.f4.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f26,f23,f2
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f2.f64));
	// fadds f2,f21,f22
	ctx.f2.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f21,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f23,f20,f19
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// lfs f20,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f22,f25,f24
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// fmuls f19,f25,f4
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// lfs f25,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f22,f5,f4,f22
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f4.f64 - ctx.f22.f64));
	// stfs f22,-536(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fmadds f5,f5,f24,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 + ctx.f19.f64));
	// stfs f5,-540(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// fmuls f5,f21,f2
	ctx.f5.f64 = double(float(ctx.f21.f64 * ctx.f2.f64));
	// lfs f22,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f24,f21,f23
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f23.f64));
	// lfsx f19,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-544(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfsx f19,r29,r5
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r5.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfs f4,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f21,r29,r6
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f19,-516(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// fmadds f5,f22,f23,f5
	ctx.f5.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 + ctx.f5.f64));
	// stfs f5,-520(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fmsubs f5,f22,f2,f24
	ctx.f5.f64 = double(float(ctx.f22.f64 * ctx.f2.f64 - ctx.f24.f64));
	// stfs f5,-524(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfsx f5,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f2,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f24,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f23,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f22,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f19,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// rlwinm r27,r8,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f19,-476(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fsubs f19,f5,f2
	ctx.f19.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// stfs f19,-504(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fadds f2,f2,f5
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// fadds f5,f23,f24
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfs f19,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// stfs f5,-532(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fsubs f23,f22,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f24,-508(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f21,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f21.f64 = double(temp.f32);
	// fadds f19,f19,f21
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfs f19,-512(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f19,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfs f21,-516(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// stfs f2,-420(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// stfs f23,-496(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// stfs f22,-492(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f21,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f4,f21
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// fmuls f4,f4,f5
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// lfs f5,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f19,f5,f2
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// fmuls f24,f5,f24
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// lfs f5,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f2,f5,f23
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// lfs f23,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// stfs f2,-544(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fmuls f5,f25,f22
	ctx.f5.f64 = double(float(ctx.f25.f64 * ctx.f22.f64));
	// lfs f22,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f22.f64));
	// lfs f22,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f4,f20,f22,f4
	ctx.f4.f64 = double(float(ctx.f20.f64 * ctx.f22.f64 - ctx.f4.f64));
	// lfs f22,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f22.f64 = double(temp.f32);
	// stfs f5,-532(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fmadds f2,f20,f22,f21
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f22.f64 + ctx.f21.f64));
	// lfs f22,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f22.f64 = double(temp.f32);
	// stfs f25,-508(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f5,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f25,f5,f22,f19
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 + ctx.f19.f64));
	// lfs f22,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f24,f5,f22,f24
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 - ctx.f24.f64));
	// lfs f5,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f5.f64 = double(temp.f32);
	// lfs f22,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f23,f5,f22,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 - ctx.f23.f64));
	// lfs f22,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f22,f5,f22,f21
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 + ctx.f21.f64));
	// lfs f5,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f5.f64 = double(temp.f32);
	// lfs f21,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f5,f21,f19
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f21.f64 + ctx.f19.f64));
	// lfs f19,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f5,f5,f20,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f20.f64 - ctx.f19.f64));
	// lfs f19,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-496(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f20,220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f20.f64 = double(temp.f32);
	// fadds f19,f21,f19
	ctx.f19.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// stfs f19,-424(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f19,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f5,f19
	ctx.f19.f64 = double(float(ctx.f5.f64 + ctx.f19.f64));
	// stfs f19,-380(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f19,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// lfs f19,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f5,f19,f5
	ctx.f5.f64 = double(float(ctx.f19.f64 - ctx.f5.f64));
	// lfs f19,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f23
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f23.f64));
	// stfs f19,-544(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f19,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f22
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// stfs f19,-532(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f19,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f19.f64 = double(temp.f32);
	// fadds f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// lfsx f19,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-508(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fsubs f19,f21,f5
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f5.f64));
	// fadds f5,f5,f21
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f21.f64));
	// stfs f5,-328(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f21,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f21.f64 = double(temp.f32);
	// stfs f23,-320(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f5,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f5.f64 = double(temp.f32);
	// stfs f19,-368(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fsubs f19,f5,f21
	ctx.f19.f64 = double(float(ctx.f5.f64 - ctx.f21.f64));
	// lfs f23,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f23.f64 = double(temp.f32);
	// fadds f5,f21,f5
	ctx.f5.f64 = double(float(ctx.f21.f64 + ctx.f5.f64));
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f5,-360(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// stfs f23,-316(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f5,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f23,r28,r6
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// stfs f19,-420(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// fsubs f21,f5,f23
	ctx.f21.f64 = double(float(ctx.f5.f64 - ctx.f23.f64));
	// lfsx f22,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f23,f23,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// stfs f21,-544(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// stfs f23,-492(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// fmuls f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f21.f64));
	// lfs f19,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f19.f64 = double(temp.f32);
	// fadds f5,f19,f22
	ctx.f5.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f5,-532(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// lfsx f19,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-536(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfsx f19,r27,r6
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-540(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfsx f19,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-524(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfsx f19,r27,r5
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r5.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-520(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// stfs f22,-508(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fmuls f20,f20,f5
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f5.f64));
	// lfs f5,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f19,f5,f22
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f22.f64));
	// fmuls f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// lfs f5,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f5.f64 = double(temp.f32);
	// lfs f22,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f5,f5,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f22.f64));
	// stfs f5,-480(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f22,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f22.f64 = double(temp.f32);
	// lfs f5,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f5,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f22.f64));
	// stfs f5,-476(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f22,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f22.f64 = double(temp.f32);
	// lfs f5,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f5,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f22.f64));
	// stfs f5,-428(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f22,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f22.f64 = double(temp.f32);
	// lfs f5,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f5,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f22.f64));
	// stfs f5,-432(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f5,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f5.f64 = double(temp.f32);
	// lfs f22,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f5,f22,f20
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 - ctx.f20.f64));
	// lfs f20,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f5,f5,f20,f21
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f20.f64 + ctx.f21.f64));
	// stfs f5,-540(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f21,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f21.f64 = double(temp.f32);
	// lfs f5,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f23,f5,f21,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f21.f64 + ctx.f23.f64));
	// stfs f23,-544(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f23,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f5,f5,f23,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 - ctx.f19.f64));
	// stfs f5,-536(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfs f23,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f23.f64 = double(temp.f32);
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// lfs f21,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f23,f21
	ctx.f20.f64 = double(float(ctx.f23.f64 * ctx.f21.f64));
	// fmuls f19,f5,f21
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f21.f64));
	// fsubs f21,f22,f4
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f4.f64));
	// stfs f21,-532(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f21,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f2
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f2.f64));
	// stfs f21,-508(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f21,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f21.f64 = double(temp.f32);
	// fadds f2,f21,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 + ctx.f2.f64));
	// lfs f21,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f21.f64 = double(temp.f32);
	// stfs f2,-324(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fadds f2,f21,f25
	ctx.f2.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// fsubs f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// lfs f21,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f24
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// stfs f21,-544(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fadds f4,f22,f4
	ctx.f4.f64 = double(float(ctx.f22.f64 + ctx.f4.f64));
	// stfs f4,-356(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfs f4,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f4.f64 = double(temp.f32);
	// mulli r25,r8,36
	ctx.r25.s64 = ctx.r8.s64 * 36;
	// fmsubs f5,f5,f4,f20
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f4.f64 - ctx.f20.f64));
	// stfs f5,-440(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fmadds f5,f23,f4,f19
	ctx.f5.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f19.f64));
	// stfs f5,-528(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f4,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f4.f64 = double(temp.f32);
	// mulli r24,r8,20
	ctx.r24.s64 = ctx.r8.s64 * 20;
	// lfs f5,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f5.f64 = double(temp.f32);
	// fadds f23,f5,f4
	ctx.f23.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// lfs f21,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// stfs f5,-364(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f5,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f5.f64 = double(temp.f32);
	// fadds f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// fadds f4,f2,f5
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// stfs f4,-448(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// fsubs f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 - ctx.f5.f64));
	// stfs f5,-444(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f21,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f20.f64 = double(temp.f32);
	// stfs f23,-508(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f2,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f2.f64 = double(temp.f32);
	// lfs f23,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f23.f64 = double(temp.f32);
	// mulli r26,r8,52
	ctx.r26.s64 = ctx.r8.s64 * 52;
	// lfs f22,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f22.f64 = double(temp.f32);
	// lfs f5,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f5.f64 = double(temp.f32);
	// fadds f4,f25,f5
	ctx.f4.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// stfs f4,-332(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f5,f5,f25
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f25.f64));
	// stfs f5,-336(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f5,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f5.f64 = double(temp.f32);
	// fadds f4,f24,f5
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f5.f64));
	// stfs f4,-400(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f4,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f5,f24,f5
	ctx.f5.f64 = double(float(ctx.f24.f64 - ctx.f5.f64));
	// fmuls f19,f4,f21
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// stfs f5,-404(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f5,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f4,f20
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f20.f64));
	// lfs f25,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f20,f5,f20,f19
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64 + ctx.f19.f64));
	// lfsx f19,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-540(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// fmsubs f5,f5,f21,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f21.f64 - ctx.f4.f64));
	// lfsx f19,r25,r6
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-544(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfsx f19,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-532(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfsx f19,r25,r5
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r5.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-536(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfsx f19,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f5,-516(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// stfs f19,-504(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfsx f4,r26,r6
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r6.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f5,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f19,r24,r6
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f20,-424(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// stfs f19,-480(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fsubs f19,f5,f4
	ctx.f19.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfsx f20,r26,r5
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r5.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// lfsx f21,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fadds f4,f20,f21
	ctx.f4.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f19,-524(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f5,-476(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// stfs f4,-496(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// stfs f21,-492(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f20,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f4,f25,f4
	ctx.f4.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// fsubs f19,f19,f20
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfs f19,-520(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f19,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f19.f64 = double(temp.f32);
	// mulli r22,r8,60
	ctx.r22.s64 = ctx.r8.s64 * 60;
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// stfs f20,-512(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f20,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f20.f64 = double(temp.f32);
	// add r18,r22,r4
	ctx.r18.u64 = ctx.r22.u64 + ctx.r4.u64;
	// lfs f19,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f20
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfs f19,-540(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f19,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// lfs f19,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f25,f19
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// stfs f20,-544(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fmuls f25,f24,f5
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// add r17,r22,r3
	ctx.r17.u64 = ctx.r22.u64 + ctx.r3.u64;
	// fmuls f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f21.f64));
	// fmuls f20,f22,f20
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// lfs f5,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f23,f5
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// lfs f5,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f23,f23,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// lfs f5,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f22,f5
	ctx.f5.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// stfs f5,-532(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f22,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f4,f2,f22,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 - ctx.f4.f64));
	// lfs f22,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f2,f2,f22,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 + ctx.f19.f64));
	// lfs f5,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f5.f64 = double(temp.f32);
	// lfs f22,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f25,f5,f22,f25
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 + ctx.f25.f64));
	// lfs f22,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f24,f5,f22,f24
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 - ctx.f24.f64));
	// lfs f5,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f5.f64 = double(temp.f32);
	// lfs f22,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f23,f5,f22,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 - ctx.f23.f64));
	// lfs f22,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f5,f22,f21
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 + ctx.f21.f64));
	// lfs f5,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f5.f64 = double(temp.f32);
	// lfs f21,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f5,f21,f19
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f21.f64 + ctx.f19.f64));
	// lfs f19,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f5,f5,f19,f20
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f19.f64 - ctx.f20.f64));
	// lfs f20,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-532(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f20,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f20
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfs f19,-524(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f19,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// stfs f20,-520(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f20,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f20.f64 = double(temp.f32);
	// fadds f19,f21,f20
	ctx.f19.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f19,-428(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f19,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f19,f5,f19
	ctx.f19.f64 = double(float(ctx.f5.f64 + ctx.f19.f64));
	// lfs f20,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f20.f64 = double(temp.f32);
	// stfs f19,-376(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fsubs f5,f20,f5
	ctx.f5.f64 = double(float(ctx.f20.f64 - ctx.f5.f64));
	// lfs f19,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f19,f19,f22
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// stfs f19,-480(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fsubs f19,f20,f23
	ctx.f19.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// fadds f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// stfs f23,-464(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f23,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfsx f22,r24,r5
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r5.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f23,-468(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfsx f23,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// stfs f19,-436(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// stfs f22,-544(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f22,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f22,f20
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// lfs f22,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f22,f19
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// fsubs f22,f21,f5
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f5.f64));
	// stfs f22,-476(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fadds f5,f5,f21
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f21.f64));
	// lfsx f21,r22,r6
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,-528(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f21,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,-540(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f22,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f22.f64 = double(temp.f32);
	// stfs f5,-424(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// fadds f5,f22,f23
	ctx.f5.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfsx f21,r22,r5
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f21,-536(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfs f22,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-544(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f21,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f21.f64 = double(temp.f32);
	// stfs f5,-496(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// stfs f23,-492(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// lfs f5,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// lfs f23,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfs f23,-512(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f22,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// stfs f23,-504(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f22,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f22.f64 = double(temp.f32);
	// stfs f5,-544(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f23,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// stfs f23,-488(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f22,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f23,-536(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfs f23,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f5,f23,f22,f21
	ctx.f5.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 - ctx.f21.f64));
	// lfs f22,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f23,f23,f22,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 + ctx.f20.f64));
	// lfs f21,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f21,f22,f19
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f22.f64 + ctx.f19.f64));
	// lfs f20,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f21,f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 - ctx.f19.f64));
	// stfs f21,-528(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f21,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f21,f20
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f20.f64));
	// lfs f19,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f21,f19
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f19.f64));
	// fsubs f21,f5,f4
	ctx.f21.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfs f21,-544(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fsubs f21,f23,f2
	ctx.f21.f64 = double(float(ctx.f23.f64 - ctx.f2.f64));
	// stfs f21,-540(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// fadds f2,f23,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 + ctx.f2.f64));
	// lfs f23,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f23.f64 = double(temp.f32);
	// fadds f4,f5,f4
	ctx.f4.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// lfs f5,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f5.f64 = double(temp.f32);
	// fadds f21,f22,f25
	ctx.f21.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// stfs f21,-532(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fsubs f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// stfs f4,-456(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// stfs f2,-500(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// fmsubs f23,f5,f23,f20
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 - ctx.f20.f64));
	// stfs f23,-472(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f23,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f5,f5,f23,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 + ctx.f19.f64));
	// lfs f21,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f21,f24,f21
	ctx.f21.f64 = double(float(ctx.f24.f64 - ctx.f21.f64));
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f5,-516(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// mulli r20,r8,28
	ctx.r20.s64 = ctx.r8.s64 * 28;
	// lfs f23,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f23.f64 = double(temp.f32);
	// add r14,r20,r4
	ctx.r14.u64 = ctx.r20.u64 + ctx.r4.u64;
	// lfs f5,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f5.f64 = double(temp.f32);
	// fadds f22,f23,f5
	ctx.f22.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// stfs f22,-380(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fsubs f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f23.f64));
	// stfs f5,-496(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f23,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f23.f64 = double(temp.f32);
	// lfs f5,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f5.f64 = double(temp.f32);
	// fadds f22,f23,f5
	ctx.f22.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// lfs f20,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f5,f23,f5
	ctx.f5.f64 = double(float(ctx.f23.f64 - ctx.f5.f64));
	// stfs f5,-348(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fadds f5,f25,f21
	ctx.f5.f64 = double(float(ctx.f25.f64 + ctx.f21.f64));
	// stfs f5,-492(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// fsubs f5,f21,f25
	ctx.f5.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// stfs f5,-480(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f5,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f5.f64 = double(temp.f32);
	// mulli r21,r8,44
	ctx.r21.s64 = ctx.r8.s64 * 44;
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfs f5,-432(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f5,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f5.f64 = double(temp.f32);
	// stw r14,-544(r1)
	PPC_STORE_U32(ctx.r1.u32 + -544, ctx.r14.u32);
	// fsubs f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// stfs f5,-440(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f5,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f5.f64 = double(temp.f32);
	// fadds f4,f24,f5
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f5.f64));
	// stfs f4,-396(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fsubs f5,f24,f5
	ctx.f5.f64 = double(float(ctx.f24.f64 - ctx.f5.f64));
	// stfs f5,-376(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f4,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f4.f64 = double(temp.f32);
	// mulli r23,r8,12
	ctx.r23.s64 = ctx.r8.s64 * 12;
	// lfs f5,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f2,f5,f4
	ctx.f2.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfs f21,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f21.f64 = double(temp.f32);
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// lfs f4,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f19,f4,f21
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// stfs f5,-532(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f5,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f4,f20
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f20.f64));
	// stfs f22,-484(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// stfs f2,-428(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// add r14,r20,r3
	ctx.r14.u64 = ctx.r20.u64 + ctx.r3.u64;
	// lfs f2,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f2.f64 = double(temp.f32);
	// add r16,r21,r4
	ctx.r16.u64 = ctx.r21.u64 + ctx.r4.u64;
	// lfs f25,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f25.f64 = double(temp.f32);
	// add r15,r21,r3
	ctx.r15.u64 = ctx.r21.u64 + ctx.r3.u64;
	// lfs f24,180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 180);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f20,f5,f20,f19
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64 + ctx.f19.f64));
	// lfsx f19,r20,r6
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-528(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// fmsubs f5,f5,f21,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f21.f64 - ctx.f4.f64));
	// lfsx f19,r20,r5
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r5.u32);
	ctx.f19.f64 = double(temp.f32);
	// stw r14,-488(r1)
	PPC_STORE_U32(ctx.r1.u32 + -488, ctx.r14.u32);
	// stfs f19,-540(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfsx f19,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-408(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// stfs f5,-504(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f5,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r21,r6
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r6.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f19,r23,r6
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f20,-436(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// stfs f19,-512(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fsubs f19,f5,f4
	ctx.f19.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfsx f20,r21,r5
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r5.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f4,f4,f5
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// lfs f21,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// stfs f19,-536(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fadds f19,f20,f21
	ctx.f19.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f4,-416(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// stfs f19,-460(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// stfs f21,-412(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lwz r14,-544(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	// lfs f5,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// lfs f20,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f5,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 - ctx.f20.f64));
	// lwz r14,-488(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	// stfs f20,-524(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f20,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f20.f64 = double(temp.f32);
	// fadds f5,f20,f5
	ctx.f5.f64 = double(float(ctx.f20.f64 + ctx.f5.f64));
	// stfs f5,-520(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f20,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f20.f64 = double(temp.f32);
	// lfs f5,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fadds f20,f20,f5
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f5.f64));
	// stfs f20,-528(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f20,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f5,f5,f20
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f20.f64));
	// lfs f20,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f25,f20
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f20.f64));
	// stfs f5,-488(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// fmuls f25,f25,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// fmuls f19,f24,f4
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f4.f64));
	// fmuls f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f21.f64));
	// fmuls f5,f22,f5
	ctx.f5.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// lfs f4,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f21,f23,f4
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// lfs f4,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// lfs f4,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f22,f4
	ctx.f4.f64 = double(float(ctx.f22.f64 * ctx.f4.f64));
	// lfs f22,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f22.f64 = double(temp.f32);
	// stfs f4,-540(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// fmsubs f4,f2,f22,f25
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 - ctx.f25.f64));
	// lfs f25,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f25.f64 = double(temp.f32);
	// stfs f5,-460(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fmadds f2,f2,f25,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64 + ctx.f20.f64));
	// lfs f5,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f5.f64 = double(temp.f32);
	// lfs f22,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f22.f64 = double(temp.f32);
	// lfs f25,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f24,f5,f22,f24
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 - ctx.f24.f64));
	// fmadds f25,f5,f25,f19
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f25.f64 + ctx.f19.f64));
	// lfs f22,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f22.f64 = double(temp.f32);
	// lfs f5,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f23,f5,f22,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 - ctx.f23.f64));
	// lfs f22,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f5,f22,f21
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 + ctx.f21.f64));
	// lfs f5,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f5.f64 = double(temp.f32);
	// lfs f21,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f21,f5,f21,f20
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f21.f64 + ctx.f20.f64));
	// lfs f20,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f5,f5,f20,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f20.f64 - ctx.f19.f64));
	// lfs f20,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f20
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfs f19,-528(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f19,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// lfs f19,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f21,f19
	ctx.f19.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// stfs f19,-536(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfs f19,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f5,f19
	ctx.f19.f64 = double(float(ctx.f5.f64 + ctx.f19.f64));
	// stfs f19,-524(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f19,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f23,f19
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// stfs f19,-408(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f19,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f22,f19
	ctx.f19.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// stfs f19,-540(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f19,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f5,f19,f5
	ctx.f5.f64 = double(float(ctx.f19.f64 - ctx.f5.f64));
	// stfs f5,-416(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f5,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f5,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f22.f64));
	// stfs f5,-412(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f5,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f21,f5
	ctx.f5.f64 = double(float(ctx.f21.f64 - ctx.f5.f64));
	// stfs f5,-460(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f5,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f23.f64));
	// stfs f5,-488(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f5,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f5.f64 = double(temp.f32);
	// lfs f23,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f23.f64 = double(temp.f32);
	// fadds f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f23.f64));
	// lfs f21,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f21.f64 = double(temp.f32);
	// stfs f5,-456(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// fadds f5,f21,f18
	ctx.f5.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// lfs f19,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// lfs f22,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f22.f64 = double(temp.f32);
	// stfs f21,-520(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// lfs f21,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f19.f64 = double(temp.f32);
	// fadds f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// stfs f21,-472(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfsx f21,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,-500(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfsx f21,r23,r5
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,-448(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f23,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f17,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 - ctx.f23.f64));
	// lfs f21,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f21,f19
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f19.f64));
	// lfs f21,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f21,f20
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f20.f64));
	// fsubs f21,f5,f23
	ctx.f21.f64 = double(float(ctx.f5.f64 - ctx.f23.f64));
	// stfs f21,-504(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fadds f5,f23,f5
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// stfs f5,-516(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// fadds f5,f26,f15
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f15.f64));
	// fadds f23,f5,f22
	ctx.f23.f64 = double(float(ctx.f5.f64 + ctx.f22.f64));
	// stfs f23,-512(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fsubs f5,f5,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f22.f64));
	// stfs f5,-452(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f23,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f5,f23,f22
	ctx.f5.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f23,-500(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f22,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f22,f5
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// lfs f22,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f23
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// lfs f23,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f5,f23,f5,f19
	ctx.f5.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f19.f64));
	// lfs f19,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f23,f23,f19,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f19.f64 - ctx.f21.f64));
	// lfs f21,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f22,f21,f20,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 - ctx.f22.f64));
	// fadds f19,f23,f24
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfs f20,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f21,f21,f20,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f18.f64));
	// fadds f18,f22,f4
	ctx.f18.f64 = double(float(ctx.f22.f64 + ctx.f4.f64));
	// stfs f18,-468(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fsubs f4,f22,f4
	ctx.f4.f64 = double(float(ctx.f22.f64 - ctx.f4.f64));
	// lfs f22,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f22.f64 = double(temp.f32);
	// fadds f20,f5,f25
	ctx.f20.f64 = double(float(ctx.f5.f64 + ctx.f25.f64));
	// fsubs f5,f25,f5
	ctx.f5.f64 = double(float(ctx.f25.f64 - ctx.f5.f64));
	// fsubs f25,f23,f24
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// lfs f24,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f19,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// fadds f18,f21,f2
	ctx.f18.f64 = double(float(ctx.f21.f64 + ctx.f2.f64));
	// fsubs f2,f21,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 - ctx.f2.f64));
	// fadds f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// lfs f21,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f21,-500(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f21,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f21,-464(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f21,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f21,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f21,-528(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f21,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfs f21,-436(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f21,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f21.f64 = double(temp.f32);
	// fadds f20,f5,f21
	ctx.f20.f64 = double(float(ctx.f5.f64 + ctx.f21.f64));
	// stfs f20,-392(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fsubs f5,f21,f5
	ctx.f5.f64 = double(float(ctx.f21.f64 - ctx.f5.f64));
	// stfs f5,-304(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f5,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f5,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f19.f64));
	// stfs f5,-468(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f5,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f5.f64 = double(temp.f32);
	// fadds f21,f4,f5
	ctx.f21.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// stfs f21,-388(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfs f5,-536(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfs f5,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f4,f5,f25
	ctx.f4.f64 = double(float(ctx.f5.f64 - ctx.f25.f64));
	// stfs f4,-372(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// fadds f5,f25,f5
	ctx.f5.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// stfs f5,-308(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f5,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f4,f5,f2
	ctx.f4.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// stfs f4,-384(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fadds f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// lfs f2,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f4.f64 = double(temp.f32);
	// stfs f5,-540(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// fsubs f4,f23,f4
	ctx.f4.f64 = double(float(ctx.f23.f64 - ctx.f4.f64));
	// fsubs f5,f2,f24
	ctx.f5.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// lfs f21,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f21.f64 = double(temp.f32);
	// fadds f2,f24,f2
	ctx.f2.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// lfs f24,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f24.f64 = double(temp.f32);
	// fadds f25,f21,f24
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// lfs f20,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f21.f64));
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfs f19,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f5,f4
	ctx.f20.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// fsubs f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// fsubs f4,f19,f2
	ctx.f4.f64 = double(float(ctx.f19.f64 - ctx.f2.f64));
	// fadds f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// lfs f19,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f3.f64));
	// stfs f19,-484(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f19,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f18.f64 = double(temp.f32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f23,-448(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f23,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f17.f64));
	// stfs f23,-500(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f18,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f18.f64 = double(temp.f32);
	// lfs f23,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// stfs f23,-456(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f23,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f23.f64 = double(temp.f32);
	// fadds f18,f23,f25
	ctx.f18.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// stfs f18,-408(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// fsubs f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f25.f64));
	// stfs f25,-488(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f25,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f25.f64 = double(temp.f32);
	// lfs f23,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f23.f64 = double(temp.f32);
	// fadds f18,f25,f20
	ctx.f18.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// fadds f17,f23,f5
	ctx.f17.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// fsubs f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 - ctx.f23.f64));
	// lfs f5,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// lfs f20,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f5,f20,f5
	ctx.f5.f64 = double(float(ctx.f20.f64 - ctx.f5.f64));
	// stfs f5,-412(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f5,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f5,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f22.f64));
	// stfs f5,-416(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f5,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f5.f64 = double(temp.f32);
	// lfs f20,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f5,f20,f5
	ctx.f5.f64 = double(float(ctx.f20.f64 - ctx.f5.f64));
	// stfs f5,-396(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f20,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f20.f64 = double(temp.f32);
	// lfs f5,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f20,f5
	ctx.f5.f64 = double(float(ctx.f20.f64 - ctx.f5.f64));
	// stfs f5,-400(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fmuls f20,f17,f11
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// stfs f20,-520(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fmuls f5,f18,f11
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// fmuls f25,f25,f11
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// stfs f25,-512(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fmuls f25,f23,f11
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// stfs f25,-524(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f25,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f25.f64 = double(temp.f32);
	// fadds f23,f19,f25
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f25.f64));
	// stfs f23,-484(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fsubs f25,f25,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f19.f64));
	// stfs f25,-460(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f23,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f23.f64 = double(temp.f32);
	// lfs f25,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f25.f64 = double(temp.f32);
	// fadds f20,f23,f25
	ctx.f20.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// stfs f20,-448(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// stfs f25,-500(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f25,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f25.f64 = double(temp.f32);
	// lfs f23,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f23.f64 = double(temp.f32);
	// fadds f20,f23,f25
	ctx.f20.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// fsubs f23,f25,f23
	ctx.f23.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// lfs f25,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f25.f64 = double(temp.f32);
	// fadds f19,f25,f4
	ctx.f19.f64 = double(float(ctx.f25.f64 + ctx.f4.f64));
	// fsubs f18,f4,f25
	ctx.f18.f64 = double(float(ctx.f4.f64 - ctx.f25.f64));
	// lfs f25,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f25.f64 = double(temp.f32);
	// lfs f4,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f4.f64 = double(temp.f32);
	// fadds f17,f25,f4
	ctx.f17.f64 = double(float(ctx.f25.f64 + ctx.f4.f64));
	// fsubs f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f25.f64));
	// stfs f4,-452(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fmuls f4,f20,f0
	ctx.f4.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmuls f25,f23,f0
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f23,f19,f0
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f23,0(r4)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmuls f23,f18,f0
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfsx f23,r22,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fmuls f20,f17,f11
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// stfs f20,-456(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f20,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f11
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// stfs f20,-464(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f20,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f23,f20,f13,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f23.f64));
	// lfs f20,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f20.f64 = double(temp.f32);
	// stfs f23,-472(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fadds f23,f20,f21
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// lfs f20,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f20.f64 = double(temp.f32);
	// fadds f19,f20,f24
	ctx.f19.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// fsubs f18,f20,f24
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// lfs f20,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f20.f64 = double(temp.f32);
	// lfs f24,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f24.f64 = double(temp.f32);
	// fadds f17,f24,f20
	ctx.f17.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// fsubs f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// fmuls f20,f19,f0
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f20,-452(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fmuls f20,f18,f0
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f20,-484(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fadds f19,f5,f4
	ctx.f19.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// fsubs f18,f5,f4
	ctx.f18.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfs f5,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f20,f17,f0
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fadds f17,f5,f25
	ctx.f17.f64 = double(float(ctx.f5.f64 + ctx.f25.f64));
	// fsubs f25,f5,f25
	ctx.f25.f64 = double(float(ctx.f5.f64 - ctx.f25.f64));
	// lfs f5,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f4,f23,f5
	ctx.f4.f64 = double(float(ctx.f23.f64 - ctx.f5.f64));
	// fadds f5,f23,f5
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// fsubs f23,f21,f2
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f2.f64));
	// fadds f2,f21,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 + ctx.f2.f64));
	// fmuls f24,f24,f0
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// stfsx f4,r22,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r5.u32, temp.u32);
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// stfs f5,0(r3)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f5,f23,f0
	ctx.f5.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfsx f5,r20,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r5.u32, temp.u32);
	// fmuls f5,f2,f0
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfsx f5,r7,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// lfs f5,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f5.f64 = double(temp.f32);
	// stfsx f20,r7,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f2,f4,f5
	ctx.f2.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// stfsx f24,r20,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r6.u32, temp.u32);
	// fadds f24,f5,f4
	ctx.f24.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// stfsx f19,r10,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfsx f18,r21,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r6.u32, temp.u32);
	// lfs f4,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f5.f64 = double(temp.f32);
	// stfsx f2,r21,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r5.u32, temp.u32);
	// fsubs f23,f4,f5
	ctx.f23.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// stfsx f24,r10,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// stfsx f23,r23,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// stfsx f5,r9,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f4,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfs f2,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f4,f15,f26
	ctx.f4.f64 = double(float(ctx.f15.f64 - ctx.f26.f64));
	// lfs f26,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f26.f64 = double(temp.f32);
	// stfsx f17,r9,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f26.f64));
	// stfsx f25,r23,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// lfs f25,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f26.f64 = double(temp.f32);
	// lfs f19,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f19.f64 = double(temp.f32);
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// fadds f25,f19,f1
	ctx.f25.f64 = double(float(ctx.f19.f64 + ctx.f1.f64));
	// lfs f20,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f1,f1,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f19.f64));
	// stfs f1,-444(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fsubs f1,f29,f20
	ctx.f1.f64 = double(float(ctx.f29.f64 - ctx.f20.f64));
	// stfs f1,-484(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fadds f24,f20,f29
	ctx.f24.f64 = double(float(ctx.f20.f64 + ctx.f29.f64));
	// lfs f29,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f29,f12
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// lfs f20,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f18.f64 = double(temp.f32);
	// lfs f23,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f3,f3,f23
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f23.f64));
	// lfs f21,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// lfs f21,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f15,f25,f13
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// lfs f18,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f1,f1,f12
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// stfs f1,-404(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// fmuls f19,f24,f13
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// fmsubs f29,f20,f13,f29
	ctx.f29.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f29.f64));
	// stfs f29,-432(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fadds f29,f4,f5
	ctx.f29.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// stfs f5,-452(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fmuls f20,f26,f12
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// fadds f18,f23,f3
	ctx.f18.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// fmuls f26,f26,f13
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fsubs f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 - ctx.f23.f64));
	// fmsubs f1,f25,f12,f19
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f12.f64 - ctx.f19.f64));
	// fmadds f25,f24,f12,f15
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 + ctx.f15.f64));
	// fmuls f5,f29,f0
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmadds f4,f2,f13,f20
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f20.f64));
	// fadds f17,f22,f21
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// fsubs f21,f22,f21
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fmsubs f2,f2,f12,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 - ctx.f26.f64));
	// fmuls f29,f18,f0
	ctx.f29.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f26,f17,f11
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fmuls f21,f21,f11
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// lfs f20,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f20.f64 = double(temp.f32);
	// lfs f3,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f3.f64 = double(temp.f32);
	// lfs f19,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f24,f20,f13,f19
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f19.f64));
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// lfs f19,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f22,f19,f0
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f19,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f3,f3,f13,f20
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f20.f64));
	// fadds f20,f5,f19
	ctx.f20.f64 = double(float(ctx.f5.f64 + ctx.f19.f64));
	// fsubs f5,f5,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f19.f64));
	// fadds f19,f1,f4
	ctx.f19.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// fsubs f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// fadds f1,f26,f29
	ctx.f1.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fadds f18,f25,f2
	ctx.f18.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// fsubs f29,f29,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// fsubs f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f25.f64));
	// lfs f25,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f25.f64 = double(temp.f32);
	// fadds f17,f19,f20
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfsx f17,r31,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fadds f26,f21,f22
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfsx f20,r26,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// fsubs f20,f1,f18
	ctx.f20.f64 = double(float(ctx.f1.f64 - ctx.f18.f64));
	// stfsx f20,r26,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fadds f1,f18,f1
	ctx.f1.f64 = double(float(ctx.f18.f64 + ctx.f1.f64));
	// stfsx f1,r31,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fsubs f1,f29,f4
	ctx.f1.f64 = double(float(ctx.f29.f64 - ctx.f4.f64));
	// stfsx f1,r24,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fadds f4,f4,f29
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f29.f64));
	// stfsx f4,r29,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fadds f4,f2,f5
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// stfsx f4,r29,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fsubs f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 - ctx.f5.f64));
	// stfsx f5,r24,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fadds f5,f25,f26
	ctx.f5.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfsx f5,r30,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f2,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f5,f25,f26
	ctx.f5.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// lfs f4,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// stfsx f5,r25,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// lfs f5,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f2.f64 = double(temp.f32);
	// fadds f1,f2,f5
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// lfs f5,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f26,f5,f13
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f29,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f29.f64 = double(temp.f32);
	// lfs f5,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f5.f64 = double(temp.f32);
	// fadds f20,f29,f5
	ctx.f20.f64 = double(float(ctx.f29.f64 + ctx.f5.f64));
	// lfs f5,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f19,f27,f5
	ctx.f19.f64 = double(float(ctx.f27.f64 - ctx.f5.f64));
	// fmuls f25,f2,f12
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f29,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f17,f2,f13
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f2,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f5,f4,f10
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fadds f15,f2,f14
	ctx.f15.f64 = double(float(ctx.f2.f64 + ctx.f14.f64));
	// lfs f2,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f4,f1,f10
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// lfs f1,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f18,f1,f13
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f1,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f1.f64 = double(temp.f32);
	// fadds f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// lfs f1,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f29,f1
	ctx.f1.f64 = double(float(ctx.f29.f64 + ctx.f1.f64));
	// lfs f29,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// stfs f29,-440(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f29,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f3,f29
	ctx.f29.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// stfs f29,-404(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f29,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f29.f64 = double(temp.f32);
	// stfs f2,-384(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fsubs f2,f23,f29
	ctx.f2.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// lfs f29,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f23,f19,f0
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f1,-444(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fsubs f1,f24,f29
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// lfs f24,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f29,f22,f21
	ctx.f29.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fsubs f3,f24,f3
	ctx.f3.f64 = double(float(ctx.f24.f64 - ctx.f3.f64));
	// lfs f24,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f24.f64 = double(temp.f32);
	// lfs f21,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f26,f24,f12,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 - ctx.f26.f64));
	// lfs f22,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f25,f21,f13,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 + ctx.f25.f64));
	// fmuls f24,f20,f11
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// fmadds f22,f22,f12,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f18.f64));
	// fmsubs f21,f21,f12,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 - ctx.f17.f64));
	// fmuls f20,f15,f0
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f18,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f18.f64 = double(temp.f32);
	// fadds f15,f5,f28
	ctx.f15.f64 = double(float(ctx.f5.f64 + ctx.f28.f64));
	// lfs f19,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f5,f28,f5
	ctx.f5.f64 = double(float(ctx.f28.f64 - ctx.f5.f64));
	// fadds f28,f4,f16
	ctx.f28.f64 = double(float(ctx.f4.f64 + ctx.f16.f64));
	// fsubs f4,f16,f4
	ctx.f4.f64 = double(float(ctx.f16.f64 - ctx.f4.f64));
	// stfs f4,-388(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f4,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f18,f18,f10
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64));
	// lfs f16,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// fsubs f16,f16,f4
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f4.f64));
	// stfsx f16,r25,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// lfs f16,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f16.f64 = double(temp.f32);
	// fadds f4,f4,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f16.f64));
	// stfsx f4,r30,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fsubs f4,f2,f1
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// stfsx f4,r27,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f4,f1,f2
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// stfsx f4,r28,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fadds f4,f3,f29
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// stfsx f4,r28,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fsubs f4,f3,f29
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// stfsx f4,r27,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fadds f4,f25,f26
	ctx.f4.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f3,f26,f25
	ctx.f3.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fsubs f26,f21,f22
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// fadds f29,f21,f22
	ctx.f29.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f22,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f22.f64 = double(temp.f32);
	// fadds f2,f23,f24
	ctx.f2.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f1,f23,f24
	ctx.f1.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// fadds f23,f18,f22
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// fmuls f18,f15,f8
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f8.f64));
	// fadds f25,f19,f20
	ctx.f25.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f24,f20,f19
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fmuls f19,f5,f6
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fmuls f17,f17,f10
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// fmuls f21,f28,f8
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// fmadds f28,f28,f9,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f9.f64 + ctx.f18.f64));
	// lfs f18,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f21,f15,f9,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f9.f64 - ctx.f21.f64));
	// fmuls f15,f22,f6
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// lfs f20,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f20,f6
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// fmadds f20,f20,f7,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f19.f64));
	// fadds f19,f17,f18
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f18,-372(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// fmuls f17,f23,f9
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// lfs f18,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f5,f5,f7,f16
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 - ctx.f16.f64));
	// fmuls f16,f23,f8
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fadds f23,f2,f4
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// stfs f23,-388(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fadds f23,f25,f29
	ctx.f23.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// stfs f23,-384(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fsubs f29,f25,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 - ctx.f29.f64));
	// stfs f29,-444(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f29,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// fmuls f25,f29,f12
	ctx.f25.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// lfs f29,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f23,f29,f12
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// lfs f29,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f18,f29,f18
	ctx.f18.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// lfs f29,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f27.f64));
	// lfs f27,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f27.f64 = double(temp.f32);
	// fadds f2,f26,f1
	ctx.f2.f64 = double(float(ctx.f26.f64 + ctx.f1.f64));
	// stfs f29,-392(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fsubs f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f26.f64));
	// lfs f26,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f26.f64 = double(temp.f32);
	// fadds f29,f24,f3
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f3.f64));
	// fsubs f3,f24,f3
	ctx.f3.f64 = double(float(ctx.f24.f64 - ctx.f3.f64));
	// fmsubs f27,f27,f13,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 - ctx.f25.f64));
	// fmadds f26,f26,f13,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 + ctx.f23.f64));
	// fmuls f25,f18,f11
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// lfs f23,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f24,f23,f0
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f23,f18,f6
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f6.f64));
	// stfs f23,-392(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fmadds f23,f19,f8,f17
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f8.f64 + ctx.f17.f64));
	// fmsubs f19,f19,f9,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f9.f64 - ctx.f16.f64));
	// fmsubs f18,f18,f7,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f7.f64 - ctx.f15.f64));
	// fadds f16,f23,f21
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// fadds f15,f19,f28
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// fsubs f28,f19,f28
	ctx.f28.f64 = double(float(ctx.f19.f64 - ctx.f28.f64));
	// fadds f19,f18,f20
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// lfs f17,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f22,f22,f7,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 + ctx.f17.f64));
	// fadds f17,f26,f27
	ctx.f17.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// fadds f26,f24,f25
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fadds f21,f22,f5
	ctx.f21.f64 = double(float(ctx.f22.f64 + ctx.f5.f64));
	// fsubs f5,f5,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f22.f64));
	// fsubs f22,f18,f20
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// lfs f20,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f20.f64 = double(temp.f32);
	// fadds f18,f16,f20
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfsx f18,r27,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fsubs f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// stfsx f20,r28,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f20,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f20,f15
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// stfsx f18,r28,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfsx f20,r27,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// lfs f20,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f20,f23
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// stfsx f18,r30,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// stfsx f23,r25,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fadds f23,f28,f4
	ctx.f23.f64 = double(float(ctx.f28.f64 + ctx.f4.f64));
	// stfsx f23,r25,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// fsubs f4,f28,f4
	ctx.f4.f64 = double(float(ctx.f28.f64 - ctx.f4.f64));
	// stfsx f4,r30,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f4,f21,f2
	ctx.f4.f64 = double(float(ctx.f21.f64 + ctx.f2.f64));
	// stfsx f4,r24,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// fsubs f4,f21,f2
	ctx.f4.f64 = double(float(ctx.f21.f64 - ctx.f2.f64));
	// stfsx f4,r29,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f4,f29,f19
	ctx.f4.f64 = double(float(ctx.f29.f64 - ctx.f19.f64));
	// stfsx f4,r29,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f4,f19,f29
	ctx.f4.f64 = double(float(ctx.f19.f64 + ctx.f29.f64));
	// stfsx f4,r24,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fsubs f4,f3,f5
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// stfsx f4,r31,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// stfsx f5,r26,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f22,f1
	ctx.f5.f64 = double(float(ctx.f22.f64 + ctx.f1.f64));
	// stfsx f5,r26,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fsubs f5,f22,f1
	ctx.f5.f64 = double(float(ctx.f22.f64 - ctx.f1.f64));
	// stfsx f5,r31,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f4,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfs f3,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// lfs f2,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f3.f64));
	// lfs f1,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// lfs f28,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f23,f14,f28
	ctx.f23.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// lfs f1,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f1.f64 = double(temp.f32);
	// lfs f29,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f28,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f29,f29,f12
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// lfs f22,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f5,f5,f10
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// fsubs f22,f28,f22
	ctx.f22.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// fmuls f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmuls f2,f2,f10
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// lfs f28,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmadds f1,f28,f12,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f1.f64));
	// lfs f28,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f29,f28,f13,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 - ctx.f29.f64));
	// lfs f16,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// lfs f18,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f18.f64 = double(temp.f32);
	// fadds f21,f4,f31
	ctx.f21.f64 = double(float(ctx.f4.f64 + ctx.f31.f64));
	// addi r11,r11,248
	ctx.r11.s64 = ctx.r11.s64 + 248;
	// fadds f20,f3,f16
	ctx.f20.f64 = double(float(ctx.f3.f64 + ctx.f16.f64));
	// fsubs f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// fsubs f4,f31,f4
	ctx.f4.f64 = double(float(ctx.f31.f64 - ctx.f4.f64));
	// fadds f24,f5,f30
	ctx.f24.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// fsubs f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// fsubs f3,f16,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 - ctx.f3.f64));
	// fadds f19,f2,f18
	ctx.f19.f64 = double(float(ctx.f2.f64 + ctx.f18.f64));
	// fadds f31,f29,f1
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f1.f64));
	// fsubs f1,f29,f1
	ctx.f1.f64 = double(float(ctx.f29.f64 - ctx.f1.f64));
	// fadds f30,f22,f23
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f29,f23,f22
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fmuls f23,f21,f7
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f7.f64));
	// fmuls f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// fmuls f22,f20,f6
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// fmuls f20,f20,f7
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// fsubs f2,f18,f2
	ctx.f2.f64 = double(float(ctx.f18.f64 - ctx.f2.f64));
	// fadds f28,f26,f17
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// fmuls f18,f5,f9
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// fmuls f16,f4,f9
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f9.f64));
	// fmsubs f23,f24,f6,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 - ctx.f23.f64));
	// fmadds f24,f24,f7,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 + ctx.f21.f64));
	// fadds f21,f30,f31
	ctx.f21.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// fsubs f31,f30,f31
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f31.f64));
	// fmuls f30,f3,f9
	ctx.f30.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// fmadds f22,f19,f7,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 + ctx.f22.f64));
	// fmsubs f20,f19,f6,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f6.f64 - ctx.f20.f64));
	// fmuls f19,f3,f8
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// fmadds f4,f4,f8,f18
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f18.f64));
	// fmsubs f5,f5,f8,f16
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f8.f64 - ctx.f16.f64));
	// fmsubs f3,f2,f8,f30
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f8.f64 - ctx.f30.f64));
	// fadds f30,f22,f23
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f22,f20,f24
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// fmadds f2,f2,f9,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f19.f64));
	// fadds f19,f30,f28
	ctx.f19.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// stfsx f19,r23,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfsx f30,r9,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fsubs f28,f21,f22
	ctx.f28.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfsx f28,r9,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f28,f22,f21
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfsx f28,r23,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fsubs f30,f31,f23
	ctx.f30.f64 = double(float(ctx.f31.f64 - ctx.f23.f64));
	// stfsx f30,r10,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f30,f26,f17
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// lwz r9,-344(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	// fsubs f28,f20,f24
	ctx.f28.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// add r3,r19,r3
	ctx.r3.u64 = ctx.r19.u64 + ctx.r3.u64;
	// fadds f21,f3,f4
	ctx.f21.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// fsubs f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// add r4,r19,r4
	ctx.r4.u64 = ctx.r19.u64 + ctx.r4.u64;
	// fadds f24,f2,f5
	ctx.f24.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// fadds f26,f1,f25
	ctx.f26.f64 = double(float(ctx.f1.f64 + ctx.f25.f64));
	// fadds f3,f23,f31
	ctx.f3.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// stfs f3,0(r15)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r15.u32 + 0, temp.u32);
	// fadds f22,f29,f27
	ctx.f22.f64 = double(float(ctx.f29.f64 + ctx.f27.f64));
	// stw r9,-344(r1)
	PPC_STORE_U32(ctx.r1.u32 + -344, ctx.r9.u32);
	// fsubs f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// fsubs f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// fsubs f2,f25,f1
	ctx.f2.f64 = double(float(ctx.f25.f64 - ctx.f1.f64));
	// fadds f3,f28,f30
	ctx.f3.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f3,0(r16)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fsubs f3,f28,f30
	ctx.f3.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// stfsx f3,r10,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lwz r10,-544(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	// fadds f3,f24,f26
	ctx.f3.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// stfs f3,0(r10)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// fsubs f3,f24,f26
	ctx.f3.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// stfsx f3,r7,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// fsubs f3,f22,f21
	ctx.f3.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfsx f3,r7,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// fadds f3,f21,f22
	ctx.f3.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f3,0(r14)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fsubs f3,f29,f5
	ctx.f3.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// stfs f3,0(r5)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f5,f5,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// stfs f5,0(r17)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r17.u32 + 0, temp.u32);
	// fadds f5,f4,f2
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f2.f64));
	// stfs f5,0(r18)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// fsubs f5,f4,f2
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// stfs f5,0(r6)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// subf r5,r19,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r19.s64;
	// subf r6,r19,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r19.s64;
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d43de4
	if (!ctx.cr0.eq) goto loc_82D43DE4;
loc_82D453AC:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D453B4;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D453B8"))) PPC_WEAK_FUNC(sub_82D453B8);
PPC_FUNC_IMPL(__imp__sub_82D453B8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-3424
	ctx.r5.s64 = ctx.r11.s64 + -3424;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,15720
	ctx.r4.s64 = ctx.r11.s64 + 15720;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D453D0"))) PPC_WEAK_FUNC(sub_82D453D0);
PPC_FUNC_IMPL(__imp__sub_82D453D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e3c
	ctx.lr = 0x82D453D8;
	__savegprlr_17(ctx, base);
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82e28ee0
	ctx.lr = 0x82D453E0;
	__savefpr_14(ctx, base);
	// mulli r11,r9,120
	ctx.r11.s64 = ctx.r9.s64 * 120;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-120
	ctx.r11.s64 = ctx.r11.s64 + -120;
	// bge cr6,0x82d45b90
	if (!ctx.cr6.lt) goto loc_82D45B90;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r18,r9,r10
	ctx.r18.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// rlwinm r27,r7,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfs f11,-3656(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -3656);
	ctx.f11.f64 = double(temp.f32);
	// lis r17,-32234
	ctx.r17.s64 = -2112487424;
	// lfs f12,-3660(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -3660);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-3664(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -3664);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-28552(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
loc_82D45424:
	// lfs f9,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// rlwinm r10,r8,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f10,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// rlwinm r9,r8,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f31,f9,f10
	ctx.f31.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// lfs f7,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f3,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// lfs f8,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// mulli r7,r8,24
	ctx.r7.s64 = ctx.r8.s64 * 24;
	// lfs f4,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f9,f8,f7
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// lfsx f30,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f7,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f29,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f27,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f28,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f25,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f25.f64 = double(temp.f32);
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f21,f3,f31
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// lfsx f26,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f20,f4,f31
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// lfsx f31,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f23,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// mulli r30,r8,20
	ctx.r30.s64 = ctx.r8.s64 * 20;
	// lfsx f24,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfs f5,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f6.f64 = double(temp.f32);
	// lfs f1,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f17,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f19.f64 = double(temp.f32);
	// add r26,r31,r4
	ctx.r26.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fmsubs f4,f4,f9,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 - ctx.f21.f64));
	// stfs f17,-308(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fmadds f9,f3,f9,f20
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 + ctx.f20.f64));
	// lfsx f22,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f3,f7,f30
	ctx.f3.f64 = double(float(ctx.f7.f64 - ctx.f30.f64));
	// lfs f20,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f20.f64 = double(temp.f32);
	// fadds f7,f30,f7
	ctx.f7.f64 = double(float(ctx.f30.f64 + ctx.f7.f64));
	// lfs f18,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f18.f64 = double(temp.f32);
	// fadds f30,f31,f29
	ctx.f30.f64 = double(float(ctx.f31.f64 + ctx.f29.f64));
	// add r25,r31,r3
	ctx.r25.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fsubs f31,f29,f31
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f31.f64));
	// add r24,r30,r4
	ctx.r24.u64 = ctx.r30.u64 + ctx.r4.u64;
	// fsubs f29,f28,f27
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// add r23,r30,r3
	ctx.r23.u64 = ctx.r30.u64 + ctx.r3.u64;
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fadds f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fsubs f25,f24,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fmuls f21,f1,f7
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// fmuls f23,f5,f30
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fmuls f30,f6,f30
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmsubs f6,f6,f3,f23
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 - ctx.f23.f64));
	// lfs f23,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f5,f5,f3,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f3.f64 + ctx.f30.f64));
	// lfs f30,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f7,f2,f7,f1
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f7.f64 - ctx.f1.f64));
	// fmadds f3,f2,f31,f21
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f31.f64 + ctx.f21.f64));
	// lfs f21,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f21,f28
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f28.f64));
	// lfs f31,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f15,f30,f25
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// fmuls f21,f21,f26
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f26.f64));
	// fadds f2,f6,f10
	ctx.f2.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fsubs f1,f8,f5
	ctx.f1.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// fadds f8,f5,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// fsubs f5,f9,f7
	ctx.f5.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fadds f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fsubs f6,f4,f3
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fadds f7,f3,f4
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// lfs f3,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f3,f27
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f4,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f16,f3,f29
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f29.f64));
	// fmuls f3,f19,f24
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f24.f64));
	// stfs f3,-312(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fmsubs f3,f4,f29,f17
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 - ctx.f17.f64));
	// fmadds f4,f4,f27,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f27.f64 + ctx.f16.f64));
	// lfsx f16,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-336(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fmadds f29,f23,f26,f14
	ctx.f29.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 + ctx.f14.f64));
	// lfs f26,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f28,f23,f28,f21
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f28.f64 - ctx.f21.f64));
	// lfsx f16,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f27,f26,f22
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// stfs f16,-308(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fsubs f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// lfsx f22,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r29,r8,28
	ctx.r29.s64 = ctx.r8.s64 * 28;
	// lfs f23,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// mulli r28,r8,12
	ctx.r28.s64 = ctx.r8.s64 * 12;
	// lfs f21,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f17,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f30,f27
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f27.f64));
	// fmuls f14,f19,f26
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f26.f64));
	// fsubs f19,f23,f22
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fsubs f30,f21,f17
	ctx.f30.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// stfs f30,-332(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfs f30,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fadds f22,f17,f21
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// fmadds f27,f31,f27,f15
	ctx.f27.f64 = double(float(ctx.f31.f64 * ctx.f27.f64 + ctx.f15.f64));
	// lfs f15,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// add r22,r29,r4
	ctx.r22.u64 = ctx.r29.u64 + ctx.r4.u64;
	// add r21,r29,r3
	ctx.r21.u64 = ctx.r29.u64 + ctx.r3.u64;
	// add r20,r28,r4
	ctx.r20.u64 = ctx.r28.u64 + ctx.r4.u64;
	// fmsubs f25,f31,f25,f16
	ctx.f25.f64 = double(float(ctx.f31.f64 * ctx.f25.f64 - ctx.f16.f64));
	// lfs f31,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmsubs f24,f20,f24,f14
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f24.f64 - ctx.f14.f64));
	// add r19,r28,r3
	ctx.r19.u64 = ctx.r28.u64 + ctx.r3.u64;
	// lfs f16,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f26,f20,f26,f16
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f26.f64 + ctx.f16.f64));
	// lfs f16,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// lfs f21,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f30,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// stfs f21,-316(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f21,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f20.f64 = double(temp.f32);
	// fadds f30,f21,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// fadds f21,f20,f31
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f31.f64));
	// fsubs f31,f31,f20
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f20.f64));
	// fadds f20,f25,f3
	ctx.f20.f64 = double(float(ctx.f25.f64 + ctx.f3.f64));
	// fsubs f3,f3,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f25.f64));
	// fadds f25,f27,f4
	ctx.f25.f64 = double(float(ctx.f27.f64 + ctx.f4.f64));
	// fsubs f27,f4,f27
	ctx.f27.f64 = double(float(ctx.f4.f64 - ctx.f27.f64));
	// lfs f4,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f14,f4,f22
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f22.f64));
	// fmuls f4,f4,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// fadds f17,f26,f29
	ctx.f17.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fsubs f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// fadds f26,f24,f28
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// fsubs f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// lfs f24,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f19,f18,f19,f14
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 - ctx.f14.f64));
	// lfs f14,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f4,f18,f22,f4
	ctx.f4.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 + ctx.f4.f64));
	// stfs f4,-336(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f4,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f4.f64 = double(temp.f32);
	// stfs f19,-328(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fmuls f19,f16,f21
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f21.f64));
	// fmuls f14,f4,f14
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f14.f64));
	// lfs f22,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f16,f22
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f22.f64));
	// fmuls f16,f4,f23
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// fmuls f4,f15,f30
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f30.f64));
	// stfs f4,-308(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fmsubs f22,f24,f22,f19
	ctx.f22.f64 = double(float(ctx.f24.f64 * ctx.f22.f64 - ctx.f19.f64));
	// lfs f4,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f4.f64 = double(temp.f32);
	// fmsubs f23,f4,f23,f14
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f23.f64 - ctx.f14.f64));
	// fmuls f15,f15,f31
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// fmadds f24,f24,f21,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f21.f64 + ctx.f18.f64));
	// lfs f21,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f4,f21,f16
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f21.f64 + ctx.f16.f64));
	// lfs f4,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f4.f64 = double(temp.f32);
	// lfs f19,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f31,f4,f31,f19
	ctx.f31.f64 = double(float(ctx.f4.f64 * ctx.f31.f64 + ctx.f19.f64));
	// lfsx f14,r28,r6
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f4,f4,f30,f15
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64 - ctx.f15.f64));
	// stfs f14,-308(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfsx f14,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-324(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f14,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f14,-312(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f14,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f24
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// stfs f14,-292(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f14,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f14.f64 = double(temp.f32);
	// fadds f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// lfs f14,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfsx f19,r29,r6
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f14,f31,f21
	ctx.f14.f64 = double(float(ctx.f31.f64 + ctx.f21.f64));
	// lfs f30,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f31,f31,f21
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f21.f64));
	// lfsx f16,r29,r5
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f21,f23,f4
	ctx.f21.f64 = double(float(ctx.f23.f64 - ctx.f4.f64));
	// lfs f18,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// fadds f4,f4,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f23.f64));
	// stfs f4,-316(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fsubs f23,f30,f19
	ctx.f23.f64 = double(float(ctx.f30.f64 - ctx.f19.f64));
	// lfs f15,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// fadds f30,f19,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 + ctx.f30.f64));
	// fadds f19,f16,f18
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f4,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f16,f15,f4
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f4.f64));
	// stfs f16,-328(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fadds f4,f4,f15
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f15.f64));
	// stfs f4,-320(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f16,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f16.f64 = double(temp.f32);
	// lfs f4,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fadds f15,f16,f4
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f4.f64));
	// stfs f15,-324(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fsubs f4,f4,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f16.f64));
	// stfs f4,-336(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f4,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f15,f4,f19
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// fmuls f16,f4,f23
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// lfs f4,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f4.f64 = double(temp.f32);
	// fmsubs f23,f4,f23,f15
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f23.f64 - ctx.f15.f64));
	// stfs f23,-304(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fmadds f4,f4,f19,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f19.f64 + ctx.f16.f64));
	// lfs f19,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-332(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fadds f15,f20,f2
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f2.f64));
	// fsubs f2,f2,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f20.f64));
	// stfs f2,-308(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f23,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f23.f64 = double(temp.f32);
	// stfs f15,-296(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f16,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f16,f18
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f18.f64));
	// lfs f19,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// stfs f4,-300(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f4,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f4.f64 = double(temp.f32);
	// lfs f15,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f15.f64));
	// lfs f16,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f19,f16
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfs f2,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f23,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// lfs f23,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f23,f18
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f18.f64));
	// lfs f23,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f19,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// lfs f19,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f2,f4,f19,f2
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f19.f64 - ctx.f2.f64));
	// lfs f19,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f20,f19,f30,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f30.f64 + ctx.f20.f64));
	// stfs f20,-332(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f19,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f20.f64 = double(temp.f32);
	// stfs f23,-328(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fmadds f23,f20,f19,f16
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f19.f64 + ctx.f16.f64));
	// lfs f19,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f4,f4,f19,f15
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f19.f64 + ctx.f15.f64));
	// lfs f19,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f30,f19,f30,f18
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f30.f64 - ctx.f18.f64));
	// lfs f19,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f20,f20,f19,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64 - ctx.f18.f64));
	// lfs f19,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f19.f64 = double(temp.f32);
	// fadds f18,f2,f19
	ctx.f18.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// stfs f18,-328(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fsubs f2,f19,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 - ctx.f2.f64));
	// stfs f2,-288(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f2,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f2.f64 = double(temp.f32);
	// fadds f19,f23,f2
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f2.f64));
	// stfs f19,-304(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fsubs f2,f23,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 - ctx.f2.f64));
	// lfs f23,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f23.f64 = double(temp.f32);
	// stfs f2,-324(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fadds f2,f4,f23
	ctx.f2.f64 = double(float(ctx.f4.f64 + ctx.f23.f64));
	// fsubs f4,f23,f4
	ctx.f4.f64 = double(float(ctx.f23.f64 - ctx.f4.f64));
	// stfs f4,-336(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fsubs f4,f30,f20
	ctx.f4.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// stfs f4,-320(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fadds f16,f20,f30
	ctx.f16.f64 = double(float(ctx.f20.f64 + ctx.f30.f64));
	// lfs f4,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f18,f4
	ctx.f4.f64 = double(float(ctx.f18.f64 + ctx.f4.f64));
	// stfs f16,-300(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fadds f18,f25,f8
	ctx.f18.f64 = double(float(ctx.f25.f64 + ctx.f8.f64));
	// lfs f20,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f20.f64 = double(temp.f32);
	// fadds f30,f19,f14
	ctx.f30.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// fsubs f19,f6,f17
	ctx.f19.f64 = double(float(ctx.f6.f64 - ctx.f17.f64));
	// fadds f23,f2,f24
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f24.f64));
	// fsubs f15,f2,f24
	ctx.f15.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// stfs f15,-332(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f2,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f8,f8,f25
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f25.f64));
	// fadds f6,f17,f6
	ctx.f6.f64 = double(float(ctx.f17.f64 + ctx.f6.f64));
	// fadds f2,f16,f2
	ctx.f2.f64 = double(float(ctx.f16.f64 + ctx.f2.f64));
	// fadds f16,f26,f9
	ctx.f16.f64 = double(float(ctx.f26.f64 + ctx.f9.f64));
	// fadds f24,f20,f4
	ctx.f24.f64 = double(float(ctx.f20.f64 + ctx.f4.f64));
	// fsubs f4,f20,f4
	ctx.f4.f64 = double(float(ctx.f20.f64 - ctx.f4.f64));
	// fsubs f20,f19,f30
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f30.f64));
	// fadds f30,f30,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f19.f64));
	// fadds f19,f23,f18
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// fsubs f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// lfs f18,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f18.f64 = double(temp.f32);
	// fadds f15,f18,f15
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// fsubs f9,f9,f26
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f26.f64));
	// fadds f18,f16,f2
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f2.f64));
	// fsubs f2,f2,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f16.f64));
	// fadds f16,f20,f24
	ctx.f16.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// fsubs f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// fsubs f20,f23,f30
	ctx.f20.f64 = double(float(ctx.f23.f64 - ctx.f30.f64));
	// fadds f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// fadds f23,f19,f18
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fsubs f18,f2,f4
	ctx.f18.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// fadds f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fmuls f2,f16,f0
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f2,0(r4)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmuls f2,f24,f0
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f24,f20,f0
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmuls f30,f30,f0
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// lfs f26,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f23,0(r3)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfsx f2,r29,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fmuls f2,f19,f0
	ctx.f2.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfsx f2,r29,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fmuls f2,f18,f0
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfsx f24,r28,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// stfsx f2,r28,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// stfsx f30,r10,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f4,r10,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f2,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f2.f64 = double(temp.f32);
	// lfs f30,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// lfs f26,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f26.f64 = double(temp.f32);
	// lfs f4,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// lfs f2,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f2,f14,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 - ctx.f2.f64));
	// lfs f25,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f15,f0
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f19,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f15,f10,f27
	ctx.f15.f64 = double(float(ctx.f10.f64 - ctx.f27.f64));
	// lfs f20,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f20.f64 = double(temp.f32);
	// fadds f27,f27,f10
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f10.f64));
	// lfs f18,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f18.f64 = double(temp.f32);
	// fadds f10,f3,f1
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// stfs f10,-288(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fsubs f16,f26,f25
	ctx.f16.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fsubs f26,f22,f20
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// fsubs f20,f18,f19
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// fadds f25,f18,f19
	ctx.f25.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f21
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// lfs f19,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f14,f1,f3
	ctx.f14.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// fmuls f10,f15,f0
	ctx.f10.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fadds f15,f2,f4
	ctx.f15.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fsubs f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f2,f6,f9
	ctx.f2.f64 = double(float(ctx.f6.f64 - ctx.f9.f64));
	// fadds f9,f9,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f6.f64));
	// fadds f6,f30,f8
	ctx.f6.f64 = double(float(ctx.f30.f64 + ctx.f8.f64));
	// fsubs f30,f8,f30
	ctx.f30.f64 = double(float(ctx.f8.f64 - ctx.f30.f64));
	// fmuls f3,f27,f0
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fadds f8,f20,f22
	ctx.f8.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// fsubs f23,f5,f29
	ctx.f23.f64 = double(float(ctx.f5.f64 - ctx.f29.f64));
	// fadds f19,f19,f31
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f31.f64));
	// fmuls f1,f14,f0
	ctx.f1.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fadds f14,f25,f26
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fadds f24,f28,f7
	ctx.f24.f64 = double(float(ctx.f28.f64 + ctx.f7.f64));
	// fsubs f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f25,f23,f11
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// fmuls f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fmuls f20,f19,f12
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f27,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f27.f64 = double(temp.f32);
	// stfs f8,-288(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fmuls f8,f6,f0
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f6,f30,f0
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// stfs f6,-296(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fmuls f6,f18,f12
	ctx.f6.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// stfs f6,-292(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fmuls f30,f26,f13
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmsubs f26,f24,f12,f25
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 - ctx.f25.f64));
	// fmadds f25,f24,f11,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f11.f64 + ctx.f23.f64));
	// fmuls f27,f27,f0
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f6,f14,f13
	ctx.f6.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// lfs f23,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f24,f23,f13
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fmuls f23,f22,f13
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmadds f22,f18,f11,f20
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 + ctx.f20.f64));
	// lfs f20,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f20,f19,f11,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 - ctx.f20.f64));
	// fadds f19,f2,f15
	ctx.f19.f64 = double(float(ctx.f2.f64 + ctx.f15.f64));
	// fadds f18,f9,f4
	ctx.f18.f64 = double(float(ctx.f9.f64 + ctx.f4.f64));
	// fsubs f2,f2,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f15.f64));
	// fsubs f15,f4,f9
	ctx.f15.f64 = double(float(ctx.f4.f64 - ctx.f9.f64));
	// fmuls f9,f19,f13
	ctx.f9.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmuls f4,f18,f13
	ctx.f4.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// fmuls f2,f2,f13
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmuls f19,f15,f13
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fadds f18,f9,f17
	ctx.f18.f64 = double(float(ctx.f9.f64 + ctx.f17.f64));
	// stfsx f18,r9,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f9,f17
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f17.f64));
	// stfsx f9,r30,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f9,f8,f4
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// stfsx f9,r30,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f4,f8
	ctx.f9.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// stfsx f9,r9,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f9,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f8,f9,f2
	ctx.f8.f64 = double(float(ctx.f9.f64 - ctx.f2.f64));
	// stfsx f8,r31,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 + ctx.f9.f64));
	// stfsx f9,r7,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f19,f16
	ctx.f9.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// stfsx f9,r7,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f19,f16
	ctx.f9.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// stfsx f9,r31,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f9,f7,f28
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f28.f64));
	// fadds f8,f29,f5
	ctx.f8.f64 = double(float(ctx.f29.f64 + ctx.f5.f64));
	// lfs f5,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f5,f21
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f21.f64));
	// lfs f7,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f7.f64 = double(temp.f32);
	// fadds f29,f30,f1
	ctx.f29.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// addic. r18,r18,-1
	ctx.xer.ca = ctx.r18.u32 > 0;
	ctx.r18.s64 = ctx.r18.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r18.s32, 0, ctx.xer);
	// fsubs f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fmuls f28,f9,f12
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// add r4,r27,r4
	ctx.r4.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fsubs f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f31.f64));
	// addi r11,r11,120
	ctx.r11.s64 = ctx.r11.s64 + 120;
	// fadds f2,f24,f27
	ctx.f2.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// fsubs f31,f27,f24
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// fadds f4,f6,f10
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fmuls f30,f8,f12
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmuls f27,f5,f12
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f24,f5,f11
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fadds f6,f23,f3
	ctx.f6.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// fmadds f8,f8,f11,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f11.f64 + ctx.f28.f64));
	// fsubs f3,f3,f23
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f23.f64));
	// fmsubs f9,f9,f11,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f11.f64 - ctx.f30.f64));
	// fmadds f5,f7,f11,f27
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f11.f64 + ctx.f27.f64));
	// fmsubs f7,f7,f12,f24
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 - ctx.f24.f64));
	// fadds f28,f8,f20
	ctx.f28.f64 = double(float(ctx.f8.f64 + ctx.f20.f64));
	// fsubs f8,f20,f8
	ctx.f8.f64 = double(float(ctx.f20.f64 - ctx.f8.f64));
	// fadds f30,f9,f22
	ctx.f30.f64 = double(float(ctx.f9.f64 + ctx.f22.f64));
	// fadds f27,f5,f26
	ctx.f27.f64 = double(float(ctx.f5.f64 + ctx.f26.f64));
	// fsubs f9,f9,f22
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f22.f64));
	// fsubs f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 - ctx.f5.f64));
	// fadds f26,f7,f25
	ctx.f26.f64 = double(float(ctx.f7.f64 + ctx.f25.f64));
	// fsubs f7,f7,f25
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f25.f64));
	// fadds f25,f30,f4
	ctx.f25.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// stfs f25,0(r26)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fsubs f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 - ctx.f4.f64));
	// stfsx f4,r7,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// fsubs f4,f2,f28
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f28.f64));
	// stfsx f4,r7,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// fadds f4,f28,f2
	ctx.f4.f64 = double(float(ctx.f28.f64 + ctx.f2.f64));
	// stfs f4,0(r25)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fsubs f4,f31,f9
	ctx.f4.f64 = double(float(ctx.f31.f64 - ctx.f9.f64));
	// stfsx f4,r9,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f31.f64));
	// stfs f9,0(r23)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// fadds f9,f8,f10
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// stfs f9,0(r24)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fsubs f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 - ctx.f10.f64));
	// stfsx f10,r9,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f10,f27,f6
	ctx.f10.f64 = double(float(ctx.f27.f64 + ctx.f6.f64));
	// stfs f10,0(r20)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// fsubs f10,f27,f6
	ctx.f10.f64 = double(float(ctx.f27.f64 - ctx.f6.f64));
	// stfsx f10,r10,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f10,f29,f26
	ctx.f10.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// stfsx f10,r10,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f10,f26,f29
	ctx.f10.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// stfs f10,0(r19)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// fsubs f10,f1,f5
	ctx.f10.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// stfs f10,0(r5)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f10,f5,f1
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// stfs f10,0(r21)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// fadds f10,f7,f3
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// stfs f10,0(r22)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// fsubs f10,f7,f3
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfs f10,0(r6)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lwz r10,3532(r17)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r17.u32 + 3532);
	// subf r5,r27,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r27.s64;
	// subf r6,r27,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r27.s64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d45424
	if (!ctx.cr0.eq) goto loc_82D45424;
loc_82D45B90:
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82e28f2c
	ctx.lr = 0x82D45B98;
	__restfpr_14(ctx, base);
	// b 0x82e28e8c
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D45BA0"))) PPC_WEAK_FUNC(sub_82D45BA0);
PPC_FUNC_IMPL(__imp__sub_82D45BA0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-3368
	ctx.r5.s64 = ctx.r11.s64 + -3368;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,21456
	ctx.r4.s64 = ctx.r11.s64 + 21456;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D45BB8"))) PPC_WEAK_FUNC(sub_82D45BB8);
PPC_FUNC_IMPL(__imp__sub_82D45BB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e4c
	ctx.lr = 0x82D45BC0;
	__savegprlr_21(ctx, base);
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28ee0
	ctx.lr = 0x82D45BC8;
	__savefpr_14(ctx, base);
	// mulli r11,r9,88
	ctx.r11.s64 = ctx.r9.s64 * 88;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-88
	ctx.r11.s64 = ctx.r11.s64 + -88;
	// bge cr6,0x82d460d4
	if (!ctx.cr6.lt) goto loc_82D460D4;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r22,r9,r10
	ctx.r22.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// rlwinm r29,r7,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32255
	ctx.r7.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lfs f0,-28552(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,-12288(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -12288);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-6316(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6316);
	ctx.f13.f64 = double(temp.f32);
loc_82D45C04:
	// lfs f2,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f3,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// rlwinm r31,r8,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f31,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fadds f29,f2,f3
	ctx.f29.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfs f1,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// fsubs f2,f1,f31
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// add r28,r31,r3
	ctx.r28.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// add r27,r31,r5
	ctx.r27.u64 = ctx.r31.u64 + ctx.r5.u64;
	// lfsx f28,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f28.f64 = double(temp.f32);
	// add r26,r31,r4
	ctx.r26.u64 = ctx.r31.u64 + ctx.r4.u64;
	// lfsx f31,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// mulli r9,r8,12
	ctx.r9.s64 = ctx.r8.s64 * 12;
	// fsubs f21,f31,f28
	ctx.f21.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// lfsx f26,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f27,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// fadds f28,f26,f27
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// lfs f24,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// fadds f26,f24,f25
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// lfsx f22,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// fsubs f24,f23,f22
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfs f10,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfs f8,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f8.f64 = double(temp.f32);
	// lfs f11,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r30,r8,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f9,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f9.f64 = double(temp.f32);
	// mulli r7,r8,20
	ctx.r7.s64 = ctx.r8.s64 * 20;
	// fmuls f22,f10,f21
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f21.f64));
	// lfs f4,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// lfs f6,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f20,f8,f26
	ctx.f20.f64 = double(float(ctx.f8.f64 * ctx.f26.f64));
	// lfs f30,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f26,f9,f26
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// fmuls f19,f6,f25
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// add r25,r30,r3
	ctx.r25.u64 = ctx.r30.u64 + ctx.r3.u64;
	// fmuls f25,f7,f25
	ctx.f25.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// add r24,r30,r5
	ctx.r24.u64 = ctx.r30.u64 + ctx.r5.u64;
	// add r23,r30,r6
	ctx.r23.u64 = ctx.r30.u64 + ctx.r6.u64;
	// fmsubs f10,f11,f21,f10
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f21.f64 - ctx.f10.f64));
	// fmadds f11,f11,f28,f22
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f28.f64 + ctx.f22.f64));
	// fmuls f28,f4,f27
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// fmsubs f9,f9,f24,f20
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f24.f64 - ctx.f20.f64));
	// fmadds f8,f8,f24,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f24.f64 + ctx.f26.f64));
	// lfs f24,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f26,f4,f31
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmadds f6,f6,f23,f25
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f23.f64 + ctx.f25.f64));
	// lfs f25,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f7,f7,f23,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f23.f64 - ctx.f19.f64));
	// lfs f23,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f4,f5,f31,f28
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f31.f64 - ctx.f28.f64));
	// fsubs f31,f10,f9
	ctx.f31.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fadds f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f28,f8,f11
	ctx.f28.f64 = double(float(ctx.f8.f64 - ctx.f11.f64));
	// fadds f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// fmadds f5,f5,f27,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f27.f64 + ctx.f26.f64));
	// lfs f27,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f9,f31,f13
	ctx.f9.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// lfs f31,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f21,f31,f29
	ctx.f21.f64 = double(float(ctx.f31.f64 * ctx.f29.f64));
	// fmuls f22,f31,f2
	ctx.f22.f64 = double(float(ctx.f31.f64 * ctx.f2.f64));
	// fmuls f8,f28,f13
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f2,f30,f2,f21
	ctx.f2.f64 = double(float(ctx.f30.f64 * ctx.f2.f64 + ctx.f21.f64));
	// lfsx f21,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f31,f30,f29,f22
	ctx.f31.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 - ctx.f22.f64));
	// lfsx f30,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f29,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f22,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f16,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f5,f2
	ctx.f14.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// stfs f16,-272(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fsubs f15,f4,f31
	ctx.f15.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// lfsx f19,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f4,f31,f4
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// lfsx f20,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// lfsx f17,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f18,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f31,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// lfs f2,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f16,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f14,f13
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// stfs f14,-260(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// fsubs f14,f30,f29
	ctx.f14.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fadds f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fadds f29,f21,f22
	ctx.f29.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fsubs f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fadds f19,f17,f18
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fsubs f17,f31,f2
	ctx.f17.f64 = double(float(ctx.f31.f64 - ctx.f2.f64));
	// fadds f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// lfs f31,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f31.f64 = double(temp.f32);
	// fadds f31,f16,f31
	ctx.f31.f64 = double(float(ctx.f16.f64 + ctx.f31.f64));
	// stfs f31,-268(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// lfs f31,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f31,f31,f16
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f16.f64));
	// stfs f31,-272(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fmuls f16,f27,f14
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f14.f64));
	// fmuls f31,f27,f29
	ctx.f31.f64 = double(float(ctx.f27.f64 * ctx.f29.f64));
	// fmuls f27,f23,f19
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f19.f64));
	// fmadds f29,f28,f29,f16
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f29.f64 + ctx.f16.f64));
	// fmsubs f31,f28,f14,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 * ctx.f14.f64 - ctx.f31.f64));
	// fmuls f16,f26,f17
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// lfs f28,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f28.f64 = double(temp.f32);
	// stfs f27,-268(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fmr f27,f28
	ctx.f27.f64 = ctx.f28.f64;
	// fmuls f26,f26,f27
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fmadds f27,f25,f27,f16
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f27.f64 + ctx.f16.f64));
	// lfs f16,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f26,f25,f17,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f17.f64 - ctx.f26.f64));
	// lfs f17,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f17.f64 = double(temp.f32);
	// lfs f25,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f25.f64 = double(temp.f32);
	// lfs f28,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f28.f64 = double(temp.f32);
	// stfs f16,-268(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fmsubs f28,f24,f21,f28
	ctx.f28.f64 = double(float(ctx.f24.f64 * ctx.f21.f64 - ctx.f28.f64));
	// fmuls f21,f23,f21
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f21.f64));
	// lfs f23,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f23,f18
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f18.f64));
	// lfs f16,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f20.f64));
	// fmadds f24,f24,f19,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f19.f64 + ctx.f21.f64));
	// lfs f21,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f21.f64 = double(temp.f32);
	// stfs f24,-264(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fmuls f24,f17,f2
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// stfs f23,-272(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fmr f23,f21
	ctx.f23.f64 = ctx.f21.f64;
	// fmuls f2,f25,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// fmuls f19,f16,f22
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f22.f64));
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// fmsubs f25,f25,f23,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f23.f64 - ctx.f24.f64));
	// lfs f21,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f21.f64 = double(temp.f32);
	// stfs f2,-268(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fmsubs f30,f21,f30,f19
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f30.f64 - ctx.f19.f64));
	// lfs f2,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f22,f21,f22,f16
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f22.f64 + ctx.f16.f64));
	// fmsubs f24,f2,f20,f14
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f20.f64 - ctx.f14.f64));
	// fadds f21,f25,f28
	ctx.f21.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// fsubs f20,f28,f25
	ctx.f20.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// lfs f25,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f25.f64 = double(temp.f32);
	// fadds f28,f24,f30
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// lfs f19,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f23,f17,f23,f19
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f23.f64 + ctx.f19.f64));
	// lfs f19,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f2,f2,f18,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f18.f64 + ctx.f19.f64));
	// fsubs f19,f24,f30
	ctx.f19.f64 = double(float(ctx.f24.f64 - ctx.f30.f64));
	// fadds f30,f23,f25
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// fsubs f18,f23,f25
	ctx.f18.f64 = double(float(ctx.f23.f64 - ctx.f25.f64));
	// fadds f25,f2,f22
	ctx.f25.f64 = double(float(ctx.f2.f64 + ctx.f22.f64));
	// fsubs f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f22.f64));
	// fmuls f24,f20,f13
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// fadds f20,f28,f27
	ctx.f20.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// fmuls f23,f19,f13
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fadds f19,f30,f29
	ctx.f19.f64 = double(float(ctx.f30.f64 + ctx.f29.f64));
	// fmuls f22,f18,f13
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// stfs f22,-256(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fadds f22,f21,f31
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f31.f64));
	// fmuls f2,f2,f13
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// stfs f2,-268(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fadds f2,f10,f3
	ctx.f2.f64 = double(float(ctx.f10.f64 + ctx.f3.f64));
	// fsubs f18,f26,f25
	ctx.f18.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fmuls f26,f26,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmuls f21,f21,f12
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fsubs f17,f2,f22
	ctx.f17.f64 = double(float(ctx.f2.f64 - ctx.f22.f64));
	// fadds f22,f22,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f2.f64));
	// fadds f2,f4,f7
	ctx.f2.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// fmuls f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// fsubs f16,f20,f2
	ctx.f16.f64 = double(float(ctx.f20.f64 - ctx.f2.f64));
	// fadds f20,f2,f20
	ctx.f20.f64 = double(float(ctx.f2.f64 + ctx.f20.f64));
	// fadds f2,f11,f1
	ctx.f2.f64 = double(float(ctx.f11.f64 + ctx.f1.f64));
	// fmuls f11,f11,f12
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// fmsubs f7,f7,f0,f4
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 - ctx.f4.f64));
	// fmadds f4,f25,f12,f26
	ctx.f4.f64 = double(float(ctx.f25.f64 * ctx.f12.f64 + ctx.f26.f64));
	// lfs f25,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f14,f2,f19
	ctx.f14.f64 = double(float(ctx.f2.f64 - ctx.f19.f64));
	// fadds f2,f19,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 + ctx.f2.f64));
	// stfs f2,-264(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fadds f2,f5,f6
	ctx.f2.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fmsubs f11,f1,f0,f11
	ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 - ctx.f11.f64));
	// fadds f19,f2,f18
	ctx.f19.f64 = double(float(ctx.f2.f64 + ctx.f18.f64));
	// fsubs f2,f18,f2
	ctx.f2.f64 = double(float(ctx.f18.f64 - ctx.f2.f64));
	// stfs f2,-272(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fadds f18,f16,f17
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// fmuls f18,f18,f0
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfsx f18,r9,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmuls f18,f17,f0
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f2,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f16,f2,f20
	ctx.f16.f64 = double(float(ctx.f2.f64 - ctx.f20.f64));
	// fadds f2,f2,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f20.f64));
	// fsubs f20,f14,f19
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// fadds f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// fmuls f17,f16,f0
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f14,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// stfsx f20,r9,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f18,r10,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fmuls f20,f19,f0
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfsx f20,r10,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// stfsx f17,r7,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// fmuls f20,f14,f0
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfsx f20,r7,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// stfs f2,0(r3)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f2,f30,f12
	ctx.f2.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// fmuls f30,f28,f12
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fmuls f20,f10,f12
	ctx.f20.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// fmuls f28,f6,f0
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmsubs f10,f29,f0,f2
	ctx.f10.f64 = double(float(ctx.f29.f64 * ctx.f0.f64 - ctx.f2.f64));
	// lfs f2,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f2.f64 = double(temp.f32);
	// fadds f1,f2,f22
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f22.f64));
	// lfs f22,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f6,f27,f0,f30
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 - ctx.f30.f64));
	// fmsubs f3,f3,f0,f20
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f20.f64));
	// fmsubs f5,f5,f12,f28
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 - ctx.f28.f64));
	// fmsubs f2,f31,f0,f21
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f0.f64 - ctx.f21.f64));
	// fsubs f29,f7,f25
	ctx.f29.f64 = double(float(ctx.f7.f64 - ctx.f25.f64));
	// fsubs f27,f4,f23
	ctx.f27.f64 = double(float(ctx.f4.f64 - ctx.f23.f64));
	// fsubs f31,f10,f24
	ctx.f31.f64 = double(float(ctx.f10.f64 - ctx.f24.f64));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// stfs f1,0(r4)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f30,f6,f22
	ctx.f30.f64 = double(float(ctx.f6.f64 - ctx.f22.f64));
	// fsubs f26,f3,f8
	ctx.f26.f64 = double(float(ctx.f3.f64 - ctx.f8.f64));
	// fsubs f1,f11,f9
	ctx.f1.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// fsubs f28,f15,f5
	ctx.f28.f64 = double(float(ctx.f15.f64 - ctx.f5.f64));
	// fadds f6,f6,f22
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f22.f64));
	// fadds f8,f3,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f8.f64));
	// lfs f22,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f22.f64 = double(temp.f32);
	// fadds f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f9.f64));
	// fsubs f3,f2,f22
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f22.f64));
	// addic. r22,r22,-1
	ctx.xer.ca = ctx.r22.u32 > 0;
	ctx.r22.s64 = ctx.r22.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r22.s32, 0, ctx.xer);
	// fadds f9,f5,f15
	ctx.f9.f64 = double(float(ctx.f5.f64 + ctx.f15.f64));
	// addi r11,r11,88
	ctx.r11.s64 = ctx.r11.s64 + 88;
	// fadds f5,f4,f23
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f23.f64));
	// fadds f4,f31,f1
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fsubs f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// fadds f31,f29,f30
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fadds f7,f7,f25
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f25.f64));
	// fsubs f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f30.f64));
	// fadds f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f22.f64));
	// fsubs f29,f28,f27
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fadds f27,f3,f26
	ctx.f27.f64 = double(float(ctx.f3.f64 + ctx.f26.f64));
	// fsubs f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 - ctx.f3.f64));
	// fadds f10,f10,f24
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f24.f64));
	// fsubs f24,f4,f31
	ctx.f24.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// stfsx f24,r10,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f25,f7,f6
	ctx.f25.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// fadds f4,f31,f4
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// stfsx f4,r9,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f26,f8,f2
	ctx.f26.f64 = double(float(ctx.f8.f64 - ctx.f2.f64));
	// fadds f8,f2,f8
	ctx.f8.f64 = double(float(ctx.f2.f64 + ctx.f8.f64));
	// fsubs f4,f1,f28
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// fadds f31,f29,f27
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f27.f64));
	// stfsx f31,r10,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f31,f29,f27
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// stfsx f31,r9,r6
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f31,f30,f3
	ctx.f31.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// stfsx f31,r7,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f3,f30,f3
	ctx.f3.f64 = double(float(ctx.f30.f64 - ctx.f3.f64));
	// stfs f3,0(r6)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// stfs f4,0(r5)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f1,f28,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// stfsx f1,r7,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fsubs f3,f5,f9
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// fadds f9,f5,f9
	ctx.f9.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// fadds f4,f25,f26
	ctx.f4.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfsx f4,r30,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f4,f11,f10
	ctx.f4.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// add r4,r29,r4
	ctx.r4.u64 = ctx.r29.u64 + ctx.r4.u64;
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// subf r5,r29,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r29.s64;
	// fadds f10,f7,f6
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f6.f64));
	// fsubs f1,f25,f26
	ctx.f1.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfsx f1,r31,r6
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// subf r6,r29,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r29.s64;
	// fsubs f7,f4,f3
	ctx.f7.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// stfs f7,0(r27)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fadds f7,f3,f4
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// stfs f7,0(r25)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fsubs f7,f11,f10
	ctx.f7.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// stfs f7,0(r24)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// stfs f11,0(r28)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fadds f11,f9,f8
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// stfs f11,0(r26)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fsubs f11,f9,f8
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// stfs f11,0(r23)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// lwz r10,3532(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d45c04
	if (!ctx.cr0.eq) goto loc_82D45C04;
loc_82D460D4:
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28f2c
	ctx.lr = 0x82D460DC;
	__restfpr_14(ctx, base);
	// b 0x82e28e9c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D460E0"))) PPC_WEAK_FUNC(sub_82D460E0);
PPC_FUNC_IMPL(__imp__sub_82D460E0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-3312
	ctx.r5.s64 = ctx.r11.s64 + -3312;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,23480
	ctx.r4.s64 = ctx.r11.s64 + 23480;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D460F8"))) PPC_WEAK_FUNC(sub_82D460F8);
PPC_FUNC_IMPL(__imp__sub_82D460F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D46100;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28ee0
	ctx.lr = 0x82D46108;
	__savefpr_14(ctx, base);
	// mulli r11,r9,72
	ctx.r11.s64 = ctx.r9.s64 * 72;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-72
	ctx.r11.s64 = ctx.r11.s64 + -72;
	// bge cr6,0x82d46568
	if (!ctx.cr6.lt) goto loc_82D46568;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r25,r9,r10
	ctx.r25.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r7,-32250
	ctx.r7.s64 = -2113536000;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f12,-3200(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -3200);
	ctx.f12.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f13,-3204(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -3204);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,-6952(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -6952);
	ctx.f10.f64 = double(temp.f32);
	// lfs f0,-28552(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,-3208(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -3208);
	ctx.f11.f64 = double(temp.f32);
loc_82D46154:
	// lfs f8,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f28,f8,f9
	ctx.f28.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// lfs f6,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfs f4,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// lfs f7,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// add r29,r7,r4
	ctx.r29.u64 = ctx.r7.u64 + ctx.r4.u64;
	// lfs f5,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f8,f7,f6
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// fadds f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// lfsx f27,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f6,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// add r28,r7,r3
	ctx.r28.u64 = ctx.r7.u64 + ctx.r3.u64;
	// lfsx f26,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// mulli r31,r8,12
	ctx.r31.s64 = ctx.r8.s64 * 12;
	// lfsx f24,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f22,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f19,f4,f28
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// lfs f23,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f5,f28
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// lfsx f28,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f20,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f20.f64 = double(temp.f32);
	// add r27,r31,r4
	ctx.r27.u64 = ctx.r31.u64 + ctx.r4.u64;
	// lfs f2,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f2.f64 = double(temp.f32);
	// lfs f31,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f31.f64 = double(temp.f32);
	// rlwinm r9,r8,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f29,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f29.f64 = double(temp.f32);
	// add r26,r31,r3
	ctx.r26.u64 = ctx.r31.u64 + ctx.r3.u64;
	// lfs f3,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f3.f64 = double(temp.f32);
	// lfs f1,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f1.f64 = double(temp.f32);
	// lfs f30,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f30.f64 = double(temp.f32);
	// lfs f21,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f5,f5,f8,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f8.f64 - ctx.f19.f64));
	// lfsx f16,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f8,f4,f8,f18
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f18.f64));
	// stfs f16,-240(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// fsubs f4,f6,f27
	ctx.f4.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// lfsx f16,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f6,f27,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 + ctx.f6.f64));
	// stfs f16,-224(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -224, temp.u32);
	// fadds f27,f28,f26
	ctx.f27.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// lfsx f16,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// lfsx f17,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f26,f25,f24
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfs f16,-236(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fadds f24,f22,f23
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f22,f20,f21
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fmuls f20,f2,f4
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// fmuls f19,f31,f26
	ctx.f19.f64 = double(float(ctx.f31.f64 * ctx.f26.f64));
	// fmuls f18,f29,f25
	ctx.f18.f64 = double(float(ctx.f29.f64 * ctx.f25.f64));
	// fmuls f31,f31,f24
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f24.f64));
	// fmuls f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f23.f64));
	// fmsubs f4,f3,f4,f2
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f4.f64 - ctx.f2.f64));
	// fmadds f3,f3,f27,f20
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f27.f64 + ctx.f20.f64));
	// lfs f27,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f27.f64 = double(temp.f32);
	// lfs f20,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f2,f1,f26,f31
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f26.f64 - ctx.f31.f64));
	// lfs f26,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f31,f30,f23,f18
	ctx.f31.f64 = double(float(ctx.f30.f64 * ctx.f23.f64 + ctx.f18.f64));
	// lfs f18,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f30,f30,f25,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f25.f64 - ctx.f29.f64));
	// lfs f29,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f29.f64 = double(temp.f32);
	// lfs f25,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f16,f18,f17
	ctx.f16.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fmadds f1,f1,f24,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64 + ctx.f19.f64));
	// stfs f16,-232(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -232, temp.u32);
	// lfs f24,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f15,f29,f22
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f22.f64));
	// lfs f23,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f25,f21
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f21.f64));
	// lfs f19,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f16,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f18,-228(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -228, temp.u32);
	// lfs f18,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f18
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f17,-224(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -224, temp.u32);
	// lfs f17,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f17.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f17,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,-240(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// lfs f17,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,-232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -232);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f29,f16
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f16.f64));
	// lfs f29,-228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -228);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f25,f25,f29
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f29.f64));
	// lfs f29,-232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -232);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f29,f27,f29,f15
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f29.f64 + ctx.f15.f64));
	// fmsubs f27,f27,f22,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f22.f64 - ctx.f16.f64));
	// lfs f22,-228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -228);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f19,f18
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// fmsubs f25,f26,f21,f25
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f21.f64 - ctx.f25.f64));
	// lfs f21,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f26,f26,f22,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f22.f64 + ctx.f14.f64));
	// lfs f22,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f23,f22
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// fmuls f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f21.f64));
	// fmuls f14,f19,f17
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// fadds f19,f27,f1
	ctx.f19.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// fsubs f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f27.f64));
	// fmsubs f23,f24,f22,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f22.f64 - ctx.f23.f64));
	// fmadds f24,f24,f21,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f21.f64 + ctx.f16.f64));
	// fmadds f21,f20,f17,f15
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f17.f64 + ctx.f15.f64));
	// fmsubs f20,f20,f18,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f18.f64 - ctx.f14.f64));
	// fadds f17,f25,f5
	ctx.f17.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// fsubs f5,f5,f25
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f25.f64));
	// fadds f18,f26,f8
	ctx.f18.f64 = double(float(ctx.f26.f64 + ctx.f8.f64));
	// fsubs f22,f2,f29
	ctx.f22.f64 = double(float(ctx.f2.f64 - ctx.f29.f64));
	// fsubs f8,f26,f8
	ctx.f8.f64 = double(float(ctx.f26.f64 - ctx.f8.f64));
	// fadds f2,f29,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fsubs f29,f23,f31
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f31.f64));
	// fadds f27,f24,f30
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// fsubs f26,f4,f21
	ctx.f26.f64 = double(float(ctx.f4.f64 - ctx.f21.f64));
	// fadds f25,f20,f3
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f3.f64));
	// fsubs f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 - ctx.f30.f64));
	// fadds f4,f21,f4
	ctx.f4.f64 = double(float(ctx.f21.f64 + ctx.f4.f64));
	// fadds f31,f23,f31
	ctx.f31.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// fsubs f3,f3,f20
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f20.f64));
	// fadds f24,f29,f22
	ctx.f24.f64 = double(float(ctx.f29.f64 + ctx.f22.f64));
	// fadds f21,f27,f19
	ctx.f21.f64 = double(float(ctx.f27.f64 + ctx.f19.f64));
	// fadds f16,f17,f26
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// fadds f14,f18,f25
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// stfs f14,-228(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -228, temp.u32);
	// fsubs f29,f22,f29
	ctx.f29.f64 = double(float(ctx.f22.f64 - ctx.f29.f64));
	// fsubs f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// fsubs f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 - ctx.f27.f64));
	// fsubs f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// fadds f20,f30,f1
	ctx.f20.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fsubs f15,f5,f4
	ctx.f15.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fadds f14,f16,f24
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// stfs f14,-232(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -232, temp.u32);
	// fsubs f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// fmuls f17,f25,f12
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// fmuls f16,f27,f12
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fmuls f24,f24,f11
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// lfs f23,-228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -228);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// lfs f14,-228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -228);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// fmuls f23,f23,f11
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// stfs f23,-224(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -224, temp.u32);
	// lfs f23,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f14,f10
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// fmuls f22,f23,f6
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// fmuls f21,f23,f28
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// lfs f23,-232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -232);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f19,f23,f10
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// lfs f23,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f28,f23,f28,f22
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f28.f64 + ctx.f22.f64));
	// fmsubs f6,f23,f6,f21
	ctx.f6.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 - ctx.f21.f64));
	// fmuls f22,f29,f12
	ctx.f22.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// addic. r25,r25,-1
	ctx.xer.ca = ctx.r25.u32 > 0;
	ctx.r25.s64 = ctx.r25.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// fmuls f23,f26,f12
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// addi r11,r11,72
	ctx.r11.s64 = ctx.r11.s64 + 72;
	// fmadds f27,f27,f13,f17
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fmsubs f25,f25,f13,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 - ctx.f16.f64));
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fmsubs f26,f26,f13,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 - ctx.f22.f64));
	// fadds f22,f31,f2
	ctx.f22.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// fmadds f29,f29,f13,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f13.f64 + ctx.f23.f64));
	// fsubs f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// fadds f21,f22,f15
	ctx.f21.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// fsubs f23,f15,f22
	ctx.f23.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// fsubs f22,f9,f28
	ctx.f22.f64 = double(float(ctx.f9.f64 - ctx.f28.f64));
	// fadds f9,f28,f9
	ctx.f9.f64 = double(float(ctx.f28.f64 + ctx.f9.f64));
	// fadds f28,f6,f7
	ctx.f28.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// fsubs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// fmuls f6,f21,f11
	ctx.f6.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// lfs f21,-232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -232);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f22
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fmsubs f22,f22,f0,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 - ctx.f19.f64));
	// lfs f19,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f19.f64 = double(temp.f32);
	// fadds f17,f14,f28
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// fmsubs f28,f28,f0,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 - ctx.f18.f64));
	// fmuls f21,f21,f0
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// stfs f21,0(r4)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f21,f22,f24
	ctx.f21.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// fadds f22,f28,f19
	ctx.f22.f64 = double(float(ctx.f28.f64 + ctx.f19.f64));
	// fsubs f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// fmuls f18,f17,f0
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fadds f19,f21,f27
	ctx.f19.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// stfsx f19,r9,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// stfsx f27,r31,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f27,f24,f25
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfsx f27,r10,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f27,f25,f24
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfsx f27,r7,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// stfs f18,0(r3)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f27,f22,f29
	ctx.f27.f64 = double(float(ctx.f22.f64 - ctx.f29.f64));
	// stfsx f27,r9,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f29,f22,f29
	ctx.f29.f64 = double(float(ctx.f22.f64 + ctx.f29.f64));
	// stfsx f29,r31,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fsubs f29,f28,f26
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfsx f29,r10,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f29,f28,f26
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// fadds f28,f8,f3
	ctx.f28.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// stfsx f29,r7,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// fsubs f8,f8,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f3.f64));
	// add r3,r30,r3
	ctx.r3.u64 = ctx.r30.u64 + ctx.r3.u64;
	// fsubs f3,f1,f30
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// add r4,r30,r4
	ctx.r4.u64 = ctx.r30.u64 + ctx.r4.u64;
	// fmuls f1,f9,f0
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f27,f5,f12
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fadds f29,f28,f20
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f20.f64));
	// fsubs f31,f20,f28
	ctx.f31.f64 = double(float(ctx.f20.f64 - ctx.f28.f64));
	// fmuls f30,f3,f13
	ctx.f30.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmadds f4,f23,f10,f1
	ctx.f4.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 + ctx.f1.f64));
	// fsubs f1,f23,f9
	ctx.f1.f64 = double(float(ctx.f23.f64 - ctx.f9.f64));
	// fmuls f28,f2,f12
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fmuls f9,f31,f11
	ctx.f9.f64 = double(float(ctx.f31.f64 * ctx.f11.f64));
	// fmuls f31,f3,f12
	ctx.f31.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// stfsx f1,r9,r6
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fmuls f1,f29,f10
	ctx.f1.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// fadds f29,f29,f7
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// fmsubs f5,f5,f13,f28
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 - ctx.f28.f64));
	// fmadds f3,f8,f13,f31
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 + ctx.f31.f64));
	// fmsubs f8,f8,f12,f30
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 - ctx.f30.f64));
	// fmsubs f7,f7,f0,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 - ctx.f1.f64));
	// fsubs f1,f4,f6
	ctx.f1.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fmadds f4,f2,f13,f27
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f27.f64));
	// fmuls f31,f29,f0
	ctx.f31.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fsubs f2,f7,f9
	ctx.f2.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// fadds f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fadds f7,f1,f3
	ctx.f7.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// stfs f7,0(r27)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fsubs f7,f3,f1
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// stfsx f7,r10,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f7,f6,f8
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f7,0(r29)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fsubs f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f8,0(r6)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// stfsx f31,r9,r5
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f2,f5
	ctx.f8.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// stfs f8,0(r26)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fsubs f8,f2,f5
	ctx.f8.f64 = double(float(ctx.f2.f64 - ctx.f5.f64));
	// stfsx f8,r10,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f9,f4
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f4.f64));
	// stfs f8,0(r28)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fsubs f9,f9,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f4.f64));
	// stfs f9,0(r5)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r10,3532(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 3532);
	// subf r6,r30,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r30.s64;
	// subf r5,r30,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r30.s64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d46154
	if (!ctx.cr0.eq) goto loc_82D46154;
loc_82D46568:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f2c
	ctx.lr = 0x82D46570;
	__restfpr_14(ctx, base);
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D46578"))) PPC_WEAK_FUNC(sub_82D46578);
PPC_FUNC_IMPL(__imp__sub_82D46578) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-3256
	ctx.r5.s64 = ctx.r11.s64 + -3256;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,24824
	ctx.r4.s64 = ctx.r11.s64 + 24824;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D46590"))) PPC_WEAK_FUNC(sub_82D46590);
PPC_FUNC_IMPL(__imp__sub_82D46590) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D46598;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28ee0
	ctx.lr = 0x82D465A0;
	__savefpr_14(ctx, base);
	// mulli r11,r9,56
	ctx.r11.s64 = ctx.r9.s64 * 56;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-56
	ctx.r11.s64 = ctx.r11.s64 + -56;
	// bge cr6,0x82d46890
	if (!ctx.cr6.lt) goto loc_82D46890;
	// subf r30,r9,r10
	ctx.r30.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f13,-3664(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -3664);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-28552(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
loc_82D465D4:
	// lfs f11,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f31,f11,f12
	ctx.f31.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// lfs f9,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfs f7,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// lfs f10,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// add r29,r10,r4
	ctx.r29.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lfs f8,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f11,f10,f9
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fadds f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// add r28,r9,r6
	ctx.r28.u64 = ctx.r9.u64 + ctx.r6.u64;
	// lfsx f30,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f30.f64 = double(temp.f32);
	// mulli r7,r8,12
	ctx.r7.s64 = ctx.r8.s64 * 12;
	// lfsx f29,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfs f9,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f28,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfs f27,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f7,f31
	ctx.f20.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// lfsx f26,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f19,f8,f31
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// lfsx f31,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f31.f64 = double(temp.f32);
	// add r27,r9,r5
	ctx.r27.u64 = ctx.r9.u64 + ctx.r5.u64;
	// lfsx f24,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// add r26,r7,r6
	ctx.r26.u64 = ctx.r7.u64 + ctx.r6.u64;
	// lfsx f22,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// add r25,r7,r5
	ctx.r25.u64 = ctx.r7.u64 + ctx.r5.u64;
	// lfs f5,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f5.f64 = double(temp.f32);
	// lfs f3,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f3.f64 = double(temp.f32);
	// lfs f6,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f6.f64 = double(temp.f32);
	// lfs f4,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f4.f64 = double(temp.f32);
	// lfs f25,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// lfs f23,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f8,f8,f11,f20
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f11.f64 - ctx.f20.f64));
	// lfs f21,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f11,f7,f11,f19
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f11.f64 + ctx.f19.f64));
	// lfs f1,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fadds f7,f30,f9
	ctx.f7.f64 = double(float(ctx.f30.f64 + ctx.f9.f64));
	// lfs f2,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f30.f64));
	// lfs f18,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f30,f29,f31
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f31.f64));
	// fadds f31,f31,f29
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f29.f64));
	// fsubs f29,f28,f27
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fadds f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fsubs f25,f24,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fadds f23,f21,f22
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fmuls f20,f5,f30
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fmuls f21,f5,f7
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// fmuls f19,f3,f31
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f3,f3,f9
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// fmuls f16,f1,f29
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f29.f64));
	// fmuls f15,f1,f27
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// fmsubs f7,f6,f7,f20
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f7.f64 - ctx.f20.f64));
	// lfs f20,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f5,f6,f30,f21
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f30.f64 + ctx.f21.f64));
	// lfs f30,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f9,f4,f9,f19
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 - ctx.f19.f64));
	// lfs f19,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f6,f4,f31,f3
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f31.f64 + ctx.f3.f64));
	// lfs f21,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f27,f2,f27,f16
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f27.f64 + ctx.f16.f64));
	// lfs f31,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f31.f64 = double(temp.f32);
	// fmsubs f2,f2,f29,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f29.f64 - ctx.f15.f64));
	// fmuls f15,f20,f24
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f24.f64));
	// fmuls f29,f30,f28
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmuls f16,f30,f26
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f26.f64));
	// fmuls f20,f20,f22
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f22.f64));
	// fsubs f3,f11,f7
	ctx.f3.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// fadds f4,f5,f8
	ctx.f4.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// fsubs f1,f12,f9
	ctx.f1.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// fmuls f14,f19,f23
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// fsubs f17,f4,f3
	ctx.f17.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fsubs f3,f10,f6
	ctx.f3.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fmuls f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f23.f64));
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// fmadds f30,f31,f26,f29
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f26.f64 + ctx.f29.f64));
	// addi r11,r11,56
	ctx.r11.s64 = ctx.r11.s64 + 56;
	// fmsubs f31,f31,f28,f16
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f28.f64 - ctx.f16.f64));
	// fmsubs f28,f21,f24,f20
	ctx.f28.f64 = double(float(ctx.f21.f64 * ctx.f24.f64 - ctx.f20.f64));
	// fmadds f29,f21,f22,f15
	ctx.f29.f64 = double(float(ctx.f21.f64 * ctx.f22.f64 + ctx.f15.f64));
	// fmadds f26,f18,f25,f14
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f25.f64 + ctx.f14.f64));
	// fadds f12,f9,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f12.f64));
	// fsubs f9,f8,f5
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// fadds f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// fadds f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fmsubs f25,f19,f25,f23
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f25.f64 - ctx.f23.f64));
	// fsubs f23,f28,f31
	ctx.f23.f64 = double(float(ctx.f28.f64 - ctx.f31.f64));
	// fsubs f24,f30,f29
	ctx.f24.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fsubs f22,f27,f26
	ctx.f22.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// fadds f8,f29,f30
	ctx.f8.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fadds f5,f28,f31
	ctx.f5.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// fadds f7,f26,f27
	ctx.f7.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f21,f2,f25
	ctx.f21.f64 = double(float(ctx.f2.f64 - ctx.f25.f64));
	// fadds f2,f25,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// fadds f25,f24,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// fsubs f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// fsubs f23,f1,f22
	ctx.f23.f64 = double(float(ctx.f1.f64 - ctx.f22.f64));
	// fadds f1,f22,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 + ctx.f1.f64));
	// fadds f22,f21,f3
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f3.f64));
	// fsubs f21,f3,f21
	ctx.f21.f64 = double(float(ctx.f3.f64 - ctx.f21.f64));
	// fadds f6,f12,f2
	ctx.f6.f64 = double(float(ctx.f12.f64 + ctx.f2.f64));
	// fsubs f12,f12,f2
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f2.f64));
	// fsubs f19,f17,f25
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f25.f64));
	// fadds f20,f4,f24
	ctx.f20.f64 = double(float(ctx.f4.f64 + ctx.f24.f64));
	// fmuls f3,f23,f0
	ctx.f3.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fsubs f18,f24,f4
	ctx.f18.f64 = double(float(ctx.f24.f64 - ctx.f4.f64));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f23,f22,f0
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmuls f22,f21,f0
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fadds f21,f17,f25
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// fmuls f24,f19,f13
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmuls f25,f20,f13
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// fmuls f4,f21,f13
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmuls f21,f18,f13
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// fadds f20,f4,f3
	ctx.f20.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// stfsx f20,r9,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f20,f23,f25
	ctx.f20.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// stfsx f20,r9,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// stfsx f4,r10,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f4,f23,f25
	ctx.f4.f64 = double(float(ctx.f23.f64 - ctx.f25.f64));
	// stfsx f4,r10,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f4,f22,f24
	ctx.f4.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// stfs f4,0(r5)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f4,f21,f1
	ctx.f4.f64 = double(float(ctx.f21.f64 - ctx.f1.f64));
	// stfs f4,0(r6)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f4,f22,f24
	ctx.f4.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfsx f4,r7,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f4,f21,f1
	ctx.f4.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// stfsx f4,r7,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f4,f9,f8
	ctx.f4.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// subf r5,r31,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r31.s64;
	// fadds f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// subf r6,r31,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r31.s64;
	// fadds f8,f11,f5
	ctx.f8.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// fsubs f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 - ctx.f11.f64));
	// fadds f5,f7,f10
	ctx.f5.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fsubs f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// fadds f7,f4,f6
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fsubs f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fsubs f4,f11,f12
	ctx.f4.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// fadds f3,f5,f8
	ctx.f3.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// fadds f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// fsubs f8,f5,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f8.f64));
	// fsubs f5,f10,f9
	ctx.f5.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fadds f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f9.f64));
	// fmuls f11,f7,f0
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmuls f11,f6,f0
	ctx.f11.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fmuls f9,f4,f0
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f7,f3,f0
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// stfs f7,0(r3)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f11,0(r26)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fmuls f11,f8,f0
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// stfs f11,0(r25)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fmuls f11,f5,f0
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// stfs f11,0(r27)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// stfs f9,0(r28)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fmuls f11,f10,f0
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// stfsx f11,r10,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f12,0(r29)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// lwz r10,3532(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 3532);
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d465d4
	if (!ctx.cr0.eq) goto loc_82D465D4;
loc_82D46890:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f2c
	ctx.lr = 0x82D46898;
	__restfpr_14(ctx, base);
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D468A0"))) PPC_WEAK_FUNC(sub_82D468A0);
PPC_FUNC_IMPL(__imp__sub_82D468A0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-3184
	ctx.r5.s64 = ctx.r11.s64 + -3184;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,26000
	ctx.r4.s64 = ctx.r11.s64 + 26000;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D468B8"))) PPC_WEAK_FUNC(sub_82D468B8);
PPC_FUNC_IMPL(__imp__sub_82D468B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82D468C0;
	__savegprlr_27(ctx, base);
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82e28eec
	ctx.lr = 0x82D468C8;
	__savefpr_17(ctx, base);
	// mulli r11,r9,40
	ctx.r11.s64 = ctx.r9.s64 * 40;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-40
	ctx.r11.s64 = ctx.r11.s64 + -40;
	// bge cr6,0x82d46b04
	if (!ctx.cr6.lt) goto loc_82D46B04;
	// subf r28,r9,r10
	ctx.r28.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r31,-32255
	ctx.r31.s64 = -2113863680;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f12,-12288(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -12288);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,-28552(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,-6316(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6316);
	ctx.f13.f64 = double(temp.f32);
loc_82D46904:
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f2,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// add r31,r9,r4
	ctx.r31.u64 = ctx.r9.u64 + ctx.r4.u64;
	// fadds f28,f2,f3
	ctx.f28.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfs f31,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// add r30,r9,r3
	ctx.r30.u64 = ctx.r9.u64 + ctx.r3.u64;
	// lfs f1,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// fsubs f2,f1,f31
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// lfsx f27,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// lfsx f25,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfs f31,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// add r29,r10,r4
	ctx.r29.u64 = ctx.r10.u64 + ctx.r4.u64;
	// fsubs f20,f31,f27
	ctx.f20.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// lfs f26,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fadds f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// lfsx f23,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfsx f24,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfsx f21,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f25,f24,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f22,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfs f10,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// fadds f23,f21,f22
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f8,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f7,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f7.f64 = double(temp.f32);
	// lfs f9,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f9.f64 = double(temp.f32);
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// lfs f11,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f21,f10,f20
	ctx.f21.f64 = double(float(ctx.f10.f64 * ctx.f20.f64));
	// lfs f6,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f18,f7,f31
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// lfs f29,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f10,f10,f27
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// lfs f4,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f17,f7,f26
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// lfs f30,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f19,f8,f25
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// lfs f5,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f25,f9,f25
	ctx.f25.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// addi r11,r11,40
	ctx.r11.s64 = ctx.r11.s64 + 40;
	// fmadds f7,f6,f26,f18
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f26.f64 + ctx.f18.f64));
	// fmsubs f10,f11,f20,f10
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f20.f64 - ctx.f10.f64));
	// fmadds f11,f11,f27,f21
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f27.f64 + ctx.f21.f64));
	// fmadds f9,f9,f23,f19
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f23.f64 + ctx.f19.f64));
	// fmuls f27,f4,f24
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f24.f64));
	// fmuls f26,f29,f28
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f28.f64));
	// fmsubs f8,f8,f23,f25
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f23.f64 - ctx.f25.f64));
	// fmuls f25,f5,f24
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// fmuls f28,f30,f28
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmsubs f6,f6,f31,f17
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64 - ctx.f17.f64));
	// fsubs f31,f10,f9
	ctx.f31.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fadds f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f9,f3,f7
	ctx.f9.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// fadds f7,f7,f3
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// fmsubs f3,f30,f2,f26
	ctx.f3.f64 = double(float(ctx.f30.f64 * ctx.f2.f64 - ctx.f26.f64));
	// fmsubs f5,f5,f22,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 - ctx.f27.f64));
	// fmadds f2,f29,f2,f28
	ctx.f2.f64 = double(float(ctx.f29.f64 * ctx.f2.f64 + ctx.f28.f64));
	// fmadds f4,f4,f22,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f22.f64 + ctx.f25.f64));
	// fadds f27,f8,f11
	ctx.f27.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// fsubs f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// fadds f8,f6,f1
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f1.f64));
	// fsubs f6,f1,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 - ctx.f6.f64));
	// fadds f1,f3,f5
	ctx.f1.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// fadds f3,f2,f4
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fsubs f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fadds f2,f1,f31
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f31.f64));
	// fsubs f29,f31,f1
	ctx.f29.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// fadds f1,f3,f27
	ctx.f1.f64 = double(float(ctx.f3.f64 + ctx.f27.f64));
	// fadds f31,f4,f11
	ctx.f31.f64 = double(float(ctx.f4.f64 + ctx.f11.f64));
	// fsubs f30,f5,f10
	ctx.f30.f64 = double(float(ctx.f5.f64 - ctx.f10.f64));
	// fsubs f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 - ctx.f3.f64));
	// fsubs f4,f4,f11
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f11.f64));
	// fadds f28,f5,f10
	ctx.f28.f64 = double(float(ctx.f5.f64 + ctx.f10.f64));
	// fmuls f10,f3,f13
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f3,f2,f12
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fmuls f5,f4,f13
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fmuls f4,f28,f13
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// fmuls f28,f1,f12
	ctx.f28.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// fmuls f11,f29,f13
	ctx.f11.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// fmuls f29,f30,f12
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// fadds f2,f2,f9
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f9.f64));
	// fmuls f27,f31,f12
	ctx.f27.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// fadds f1,f1,f8
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f8.f64));
	// fadds f31,f31,f6
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// fmsubs f9,f9,f0,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 - ctx.f3.f64));
	// fsubs f30,f30,f7
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f7.f64));
	// fmsubs f8,f8,f0,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f28.f64));
	// fmadds f7,f7,f0,f29
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 + ctx.f29.f64));
	// fmuls f3,f2,f0
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f3,0(r4)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmsubs f6,f6,f0,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 - ctx.f27.f64));
	// add r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fmuls f3,f1,f0
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f1,f31,f0
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fsubs f31,f10,f9
	ctx.f31.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// stfsx f31,r9,r6
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// stfs f10,0(r29)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fmuls f2,f30,f0
	ctx.f2.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fsubs f9,f8,f11
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f11.f64));
	// stfsx f9,r10,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfs f3,0(r3)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// stfsx f11,r9,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f10,f5,f7
	ctx.f10.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// stfsx f2,r10,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f11,f7,f5
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// stfs f10,0(r6)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f9,f6,f4
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// stfs f11,0(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fsubs f10,f6,f4
	ctx.f10.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// stfs f9,0(r30)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// add r3,r7,r3
	ctx.r3.u64 = ctx.r7.u64 + ctx.r3.u64;
	// stfsx f1,r10,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// subf r6,r7,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r7.s64;
	// stfs f10,0(r5)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r10,3532(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 3532);
	// subf r5,r7,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r7.s64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d46904
	if (!ctx.cr0.eq) goto loc_82D46904;
loc_82D46B04:
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82e28f38
	ctx.lr = 0x82D46B0C;
	__restfpr_17(ctx, base);
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D46B10"))) PPC_WEAK_FUNC(sub_82D46B10);
PPC_FUNC_IMPL(__imp__sub_82D46B10) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-3128
	ctx.r5.s64 = ctx.r11.s64 + -3128;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,26808
	ctx.r4.s64 = ctx.r11.s64 + 26808;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D46B28"))) PPC_WEAK_FUNC(sub_82D46B28);
PPC_FUNC_IMPL(__imp__sub_82D46B28) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// stfd f30,-24(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.f30.u64);
	// stfd f31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.f31.u64);
	// mulli r11,r9,24
	ctx.r11.s64 = ctx.r9.s64 * 24;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r7,r11,-24
	ctx.r7.s64 = ctx.r11.s64 + -24;
	// bge cr6,0x82d46c90
	if (!ctx.cr6.lt) goto loc_82D46C90;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f0,-28552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
loc_82D46B60:
	// lfs f12,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fadds f3,f12,f13
	ctx.f3.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f11,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f9,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f12,f11,f10
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// lfsx f2,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f10,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f1,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfs f4,20(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	ctx.f4.f64 = double(temp.f32);
	// lfs f6,12(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,16(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f31,f8,f3
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// lfs f7,8(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f30,f9,f3
	ctx.f30.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// lfsx f3,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f3.f64 = double(temp.f32);
	// addi r7,r7,24
	ctx.r7.s64 = ctx.r7.s64 + 24;
	// fmsubs f9,f9,f12,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 - ctx.f31.f64));
	// fmadds f12,f8,f12,f30
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 + ctx.f30.f64));
	// fsubs f8,f10,f2
	ctx.f8.f64 = double(float(ctx.f10.f64 - ctx.f2.f64));
	// fadds f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 + ctx.f10.f64));
	// fadds f2,f3,f1
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// fsubs f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// fmuls f30,f6,f8
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f1,f4,f10
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fmuls f31,f6,f2
	ctx.f31.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// fmadds f6,f5,f3,f1
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f3.f64 + ctx.f1.f64));
	// fmsubs f8,f7,f8,f31
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 - ctx.f31.f64));
	// fmadds f7,f7,f2,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f2.f64 + ctx.f30.f64));
	// fmsubs f10,f5,f10,f4
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 - ctx.f4.f64));
	// fsubs f4,f9,f6
	ctx.f4.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// fadds f5,f8,f13
	ctx.f5.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// fadds f9,f6,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// fadds f6,f7,f11
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// fsubs f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// fadds f7,f10,f12
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// fsubs f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// fadds f10,f4,f5
	ctx.f10.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f8,f4,f5
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// fsubs f5,f11,f9
	ctx.f5.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// fsubs f4,f6,f7
	ctx.f4.f64 = double(float(ctx.f6.f64 - ctx.f7.f64));
	// fadds f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f6.f64));
	// fadds f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fadds f9,f12,f13
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fsubs f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// fmuls f12,f10,f0
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// stfs f12,0(r4)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmuls f12,f8,f0
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// stfsx f12,r11,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fmuls f12,f5,f0
	ctx.f12.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f10,f4,f0
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// stfsx f10,r11,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fmuls f10,f7,f0
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// stfs f10,0(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fmuls f12,f11,f0
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// stfsx f12,r11,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fmuls f12,f9,f0
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// stfsx f12,r11,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f13,0(r6)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lwz r11,3532(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3532);
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// subf r5,r31,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r31.s64;
	// subf r6,r31,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r31.s64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bne 0x82d46b60
	if (!ctx.cr0.eq) goto loc_82D46B60;
loc_82D46C90:
	// lfd f30,-24(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// lfd f31,-16(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D46CA0"))) PPC_WEAK_FUNC(sub_82D46CA0);
PPC_FUNC_IMPL(__imp__sub_82D46CA0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-3072
	ctx.r5.s64 = ctx.r11.s64 + -3072;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,27432
	ctx.r4.s64 = ctx.r11.s64 + 27432;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D46CB8"))) PPC_WEAK_FUNC(sub_82D46CB8);
PPC_FUNC_IMPL(__imp__sub_82D46CB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// addi r11,r11,-8
	ctx.r11.s64 = ctx.r11.s64 + -8;
	// bgelr cr6
	if (!ctx.cr6.lt) return;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,-28552(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
loc_82D46CE0:
	// lfs f12,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fadds f7,f12,f13
	ctx.f7.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f8,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f12,f11,f10
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// lfs f9,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// fmuls f10,f8,f7
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fmuls f7,f9,f7
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// fmsubs f10,f9,f12,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 - ctx.f10.f64));
	// fmadds f12,f8,f12,f7
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 + ctx.f7.f64));
	// fadds f9,f10,f13
	ctx.f9.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// fadds f8,f12,f11
	ctx.f8.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// fsubs f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 - ctx.f13.f64));
	// fsubs f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// fmuls f11,f9,f0
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmuls f11,f8,f0
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// stfs f11,0(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f13,0(r6)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fmuls f13,f12,f0
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f13,0(r5)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// add r3,r8,r3
	ctx.r3.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r4,r8,r4
	ctx.r4.u64 = ctx.r8.u64 + ctx.r4.u64;
	// subf r5,r8,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r8.s64;
	// subf r6,r8,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r8.s64;
	// bne 0x82d46ce0
	if (!ctx.cr0.eq) goto loc_82D46CE0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D46D68"))) PPC_WEAK_FUNC(sub_82D46D68);
PPC_FUNC_IMPL(__imp__sub_82D46D68) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r11,-3016
	ctx.r5.s64 = ctx.r11.s64 + -3016;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,27832
	ctx.r4.s64 = ctx.r11.s64 + 27832;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D46D80"))) PPC_WEAK_FUNC(sub_82D46D80);
PPC_FUNC_IMPL(__imp__sub_82D46D80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D46D88;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D46D90;
	__savefpr_14(ctx, base);
	// rlwinm r11,r9,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// addi r11,r11,-32
	ctx.r11.s64 = ctx.r11.s64 + -32;
	// bge cr6,0x82d484ac
	if (!ctx.cr6.lt) goto loc_82D484AC;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r17,r7,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// stw r10,-360(r1)
	PPC_STORE_U32(ctx.r1.u32 + -360, ctx.r10.u32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r7,-32236
	ctx.r7.s64 = -2112618496;
	// lfs f31,-8012(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8012);
	ctx.f31.f64 = double(temp.f32);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f1,-8008(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -8008);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,-8004(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8004);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,-8000(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8000);
	ctx.f3.f64 = double(temp.f32);
	// lfs f10,136(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 136);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f12.f64 = double(temp.f32);
loc_82D46DEC:
	// lfs f0,24(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// lfs f9,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f30,f0,f9
	ctx.f30.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// lfs f7,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f25,f0,f8
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f6,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f9,f7
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f8,f6
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// lfs f4,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f29,f5,f7
	ctx.f29.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// fmuls f28,f4,f6
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f13,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f26,f4,f7
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// fmuls f27,f5,f6
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fmuls f20,f0,f5
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// fmuls f16,f13,f4
	ctx.f16.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fmadds f30,f13,f8,f30
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 + ctx.f30.f64));
	// stfs f30,-388(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fmuls f19,f0,f6
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// fmuls f15,f13,f7
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fmsubs f30,f13,f9,f25
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 - ctx.f25.f64));
	// stfs f30,-384(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fmuls f21,f8,f7
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fadds f30,f28,f29
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fsubs f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fadds f28,f26,f27
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fadds f26,f22,f24
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f22,f16,f20
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f22,-424(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// fadds f22,f15,f19
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f22,-520(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fmuls f23,f9,f6
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f18,f0,f4
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// fmuls f22,f13,f5
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// fmuls f17,f0,f7
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fsubs f25,f21,f23
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fsubs f21,f22,f18
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f21,-412(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fmuls f21,f13,f6
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// stfs f22,-568(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// fsubs f22,f15,f19
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f22,-400(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fmuls f19,f13,f27
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f27.f64));
	// fmuls f18,f0,f27
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f27.f64));
	// fmuls f15,f25,f0
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fsubs f22,f17,f21
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// stfs f22,-572(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// fsubs f22,f20,f16
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f22,-436(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fmuls f16,f26,f0
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fadds f14,f21,f17
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// stfs f14,-392(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fmuls f14,f24,f0
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f22,f0,f30
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmuls f21,f13,f30
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// fmuls f20,f0,f29
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// fmuls f17,f13,f28
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// fmadds f16,f25,f13,f16
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f16,-544(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fmsubs f16,f26,f13,f15
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f16,-508(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fmadds f16,f23,f13,f14
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f16,-488(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// fadds f16,f19,f22
	ctx.f16.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f16,-480(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f22,-548(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// fsubs f22,f21,f18
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f22,-440(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fadds f22,f18,f21
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f22,-496(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fsubs f22,f20,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f22,-432(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fadds f22,f17,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f22,-380(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fmuls f21,f0,f28
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// rlwinm r10,r8,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fmuls f22,f13,f29
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// fmuls f18,f8,f5
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// fmuls f19,f9,f4
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// fmuls f16,f9,f30
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fmuls f15,f8,f27
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmuls f17,f8,f4
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fmuls f14,f8,f30
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fadds f20,f21,f22
	ctx.f20.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f20,-532(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,-404(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// fmuls f22,f9,f27
	ctx.f22.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// stfs f22,-512(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fadds f21,f18,f19
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f19,-500(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// fmuls f18,f23,f0
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f20,f9,f5
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmsubs f18,f24,f13,f18
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f18,-456(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// fsubs f22,f20,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fsubs f18,f16,f15
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f18,-372(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,-484(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fadds f18,f15,f16
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f18,-472(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fmuls f16,f8,f28
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// lfs f17,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f17.f64 = double(temp.f32);
	// fadds f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f18,-556(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,-416(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// fmuls f17,f9,f29
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// fmuls f14,f19,f0
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fsubs f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f15,-364(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,-420(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// fmuls f16,f9,f28
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f17,f8,f29
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// fadds f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f15,-368(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,-408(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// fmuls f15,f20,f0
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmsubs f20,f20,f13,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f20,-492(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfsx f20,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f22,f0
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f20,-512(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fmuls f16,f21,f0
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// lfs f20,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmadds f19,f19,f13,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f19,-536(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfsx f19,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-428(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fmuls f19,f18,f0
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fmadds f17,f21,f13,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f17,-444(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fmsubs f17,f22,f13,f16
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f17,-452(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fmadds f20,f18,f13,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f20.f64));
	// stfs f20,-540(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f20,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmsubs f20,f20,f13,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f19.f64));
	// stfs f20,-476(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f17,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f15,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f20,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmuls f18,f19,f0
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f19,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f17,f19,f13,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 - ctx.f17.f64));
	// stfs f17,-528(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f17,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f17.f64 = double(temp.f32);
	// rlwinm r7,r8,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fmadds f17,f17,f13,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f17,-552(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfs f17,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f17.f64 = double(temp.f32);
	// mulli r9,r8,48
	ctx.r9.s64 = ctx.r8.s64 * 48;
	// fmadds f17,f17,f13,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f17,-504(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f17,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f13,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f17,-524(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f17,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f20,f17,f13,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f20.f64));
	// stfs f20,-448(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f20,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f13,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f18.f64));
	// stfs f20,-576(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// lfs f20,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f20,f18
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f18.f64));
	// lfs f17,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f20,f17
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f17.f64));
	// lfs f16,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f16.f64 = double(temp.f32);
	// lfs f20,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f17,f16,f17,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f17.f64 + ctx.f15.f64));
	// lfs f15,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f16,f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 - ctx.f14.f64));
	// stfs f16,-540(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// fmuls f15,f20,f7
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// fmuls f14,f20,f6
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// lfs f20,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fadds f16,f17,f20
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f16,-564(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// lfsx f16,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f16,-512(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fmadds f6,f18,f6,f15
	ctx.f6.f64 = double(float(ctx.f18.f64 * ctx.f6.f64 + ctx.f15.f64));
	// stfs f20,-472(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fmsubs f7,f18,f7,f14
	ctx.f7.f64 = double(float(ctx.f18.f64 * ctx.f7.f64 - ctx.f14.f64));
	// lfs f20,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f16,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f7,-460(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfsx f7,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f18,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,-476(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfsx f18,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f6,-396(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfsx f6,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfs f17,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f20,f17
	ctx.f17.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f17,-464(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f17,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f17,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f17.f64 = double(temp.f32);
	// stfs f20,-376(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfsx f20,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f15,f17
	ctx.f14.f64 = double(float(ctx.f15.f64 * ctx.f17.f64));
	// lfsx f17,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-428(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f17,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f17.f64));
	// fmadds f17,f16,f17,f14
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,-540(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f17,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f16,f17,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,-488(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f17,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f7,f17
	ctx.f16.f64 = double(float(ctx.f7.f64 * ctx.f17.f64));
	// lfs f17,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f7,f17
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f17.f64));
	// lfs f7,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f14,f20,f7
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// lfs f7,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f20,f7
	ctx.f7.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// fmuls f20,f18,f26
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f26.f64));
	// stfs f7,-512(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fmadds f7,f6,f17,f16
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f17.f64 + ctx.f16.f64));
	// lfs f17,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f18,f25
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// fmsubs f6,f6,f17,f15
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f17,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f17.f64 = double(temp.f32);
	// stfs f20,-476(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// mulli r31,r8,60
	ctx.r31.s64 = ctx.r8.s64 * 60;
	// stfs f18,-456(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// fmr f18,f17
	ctx.f18.f64 = ctx.f17.f64;
	// lfs f17,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f17.f64 = double(temp.f32);
	// mulli r30,r8,28
	ctx.r30.s64 = ctx.r8.s64 * 28;
	// lfs f15,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f20,f18,f17,f14
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f14.f64));
	// lfs f17,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f14.f64 = double(temp.f32);
	// mulli r29,r8,44
	ctx.r29.s64 = ctx.r8.s64 * 44;
	// mulli r28,r8,12
	ctx.r28.s64 = ctx.r8.s64 * 12;
	// lfs f16,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f16.f64));
	// lfs f17,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f25,f17,f25,f16
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f25.f64 + ctx.f16.f64));
	// lfs f16,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f26,f17,f26,f16
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 - ctx.f16.f64));
	// lfs f16,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f7,f25
	ctx.f17.f64 = double(float(ctx.f7.f64 + ctx.f25.f64));
	// fsubs f7,f25,f7
	ctx.f7.f64 = double(float(ctx.f25.f64 - ctx.f7.f64));
	// fsubs f25,f26,f6
	ctx.f25.f64 = double(float(ctx.f26.f64 - ctx.f6.f64));
	// fadds f6,f6,f26
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f26.f64));
	// fadds f26,f17,f16
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// fsubs f16,f15,f7
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f7.f64));
	// fadds f7,f7,f15
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f15.f64));
	// fsubs f15,f14,f25
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// fadds f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// stfs f25,-336(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f25,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f25.f64 = double(temp.f32);
	// fadds f14,f25,f6
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f6.f64));
	// stfs f14,-564(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// fsubs f6,f25,f6
	ctx.f6.f64 = double(float(ctx.f25.f64 - ctx.f6.f64));
	// stfs f6,-468(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f6,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f6.f64 = double(temp.f32);
	// lfs f25,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f6
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f6.f64));
	// stfs f25,-456(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f25,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f25.f64 = double(temp.f32);
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f25
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f25.f64));
	// stfs f14,-412(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f14.f64));
	// stfs f25,-516(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f25,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f6,f6,f25
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f25.f64));
	// lfsx f25,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,-460(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfsx f25,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,-396(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfsx f25,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,-376(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfsx f25,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f6,-560(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// stfs f25,-480(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfsx f6,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f25,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,-512(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fmuls f25,f6,f9
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-440(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fmuls f14,f6,f8
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// lfsx f6,r29,r6
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r6.u32);
	ctx.f6.f64 = double(temp.f32);
	// stfs f6,-476(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfsx f6,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// stfs f6,-488(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f6,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f8,f6,f8,f25
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64 + ctx.f25.f64));
	// stfs f8,-424(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfsx f8,r28,r6
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r6.u32);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f9,f6,f9,f14
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 - ctx.f14.f64));
	// stfs f8,-428(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// stfs f9,-460(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f8,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f6,f8,f9
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f9,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f25,f8,f9
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f8,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f8.f64 = double(temp.f32);
	// lfs f14,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f8,f14
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f14.f64));
	// lfs f8,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f9,f8,f9,f6
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f9.f64 + ctx.f6.f64));
	// stfs f9,-540(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f9,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f9.f64 = double(temp.f32);
	// lfs f6,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f9,f6
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// lfs f9,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f9,f8,f9,f25
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f9.f64 - ctx.f25.f64));
	// stfs f9,-464(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f9,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f25,f9,f8
	ctx.f25.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// lfs f9,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f8,f9,f8,f14
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 + ctx.f14.f64));
	// stfs f8,-472(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f8,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f8.f64 = double(temp.f32);
	// lfs f14,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f8,f14
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f14.f64));
	// lfs f8,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f9,f9,f8,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 - ctx.f6.f64));
	// lfs f6,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f6.f64 = double(temp.f32);
	// fadds f6,f6,f20
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f20.f64));
	// stfs f6,-444(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f6,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f6.f64 = double(temp.f32);
	// lfs f8,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f6,f6,f20
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f20.f64));
	// fmuls f8,f8,f19
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f19.f64));
	// stfs f6,-432(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// stfs f8,-532(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f20,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f20.f64 = double(temp.f32);
	// lfs f6,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f6.f64 = double(temp.f32);
	// fmr f8,f6
	ctx.f8.f64 = ctx.f6.f64;
	// fadds f6,f8,f18
	ctx.f6.f64 = double(float(ctx.f8.f64 + ctx.f18.f64));
	// stfs f6,-452(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fsubs f8,f8,f18
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f18.f64));
	// stfs f8,-480(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f6,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f6.f64 = double(temp.f32);
	// lfs f8,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f18,f8,f6
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// lfs f6,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f6.f64 = double(temp.f32);
	// lfs f8,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f8,f6,f8,f25
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64 + ctx.f25.f64));
	// lfs f25,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f6,f6,f25,f14
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f25.f64 - ctx.f14.f64));
	// lfs f25,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f25.f64 = double(temp.f32);
	// lfs f14,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f25,f20,f25,f14
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f25.f64 + ctx.f14.f64));
	// lfs f14,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f20,f20,f19,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64 - ctx.f18.f64));
	// lfs f18,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,-380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f14,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,-424(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f18,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f14,-440(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,-404(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f18,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,-416(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f14,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,-348(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// rlwinm r25,r8,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f18,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f18.f64 = double(temp.f32);
	// mulli r23,r8,56
	ctx.r23.s64 = ctx.r8.s64 * 56;
	// lfs f14,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f14,-412(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f14,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,-356(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fadds f18,f25,f8
	ctx.f18.f64 = double(float(ctx.f25.f64 + ctx.f8.f64));
	// stfs f18,-560(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfs f18,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f8,f25,f8
	ctx.f8.f64 = double(float(ctx.f25.f64 - ctx.f8.f64));
	// fadds f18,f9,f18
	ctx.f18.f64 = double(float(ctx.f9.f64 + ctx.f18.f64));
	// stfs f18,-516(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// fadds f18,f20,f6
	ctx.f18.f64 = double(float(ctx.f20.f64 + ctx.f6.f64));
	// stfs f18,-532(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fsubs f6,f20,f6
	ctx.f6.f64 = double(float(ctx.f20.f64 - ctx.f6.f64));
	// lfs f18,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f14.f64 = double(temp.f32);
	// add r16,r25,r5
	ctx.r16.u64 = ctx.r25.u64 + ctx.r5.u64;
	// lfs f20,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// fsubs f9,f20,f9
	ctx.f9.f64 = double(float(ctx.f20.f64 - ctx.f9.f64));
	// mulli r24,r8,24
	ctx.r24.s64 = ctx.r8.s64 * 24;
	// mulli r27,r8,40
	ctx.r27.s64 = ctx.r8.s64 * 40;
	// add r15,r24,r5
	ctx.r15.u64 = ctx.r24.u64 + ctx.r5.u64;
	// add r19,r23,r5
	ctx.r19.u64 = ctx.r23.u64 + ctx.r5.u64;
	// lfs f20,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f20.f64 = double(temp.f32);
	// fadds f25,f20,f19
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfs f20,-452(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f19,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f14,f20,f19
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfs f14,-432(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfs f20,-444(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fsubs f20,f18,f6
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f6.f64));
	// lfsx f19,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f6,f6,f18
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f18.f64));
	// stfs f6,-316(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fadds f6,f8,f9
	ctx.f6.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// stfs f19,-516(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// lfs f8,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,-560(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// stfs f9,-340(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfsx f9,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f18,f9,f28
	ctx.f18.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f19,f9,f29
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// stfs f6,-540(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// fmuls f9,f8,f21
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f21.f64));
	// lfsx f6,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f14,f8,f22
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f22.f64));
	// lfs f8,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f8.f64 = double(temp.f32);
	// stfs f9,-528(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// fmr f9,f8
	ctx.f9.f64 = ctx.f8.f64;
	// stfs f6,-532(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// stfs f20,-488(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfsx f20,r27,r5
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r5.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-460(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fmuls f20,f20,f9
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f9.f64));
	// fmuls f9,f6,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// lfs f8,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f8.f64 = double(temp.f32);
	// stfs f9,-560(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// fmadds f9,f8,f28,f19
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f28.f64 + ctx.f19.f64));
	// fmsubs f8,f8,f29,f18
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f29.f64 - ctx.f18.f64));
	// lfs f29,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f6,f29,f21,f14
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f21.f64 + ctx.f14.f64));
	// lfs f28,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f28.f64 = double(temp.f32);
	// lfs f21,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f21,f28
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f28.f64));
	// lfs f21,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f21,f28
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f28.f64));
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f29,f29,f22,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f22.f64 - ctx.f14.f64));
	// lfs f28,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f28,f28,f22,f20
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 + ctx.f20.f64));
	// lfs f14,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f20.f64 = double(temp.f32);
	// mulli r21,r8,52
	ctx.r21.s64 = ctx.r8.s64 * 52;
	// fmsubs f22,f20,f22,f14
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f22.f64 - ctx.f14.f64));
	// lfs f20,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f21,f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f19.f64));
	// lfs f19,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f20,f19,f20,f18
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f20.f64 - ctx.f18.f64));
	// add r14,r21,r3
	ctx.r14.u64 = ctx.r21.u64 + ctx.r3.u64;
	// rlwinm r22,r8,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f19,f28,f9
	ctx.f19.f64 = double(float(ctx.f28.f64 + ctx.f9.f64));
	// mulli r20,r8,36
	ctx.r20.s64 = ctx.r8.s64 * 36;
	// fsubs f9,f9,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f28.f64));
	// fadds f18,f22,f8
	ctx.f18.f64 = double(float(ctx.f22.f64 + ctx.f8.f64));
	// fsubs f8,f8,f22
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f22.f64));
	// fadds f28,f21,f6
	ctx.f28.f64 = double(float(ctx.f21.f64 + ctx.f6.f64));
	// stw r14,-428(r1)
	PPC_STORE_U32(ctx.r1.u32 + -428, ctx.r14.u32);
	// fadds f22,f20,f29
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f29.f64));
	// fsubs f29,f20,f29
	ctx.f29.f64 = double(float(ctx.f20.f64 - ctx.f29.f64));
	// lfsx f20,r20,r5
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r5.u32);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f6,f21,f6
	ctx.f6.f64 = double(float(ctx.f21.f64 - ctx.f6.f64));
	// stfs f20,-528(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// mulli r26,r8,20
	ctx.r26.s64 = ctx.r8.s64 * 20;
	// fsubs f21,f8,f9
	ctx.f21.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// fadds f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// lfsx f20,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f8,f28,f19
	ctx.f8.f64 = double(float(ctx.f28.f64 + ctx.f19.f64));
	// stfs f20,-520(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fsubs f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// stfs f28,-460(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fsubs f28,f18,f22
	ctx.f28.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// stfs f28,-480(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fadds f28,f22,f18
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// stfs f28,-464(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fadds f28,f29,f6
	ctx.f28.f64 = double(float(ctx.f29.f64 + ctx.f6.f64));
	// stfs f28,-456(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfsx f28,r22,r5
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r5.u32);
	ctx.f28.f64 = double(temp.f32);
	// add r18,r22,r3
	ctx.r18.u64 = ctx.r22.u64 + ctx.r3.u64;
	// stfs f28,-572(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// fsubs f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f29.f64));
	// lfsx f22,r21,r5
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r5.u32);
	ctx.f22.f64 = double(temp.f32);
	// add r14,r20,r3
	ctx.r14.u64 = ctx.r20.u64 + ctx.r3.u64;
	// stfs f22,-552(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfsx f20,r26,r5
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r5.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-560(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// stw r18,-320(r1)
	PPC_STORE_U32(ctx.r1.u32 + -320, ctx.r18.u32);
	// lfs f20,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f19,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f19.f64 = double(temp.f32);
	// stw r14,-312(r1)
	PPC_STORE_U32(ctx.r1.u32 + -312, ctx.r14.u32);
	// stfs f19,-516(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// fmuls f19,f19,f20
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f20.f64));
	// stfs f6,-472(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfsx f6,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfs f29,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f18,f6,f20
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// lfs f20,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f6,f6,f20,f19
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f20.f64 + ctx.f19.f64));
	// stfs f6,-532(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fmuls f6,f29,f30
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f30.f64));
	// fmuls f20,f29,f27
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f27.f64));
	// lfs f29,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f29.f64 = double(temp.f32);
	// lwz r18,-428(r1)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	// lfs f28,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f19,f28,f29
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f29.f64));
	// lfs f29,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f14,f28,f29
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f29.f64));
	// lfs f29,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f29.f64 = double(temp.f32);
	// lfs f28,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f29,f22,f29
	ctx.f29.f64 = double(float(ctx.f22.f64 * ctx.f29.f64));
	// fmuls f22,f22,f28
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// stfs f29,-568(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// lfs f28,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f28.f64 = double(temp.f32);
	// fmr f29,f28
	ctx.f29.f64 = ctx.f28.f64;
	// lfs f28,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f6,f29,f27,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f27.f64 + ctx.f6.f64));
	// fmsubs f30,f29,f30,f20
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f30.f64 - ctx.f20.f64));
	// lfs f29,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f28,f29,f28,f19
	ctx.f28.f64 = double(float(ctx.f29.f64 * ctx.f28.f64 + ctx.f19.f64));
	// stfs f28,-572(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// lfs f28,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f28.f64 = double(temp.f32);
	// add r18,r25,r6
	ctx.r18.u64 = ctx.r25.u64 + ctx.r6.u64;
	// fmuls f19,f28,f23
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// lfs f27,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f28,f24
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f24.f64));
	// lfs f28,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f29,f29,f28,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f28.f64 - ctx.f14.f64));
	// lfs f14,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f14.f64 = double(temp.f32);
	// lfs f28,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f27,f28,f14
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f28.f64 + ctx.f14.f64));
	// lfs f14,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f27,f27,f14,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f14.f64 - ctx.f22.f64));
	// lfs f22,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f22.f64 = double(temp.f32);
	// stw r18,-328(r1)
	PPC_STORE_U32(ctx.r1.u32 + -328, ctx.r18.u32);
	// fmsubs f24,f22,f24,f19
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f24.f64 - ctx.f19.f64));
	// lfs f19,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f23,f22,f23,f20
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 + ctx.f20.f64));
	// fadds f22,f28,f6
	ctx.f22.f64 = double(float(ctx.f28.f64 + ctx.f6.f64));
	// fadds f20,f27,f30
	ctx.f20.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// lfs f27,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f28.f64));
	// fadds f28,f23,f27
	ctx.f28.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// fsubs f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// fadds f23,f24,f29
	ctx.f23.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// fsubs f29,f24,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// fadds f24,f28,f22
	ctx.f24.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// fsubs f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// fsubs f22,f20,f23
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// fadds f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// fadds f20,f27,f30
	ctx.f20.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f20,-392(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfs f30,-352(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfsx f20,r29,r5
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r5.u32);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f30,f6,f29
	ctx.f30.f64 = double(float(ctx.f6.f64 - ctx.f29.f64));
	// stfs f20,-568(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// fadds f6,f29,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 + ctx.f6.f64));
	// lfsx f29,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-572(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// lfsx f27,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,-552(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// stfs f30,-388(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f30,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f27,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,-436(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// stfs f6,-324(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f6,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f6,f6,f30,f18
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64 - ctx.f18.f64));
	// lfsx f30,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfs f18,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f19,f30,f19
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f19.f64));
	// fmuls f18,f30,f18
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f18.f64));
	// lfsx f29,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f27,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfs f30,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f30.f64 = double(temp.f32);
	// stfs f27,-520(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fmuls f14,f29,f30
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f30.f64));
	// lfsx f27,r27,r6
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r6.u32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,-528(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f30,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f27,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f30.f64));
	// stfs f27,-516(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f29,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f29.f64 = double(temp.f32);
	// lfs f27,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f27.f64 = double(temp.f32);
	// stfs f6,-560(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// fmuls f20,f20,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f27.f64));
	// lfsx f6,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// stfs f30,-576(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// fmr f30,f29
	ctx.f30.f64 = ctx.f29.f64;
	// fmuls f27,f6,f27
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// fmadds f6,f6,f30,f20
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64 + ctx.f20.f64));
	// lfs f20,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f20.f64 = double(temp.f32);
	// lfs f29,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f30,f29,f30,f27
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f30.f64 - ctx.f27.f64));
	// lfs f27,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f27.f64 = double(temp.f32);
	// lfs f29,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f27,f29,f27,f19
	ctx.f27.f64 = double(float(ctx.f29.f64 * ctx.f27.f64 + ctx.f19.f64));
	// stfs f27,-448(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f27,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f27,f20
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// lfs f27,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f29,f29,f27,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f27.f64 - ctx.f18.f64));
	// stfs f29,-504(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f29,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f29.f64 = double(temp.f32);
	// lfs f27,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f29,f27,f29,f14
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f29.f64 + ctx.f14.f64));
	// stfs f29,-500(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f18,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f27,f27,f18,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f18.f64 - ctx.f14.f64));
	// stfs f27,-484(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f29,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f29.f64 = double(temp.f32);
	// lfs f19,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f29
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f29.f64));
	// lfs f27,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f27.f64 = double(temp.f32);
	// lfs f18,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f27,f18
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f27,f14
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f14.f64));
	// lfs f27,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f29,f27,f29,f20
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f29.f64 + ctx.f20.f64));
	// lfs f20,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f20.f64 = double(temp.f32);
	// add r18,r23,r6
	ctx.r18.u64 = ctx.r23.u64 + ctx.r6.u64;
	// fmsubs f27,f27,f20,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 - ctx.f19.f64));
	// lfs f19,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f20.f64 = double(temp.f32);
	// stw r18,-420(r1)
	PPC_STORE_U32(ctx.r1.u32 + -420, ctx.r18.u32);
	// fmadds f20,f19,f20,f18
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f20.f64 + ctx.f18.f64));
	// lfs f18,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f19,f19,f18,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 - ctx.f14.f64));
	// lfs f18,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,-576(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,-568(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// lfs f18,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,-492(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f14,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// lfs f14,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f6
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f6.f64));
	// stfs f14,-536(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfs f14,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f6,f14,f6
	ctx.f6.f64 = double(float(ctx.f14.f64 - ctx.f6.f64));
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f30
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f30.f64));
	// stfs f14,-524(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f30,f14,f30
	ctx.f30.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// stfs f30,-572(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// lfs f30,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f30.f64 = double(temp.f32);
	// lfs f14,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f30
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f30.f64));
	// stfs f14,-500(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f14,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f14.f64));
	// stfs f30,-532(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f30,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f30.f64 = double(temp.f32);
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f30
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// stfs f14,-504(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fadds f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// stfs f30,-484(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fadds f30,f6,f18
	ctx.f30.f64 = double(float(ctx.f6.f64 + ctx.f18.f64));
	// stfs f30,-384(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fsubs f6,f18,f6
	ctx.f6.f64 = double(float(ctx.f18.f64 - ctx.f6.f64));
	// stfs f6,-332(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f30,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f30.f64 = double(temp.f32);
	// lfs f6,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f18,f6,f30
	ctx.f18.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// stfs f18,-400(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fadds f6,f30,f6
	ctx.f6.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// stfs f6,-344(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f6,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f6.f64 = double(temp.f32);
	// lfs f30,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f30.f64 = double(temp.f32);
	// add r18,r24,r6
	ctx.r18.u64 = ctx.r24.u64 + ctx.r6.u64;
	// fmuls f18,f6,f30
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f30,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f30.f64 = double(temp.f32);
	// add r14,r21,r4
	ctx.r14.u64 = ctx.r21.u64 + ctx.r4.u64;
	// fmuls f14,f6,f30
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fsubs f30,f27,f19
	ctx.f30.f64 = double(float(ctx.f27.f64 - ctx.f19.f64));
	// fsubs f6,f29,f20
	ctx.f6.f64 = double(float(ctx.f29.f64 - ctx.f20.f64));
	// stw r18,-512(r1)
	PPC_STORE_U32(ctx.r1.u32 + -512, ctx.r18.u32);
	// add r18,r22,r4
	ctx.r18.u64 = ctx.r22.u64 + ctx.r4.u64;
	// stw r14,-408(r1)
	PPC_STORE_U32(ctx.r1.u32 + -408, ctx.r14.u32);
	// lwz r14,-420(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	// stw r18,-476(r1)
	PPC_STORE_U32(ctx.r1.u32 + -476, ctx.r18.u32);
	// add r18,r20,r4
	ctx.r18.u64 = ctx.r20.u64 + ctx.r4.u64;
	// fadds f30,f30,f6
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// stfs f30,-520(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fsubs f30,f27,f19
	ctx.f30.f64 = double(float(ctx.f27.f64 - ctx.f19.f64));
	// fsubs f6,f30,f6
	ctx.f6.f64 = double(float(ctx.f30.f64 - ctx.f6.f64));
	// stfs f6,-528(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// fadds f6,f20,f29
	ctx.f6.f64 = double(float(ctx.f20.f64 + ctx.f29.f64));
	// stfs f6,-536(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fadds f6,f19,f27
	ctx.f6.f64 = double(float(ctx.f19.f64 + ctx.f27.f64));
	// stfs f6,-552(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfs f6,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f27,r22,r6
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r6.u32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,-576(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// lfsx f27,r20,r6
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r6.u32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,-568(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// lfsx f27,r21,r6
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r6.u32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,-492(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfsx f30,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfs f27,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f27.f64 = double(temp.f32);
	// lfs f20,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f27,f30,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f27.f64));
	// fmuls f20,f30,f20
	ctx.f20.f64 = double(float(ctx.f30.f64 * ctx.f20.f64));
	// lwz r14,-476(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	// lfs f29,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// lwz r14,-512(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	// fmuls f30,f29,f4
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f4.f64));
	// stfs f30,-524(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// fmuls f19,f29,f5
	ctx.f19.f64 = double(float(ctx.f29.f64 * ctx.f5.f64));
	// lfs f29,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f30,f6,f29,f18
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f29.f64 + ctx.f18.f64));
	// lfs f29,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f6,f6,f29,f14
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f29.f64 - ctx.f14.f64));
	// lfs f18,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f18.f64 = double(temp.f32);
	// lfs f29,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// lwz r14,-408(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	// fmadds f27,f29,f18,f27
	ctx.f27.f64 = double(float(ctx.f29.f64 * ctx.f18.f64 + ctx.f27.f64));
	// stfs f27,-572(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// lfs f27,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// lfs f18,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f27,f18
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// lfs f27,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f29,f29,f27,f20
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f27.f64 - ctx.f20.f64));
	// lfs f27,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// lfs f20,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f27,f20
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// lfs f27,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f4,f27,f4,f19
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f4.f64 + ctx.f19.f64));
	// lfs f19,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f5,f27,f5,f19
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 - ctx.f19.f64));
	// stfs f5,-548(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f5,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f19,f5,f0
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// lfs f27,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f14,f5,f13
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f5,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f5,f27,f5,f18
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f18.f64));
	// lfs f18,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f27,f27,f18,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f18.f64 - ctx.f20.f64));
	// lfs f20,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f13,f20,f13,f19
	ctx.f13.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f19.f64));
	// lfs f19,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f20,f30,f19
	ctx.f20.f64 = double(float(ctx.f30.f64 - ctx.f19.f64));
	// fadds f30,f19,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 + ctx.f30.f64));
	// fsubs f19,f6,f29
	ctx.f19.f64 = double(float(ctx.f6.f64 - ctx.f29.f64));
	// fadds f6,f29,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 + ctx.f6.f64));
	// fsubs f29,f4,f5
	ctx.f29.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// lfs f18,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f27
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f27.f64));
	// stfs f18,-544(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f18,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f18.f64 = double(temp.f32);
	// fadds f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// fadds f18,f30,f18
	ctx.f18.f64 = double(float(ctx.f30.f64 + ctx.f18.f64));
	// stfs f18,-508(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fsubs f18,f20,f19
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// lfs f4,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f4.f64 = double(temp.f32);
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f19,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f30,f30,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f19.f64));
	// stfs f30,-448(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f30,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f30.f64 = double(temp.f32);
	// fadds f4,f27,f4
	ctx.f4.f64 = double(float(ctx.f27.f64 + ctx.f4.f64));
	// fsubs f19,f30,f6
	ctx.f19.f64 = double(float(ctx.f30.f64 - ctx.f6.f64));
	// stfs f19,-436(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fadds f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f30.f64));
	// stfs f6,-496(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f6,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f6.f64 = double(temp.f32);
	// fadds f27,f8,f26
	ctx.f27.f64 = double(float(ctx.f8.f64 + ctx.f26.f64));
	// fsubs f8,f26,f8
	ctx.f8.f64 = double(float(ctx.f26.f64 - ctx.f8.f64));
	// lfs f26,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// add r14,r26,r4
	ctx.r14.u64 = ctx.r26.u64 + ctx.r4.u64;
	// fadds f19,f6,f18
	ctx.f19.f64 = double(float(ctx.f6.f64 + ctx.f18.f64));
	// fsubs f30,f18,f6
	ctx.f30.f64 = double(float(ctx.f18.f64 - ctx.f6.f64));
	// lfs f6,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f18,f6,f20
	ctx.f18.f64 = double(float(ctx.f6.f64 - ctx.f20.f64));
	// fadds f6,f20,f6
	ctx.f6.f64 = double(float(ctx.f20.f64 + ctx.f6.f64));
	// stfs f6,-576(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// fmuls f6,f30,f12
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// fmuls f20,f18,f12
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// lfs f18,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f0,f18,f0,f14
	ctx.f0.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 - ctx.f14.f64));
	// lfs f18,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f24
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// stfs f18,-548(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f14,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f30,f19,f12
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f18,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f18,-520(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f18,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// lfs f14,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// lfs f23,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f19.f64 = double(temp.f32);
	// stfs f18,-576(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// fmuls f19,f19,f12
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f18,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f18,-536(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfs f14,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f29
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f29.f64));
	// stfs f14,-552(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fadds f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f14.f64));
	// lfs f14,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfs f23,-524(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f14,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfs f23,-568(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// lfs f14,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// lfsx f14,r26,r6
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-572(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f27
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f27.f64));
	// stfs f14,-528(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f27,f27,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f14.f64));
	// stfs f27,-560(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfs f27,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f27.f64 = double(temp.f32);
	// lfs f14,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f27
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f27.f64));
	// stfs f14,-544(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f14,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 - ctx.f27.f64));
	// fadds f14,f26,f8
	ctx.f14.f64 = double(float(ctx.f26.f64 + ctx.f8.f64));
	// fsubs f8,f8,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f26.f64));
	// stfs f8,-396(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f8,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f8.f64 = double(temp.f32);
	// fadds f26,f8,f24
	ctx.f26.f64 = double(float(ctx.f8.f64 + ctx.f24.f64));
	// stfs f26,-516(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// fsubs f8,f8,f24
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f24.f64));
	// stfs f8,-376(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f8,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f8.f64 = double(temp.f32);
	// fadds f26,f23,f8
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f8.f64));
	// stfs f26,-524(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// fsubs f8,f23,f8
	ctx.f8.f64 = double(float(ctx.f23.f64 - ctx.f8.f64));
	// stfs f8,-568(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// lfs f8,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f26,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f8,f26
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f26.f64));
	// lfs f26,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f8,f8,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f26.f64));
	// stfs f8,-556(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f24,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f8,f24,f26,f23
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f26.f64 + ctx.f23.f64));
	// lfs f26,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f26.f64 = double(temp.f32);
	// lfs f23,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f26,f24,f26,f23
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f26.f64 - ctx.f23.f64));
	// fadds f24,f8,f13
	ctx.f24.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// fsubs f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// fadds f8,f26,f0
	ctx.f8.f64 = double(float(ctx.f26.f64 + ctx.f0.f64));
	// fsubs f0,f0,f26
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f26.f64));
	// fadds f26,f24,f5
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f5.f64));
	// fsubs f5,f24,f5
	ctx.f5.f64 = double(float(ctx.f24.f64 - ctx.f5.f64));
	// fadds f24,f8,f4
	ctx.f24.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// fadds f23,f0,f13
	ctx.f23.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// fsubs f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// fsubs f13,f4,f8
	ctx.f13.f64 = double(float(ctx.f4.f64 - ctx.f8.f64));
	// fadds f8,f26,f25
	ctx.f8.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// fsubs f4,f25,f26
	ctx.f4.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// lfs f26,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// stfs f26,-564(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// lfs f26,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f25,f26,f23
	ctx.f25.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// fadds f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fsubs f23,f0,f29
	ctx.f23.f64 = double(float(ctx.f0.f64 - ctx.f29.f64));
	// fadds f0,f29,f0
	ctx.f0.f64 = double(float(ctx.f29.f64 + ctx.f0.f64));
	// stfs f0,-556(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f29,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f0,f29,f24
	ctx.f0.f64 = double(float(ctx.f29.f64 - ctx.f24.f64));
	// fmuls f29,f25,f12
	ctx.f29.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// fmuls f26,f26,f12
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// fmuls f25,f23,f12
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// lfs f23,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f24,f23,f12
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// lfs f23,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f23.f64 = double(temp.f32);
	// stfs f24,-464(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fadds f24,f8,f23
	ctx.f24.f64 = double(float(ctx.f8.f64 + ctx.f23.f64));
	// fsubs f8,f8,f23
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f23.f64));
	// lfs f23,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f23,-556(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f23,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfs f23,-576(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// lfs f23,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f18,f23,f24
	ctx.f18.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// stfsx f18,r31,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f24,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// lfs f18,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f18.f64 = double(temp.f32);
	// lfs f24,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f18,f24,f18
	ctx.f18.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// stfsx f18,r31,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// stfs f23,0(r3)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f23,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f23.f64 = double(temp.f32);
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// stfs f24,0(r4)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f24,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f18,f24,f23
	ctx.f18.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// stfsx f18,r30,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fsubs f18,f8,f27
	ctx.f18.f64 = double(float(ctx.f8.f64 - ctx.f27.f64));
	// stfsx f18,r30,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfsx f24,r10,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f8,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f27.f64));
	// stfsx f8,r10,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f8,f4,f0
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f0.f64));
	// lfs f18,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f18.f64 = double(temp.f32);
	// fadds f0,f0,f4
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f4.f64));
	// lfs f27,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f4,f22,f28
	ctx.f4.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// lfs f24,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f24.f64 = double(temp.f32);
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// lfs f22,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// stfs f22,-556(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// fadds f27,f27,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f18.f64));
	// lfs f18,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f22.f64 = double(temp.f32);
	// fadds f24,f13,f24
	ctx.f24.f64 = double(float(ctx.f13.f64 + ctx.f24.f64));
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// stfs f22,-544(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f18,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// stfs f22,-564(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// lfs f18,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// stfs f22,-576(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// lfs f18,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// lfs f18,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f13,f18,f13
	ctx.f13.f64 = double(float(ctx.f18.f64 - ctx.f13.f64));
	// stfs f13,-572(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// lfs f13,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f5
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f5.f64));
	// stfs f13,-492(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f13,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f13.f64 = double(temp.f32);
	// lfs f23,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f13,f17,f13
	ctx.f13.f64 = double(float(ctx.f17.f64 - ctx.f13.f64));
	// fadds f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 + ctx.f23.f64));
	// stfs f13,-552(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfs f5,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f5.f64 = double(temp.f32);
	// lfs f13,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f13.f64 = double(temp.f32);
	// fadds f18,f5,f13
	ctx.f18.f64 = double(float(ctx.f5.f64 + ctx.f13.f64));
	// stfs f18,-504(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fsubs f13,f13,f5
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f5.f64));
	// stfs f13,-484(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f13,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f13.f64 = double(temp.f32);
	// lfs f5,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f5.f64 = double(temp.f32);
	// fadds f13,f13,f17
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f17.f64));
	// stfs f13,-500(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// fadds f17,f0,f5
	ctx.f17.f64 = double(float(ctx.f0.f64 + ctx.f5.f64));
	// lfs f13,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f5,f0
	ctx.f0.f64 = double(float(ctx.f5.f64 - ctx.f0.f64));
	// fadds f18,f8,f13
	ctx.f18.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// fsubs f13,f8,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 - ctx.f13.f64));
	// fsubs f8,f4,f27
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f27.f64));
	// fadds f5,f27,f4
	ctx.f5.f64 = double(float(ctx.f27.f64 + ctx.f4.f64));
	// fmuls f4,f23,f10
	ctx.f4.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// fmuls f27,f23,f11
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// fmuls f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// stfs f0,-496(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fmuls f23,f18,f12
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// stfs f23,-508(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fmuls f0,f13,f12
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f0,-536(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fmuls f23,f17,f12
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// stfs f23,-548(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// fmuls f13,f22,f10
	ctx.f13.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// lfs f0,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f0.f64 = double(temp.f32);
	// fadds f23,f0,f28
	ctx.f23.f64 = double(float(ctx.f0.f64 + ctx.f28.f64));
	// fsubs f28,f0,f28
	ctx.f28.f64 = double(float(ctx.f0.f64 - ctx.f28.f64));
	// lfs f0,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f18,f0,f11
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f0,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f17,f0,f11
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// fmuls f0,f22,f11
	ctx.f0.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// lfs f22,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f22.f64 = double(temp.f32);
	// stfs f0,-468(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fmuls f0,f8,f12
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// stfs f13,-556(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// fmsubs f8,f24,f11,f4
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f11.f64 - ctx.f4.f64));
	// fmuls f4,f23,f12
	ctx.f4.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// lfs f23,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// stfs f22,-576(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// fmr f22,f23
	ctx.f22.f64 = ctx.f23.f64;
	// fmuls f13,f5,f12
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmadds f5,f24,f10,f27
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f27.f64));
	// lfs f27,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f10,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 + ctx.f18.f64));
	// lfs f24,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f24,f24,f10,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f17.f64));
	// fmuls f28,f28,f12
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// lfs f23,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f23,f22,f10,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 + ctx.f23.f64));
	// fmsubs f22,f22,f11,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 - ctx.f18.f64));
	// lfs f18,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f17.f64 = double(temp.f32);
	// stfs f22,-564(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// fmsubs f22,f18,f10,f17
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f10.f64 - ctx.f17.f64));
	// fmuls f17,f18,f11
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// lfs f18,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfsx f18,r29,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// lfs f18,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfsx f18,r7,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// lfs f18,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfsx f14,r29,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfsx f18,r7,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f18,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfsx f14,r28,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfsx f18,r9,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f18,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfsx f14,r28,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f14,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfsx f18,r9,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f18,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f10,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64 + ctx.f17.f64));
	// stfs f18,-556(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f18,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f18.f64 = double(temp.f32);
	// fadds f17,f0,f18
	ctx.f17.f64 = double(float(ctx.f0.f64 + ctx.f18.f64));
	// stfs f17,-576(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// fsubs f0,f18,f0
	ctx.f0.f64 = double(float(ctx.f18.f64 - ctx.f0.f64));
	// stfs f0,-496(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f0,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f0.f64 = double(temp.f32);
	// fadds f17,f22,f27
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// fadds f0,f25,f0
	ctx.f0.f64 = double(float(ctx.f25.f64 + ctx.f0.f64));
	// stfs f0,-568(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// lfs f0,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f0.f64 = double(temp.f32);
	// stfs f17,-524(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// fsubs f18,f21,f0
	ctx.f18.f64 = double(float(ctx.f21.f64 - ctx.f0.f64));
	// lfs f17,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f17.f64 = double(temp.f32);
	// lfs f0,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f0.f64 = double(temp.f32);
	// fadds f17,f28,f17
	ctx.f17.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// stfs f17,-560(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// fsubs f17,f0,f9
	ctx.f17.f64 = double(float(ctx.f0.f64 - ctx.f9.f64));
	// lfs f0,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f14,f0,f11
	ctx.f14.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f0,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// stfs f0,-468(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fsubs f0,f22,f27
	ctx.f0.f64 = double(float(ctx.f22.f64 - ctx.f27.f64));
	// lfs f27,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// lfs f27,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f4,f27
	ctx.f27.f64 = double(float(ctx.f4.f64 + ctx.f27.f64));
	// stfs f27,-572(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// fadds f27,f23,f8
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f8.f64));
	// stfs f27,-552(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfs f27,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f8,f8,f23
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f23.f64));
	// fadds f27,f27,f5
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f5.f64));
	// stfs f27,-520(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f27,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f27.f64 = double(temp.f32);
	// fadds f22,f28,f0
	ctx.f22.f64 = double(float(ctx.f28.f64 + ctx.f0.f64));
	// fadds f27,f13,f27
	ctx.f27.f64 = double(float(ctx.f13.f64 + ctx.f27.f64));
	// stfs f27,-528(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f27,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f4,f27,f4
	ctx.f4.f64 = double(float(ctx.f27.f64 - ctx.f4.f64));
	// lfs f27,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f5,f27,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 - ctx.f5.f64));
	// lfs f27,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f13,f27,f13
	ctx.f13.f64 = double(float(ctx.f27.f64 - ctx.f13.f64));
	// fmuls f27,f18,f12
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// stfs f27,-564(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -564, temp.u32);
	// fmuls f27,f17,f12
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// stfs f27,-544(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f27,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f27,f27,f10,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f14.f64));
	// stfs f27,-508(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f18,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f18.f64 = double(temp.f32);
	// lfs f27,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f10,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 + ctx.f18.f64));
	// stfs f27,-468(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f27,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f20.f64));
	// stfs f27,-532(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f27,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f6
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f6.f64));
	// stfs f27,-516(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f27,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f27.f64 = double(temp.f32);
	// fadds f23,f27,f24
	ctx.f23.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// stfs f23,-548(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// fsubs f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// stfs f27,-556(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f24,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f24.f64 = double(temp.f32);
	// lfs f27,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f23,f27,f24
	ctx.f23.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// stfsx f23,r20,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r5.u32, temp.u32);
	// fsubs f23,f0,f28
	ctx.f23.f64 = double(float(ctx.f0.f64 - ctx.f28.f64));
	// fadds f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// stfsx f27,r24,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// lfs f27,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f27,f2
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// fmuls f27,f27,f3
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// lfs f0,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f0.f64 = double(temp.f32);
	// lfs f28,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f18,f0,f28
	ctx.f18.f64 = double(float(ctx.f0.f64 - ctx.f28.f64));
	// fadds f17,f28,f0
	ctx.f17.f64 = double(float(ctx.f28.f64 + ctx.f0.f64));
	// lfs f0,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f0.f64 = double(temp.f32);
	// lfs f28,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f14,f0,f28
	ctx.f14.f64 = double(float(ctx.f0.f64 - ctx.f28.f64));
	// fadds f28,f28,f0
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f0.f64));
	// fsubs f0,f4,f5
	ctx.f0.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// stfs f0,-576(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -576, temp.u32);
	// fadds f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// fsubs f4,f8,f13
	ctx.f4.f64 = double(float(ctx.f8.f64 - ctx.f13.f64));
	// fadds f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// lfs f8,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f15,f8
	ctx.f8.f64 = double(float(ctx.f15.f64 - ctx.f8.f64));
	// stfs f8,-524(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f8,-564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -564);
	ctx.f8.f64 = double(temp.f32);
	// fadds f0,f8,f15
	ctx.f0.f64 = double(float(ctx.f8.f64 + ctx.f15.f64));
	// lfs f8,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f8.f64 = double(temp.f32);
	// fadds f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// stfs f8,-572(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -572, temp.u32);
	// lfs f8,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// stfs f8,-552(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfs f8,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f8.f64 = double(temp.f32);
	// stfs f13,-468(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fmr f13,f8
	ctx.f13.f64 = ctx.f8.f64;
	// lfs f8,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f13.f64));
	// stfs f8,-568(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -568, temp.u32);
	// lfs f8,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f8.f64 = double(temp.f32);
	// fadds f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// lfs f8,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f8.f64 = double(temp.f32);
	// fadds f7,f29,f8
	ctx.f7.f64 = double(float(ctx.f29.f64 + ctx.f8.f64));
	// fmsubs f8,f7,f3,f24
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f3.f64 - ctx.f24.f64));
	// lfs f24,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f7,f7,f2,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f2.f64 + ctx.f27.f64));
	// stfs f7,-520(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f7,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f7.f64 = double(temp.f32);
	// lfs f27,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f7
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f7.f64));
	// stfsx f27,r20,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r6.u32, temp.u32);
	// lfs f27,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f27.f64 = double(temp.f32);
	// fadds f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f27.f64));
	// stfsx f7,r24,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f7.f64 = double(temp.f32);
	// lfs f27,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f7
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f7.f64));
	// stfsx f27,r22,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r5.u32, temp.u32);
	// lfs f27,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f27.f64 = double(temp.f32);
	// fadds f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f27.f64));
	// stfsx f7,r23,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// stfsx f23,r22,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// stfsx f22,r23,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// stfsx f18,r21,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r5.u32, temp.u32);
	// stfsx f17,r25,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// stfsx f14,r21,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r6.u32, temp.u32);
	// stfsx f28,r25,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,-576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -576);
	ctx.f28.f64 = double(temp.f32);
	// stfsx f28,r26,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// stfsx f5,r27,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// stfsx f4,r26,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// lfs f7,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f7.f64 = double(temp.f32);
	// lfs f4,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f7,f7,f29
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// fmuls f29,f4,f10
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f5,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f4.f64 = double(temp.f32);
	// stfsx f5,r27,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fmuls f28,f4,f11
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// lfs f27,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f27.f64 = double(temp.f32);
	// lfs f5,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f5.f64 = double(temp.f32);
	// lfs f22,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f5,f5,f25
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f25.f64));
	// fmuls f25,f22,f31
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f31.f64));
	// lfs f4,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f4.f64 = double(temp.f32);
	// fadds f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// lfs f4,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f20,f4
	ctx.f4.f64 = double(float(ctx.f20.f64 + ctx.f4.f64));
	// lfs f23,-568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -568);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,-572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -572);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f29,f27,f11,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f29.f64));
	// lfs f27,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f27,f31
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmsubs f28,f24,f10,f28
	ctx.f28.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f28.f64));
	// lfs f24,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f27,f27,f1,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f25.f64));
	// fadds f25,f23,f24
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f23,f13,f20
	ctx.f23.f64 = double(float(ctx.f13.f64 + ctx.f20.f64));
	// fsubs f13,f20,f13
	ctx.f13.f64 = double(float(ctx.f20.f64 - ctx.f13.f64));
	// fmsubs f22,f22,f1,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f1.f64 - ctx.f18.f64));
	// fmuls f18,f7,f31
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f20,f5,f31
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fmuls f17,f4,f3
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// fmuls f15,f4,f2
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// fsubs f4,f28,f29
	ctx.f4.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// fadds f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// lfs f14,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f5,f5,f1,f18
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 + ctx.f18.f64));
	// fmsubs f7,f7,f1,f20
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f1.f64 - ctx.f20.f64));
	// fmadds f28,f6,f2,f17
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 + ctx.f17.f64));
	// fmsubs f6,f6,f3,f15
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 - ctx.f15.f64));
	// fadds f18,f5,f22
	ctx.f18.f64 = double(float(ctx.f5.f64 + ctx.f22.f64));
	// fsubs f5,f22,f5
	ctx.f5.f64 = double(float(ctx.f22.f64 - ctx.f5.f64));
	// lfs f22,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f22.f64 = double(temp.f32);
	// fadds f20,f7,f27
	ctx.f20.f64 = double(float(ctx.f7.f64 + ctx.f27.f64));
	// fsubs f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// fadds f27,f4,f22
	ctx.f27.f64 = double(float(ctx.f4.f64 + ctx.f22.f64));
	// fsubs f4,f22,f4
	ctx.f4.f64 = double(float(ctx.f22.f64 - ctx.f4.f64));
	// fadds f22,f29,f0
	ctx.f22.f64 = double(float(ctx.f29.f64 + ctx.f0.f64));
	// fadds f17,f28,f8
	ctx.f17.f64 = double(float(ctx.f28.f64 + ctx.f8.f64));
	// fsubs f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f29.f64));
	// fsubs f29,f25,f20
	ctx.f29.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// stfsx f29,r10,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f15,f6,f14
	ctx.f15.f64 = double(float(ctx.f6.f64 + ctx.f14.f64));
	// fsubs f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// fadds f29,f20,f25
	ctx.f29.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// stfsx f29,r30,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fsubs f6,f6,f14
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f14.f64));
	// lfs f20,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f28,f18,f27
	ctx.f28.f64 = double(float(ctx.f18.f64 - ctx.f27.f64));
	// stfsx f28,r10,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f28,f27,f18
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f18.f64));
	// stfsx f28,r30,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f29,f24,f5
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f5.f64));
	// stfs f29,0(r5)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f5,f5,f24
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f24.f64));
	// stfsx f5,r31,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fsubs f29,f7,f4
	ctx.f29.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// stfs f29,0(r6)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f7,f4,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// stfsx f7,r31,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f5,f22,f17
	ctx.f5.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfsx f5,r9,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f17,f22
	ctx.f7.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfsx f7,r28,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fsubs f5,f15,f23
	ctx.f5.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// stfsx f5,r9,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f7,f23,f15
	ctx.f7.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// stfsx f7,r28,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fsubs f5,f0,f6
	ctx.f5.f64 = double(float(ctx.f0.f64 - ctx.f6.f64));
	// lfs f4,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f4.f64 = double(temp.f32);
	// stfsx f5,r7,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// fadds f0,f6,f0
	ctx.f0.f64 = double(float(ctx.f6.f64 + ctx.f0.f64));
	// fsubs f7,f8,f13
	ctx.f7.f64 = double(float(ctx.f8.f64 - ctx.f13.f64));
	// lfs f23,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f0,r29,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fadds f29,f4,f9
	ctx.f29.f64 = double(float(ctx.f4.f64 + ctx.f9.f64));
	// lfs f27,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f5,f20,f26
	ctx.f5.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// stfsx f7,r7,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// fsubs f7,f23,f19
	ctx.f7.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// lfs f22,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f28,f27,f10
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f4,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f0,f22,f30
	ctx.f0.f64 = double(float(ctx.f22.f64 - ctx.f30.f64));
	// lfs f24,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f24.f64 = double(temp.f32);
	// fadds f21,f4,f21
	ctx.f21.f64 = double(float(ctx.f4.f64 + ctx.f21.f64));
	// lfs f18,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f18.f64 = double(temp.f32);
	// fadds f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// fsubs f6,f24,f18
	ctx.f6.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// lfs f9,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f17,f9,f11
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// lfs f4,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f4.f64 = double(temp.f32);
	// stfsx f13,r29,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fmuls f15,f4,f10
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fadds f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// lfs f25,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f8,f5,f3
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// fmuls f13,f7,f3
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// fmsubs f4,f4,f11,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 - ctx.f28.f64));
	// fmuls f22,f0,f3
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// fmuls f28,f21,f12
	ctx.f28.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmuls f14,f9,f10
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// fmuls f21,f6,f3
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// fmuls f9,f29,f12
	ctx.f9.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// fmadds f29,f25,f10,f17
	ctx.f29.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 + ctx.f17.f64));
	// fmadds f27,f27,f11,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f15.f64));
	// fadds f24,f18,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// fmadds f0,f0,f2,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f2.f64 + ctx.f13.f64));
	// fmsubs f13,f6,f2,f8
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 - ctx.f8.f64));
	// fmsubs f8,f7,f2,f22
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f2.f64 - ctx.f22.f64));
	// fsubs f22,f16,f28
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f28.f64));
	// fmsubs f25,f25,f11,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 - ctx.f14.f64));
	// fmadds f7,f5,f2,f21
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f2.f64 + ctx.f21.f64));
	// lfs f5,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f6,f5,f9
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// fadds f9,f9,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f5.f64));
	// fadds f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f20.f64));
	// fadds f23,f19,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// fsubs f5,f4,f29
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f29.f64));
	// fadds f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f16.f64));
	// fmuls f21,f26,f1
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// lwz r10,-360(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	// fmuls f19,f30,f31
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// add r4,r17,r4
	ctx.r4.u64 = ctx.r17.u64 + ctx.r4.u64;
	// fmuls f18,f30,f1
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f1.f64));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fmuls f20,f24,f1
	ctx.f20.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// fadds f4,f29,f4
	ctx.f4.f64 = double(float(ctx.f29.f64 + ctx.f4.f64));
	// fsubs f29,f25,f27
	ctx.f29.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// fadds f30,f25,f27
	ctx.f30.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stw r10,-360(r1)
	PPC_STORE_U32(ctx.r1.u32 + -360, ctx.r10.u32);
	// lwz r10,-428(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	// fmsubs f27,f24,f31,f21
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f31.f64 - ctx.f21.f64));
	// fmadds f25,f23,f1,f19
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f19.f64));
	// fmsubs f24,f23,f31,f18
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f31.f64 - ctx.f18.f64));
	// fmadds f26,f26,f31,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f31.f64 + ctx.f20.f64));
	// fadds f23,f13,f0
	ctx.f23.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// fadds f20,f5,f6
	ctx.f20.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fadds f21,f7,f8
	ctx.f21.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fadds f19,f29,f22
	ctx.f19.f64 = double(float(ctx.f29.f64 + ctx.f22.f64));
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fsubs f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// fsubs f13,f22,f29
	ctx.f13.f64 = double(float(ctx.f22.f64 - ctx.f29.f64));
	// fadds f7,f30,f9
	ctx.f7.f64 = double(float(ctx.f30.f64 + ctx.f9.f64));
	// fadds f5,f25,f27
	ctx.f5.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fadds f29,f24,f26
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// fsubs f18,f20,f23
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// stfsx f18,r27,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// stfsx f23,r26,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fsubs f23,f21,f19
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfsx f23,r27,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fadds f23,f4,f28
	ctx.f23.f64 = double(float(ctx.f4.f64 + ctx.f28.f64));
	// add r3,r17,r3
	ctx.r3.u64 = ctx.r17.u64 + ctx.r3.u64;
	// fsubs f4,f28,f4
	ctx.f4.f64 = double(float(ctx.f28.f64 - ctx.f4.f64));
	// subf r5,r17,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r17.s64;
	// fadds f28,f19,f21
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfs f28,0(r14)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fsubs f28,f6,f8
	ctx.f28.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// stfs f28,0(r16)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fadds f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-328(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	// fsubs f8,f0,f13
	ctx.f8.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// subf r6,r17,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r17.s64;
	// fsubs f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f30.f64));
	// fsubs f30,f24,f26
	ctx.f30.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-408(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-320(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	// fsubs f0,f7,f5
	ctx.f0.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// stfs f0,0(r19)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// fadds f0,f5,f7
	ctx.f0.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-420(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	// fsubs f0,f29,f23
	ctx.f0.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-476(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	// fadds f0,f23,f29
	ctx.f0.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-312(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	// fsubs f0,f9,f30
	ctx.f0.f64 = double(float(ctx.f9.f64 - ctx.f30.f64));
	// stfs f0,0(r15)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r15.u32 + 0, temp.u32);
	// fadds f0,f30,f9
	ctx.f0.f64 = double(float(ctx.f30.f64 + ctx.f9.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-512(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	// fsubs f0,f27,f4
	ctx.f0.f64 = double(float(ctx.f27.f64 - ctx.f4.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// fadds f0,f4,f27
	ctx.f0.f64 = double(float(ctx.f4.f64 + ctx.f27.f64));
	// stfs f0,0(r18)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d46dec
	if (!ctx.cr0.eq) goto loc_82D46DEC;
loc_82D484AC:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D484B4;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D484B8"))) PPC_WEAK_FUNC(sub_82D484B8);
PPC_FUNC_IMPL(__imp__sub_82D484B8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-2944
	ctx.r5.s64 = ctx.r11.s64 + -2944;
	// lis r11,-32044
	ctx.r11.s64 = -2100035584;
	// addi r4,r11,28032
	ctx.r4.s64 = ctx.r11.s64 + 28032;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D484D0"))) PPC_WEAK_FUNC(sub_82D484D0);
PPC_FUNC_IMPL(__imp__sub_82D484D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e40
	ctx.lr = 0x82D484D8;
	__savegprlr_18(ctx, base);
	// addi r12,r1,-120
	ctx.r12.s64 = ctx.r1.s64 + -120;
	// bl 0x82e28ee0
	ctx.lr = 0x82D484E0;
	__savefpr_14(ctx, base);
	// rlwinm r11,r9,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// addi r11,r11,-32
	ctx.r11.s64 = ctx.r11.s64 + -32;
	// bge cr6,0x82d48d04
	if (!ctx.cr6.lt) goto loc_82D48D04;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r19,r9,r10
	ctx.r19.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// rlwinm r25,r7,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32236
	ctx.r7.s64 = -2112618496;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lis r18,-32234
	ctx.r18.s64 = -2112487424;
	// lfs f9,-8016(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,136(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 136);
	ctx.f8.f64 = double(temp.f32);
	// lfs f10,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
loc_82D4851C:
	// lfs f0,20(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r10,r8,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r30,r8,3,0,28
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f13,f12
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// fmuls f2,f0,f11
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f7,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f31,f13,f11
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f6,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f3,f0,f12
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfsx f18,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f28,f7,f12
	ctx.f28.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// lfsx f17,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f27,f7,f11
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// lfs f5,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f26,f6,f11
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// add r24,r30,r5
	ctx.r24.u64 = ctx.r30.u64 + ctx.r5.u64;
	// fmuls f25,f6,f12
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// lfs f30,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f24,f0,f7
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// lfs f29,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f22,f13,f6
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// lfs f4,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f23,f0,f6
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// lfsx f15,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f1,f2
	ctx.f14.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// stfs f14,-352(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fmuls f21,f13,f7
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// lfs f16,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f3,f31
	ctx.f14.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// mulli r7,r8,20
	ctx.r7.s64 = ctx.r8.s64 * 20;
	// fadds f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// stfs f3,-304(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fsubs f3,f1,f2
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// stfs f3,-316(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fsubs f3,f28,f26
	ctx.f3.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// fadds f2,f25,f27
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f1,f25,f27
	ctx.f1.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// fadds f31,f26,f28
	ctx.f31.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fsubs f28,f24,f22
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f25,f22,f24
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f27,f21,f23
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// fadds f26,f21,f23
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fmuls f20,f5,f12
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f19,f5,f11
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fmuls f23,f13,f2
	ctx.f23.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f22,f0,f1
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// fmadds f20,f4,f11,f20
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 + ctx.f20.f64));
	// fmsubs f19,f4,f12,f19
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 - ctx.f19.f64));
	// lfs f24,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f21,f18,f24
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f24.f64));
	// fmuls f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// fmuls f24,f0,f3
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// fmadds f21,f17,f14,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f14.f64 + ctx.f21.f64));
	// lfs f14,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f18,f17,f14,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f14.f64 - ctx.f18.f64));
	// fsubs f17,f24,f23
	ctx.f17.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f24,-336(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fmuls f23,f0,f2
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// fmuls f24,f13,f3
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fadds f14,f23,f24
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f14,-292(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// stfs f24,-296(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fmuls f23,f13,f1
	ctx.f23.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// fmuls f24,f0,f31
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fsubs f14,f24,f23
	ctx.f14.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f24,-300(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fmuls f24,f13,f31
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fadds f23,f22,f24
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f22,f21,f30
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// stfs f22,-308(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fsubs f22,f29,f18
	ctx.f22.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// fsubs f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// fadds f29,f18,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// mulli r31,r8,24
	ctx.r31.s64 = ctx.r8.s64 * 24;
	// fmuls f21,f15,f3
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// fmuls f18,f15,f2
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// mulli r29,r8,28
	ctx.r29.s64 = ctx.r8.s64 * 28;
	// lfsx f15,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-352(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfsx f15,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-328(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fmadds f2,f16,f2,f21
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f2.f64 + ctx.f21.f64));
	// lfsx f21,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,-312(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fmsubs f3,f16,f3,f18
	ctx.f3.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 - ctx.f18.f64));
	// stfs f3,-332(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fmuls f21,f21,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64));
	// lfsx f15,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-348(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// mulli r28,r8,12
	ctx.r28.s64 = ctx.r8.s64 * 12;
	// lfsx f3,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f18,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,-320(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfsx f16,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-324(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfsx f15,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-344(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fmuls f15,f3,f1
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f1,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f21,f3,f31,f21
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f31.f64 + ctx.f21.f64));
	// fmuls f16,f16,f1
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f1.f64));
	// add r22,r28,r5
	ctx.r22.u64 = ctx.r28.u64 + ctx.r5.u64;
	// fmuls f1,f18,f1
	ctx.f1.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// add r23,r29,r5
	ctx.r23.u64 = ctx.r29.u64 + ctx.r5.u64;
	// add r21,r29,r6
	ctx.r21.u64 = ctx.r29.u64 + ctx.r6.u64;
	// add r27,r28,r6
	ctx.r27.u64 = ctx.r28.u64 + ctx.r6.u64;
	// lfs f18,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f27
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f27.f64));
	// stfs f18,-304(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f3,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f3,f3,f31,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64 - ctx.f15.f64));
	// stfs f3,-312(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f3,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f3,f25
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f3,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f3.f64 = double(temp.f32);
	// lfs f31,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f31.f64 = double(temp.f32);
	// fmadds f31,f31,f3,f16
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f16.f64));
	// lfs f16,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f18,f16,f3,f1
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 - ctx.f1.f64));
	// lfs f3,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f3,f20
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// lfs f3,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f3.f64 = double(temp.f32);
	// lfs f1,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f25,f3,f25,f1
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f25.f64 + ctx.f1.f64));
	// lfs f1,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// stfs f1,-304(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fmsubs f3,f3,f27,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f27.f64 - ctx.f15.f64));
	// stfs f3,-348(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f1,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f27,f1,f28
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmuls f15,f3,f28
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// lfs f3,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f28,f3,f19,f16
	ctx.f28.f64 = double(float(ctx.f3.f64 * ctx.f19.f64 + ctx.f16.f64));
	// lfs f19,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f19.f64 = double(temp.f32);
	// lfs f16,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f3,f3,f20,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f20.f64 - ctx.f16.f64));
	// lfs f20,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f27,f20,f26,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f26.f64 + ctx.f27.f64));
	// lfs f16,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f21,f31
	ctx.f20.f64 = double(float(ctx.f21.f64 - ctx.f31.f64));
	// fadds f31,f31,f21
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f21.f64));
	// fsubs f21,f19,f18
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fadds f18,f25,f2
	ctx.f18.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// fsubs f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f25.f64));
	// lfs f25,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f16,f25,f16
	ctx.f16.f64 = double(float(ctx.f25.f64 - ctx.f16.f64));
	// stfs f16,-320(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f16,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f16.f64 = double(temp.f32);
	// fadds f25,f16,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 + ctx.f25.f64));
	// fsubs f16,f21,f20
	ctx.f16.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fmsubs f1,f1,f26,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f26.f64 - ctx.f15.f64));
	// lfs f26,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f15,f28,f27
	ctx.f15.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// lfs f20,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// stfs f28,-352(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfsx f28,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// add r20,r31,r6
	ctx.r20.u64 = ctx.r31.u64 + ctx.r6.u64;
	// stfs f28,-312(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfsx f28,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,-344(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfsx f28,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,-348(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfsx f28,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,-340(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfsx f28,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,-316(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfsx f27,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f28,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f27,-332(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fmuls f27,f26,f11
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// stfs f28,-328(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fsubs f28,f3,f1
	ctx.f28.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// stfs f28,-324(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fmuls f28,f26,f12
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// fadds f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// stfs f3,-304(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fmsubs f12,f20,f12,f27
	ctx.f12.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 - ctx.f27.f64));
	// stfs f12,-284(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fmadds f11,f20,f11,f28
	ctx.f11.f64 = double(float(ctx.f20.f64 * ctx.f11.f64 + ctx.f28.f64));
	// stfs f11,-288(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f12,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f3,f12,f5
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f5.f64));
	// fmuls f1,f12,f4
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// lfs f12,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f28,f11,f12
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f11,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f27,f11,f12
	ctx.f27.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f12,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f26,f12,f14
	ctx.f26.f64 = double(float(ctx.f12.f64 * ctx.f14.f64));
	// lfs f12,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f20,f12,f14
	ctx.f20.f64 = double(float(ctx.f12.f64 * ctx.f14.f64));
	// lfs f12,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f14,f12,f7
	ctx.f14.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// lfs f11,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f12,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// stfs f12,-300(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fmadds f12,f11,f4,f3
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f4.f64 + ctx.f3.f64));
	// lfs f3,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f11,f11,f5,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f5.f64 - ctx.f1.f64));
	// lfs f1,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lfs f5,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f5,f5,f24,f28
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 + ctx.f28.f64));
	// fmsubs f4,f4,f24,f27
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f24.f64 - ctx.f27.f64));
	// lfs f27,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f3,f3,f23,f26
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f23.f64 + ctx.f26.f64));
	// lfs f26,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f1,f1,f23,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f23.f64 - ctx.f20.f64));
	// fmadds f6,f26,f6,f14
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f6.f64 + ctx.f14.f64));
	// fadds f28,f27,f15
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// fsubs f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// fsubs f24,f11,f1
	ctx.f24.f64 = double(float(ctx.f11.f64 - ctx.f1.f64));
	// fadds f11,f1,f11
	ctx.f11.f64 = double(float(ctx.f1.f64 + ctx.f11.f64));
	// lfs f20,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f7,f26,f7,f20
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 - ctx.f20.f64));
	// fsubs f26,f12,f3
	ctx.f26.f64 = double(float(ctx.f12.f64 - ctx.f3.f64));
	// fadds f12,f3,f12
	ctx.f12.f64 = double(float(ctx.f3.f64 + ctx.f12.f64));
	// fsubs f3,f6,f5
	ctx.f3.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fadds f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f5.f64));
	// fsubs f5,f7,f4
	ctx.f5.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// fadds f7,f7,f4
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// fadds f4,f3,f24
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f24.f64));
	// fsubs f3,f24,f3
	ctx.f3.f64 = double(float(ctx.f24.f64 - ctx.f3.f64));
	// stfs f3,-312(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f3,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f1,f12,f6
	ctx.f1.f64 = double(float(ctx.f12.f64 - ctx.f6.f64));
	// fsubs f23,f26,f5
	ctx.f23.f64 = double(float(ctx.f26.f64 - ctx.f5.f64));
	// fadds f5,f5,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f26.f64));
	// fsubs f26,f11,f7
	ctx.f26.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// lfs f24,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f4,f8
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// fmuls f15,f3,f24
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// add r26,r30,r6
	ctx.r26.u64 = ctx.r30.u64 + ctx.r6.u64;
	// fsubs f3,f16,f28
	ctx.f3.f64 = double(float(ctx.f16.f64 - ctx.f28.f64));
	// fmuls f24,f4,f9
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f9.f64));
	// lfs f4,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f20,f27,f21
	ctx.f20.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// fsubs f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 - ctx.f4.f64));
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// stfs f3,-340(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fmsubs f24,f23,f8,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f8.f64 - ctx.f24.f64));
	// fmadds f23,f23,f9,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f9.f64 + ctx.f14.f64));
	// lfsx f14,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-344(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fmuls f20,f20,f10
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// lfsx f14,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f3,f2,f22
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f22.f64));
	// stfs f14,-348(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-328(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// stfs f23,-324(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f23,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// stfs f23,-300(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f14,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f4
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f4.f64));
	// stfs f14,-316(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f14,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f4,f4,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f14.f64));
	// stfs f4,-280(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fadds f4,f3,f20
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f20.f64));
	// stfs f4,-340(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fsubs f4,f3,f20
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f20.f64));
	// stfs f4,-276(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f4,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f23,f4
	ctx.f3.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// lfs f4,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f23,f4,f0
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// lfs f4,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f20,f4,f0
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// lfs f0,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f14,f0,f17
	ctx.f14.f64 = double(float(ctx.f0.f64 * ctx.f17.f64));
	// lfs f0,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f0.f64 = double(temp.f32);
	// lfs f4,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f0,f0,f17
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f17.f64));
	// stfs f0,-296(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f17,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f0,f17,f4,f3
	ctx.f0.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 + ctx.f3.f64));
	// lfs f3,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f4,f3,f4,f15
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f4.f64 - ctx.f15.f64));
	// lfs f3,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f3,f3,f13,f23
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f23.f64));
	// lfs f23,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f13,f23,f13,f20
	ctx.f13.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f20.f64));
	// lfs f20,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f23,f20,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f20.f64 + ctx.f14.f64));
	// lfs f17,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f20,f17,f20,f15
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f20.f64 - ctx.f15.f64));
	// lfs f15,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f15,f3
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f3.f64));
	// fadds f3,f3,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f15.f64));
	// fsubs f15,f14,f13
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f13.f64));
	// fadds f13,f13,f14
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f14.f64));
	// fsubs f14,f23,f0
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f0.f64));
	// fadds f0,f23,f0
	ctx.f0.f64 = double(float(ctx.f23.f64 + ctx.f0.f64));
	// fsubs f23,f20,f4
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f4.f64));
	// fadds f4,f20,f4
	ctx.f4.f64 = double(float(ctx.f20.f64 + ctx.f4.f64));
	// fadds f20,f14,f15
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f20,-288(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fsubs f20,f17,f23
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f23.f64));
	// stfs f20,-284(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fadds f23,f23,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f17.f64));
	// stfs f23,-292(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fsubs f20,f13,f4
	ctx.f20.f64 = double(float(ctx.f13.f64 - ctx.f4.f64));
	// lfs f23,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f23,f8
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fmuls f23,f23,f9
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// stfs f23,-284(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fadds f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f21.f64));
	// lfs f17,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f28,f16
	ctx.f16.f64 = double(float(ctx.f28.f64 + ctx.f16.f64));
	// fmadds f23,f17,f9,f14
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 + ctx.f14.f64));
	// lfs f21,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f27,f27,f10
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f14,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f17,f17,f8,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f8.f64 - ctx.f14.f64));
	// fadds f14,f24,f23
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// stfs f14,-328(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f14,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f23,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f23.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// fsubs f23,f17,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 - ctx.f23.f64));
	// stfs f23,-324(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f23,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f23.f64 = double(temp.f32);
	// lfs f17,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f23,f23,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f17.f64));
	// stfsx f23,r10,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f17,f14,f23
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// stfsx f17,r10,r6
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f17,f1,f26
	ctx.f17.f64 = double(float(ctx.f1.f64 - ctx.f26.f64));
	// stfs f17,-288(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fsubs f23,f3,f0
	ctx.f23.f64 = double(float(ctx.f3.f64 - ctx.f0.f64));
	// fsubs f17,f3,f0
	ctx.f17.f64 = double(float(ctx.f3.f64 - ctx.f0.f64));
	// fadds f1,f26,f1
	ctx.f1.f64 = double(float(ctx.f26.f64 + ctx.f1.f64));
	// fmuls f26,f15,f8
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f8.f64));
	// fadds f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fmuls f17,f21,f8
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f8.f64));
	// lfs f21,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f21.f64 = double(temp.f32);
	// fadds f30,f21,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// lfs f21,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f26,f21,f9,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f9.f64 + ctx.f26.f64));
	// fmuls f21,f21,f8
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f8.f64));
	// fmsubs f28,f5,f9,f17
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 - ctx.f17.f64));
	// lfs f17,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f5,f5,f8
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// stfs f5,-284(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fsubs f5,f22,f2
	ctx.f5.f64 = double(float(ctx.f22.f64 - ctx.f2.f64));
	// lfs f22,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f22.f64 = double(temp.f32);
	// lfs f2,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f22.f64));
	// lfs f22,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfsx f2,r28,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// stfsx f22,r28,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fmuls f2,f16,f10
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// lfs f22,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f22.f64 = double(temp.f32);
	// stfs f21,-280(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fmr f21,f22
	ctx.f21.f64 = ctx.f22.f64;
	// lfs f22,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f22,0(r5)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f22,f24,f17
	ctx.f22.f64 = double(float(ctx.f24.f64 - ctx.f17.f64));
	// stfs f22,0(r6)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f24,f24,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f17.f64));
	// lfs f16,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f22,f15,f9,f16
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f9.f64 - ctx.f16.f64));
	// lfs f16,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f16.f64 = double(temp.f32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// stfsx f21,r29,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f15,f20,f1
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f1.f64));
	// fadds f17,f21,f23
	ctx.f17.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfsx f24,r29,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fsubs f14,f21,f23
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// lfs f23,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f23.f64 = double(temp.f32);
	// fadds f21,f1,f20
	ctx.f21.f64 = double(float(ctx.f1.f64 + ctx.f20.f64));
	// lfs f24,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f24.f64 = double(temp.f32);
	// lfs f16,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f24,f24,f9,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 + ctx.f16.f64));
	// fmuls f1,f17,f10
	ctx.f1.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// fsubs f17,f23,f18
	ctx.f17.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// lfs f23,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f19,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 - ctx.f23.f64));
	// stfs f23,-276(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// fadds f23,f23,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f17.f64));
	// lfs f20,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f16,f29,f25
	ctx.f16.f64 = double(float(ctx.f29.f64 - ctx.f25.f64));
	// fsubs f20,f20,f31
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f31.f64));
	// addic. r19,r19,-1
	ctx.xer.ca = ctx.r19.u32 > 0;
	ctx.r19.s64 = ctx.r19.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r19.s32, 0, ctx.xer);
	// fmuls f21,f21,f10
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// fadds f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// fadds f12,f6,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 + ctx.f12.f64));
	// lfs f6,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f6.f64 = double(temp.f32);
	// fadds f0,f0,f3
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f3.f64));
	// fadds f3,f25,f29
	ctx.f3.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// fadds f6,f6,f19
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f19.f64));
	// fadds f13,f4,f13
	ctx.f13.f64 = double(float(ctx.f4.f64 + ctx.f13.f64));
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// lfs f16,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fmuls f16,f15,f10
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// stfs f16,-276(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f16,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f29,f25
	ctx.f15.f64 = double(float(ctx.f29.f64 - ctx.f25.f64));
	// fsubs f16,f16,f31
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f31.f64));
	// fadds f4,f12,f0
	ctx.f4.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fsubs f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// fadds f12,f3,f6
	ctx.f12.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// fsubs f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// fadds f3,f11,f13
	ctx.f3.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// fmuls f15,f14,f10
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// fadds f14,f27,f30
	ctx.f14.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f14,-280(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// fadds f27,f5,f2
	ctx.f27.f64 = double(float(ctx.f5.f64 + ctx.f2.f64));
	// fadds f14,f28,f26
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// fsubs f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// fsubs f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// fsubs f2,f22,f24
	ctx.f2.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// fadds f26,f24,f22
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// fsubs f24,f23,f1
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f1.f64));
	// stfsx f24,r7,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// fsubs f24,f21,f20
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfsx f24,r7,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// fadds f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f23.f64));
	// stfsx f1,r30,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f1,f21,f20
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfsx f1,r30,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f23.f64 = double(temp.f32);
	// fadds f31,f23,f31
	ctx.f31.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// fsubs f7,f26,f27
	ctx.f7.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// lfs f1,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f24,f17,f1
	ctx.f24.f64 = double(float(ctx.f17.f64 - ctx.f1.f64));
	// stfsx f24,r9,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f24,f15,f16
	ctx.f24.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfsx f24,r9,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f17.f64));
	// stfsx f1,r31,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f1,f15,f16
	ctx.f1.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfsx f1,r31,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// subf r6,r25,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r25.s64;
	// lfs f24,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f1,f24,f14
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// stfsx f1,r31,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// stfs f7,0(r20)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// fadds f7,f14,f24
	ctx.f7.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// lfs f1,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f1.f64 = double(temp.f32);
	// subf r5,r25,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r25.s64;
	// stfsx f7,r9,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f1,f18,f1
	ctx.f1.f64 = double(float(ctx.f18.f64 + ctx.f1.f64));
	// fadds f7,f26,f27
	ctx.f7.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// stfsx f7,r9,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f7,f30,f2
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f2.f64));
	// stfs f7,0(r24)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fsubs f7,f28,f5
	ctx.f7.f64 = double(float(ctx.f28.f64 - ctx.f5.f64));
	// stfs f7,0(r26)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fadds f7,f2,f30
	ctx.f7.f64 = double(float(ctx.f2.f64 + ctx.f30.f64));
	// stfsx f7,r7,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f28,f5
	ctx.f7.f64 = double(float(ctx.f28.f64 + ctx.f5.f64));
	// stfsx f7,r7,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fadds f7,f31,f1
	ctx.f7.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fsubs f5,f1,f31
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// fsubs f11,f7,f4
	ctx.f11.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// stfs f11,0(r23)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// fadds f11,f4,f7
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// fsubs f4,f3,f12
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f12.f64));
	// stfs f4,0(r21)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// stfs f11,0(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f12,f3,f12
	ctx.f12.f64 = double(float(ctx.f3.f64 + ctx.f12.f64));
	// stfs f12,0(r4)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f12,f5,f13
	ctx.f12.f64 = double(float(ctx.f5.f64 - ctx.f13.f64));
	// stfs f12,0(r22)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// fsubs f7,f0,f6
	ctx.f7.f64 = double(float(ctx.f0.f64 - ctx.f6.f64));
	// stfs f7,0(r27)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fadds f13,f13,f5
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f5.f64));
	// stfsx f13,r10,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f0,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f6.f64));
	// stfsx f0,r10,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,3532(r18)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r18.u32 + 3532);
	// add r3,r25,r3
	ctx.r3.u64 = ctx.r25.u64 + ctx.r3.u64;
	// add r4,r25,r4
	ctx.r4.u64 = ctx.r25.u64 + ctx.r4.u64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d4851c
	if (!ctx.cr0.eq) goto loc_82D4851C;
loc_82D48D04:
	// addi r12,r1,-120
	ctx.r12.s64 = ctx.r1.s64 + -120;
	// bl 0x82e28f2c
	ctx.lr = 0x82D48D0C;
	__restfpr_14(ctx, base);
	// b 0x82e28e90
	__restgprlr_18(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D48D10"))) PPC_WEAK_FUNC(sub_82D48D10);
PPC_FUNC_IMPL(__imp__sub_82D48D10) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-2872
	ctx.r5.s64 = ctx.r11.s64 + -2872;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-31536
	ctx.r4.s64 = ctx.r11.s64 + -31536;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D48D28"))) PPC_WEAK_FUNC(sub_82D48D28);
PPC_FUNC_IMPL(__imp__sub_82D48D28) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D48D30;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28ef0
	ctx.lr = 0x82D48D38;
	__savefpr_18(ctx, base);
	// mulli r11,r9,24
	ctx.r11.s64 = ctx.r9.s64 * 24;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-24
	ctx.r11.s64 = ctx.r11.s64 + -24;
	// bge cr6,0x82d48fd0
	if (!ctx.cr6.lt) goto loc_82D48FD0;
	// subf r30,r9,r10
	ctx.r30.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f6,140(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f6.f64 = double(temp.f32);
loc_82D48D64:
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// mulli r7,r8,12
	ctx.r7.s64 = ctx.r8.s64 * 12;
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f10,f0
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f7,f10,f13
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f3,f9,f13
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f9,f0
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfsx f26,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f24,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f1,f12,f0
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// add r29,r9,r4
	ctx.r29.u64 = ctx.r9.u64 + ctx.r4.u64;
	// fmuls f31,f12,f13
	ctx.f31.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f5,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// add r27,r7,r4
	ctx.r27.u64 = ctx.r7.u64 + ctx.r4.u64;
	// lfs f4,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// add r28,r10,r5
	ctx.r28.u64 = ctx.r10.u64 + ctx.r5.u64;
	// add r25,r7,r3
	ctx.r25.u64 = ctx.r7.u64 + ctx.r3.u64;
	// add r26,r9,r3
	ctx.r26.u64 = ctx.r9.u64 + ctx.r3.u64;
	// lfs f30,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f25,f8,f3
	ctx.f25.f64 = double(float(ctx.f8.f64 - ctx.f3.f64));
	// lfsx f29,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f23,f2,f7
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// lfs f27,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f22,f30,f10
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// lfs f28,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// fmuls f21,f30,f9
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// fadds f8,f3,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f8.f64));
	// lfs f3,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f1,f11,f13,f1
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f1.f64));
	// fmsubs f31,f11,f0,f31
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f31.f64));
	// fmuls f2,f29,f25
	ctx.f2.f64 = double(float(ctx.f29.f64 * ctx.f25.f64));
	// fmuls f30,f29,f23
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f23.f64));
	// fmuls f29,f27,f12
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fmuls f27,f27,f11
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// fmsubs f10,f24,f10,f21
	ctx.f10.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f21.f64));
	// fmadds f9,f24,f9,f22
	ctx.f9.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 + ctx.f22.f64));
	// lfs f22,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f3,f8
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// lfsx f24,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f20,f3,f7
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// fmadds f2,f28,f23,f2
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f23.f64 + ctx.f2.f64));
	// fmsubs f30,f28,f25,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f25.f64 - ctx.f30.f64));
	// fmuls f23,f12,f7
	ctx.f23.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// fmuls f25,f12,f8
	ctx.f25.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// fmsubs f12,f26,f12,f27
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 - ctx.f27.f64));
	// fmadds f29,f26,f11,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 * ctx.f11.f64 + ctx.f29.f64));
	// fadds f27,f2,f5
	ctx.f27.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// fsubs f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// fmsubs f28,f11,f8,f23
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 - ctx.f23.f64));
	// lfsx f23,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f2,f4,f30
	ctx.f2.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// fadds f26,f10,f12
	ctx.f26.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// lfs f10,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f19,f10,f0
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f18,f10,f13
	ctx.f18.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfsx f10,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f10.f64 = double(temp.f32);
	// fadds f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// fadds f30,f9,f29
	ctx.f30.f64 = double(float(ctx.f9.f64 + ctx.f29.f64));
	// fsubs f9,f29,f9
	ctx.f9.f64 = double(float(ctx.f29.f64 - ctx.f9.f64));
	// lfs f29,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f11,f11,f7,f25
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64 + ctx.f25.f64));
	// lfsx f25,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f7,f25,f7,f21
	ctx.f7.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 + ctx.f21.f64));
	// fmsubs f8,f25,f8,f20
	ctx.f8.f64 = double(float(ctx.f25.f64 * ctx.f8.f64 - ctx.f20.f64));
	// fmadds f13,f29,f13,f19
	ctx.f13.f64 = double(float(ctx.f29.f64 * ctx.f13.f64 + ctx.f19.f64));
	// fmsubs f0,f29,f0,f18
	ctx.f0.f64 = double(float(ctx.f29.f64 * ctx.f0.f64 - ctx.f18.f64));
	// fmuls f29,f22,f1
	ctx.f29.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fmuls f19,f10,f28
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f22,f22,f31
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f31.f64));
	// fadds f3,f12,f9
	ctx.f3.f64 = double(float(ctx.f12.f64 + ctx.f9.f64));
	// fmuls f28,f23,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// fmadds f31,f24,f31,f29
	ctx.f31.f64 = double(float(ctx.f24.f64 * ctx.f31.f64 + ctx.f29.f64));
	// fmadds f29,f23,f11,f19
	ctx.f29.f64 = double(float(ctx.f23.f64 * ctx.f11.f64 + ctx.f19.f64));
	// fmsubs f1,f24,f1,f22
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f1.f64 - ctx.f22.f64));
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// fmsubs f11,f10,f11,f28
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 - ctx.f28.f64));
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// fadds f28,f29,f13
	ctx.f28.f64 = double(float(ctx.f29.f64 + ctx.f13.f64));
	// fadds f10,f31,f7
	ctx.f10.f64 = double(float(ctx.f31.f64 + ctx.f7.f64));
	// fsubs f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f31.f64));
	// fsubs f13,f13,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f29.f64));
	// fadds f31,f1,f8
	ctx.f31.f64 = double(float(ctx.f1.f64 + ctx.f8.f64));
	// fsubs f8,f8,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f1.f64));
	// fadds f1,f11,f0
	ctx.f1.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// fadds f29,f28,f30
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// fsubs f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f11.f64));
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fadds f11,f10,f27
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f27.f64));
	// fsubs f10,f27,f10
	ctx.f10.f64 = double(float(ctx.f27.f64 - ctx.f10.f64));
	// fsubs f25,f2,f7
	ctx.f25.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// fadds f28,f31,f4
	ctx.f28.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// fsubs f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// fadds f31,f1,f26
	ctx.f31.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// fsubs f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f26.f64));
	// fsubs f27,f0,f13
	ctx.f27.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// fadds f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// fsubs f24,f11,f29
	ctx.f24.f64 = double(float(ctx.f11.f64 - ctx.f29.f64));
	// stfsx f24,r7,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// fadds f11,f29,f11
	ctx.f11.f64 = double(float(ctx.f29.f64 + ctx.f11.f64));
	// stfs f11,0(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f13,f9,f12
	ctx.f13.f64 = double(float(ctx.f9.f64 - ctx.f12.f64));
	// fsubs f26,f5,f8
	ctx.f26.f64 = double(float(ctx.f5.f64 - ctx.f8.f64));
	// fsubs f11,f30,f4
	ctx.f11.f64 = double(float(ctx.f30.f64 - ctx.f4.f64));
	// fsubs f29,f31,f28
	ctx.f29.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// stfsx f29,r7,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// fadds f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// stfs f31,0(r4)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f31,f10,f1
	ctx.f31.f64 = double(float(ctx.f10.f64 - ctx.f1.f64));
	// stfsx f31,r9,r5
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f10,f1,f10
	ctx.f10.f64 = double(float(ctx.f1.f64 + ctx.f10.f64));
	// stfsx f10,r10,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f11,r9,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f11,f4,f30
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f30.f64));
	// stfsx f11,r10,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f11,f27,f3
	ctx.f11.f64 = double(float(ctx.f27.f64 - ctx.f3.f64));
	// fadds f9,f3,f27
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f27.f64));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fadds f10,f7,f2
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f2.f64));
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fmuls f12,f11,f6
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// fadds f11,f8,f5
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// fadds f8,f13,f0
	ctx.f8.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// fsubs f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// fmuls f9,f9,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fsubs f0,f26,f12
	ctx.f0.f64 = double(float(ctx.f26.f64 - ctx.f12.f64));
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f12,f12,f26
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f26.f64));
	// subf r5,r31,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r31.s64;
	// fmuls f0,f8,f6
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// fmuls f13,f13,f6
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fadds f8,f9,f25
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f25.f64));
	// stfs f8,0(r29)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// stfs f12,0(r25)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fsubs f12,f9,f25
	ctx.f12.f64 = double(float(ctx.f9.f64 - ctx.f25.f64));
	// stfsx f12,r10,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f12,f11,f0
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// stfs f12,0(r28)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fadds f12,f13,f10
	ctx.f12.f64 = double(float(ctx.f13.f64 + ctx.f10.f64));
	// stfs f12,0(r27)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fadds f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// stfs f0,0(r26)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fsubs f0,f13,f10
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lwz r10,3532(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 3532);
	// subf r6,r31,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r31.s64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d48d64
	if (!ctx.cr0.eq) goto loc_82D48D64;
loc_82D48FD0:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f3c
	ctx.lr = 0x82D48FD8;
	__restfpr_18(ctx, base);
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D48FE0"))) PPC_WEAK_FUNC(sub_82D48FE0);
PPC_FUNC_IMPL(__imp__sub_82D48FE0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-2808
	ctx.r5.s64 = ctx.r11.s64 + -2808;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-29400
	ctx.r4.s64 = ctx.r11.s64 + -29400;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D48FF8"))) PPC_WEAK_FUNC(sub_82D48FF8);
PPC_FUNC_IMPL(__imp__sub_82D48FF8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// stfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.f31.u64);
	// rlwinm r11,r9,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// addi r7,r11,-16
	ctx.r7.s64 = ctx.r11.s64 + -16;
	// bge cr6,0x82d49124
	if (!ctx.cr6.lt) goto loc_82D49124;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D49028:
	// lfs f0,0(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f12,8(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fmuls f6,f12,f0
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f13,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f5,f12,f13
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f10,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f10,f0
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f11,12(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f3,f10,f13
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// add r9,r11,r3
	ctx.r9.u64 = ctx.r11.u64 + ctx.r3.u64;
	// lfs f9,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// addi r7,r7,16
	ctx.r7.s64 = ctx.r7.s64 + 16;
	// lfs f8,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f10,f11,f13,f6
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f6.f64));
	// fmsubs f6,f11,f0,f5
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f5.f64));
	// lfsx f5,r11,r5
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f13,f9,f13,f4
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 + ctx.f4.f64));
	// lfsx f4,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fmsubs f0,f9,f0,f3
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 - ctx.f3.f64));
	// lfs f9,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f1,f4,f12
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// lfsx f3,r11,r6
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f4,f4,f11
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmuls f2,f9,f10
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// fmuls f31,f9,f6
	ctx.f31.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmadds f11,f3,f11,f1
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 + ctx.f1.f64));
	// fmsubs f12,f3,f12,f4
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 - ctx.f4.f64));
	// fmadds f9,f5,f6,f2
	ctx.f9.f64 = double(float(ctx.f5.f64 * ctx.f6.f64 + ctx.f2.f64));
	// fmsubs f10,f5,f10,f31
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 - ctx.f31.f64));
	// fadds f6,f9,f8
	ctx.f6.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// fsubs f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// fadds f8,f11,f13
	ctx.f8.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// fadds f11,f10,f7
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// fsubs f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// fadds f7,f12,f0
	ctx.f7.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fsubs f12,f6,f8
	ctx.f12.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// stfsx f12,r11,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f12,f8,f6
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfs f12,0(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fsubs f12,f13,f10
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// fsubs f8,f7,f11
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f11.f64));
	// stfsx f8,r11,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f7.f64));
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f11,f9,f0
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f0.f64));
	// stfs f11,0(r5)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f0,f0,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f9.f64));
	// stfs f0,0(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// stfs f12,0(r6)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f0,f10,f13
	ctx.f0.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// stfsx f0,r11,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,3532(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// subf r5,r31,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r31.s64;
	// subf r6,r31,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r31.s64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bne 0x82d49028
	if (!ctx.cr0.eq) goto loc_82D49028;
loc_82D49124:
	// lfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r30,-16(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D49138"))) PPC_WEAK_FUNC(sub_82D49138);
PPC_FUNC_IMPL(__imp__sub_82D49138) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-2744
	ctx.r5.s64 = ctx.r11.s64 + -2744;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-28680
	ctx.r4.s64 = ctx.r11.s64 + -28680;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D49150"))) PPC_WEAK_FUNC(sub_82D49150);
PPC_FUNC_IMPL(__imp__sub_82D49150) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D49158;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D49160;
	__savefpr_14(ctx, base);
	// mulli r11,r9,248
	ctx.r11.s64 = ctx.r9.s64 * 248;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-248
	ctx.r11.s64 = ctx.r11.s64 + -248;
	// bge cr6,0x82d4a640
	if (!ctx.cr6.lt) goto loc_82D4A640;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r17,r7,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// stw r10,-352(r1)
	PPC_STORE_U32(ctx.r1.u32 + -352, ctx.r10.u32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r7,-32236
	ctx.r7.s64 = -2112618496;
	// lfs f8,-8012(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8012);
	ctx.f8.f64 = double(temp.f32);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f9,-8008(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -8008);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-8004(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8004);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,-8000(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8000);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,136(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D491BC:
	// lfs f30,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// rlwinm r9,r8,5,0,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f28,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// mulli r10,r8,48
	ctx.r10.s64 = ctx.r8.s64 * 48;
	// lfs f27,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f28,f30
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// fmuls f23,f27,f30
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// lfs f7,120(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// lfs f29,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f22,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f7,f22
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f22.f64));
	// lfs f6,124(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 124);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// rlwinm r7,r8,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f3,184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f4.f64 = double(temp.f32);
	// mulli r31,r8,60
	ctx.r31.s64 = ctx.r8.s64 * 60;
	// lfs f2,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f21,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f30,f27,f29,f24
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f29.f64 + ctx.f24.f64));
	// lfsx f27,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f29,f28,f29,f23
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f29.f64 - ctx.f23.f64));
	// lfsx f28,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f20,r3,r7
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r7.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f3,f28
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// fmuls f16,f5,f20
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// lfsx f19,r5,r7
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r7.u32);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f28,f2,f28
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// lfs f1,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f4,f20
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f20.f64));
	// lfs f31,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmadds f6,f6,f21,f17
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f21.f64 + ctx.f17.f64));
	// lfs f26,192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 192);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f7,f7,f21,f22
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f21.f64 - ctx.f22.f64));
	// lfsx f24,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 196);
	ctx.f25.f64 = double(temp.f32);
	// mulli r30,r8,44
	ctx.r30.s64 = ctx.r8.s64 * 44;
	// lfsx f23,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f15,r6,r7
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r7.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-512(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fmadds f2,f2,f27,f18
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64 + ctx.f18.f64));
	// lfs f22,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f4,f4,f19,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f19.f64 + ctx.f16.f64));
	// lfs f21,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f3,f3,f27,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f27.f64 - ctx.f28.f64));
	// lfs f27,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f5,f5,f19,f20
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f19.f64 - ctx.f20.f64));
	// lfs f18,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f18.f64 = double(temp.f32);
	// fadds f28,f6,f1
	ctx.f28.f64 = double(float(ctx.f6.f64 + ctx.f1.f64));
	// lfs f20,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f6,f1,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 - ctx.f6.f64));
	// lfs f19,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f1,f31,f7
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f7.f64));
	// lfs f17,180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 180);
	ctx.f17.f64 = double(temp.f32);
	// fadds f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f31.f64));
	// fmuls f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// fmuls f24,f25,f24
	ctx.f24.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// fadds f31,f2,f4
	ctx.f31.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fsubs f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f2,f5,f3
	ctx.f2.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fmadds f25,f25,f23,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f23.f64 + ctx.f16.f64));
	// lfsx f16,r4,r7
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r7.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f26,f26,f23,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f23.f64 - ctx.f24.f64));
	// lfsx f24,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f27,f24
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f24.f64));
	// lfsx f23,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f3,f31,f28
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f28.f64));
	// stfs f16,-528(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// fsubs f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 - ctx.f31.f64));
	// fsubs f28,f1,f4
	ctx.f28.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// fadds f4,f4,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fsubs f1,f6,f2
	ctx.f1.f64 = double(float(ctx.f6.f64 - ctx.f2.f64));
	// fadds f6,f2,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 + ctx.f6.f64));
	// fadds f2,f7,f5
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// fsubs f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// lfs f5,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f15,f5,f24
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// lfsx f24,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// stfs f24,-432(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fmuls f24,f22,f16
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// lfsx f16,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-436(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fmadds f27,f27,f23,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f23.f64 + ctx.f15.f64));
	// lfs f16,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f5,f5,f23,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 - ctx.f14.f64));
	// stfs f24,-528(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// fmuls f16,f21,f16
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f16.f64));
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// mulli r29,r8,28
	ctx.r29.s64 = ctx.r8.s64 * 28;
	// stfs f16,-512(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fmr f16,f15
	ctx.f16.f64 = ctx.f15.f64;
	// lfsx f24,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// mulli r28,r8,12
	ctx.r28.s64 = ctx.r8.s64 * 12;
	// lfsx f23,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// rlwinm r25,r8,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r23,r8,24
	ctx.r23.s64 = ctx.r8.s64 * 24;
	// mulli r27,r8,40
	ctx.r27.s64 = ctx.r8.s64 * 40;
	// add r16,r23,r5
	ctx.r16.u64 = ctx.r23.u64 + ctx.r5.u64;
	// lfs f15,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f21,f21,f16,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f22,f22,f16,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f16.f64 - ctx.f15.f64));
	// lfs f16,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f20,f16
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f16.f64));
	// fmuls f14,f19,f16
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// fadds f16,f27,f30
	ctx.f16.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// fadds f27,f5,f29
	ctx.f27.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// fsubs f5,f29,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// fadds f29,f21,f25
	ctx.f29.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// fsubs f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// fadds f21,f22,f26
	ctx.f21.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// fsubs f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// stfs f26,-512(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fmuls f26,f18,f24
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f24.f64));
	// stfs f26,-528(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f22,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f26,f19,f22,f15
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 + ctx.f15.f64));
	// fmsubs f22,f20,f22,f14
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f22.f64 - ctx.f14.f64));
	// fmuls f14,f17,f24
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f24.f64));
	// fadds f20,f29,f16
	ctx.f20.f64 = double(float(ctx.f29.f64 + ctx.f16.f64));
	// fsubs f29,f16,f29
	ctx.f29.f64 = double(float(ctx.f16.f64 - ctx.f29.f64));
	// lfs f16,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f19,f27,f21
	ctx.f19.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// fadds f27,f21,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// fadds f21,f25,f5
	ctx.f21.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// fsubs f5,f5,f25
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f25.f64));
	// lfs f15,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f24,f17,f23,f15
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f23.f64 + ctx.f15.f64));
	// lfs f17,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f23,f18,f23,f14
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f23.f64 - ctx.f14.f64));
	// lfsx f18,r29,r6
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r6.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,-528(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// fsubs f25,f30,f17
	ctx.f25.f64 = double(float(ctx.f30.f64 - ctx.f17.f64));
	// lfsx f14,r28,r6
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// stfs f14,-436(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfsx f14,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-432(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfsx f14,r25,r5
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f23,-476(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// stfs f14,-392(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f23,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f14,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f23,-460(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// stfs f14,-360(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfsx f23,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f14,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// stfs f16,-512(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fmuls f16,f16,f23
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f23.f64));
	// stfs f14,-440(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fmuls f14,f17,f23
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f23.f64));
	// lfsx f18,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// lfs f23,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f15,f18
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f18.f64));
	// fmuls f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f18.f64));
	// lfs f18,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f18.f64 = double(temp.f32);
	// stfs f23,-528(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// fmr f23,f18
	ctx.f23.f64 = ctx.f18.f64;
	// mulli r22,r8,56
	ctx.r22.s64 = ctx.r8.s64 * 56;
	// fmadds f18,f17,f23,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f23.f64 + ctx.f16.f64));
	// stfs f18,-416(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f18,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f23,f18,f23,f14
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f23.f64 - ctx.f14.f64));
	// stfs f23,-496(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f18,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f18.f64 = double(temp.f32);
	// lfs f23,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f23,f18
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f18.f64));
	// lfs f17,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f17.f64 = double(temp.f32);
	// lfs f23,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f23,f17,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f17.f64 + ctx.f15.f64));
	// stfs f23,-520(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f23,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f23,f18
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f18.f64));
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f14.f64));
	// stfs f18,-524(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f17,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f18,f17
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f18,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// stfs f18,-528(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f17,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f18,f23,f17,f16
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f17.f64 + ctx.f16.f64));
	// lfs f23,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f23.f64 = double(temp.f32);
	// lfs f16,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f17,f23,f17,f15
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f23,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// lfs f15,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f16,f16,f23,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f23.f64 + ctx.f14.f64));
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f23,f15,f23,f14
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f23.f64 - ctx.f14.f64));
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,-528(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f15,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f26.f64));
	// fsubs f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// lfs f14,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f24
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// stfs f14,-496(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f14,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// stfs f24,-512(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f24,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f24.f64 = double(temp.f32);
	// lfs f14,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f24
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// stfs f14,-520(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f14,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,-468(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-388(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f15,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f14,-368(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f14,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// fsubs f14,f26,f24
	ctx.f14.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// stfs f14,-356(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fadds f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// stfs f26,-336(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f26,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f26.f64 = double(temp.f32);
	// fadds f24,f26,f22
	ctx.f24.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// stfs f24,-348(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fsubs f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// lfs f22,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f22.f64 = double(temp.f32);
	// stfs f26,-320(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfsx f26,r27,r5
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r5.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f22,-528(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f14,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f14.f64 = double(temp.f32);
	// add r15,r22,r5
	ctx.r15.u64 = ctx.r22.u64 + ctx.r5.u64;
	// stfs f14,-496(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// rlwinm r21,r8,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f14,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f14.f64 = double(temp.f32);
	// mulli r24,r8,52
	ctx.r24.s64 = ctx.r8.s64 * 52;
	// stfs f14,-520(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f14,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f14.f64));
	// lfs f24,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f24,f14
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f14.f64));
	// mulli r20,r8,36
	ctx.r20.s64 = ctx.r8.s64 * 36;
	// fmadds f24,f24,f26,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f26.f64 + ctx.f22.f64));
	// lfs f22,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f26,f22,f26,f14
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f26.f64 - ctx.f14.f64));
	// lfs f14,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-528(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// add r19,r21,r3
	ctx.r19.u64 = ctx.r21.u64 + ctx.r3.u64;
	// lfsx f14,r21,r5
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// add r18,r20,r3
	ctx.r18.u64 = ctx.r20.u64 + ctx.r3.u64;
	// stfs f14,-436(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfsx f14,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-512(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfsx f14,r24,r5
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-392(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfsx f22,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stw r18,-316(r1)
	PPC_STORE_U32(ctx.r1.u32 + -316, ctx.r18.u32);
	// fadds f14,f24,f18
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f18.f64));
	// stfs f14,-428(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fsubs f24,f18,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 - ctx.f24.f64));
	// stfs f24,-432(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fadds f24,f26,f17
	ctx.f24.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// stfs f24,-396(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fsubs f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f26.f64));
	// stfs f26,-524(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f26,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f24,r20,r5
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r5.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f18,f26,f22
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f22.f64));
	// stfs f24,-516(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f24,220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f17,f24,f22
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// lfs f22,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f22.f64));
	// lfs f22,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f24,f24,f22,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f22.f64 + ctx.f18.f64));
	// stfs f24,-476(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f24,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f26,f26,f22,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f22.f64 - ctx.f17.f64));
	// lfs f18,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f18.f64 = double(temp.f32);
	// stfs f26,-440(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fmuls f18,f18,f24
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f24.f64));
	// lfs f24,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f24.f64 = double(temp.f32);
	// lfs f26,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f26,f24
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// lfs f26,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// stfs f26,-528(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f22,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f22.f64 = double(temp.f32);
	// fmr f26,f22
	ctx.f26.f64 = ctx.f22.f64;
	// lfs f24,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f26
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// stfs f24,-432(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f24,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f24.f64 = double(temp.f32);
	// fadds f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// stfs f26,-360(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f26,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f26.f64 = double(temp.f32);
	// lfs f24,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f22,f24,f26,f14
	ctx.f22.f64 = double(float(ctx.f24.f64 * ctx.f26.f64 + ctx.f14.f64));
	// lfs f24,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f18,f24,f26,f18
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f26.f64 - ctx.f18.f64));
	// lfs f24,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f24.f64 = double(temp.f32);
	// lfs f26,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f24,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 + ctx.f17.f64));
	// stfs f26,-504(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f26,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f26.f64 = double(temp.f32);
	// lfs f17,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f26,f26,f24,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 - ctx.f17.f64));
	// lfs f24,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f24.f64 = double(temp.f32);
	// stfs f26,-464(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fadds f26,f24,f16
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f16.f64));
	// fsubs f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// lfs f16,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f16,f23
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// mulli r26,r8,20
	ctx.r26.s64 = ctx.r8.s64 * 20;
	// fsubs f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// lfs f16,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f26,f16
	ctx.f14.f64 = double(float(ctx.f26.f64 + ctx.f16.f64));
	// stfs f14,-456(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// fsubs f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f16.f64));
	// stfs f26,-444(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f26,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f16,f26,f17
	ctx.f16.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// stfs f16,-424(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// fadds f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// stfs f26,-472(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fadds f26,f23,f24
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f26,-436(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fsubs f26,f24,f23
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// stfs f26,-392(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f26,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,-524(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f23,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f16,f24,f23
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f26,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f26,f23
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// lfs f17,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f17.f64 = double(temp.f32);
	// lfs f23,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f26,f26,f17,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f17.f64 + ctx.f16.f64));
	// lfsx f16,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-528(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// fmsubs f24,f24,f17,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f17.f64 - ctx.f14.f64));
	// lfsx f14,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-512(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfsx f17,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f16,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f26,f22
	ctx.f14.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// stfs f14,-520(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fsubs f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// stfs f26,-412(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfsx f26,r29,r5
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r5.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f22,f23,f17
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// stfs f26,-476(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fadds f26,f24,f18
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f18.f64));
	// stfs f26,-396(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfsx f26,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,-508(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fsubs f26,f18,f24
	ctx.f26.f64 = double(float(ctx.f18.f64 - ctx.f24.f64));
	// stfs f26,-516(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfsx f26,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,-440(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfsx f26,r26,r5
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r5.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,-428(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// lfs f26,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f24,f26,f17
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// lfs f26,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f18,f26,f16
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// lfs f26,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f26,f16
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// lfs f26,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f14
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f14.f64));
	// lfs f26,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f26,f14
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f14.f64));
	// lfs f26,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f23,f23,f26,f24
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 + ctx.f24.f64));
	// lfs f24,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f22,f24,f26,f22
	ctx.f22.f64 = double(float(ctx.f24.f64 * ctx.f26.f64 - ctx.f22.f64));
	// lfs f24,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f24.f64 = double(temp.f32);
	// lfs f26,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f24,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 + ctx.f18.f64));
	// stfs f26,-496(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f26,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f26,f26,f24,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 - ctx.f17.f64));
	// stfs f26,-416(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f26,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f26.f64 = double(temp.f32);
	// lfs f24,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f18,f26,f24,f16
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 + ctx.f16.f64));
	// lfs f26,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f26,f26,f24,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 - ctx.f14.f64));
	// stfs f26,-524(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f17,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f17.f64 = double(temp.f32);
	// add r14,r22,r6
	ctx.r14.u64 = ctx.r22.u64 + ctx.r6.u64;
	// lfs f26,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f26.f64 = double(temp.f32);
	// add r18,r25,r6
	ctx.r18.u64 = ctx.r25.u64 + ctx.r6.u64;
	// fmuls f16,f26,f17
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// lfs f24,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f24,f17
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f17.f64));
	// lfs f17,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f17.f64 = double(temp.f32);
	// stw r14,-512(r1)
	PPC_STORE_U32(ctx.r1.u32 + -512, ctx.r14.u32);
	// add r14,r23,r6
	ctx.r14.u64 = ctx.r23.u64 + ctx.r6.u64;
	// stw r18,-324(r1)
	PPC_STORE_U32(ctx.r1.u32 + -324, ctx.r18.u32);
	// stw r14,-308(r1)
	PPC_STORE_U32(ctx.r1.u32 + -308, ctx.r14.u32);
	// fmadds f24,f24,f17,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f26,f26,f17,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f17.f64 - ctx.f14.f64));
	// lfs f14,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f24,f16
	ctx.f17.f64 = double(float(ctx.f24.f64 + ctx.f16.f64));
	// fsubs f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// fadds f16,f26,f14
	ctx.f16.f64 = double(float(ctx.f26.f64 + ctx.f14.f64));
	// fsubs f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// lfs f14,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,-484(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f14,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,-404(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f17,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f17,f16
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f14,-364(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fadds f14,f18,f23
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// stfs f14,-460(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fsubs f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// stfs f23,-480(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfsx f23,r28,r5
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r5.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f23,-528(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// stfs f17,-380(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f17,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f24,f17
	ctx.f16.f64 = double(float(ctx.f24.f64 + ctx.f17.f64));
	// lfs f14,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f17,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 - ctx.f24.f64));
	// stfs f24,-340(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f24,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f24.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// fsubs f17,f24,f26
	ctx.f17.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// stfs f14,-516(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// fadds f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// lfs f24,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f24.f64 = double(temp.f32);
	// stfs f24,-476(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f14,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,-504(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f22,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f24,f22
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// lfsx f14,r27,r6
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f16,-440(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// stfs f17,-396(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfsx f24,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfs f17,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f24
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f24.f64));
	// stfs f14,-428(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fmuls f16,f16,f24
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f24.f64));
	// lfsx f14,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-524(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfsx f23,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f14,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lfs f24,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f24.f64 = double(temp.f32);
	// stfs f14,-452(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fmuls f14,f24,f23
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f24,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// stfs f26,-344(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f26,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f22,f26,f22
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f22.f64));
	// lfs f23,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f23.f64 = double(temp.f32);
	// stfs f24,-528(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// fmr f24,f23
	ctx.f24.f64 = ctx.f23.f64;
	// fmadds f18,f26,f24,f18
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 + ctx.f18.f64));
	// lfs f26,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f26,f26,f24,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 - ctx.f22.f64));
	// stfs f26,-520(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f24,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// lwz r18,-512(r1)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	// lfs f26,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f24,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 + ctx.f17.f64));
	// stfs f26,-488(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f26,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f26.f64 = double(temp.f32);
	// lfs f23,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f17,f26,f23
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// lfs f23,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f24,f23,f24,f16
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f24.f64 - ctx.f16.f64));
	// stfs f24,-492(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f22,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f24,f22,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f22.f64 + ctx.f14.f64));
	// stfs f24,-448(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f24,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f24,f23
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f14,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f23,f22,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 - ctx.f14.f64));
	// stfs f23,-500(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f22,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f23,f22
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// lfs f22,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f17,f24,f22,f17
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f22.f64 + ctx.f17.f64));
	// add r18,r21,r4
	ctx.r18.u64 = ctx.r21.u64 + ctx.r4.u64;
	// fmsubs f22,f26,f22,f16
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f22.f64 - ctx.f16.f64));
	// lfs f16,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f16.f64 = double(temp.f32);
	// lfs f26,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f18,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 + ctx.f26.f64));
	// lfs f24,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f16.f64));
	// lfs f16,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,-528(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f16,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,-476(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f18,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,-524(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f18,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f16,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f26,f16
	ctx.f16.f64 = double(float(ctx.f26.f64 + ctx.f16.f64));
	// stfs f16,-420(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f16,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f26,f16,f26
	ctx.f26.f64 = double(float(ctx.f16.f64 - ctx.f26.f64));
	// stfs f26,-412(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f26,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// stfs f16,-464(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fadds f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// stfs f26,-372(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f26,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f26.f64 = double(temp.f32);
	// lfs f24,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f24.f64 = double(temp.f32);
	// stw r18,-528(r1)
	PPC_STORE_U32(ctx.r1.u32 + -528, ctx.r18.u32);
	// fadds f16,f24,f26
	ctx.f16.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// stfs f16,-428(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fsubs f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// stfs f26,-332(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f24,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f24.f64 = double(temp.f32);
	// add r18,r20,r4
	ctx.r18.u64 = ctx.r20.u64 + ctx.r4.u64;
	// lfs f26,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// stfs f16,-476(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fadds f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// stfs f26,-312(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f26,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// lfs f24,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f24.f64 = double(temp.f32);
	// stw r18,-516(r1)
	PPC_STORE_U32(ctx.r1.u32 + -516, ctx.r18.u32);
	// fmuls f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// lfs f24,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f26,f26,f24,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 + ctx.f14.f64));
	// add r18,r24,r4
	ctx.r18.u64 = ctx.r24.u64 + ctx.r4.u64;
	// lfs f14,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f24,f23,f24,f16
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f24.f64 - ctx.f16.f64));
	// fadds f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f14,-384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f14,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,-528(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,-408(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f18,-480(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f14,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// lfsx f16,r20,r6
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f18,-488(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfsx f18,r21,r6
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r6.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f16,-508(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fsubs f16,f17,f26
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f26.f64));
	// stfs f18,-500(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// fadds f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// stfs f26,-492(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// fsubs f26,f22,f24
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// lfs f23,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// lwz r14,-516(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	// stfs f26,-504(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fadds f26,f24,f22
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// stfs f16,-516(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfsx f14,r24,r6
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-376(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfsx f14,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-448(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// stfs f26,-460(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f26,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f26.f64 = double(temp.f32);
	// lfs f24,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f22,f26,f23
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// fmuls f17,f24,f23
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f18,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f14,r26,r6
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r6.u32);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f23.f64 = double(temp.f32);
	// stfs f14,-416(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// fmuls f14,f23,f18
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f18.f64));
	// lfs f23,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f23,f18
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f18.f64));
	// lfs f23,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f23.f64 = double(temp.f32);
	// lfs f16,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f23,f16
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// lfs f23,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f24,f24,f23,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f23.f64 + ctx.f22.f64));
	// stfs f24,-452(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f22,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f23,f24,f22
	ctx.f23.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f24,-400(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f24,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f26,f26,f24,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 - ctx.f17.f64));
	// stfs f26,-524(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f22,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f22.f64 = double(temp.f32);
	// lfs f26,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f22,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f22.f64 + ctx.f14.f64));
	// stfs f26,-500(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f24,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// lfs f26,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f26,f24
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// lfs f24,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f24,f24,f22,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f22.f64 - ctx.f18.f64));
	// stfs f24,-520(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f22,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f18,f24,f22
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// lfs f22,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,-496(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f22,-504(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f22,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,-516(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,-460(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f22,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f26,f26,f22,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f22.f64 + ctx.f16.f64));
	// stfs f26,-492(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f26,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f26,f26,f22,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f22.f64 - ctx.f17.f64));
	// stfs f26,-508(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f26,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f26.f64 = double(temp.f32);
	// lfs f22,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f26,f22,f18
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f22.f64 + ctx.f18.f64));
	// stfs f22,-488(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f22,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f22.f64 = double(temp.f32);
	// fadds f17,f22,f23
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f18,f23,f22
	ctx.f18.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfs f23,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f23,f22
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f14,f22,f23
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfs f22,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f23,-480(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f23,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fmuls f22,f18,f0
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fmuls f18,f17,f0
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fmuls f17,f16,f0
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f16,f14,f0
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f16,-328(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f16,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f26,f16
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// lfs f26,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f14.f64));
	// stfs f26,-400(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f26,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f26.f64 = double(temp.f32);
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// fadds f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 + ctx.f26.f64));
	// stfs f26,-500(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f26,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f26.f64 = double(temp.f32);
	// lfs f14,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f14.f64 = double(temp.f32);
	// fadds f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 + ctx.f26.f64));
	// stfs f26,-524(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f26,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f20,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// stfs f26,-408(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f26,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f27,f26
	ctx.f26.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// stfs f26,-448(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// lfs f26,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// stfs f26,-452(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f26,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f3
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// stfs f26,-492(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// lfs f26,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f14.f64));
	// lfs f14,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// lfs f14,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f24,f24,f14,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f2
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f2.f64));
	// stfs f14,-488(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f14,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f14.f64 = double(temp.f32);
	// fadds f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 + ctx.f27.f64));
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f3,f3,f14
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f14.f64));
	// stfs f3,-456(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f3,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f3.f64 = double(temp.f32);
	// lfs f14,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f3,f14,f3
	ctx.f3.f64 = double(float(ctx.f14.f64 - ctx.f3.f64));
	// lfs f14,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfs f14,-384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f14,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// stfs f23,-376(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// lfs f14,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f14.f64));
	// stfs f2,-472(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f2,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f2.f64 = double(temp.f32);
	// lfs f14,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f2
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f2.f64));
	// stfs f14,-484(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f14,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f2,f14,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 - ctx.f2.f64));
	// stfs f2,-372(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f2,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f2.f64 = double(temp.f32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f2
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f2.f64));
	// stfs f14,-380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f2,f14,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 - ctx.f2.f64));
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f26,f14
	ctx.f14.f64 = double(float(ctx.f26.f64 + ctx.f14.f64));
	// stfs f14,-448(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// lfs f14,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f24,f14
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// stfs f14,-420(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f14,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,-480(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f14,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f3,f14
	ctx.f14.f64 = double(float(ctx.f3.f64 + ctx.f14.f64));
	// stfs f14,-492(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f3,f14,f3
	ctx.f3.f64 = double(float(ctx.f14.f64 - ctx.f3.f64));
	// lfs f14,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f23
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// stfs f14,-488(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f14,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// stfs f23,-520(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f23,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfs f14,-508(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// stfs f23,-468(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f14,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f24,f14
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// stfs f14,-400(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// stfs f24,-408(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f24,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f24.f64 = double(temp.f32);
	// lfs f14,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// stfs f24,-420(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f24,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f24.f64 = double(temp.f32);
	// fadds f14,f24,f20
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// stfs f14,-468(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fsubs f24,f24,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f20.f64));
	// stfs f24,-484(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fsubs f24,f15,f23
	ctx.f24.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// stfs f24,-472(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fadds f24,f23,f15
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// stfs f24,-456(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f24,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f23.f64 = double(temp.f32);
	// fadds f15,f23,f24
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f20,f24,f23
	ctx.f20.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f24,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f14,f23,f24
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// fadds f23,f24,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// fmuls f24,f20,f0
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmuls f20,f15,f0
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f20,-524(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// fmuls f20,f14,f0
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f20,-500(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f23,-452(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f20,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f15,f23,f20
	ctx.f15.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfsx f15,r31,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f15,f20,f23
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// lfs f23,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f14,f23,f16
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// lfs f20,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f20.f64 = double(temp.f32);
	// fadds f16,f23,f16
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f16.f64));
	// lfs f23,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f23,-484(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f20,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f20.f64 = double(temp.f32);
	// fadds f23,f20,f27
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// fsubs f27,f27,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f20.f64));
	// stfs f27,-468(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f20,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f20.f64 = double(temp.f32);
	// lfs f27,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// stfs f27,-508(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f27,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f27.f64 = double(temp.f32);
	// lfs f20,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// lfs f27,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// stfsx f27,r31,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f27,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// stfs f15,0(r3)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f27,0(r4)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f27,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f23,f26,f27
	ctx.f23.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// stfsx f23,r29,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// stfsx f14,r29,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// stfsx f27,r9,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f16,r9,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmuls f27,f20,f0
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f16,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f16.f64 = double(temp.f32);
	// lfs f26,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f16,f29,f16
	ctx.f16.f64 = double(float(ctx.f29.f64 - ctx.f16.f64));
	// stfs f16,-472(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fadds f15,f26,f2
	ctx.f15.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// lfs f14,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f16.f64 = double(temp.f32);
	// lfs f26,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,-480(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f16,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f20,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f23,f26,f27
	ctx.f23.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// stfsx f23,r30,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// lfs f23,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f23.f64 = double(temp.f32);
	// lfs f26,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f26.f64 = double(temp.f32);
	// stfsx f27,r3,r7
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r3.u32 + ctx.r7.u32, temp.u32);
	// fadds f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// lfs f27,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f27.f64 = double(temp.f32);
	// stfs f16,-456(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// fsubs f27,f27,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f20.f64));
	// lfs f23,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f23.f64 = double(temp.f32);
	// lfs f16,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f23,f19,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 - ctx.f23.f64));
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f20,-364(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f16,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f16.f64 = double(temp.f32);
	// lfs f20,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f20,-464(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f20,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f31,f20
	ctx.f20.f64 = double(float(ctx.f31.f64 - ctx.f20.f64));
	// stfs f20,-412(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f20,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f16,f2,f20
	ctx.f16.f64 = double(float(ctx.f2.f64 - ctx.f20.f64));
	// lfs f2,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f2.f64 = double(temp.f32);
	// lfs f20,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f14,f2,f20
	ctx.f14.f64 = double(float(ctx.f2.f64 - ctx.f20.f64));
	// lfs f20,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f20.f64 = double(temp.f32);
	// lfs f2,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f20.f64));
	// stfs f2,-468(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f20,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f20.f64 = double(temp.f32);
	// lfs f2,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f20.f64));
	// lfs f20,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// lfs f19,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f19.f64 = double(temp.f32);
	// fadds f29,f19,f29
	ctx.f29.f64 = double(float(ctx.f19.f64 + ctx.f29.f64));
	// fmuls f19,f15,f0
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f19,-516(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f19,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f16,-444(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fmuls f16,f14,f0
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f16,-404(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// fsubs f15,f7,f19
	ctx.f15.f64 = double(float(ctx.f7.f64 - ctx.f19.f64));
	// lfs f16,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f16.f64 = double(temp.f32);
	// fadds f7,f19,f7
	ctx.f7.f64 = double(float(ctx.f19.f64 + ctx.f7.f64));
	// stfs f15,-368(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// stfs f7,-484(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f7,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f7.f64 = double(temp.f32);
	// fadds f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f31.f64));
	// lfs f19,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f31,f23,f13
	ctx.f31.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// stfs f7,-508(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fsubs f7,f27,f26
	ctx.f7.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// fadds f26,f26,f27
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// lfs f27,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f23,f23,f12,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 - ctx.f16.f64));
	// stfs f23,-504(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fmadds f31,f27,f12,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 * ctx.f12.f64 + ctx.f31.f64));
	// lfs f27,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f27,f27,f12,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f12.f64 - ctx.f19.f64));
	// fmuls f19,f2,f12
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f15,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f13
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// fmuls f23,f15,f0
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f23,-388(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f23,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f29,f13
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// fmadds f23,f23,f12,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 + ctx.f14.f64));
	// stfs f23,-424(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// fmuls f23,f2,f13
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f2,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f14,f29,f12
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// lfs f29,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f29.f64 = double(temp.f32);
	// fadds f16,f2,f16
	ctx.f16.f64 = double(float(ctx.f2.f64 + ctx.f16.f64));
	// lfs f2,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f29,f29,f2
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f2.f64));
	// stfsx f29,r30,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f29,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f29.f64 = double(temp.f32);
	// fadds f2,f29,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// stfsx f2,r4,r7
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r4.u32 + ctx.r7.u32, temp.u32);
	// lfs f2,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f29,f3,f2
	ctx.f29.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfsx f29,r28,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfsx f3,r10,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f2,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f29,f2,f3
	ctx.f29.f64 = double(float(ctx.f2.f64 - ctx.f3.f64));
	// stfsx f29,r28,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f29,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f29.f64 = double(temp.f32);
	// fadds f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fmsubs f2,f29,f13,f19
	ctx.f2.f64 = double(float(ctx.f29.f64 * ctx.f13.f64 - ctx.f19.f64));
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f19,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f3,f26,f0
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmuls f26,f16,f0
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fadds f19,f7,f19
	ctx.f19.f64 = double(float(ctx.f7.f64 + ctx.f19.f64));
	// fadds f16,f27,f31
	ctx.f16.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// fmadds f29,f29,f12,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f12.f64 + ctx.f23.f64));
	// fmadds f23,f20,f12,f15
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f15.f64));
	// lfs f15,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f20,f20,f13,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f14.f64));
	// lfs f14,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-404(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f14,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f31.f64));
	// lfs f15,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f27,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f14,f19,f16
	ctx.f14.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// stfsx f14,r20,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r5.u32, temp.u32);
	// fadds f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfsx f19,r23,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// lfs f19,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f7,f19,f7
	ctx.f7.f64 = double(float(ctx.f19.f64 - ctx.f7.f64));
	// stfs f7,-468(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f19,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f19.f64 = double(temp.f32);
	// lfs f7,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f7,f19,f7
	ctx.f7.f64 = double(float(ctx.f19.f64 - ctx.f7.f64));
	// stfs f7,-400(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f19,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f19.f64 = double(temp.f32);
	// lfs f7,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f7.f64 = double(temp.f32);
	// fadds f7,f19,f7
	ctx.f7.f64 = double(float(ctx.f19.f64 + ctx.f7.f64));
	// stfs f7,-464(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f7,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f7.f64 = double(temp.f32);
	// lfs f19,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f7
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f7.f64));
	// lfs f7,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f7.f64 = double(temp.f32);
	// lfs f16,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f7,f16
	ctx.f16.f64 = double(float(ctx.f7.f64 - ctx.f16.f64));
	// lfs f7,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f14,f7,f13
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f7,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f12
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// stfs f7,-444(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// stfs f31,-424(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f31,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f7,f31,f27
	ctx.f7.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// lfs f31,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f31.f64 = double(temp.f32);
	// fadds f31,f26,f31
	ctx.f31.f64 = double(float(ctx.f26.f64 + ctx.f31.f64));
	// stfs f31,-516(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// fadds f31,f23,f2
	ctx.f31.f64 = double(float(ctx.f23.f64 + ctx.f2.f64));
	// stfs f31,-408(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// fadds f31,f20,f29
	ctx.f31.f64 = double(float(ctx.f20.f64 + ctx.f29.f64));
	// stfs f31,-504(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f31,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f23.f64));
	// lfs f27,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f27.f64 = double(temp.f32);
	// fadds f31,f3,f31
	ctx.f31.f64 = double(float(ctx.f3.f64 + ctx.f31.f64));
	// lfs f23,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 - ctx.f3.f64));
	// fmsubs f23,f23,f12,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 - ctx.f14.f64));
	// stfs f23,-376(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fmuls f27,f19,f0
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f23,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f23.f64 = double(temp.f32);
	// stfs f31,-384(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fsubs f29,f20,f29
	ctx.f29.f64 = double(float(ctx.f20.f64 - ctx.f29.f64));
	// lfs f31,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f31,f31,f26
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f26.f64));
	// fmuls f26,f16,f0
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f19,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f23,f23,f13,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f19.f64));
	// stfs f23,-444(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f23,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f20,f15,f23
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// stfsx f20,r20,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r6.u32, temp.u32);
	// fadds f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// stfsx f23,r23,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// lfs f23,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f19,f23,f12
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// lfs f20,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f16,f23,f20
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfsx f16,r21,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfsx f23,r22,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// lfs f23,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f20,f21,f22
	ctx.f20.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// fmuls f16,f23,f10
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// lfs f23,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f24,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// fmuls f14,f20,f8
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// fsubs f20,f25,f17
	ctx.f20.f64 = double(float(ctx.f25.f64 - ctx.f17.f64));
	// fmuls f15,f23,f10
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// fmsubs f23,f23,f11,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f11.f64 - ctx.f16.f64));
	// lfs f16,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f7
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f7.f64));
	// stfsx f16,r21,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r6.u32, temp.u32);
	// lfs f16,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f16.f64 = double(temp.f32);
	// fadds f7,f7,f16
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f16.f64));
	// stfsx f7,r22,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f7.f64 = double(temp.f32);
	// lfs f16,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f7
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f7.f64));
	// stfsx f16,r24,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// lfs f16,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f16.f64 = double(temp.f32);
	// fadds f7,f7,f16
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f16.f64));
	// stfsx f7,r25,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// lfs f7,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f20,f20,f8
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// lfs f16,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f7
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f7.f64));
	// stfsx f16,r24,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// lfs f16,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f16.f64 = double(temp.f32);
	// fadds f7,f7,f16
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f16.f64));
	// stfsx f7,r25,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// fsubs f7,f31,f29
	ctx.f7.f64 = double(float(ctx.f31.f64 - ctx.f29.f64));
	// stfsx f7,r26,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f29,f31
	ctx.f7.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// stfsx f7,r27,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fsubs f7,f2,f3
	ctx.f7.f64 = double(float(ctx.f2.f64 - ctx.f3.f64));
	// stfsx f7,r26,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// fadds f7,f3,f2
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f2.f64));
	// lfs f29,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f29.f64 = double(temp.f32);
	// fadds f2,f26,f4
	ctx.f2.f64 = double(float(ctx.f26.f64 + ctx.f4.f64));
	// lfs f31,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f4,f4,f26
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f26.f64));
	// stfsx f7,r27,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fsubs f26,f21,f22
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// lfs f16,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f7,f1,f27
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f27.f64));
	// fadds f3,f27,f1
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// fsubs f1,f31,f29
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f29.f64));
	// fsubs f27,f25,f17
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f17.f64));
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f21,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f13,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 + ctx.f19.f64));
	// fadds f31,f29,f31
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// lfs f29,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f29.f64 = double(temp.f32);
	// fadds f25,f17,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// lfs f17,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f29,f29,f11,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f11.f64 + ctx.f15.f64));
	// fmsubs f26,f26,f9,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f9.f64 - ctx.f20.f64));
	// lfs f20,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// lfs f20,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// lfs f16,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fadds f19,f1,f7
	ctx.f19.f64 = double(float(ctx.f1.f64 + ctx.f7.f64));
	// fsubs f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f1.f64));
	// lfs f1,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f27,f27,f9,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 + ctx.f14.f64));
	// fmsubs f1,f1,f12,f16
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 - ctx.f16.f64));
	// lfs f16,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f17,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f16,-444(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fadds f17,f31,f2
	ctx.f17.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// lfs f15,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// lfs f31,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f31.f64 = double(temp.f32);
	// fadds f31,f31,f15
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f15.f64));
	// fmuls f16,f24,f8
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// fmuls f14,f25,f10
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// fmuls f15,f22,f10
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// fmuls f31,f31,f0
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// stfs f31,-404(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// fmuls f31,f20,f8
	ctx.f31.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// fmsubs f22,f22,f11,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 - ctx.f14.f64));
	// fmadds f25,f25,f11,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 + ctx.f15.f64));
	// fmsubs f31,f24,f9,f31
	ctx.f31.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 - ctx.f31.f64));
	// fmadds f24,f20,f9,f16
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 + ctx.f16.f64));
	// fsubs f20,f1,f21
	ctx.f20.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// fadds f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f21.f64));
	// fadds f14,f22,f29
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f29.f64));
	// fadds f15,f20,f4
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f4.f64));
	// fsubs f4,f4,f20
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f20.f64));
	// fadds f20,f25,f23
	ctx.f20.f64 = double(float(ctx.f25.f64 + ctx.f23.f64));
	// lfs f16,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f21,f6,f16
	ctx.f21.f64 = double(float(ctx.f6.f64 - ctx.f16.f64));
	// fadds f6,f16,f6
	ctx.f6.f64 = double(float(ctx.f16.f64 + ctx.f6.f64));
	// fadds f16,f31,f27
	ctx.f16.f64 = double(float(ctx.f31.f64 + ctx.f27.f64));
	// fsubs f31,f31,f27
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// fadds f27,f24,f26
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// fsubs f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// fadds f24,f1,f3
	ctx.f24.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fsubs f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// fsubs f1,f22,f29
	ctx.f1.f64 = double(float(ctx.f22.f64 - ctx.f29.f64));
	// lfs f22,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f29,f23,f25
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f25.f64));
	// lfs f23,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f25,f19,f16
	ctx.f25.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// stfsx f25,r9,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f25,f16,f19
	ctx.f25.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfsx f25,r29,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fsubs f25,f27,f15
	ctx.f25.f64 = double(float(ctx.f27.f64 - ctx.f15.f64));
	// stfsx f25,r9,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 + ctx.f27.f64));
	// stfsx f27,r29,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fsubs f27,f7,f26
	ctx.f27.f64 = double(float(ctx.f7.f64 - ctx.f26.f64));
	// stfs f27,0(r5)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f7,f26,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 + ctx.f7.f64));
	// stfsx f7,r31,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fsubs f7,f31,f4
	ctx.f7.f64 = double(float(ctx.f31.f64 - ctx.f4.f64));
	// stfs f7,0(r6)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f7,f4,f31
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f31.f64));
	// stfsx f7,r31,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f7,f24,f20
	ctx.f7.f64 = double(float(ctx.f24.f64 - ctx.f20.f64));
	// stfsx f7,r10,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f20,f24
	ctx.f7.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// stfsx f7,r28,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fsubs f7,f14,f17
	ctx.f7.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfsx f7,r10,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f7,f17,f14
	ctx.f7.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfsx f7,r28,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fsubs f7,f3,f1
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// stfsx f7,r5,r7
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r7.u32, temp.u32);
	// fadds f7,f1,f3
	ctx.f7.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// stfsx f7,r30,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fsubs f7,f29,f2
	ctx.f7.f64 = double(float(ctx.f29.f64 - ctx.f2.f64));
	// stfsx f7,r6,r7
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r6.u32 + ctx.r7.u32, temp.u32);
	// fadds f7,f2,f29
	ctx.f7.f64 = double(float(ctx.f2.f64 + ctx.f29.f64));
	// lfs f26,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f26.f64 = double(temp.f32);
	// lfs f20,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f4,f5,f23
	ctx.f4.f64 = double(float(ctx.f5.f64 - ctx.f23.f64));
	// lfs f24,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f3,f26,f20
	ctx.f3.f64 = double(float(ctx.f26.f64 - ctx.f20.f64));
	// lfs f29,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f2,f24,f22
	ctx.f2.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// lfs f25,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f27,f29,f12
	ctx.f27.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// lfs f1,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f25,f12
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// stfsx f7,r30,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fmuls f17,f1,f12
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// fsubs f7,f30,f18
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// lfs f31,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f31.f64 = double(temp.f32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fmuls f16,f31,f12
	ctx.f16.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// lwz r9,-324(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	// fmadds f31,f31,f13,f19
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f13.f64 + ctx.f19.f64));
	// lfs f19,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f22,f2,f11
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lwz r10,-352(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	// fadds f26,f20,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 + ctx.f26.f64));
	// addi r11,r11,248
	ctx.r11.s64 = ctx.r11.s64 + 248;
	// fmuls f20,f7,f11
	ctx.f20.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fadds f5,f23,f5
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// fmsubs f1,f1,f13,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 - ctx.f27.f64));
	// fsubs f27,f28,f19
	ctx.f27.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// fmuls f23,f4,f11
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fadds f28,f19,f28
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// stw r10,-352(r1)
	PPC_STORE_U32(ctx.r1.u32 + -352, ctx.r10.u32);
	// fmuls f19,f3,f11
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// fmadds f29,f29,f13,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fmsubs f25,f25,f13,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 - ctx.f16.f64));
	// fadds f30,f18,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 + ctx.f30.f64));
	// fmsubs f3,f3,f10,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 - ctx.f22.f64));
	// fmsubs f4,f4,f10,f20
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f10.f64 - ctx.f20.f64));
	// fmuls f22,f24,f9
	ctx.f22.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// fmuls f20,f26,f9
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// fmadds f7,f7,f10,f23
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64 + ctx.f23.f64));
	// fsubs f23,f1,f31
	ctx.f23.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// fmadds f2,f2,f10,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f10.f64 + ctx.f19.f64));
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fsubs f31,f25,f29
	ctx.f31.f64 = double(float(ctx.f25.f64 - ctx.f29.f64));
	// fmuls f19,f30,f8
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// fmuls f18,f30,f9
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// fadds f30,f25,f29
	ctx.f30.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// fmsubs f29,f26,f8,f22
	ctx.f29.f64 = double(float(ctx.f26.f64 * ctx.f8.f64 - ctx.f22.f64));
	// fmadds f26,f24,f8,f20
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f8.f64 + ctx.f20.f64));
	// fadds f24,f3,f7
	ctx.f24.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// fsubs f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// fadds f3,f2,f4
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fsubs f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fadds f2,f23,f21
	ctx.f2.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// fadds f22,f31,f27
	ctx.f22.f64 = double(float(ctx.f31.f64 + ctx.f27.f64));
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// fmadds f25,f5,f9,f19
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 + ctx.f19.f64));
	// fmsubs f5,f5,f8,f18
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f8.f64 - ctx.f18.f64));
	// fsubs f21,f2,f24
	ctx.f21.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// stfsx f21,r27,r5
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f2,f24,f2
	ctx.f2.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// stfsx f2,r26,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fsubs f24,f3,f22
	ctx.f24.f64 = double(float(ctx.f3.f64 - ctx.f22.f64));
	// stfsx f24,r27,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fadds f3,f22,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 + ctx.f3.f64));
	// stfsx f3,r26,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fsubs f2,f23,f4
	ctx.f2.f64 = double(float(ctx.f23.f64 - ctx.f4.f64));
	// stfsx f2,r25,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fadds f4,f4,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f23.f64));
	// stfsx f4,r24,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fsubs f4,f27,f31
	ctx.f4.f64 = double(float(ctx.f27.f64 - ctx.f31.f64));
	// add r3,r17,r3
	ctx.r3.u64 = ctx.r17.u64 + ctx.r3.u64;
	// fadds f3,f30,f6
	ctx.f3.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// add r4,r17,r4
	ctx.r4.u64 = ctx.r17.u64 + ctx.r4.u64;
	// fadds f2,f25,f29
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// subf r5,r17,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r17.s64;
	// fadds f31,f5,f26
	ctx.f31.f64 = double(float(ctx.f5.f64 + ctx.f26.f64));
	// subf r6,r17,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r17.s64;
	// fadds f27,f1,f28
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f28.f64));
	// fsubs f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// fsubs f30,f29,f25
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f25.f64));
	// fsubs f5,f5,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f26.f64));
	// fsubs f1,f28,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// fsubs f29,f7,f4
	ctx.f29.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// stfs f29,0(r9)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// fadds f7,f4,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// stfs f7,0(r18)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// lwz r9,-512(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	// fsubs f7,f3,f2
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f7,0(r15)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r15.u32 + 0, temp.u32);
	// fadds f7,f2,f3
	ctx.f7.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f7,0(r19)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// fsubs f7,f31,f27
	ctx.f7.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// stfs f7,0(r9)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lwz r9,-528(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	// fadds f7,f27,f31
	ctx.f7.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// stfs f7,0(r9)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lwz r9,-316(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	// fsubs f7,f6,f5
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// stfs f7,0(r16)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fadds f7,f5,f6
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// stfs f7,0(r9)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lwz r9,-308(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	// fsubs f7,f30,f1
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f1.f64));
	// stfs f7,0(r9)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// fadds f7,f1,f30
	ctx.f7.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// stfs f7,0(r14)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// lwz r9,3532(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3532);
	// xor r8,r9,r8
	ctx.r8.u64 = ctx.r9.u64 ^ ctx.r8.u64;
	// bne 0x82d491bc
	if (!ctx.cr0.eq) goto loc_82D491BC;
loc_82D4A640:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D4A648;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4A650"))) PPC_WEAK_FUNC(sub_82D4A650);
PPC_FUNC_IMPL(__imp__sub_82D4A650) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-2688
	ctx.r5.s64 = ctx.r11.s64 + -2688;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-28336
	ctx.r4.s64 = ctx.r11.s64 + -28336;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4A668"))) PPC_WEAK_FUNC(sub_82D4A668);
PPC_FUNC_IMPL(__imp__sub_82D4A668) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e44
	ctx.lr = 0x82D4A670;
	__savegprlr_19(ctx, base);
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28ee0
	ctx.lr = 0x82D4A678;
	__savefpr_14(ctx, base);
	// mulli r11,r9,120
	ctx.r11.s64 = ctx.r9.s64 * 120;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-120
	ctx.r11.s64 = ctx.r11.s64 + -120;
	// bge cr6,0x82d4adbc
	if (!ctx.cr6.lt) goto loc_82D4ADBC;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r20,r9,r10
	ctx.r20.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// rlwinm r26,r7,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32236
	ctx.r7.s64 = -2112618496;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lfs f13,-8016(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,136(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D4A6B4:
	// rlwinm r30,r8,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f11,56(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f10,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f10.f64 = double(temp.f32);
	// add r25,r30,r3
	ctx.r25.u64 = ctx.r30.u64 + ctx.r3.u64;
	// lfs f9,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// mulli r9,r8,24
	ctx.r9.s64 = ctx.r8.s64 * 24;
	// lfs f7,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f29,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f28,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f19,f9,f28
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f20,f11,f30
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfsx f26,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f30,f10,f30
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfsx f27,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f28,f8,f28
	ctx.f28.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r31,r8,20
	ctx.r31.s64 = ctx.r8.s64 * 20;
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f18,f7,f26
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// lfs f6,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f6.f64 = double(temp.f32);
	// lfs f4,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f26,f6,f26
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// lfs f3,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f24,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f22,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f8,f8,f27,f19
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f27.f64 + ctx.f19.f64));
	// fmadds f10,f10,f29,f20
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f29.f64 + ctx.f20.f64));
	// lfsx f25,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f11,f11,f29,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f29.f64 - ctx.f30.f64));
	// lfsx f23,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f30,f5,f24
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// lfsx f21,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f9,f9,f27,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f27.f64 - ctx.f28.f64));
	// mulli r29,r8,28
	ctx.r29.s64 = ctx.r8.s64 * 28;
	// fmuls f29,f4,f24
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f24.f64));
	// lfs f1,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f28,f3,f22
	ctx.f28.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// lfs f31,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f19,f2,f22
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// lfs f27,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f6,f6,f25,f18
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f25.f64 + ctx.f18.f64));
	// lfs f22,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f7,f7,f25,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f25.f64 - ctx.f26.f64));
	// lfs f20,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f20.f64 = double(temp.f32);
	// lfs f26,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f26.f64 = double(temp.f32);
	// add r24,r29,r5
	ctx.r24.u64 = ctx.r29.u64 + ctx.r5.u64;
	// lfs f25,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f25.f64 = double(temp.f32);
	// mulli r28,r8,12
	ctx.r28.s64 = ctx.r8.s64 * 12;
	// lfsx f18,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f4,f4,f23,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f23.f64 + ctx.f30.f64));
	// lfsx f16,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f5,f5,f23,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 - ctx.f29.f64));
	// lfs f23,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f30,f2,f21,f28
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f21.f64 + ctx.f28.f64));
	// lfs f2,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f3,f3,f21,f19
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f21.f64 - ctx.f19.f64));
	// lfs f17,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// fadds f29,f10,f1
	ctx.f29.f64 = double(float(ctx.f10.f64 + ctx.f1.f64));
	// lfsx f19,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f10,f1,f10
	ctx.f10.f64 = double(float(ctx.f1.f64 - ctx.f10.f64));
	// fadds f1,f6,f8
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// add r23,r29,r6
	ctx.r23.u64 = ctx.r29.u64 + ctx.r6.u64;
	// fsubs f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// add r22,r28,r5
	ctx.r22.u64 = ctx.r28.u64 + ctx.r5.u64;
	// fsubs f28,f31,f11
	ctx.f28.f64 = double(float(ctx.f31.f64 - ctx.f11.f64));
	// add r21,r28,r6
	ctx.r21.u64 = ctx.r28.u64 + ctx.r6.u64;
	// fsubs f6,f9,f7
	ctx.f6.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// fadds f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f31.f64));
	// lfs f31,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f31.f64 = double(temp.f32);
	// fadds f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// lfs f7,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f24,f4,f30
	ctx.f24.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// fsubs f21,f5,f3
	ctx.f21.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fadds f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// lfs f30,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f30.f64 = double(temp.f32);
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// lfsx f3,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f14,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// add r27,r30,r4
	ctx.r27.u64 = ctx.r30.u64 + ctx.r4.u64;
	// stfs f14,-324(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-328(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fsubs f14,f21,f24
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// fadds f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// lfs f15,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f21,f23,f3
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// fmuls f3,f30,f3
	ctx.f3.f64 = double(float(ctx.f30.f64 * ctx.f3.f64));
	// stfs f3,-320(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fmadds f3,f30,f19,f21
	ctx.f3.f64 = double(float(ctx.f30.f64 * ctx.f19.f64 + ctx.f21.f64));
	// lfs f21,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f30,f23,f19,f21
	ctx.f30.f64 = double(float(ctx.f23.f64 * ctx.f19.f64 - ctx.f21.f64));
	// stfs f30,-312(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fmuls f23,f7,f18
	ctx.f23.f64 = double(float(ctx.f7.f64 * ctx.f18.f64));
	// lfs f30,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f21,f31,f18
	ctx.f21.f64 = double(float(ctx.f31.f64 * ctx.f18.f64));
	// fmuls f18,f25,f16
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f16.f64));
	// fmuls f19,f2,f16
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// fmuls f16,f27,f30
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmuls f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// stfs f30,-320(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fmadds f31,f31,f17,f23
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f17.f64 + ctx.f23.f64));
	// fmsubs f30,f7,f17,f21
	ctx.f30.f64 = double(float(ctx.f7.f64 * ctx.f17.f64 - ctx.f21.f64));
	// lfs f7,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f2,f2,f15,f18
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f15.f64 - ctx.f18.f64));
	// lfs f17,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f25,f25,f15,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f15.f64 + ctx.f19.f64));
	// lfs f19,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f26,f26,f7,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 + ctx.f16.f64));
	// lfs f18,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f7,f27,f7,f23
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 - ctx.f23.f64));
	// fsubs f27,f31,f26
	ctx.f27.f64 = double(float(ctx.f31.f64 - ctx.f26.f64));
	// fadds f31,f26,f31
	ctx.f31.f64 = double(float(ctx.f26.f64 + ctx.f31.f64));
	// fsubs f26,f30,f7
	ctx.f26.f64 = double(float(ctx.f30.f64 - ctx.f7.f64));
	// fadds f30,f7,f30
	ctx.f30.f64 = double(float(ctx.f7.f64 + ctx.f30.f64));
	// lfs f7,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f16,f20,f7
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// fmuls f15,f22,f7
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f7.f64));
	// lfs f7,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fadds f23,f26,f27
	ctx.f23.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// lfs f26,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f22,f22,f7,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 + ctx.f16.f64));
	// lfs f16,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f7,f20,f7,f15
	ctx.f7.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 - ctx.f15.f64));
	// stfs f7,-320(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfsx f7,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f20,f17,f19
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f19.f64));
	// stfs f7,-328(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfsx f7,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,-336(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfsx f7,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,-332(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfsx f7,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,-340(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfsx f7,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f15,f25,f22
	ctx.f15.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// stfs f7,-316(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fadds f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// lfsx f7,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,-304(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfsx f7,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,-300(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f7,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f19,f7,f19
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f19.f64));
	// stfs f25,-324(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fmadds f7,f7,f18,f20
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f18.f64 + ctx.f20.f64));
	// stfs f7,-348(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// stfs f15,-308(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fmsubs f7,f17,f18,f19
	ctx.f7.f64 = double(float(ctx.f17.f64 * ctx.f18.f64 - ctx.f19.f64));
	// stfs f7,-344(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f25,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f22,f2,f25
	ctx.f22.f64 = double(float(ctx.f2.f64 - ctx.f25.f64));
	// stfs f22,-352(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fadds f2,f25,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// lfs f7,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f7.f64 = double(temp.f32);
	// stfs f2,-320(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fmuls f19,f26,f7
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// lfs f25,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f18,f21,f7
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f7.f64));
	// lfs f7,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f7.f64 = double(temp.f32);
	// lfs f2,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f17,f7,f25
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// fmuls f15,f2,f25
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfs f25,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f25.f64 = double(temp.f32);
	// lfs f22,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f22,f25,f22
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f22.f64));
	// stfs f22,-328(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f22,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f21,f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f19.f64));
	// stfs f21,-332(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f21,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f26,f26,f20,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 - ctx.f18.f64));
	// fmuls f19,f22,f21
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f21.f64));
	// lfs f21,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f2,f2,f21,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64 + ctx.f17.f64));
	// lfs f17,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f21,f7,f21,f15
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f21.f64 - ctx.f15.f64));
	// lfs f7,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f25,f25,f7,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 - ctx.f19.f64));
	// lfs f19,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f22,f22,f7,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 + ctx.f18.f64));
	// lfs f18,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f18.f64 = double(temp.f32);
	// lfs f20,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f7,f20,f3
	ctx.f7.f64 = double(float(ctx.f20.f64 - ctx.f3.f64));
	// fadds f3,f20,f3
	ctx.f3.f64 = double(float(ctx.f20.f64 + ctx.f3.f64));
	// fsubs f20,f26,f19
	ctx.f20.f64 = double(float(ctx.f26.f64 - ctx.f19.f64));
	// fadds f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// lfs f19,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f7,f19
	ctx.f19.f64 = double(float(ctx.f7.f64 + ctx.f19.f64));
	// fsubs f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f3.f64));
	// fsubs f15,f17,f20
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f15,-340(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfs f20,-284(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lfs f20,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f7,f20,f7
	ctx.f7.f64 = double(float(ctx.f20.f64 - ctx.f7.f64));
	// stfs f7,-288(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f20,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f20.f64 = double(temp.f32);
	// lfs f7,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f15,f16,f20
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f20.f64));
	// fmuls f17,f7,f20
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f20.f64));
	// lfs f20,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f25
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f25.f64));
	// stfs f20,-304(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f20,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f22
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// stfs f20,-308(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f20,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f20.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// lfs f20,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f20.f64 = double(temp.f32);
	// fadds f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// stfs f25,-336(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f20,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f25,f14,f23
	ctx.f25.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// stfs f25,-300(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fmadds f25,f16,f20,f17
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f20.f64 + ctx.f17.f64));
	// fmuls f17,f19,f13
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fsubs f16,f27,f24
	ctx.f16.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// fmsubs f20,f7,f20,f15
	ctx.f20.f64 = double(float(ctx.f7.f64 * ctx.f20.f64 - ctx.f15.f64));
	// fmuls f15,f19,f12
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f19,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f19,f19,f12,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 - ctx.f17.f64));
	// fmuls f17,f16,f0
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f16,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f13,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 + ctx.f15.f64));
	// fsubs f15,f25,f2
	ctx.f15.f64 = double(float(ctx.f25.f64 - ctx.f2.f64));
	// fadds f2,f25,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// stfs f2,-328(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fsubs f2,f20,f21
	ctx.f2.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfs f2,-340(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f7,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// stfs f7,-300(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f7,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f7,f7,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f26.f64));
	// fsubs f2,f10,f6
	ctx.f2.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// lfs f25,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f25.f64 = double(temp.f32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fadds f20,f25,f2
	ctx.f20.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// fsubs f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f25.f64));
	// stfs f2,-316(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fadds f2,f8,f28
	ctx.f2.f64 = double(float(ctx.f8.f64 + ctx.f28.f64));
	// fadds f25,f2,f17
	ctx.f25.f64 = double(float(ctx.f2.f64 + ctx.f17.f64));
	// stfs f25,-312(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fsubs f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f17.f64));
	// stfs f2,-296(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fsubs f25,f5,f30
	ctx.f25.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// fsubs f2,f29,f1
	ctx.f2.f64 = double(float(ctx.f29.f64 - ctx.f1.f64));
	// fadds f17,f25,f2
	ctx.f17.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// stfs f17,-280(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fsubs f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f25.f64));
	// stfs f2,-268(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fsubs f25,f11,f9
	ctx.f25.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// fsubs f2,f31,f4
	ctx.f2.f64 = double(float(ctx.f31.f64 - ctx.f4.f64));
	// fadds f17,f25,f2
	ctx.f17.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// stfs f17,-272(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fsubs f2,f25,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 - ctx.f2.f64));
	// stfs f2,-276(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f2,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f2.f64 = double(temp.f32);
	// fadds f25,f15,f2
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// stfs f25,-304(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fsubs f2,f2,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f15.f64));
	// lfs f15,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f21
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// stfs f15,-300(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// stfs f2,-292(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f17,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f17.f64 = double(temp.f32);
	// lfs f2,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f2,f17,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 - ctx.f2.f64));
	// lfs f25,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,-332(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fmuls f17,f2,f12
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fmuls f15,f2,f13
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f2,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f25.f64));
	// stfs f2,-300(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f2,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f17,f2,f13,f17
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f17,-344(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fmsubs f2,f2,f12,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 - ctx.f15.f64));
	// stfs f2,-340(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fsubs f2,f18,f7
	ctx.f2.f64 = double(float(ctx.f18.f64 - ctx.f7.f64));
	// lfs f17,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f2,f17
	ctx.f15.f64 = double(float(ctx.f2.f64 + ctx.f17.f64));
	// fsubs f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f17.f64));
	// lfs f17,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f19,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfs f17,-348(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f17,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,-352(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f17,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f17.f64 = double(temp.f32);
	// stfs f2,-300(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fsubs f2,f17,f16
	ctx.f2.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f17,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// fmuls f17,f15,f0
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f17,-304(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f17,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f20,f17
	ctx.f17.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfsx f17,r30,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// lfs f17,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfsx f16,r30,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f16,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfsx f20,r28,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f20,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfsx f20,r28,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f20,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f17,f20,f2
	ctx.f17.f64 = double(float(ctx.f20.f64 - ctx.f2.f64));
	// stfs f17,0(r5)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f2,f2,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f20.f64));
	// lfs f17,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f17.f64 = double(temp.f32);
	// fadds f7,f7,f18
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f18.f64));
	// fsubs f16,f19,f17
	ctx.f16.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f16,0(r6)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// stfsx f2,r29,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fadds f2,f19,f17
	ctx.f2.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// lfs f19,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f19.f64 = double(temp.f32);
	// fadds f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// stfsx f2,r29,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fsubs f2,f19,f21
	ctx.f2.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// lfs f18,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f18.f64 = double(temp.f32);
	// fadds f4,f31,f4
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// lfs f20,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f24,f18,f12
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// lfs f31,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f31.f64 = double(temp.f32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// fmuls f17,f20,f12
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fadds f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// lfs f9,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f9.f64 = double(temp.f32);
	// fadds f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f31.f64));
	// lfs f31,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f31.f64 = double(temp.f32);
	// fadds f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// lfs f30,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f30.f64 = double(temp.f32);
	// fadds f9,f9,f22
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f22.f64));
	// fsubs f22,f31,f30
	ctx.f22.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// stfsx f22,r31,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fsubs f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f25.f64));
	// lfs f25,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f16,f25,f12
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f25,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f15,f25,f12
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// fadds f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fmuls f6,f27,f0
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// lfs f27,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f27.f64 = double(temp.f32);
	// fadds f22,f30,f31
	ctx.f22.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// fmadds f27,f27,f13,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 + ctx.f24.f64));
	// fmuls f24,f23,f0
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// lfs f23,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f25,f25,f13,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 - ctx.f17.f64));
	// fsubs f8,f28,f8
	ctx.f8.f64 = double(float(ctx.f28.f64 - ctx.f8.f64));
	// fadds f31,f7,f2
	ctx.f31.f64 = double(float(ctx.f7.f64 + ctx.f2.f64));
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fadds f1,f1,f29
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f29.f64));
	// fmsubs f28,f18,f13,f16
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 - ctx.f16.f64));
	// fmadds f29,f20,f13,f15
	ctx.f29.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f15.f64));
	// fsubs f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// fsubs f30,f25,f27
	ctx.f30.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// fmuls f7,f31,f0
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fadds f31,f6,f10
	ctx.f31.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fadds f6,f25,f27
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// lfs f25,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f25.f64 = double(temp.f32);
	// fadds f27,f8,f24
	ctx.f27.f64 = double(float(ctx.f8.f64 + ctx.f24.f64));
	// fsubs f8,f8,f24
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f24.f64));
	// fsubs f24,f23,f25
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f25.f64));
	// fadds f23,f23,f25
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// fadds f25,f29,f28
	ctx.f25.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// fsubs f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// fadds f28,f4,f1
	ctx.f28.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fsubs f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// fadds f1,f11,f5
	ctx.f1.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fsubs f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// fadds f5,f3,f9
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f9.f64));
	// fsubs f9,f3,f9
	ctx.f9.f64 = double(float(ctx.f3.f64 - ctx.f9.f64));
	// lfs f3,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f20,f7,f3
	ctx.f20.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfsx f20,r31,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// stfsx f22,r10,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f7,f3
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// stfsx f7,r10,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f3,f7,f2
	ctx.f3.f64 = double(float(ctx.f7.f64 - ctx.f2.f64));
	// stfsx f3,r7,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// stfsx f24,r7,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// fadds f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// stfsx f7,r9,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f7,f31,f6
	ctx.f7.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// stfsx f23,r9,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f7,r9,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f3,f25,f27
	ctx.f3.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// stfsx f3,r9,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f7,f6,f31
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f31.f64));
	// stfsx f7,r7,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f25,f27
	ctx.f7.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stfsx f7,r7,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f7,f10,f29
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f29.f64));
	// stfsx f7,r10,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f6,f30,f8
	ctx.f6.f64 = double(float(ctx.f30.f64 - ctx.f8.f64));
	// stfsx f6,r10,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f10,f29,f10
	ctx.f10.f64 = double(float(ctx.f29.f64 + ctx.f10.f64));
	// stfsx f10,r31,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f30,f8
	ctx.f8.f64 = double(float(ctx.f30.f64 + ctx.f8.f64));
	// stfsx f8,r31,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fadds f10,f21,f19
	ctx.f10.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// lfs f8,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f6,f9,f11
	ctx.f6.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// fadds f8,f26,f8
	ctx.f8.f64 = double(float(ctx.f26.f64 + ctx.f8.f64));
	// addic. r20,r20,-1
	ctx.xer.ca = ctx.r20.u32 > 0;
	ctx.r20.s64 = ctx.r20.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r20.s32, 0, ctx.xer);
	// fadds f9,f9,f11
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// subf r5,r26,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r26.s64;
	// fsubs f7,f28,f5
	ctx.f7.f64 = double(float(ctx.f28.f64 - ctx.f5.f64));
	// stfs f7,0(r24)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fadds f7,f5,f28
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f28.f64));
	// subf r6,r26,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r26.s64;
	// addi r11,r11,120
	ctx.r11.s64 = ctx.r11.s64 + 120;
	// fadds f11,f8,f10
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fsubs f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// fsubs f8,f11,f1
	ctx.f8.f64 = double(float(ctx.f11.f64 - ctx.f1.f64));
	// stfs f8,0(r23)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// stfs f7,0(r3)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f1.f64));
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f11,f4,f10
	ctx.f11.f64 = double(float(ctx.f4.f64 - ctx.f10.f64));
	// stfs f11,0(r22)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// fadds f11,f10,f4
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f4.f64));
	// stfs f6,0(r21)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// add r3,r26,r3
	ctx.r3.u64 = ctx.r26.u64 + ctx.r3.u64;
	// stfs f11,0(r25)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// add r4,r26,r4
	ctx.r4.u64 = ctx.r26.u64 + ctx.r4.u64;
	// stfs f9,0(r27)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// lwz r10,3532(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d4a6b4
	if (!ctx.cr0.eq) goto loc_82D4A6B4;
loc_82D4ADBC:
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28f2c
	ctx.lr = 0x82D4ADC4;
	__restfpr_14(ctx, base);
	// b 0x82e28e94
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4ADC8"))) PPC_WEAK_FUNC(sub_82D4ADC8);
PPC_FUNC_IMPL(__imp__sub_82D4ADC8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-2632
	ctx.r5.s64 = ctx.r11.s64 + -2632;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-22936
	ctx.r4.s64 = ctx.r11.s64 + -22936;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4ADE0"))) PPC_WEAK_FUNC(sub_82D4ADE0);
PPC_FUNC_IMPL(__imp__sub_82D4ADE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e44
	ctx.lr = 0x82D4ADE8;
	__savegprlr_19(ctx, base);
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28ee0
	ctx.lr = 0x82D4ADF0;
	__savefpr_14(ctx, base);
	// mulli r11,r9,88
	ctx.r11.s64 = ctx.r9.s64 * 88;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-88
	ctx.r11.s64 = ctx.r11.s64 + -88;
	// bge cr6,0x82d4b20c
	if (!ctx.cr6.lt) goto loc_82D4B20C;
	// subf r28,r9,r10
	ctx.r28.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// rlwinm r29,r7,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lfs f13,-28552(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f0.f64 = double(temp.f32);
loc_82D4AE24:
	// rlwinm r9,r8,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,24(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r7,r8,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// add r27,r9,r3
	ctx.r27.u64 = ctx.r9.u64 + ctx.r3.u64;
	// lfs f6,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f6.f64 = double(temp.f32);
	// add r24,r9,r4
	ctx.r24.u64 = ctx.r9.u64 + ctx.r4.u64;
	// lfs f5,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f5.f64 = double(temp.f32);
	// add r26,r7,r3
	ctx.r26.u64 = ctx.r7.u64 + ctx.r3.u64;
	// lfs f10,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f27,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f27.f64 = double(temp.f32);
	// add r25,r7,r4
	ctx.r25.u64 = ctx.r7.u64 + ctx.r4.u64;
	// lfsx f21,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f28,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// mulli r30,r8,20
	ctx.r30.s64 = ctx.r8.s64 * 20;
	// fmuls f20,f12,f28
	ctx.f20.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// lfs f22,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f28,f11,f28
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// lfs f26,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// lfs f3,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f10,f26
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// lfs f1,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f1.f64 = double(temp.f32);
	// lfs f9,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f9.f64 = double(temp.f32);
	// lfs f4,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f26,f9,f26
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// fmuls f29,f4,f3
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfsx f25,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfs f2,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// add r23,r31,r3
	ctx.r23.u64 = ctx.r31.u64 + ctx.r3.u64;
	// lfs f8,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f8.f64 = double(temp.f32);
	// add r22,r30,r3
	ctx.r22.u64 = ctx.r30.u64 + ctx.r3.u64;
	// lfs f24,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// fmadds f11,f11,f27,f20
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f27.f64 + ctx.f20.f64));
	// lfs f7,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f12,f12,f27,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f27.f64 - ctx.f28.f64));
	// lfsx f23,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f28,f6,f22
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// lfs f31,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f27,f5,f22
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f22.f64));
	// lfs f30,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f9,f9,f25,f19
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f25.f64 + ctx.f19.f64));
	// lfs f22,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f10,f10,f25,f26
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f25.f64 - ctx.f26.f64));
	// lfsx f19,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f29,f1,f2,f29
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 + ctx.f29.f64));
	// lfs f26,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f18,f8,f24
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f24.f64));
	// lfs f25,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f7,f24
	ctx.f24.f64 = double(float(ctx.f7.f64 * ctx.f24.f64));
	// lfsx f17,r30,r5
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// add r21,r31,r4
	ctx.r21.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fmadds f5,f5,f21,f28
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f21.f64 + ctx.f28.f64));
	// fmsubs f6,f6,f21,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f21.f64 - ctx.f27.f64));
	// fmuls f21,f1,f3
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f3,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f3.f64 = double(temp.f32);
	// fadds f28,f9,f11
	ctx.f28.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fsubs f9,f9,f11
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// fadds f11,f10,f12
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fmadds f7,f7,f23,f18
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f23.f64 + ctx.f18.f64));
	// lfs f18,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f10,f12,f10
	ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fmsubs f8,f8,f23,f24
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f23.f64 - ctx.f24.f64));
	// lfs f24,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f20,f5,f29
	ctx.f20.f64 = double(float(ctx.f5.f64 - ctx.f29.f64));
	// fadds f1,f29,f5
	ctx.f1.f64 = double(float(ctx.f29.f64 + ctx.f5.f64));
	// lfs f5,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f4,f4,f2,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64 - ctx.f21.f64));
	// lfs f29,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f12,f9,f0
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fnmsubs f9,f28,f13,f31
	ctx.f9.f64 = double(float(-(ctx.f28.f64 * ctx.f13.f64 - ctx.f31.f64)));
	// fnmsubs f27,f11,f13,f30
	ctx.f27.f64 = double(float(-(ctx.f11.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f2,f20,f0
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f20,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fadds f21,f4,f6
	ctx.f21.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fsubs f4,f4,f6
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fnmsubs f6,f1,f13,f7
	ctx.f6.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// lfsx f16,r31,r6
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r6.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f24,f18
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f18.f64));
	// stfs f16,-264(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fmuls f18,f23,f18
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f18.f64));
	// lfsx f16,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// stfs f16,-272(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fmuls f16,f3,f16
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f16.f64));
	// lfsx f15,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f30.f64));
	// stfs f15,-268(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fnmsubs f15,f21,f13,f8
	ctx.f15.f64 = double(float(-(ctx.f21.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// stfs f15,-260(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// fmuls f15,f26,f20
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// fmuls f20,f25,f20
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f20.f64));
	// add r20,r30,r4
	ctx.r20.u64 = ctx.r30.u64 + ctx.r4.u64;
	// fadds f7,f1,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 + ctx.f7.f64));
	// fadds f1,f21,f8
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f8.f64));
	// lfsx f21,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f23,f23,f17,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f17.f64 + ctx.f14.f64));
	// fmsubs f24,f24,f17,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f17.f64 - ctx.f18.f64));
	// lfs f17,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fadds f8,f9,f10
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fmadds f25,f25,f19,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f19.f64 + ctx.f15.f64));
	// fmsubs f20,f26,f19,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f19.f64 - ctx.f20.f64));
	// lfs f26,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f22,f26
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f26.f64));
	// lfs f26,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// lfs f19,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f5,f26
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// fmadds f22,f22,f19,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 + ctx.f16.f64));
	// lfs f16,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f3,f3,f19,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f19.f64 - ctx.f15.f64));
	// fadds f19,f23,f25
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// fsubs f23,f25,f23
	ctx.f23.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// fadds f25,f24,f20
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// fsubs f20,f24,f20
	ctx.f20.f64 = double(float(ctx.f24.f64 - ctx.f20.f64));
	// fmuls f15,f29,f26
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f26.f64));
	// lfs f26,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f29,f29,f26,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f26.f64 + ctx.f14.f64));
	// fadds f28,f19,f22
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// fmuls f24,f23,f0
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fnmsubs f18,f25,f13,f3
	ctx.f18.f64 = double(float(-(ctx.f25.f64 * ctx.f13.f64 - ctx.f3.f64)));
	// fmuls f23,f20,f0
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fnmsubs f20,f19,f13,f22
	ctx.f20.f64 = double(float(-(ctx.f19.f64 * ctx.f13.f64 - ctx.f22.f64)));
	// lfs f22,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fadds f3,f25,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 + ctx.f3.f64));
	// lfsx f25,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f5,f5,f26,f15
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f26.f64 - ctx.f15.f64));
	// lfsx f26,r30,r6
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r6.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f19,f28,f31
	ctx.f19.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// fsubs f31,f31,f28
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// fadds f30,f20,f23
	ctx.f30.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// fadds f28,f11,f3
	ctx.f28.f64 = double(float(ctx.f11.f64 + ctx.f3.f64));
	// fsubs f3,f11,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 - ctx.f3.f64));
	// fsubs f11,f8,f30
	ctx.f11.f64 = double(float(ctx.f8.f64 - ctx.f30.f64));
	// stfs f11,-264(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfs f11,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f11.f64 = double(temp.f32);
	// fadds f15,f30,f8
	ctx.f15.f64 = double(float(ctx.f30.f64 + ctx.f8.f64));
	// lfs f8,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f14,f11,f25
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// fmuls f30,f17,f22
	ctx.f30.f64 = double(float(ctx.f17.f64 * ctx.f22.f64));
	// fmuls f25,f8,f25
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// fmuls f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f22.f64));
	// fmadds f8,f8,f21,f14
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f21.f64 + ctx.f14.f64));
	// fmadds f30,f16,f26,f30
	ctx.f30.f64 = double(float(ctx.f16.f64 * ctx.f26.f64 + ctx.f30.f64));
	// fmsubs f11,f11,f21,f25
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f21.f64 - ctx.f25.f64));
	// fmsubs f26,f17,f26,f22
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 - ctx.f22.f64));
	// fadds f25,f8,f30
	ctx.f25.f64 = double(float(ctx.f8.f64 + ctx.f30.f64));
	// fsubs f30,f30,f8
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f8.f64));
	// fadds f8,f11,f26
	ctx.f8.f64 = double(float(ctx.f11.f64 + ctx.f26.f64));
	// fsubs f26,f11,f26
	ctx.f26.f64 = double(float(ctx.f11.f64 - ctx.f26.f64));
	// fmuls f11,f30,f0
	ctx.f11.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fadds f22,f8,f5
	ctx.f22.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// fmuls f30,f26,f0
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fadds f26,f25,f29
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// fnmsubs f8,f8,f13,f5
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f13.f64 - ctx.f5.f64)));
	// fnmsubs f29,f25,f13,f29
	ctx.f29.f64 = double(float(-(ctx.f25.f64 * ctx.f13.f64 - ctx.f29.f64)));
	// fadds f5,f7,f26
	ctx.f5.f64 = double(float(ctx.f7.f64 + ctx.f26.f64));
	// fsubs f7,f26,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 - ctx.f7.f64));
	// fadds f26,f1,f22
	ctx.f26.f64 = double(float(ctx.f1.f64 + ctx.f22.f64));
	// fsubs f1,f22,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 - ctx.f1.f64));
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// fsubs f25,f19,f5
	ctx.f25.f64 = double(float(ctx.f19.f64 - ctx.f5.f64));
	// stfsx f25,r30,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f25,f7,f3
	ctx.f25.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// addi r11,r11,88
	ctx.r11.s64 = ctx.r11.s64 + 88;
	// fsubs f7,f7,f3
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// fsubs f3,f26,f28
	ctx.f3.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// stfsx f3,r30,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f5,f5,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f19.f64));
	// stfs f5,0(r3)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f5,f26,f28
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// stfs f5,0(r4)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f26,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f26.f64 = double(temp.f32);
	// fadds f3,f27,f12
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f12.f64));
	// fadds f28,f26,f2
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// fsubs f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// fsubs f5,f31,f1
	ctx.f5.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// stfsx f5,r10,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f25,r10,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f5,f1,f31
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f31.f64));
	// stfsx f5,r9,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f6,f4
	ctx.f5.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// stfsx f7,r9,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f7,f29,f30
	ctx.f7.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fadds f1,f18,f24
	ctx.f1.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// fadds f31,f8,f11
	ctx.f31.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// add r4,r29,r4
	ctx.r4.u64 = ctx.r29.u64 + ctx.r4.u64;
	// fsubs f9,f20,f23
	ctx.f9.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// fsubs f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f30.f64));
	// fsubs f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// fsubs f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 - ctx.f11.f64));
	// fsubs f8,f2,f26
	ctx.f8.f64 = double(float(ctx.f2.f64 - ctx.f26.f64));
	// fsubs f4,f18,f24
	ctx.f4.f64 = double(float(ctx.f18.f64 - ctx.f24.f64));
	// fsubs f12,f27,f12
	ctx.f12.f64 = double(float(ctx.f27.f64 - ctx.f12.f64));
	// fadds f2,f5,f7
	ctx.f2.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fsubs f7,f5,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// fadds f5,f1,f3
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fsubs f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// fadds f1,f28,f31
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// fadds f29,f9,f10
	ctx.f29.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fadds f9,f6,f30
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f30.f64));
	// fsubs f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// fadds f30,f12,f4
	ctx.f30.f64 = double(float(ctx.f12.f64 + ctx.f4.f64));
	// fsubs f31,f31,f28
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// fsubs f12,f12,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f4.f64));
	// fsubs f4,f8,f11
	ctx.f4.f64 = double(float(ctx.f8.f64 - ctx.f11.f64));
	// fadds f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// fsubs f8,f15,f2
	ctx.f8.f64 = double(float(ctx.f15.f64 - ctx.f2.f64));
	// stfsx f8,r31,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fsubs f28,f1,f5
	ctx.f28.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// stfsx f28,r31,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f8,f2,f15
	ctx.f8.f64 = double(float(ctx.f2.f64 + ctx.f15.f64));
	// stfs f8,0(r26)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fadds f8,f1,f5
	ctx.f8.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// stfs f8,0(r25)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// lfs f8,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f2,f7,f3
	ctx.f2.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// fadds f7,f7,f3
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// fsubs f5,f8,f31
	ctx.f5.f64 = double(float(ctx.f8.f64 - ctx.f31.f64));
	// stfsx f5,r7,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// stfsx f2,r7,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// fadds f8,f31,f8
	ctx.f8.f64 = double(float(ctx.f31.f64 + ctx.f8.f64));
	// stfs f8,0(r23)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// fsubs f8,f29,f9
	ctx.f8.f64 = double(float(ctx.f29.f64 - ctx.f9.f64));
	// stfs f7,0(r21)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// fadds f7,f4,f30
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f30.f64));
	// stfs f8,0(r27)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fadds f9,f9,f29
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f29.f64));
	// stfs f7,0(r24)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fsubs f8,f6,f12
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// stfsx f9,r10,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f9,f4,f30
	ctx.f9.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// stfsx f9,r10,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f9,f10,f11
	ctx.f9.f64 = double(float(ctx.f10.f64 - ctx.f11.f64));
	// stfs f9,0(r5)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// stfs f8,0(r6)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f12,f6,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 + ctx.f12.f64));
	// stfs f11,0(r22)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// subf r5,r29,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r29.s64;
	// stfs f12,0(r20)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// lwz r10,3532(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 3532);
	// subf r6,r29,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r29.s64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d4ae24
	if (!ctx.cr0.eq) goto loc_82D4AE24;
loc_82D4B20C:
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28f2c
	ctx.lr = 0x82D4B214;
	__restfpr_14(ctx, base);
	// b 0x82e28e94
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4B218"))) PPC_WEAK_FUNC(sub_82D4B218);
PPC_FUNC_IMPL(__imp__sub_82D4B218) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-2576
	ctx.r5.s64 = ctx.r11.s64 + -2576;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-21024
	ctx.r4.s64 = ctx.r11.s64 + -21024;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4B230"))) PPC_WEAK_FUNC(sub_82D4B230);
PPC_FUNC_IMPL(__imp__sub_82D4B230) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D4B238;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28ee0
	ctx.lr = 0x82D4B240;
	__savefpr_14(ctx, base);
	// mulli r11,r9,72
	ctx.r11.s64 = ctx.r9.s64 * 72;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-72
	ctx.r11.s64 = ctx.r11.s64 + -72;
	// bge cr6,0x82d4b5f4
	if (!ctx.cr6.lt) goto loc_82D4B5F4;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r25,r9,r10
	ctx.r25.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f13,-7588(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -7588);
	ctx.f13.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f0,-7584(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -7584);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,-12288(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -12288);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-7592(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7592);
	ctx.f12.f64 = double(temp.f32);
loc_82D4B284:
	// lfs f8,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f6,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// mulli r7,r8,12
	ctx.r7.s64 = ctx.r8.s64 * 12;
	// lfs f5,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f27,f6,f8
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f26,f5,f8
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// lfs f7,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f10,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// lfs f2,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f25,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f19,f2,f25
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfs f4,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f4.f64 = double(temp.f32);
	// rlwinm r9,r8,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f30,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f30.f64 = double(temp.f32);
	// add r28,r10,r4
	ctx.r28.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lfs f31,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f31.f64 = double(temp.f32);
	// add r29,r9,r4
	ctx.r29.u64 = ctx.r9.u64 + ctx.r4.u64;
	// lfs f9,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f9.f64 = double(temp.f32);
	// lfs f3,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f3.f64 = double(temp.f32);
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmadds f8,f5,f7,f27
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 + ctx.f27.f64));
	// lfsx f5,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f7,f6,f7,f26
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f7.f64 - ctx.f26.f64));
	// lfsx f6,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f21,f10,f6
	ctx.f21.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// lfsx f24,r7,r5
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// add r27,r7,r6
	ctx.r27.u64 = ctx.r7.u64 + ctx.r6.u64;
	// lfs f27,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f31,f23
	ctx.f18.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// fmuls f20,f4,f27
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// lfs f1,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f17,f30,f23
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f23.f64));
	// lfsx f26,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f27,f3,f27
	ctx.f27.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfsx f22,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f29,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// add r26,r31,r6
	ctx.r26.u64 = ctx.r31.u64 + ctx.r6.u64;
	// lfs f28,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f23,f9,f5,f21
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f5.f64 + ctx.f21.f64));
	// fmuls f21,f9,f6
	ctx.f21.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmadds f6,f1,f24,f19
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f24.f64 + ctx.f19.f64));
	// fmuls f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// lfs f25,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f9,f3,f26,f20
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f26.f64 + ctx.f20.f64));
	// lfs f20,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f3,f30,f22,f18
	ctx.f3.f64 = double(float(ctx.f30.f64 * ctx.f22.f64 + ctx.f18.f64));
	// lfs f18,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f31,f31,f22,f17
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f22.f64 - ctx.f17.f64));
	// lfs f22,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f17,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f10,f10,f5,f21
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f5.f64 - ctx.f21.f64));
	// lfs f21,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f5,f4,f26,f27
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f26.f64 - ctx.f27.f64));
	// lfs f26,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f4,f2,f24,f1
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f24.f64 - ctx.f1.f64));
	// lfs f24,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f2,f23,f9
	ctx.f2.f64 = double(float(ctx.f23.f64 - ctx.f9.f64));
	// fsubs f30,f29,f3
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f3.f64));
	// fadds f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// fsubs f29,f28,f31
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f31.f64));
	// fadds f31,f31,f28
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f28.f64));
	// fsubs f1,f6,f8
	ctx.f1.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// fadds f9,f9,f23
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f23.f64));
	// lfs f23,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f23.f64 = double(temp.f32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// lfsx f6,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f28,f10,f5
	ctx.f28.f64 = double(float(ctx.f10.f64 - ctx.f5.f64));
	// fsubs f19,f7,f4
	ctx.f19.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// fadds f10,f5,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f10.f64));
	// lfs f5,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fadds f7,f4,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// lfsx f4,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f27,f1,f2
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fsubs f16,f19,f28
	ctx.f16.f64 = double(float(ctx.f19.f64 - ctx.f28.f64));
	// fadds f15,f7,f10
	ctx.f15.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// stfs f15,-224(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -224, temp.u32);
	// lfsx f15,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-236(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// lfsx f15,r31,r5
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r5.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// stfs f14,-232(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -232, temp.u32);
	// fmuls f14,f18,f4
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f4.f64));
	// fmuls f4,f23,f4
	ctx.f4.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// stfs f4,-240(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// stfs f15,-228(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -228, temp.u32);
	// fmuls f15,f21,f6
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// fmuls f6,f20,f6
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// fadds f28,f19,f28
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// fsubs f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// fmadds f23,f23,f17,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f17.f64 + ctx.f14.f64));
	// fmadds f4,f20,f5,f15
	ctx.f4.f64 = double(float(ctx.f20.f64 * ctx.f5.f64 + ctx.f15.f64));
	// fmsubs f5,f21,f5,f6
	ctx.f5.f64 = double(float(ctx.f21.f64 * ctx.f5.f64 - ctx.f6.f64));
	// lfs f20,-232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -232);
	ctx.f20.f64 = double(temp.f32);
	// lfs f6,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f14,f22,f20
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// fmsubs f21,f18,f17,f6
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f6.f64));
	// lfs f6,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f18,f26,f6
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// fmuls f17,f24,f20
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f20.f64));
	// lfs f20,-228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -228);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f25,f6
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// lfs f6,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f25,f25,f20,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f20.f64 + ctx.f18.f64));
	// fmadds f22,f22,f6,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 + ctx.f17.f64));
	// fmsubs f26,f26,f20,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 - ctx.f15.f64));
	// fmsubs f6,f24,f6,f14
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 - ctx.f14.f64));
	// fsubs f24,f25,f4
	ctx.f24.f64 = double(float(ctx.f25.f64 - ctx.f4.f64));
	// fadds f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// fsubs f25,f23,f22
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// fsubs f22,f26,f5
	ctx.f22.f64 = double(float(ctx.f26.f64 - ctx.f5.f64));
	// fadds f5,f5,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f26.f64));
	// fsubs f26,f21,f6
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f6.f64));
	// fadds f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f6.f64));
	// fadds f6,f25,f24
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// fadds f20,f23,f4
	ctx.f20.f64 = double(float(ctx.f23.f64 + ctx.f4.f64));
	// fsubs f1,f24,f25
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// fadds f18,f26,f22
	ctx.f18.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// fsubs f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// lfs f22,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f7,f5,f21
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f21.f64));
	// fadds f17,f21,f5
	ctx.f17.f64 = double(float(ctx.f21.f64 + ctx.f5.f64));
	// fadds f15,f6,f27
	ctx.f15.f64 = double(float(ctx.f6.f64 + ctx.f27.f64));
	// fsubs f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// fmuls f19,f1,f13
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fadds f25,f18,f16
	ctx.f25.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// fsubs f21,f17,f22
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// fmuls f27,f6,f12
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// fsubs f6,f16,f18
	ctx.f6.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f6,-240(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// fadds f6,f8,f9
	ctx.f6.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fmuls f5,f25,f12
	ctx.f5.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// fmuls f18,f1,f0
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f16,f10,f13
	ctx.f16.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fsubs f24,f20,f6
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f6.f64));
	// fadds f14,f20,f6
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f6.f64));
	// fmuls f20,f28,f13
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// fnmsubs f6,f15,f11,f30
	ctx.f6.f64 = double(float(-(ctx.f15.f64 * ctx.f11.f64 - ctx.f30.f64)));
	// fadds f30,f15,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 + ctx.f30.f64));
	// stfsx f30,r9,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fmuls f15,f7,f13
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmadds f7,f7,f0,f16
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 + ctx.f16.f64));
	// fmuls f25,f24,f12
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fmuls f24,f26,f13
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmadds f26,f26,f0,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f20.f64));
	// fnmsubs f30,f14,f11,f3
	ctx.f30.f64 = double(float(-(ctx.f14.f64 * ctx.f11.f64 - ctx.f3.f64)));
	// fmsubs f10,f10,f0,f15
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 - ctx.f15.f64));
	// fmsubs f28,f28,f0,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 - ctx.f24.f64));
	// fsubs f24,f6,f27
	ctx.f24.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// fadds f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f27.f64));
	// fmadds f27,f2,f0,f19
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f19.f64));
	// fmsubs f2,f2,f13,f18
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 - ctx.f18.f64));
	// lfs f1,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f1,f11,f29
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 + ctx.f29.f64));
	// lfs f20,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f29,f20,f29
	ctx.f29.f64 = double(float(ctx.f20.f64 - ctx.f29.f64));
	// fadds f20,f14,f3
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f3.f64));
	// fsubs f3,f1,f5
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// fadds f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fadds f1,f30,f25
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// addic. r25,r25,-1
	ctx.xer.ca = ctx.r25.u32 > 0;
	ctx.r25.s64 = ctx.r25.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// fsubs f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// addi r11,r11,72
	ctx.r11.s64 = ctx.r11.s64 + 72;
	// fsubs f25,f24,f28
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f28.f64));
	// stfsx f25,r10,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f28,f24,f28
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// stfsx f28,r7,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fsubs f28,f6,f26
	ctx.f28.f64 = double(float(ctx.f6.f64 - ctx.f26.f64));
	// stfs f28,0(r5)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f6,f6,f26
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f26.f64));
	// stfsx f6,r31,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// stfsx f29,r9,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fsubs f6,f27,f3
	ctx.f6.f64 = double(float(ctx.f27.f64 - ctx.f3.f64));
	// stfsx f6,r10,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f3,f27
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f27.f64));
	// stfsx f6,r7,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f2,f5
	ctx.f6.f64 = double(float(ctx.f2.f64 - ctx.f5.f64));
	// stfs f6,0(r6)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f6,f5,f2
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f2.f64));
	// stfsx f6,r31,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f1,f7
	ctx.f6.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// stfs f20,0(r3)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f7,f1,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 + ctx.f7.f64));
	// stfsx f6,r9,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// stfsx f7,r7,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f30,f10
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f10.f64));
	// stfsx f7,r10,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f30,f10
	ctx.f10.f64 = double(float(ctx.f30.f64 + ctx.f10.f64));
	// stfsx f10,r31,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f10,f17,f22
	ctx.f10.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f8,f4,f23
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f23.f64));
	// add r3,r30,r3
	ctx.r3.u64 = ctx.r30.u64 + ctx.r3.u64;
	// fmuls f7,f21,f12
	ctx.f7.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// subf r5,r30,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r30.s64;
	// subf r6,r30,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r30.s64;
	// fmuls f6,f9,f13
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fadds f4,f10,f31
	ctx.f4.f64 = double(float(ctx.f10.f64 + ctx.f31.f64));
	// stfs f4,0(r4)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fnmsubs f10,f10,f11,f31
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f11.f64 - ctx.f31.f64)));
	// add r4,r30,r4
	ctx.r4.u64 = ctx.r30.u64 + ctx.r4.u64;
	// fmuls f5,f8,f13
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fmadds f8,f8,f0,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f6.f64));
	// fadds f6,f10,f7
	ctx.f6.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// fsubs f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// fmsubs f9,f9,f0,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 - ctx.f5.f64));
	// fsubs f7,f8,f6
	ctx.f7.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f7,0(r27)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f8,0(r29)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fsubs f8,f9,f10
	ctx.f8.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// stfs f8,0(r26)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fadds f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f9.f64));
	// stfs f10,0(r28)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// lwz r10,3532(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 3532);
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d4b284
	if (!ctx.cr0.eq) goto loc_82D4B284;
loc_82D4B5F4:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f2c
	ctx.lr = 0x82D4B5FC;
	__restfpr_14(ctx, base);
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4B600"))) PPC_WEAK_FUNC(sub_82D4B600);
PPC_FUNC_IMPL(__imp__sub_82D4B600) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-2520
	ctx.r5.s64 = ctx.r11.s64 + -2520;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-19920
	ctx.r4.s64 = ctx.r11.s64 + -19920;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4B618"))) PPC_WEAK_FUNC(sub_82D4B618);
PPC_FUNC_IMPL(__imp__sub_82D4B618) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D4B620;
	__savegprlr_26(ctx, base);
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28ef4
	ctx.lr = 0x82D4B628;
	__savefpr_19(ctx, base);
	// mulli r11,r9,56
	ctx.r11.s64 = ctx.r9.s64 * 56;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-56
	ctx.r11.s64 = ctx.r11.s64 + -56;
	// bge cr6,0x82d4b898
	if (!ctx.cr6.lt) goto loc_82D4B898;
	// subf r30,r9,r10
	ctx.r30.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f0,140(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D4B654:
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// lfs f11,48(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f11.f64 = double(temp.f32);
	// add r29,r10,r4
	ctx.r29.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lfs f10,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f10.f64 = double(temp.f32);
	// lfs f13,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f12.f64 = double(temp.f32);
	// lfs f9,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f31,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfs f7,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// rlwinm r7,r8,3,0,28
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f5,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f5.f64 = double(temp.f32);
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f30,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// add r28,r7,r5
	ctx.r28.u64 = ctx.r7.u64 + ctx.r5.u64;
	// lfs f6,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f6.f64 = double(temp.f32);
	// add r27,r9,r3
	ctx.r27.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fmuls f21,f5,f30
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f3,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfs f1,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f11,f1
	ctx.f22.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// lfsx f28,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f1,f10,f1
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f1.f64));
	// lfsx f26,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f20,f13,f28
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f27,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f28,f12,f28
	ctx.f28.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// lfs f24,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f19,f9,f26
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// lfsx f25,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f26,f8,f26
	ctx.f26.f64 = double(float(ctx.f8.f64 * ctx.f26.f64));
	// lfsx f23,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfs f2,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f29,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f10,f10,f31,f22
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64 + ctx.f22.f64));
	// fmsubs f11,f11,f31,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f31.f64 - ctx.f1.f64));
	// fmuls f31,f7,f24
	ctx.f31.f64 = double(float(ctx.f7.f64 * ctx.f24.f64));
	// fmadds f12,f12,f27,f20
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f27.f64 + ctx.f20.f64));
	// fmsubs f13,f13,f27,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f27.f64 - ctx.f28.f64));
	// lfs f27,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f8,f8,f25,f19
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f25.f64 + ctx.f19.f64));
	// fmsubs f9,f9,f25,f26
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f25.f64 - ctx.f26.f64));
	// lfs f26,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f28,f6,f24
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// lfs f24,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f1,f4,f29,f21
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 + ctx.f21.f64));
	// fmadds f6,f6,f23,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f23.f64 + ctx.f31.f64));
	// fadds f31,f12,f3
	ctx.f31.f64 = double(float(ctx.f12.f64 + ctx.f3.f64));
	// fsubs f12,f3,f12
	ctx.f12.f64 = double(float(ctx.f3.f64 - ctx.f12.f64));
	// fsubs f3,f2,f13
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f13.f64));
	// fadds f13,f13,f2
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f2.f64));
	// fadds f2,f8,f10
	ctx.f2.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fsubs f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// fadds f8,f9,f11
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fsubs f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f7,f7,f23,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f23.f64 - ctx.f28.f64));
	// lfs f28,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f23,f4,f30
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// lfs f4,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f4.f64 = double(temp.f32);
	// fadds f25,f1,f6
	ctx.f25.f64 = double(float(ctx.f1.f64 + ctx.f6.f64));
	// fsubs f6,f6,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// lfsx f1,r7,r6
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f4,f9
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f9.f64));
	// fadds f30,f11,f10
	ctx.f30.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// fsubs f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f11.f64));
	// fmsubs f10,f5,f29,f23
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f29.f64 - ctx.f23.f64));
	// lfsx f5,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f23,f27,f9
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// fadds f9,f25,f31
	ctx.f9.f64 = double(float(ctx.f25.f64 + ctx.f31.f64));
	// fsubs f31,f31,f25
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f25.f64));
	// fsubs f29,f3,f6
	ctx.f29.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// fadds f25,f10,f7
	ctx.f25.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// fsubs f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// fadds f7,f6,f3
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// fmuls f3,f26,f5
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fmadds f4,f4,f28,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f28.f64 + ctx.f23.f64));
	// fmsubs f6,f27,f28,f22
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f28.f64 - ctx.f22.f64));
	// fmuls f28,f24,f5
	ctx.f28.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// fmadds f5,f24,f1,f3
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f1.f64 + ctx.f3.f64));
	// fmsubs f1,f26,f1,f28
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 - ctx.f28.f64));
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// fsubs f28,f12,f10
	ctx.f28.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// addi r11,r11,56
	ctx.r11.s64 = ctx.r11.s64 + 56;
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f10,f4,f5
	ctx.f10.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// fadds f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// fadds f3,f25,f13
	ctx.f3.f64 = double(float(ctx.f25.f64 + ctx.f13.f64));
	// fsubs f13,f13,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f25.f64));
	// fsubs f4,f6,f1
	ctx.f4.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// fadds f6,f1,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 + ctx.f6.f64));
	// fadds f1,f5,f2
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f2.f64));
	// fsubs f27,f4,f10
	ctx.f27.f64 = double(float(ctx.f4.f64 - ctx.f10.f64));
	// fadds f26,f6,f8
	ctx.f26.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// fsubs f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// fsubs f6,f2,f5
	ctx.f6.f64 = double(float(ctx.f2.f64 - ctx.f5.f64));
	// fsubs f5,f9,f1
	ctx.f5.f64 = double(float(ctx.f9.f64 - ctx.f1.f64));
	// stfsx f5,r10,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f1,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 + ctx.f9.f64));
	// stfs f9,0(r3)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f10,f4,f10
	ctx.f10.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fsubs f5,f27,f30
	ctx.f5.f64 = double(float(ctx.f27.f64 - ctx.f30.f64));
	// fsubs f9,f26,f3
	ctx.f9.f64 = double(float(ctx.f26.f64 - ctx.f3.f64));
	// stfsx f9,r10,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f9,f3,f26
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f26.f64));
	// stfs f9,0(r4)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f4,f30,f27
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// fsubs f9,f31,f8
	ctx.f9.f64 = double(float(ctx.f31.f64 - ctx.f8.f64));
	// stfsx f9,r9,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f8,f31
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f31.f64));
	// stfsx f9,r7,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fsubs f9,f6,f13
	ctx.f9.f64 = double(float(ctx.f6.f64 - ctx.f13.f64));
	// stfsx f9,r9,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f13,f13,f6
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f6.f64));
	// stfsx f13,r7,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fadds f8,f11,f10
	ctx.f8.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// fmuls f13,f5,f0
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f9,f4,f0
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fsubs f6,f28,f13
	ctx.f6.f64 = double(float(ctx.f28.f64 - ctx.f13.f64));
	// stfs f6,0(r5)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f28.f64));
	// subf r5,r31,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r31.s64;
	// fadds f6,f9,f29
	ctx.f6.f64 = double(float(ctx.f9.f64 + ctx.f29.f64));
	// stfsx f6,r9,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f13,r10,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f13,f9,f29
	ctx.f13.f64 = double(float(ctx.f9.f64 - ctx.f29.f64));
	// stfsx f13,r7,r6
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r6.u32, temp.u32);
	// fmuls f13,f8,f0
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fsubs f10,f12,f13
	ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// stfs f10,0(r28)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fadds f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// fadds f12,f11,f7
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f7.f64));
	// stfs f12,0(r29)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// stfs f13,0(r27)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fsubs f13,f11,f7
	ctx.f13.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// stfs f13,0(r6)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lwz r10,3532(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 3532);
	// subf r6,r31,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r31.s64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d4b654
	if (!ctx.cr0.eq) goto loc_82D4B654;
loc_82D4B898:
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28f40
	ctx.lr = 0x82D4B8A0;
	__restfpr_19(ctx, base);
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4B8A8"))) PPC_WEAK_FUNC(sub_82D4B8A8);
PPC_FUNC_IMPL(__imp__sub_82D4B8A8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-2464
	ctx.r5.s64 = ctx.r11.s64 + -2464;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-18920
	ctx.r4.s64 = ctx.r11.s64 + -18920;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4B8C0"))) PPC_WEAK_FUNC(sub_82D4B8C0);
PPC_FUNC_IMPL(__imp__sub_82D4B8C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82D4B8C8;
	__savegprlr_29(ctx, base);
	// addi r12,r1,-32
	ctx.r12.s64 = ctx.r1.s64 + -32;
	// bl 0x82e28ef8
	ctx.lr = 0x82D4B8D0;
	__savefpr_20(ctx, base);
	// mulli r11,r9,40
	ctx.r11.s64 = ctx.r9.s64 * 40;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-40
	ctx.r11.s64 = ctx.r11.s64 + -40;
	// bge cr6,0x82d4baac
	if (!ctx.cr6.lt) goto loc_82D4BAAC;
	// subf r31,r9,r10
	ctx.r31.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f13,-28552(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f0.f64 = double(temp.f32);
loc_82D4B904:
	// lfs f6,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f8,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f5,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f29,f6,f8
	ctx.f29.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f28,f5,f8
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// lfs f7,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// add r30,r9,r5
	ctx.r30.u64 = ctx.r9.u64 + ctx.r5.u64;
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// lfs f4,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f27,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f21,f4,f27
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// lfs f10,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f9.f64 = double(temp.f32);
	// lfs f3,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f27,f3,f27
	ctx.f27.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// fmadds f8,f5,f7,f29
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 + ctx.f29.f64));
	// lfsx f29,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f7,f6,f7,f28
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f7.f64 - ctx.f28.f64));
	// lfsx f6,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f12,f6
	ctx.f23.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// lfsx f5,r9,r6
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f6,f11,f6
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// lfs f26,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f25,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f22,f10,f29
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfs f1,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f29,f9,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// fmuls f20,f2,f25
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfsx f28,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f24,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f24.f64 = double(temp.f32);
	// addi r11,r11,40
	ctx.r11.s64 = ctx.r11.s64 + 40;
	// lfs f31,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmsubs f4,f4,f26,f27
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f26.f64 - ctx.f27.f64));
	// lfs f30,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f11,f11,f5,f23
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f5.f64 + ctx.f23.f64));
	// fmsubs f12,f12,f5,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f5.f64 - ctx.f6.f64));
	// fmadds f6,f3,f26,f21
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f26.f64 + ctx.f21.f64));
	// fmuls f3,f1,f25
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// fmadds f9,f9,f28,f22
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64 + ctx.f22.f64));
	// fmsubs f10,f10,f28,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 - ctx.f29.f64));
	// fmadds f5,f1,f24,f20
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f24.f64 + ctx.f20.f64));
	// fsubs f1,f30,f12
	ctx.f1.f64 = double(float(ctx.f30.f64 - ctx.f12.f64));
	// fadds f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f30.f64));
	// fmsubs f3,f2,f24,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f24.f64 - ctx.f3.f64));
	// fsubs f2,f31,f11
	ctx.f2.f64 = double(float(ctx.f31.f64 - ctx.f11.f64));
	// fadds f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f31.f64));
	// fsubs f31,f9,f8
	ctx.f31.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fsubs f30,f7,f10
	ctx.f30.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// fadds f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fsubs f8,f6,f5
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fadds f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fsubs f7,f4,f3
	ctx.f7.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fadds f5,f3,f4
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fadds f4,f8,f31
	ctx.f4.f64 = double(float(ctx.f8.f64 + ctx.f31.f64));
	// fsubs f8,f31,f8
	ctx.f8.f64 = double(float(ctx.f31.f64 - ctx.f8.f64));
	// fadds f31,f6,f9
	ctx.f31.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// fsubs f6,f6,f9
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f9.f64));
	// fsubs f3,f30,f7
	ctx.f3.f64 = double(float(ctx.f30.f64 - ctx.f7.f64));
	// fadds f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f30.f64));
	// fadds f29,f5,f10
	ctx.f29.f64 = double(float(ctx.f5.f64 + ctx.f10.f64));
	// fsubs f5,f5,f10
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f10.f64));
	// fadds f10,f4,f2
	ctx.f10.f64 = double(float(ctx.f4.f64 + ctx.f2.f64));
	// stfsx f10,r10,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fnmsubs f9,f4,f13,f2
	ctx.f9.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f2.f64)));
	// fadds f2,f31,f11
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f11.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fsubs f4,f3,f1
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// fmuls f10,f7,f0
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fadds f30,f29,f12
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f12.f64));
	// fmuls f7,f5,f0
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmadds f5,f3,f13,f1
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f1.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f11,f31,f13,f11
	ctx.f11.f64 = double(float(-(ctx.f31.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// fnmsubs f12,f29,f13,f12
	ctx.f12.f64 = double(float(-(ctx.f29.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// fadds f3,f9,f10
	ctx.f3.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// stfsx f3,r9,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// stfs f10,0(r5)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f10,f5,f8
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// stfsx f4,r10,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// subf r5,r7,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r7.s64;
	// stfsx f10,r9,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f10,f8,f5
	ctx.f10.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// stfs f10,0(r6)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f10,f11,f7
	ctx.f10.f64 = double(float(ctx.f11.f64 + ctx.f7.f64));
	// stfs f2,0(r3)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// stfs f10,0(r30)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// stfsx f11,r10,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f11,f12,f6
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
	// stfs f30,0(r4)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f12,f6,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// stfsx f11,r10,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// add r3,r7,r3
	ctx.r3.u64 = ctx.r7.u64 + ctx.r3.u64;
	// stfsx f12,r9,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// lwz r10,3532(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3532);
	// add r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 + ctx.r4.u64;
	// subf r6,r7,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r7.s64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d4b904
	if (!ctx.cr0.eq) goto loc_82D4B904;
loc_82D4BAAC:
	// addi r12,r1,-32
	ctx.r12.s64 = ctx.r1.s64 + -32;
	// bl 0x82e28f44
	ctx.lr = 0x82D4BAB4;
	__restfpr_20(ctx, base);
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4BAB8"))) PPC_WEAK_FUNC(sub_82D4BAB8);
PPC_FUNC_IMPL(__imp__sub_82D4BAB8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-2408
	ctx.r5.s64 = ctx.r11.s64 + -2408;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-18240
	ctx.r4.s64 = ctx.r11.s64 + -18240;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4BAD0"))) PPC_WEAK_FUNC(sub_82D4BAD0);
PPC_FUNC_IMPL(__imp__sub_82D4BAD0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// stfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.f31.u64);
	// mulli r11,r9,24
	ctx.r11.s64 = ctx.r9.s64 * 24;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// addi r11,r11,-24
	ctx.r11.s64 = ctx.r11.s64 + -24;
	// bge cr6,0x82d4bbf4
	if (!ctx.cr6.lt) goto loc_82D4BBF4;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r9,r9,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r9.s64;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D4BB00:
	// lfs f12,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f10,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// lfs f9,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f4,f10,f12
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// fmuls f3,f9,f12
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// add r31,r10,r3
	ctx.r31.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lfs f11,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f8,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f8.f64 = double(temp.f32);
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// lfs f7,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f7.f64 = double(temp.f32);
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// lfs f6,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f12,f9,f11,f4
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f11.f64 + ctx.f4.f64));
	// lfsx f4,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fmsubs f11,f10,f11,f3
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 - ctx.f3.f64));
	// lfs f10,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f2,f0,f10
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// lfsx f9,r10,r5
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f1,f8,f4
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// lfsx f3,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f31,f13,f10
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmuls f4,f7,f4
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f4.f64));
	// fmadds f13,f13,f9,f2
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 + ctx.f2.f64));
	// fmadds f10,f7,f3,f1
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f3.f64 + ctx.f1.f64));
	// fmsubs f0,f0,f9,f31
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f9.f64 - ctx.f31.f64));
	// fmsubs f9,f8,f3,f4
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f3.f64 - ctx.f4.f64));
	// fadds f8,f13,f6
	ctx.f8.f64 = double(float(ctx.f13.f64 + ctx.f6.f64));
	// fadds f7,f10,f12
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// fsubs f13,f6,f13
	ctx.f13.f64 = double(float(ctx.f6.f64 - ctx.f13.f64));
	// fadds f6,f9,f11
	ctx.f6.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fadds f10,f0,f5
	ctx.f10.f64 = double(float(ctx.f0.f64 + ctx.f5.f64));
	// fsubs f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// fsubs f0,f5,f0
	ctx.f0.f64 = double(float(ctx.f5.f64 - ctx.f0.f64));
	// fsubs f9,f8,f7
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// stfsx f9,r10,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f7,f8
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfs f9,0(r3)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// add r3,r7,r3
	ctx.r3.u64 = ctx.r7.u64 + ctx.r3.u64;
	// fsubs f8,f6,f10
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f10.f64));
	// stfsx f8,r10,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f6.f64));
	// stfs f10,0(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f10,f13,f11
	ctx.f10.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// stfs f10,0(r5)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// stfs f13,0(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fsubs f9,f12,f0
	ctx.f9.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// stfs f9,0(r6)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
	// stfsx f0,r10,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,3532(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// add r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 + ctx.r4.u64;
	// subf r5,r7,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r7.s64;
	// subf r6,r7,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r7.s64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bne 0x82d4bb00
	if (!ctx.cr0.eq) goto loc_82D4BB00;
loc_82D4BBF4:
	// lfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r30,-16(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D4BC08"))) PPC_WEAK_FUNC(sub_82D4BC08);
PPC_FUNC_IMPL(__imp__sub_82D4BC08) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-2352
	ctx.r5.s64 = ctx.r11.s64 + -2352;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-17712
	ctx.r4.s64 = ctx.r11.s64 + -17712;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4BC20"))) PPC_WEAK_FUNC(sub_82D4BC20);
PPC_FUNC_IMPL(__imp__sub_82D4BC20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// addi r11,r11,-8
	ctx.r11.s64 = ctx.r11.s64 + -8;
	// bgelr cr6
	if (!ctx.cr6.lt) return;
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D4BC40:
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f8,f12,f0
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fmuls f7,f11,f0
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f13,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// lfs f9,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f0,f11,f13,f8
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f8.f64));
	// fmsubs f13,f12,f13,f7
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 - ctx.f7.f64));
	// fsubs f12,f10,f0
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f0.f64));
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f12,f13,f9
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// stfs f12,0(r6)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f0,f0,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f10.f64));
	// stfs f0,0(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f0,f13,f9
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f9.f64));
	// stfs f0,0(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// subf r5,r8,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r8.s64;
	// add r3,r8,r3
	ctx.r3.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r4,r8,r4
	ctx.r4.u64 = ctx.r8.u64 + ctx.r4.u64;
	// subf r6,r8,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r8.s64;
	// bne 0x82d4bc40
	if (!ctx.cr0.eq) goto loc_82D4BC40;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D4BCA8"))) PPC_WEAK_FUNC(sub_82D4BCA8);
PPC_FUNC_IMPL(__imp__sub_82D4BCA8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,-2296
	ctx.r5.s64 = ctx.r11.s64 + -2296;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-17376
	ctx.r4.s64 = ctx.r11.s64 + -17376;
	// b 0x82d77ea0
	sub_82D77EA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4BCC0"))) PPC_WEAK_FUNC(sub_82D4BCC0);
PPC_FUNC_IMPL(__imp__sub_82D4BCC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D4BCC8;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D4BCD0;
	__savefpr_14(ctx, base);
	// stwu r1,-640(r1)
	ea = -640 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d4d770
	if (!ctx.cr6.gt) goto loc_82D4D770;
	// lwz r11,724(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	// lis r14,-32234
	ctx.r14.s64 = -2112487424;
	// lis r15,-32234
	ctx.r15.s64 = -2112487424;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r16,-32234
	ctx.r16.s64 = -2112487424;
	// lis r17,-32234
	ctx.r17.s64 = -2112487424;
	// lis r18,-32234
	ctx.r18.s64 = -2112487424;
	// lfs f26,-5432(r14)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -5432);
	ctx.f26.f64 = double(temp.f32);
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lfs f27,-2140(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + -2140);
	ctx.f27.f64 = double(temp.f32);
	// stw r11,332(r1)
	PPC_STORE_U32(ctx.r1.u32 + 332, ctx.r11.u32);
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// lwz r11,732(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f29,-2148(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + -2148);
	ctx.f29.f64 = double(temp.f32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f30,-2152(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + -2152);
	ctx.f30.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f31,-5444(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -5444);
	ctx.f31.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f1,-5448(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -5448);
	ctx.f1.f64 = double(temp.f32);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f2,-2156(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -2156);
	ctx.f2.f64 = double(temp.f32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f3,-2160(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -2160);
	ctx.f3.f64 = double(temp.f32);
	// stw r11,340(r1)
	PPC_STORE_U32(ctx.r1.u32 + 340, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lis r27,-32236
	ctx.r27.s64 = -2112618496;
	// lfs f4,-2164(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -2164);
	ctx.f4.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f5,-2168(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -2168);
	ctx.f5.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f6,-5420(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -5420);
	ctx.f6.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f7,-5424(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -5424);
	ctx.f7.f64 = double(temp.f32);
	// stw r11,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f12,136(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f13,-8016(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f8,-8004(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -8004);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,-8000(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8000);
	ctx.f9.f64 = double(temp.f32);
	// stw r11,60(r1)
	PPC_STORE_U32(ctx.r1.u32 + 60, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f10,-8008(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8008);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,-8012(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8012);
	ctx.f11.f64 = double(temp.f32);
	// lfs f28,-2144(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + -2144);
	ctx.f28.f64 = double(temp.f32);
	// stw r11,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,32(r1)
	PPC_STORE_U32(ctx.r1.u32 + 32, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,20(r1)
	PPC_STORE_U32(ctx.r1.u32 + 20, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,36(r1)
	PPC_STORE_U32(ctx.r1.u32 + 36, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,24(r1)
	PPC_STORE_U32(ctx.r1.u32 + 24, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,16(r1)
	PPC_STORE_U32(ctx.r1.u32 + 16, ctx.r11.u32);
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f0,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
	// lwz r11,16(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// lfs f25,-5428(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -5428);
	ctx.f25.f64 = double(temp.f32);
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lfs f24,-2200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2200);
	ctx.f24.f64 = double(temp.f32);
	// lwz r11,132(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lfs f23,-2196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2196);
	ctx.f23.f64 = double(temp.f32);
	// lwz r11,24(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// stfs f23,312(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f23,-2192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2192);
	ctx.f23.f64 = double(temp.f32);
	// lwz r11,36(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	// stfs f23,324(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f23,-2188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2188);
	ctx.f23.f64 = double(temp.f32);
	// stfs f23,304(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lwz r11,20(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// lfs f23,-5436(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -5436);
	ctx.f23.f64 = double(temp.f32);
	// lwz r11,32(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// stfs f23,328(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f23,-5440(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -5440);
	ctx.f23.f64 = double(temp.f32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stfs f23,336(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f23,-2184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2184);
	ctx.f23.f64 = double(temp.f32);
	// lwz r11,180(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// stfs f23,316(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f23,-2180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2180);
	ctx.f23.f64 = double(temp.f32);
	// lwz r11,60(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	// stfs f23,308(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f23,-2176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2176);
	ctx.f23.f64 = double(temp.f32);
	// lwz r11,184(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// stfs f23,320(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfs f23,-2172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2172);
	ctx.f23.f64 = double(temp.f32);
	// stfs f23,268(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
loc_82D4BE6C:
	// rlwinm r25,r7,5,0,26
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f23,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// mulli r11,r7,40
	ctx.r11.s64 = ctx.r7.s64 * 40;
	// lfsx f14,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,92(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfsx f22,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r10,r7,104
	ctx.r10.s64 = ctx.r7.s64 * 104;
	// lfsx f21,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// mulli r24,r7,96
	ctx.r24.s64 = ctx.r7.s64 * 96;
	// lfsx f14,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,132(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fsubs f14,f22,f21
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// rlwinm r23,r7,4,0,27
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r22,r7,6,0,25
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xFFFFFFC0;
	// mulli r31,r7,24
	ctx.r31.s64 = ctx.r7.s64 * 24;
	// lfsx f21,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,36(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f21,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,20(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f21,f14,f0
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// mulli r30,r7,88
	ctx.r30.s64 = ctx.r7.s64 * 88;
	// lfsx f20,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f19,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// rlwinm r29,r7,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r28,r7,72
	ctx.r28.s64 = ctx.r7.s64 * 72;
	// lfsx f18,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f17,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r27,r7,120
	ctx.r27.s64 = ctx.r7.s64 * 120;
	// lfsx f16,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r26,r7,56
	ctx.r26.s64 = ctx.r7.s64 * 56;
	// lfsx f15,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r21,r7,80
	ctx.r21.s64 = ctx.r7.s64 * 80;
	// lfsx f22,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fsubs f14,f20,f19
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fmuls f19,f14,f0
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f19,24(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// stfs f20,64(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f19,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f14,f20,f19
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f19,f21,f18
	ctx.f19.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfs f19,92(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fsubs f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// fmuls f20,f14,f0
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfs f19,52(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f18,f14,f0
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fsubs f14,f17,f16
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,132(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmuls f14,f21,f8
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f8.f64));
	// fmuls f21,f21,f9
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f17,f10
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// lfs f17,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f17,f10
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// fmsubs f17,f17,f11,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 - ctx.f16.f64));
	// stfs f17,212(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f11,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f15.f64));
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// mulli r18,r7,28
	ctx.r18.s64 = ctx.r7.s64 * 28;
	// stfs f21,16(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmr f21,f15
	ctx.f21.f64 = ctx.f15.f64;
	// stfs f17,232(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fmsubs f17,f19,f9,f14
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f9.f64 - ctx.f14.f64));
	// stfs f17,204(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// mulli r17,r7,92
	ctx.r17.s64 = ctx.r7.s64 * 92;
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f11
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// fmuls f15,f21,f8
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f8.f64));
	// fmuls f14,f21,f9
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// mulli r16,r7,12
	ctx.r16.s64 = ctx.r7.s64 * 12;
	// mulli r15,r7,76
	ctx.r15.s64 = ctx.r7.s64 * 76;
	// mulli r14,r7,44
	ctx.r14.s64 = ctx.r7.s64 * 44;
	// mulli r19,r7,112
	ctx.r19.s64 = ctx.r7.s64 * 112;
	// mulli r20,r7,48
	ctx.r20.s64 = ctx.r7.s64 * 48;
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f19,f8,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f8.f64 + ctx.f21.f64));
	// stfs f21,92(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f21,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f10,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 + ctx.f17.f64));
	// stfs f21,200(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f21,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f21,f21,f10,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 - ctx.f16.f64));
	// stfs f21,296(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f21,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f19,f21,f9,f15
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f9.f64 - ctx.f15.f64));
	// stfs f19,276(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fmadds f21,f21,f8,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f8.f64 + ctx.f14.f64));
	// stfs f21,132(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f21,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f22,f12
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// fmuls f15,f21,f12
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f18
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// fmsubs f21,f21,f13,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 - ctx.f19.f64));
	// fmadds f22,f22,f13,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f15.f64));
	// lfsx f15,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f19,f20,f23
	ctx.f19.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// lfsx f15,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fadds f20,f18,f16
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// lfsx f15,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f15,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r7,108
	ctx.r14.s64 = ctx.r7.s64 * 108;
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f16,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f16,f12
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfsx f18,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fmuls f15,f16,f13
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// mulli r14,r7,124
	ctx.r14.s64 = ctx.r7.s64 * 124;
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r7,60
	ctx.r14.s64 = ctx.r7.s64 * 60;
	// fmsubs f15,f18,f12,f15
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 - ctx.f15.f64));
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fmadds f18,f18,f13,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f18,48(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,96(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f18,f15
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f12
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmuls f18,f18,f0
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f18,24(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f18,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r7,100
	ctx.r14.s64 = ctx.r7.s64 * 100;
	// fmsubs f18,f14,f13,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f18,40(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f18,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f13,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f18,44(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f18,f13
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmsubs f18,f15,f12,f14
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f14.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f15,f13,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f14.f64));
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f22,36(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f22,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f14,240(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfs f19,220(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fsubs f19,f21,f17
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// stfs f19,264(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fadds f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// stfs f21,124(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f19,f23,f21
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfs f19,272(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// lfs f21,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// fadds f19,f20,f21
	ctx.f19.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfs f21,228(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fsubs f21,f17,f16
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f20,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f20.f64 = double(temp.f32);
	// stfs f19,216(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fadds f19,f20,f21
	ctx.f19.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f19,128(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,280(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f20,f18,f21
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// stfs f20,180(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfs f21,168(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fadds f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fadds f14,f15,f21
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfsx f20,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f19,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f17,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f21,f22,f14
	ctx.f21.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f21,140(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfsx f21,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// mulli r18,r7,44
	ctx.r18.s64 = ctx.r7.s64 * 44;
	// lfsx f15,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r18,r7,108
	ctx.r18.s64 = ctx.r7.s64 * 108;
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,196(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fadds f16,f16,f18
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f16,184(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// mulli r16,r7,84
	ctx.r16.s64 = ctx.r7.s64 * 84;
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f19,f12
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfsx f15,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f15,80(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f18,244(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfsx f16,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fmadds f18,f17,f13,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f14.f64));
	// mulli r18,r7,124
	ctx.r18.s64 = ctx.r7.s64 * 124;
	// lfsx f15,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,88(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// mulli r18,r7,60
	ctx.r18.s64 = ctx.r7.s64 * 60;
	// lfsx f15,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,60(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fmuls f15,f17,f12
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// mulli r18,r7,36
	ctx.r18.s64 = ctx.r7.s64 * 36;
	// lfsx f22,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,24(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fsubs f22,f21,f20
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// lfsx f20,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,36(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// mulli r15,r7,52
	ctx.r15.s64 = ctx.r7.s64 * 52;
	// fmsubs f19,f19,f13,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 - ctx.f15.f64));
	// lfsx f16,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// mulli r15,r7,116
	ctx.r15.s64 = ctx.r7.s64 * 116;
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmuls f21,f21,f0
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f16,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// rlwinm r15,r7,2,0,29
	ctx.r15.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f20,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f20.f64 = double(temp.f32);
	// mulli r17,r7,20
	ctx.r17.s64 = ctx.r7.s64 * 20;
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f16,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,40(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f20,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r15,r7,68
	ctx.r15.s64 = ctx.r7.s64 * 68;
	// lfsx f16,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,112(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f17,f17,f12,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f15.f64));
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f16,f15
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fmuls f16,f20,f12
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f16,f14,f0
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f12
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fmsubs f20,f20,f13,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f20,52(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f20,f20,f13,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f20,24(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f14,f20,f13
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmsubs f20,f15,f12,f14
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f14.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f15,f13,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f16,f15
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// stfs f20,36(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f20,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// stfs f20,20(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// fadds f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f14,260(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f20,164(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f20,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// stfs f14,236(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// stfs f20,84(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fadds f20,f15,f14
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,284(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f16,f15
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfsx f15,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f15,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f15,f12
	ctx.f14.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfsx f15,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f15,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfsx f15,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f15,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,80(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f16,116(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfsx f16,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r25,r7,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f15,f17,f19
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// stfs f19,48(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f19,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,248(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f19,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f17,f19,f21
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// stfs f17,32(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f17,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// lfsx f15,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f17,192(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// stfs f21,100(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f21,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f21.f64 = double(temp.f32);
	// mulli r25,r7,116
	ctx.r25.s64 = ctx.r7.s64 * 116;
	// fmadds f21,f21,f13,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f21,56(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f21,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,28(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f21,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,76(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f21,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfs f22,160(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfsx f22,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r25,r7,52
	ctx.r25.s64 = ctx.r7.s64 * 52;
	// stfs f22,252(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfsx f22,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,188(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fadds f19,f22,f16
	ctx.f19.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// fsubs f21,f16,f22
	ctx.f21.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// lfs f22,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f22,f12
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f22,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f22,f12
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f22,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f13
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmuls f22,f22,f12
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f21,f21,f0
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// stfs f21,120(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fmuls f21,f19,f0
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f21,88(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f21,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// lfs f19,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// stfs f21,36(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fmsubs f19,f19,f13,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 - ctx.f17.f64));
	// stfs f19,60(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f19,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfs f19,112(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f22,f17,f13,f16
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f16.f64));
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f18
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f17,80(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f21,f17,f12,f14
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f14.f64));
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f19,f18,f17
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f18,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f18,f18,f13,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f18,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f18
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f17,136(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f17,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f18,144(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f17,f0
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,104(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f17,f16
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f16,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f16,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f15,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,256(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// stfs f16,64(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fadds f16,f21,f15
	ctx.f16.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// fsubs f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f15,112(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,60(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f22,288(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f22,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f22.f64 = double(temp.f32);
	// fadds f15,f19,f22
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// lfs f19,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f19.f64 = double(temp.f32);
	// stfs f22,172(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fadds f22,f18,f19
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f18,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f18
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// fadds f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,292(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fmuls f15,f14,f0
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfsx f14,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f14,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f21,f17
	ctx.f16.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// stfs f21,148(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f21,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// lfs f17,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f21,f17
	ctx.f16.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// stfs f16,72(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fsubs f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// stfs f21,248(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// lfs f21,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f16,f21,f17
	ctx.f16.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// stfs f16,112(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fadds f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f15,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,60(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f15,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,160(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfsx f15,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// stfs f15,120(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fadds f16,f17,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// stfs f21,176(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fmuls f15,f15,f10
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// lfsx f21,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f14,80(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f14,f19,f9
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f9.f64));
	// fmuls f19,f19,f8
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// stfs f19,32(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f16,76(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fmuls f16,f22,f10
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// fmsubs f22,f22,f11,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 - ctx.f15.f64));
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f19,f18,f8,f14
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f8.f64 + ctx.f14.f64));
	// fmadds f16,f15,f11,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 + ctx.f16.f64));
	// stfs f16,192(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f18,f18,f9,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f9.f64 - ctx.f16.f64));
	// stfs f18,224(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fsubs f16,f21,f17
	ctx.f16.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// lfs f18,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f18.f64 = double(temp.f32);
	// fadds f17,f17,f21
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// lfs f21,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f15,f21,f18
	ctx.f15.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// fadds f14,f18,f21
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f18,f21
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// stfs f18,96(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f21,32(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f18,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfs f21,28(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f21,f16,f0
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f16,f15,f0
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f16,100(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f16,f14,f0
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f17,188(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,60(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f18,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f18,f11
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f18,f9
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// fmuls f14,f18,f8
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// lfs f18,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f21,f18
	ctx.f18.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f18,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f18,52(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f18,40(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f18,76(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f18,f11
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// lfs f18,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// stfs f21,120(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f21,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f10,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64 + ctx.f16.f64));
	// stfs f18,28(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,88(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f16,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fmadds f18,f16,f8,f15
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f8.f64 + ctx.f15.f64));
	// lfs f15,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f16,f16,f9,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f9.f64 - ctx.f14.f64));
	// stfs f16,188(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmsubs f17,f15,f10,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f10.f64 - ctx.f17.f64));
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f15,f11
	ctx.f14.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f10
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f22,256(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmsubs f22,f15,f11,f16
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 - ctx.f16.f64));
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f10,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f14.f64));
	// fadds f14,f18,f19
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f18,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f18.f64 = double(temp.f32);
	// stfs f19,44(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fsubs f19,f17,f18
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f18,252(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f18,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f18.f64 = double(temp.f32);
	// stfs f19,68(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f17,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f14,160(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f18,96(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fadds f18,f16,f22
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// stfs f22,192(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f15,f10
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// fmuls f17,f22,f11
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,208(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f22,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f20,f6
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f22,80(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f19.f64 = double(temp.f32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,300(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f22,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f22,f9
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f9.f64));
	// fmsubs f19,f19,f10,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 - ctx.f17.f64));
	// stfs f19,28(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f19,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f11,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 + ctx.f16.f64));
	// stfs f19,120(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fmuls f16,f22,f8
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// lfs f22,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f7
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f7.f64));
	// lfs f19,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f22,f20,f7
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// lfs f20,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f7
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// stfs f20,188(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f17,f19,f9
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f9.f64));
	// stfs f22,224(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fmuls f19,f19,f8
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// fmadds f18,f21,f8,f18
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f8.f64 + ctx.f18.f64));
	// stfs f18,88(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fmr f20,f18
	ctx.f20.f64 = ctx.f18.f64;
	// lfs f18,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f21,f21,f9,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64 - ctx.f16.f64));
	// fmadds f22,f20,f8,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f8.f64 + ctx.f17.f64));
	// fmsubs f20,f20,f9,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 - ctx.f19.f64));
	// lfs f19,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f19,56(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f18,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f19,152(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f19,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f18,f19,f7,f15
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 - ctx.f15.f64));
	// stfs f18,156(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f18,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f6,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f6.f64 + ctx.f14.f64));
	// stfs f18,260(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f18,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f19,f19,f6,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f6.f64 + ctx.f18.f64));
	// stfs f19,108(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f19,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f19,f19,f6,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f6.f64 - ctx.f18.f64));
	// stfs f19,224(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f19,76(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f19,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f19,f5
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f5.f64));
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f19,f4
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// lfs f19,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f19,f2
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f2.f64));
	// fmuls f14,f19,f3
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// lfs f19,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f18,f18,f19
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f18,136(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// lfs f18,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f18.f64 = double(temp.f32);
	// stfs f19,64(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fmsubs f19,f18,f5,f17
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f5.f64 - ctx.f17.f64));
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f18,f18,f4,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f16.f64));
	// fadds f16,f22,f17
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f22,40(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f22,f20,f21
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfs f22,48(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fadds f22,f21,f20
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfs f21,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f21.f64 = double(temp.f32);
	// stfs f22,52(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f20,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f20.f64 = double(temp.f32);
	// fadds f22,f20,f21
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// lfs f20,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f17,f20
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f16,152(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,80(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f20,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f17,f20
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f20,56(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f20,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f17,f20
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f16,88(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f20,120(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f20,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f20,f20,f5
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f5.f64));
	// stfs f20,108(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmr f20,f17
	ctx.f20.f64 = ctx.f17.f64;
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f20
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f17,72(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f16,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f16,f3,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 + ctx.f15.f64));
	// fmsubs f16,f16,f2,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f2.f64 - ctx.f14.f64));
	// stfs f16,156(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r8,124
	ctx.r11.s64 = ctx.r8.s64 * 124;
	// lfs f16,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f16.f64 = double(temp.f32);
	// mulli r10,r9,124
	ctx.r10.s64 = ctx.r9.s64 * 124;
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,72(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,68(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f16,f4
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// fmadds f16,f20,f4,f14
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f4.f64 + ctx.f14.f64));
	// stfs f16,140(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f22
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f16,76(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f16,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,216(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,28(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f22,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f22.f64 = double(temp.f32);
	// rlwinm r31,r8,6,0,25
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 6) & 0xFFFFFFC0;
	// fmsubs f20,f20,f5,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f5.f64 - ctx.f15.f64));
	// stfs f20,128(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f15.f64 = double(temp.f32);
	// mulli r30,r8,60
	ctx.r30.s64 = ctx.r8.s64 * 60;
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// lfs f20,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f20.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f22,240(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fsubs f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// lfs f22,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f22.f64 = double(temp.f32);
	// stfs f20,136(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// lfs f20,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f20.f64 = double(temp.f32);
	// rlwinm r29,r9,6,0,25
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 6) & 0xFFFFFFC0;
	// fadds f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f21,152(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// mulli r28,r9,60
	ctx.r28.s64 = ctx.r9.s64 * 60;
	// lfs f21,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f21.f64 = double(temp.f32);
	// stfs f20,100(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// mulli r27,r8,96
	ctx.r27.s64 = ctx.r8.s64 * 96;
	// mulli r26,r8,28
	ctx.r26.s64 = ctx.r8.s64 * 28;
	// mulli r25,r9,96
	ctx.r25.s64 = ctx.r9.s64 * 96;
	// lfs f20,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f14,f20,f3
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// fmuls f20,f20,f2
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f2.f64));
	// stfs f20,68(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f15,108(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// mulli r24,r9,28
	ctx.r24.s64 = ctx.r9.s64 * 28;
	// fsubs f20,f19,f15
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f19,f15,f2,f14
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f2.f64 - ctx.f14.f64));
	// mulli r23,r8,92
	ctx.r23.s64 = ctx.r8.s64 * 92;
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f15,f3,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f3.f64 + ctx.f14.f64));
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfs f14,208(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// rlwinm r22,r8,5,0,26
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// stfs f23,136(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// mulli r21,r9,92
	ctx.r21.s64 = ctx.r9.s64 * 92;
	// fsubs f14,f22,f23
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// stfs f23,108(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fsubs f22,f20,f21
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// fsubs f20,f19,f17
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f20,128(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f20,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f20.f64 = double(temp.f32);
	// fadds f23,f19,f17
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfs f22,156(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmr f22,f20
	ctx.f22.f64 = ctx.f20.f64;
	// rlwinm r20,r9,5,0,26
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f20,f15,f22
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f20,140(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f22,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f22,f16
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// fadds f19,f16,f22
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// lfs f22,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f17,f22,f18
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// lfs f18,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfsx f18,r11,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f18,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r8,100
	ctx.r11.s64 = ctx.r8.s64 * 100;
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f23,0(r5)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lfs f23,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfsx f18,r10,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// mulli r10,r8,24
	ctx.r10.s64 = ctx.r8.s64 * 24;
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f23,0(r6)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f23,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfsx f18,r31,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfsx f23,r30,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfsx f18,r29,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// lfs f18,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f18.f64 = double(temp.f32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfsx f23,r28,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// stfsx f14,r27,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f14,r26,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// stfsx f20,r25,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// stfsx f19,r24,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// stfsx f17,r23,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// stfsx f22,r22,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r5.u32, temp.u32);
	// lfs f22,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f14,r21,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r6.u32, temp.u32);
	// fsubs f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfsx f21,r20,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r6.u32, temp.u32);
	// lfs f21,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// lfs f20,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// lfs f19,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// fmuls f17,f18,f31
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f31.f64));
	// lfs f19,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f18,f1
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// fmuls f16,f19,f1
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// mulli r31,r9,100
	ctx.r31.s64 = ctx.r9.s64 * 100;
	// fmuls f15,f19,f31
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f31.f64));
	// lfs f19,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f1,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f1.f64 + ctx.f17.f64));
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// mulli r30,r9,24
	ctx.r30.s64 = ctx.r9.s64 * 24;
	// fmsubs f18,f17,f31,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f31.f64 - ctx.f16.f64));
	// lfs f16,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f17,f1,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f1.f64 + ctx.f15.f64));
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,140(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f15,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f15,f15,f31,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f31.f64 - ctx.f14.f64));
	// stfs f15,104(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f14,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,168(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,176(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f14,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,148(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f15,f23,f27
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f27.f64));
	// fmuls f23,f23,f28
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// stfs f23,84(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmuls f14,f20,f28
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f28.f64));
	// fmuls f20,f20,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f27.f64));
	// stfs f20,116(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmadds f23,f22,f28,f15
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 + ctx.f15.f64));
	// fmsubs f20,f21,f27,f14
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f27.f64 - ctx.f14.f64));
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f29
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f29.f64));
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f22,f22,f27,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f27.f64 - ctx.f15.f64));
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f21,f21,f28,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f28.f64 + ctx.f15.f64));
	// stfs f21,124(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f21,f19,f18
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f21,172(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fadds f21,f18,f19
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f21,128(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f21,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f16,f29
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f29.f64));
	// fsubs f19,f21,f17
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// stfs f19,244(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f19,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f19.f64 = double(temp.f32);
	// fadds f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// fmuls f19,f19,f29
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f29.f64));
	// lfs f15,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f29
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f29.f64));
	// lfs f17,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f18,f17,f30,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 + ctx.f18.f64));
	// lfs f17,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f19,f16,f30,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f30.f64 - ctx.f19.f64));
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f30,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64 - ctx.f14.f64));
	// fmadds f17,f17,f30,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 + ctx.f15.f64));
	// fadds f15,f20,f23
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,148(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f22,176(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f22,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,124(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f14,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f20,f23
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,168(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f14,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// lfs f23,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f14,r11,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r8,88
	ctx.r11.s64 = ctx.r8.s64 * 88;
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfsx f15,r10,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r8,36
	ctx.r10.s64 = ctx.r8.s64 * 36;
	// lfs f15,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfsx f14,r31,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f14,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfsx f22,r30,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f14,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f22,172(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f14,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f22,76(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f22,84(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f15,r11,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// mulli r11,r9,88
	ctx.r11.s64 = ctx.r9.s64 * 88;
	// lfs f22,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// fmuls f14,f15,f26
	ctx.f14.f64 = double(float(ctx.f15.f64 * ctx.f26.f64));
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f23,124(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f23,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfs f23,148(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fadds f23,f17,f19
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f23,116(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fadds f23,f16,f18
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f23,104(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f23,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f23.f64 = double(temp.f32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// lfs f23,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfs f23,68(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fsubs f23,f18,f16
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f23,72(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fsubs f23,f19,f17
	ctx.f23.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f23,108(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f21,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfs f23,156(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f21,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// stfs f23,152(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f23,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f23.f64 = double(temp.f32);
	// lfs f21,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f21.f64 = double(temp.f32);
	// stfs f22,208(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// lfs f22,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f22.f64 = double(temp.f32);
	// stfs f23,216(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fmuls f22,f22,f25
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f25.f64));
	// lfs f23,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f23.f64 = double(temp.f32);
	// mulli r31,r9,36
	ctx.r31.s64 = ctx.r9.s64 * 36;
	// fmadds f23,f23,f26,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 + ctx.f22.f64));
	// stfs f23,212(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f23,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f23.f64 = double(temp.f32);
	// rlwinm r30,r8,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmsubs f23,f23,f25,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f25.f64 - ctx.f14.f64));
	// stfs f23,240(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f22,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// stfsx f23,r10,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// mulli r10,r8,120
	ctx.r10.s64 = ctx.r8.s64 * 120;
	// fmuls f18,f22,f23
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// lfs f22,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f22,f23
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// lfs f19,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f19,f21
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// fmuls f14,f19,f22
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f22.f64));
	// lfs f19,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f20,f19
	ctx.f19.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfsx f19,r11,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f19,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfsx f20,r31,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f20,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f20.f64 = double(temp.f32);
	// mulli r29,r9,120
	ctx.r29.s64 = ctx.r9.s64 * 120;
	// lfs f19,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f20
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfsx f19,r10,r5
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f19,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// stfsx f20,r30,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// lfs f20,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f19,f20,f15
	ctx.f19.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// stfsx f19,r29,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// mulli r27,r8,68
	ctx.r27.s64 = ctx.r8.s64 * 68;
	// lfs f19,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f20,r28,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f20,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f15,f20,f19
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfsx f15,r27,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// mulli r26,r8,56
	ctx.r26.s64 = ctx.r8.s64 * 56;
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f19,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f20,r26,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// lfs f20,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f20.f64 = double(temp.f32);
	// mulli r11,r9,68
	ctx.r11.s64 = ctx.r9.s64 * 68;
	// fsubs f15,f20,f19
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fadds f19,f19,f20
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f20,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f20.f64 = double(temp.f32);
	// stfsx f15,r11,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f15,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f15,116(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f15,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r9,56
	ctx.r11.s64 = ctx.r9.s64 * 56;
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,200(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f20,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f20,f15
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// stfs f15,156(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,232(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f20,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfsx f19,r11,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f15,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// fmsubs f19,f19,f24,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f24.f64 - ctx.f18.f64));
	// lfs f18,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r8,108
	ctx.r11.s64 = ctx.r8.s64 * 108;
	// fmadds f18,f18,f24,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f24.f64 + ctx.f17.f64));
	// lfs f17,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f16,f17,f22,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f22.f64 + ctx.f16.f64));
	// stfs f16,220(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fmsubs f17,f17,f21,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f21.f64 - ctx.f14.f64));
	// stfs f17,228(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f16,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r10,r8,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f17,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,104(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f16,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f17.f64 = double(temp.f32);
	// mulli r31,r9,108
	ctx.r31.s64 = ctx.r9.s64 * 108;
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,196(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f16,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f16,f26
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f26.f64));
	// lfs f14,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,68(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f17,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f26
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f26.f64));
	// lfs f14,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r30,r9,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,108(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f16,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f16.f64 = double(temp.f32);
	// mulli r29,r8,80
	ctx.r29.s64 = ctx.r8.s64 * 80;
	// fmadds f17,f16,f25,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f25.f64 + ctx.f17.f64));
	// stfs f17,72(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f16,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f16.f64 = double(temp.f32);
	// mulli r28,r8,44
	ctx.r28.s64 = ctx.r8.s64 * 44;
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f14,116(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,152(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f17,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f25,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f25.f64 - ctx.f15.f64));
	// stfs f17,144(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// mulli r27,r9,80
	ctx.r27.s64 = ctx.r9.s64 * 80;
	// mulli r26,r9,44
	ctx.r26.s64 = ctx.r9.s64 * 44;
	// mulli r25,r8,112
	ctx.r25.s64 = ctx.r8.s64 * 112;
	// mulli r24,r8,12
	ctx.r24.s64 = ctx.r8.s64 * 12;
	// lfs f17,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f17,f22
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f22.f64));
	// lfs f17,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f17,f22
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f22.f64));
	// lfs f22,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f24
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f24.f64));
	// fmuls f22,f22,f23
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// stfs f22,84(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// mulli r23,r9,112
	ctx.r23.s64 = ctx.r9.s64 * 112;
	// fmsubs f22,f17,f21,f16
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f21.f64 - ctx.f16.f64));
	// lfs f17,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f21,f17,f21,f15
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f21.f64 + ctx.f15.f64));
	// lfs f15,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f15.f64 = double(temp.f32);
	// mulli r22,r9,12
	ctx.r22.s64 = ctx.r9.s64 * 12;
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f16,164(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f16,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fmadds f16,f15,f23,f14
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f23.f64 + ctx.f14.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f23,f15,f24,f14
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f24.f64 - ctx.f14.f64));
	// lfs f14,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// stfs f14,84(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f14,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,104(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f22,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,144(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfs f14,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fadds f14,f23,f18
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fsubs f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// lfs f14,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// fsubs f14,f23,f15
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfsx f14,r11,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// stfsx f23,r10,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f23.f64 = double(temp.f32);
	// mulli r11,r8,76
	ctx.r11.s64 = ctx.r8.s64 * 76;
	// fsubs f15,f23,f21
	ctx.f15.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// mulli r10,r8,48
	ctx.r10.s64 = ctx.r8.s64 * 48;
	// fadds f21,f21,f23
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// lfs f23,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfsx f14,r31,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// stfsx f23,r30,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// stfsx f15,r29,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f21,r28,r5
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fsubs f15,f23,f22
	ctx.f15.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f21,f22,f23
	ctx.f21.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfsx f15,r27,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fadds f23,f16,f19
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// lfs f22,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f21,r26,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// fsubs f15,f22,f23
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfsx f15,r25,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fadds f21,f23,f22
	ctx.f21.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// lfs f23,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f21,r24,r5
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// lfs f21,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f15,f22,f23
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfsx f15,r23,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// stfsx f23,r22,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f22,f17,f18
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfs f23,84(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// stfs f23,144(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f21,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// stfs f23,116(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f21,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// stfs f23,164(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// stfsx f22,r11,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f22,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f23,f22
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// lfs f23,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f23,f22
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// lfs f21,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfs f23,204(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f23,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f23.f64 = double(temp.f32);
	// lfs f21,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f21.f64 = double(temp.f32);
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// stfs f23,104(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f21,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// lfs f23,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f23.f64 = double(temp.f32);
	// mulli r11,r9,76
	ctx.r11.s64 = ctx.r9.s64 * 76;
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// stfs f23,180(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f23,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f23.f64 = double(temp.f32);
	// mulli r31,r9,48
	ctx.r31.s64 = ctx.r9.s64 * 48;
	// lfs f21,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfs f23,60(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// stfs f23,112(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f21,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f15,f21,f23,f15
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f23.f64 + ctx.f15.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f15,f15,f23,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f23.f64 + ctx.f14.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f23.f64));
	// fmuls f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 * ctx.f23.f64));
	// stfs f19,24(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f19,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfs f20,236(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f19,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// stfs f20,92(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f20,f20,f22,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f22.f64 - ctx.f15.f64));
	// stfs f20,68(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fmsubs f23,f21,f22,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f22.f64 - ctx.f23.f64));
	// stfs f23,72(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f22,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f22.f64 = double(temp.f32);
	// fadds f23,f18,f17
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f21,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f23,r10,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fmuls f19,f21,f22
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f22.f64));
	// lfs f23,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f21,f23
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f23.f64));
	// fmuls f18,f20,f23
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// lfs f21,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f21.f64 = double(temp.f32);
	// fadds f16,f16,f21
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// lfs f20,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f20.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f14,f20,f23
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// lfs f16,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f23,f16,f23,f19
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f23.f64 + ctx.f19.f64));
	// stfs f23,184(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fmsubs f23,f20,f22,f18
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f22.f64 - ctx.f18.f64));
	// stfs f23,36(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f22,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f20,f22
	ctx.f19.f64 = double(float(ctx.f20.f64 * ctx.f22.f64));
	// fmuls f18,f20,f23
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// lfs f20,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f20,f22
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f22.f64));
	// lfs f20,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// stfs f20,132(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f20,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f20,f22
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f22.f64));
	// lfs f20,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,160(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f20,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfs f20,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f23,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f23.f64 + ctx.f19.f64));
	// stfs f20,20(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f19,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f19.f64 = double(temp.f32);
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f20,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f20,f20,f19,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64 - ctx.f17.f64));
	// lfs f19,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f19
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// stfsx f17,r11,r6
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r8,116
	ctx.r11.s64 = ctx.r8.s64 * 116;
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfsx f19,r31,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f19,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f19,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f17,24(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f17,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// lfs f17,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f22,f17,f22,f18
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f22.f64 - ctx.f18.f64));
	// lfs f18,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f18,f18,f23,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f23.f64 + ctx.f16.f64));
	// fmsubs f23,f17,f23,f15
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f23.f64 - ctx.f15.f64));
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// mulli r31,r9,116
	ctx.r31.s64 = ctx.r9.s64 * 116;
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,92(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f15,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,272(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,264(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fadds f15,f16,f20
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f15,236(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fsubs f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f18,f15
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f15,104(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fadds f15,f21,f19
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// stfs f15,116(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,68(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// lfs f14,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// lfs f19,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f14,f22,f23
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// stfs f23,108(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f22,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// lfs f23,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f17,f22,f23
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfsx f17,r11,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// stfsx f23,r10,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f22,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f22.f64 = double(temp.f32);
	// mulli r30,r8,72
	ctx.r30.s64 = ctx.r8.s64 * 72;
	// lfs f23,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f23.f64 = double(temp.f32);
	// mulli r10,r8,52
	ctx.r10.s64 = ctx.r8.s64 * 52;
	// fsubs f17,f23,f22
	ctx.f17.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfsx f17,r31,r6
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfsx f23,r11,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f22.f64 = double(temp.f32);
	// fadds f17,f22,f23
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f22,f22,f23
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// fsubs f23,f15,f20
	ctx.f23.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfsx f23,r30,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f20,f15
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfsx f23,r10,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f23.f64 = double(temp.f32);
	// mulli r29,r9,72
	ctx.r29.s64 = ctx.r9.s64 * 72;
	// fsubs f20,f23,f16
	ctx.f20.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// fadds f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// stfsx f20,r29,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// mulli r28,r9,52
	ctx.r28.s64 = ctx.r9.s64 * 52;
	// stfsx f23,r28,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f23.f64 = double(temp.f32);
	// mulli r27,r8,84
	ctx.r27.s64 = ctx.r8.s64 * 84;
	// fsubs f20,f23,f18
	ctx.f20.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// stfsx f20,r27,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fsubs f20,f14,f21
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// mulli r11,r8,40
	ctx.r11.s64 = ctx.r8.s64 * 40;
	// stfsx f23,r11,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// mulli r11,r9,84
	ctx.r11.s64 = ctx.r9.s64 * 84;
	// fsubs f18,f19,f23
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f23.f64));
	// fadds f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// fneg f19,f17
	ctx.f19.u64 = ctx.f17.u64 ^ 0x8000000000000000;
	// stfsx f20,r11,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// mulli r11,r9,40
	ctx.r11.s64 = ctx.r9.s64 * 40;
	// stfsx f21,r11,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// mulli r11,r8,104
	ctx.r11.s64 = ctx.r8.s64 * 104;
	// stfsx f18,r11,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// mulli r11,r8,20
	ctx.r11.s64 = ctx.r8.s64 * 20;
	// stfsx f23,r11,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// mulli r11,r9,20
	ctx.r11.s64 = ctx.r9.s64 * 20;
	// stfsx f19,r11,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// mulli r11,r9,104
	ctx.r11.s64 = ctx.r9.s64 * 104;
	// stfsx f22,r11,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,332(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// add r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
	// add r4,r11,r4
	ctx.r4.u64 = ctx.r11.u64 + ctx.r4.u64;
	// lwz r11,340(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// add r5,r11,r5
	ctx.r5.u64 = ctx.r11.u64 + ctx.r5.u64;
	// add r6,r11,r6
	ctx.r6.u64 = ctx.r11.u64 + ctx.r6.u64;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lwz r11,3532(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 3532);
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d4be6c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D4BE6C;
loc_82D4D770:
	// addi r1,r1,640
	ctx.r1.s64 = ctx.r1.s64 + 640;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D4D77C;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4D780"))) PPC_WEAK_FUNC(sub_82D4D780);
PPC_FUNC_IMPL(__imp__sub_82D4D780) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-2248
	ctx.r5.s64 = ctx.r11.s64 + -2248;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-17216
	ctx.r4.s64 = ctx.r11.s64 + -17216;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4D798"))) PPC_WEAK_FUNC(sub_82D4D798);
PPC_FUNC_IMPL(__imp__sub_82D4D798) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e38
	ctx.lr = 0x82D4D7A0;
	__savegprlr_16(ctx, base);
	// addi r12,r1,-136
	ctx.r12.s64 = ctx.r1.s64 + -136;
	// bl 0x82e28ee0
	ctx.lr = 0x82D4D7A8;
	__savefpr_14(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d4e094
	if (!ctx.cr6.gt) goto loc_82D4E094;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// rlwinm r17,r11,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// rlwinm r16,r11,2,0,29
	ctx.r16.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f31,-5440(r19)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -5440);
	ctx.f31.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f1,-5436(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -5436);
	ctx.f1.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f2,-5432(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -5432);
	ctx.f2.f64 = double(temp.f32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f3,-5428(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -5428);
	ctx.f3.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f4,-5444(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -5444);
	ctx.f4.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f5,-5448(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -5448);
	ctx.f5.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f6,-5424(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -5424);
	ctx.f6.f64 = double(temp.f32);
	// lis r31,-32236
	ctx.r31.s64 = -2112618496;
	// lfs f7,-5420(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -5420);
	ctx.f7.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f8,-8004(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -8004);
	ctx.f8.f64 = double(temp.f32);
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f9,-8000(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8000);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-8008(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -8008);
	ctx.f10.f64 = double(temp.f32);
	// lis r18,-32234
	ctx.r18.s64 = -2112487424;
	// lfs f11,-8012(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8012);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-8016(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8016);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f12.f64 = double(temp.f32);
loc_82D4D840:
	// mulli r11,r7,20
	ctx.r11.s64 = ctx.r7.s64 * 20;
	// lfs f30,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// mulli r10,r7,52
	ctx.r10.s64 = ctx.r7.s64 * 52;
	// lfsx f29,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f28,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f17,f29,f28
	ctx.f17.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fadds f16,f28,f29
	ctx.f16.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// rlwinm r31,r7,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r30,r7,48
	ctx.r30.s64 = ctx.r7.s64 * 48;
	// lfsx f27,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f26,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f15,f27,f26
	ctx.f15.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// rlwinm r29,r7,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f28,f17,f12
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmuls f17,f16,f12
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// mulli r28,r7,40
	ctx.r28.s64 = ctx.r7.s64 * 40;
	// fadds f16,f26,f27
	ctx.f16.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// lfsx f25,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f26,f25,f13
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// stfs f26,-308(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfsx f24,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f24,f13
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// mulli r26,r7,56
	ctx.r26.s64 = ctx.r7.s64 * 56;
	// fmuls f26,f15,f12
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfsx f22,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r27,r7,24
	ctx.r27.s64 = ctx.r7.s64 * 24;
	// fmsubs f25,f25,f0,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 - ctx.f14.f64));
	// fmuls f14,f22,f13
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfsx f23,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// rlwinm r25,r7,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r24,r7,36
	ctx.r24.s64 = ctx.r7.s64 * 36;
	// lfsx f21,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f20,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// rlwinm r23,r7,5,0,26
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// mulli r20,r7,12
	ctx.r20.s64 = ctx.r7.s64 * 12;
	// lfsx f19,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f27,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// mulli r22,r7,60
	ctx.r22.s64 = ctx.r7.s64 * 60;
	// lfsx f18,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r21,r7,28
	ctx.r21.s64 = ctx.r7.s64 * 28;
	// lfs f15,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f24,f24,f0,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 + ctx.f15.f64));
	// lfsx f29,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f15,f22,f0
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// mulli r19,r7,44
	ctx.r19.s64 = ctx.r7.s64 * 44;
	// fmsubs f22,f23,f13,f15
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f15.f64));
	// fmadds f23,f23,f0,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f14.f64));
	// fadds f15,f28,f21
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f21.f64));
	// fsubs f28,f21,f28
	ctx.f28.f64 = double(float(ctx.f21.f64 - ctx.f28.f64));
	// fadds f14,f17,f20
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fadds f21,f26,f30
	ctx.f21.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// fsubs f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// fsubs f26,f19,f16
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// fadds f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// fadds f17,f22,f25
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// fsubs f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// fsubs f22,f24,f23
	ctx.f22.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f24,-328(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fmuls f16,f28,f8
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// fmuls f24,f14,f10
	ctx.f24.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// fmuls f28,f28,f9
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f9.f64));
	// fmuls f23,f15,f10
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// fmsubs f24,f15,f11,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 - ctx.f24.f64));
	// stfs f24,-332(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fmadds f28,f20,f8,f28
	ctx.f28.f64 = double(float(ctx.f20.f64 * ctx.f8.f64 + ctx.f28.f64));
	// stfs f28,-320(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fmadds f24,f14,f11,f23
	ctx.f24.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 + ctx.f23.f64));
	// lfsx f28,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f24,-336(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fmsubs f24,f20,f9,f16
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 - ctx.f16.f64));
	// stfs f28,-344(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfsx f20,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f16,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f28,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f24,-308(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// stfs f20,-312(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// stfs f16,-316(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// stfs f28,-324(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfsx f15,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// stfs f15,-368(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// lfsx f15,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-356(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfsx f15,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-364(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfsx f24,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// stfs f24,-376(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfsx f15,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-340(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfsx f24,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// stfs f24,-380(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfsx f28,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f15,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f28,f13
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfsx f23,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// stfs f15,-360(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fmuls f15,f28,f0
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// lfsx f24,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f28,f24,f23
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfs f23,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f23.f64 = double(temp.f32);
	// stfs f28,-312(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fmsubs f28,f23,f0,f16
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 - ctx.f16.f64));
	// lfs f23,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f23.f64 = double(temp.f32);
	// stfs f24,-316(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fmadds f24,f23,f0,f20
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f20.f64));
	// lfs f20,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f23,f20,f13,f15
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f15.f64));
	// fmadds f20,f20,f0,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f14.f64));
	// stfs f20,-384(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f16,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f16,f12
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// stfs f20,-348(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f16,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f16,f12
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// stfs f20,-352(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f20,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f16,f27,f20
	ctx.f16.f64 = double(float(ctx.f27.f64 - ctx.f20.f64));
	// fadds f15,f20,f27
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// lfs f27,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f27.f64 = double(temp.f32);
	// lfs f20,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f14,f27,f20
	ctx.f14.f64 = double(float(ctx.f27.f64 - ctx.f20.f64));
	// fadds f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// stfs f27,-312(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fmuls f27,f16,f12
	ctx.f27.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fmuls f20,f15,f12
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fmuls f16,f14,f12
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// fadds f14,f23,f28
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// fsubs f28,f23,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 - ctx.f28.f64));
	// lfs f23,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f24
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfs f15,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f15.f64 = double(temp.f32);
	// stfs f23,-312(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fmuls f15,f15,f12
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfs f23,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fsubs f23,f27,f18
	ctx.f23.f64 = double(float(ctx.f27.f64 - ctx.f18.f64));
	// stfs f23,-372(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// fadds f23,f20,f29
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f29.f64));
	// fsubs f29,f29,f20
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f20.f64));
	// lfs f20,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f20.f64 = double(temp.f32);
	// fadds f27,f27,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f18.f64));
	// fsubs f18,f16,f20
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// stfs f18,-384(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f18,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f20,-344(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f18,-376(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f18,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// stfs f18,-380(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fmuls f16,f23,f11
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// fmuls f15,f27,f8
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// fmuls f27,f27,f9
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// lfs f20,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f20,f11
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// lfs f20,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f20.f64 = double(temp.f32);
	// stfs f27,-316(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fadds f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// stfs f20,-360(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fmadds f23,f23,f10,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 + ctx.f18.f64));
	// lfs f20,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f15,f29,f9,f15
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 - ctx.f15.f64));
	// fsubs f27,f20,f14
	ctx.f27.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// lfs f20,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f20,f28,f20
	ctx.f20.f64 = double(float(ctx.f28.f64 - ctx.f20.f64));
	// fadds f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// lfs f18,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f10,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64 - ctx.f16.f64));
	// lfs f16,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f16.f64 = double(temp.f32);
	// stfs f18,-340(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// rlwinm r11,r8,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// stfs f15,-312(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// rlwinm r10,r9,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f18,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f18.f64 = double(temp.f32);
	// mulli r31,r8,28
	ctx.r31.s64 = ctx.r8.s64 * 28;
	// lfs f15,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,-324(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f14,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f14.f64 = double(temp.f32);
	// mulli r30,r9,28
	ctx.r30.s64 = ctx.r9.s64 * 28;
	// mulli r29,r8,60
	ctx.r29.s64 = ctx.r8.s64 * 60;
	// mulli r28,r9,60
	ctx.r28.s64 = ctx.r9.s64 * 60;
	// lfs f15,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f29,f29,f8,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 + ctx.f15.f64));
	// stfs f29,-316(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f29,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f29.f64 = double(temp.f32);
	// fadds f16,f24,f29
	ctx.f16.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// stfs f16,-292(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fsubs f29,f24,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// stfs f29,-344(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfsx f29,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-304(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfsx f29,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-384(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f29,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f24,f29,f13
	ctx.f24.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// lfs f29,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f16,f29,f13
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// lfs f29,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// lfs f15,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f29
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f29.f64));
	// stfs f15,-372(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f15,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-376(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f15,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f24,f15,f0,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 - ctx.f24.f64));
	// stfs f24,-300(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f24,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f15,f18,f6
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f6.f64));
	// fmadds f24,f24,f0,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 + ctx.f16.f64));
	// stfs f24,-296(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f24,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f24,f6
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// lfs f24,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f24,-364(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f16,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f16.f64 = double(temp.f32);
	// lfs f24,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// lfs f16,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f19
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfs f16,-368(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f16,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f7,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f7.f64 - ctx.f15.f64));
	// stfs f16,-380(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f15,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f18,f18,f7,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f7.f64 + ctx.f14.f64));
	// stfs f18,-360(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f29,f29,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f15.f64));
	// lfs f18,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f18,f0
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// lfs f15,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f15.f64 = double(temp.f32);
	// stfs f18,-304(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fmsubs f18,f15,f13,f14
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 - ctx.f14.f64));
	// lfs f14,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f15,f0,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 + ctx.f14.f64));
	// stfs f15,-348(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fadds f15,f17,f21
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// lfs f14,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f14,-384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f14,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f24
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// stfs f14,-304(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f14,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// lfs f14,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f14.f64 = double(temp.f32);
	// stfs f24,-368(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fadds f24,f18,f14
	ctx.f24.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,-352(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f18,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,-356(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfs f14,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// lfs f14,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f24,f14
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// stfs f14,-296(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f14,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// stfs f24,-364(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f14,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f14.f64 = double(temp.f32);
	// lfs f24,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// lfs f14,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,-288(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f14,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,-352(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f14,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,-372(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// fsubs f16,f29,f18
	ctx.f16.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// stfs f16,-376(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fadds f29,f18,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// lfs f18,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f24,f6
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmuls f14,f24,f7
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// fmadds f24,f18,f7,f16
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f7.f64 + ctx.f16.f64));
	// lfs f16,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f18,f18,f6,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f6.f64 - ctx.f14.f64));
	// lfs f14,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f24
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// fsubs f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfs f14,-348(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f14,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// lfs f14,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// stfs f24,-356(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfs f24,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// stfsx f24,r11,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f24,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f24.f64 = double(temp.f32);
	// lfs f14,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f24
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// stfsx f14,r10,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfsx f16,r31,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lfs f16,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f16.f64 = double(temp.f32);
	// fadds f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// stfsx f24,r30,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f24,f15,f18
	ctx.f24.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfsx f24,r29,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// lfs f16,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// lfs f24,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f24.f64 = double(temp.f32);
	// mulli r11,r8,56
	ctx.r11.s64 = ctx.r8.s64 * 56;
	// fsubs f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 - ctx.f24.f64));
	// lfs f16,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f5
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f5.f64));
	// stfsx f24,r28,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f24,f18,f15
	ctx.f24.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f24,0(r5)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fmuls f15,f29,f5
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f5.f64));
	// lfs f14,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f18,f28,f5
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f5.f64));
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f24,f29,f4
	ctx.f24.f64 = double(float(ctx.f29.f64 * ctx.f4.f64));
	// lfs f29,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f14.f64));
	// lfs f14,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r9,56
	ctx.r10.s64 = ctx.r9.s64 * 56;
	// fmadds f28,f28,f4,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f4.f64 + ctx.f16.f64));
	// stfs f28,-300(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f28,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f28,f4,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f4.f64 - ctx.f15.f64));
	// stfs f28,-348(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f28,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f28.f64 = double(temp.f32);
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f16,f28,f2
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f2.f64));
	// lfs f28,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f2
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f2.f64));
	// lfs f28,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f2
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f2.f64));
	// stfs f28,-296(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fmadds f24,f14,f5,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 * ctx.f5.f64 + ctx.f24.f64));
	// lfs f14,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f18,f14,f4,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f4.f64 - ctx.f18.f64));
	// stfs f18,-344(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f14,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f14.f64 = double(temp.f32);
	// rlwinm r30,r9,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f18,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f18.f64 = double(temp.f32);
	// mulli r29,r8,36
	ctx.r29.s64 = ctx.r8.s64 * 36;
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f21,-352(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fmuls f14,f27,f2
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// lfs f21,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f21.f64 = double(temp.f32);
	// fadds f28,f21,f17
	ctx.f28.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// lfs f21,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f21.f64 = double(temp.f32);
	// lfs f17,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// lfs f21,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f27,f27,f3,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64 - ctx.f15.f64));
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// lfs f19,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f3,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64 + ctx.f16.f64));
	// lfs f15,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f16.f64 = double(temp.f32);
	// mulli r28,r9,36
	ctx.r28.s64 = ctx.r9.s64 * 36;
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,0(r6)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f16,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f17,f3,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 + ctx.f14.f64));
	// fadds f14,f22,f30
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// mulli r27,r8,24
	ctx.r27.s64 = ctx.r8.s64 * 24;
	// mulli r26,r9,24
	ctx.r26.s64 = ctx.r9.s64 * 24;
	// lfs f15,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f16,f16,f3,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 - ctx.f15.f64));
	// fadds f15,f29,f14
	ctx.f15.f64 = double(float(ctx.f29.f64 + ctx.f14.f64));
	// fsubs f29,f14,f29
	ctx.f29.f64 = double(float(ctx.f14.f64 - ctx.f29.f64));
	// lfs f14,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f24
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// stfs f14,-304(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f14,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// fadds f14,f25,f26
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f14,-296(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,-328(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f14,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,-296(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f18,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,-324(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f14,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// lfs f14,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f28,f14
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// stfs f14,-300(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f14,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f14.f64 = double(temp.f32);
	// mulli r25,r9,52
	ctx.r25.s64 = ctx.r9.s64 * 52;
	// fsubs f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// lfs f22,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f23,f21
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fadds f21,f27,f19
	ctx.f21.f64 = double(float(ctx.f27.f64 + ctx.f19.f64));
	// stfs f21,-332(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f27,f27,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f19.f64));
	// stfs f27,-340(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fsubs f27,f17,f16
	ctx.f27.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f27,-336(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f27,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f21,f15,f27
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// stfsx f21,r11,r5
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f21,f27,f15
	ctx.f21.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// lfs f27,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f19,f24,f27
	ctx.f19.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// mulli r11,r8,48
	ctx.r11.s64 = ctx.r8.s64 * 48;
	// fadds f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// lfs f27,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f27.f64 = double(temp.f32);
	// lfs f15,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f27
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// stfsx f15,r10,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// stfsx f21,r31,r5
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// mulli r10,r9,48
	ctx.r10.s64 = ctx.r9.s64 * 48;
	// lfs f21,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f21.f64 = double(temp.f32);
	// fadds f27,f21,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// stfsx f27,r30,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f27,f29,f18
	ctx.f27.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// stfsx f27,r29,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f18,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// stfsx f19,r28,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f27,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f27.f64 = double(temp.f32);
	// stfsx f29,r27,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fmuls f15,f27,f1
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// stfsx f24,r26,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// fmuls f24,f27,f31
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// lfs f29,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f29.f64 = double(temp.f32);
	// mulli r31,r8,12
	ctx.r31.s64 = ctx.r8.s64 * 12;
	// fmuls f21,f29,f31
	ctx.f21.f64 = double(float(ctx.f29.f64 * ctx.f31.f64));
	// lfs f27,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f29,f1
	ctx.f18.f64 = double(float(ctx.f29.f64 * ctx.f1.f64));
	// lfs f19,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f29,f25,f26
	ctx.f29.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// lfs f26,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f26.f64 = double(temp.f32);
	// fadds f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// mulli r30,r8,44
	ctx.r30.s64 = ctx.r8.s64 * 44;
	// fmadds f26,f19,f1,f24
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f1.f64 + ctx.f24.f64));
	// lfs f24,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fmadds f25,f20,f1,f21
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f1.f64 + ctx.f21.f64));
	// fmsubs f22,f20,f31,f18
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f31.f64 - ctx.f18.f64));
	// lfs f18,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f18.f64 = double(temp.f32);
	// fadds f21,f16,f17
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f17,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f20,f18,f17
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfsx f20,r11,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f17,f17,f18
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f18,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f20,f19,f31,f15
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f31.f64 - ctx.f15.f64));
	// lfs f19,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f16,f28,f18
	ctx.f16.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// fadds f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// fsubs f15,f19,f14
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// fadds f28,f27,f29
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// fsubs f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// mulli r29,r9,44
	ctx.r29.s64 = ctx.r9.s64 * 44;
	// rlwinm r28,r8,4,0,27
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r27,r9,4,0,27
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r26,r8,52
	ctx.r26.s64 = ctx.r8.s64 * 52;
	// fadds f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// rlwinm r24,r8,3,0,28
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// rlwinm r23,r9,3,0,28
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f25,f24,f30
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// mulli r22,r8,40
	ctx.r22.s64 = ctx.r8.s64 * 40;
	// fsubs f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// fsubs f24,f21,f23
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// stfsx f24,r10,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f24,f20,f22
	ctx.f24.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfsx f17,r31,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfsx f23,r11,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f23,f22,f20
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfsx f16,r30,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// stfsx f15,r29,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// stfsx f18,r28,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// mulli r11,r9,40
	ctx.r11.s64 = ctx.r9.s64 * 40;
	// fadds f22,f27,f28
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// stfsx f19,r27,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fsubs f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfsx f27,r26,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f26,f25
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// fsubs f26,f24,f29
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// stfsx f26,r25,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// stfsx f27,r24,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f24,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// mulli r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 * 20;
	// stfsx f29,r23,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// fsubs f29,f30,f23
	ctx.f29.f64 = double(float(ctx.f30.f64 - ctx.f23.f64));
	// stfsx f29,r22,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r5.u32, temp.u32);
	// stfsx f28,r11,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// fneg f29,f22
	ctx.f29.u64 = ctx.f22.u64 ^ 0x8000000000000000;
	// stfsx f30,r10,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// mulli r31,r9,20
	ctx.r31.s64 = ctx.r9.s64 * 20;
	// stfsx f29,r31,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,3532(r18)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r18.u32 + 3532);
	// add r3,r17,r3
	ctx.r3.u64 = ctx.r17.u64 + ctx.r3.u64;
	// add r4,r17,r4
	ctx.r4.u64 = ctx.r17.u64 + ctx.r4.u64;
	// add r5,r16,r5
	ctx.r5.u64 = ctx.r16.u64 + ctx.r5.u64;
	// add r6,r16,r6
	ctx.r6.u64 = ctx.r16.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d4d840
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D4D840;
loc_82D4E094:
	// addi r12,r1,-136
	ctx.r12.s64 = ctx.r1.s64 + -136;
	// bl 0x82e28f2c
	ctx.lr = 0x82D4E09C;
	__restfpr_14(ctx, base);
	// b 0x82e28e88
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4E0A0"))) PPC_WEAK_FUNC(sub_82D4E0A0);
PPC_FUNC_IMPL(__imp__sub_82D4E0A0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-2136
	ctx.r5.s64 = ctx.r11.s64 + -2136;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-10344
	ctx.r4.s64 = ctx.r11.s64 + -10344;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4E0B8"))) PPC_WEAK_FUNC(sub_82D4E0B8);
PPC_FUNC_IMPL(__imp__sub_82D4E0B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e48
	ctx.lr = 0x82D4E0C0;
	__savegprlr_20(ctx, base);
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82e28ee4
	ctx.lr = 0x82D4E0C8;
	__savefpr_15(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d4e36c
	if (!ctx.cr6.gt) goto loc_82D4E36C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r26,r11,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r25,r11,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f8,-8000(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -8000);
	ctx.f8.f64 = double(temp.f32);
	// lis r31,-32236
	ctx.r31.s64 = -2112618496;
	// lfs f9,-8004(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8004);
	ctx.f9.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f10,-8008(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -8008);
	ctx.f10.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f11,-8012(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8012);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-8016(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D4E120:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f7,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// mulli r10,r7,24
	ctx.r10.s64 = ctx.r7.s64 * 24;
	// lfs f6,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f3,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f2,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f5,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f21,f3,f2
	ctx.f21.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f4,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// mulli r30,r7,20
	ctx.r30.s64 = ctx.r7.s64 * 20;
	// fsubs f22,f5,f4
	ctx.f22.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fadds f20,f2,f3
	ctx.f20.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fadds f4,f4,f5
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// lfsx f1,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f2,f1,f31
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// lfsx f30,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// mulli r28,r7,28
	ctx.r28.s64 = ctx.r7.s64 * 28;
	// lfsx f29,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f3,f21,f0
	ctx.f3.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fmuls f5,f22,f0
	ctx.f5.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmuls f21,f30,f12
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// fmuls f22,f29,f12
	ctx.f22.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// lfsx f26,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f31,f20,f0
	ctx.f31.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmuls f19,f26,f13
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// lfsx f28,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f26,f12
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// mulli r27,r7,12
	ctx.r27.s64 = ctx.r7.s64 * 12;
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmadds f29,f29,f13,f21
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f13.f64 + ctx.f21.f64));
	// lfsx f23,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f30,f30,f13,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 - ctx.f22.f64));
	// lfsx f24,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f22,f5,f7
	ctx.f22.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// rlwinm r29,r7,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// fmsubs f26,f23,f12,f19
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 - ctx.f19.f64));
	// rlwinm r23,r8,4,0,27
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fmadds f23,f23,f13,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f18.f64));
	// mulli r11,r9,28
	ctx.r11.s64 = ctx.r9.s64 * 28;
	// fadds f5,f3,f6
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// fsubs f6,f6,f3
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f3.f64));
	// fsubs f3,f2,f28
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f28.f64));
	// lfsx f27,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f28.f64));
	// fadds f21,f4,f27
	ctx.f21.f64 = double(float(ctx.f4.f64 + ctx.f27.f64));
	// lfsx f25,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f4,f27,f4
	ctx.f4.f64 = double(float(ctx.f27.f64 - ctx.f4.f64));
	// fadds f27,f1,f24
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f24.f64));
	// fsubs f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f1.f64));
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// fadds f24,f31,f25
	ctx.f24.f64 = double(float(ctx.f31.f64 + ctx.f25.f64));
	// fsubs f31,f25,f31
	ctx.f31.f64 = double(float(ctx.f25.f64 - ctx.f31.f64));
	// fadds f25,f23,f29
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// fadds f28,f26,f30
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// fsubs f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// fsubs f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f30.f64));
	// fmuls f26,f22,f10
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// fmuls f17,f7,f8
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// mulli r31,r8,28
	ctx.r31.s64 = ctx.r8.s64 * 28;
	// fmuls f23,f27,f11
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// fmuls f16,f3,f11
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// fmuls f15,f7,f9
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// fadds f19,f25,f24
	ctx.f19.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// fsubs f20,f5,f28
	ctx.f20.f64 = double(float(ctx.f5.f64 - ctx.f28.f64));
	// fmadds f26,f21,f11,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 + ctx.f26.f64));
	// fmuls f21,f21,f10
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// fmsubs f23,f3,f10,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 - ctx.f23.f64));
	// fmadds f3,f4,f9,f17
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 + ctx.f17.f64));
	// fmuls f17,f2,f9
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// fadds f18,f23,f26
	ctx.f18.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fsubs f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// fsubs f23,f20,f18
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfsx f23,r23,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fmuls f23,f2,f8
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// fmadds f23,f1,f9,f23
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f23.f64));
	// fmadds f2,f27,f10,f16
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 + ctx.f16.f64));
	// mulli r30,r9,12
	ctx.r30.s64 = ctx.r9.s64 * 12;
	// fsubs f27,f30,f31
	ctx.f27.f64 = double(float(ctx.f30.f64 - ctx.f31.f64));
	// rlwinm r29,r9,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fmsubs f7,f22,f11,f21
	ctx.f7.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 - ctx.f21.f64));
	// fadds f31,f30,f31
	ctx.f31.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// fadds f30,f26,f19
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// stfsx f30,r11,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f30,f18,f20
	ctx.f30.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfsx f30,r10,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fmsubs f1,f1,f8,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f8.f64 - ctx.f17.f64));
	// fsubs f30,f26,f19
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f19.f64));
	// stfs f30,0(r6)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fmsubs f4,f4,f8,f15
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 - ctx.f15.f64));
	// rlwinm r11,r9,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f5,f28,f5
	ctx.f5.f64 = double(float(ctx.f28.f64 + ctx.f5.f64));
	// mulli r10,r8,24
	ctx.r10.s64 = ctx.r8.s64 * 24;
	// fadds f30,f23,f3
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// fsubs f28,f24,f25
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// fadds f25,f29,f6
	ctx.f25.f64 = double(float(ctx.f29.f64 + ctx.f6.f64));
	// fsubs f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f29.f64));
	// fadds f29,f2,f7
	ctx.f29.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// fsubs f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// fsubs f3,f3,f23
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f23.f64));
	// rlwinm r28,r8,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f2,f1,f4
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// mulli r27,r9,20
	ctx.r27.s64 = ctx.r9.s64 * 20;
	// fadds f4,f4,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fadds f1,f30,f27
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// fsubs f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 - ctx.f30.f64));
	// fsubs f27,f5,f29
	ctx.f27.f64 = double(float(ctx.f5.f64 - ctx.f29.f64));
	// stfsx f27,r31,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f7,f28
	ctx.f27.f64 = double(float(ctx.f7.f64 + ctx.f28.f64));
	// stfsx f27,r30,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f5,f29,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 + ctx.f5.f64));
	// stfs f5,0(r5)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f28.f64));
	// stfsx f7,r11,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// mulli r23,r8,20
	ctx.r23.s64 = ctx.r8.s64 * 20;
	// fsubs f26,f25,f3
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f3.f64));
	// stfsx f26,r10,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f3,f3,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f25.f64));
	// stfsx f30,r29,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fneg f7,f1
	ctx.f7.u64 = ctx.f1.u64 ^ 0x8000000000000000;
	// stfsx f3,r28,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// stfsx f7,r27,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fsubs f7,f6,f2
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f2.f64));
	// stfsx f7,r23,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f4,f31
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f31.f64));
	// rlwinm r22,r9,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r21,r8,3,0,28
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r20,r9,24
	ctx.r20.s64 = ctx.r9.s64 * 24;
	// stfsx f7,r22,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// fadds f7,f2,f6
	ctx.f7.f64 = double(float(ctx.f2.f64 + ctx.f6.f64));
	// stfsx f7,r21,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f4,f31
	ctx.f7.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// stfsx f7,r20,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,3532(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 3532);
	// add r3,r26,r3
	ctx.r3.u64 = ctx.r26.u64 + ctx.r3.u64;
	// add r4,r26,r4
	ctx.r4.u64 = ctx.r26.u64 + ctx.r4.u64;
	// add r5,r25,r5
	ctx.r5.u64 = ctx.r25.u64 + ctx.r5.u64;
	// add r6,r25,r6
	ctx.r6.u64 = ctx.r25.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d4e120
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D4E120;
loc_82D4E36C:
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82e28f30
	ctx.lr = 0x82D4E374;
	__restfpr_15(ctx, base);
	// b 0x82e28e98
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4E378"))) PPC_WEAK_FUNC(sub_82D4E378);
PPC_FUNC_IMPL(__imp__sub_82D4E378) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-2088
	ctx.r5.s64 = ctx.r11.s64 + -2088;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-8008
	ctx.r4.s64 = ctx.r11.s64 + -8008;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4E390"))) PPC_WEAK_FUNC(sub_82D4E390);
PPC_FUNC_IMPL(__imp__sub_82D4E390) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e44
	ctx.lr = 0x82D4E398;
	__savegprlr_19(ctx, base);
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28ee0
	ctx.lr = 0x82D4E3A0;
	__savefpr_14(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d4e668
	if (!ctx.cr6.gt) goto loc_82D4E668;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lis r23,-32255
	ctx.r23.s64 = -2113863680;
	// rlwinm r27,r11,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// rlwinm r26,r11,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f17,-1988(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -1988);
	ctx.f17.f64 = double(temp.f32);
	// lis r30,-32255
	ctx.r30.s64 = -2113863680;
	// lfs f11,-28552(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -28552);
	ctx.f11.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// stfs f17,-272(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f12,-7656(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -7656);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f18,-1992(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -1992);
	ctx.f18.f64 = double(temp.f32);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f30,-12288(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -12288);
	ctx.f30.f64 = double(temp.f32);
	// lfs f31,-7592(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -7592);
	ctx.f31.f64 = double(temp.f32);
	// lfs f13,-7588(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7588);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7584(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -7584);
	ctx.f0.f64 = double(temp.f32);
	// b 0x82d4e40c
	goto loc_82D4E40C;
loc_82D4E408:
	// lfs f17,-272(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f17.f64 = double(temp.f32);
loc_82D4E40C:
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f8,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f29,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// mulli r31,r7,12
	ctx.r31.s64 = ctx.r7.s64 * 12;
	// lfsx f6,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f22,f5,f6
	ctx.f22.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// lfsx f27,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f21,f4,f5
	ctx.f21.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// mulli r30,r7,24
	ctx.r30.s64 = ctx.r7.s64 * 24;
	// lfsx f28,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f26,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f24,f28,f27
	ctx.f24.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// fsubs f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// fadds f27,f4,f6
	ctx.f27.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// lfsx f3,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f20,f4,f3
	ctx.f20.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// lfsx f25,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// mulli r29,r7,28
	ctx.r29.s64 = ctx.r7.s64 * 28;
	// fadds f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// fadds f3,f3,f6
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// fadds f23,f25,f26
	ctx.f23.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f4,f26,f25
	ctx.f4.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfsx f7,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// mulli r29,r7,20
	ctx.r29.s64 = ctx.r7.s64 * 20;
	// fsubs f6,f22,f20
	ctx.f6.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// fadds f22,f24,f7
	ctx.f22.f64 = double(float(ctx.f24.f64 + ctx.f7.f64));
	// fsubs f25,f3,f21
	ctx.f25.f64 = double(float(ctx.f3.f64 - ctx.f21.f64));
	// fsubs f24,f7,f24
	ctx.f24.f64 = double(float(ctx.f7.f64 - ctx.f24.f64));
	// fmuls f20,f5,f0
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// lfsx f10,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f21,f4,f13
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fadds f3,f10,f7
	ctx.f3.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// lfsx f2,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// rlwinm r28,r7,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f7,f23,f8
	ctx.f7.f64 = double(float(ctx.f23.f64 + ctx.f8.f64));
	// fsubs f23,f8,f23
	ctx.f23.f64 = double(float(ctx.f8.f64 - ctx.f23.f64));
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r31,r8,28
	ctx.r31.s64 = ctx.r8.s64 * 28;
	// fsubs f14,f22,f10
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f10.f64));
	// fmuls f25,f25,f31
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// lfsx f9,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f26,f8,f9
	ctx.f26.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// lfsx f1,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f8,f24,f31
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// fmuls f24,f5,f13
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmuls f19,f3,f13
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f5,f23,f31
	ctx.f5.f64 = double(float(ctx.f23.f64 * ctx.f31.f64));
	// rlwinm r30,r8,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f23,f3,f0
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// rlwinm r29,r9,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fmsubs f3,f27,f13,f20
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 - ctx.f20.f64));
	// mulli r28,r9,24
	ctx.r28.s64 = ctx.r9.s64 * 24;
	// fmsubs f16,f10,f17,f1
	ctx.f16.f64 = double(float(ctx.f10.f64 * ctx.f17.f64 - ctx.f1.f64));
	// fmuls f20,f26,f13
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmadds f26,f26,f0,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f21.f64));
	// fmuls f21,f22,f30
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// fmadds f24,f27,f0,f24
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 + ctx.f24.f64));
	// fmadds f27,f6,f30,f29
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f30.f64 + ctx.f29.f64));
	// fmsubs f23,f28,f13,f23
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 - ctx.f23.f64));
	// fmadds f28,f28,f0,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 + ctx.f19.f64));
	// fnmsubs f19,f10,f18,f8
	ctx.f19.f64 = double(float(-(ctx.f10.f64 * ctx.f18.f64 - ctx.f8.f64)));
	// fmsubs f4,f4,f0,f20
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 - ctx.f20.f64));
	// fmuls f20,f7,f30
	ctx.f20.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// fadds f15,f21,f1
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// fadds f21,f21,f8
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f8.f64));
	// fadds f22,f25,f27
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f8,f23,f26
	ctx.f8.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// fsubs f10,f4,f28
	ctx.f10.f64 = double(float(ctx.f4.f64 - ctx.f28.f64));
	// fnmsubs f17,f9,f17,f20
	ctx.f17.f64 = double(float(-(ctx.f9.f64 * ctx.f17.f64 - ctx.f20.f64)));
	// fneg f15,f15
	ctx.f15.u64 = ctx.f15.u64 ^ 0x8000000000000000;
	// fneg f21,f21
	ctx.f21.u64 = ctx.f21.u64 ^ 0x8000000000000000;
	// fadds f28,f28,f4
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f4.f64));
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// fadds f15,f9,f2
	ctx.f15.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// fmadds f9,f9,f18,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f18.f64 + ctx.f2.f64));
	// stfs f9,-268(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fsubs f9,f15,f7
	ctx.f9.f64 = double(float(ctx.f15.f64 - ctx.f7.f64));
	// fsubs f4,f27,f25
	ctx.f4.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// mulli r24,r9,12
	ctx.r24.s64 = ctx.r9.s64 * 12;
	// fadds f27,f17,f5
	ctx.f27.f64 = double(float(ctx.f17.f64 + ctx.f5.f64));
	// mulli r23,r8,12
	ctx.r23.s64 = ctx.r8.s64 * 12;
	// fsubs f6,f29,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 - ctx.f6.f64));
	// fsubs f7,f14,f1
	ctx.f7.f64 = double(float(ctx.f14.f64 - ctx.f1.f64));
	// fmuls f29,f28,f12
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// lfs f28,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f20
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f20.f64));
	// fadds f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fadds f1,f16,f21
	ctx.f1.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// fadds f25,f8,f24
	ctx.f25.f64 = double(float(ctx.f8.f64 + ctx.f24.f64));
	// fmsubs f8,f8,f11,f24
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f11.f64 - ctx.f24.f64));
	// fadds f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 + ctx.f2.f64));
	// fadds f27,f7,f9
	ctx.f27.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fsubs f9,f9,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// fsubs f5,f28,f5
	ctx.f5.f64 = double(float(ctx.f28.f64 - ctx.f5.f64));
	// mulli r22,r8,24
	ctx.r22.s64 = ctx.r8.s64 * 24;
	// fmuls f28,f26,f12
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// fadds f26,f10,f3
	ctx.f26.f64 = double(float(ctx.f10.f64 + ctx.f3.f64));
	// fmsubs f10,f10,f11,f3
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 - ctx.f3.f64));
	// fsubs f3,f1,f2
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// rlwinm r21,r9,4,0,27
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f9,f9,f12
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// stfsx f9,r11,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f9,f2,f1
	ctx.f9.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// rlwinm r20,r8,4,0,27
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f2,f19,f5
	ctx.f2.f64 = double(float(ctx.f19.f64 - ctx.f5.f64));
	// mulli r19,r9,20
	ctx.r19.s64 = ctx.r9.s64 * 20;
	// fadds f7,f5,f19
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f19.f64));
	// fmuls f5,f3,f12
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// mulli r11,r8,20
	ctx.r11.s64 = ctx.r8.s64 * 20;
	// fmuls f3,f2,f12
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fadds f2,f27,f6
	ctx.f2.f64 = double(float(ctx.f27.f64 + ctx.f6.f64));
	// fnmsubs f6,f27,f11,f6
	ctx.f6.f64 = double(float(-(ctx.f27.f64 * ctx.f11.f64 - ctx.f6.f64)));
	// stfsx f6,r10,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f6,f9,f22
	ctx.f6.f64 = double(float(ctx.f9.f64 + ctx.f22.f64));
	// stfsx f2,r31,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fnmsubs f9,f9,f11,f22
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f11.f64 - ctx.f22.f64)));
	// stfsx f6,r30,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// stfsx f26,r29,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f2,f5,f10
	ctx.f2.f64 = double(float(ctx.f5.f64 - ctx.f10.f64));
	// stfsx f2,r28,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f10,f5,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f10.f64));
	// stfsx f10,r24,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f7,f4
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// add r4,r27,r4
	ctx.r4.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fsubs f10,f8,f3
	ctx.f10.f64 = double(float(ctx.f8.f64 - ctx.f3.f64));
	// fsubs f5,f9,f29
	ctx.f5.f64 = double(float(ctx.f9.f64 - ctx.f29.f64));
	// stfsx f5,r23,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f9,f29
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f29.f64));
	// stfsx f9,r22,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r5.u32, temp.u32);
	// stfsx f25,r21,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r6.u32, temp.u32);
	// stfsx f6,r20,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r5.u32, temp.u32);
	// stfsx f10,r19,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r6.u32, temp.u32);
	// fadds f10,f3,f8
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f8.f64));
	// stfs f10,0(r6)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fnmsubs f10,f7,f11,f4
	ctx.f10.f64 = double(float(-(ctx.f7.f64 * ctx.f11.f64 - ctx.f4.f64)));
	// add r6,r26,r6
	ctx.r6.u64 = ctx.r26.u64 + ctx.r6.u64;
	// fadds f9,f10,f28
	ctx.f9.f64 = double(float(ctx.f10.f64 + ctx.f28.f64));
	// stfs f9,0(r5)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f28.f64));
	// stfsx f10,r11,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 3532);
	// add r5,r26,r5
	ctx.r5.u64 = ctx.r26.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d4e408
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D4E408;
loc_82D4E668:
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28f2c
	ctx.lr = 0x82D4E670;
	__restfpr_14(ctx, base);
	// b 0x82e28e94
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4E678"))) PPC_WEAK_FUNC(sub_82D4E678);
PPC_FUNC_IMPL(__imp__sub_82D4E678) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-2040
	ctx.r5.s64 = ctx.r11.s64 + -2040;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-7280
	ctx.r4.s64 = ctx.r11.s64 + -7280;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4E690"))) PPC_WEAK_FUNC(sub_82D4E690);
PPC_FUNC_IMPL(__imp__sub_82D4E690) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e44
	ctx.lr = 0x82D4E698;
	__savegprlr_19(ctx, base);
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28f0c
	ctx.lr = 0x82D4E6A0;
	__savefpr_25(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d4e878
	if (!ctx.cr6.gt) goto loc_82D4E878;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lis r30,-32236
	ctx.r30.s64 = -2112618496;
	// rlwinm r28,r11,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// rlwinm r27,r11,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfs f25,-3664(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -3664);
	ctx.f25.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f0,140(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f26,-1936(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -1936);
	ctx.f26.f64 = double(temp.f32);
	// lfs f27,-28552(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28552);
	ctx.f27.f64 = double(temp.f32);
	// lfs f28,-7656(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -7656);
	ctx.f28.f64 = double(temp.f32);
loc_82D4E6E8:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f11,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r30,r7,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// mulli r10,r7,12
	ctx.r10.s64 = ctx.r7.s64 * 12;
	// lfsx f9,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f13,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f1,f9,f11
	ctx.f1.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// lfsx f12,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// fadds f9,f11,f9
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f9.f64));
	// lfsx f8,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f30,f13,f12
	ctx.f30.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// mulli r31,r7,20
	ctx.r31.s64 = ctx.r7.s64 * 20;
	// lfsx f3,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f29,f12,f10
	ctx.f29.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// lfsx f7,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f31,f3,f0
	ctx.f31.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// lfsx f6,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f11,f6,f8
	ctx.f11.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// lfsx f5,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// rlwinm r29,r7,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f6,f8,f6
	ctx.f6.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// fsubs f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// rlwinm r25,r8,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f9,f9,f26
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// rlwinm r24,r8,4,0,27
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r23,r9,4,0,27
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r22,r9,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r21,r8,20
	ctx.r21.s64 = ctx.r8.s64 * 20;
	// lfsx f2,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f8,f2,f5
	ctx.f8.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// lfsx f4,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// fadds f2,f12,f13
	ctx.f2.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fmadds f12,f30,f27,f10
	ctx.f12.f64 = double(float(ctx.f30.f64 * ctx.f27.f64 + ctx.f10.f64));
	// fmuls f30,f11,f25
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// fadds f11,f11,f4
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f4.f64));
	// fmuls f6,f6,f26
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// rlwinm r20,r9,3,0,28
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f13,f29,f13
	ctx.f13.f64 = double(float(ctx.f29.f64 - ctx.f13.f64));
	// mulli r19,r9,12
	ctx.r19.s64 = ctx.r9.s64 * 12;
	// fmuls f10,f5,f28
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// fmuls f5,f2,f28
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// fmadds f2,f1,f25,f31
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f25.f64 + ctx.f31.f64));
	// fmsubs f4,f4,f0,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 - ctx.f30.f64));
	// fadds f31,f3,f11
	ctx.f31.f64 = double(float(ctx.f3.f64 + ctx.f11.f64));
	// mulli r11,r8,12
	ctx.r11.s64 = ctx.r8.s64 * 12;
	// fsubs f30,f3,f11
	ctx.f30.f64 = double(float(ctx.f3.f64 - ctx.f11.f64));
	// fsubs f1,f7,f8
	ctx.f1.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// fmadds f8,f8,f27,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f27.f64 + ctx.f7.f64));
	// fsubs f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f10,f9,f2
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f2.f64));
	// mulli r10,r9,20
	ctx.r10.s64 = ctx.r9.s64 * 20;
	// fsubs f11,f4,f6
	ctx.f11.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fmuls f3,f31,f0
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f31,f30,f0
	ctx.f31.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fsubs f30,f5,f8
	ctx.f30.f64 = double(float(ctx.f5.f64 - ctx.f8.f64));
	// rlwinm r31,r8,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r28,r3
	ctx.r3.u64 = ctx.r28.u64 + ctx.r3.u64;
	// fadds f29,f10,f11
	ctx.f29.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// fsubs f10,f13,f3
	ctx.f10.f64 = double(float(ctx.f13.f64 - ctx.f3.f64));
	// stfsx f10,r25,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fadds f13,f3,f13
	ctx.f13.f64 = double(float(ctx.f3.f64 + ctx.f13.f64));
	// stfsx f13,r24,r5
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fsubs f13,f31,f1
	ctx.f13.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// stfsx f13,r23,r6
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// fadds f13,f1,f31
	ctx.f13.f64 = double(float(ctx.f1.f64 + ctx.f31.f64));
	// stfsx f13,r22,r6
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// fadds f10,f8,f5
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// fsubs f13,f7,f29
	ctx.f13.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// stfsx f13,r21,r5
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r5.u32, temp.u32);
	// fadds f13,f11,f30
	ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f30.f64));
	// stfsx f13,r20,r6
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r6.u32, temp.u32);
	// fadds f13,f29,f7
	ctx.f13.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// stfs f13,0(r5)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f13,f11,f30
	ctx.f13.f64 = double(float(ctx.f11.f64 - ctx.f30.f64));
	// stfsx f13,r19,r6
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r6.u32, temp.u32);
	// fadds f13,f9,f2
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// fadds f11,f4,f6
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fadds f9,f11,f13
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// add r4,r28,r4
	ctx.r4.u64 = ctx.r28.u64 + ctx.r4.u64;
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// fadds f11,f9,f10
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f8,f12,f13
	ctx.f8.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// stfsx f8,r11,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// stfsx f10,r10,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// stfsx f13,r31,r5
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// add r5,r27,r5
	ctx.r5.u64 = ctx.r27.u64 + ctx.r5.u64;
	// fneg f13,f11
	ctx.f13.u64 = ctx.f11.u64 ^ 0x8000000000000000;
	// stfs f13,0(r6)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lwz r11,3532(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 3532);
	// add r6,r27,r6
	ctx.r6.u64 = ctx.r27.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d4e6e8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D4E6E8;
loc_82D4E878:
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28f58
	ctx.lr = 0x82D4E880;
	__restfpr_25(ctx, base);
	// b 0x82e28e94
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4E888"))) PPC_WEAK_FUNC(sub_82D4E888);
PPC_FUNC_IMPL(__imp__sub_82D4E888) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1984
	ctx.r5.s64 = ctx.r11.s64 + -1984;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-6512
	ctx.r4.s64 = ctx.r11.s64 + -6512;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4E8A0"))) PPC_WEAK_FUNC(sub_82D4E8A0);
PPC_FUNC_IMPL(__imp__sub_82D4E8A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e48
	ctx.lr = 0x82D4E8A8;
	__savegprlr_20(ctx, base);
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82e28f14
	ctx.lr = 0x82D4E8B0;
	__savefpr_27(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d4ea30
	if (!ctx.cr6.gt) goto loc_82D4EA30;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r30,-32255
	ctx.r30.s64 = -2113863680;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// rlwinm r29,r11,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// rlwinm r28,r11,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f29,-12288(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -12288);
	ctx.f29.f64 = double(temp.f32);
	// lfs f13,-7588(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -7588);
	ctx.f13.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f0,-7584(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7584);
	ctx.f0.f64 = double(temp.f32);
	// lfs f30,-7592(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -7592);
	ctx.f30.f64 = double(temp.f32);
loc_82D4E8F0:
	// mulli r11,r7,12
	ctx.r11.s64 = ctx.r7.s64 * 12;
	// lfs f12,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r30,r7,3,0,28
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f9,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f10,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// rlwinm r10,r7,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r26,r8,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r25,r9,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r24,r8,4,0,27
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f6,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// mulli r23,r8,12
	ctx.r23.s64 = ctx.r8.s64 * 12;
	// lfsx f8,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f31,f6,f9
	ctx.f31.f64 = double(float(ctx.f6.f64 - ctx.f9.f64));
	// lfsx f7,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f2,f8,f12
	ctx.f2.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// lfsx f4,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f1,f10,f7
	ctx.f1.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// lfsx f5,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f9,f9,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f6.f64));
	// fsubs f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfsx f3,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// fsubs f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// rlwinm r22,r8,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r21,r9,12
	ctx.r21.s64 = ctx.r9.s64 * 12;
	// fadds f4,f1,f2
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fsubs f8,f1,f2
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// fsubs f2,f31,f6
	ctx.f2.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// fmuls f1,f5,f13
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fadds f7,f6,f31
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f31.f64));
	// rlwinm r20,r9,4,0,27
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f27,f9,f13
	ctx.f27.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f31,f10,f13
	ctx.f31.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// fmuls f28,f12,f13
	ctx.f28.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// add r4,r29,r4
	ctx.r4.u64 = ctx.r29.u64 + ctx.r4.u64;
	// fmuls f6,f4,f30
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fmuls f4,f2,f30
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// fsubs f2,f8,f3
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f3.f64));
	// fmadds f8,f8,f29,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f29.f64 + ctx.f3.f64));
	// fmadds f9,f9,f0,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 + ctx.f1.f64));
	// fadds f1,f7,f11
	ctx.f1.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// stfsx f1,r26,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fnmsubs f11,f7,f29,f11
	ctx.f11.f64 = double(float(-(ctx.f7.f64 * ctx.f29.f64 - ctx.f11.f64)));
	// stfsx f2,r25,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// fmadds f12,f12,f0,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f31.f64));
	// fmsubs f10,f10,f0,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 - ctx.f28.f64));
	// fmsubs f5,f5,f0,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 - ctx.f27.f64));
	// fadds f7,f8,f6
	ctx.f7.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// fsubs f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// fadds f6,f11,f4
	ctx.f6.f64 = double(float(ctx.f11.f64 + ctx.f4.f64));
	// fsubs f11,f11,f4
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f4.f64));
	// fadds f4,f7,f9
	ctx.f4.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fsubs f9,f9,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// fadds f3,f8,f5
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// fsubs f7,f6,f12
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// stfsx f7,r24,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f11,f10
	ctx.f7.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// stfsx f7,r23,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fadds f12,f6,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 + ctx.f12.f64));
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f12,f11,f10
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// stfsx f12,r22,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r5.u32, temp.u32);
	// fsubs f12,f8,f5
	ctx.f12.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// add r5,r28,r5
	ctx.r5.u64 = ctx.r28.u64 + ctx.r5.u64;
	// fneg f11,f4
	ctx.f11.u64 = ctx.f4.u64 ^ 0x8000000000000000;
	// stfs f11,0(r6)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// stfsx f3,r21,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r6.u32, temp.u32);
	// stfsx f9,r20,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r6.u32, temp.u32);
	// stfsx f12,r11,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,3532(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 3532);
	// add r6,r28,r6
	ctx.r6.u64 = ctx.r28.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d4e8f0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D4E8F0;
loc_82D4EA30:
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82e28f60
	ctx.lr = 0x82D4EA38;
	__restfpr_27(ctx, base);
	// b 0x82e28e98
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4EA40"))) PPC_WEAK_FUNC(sub_82D4EA40);
PPC_FUNC_IMPL(__imp__sub_82D4EA40) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1928
	ctx.r5.s64 = ctx.r11.s64 + -1928;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-5984
	ctx.r4.s64 = ctx.r11.s64 + -5984;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4EA58"))) PPC_WEAK_FUNC(sub_82D4EA58);
PPC_FUNC_IMPL(__imp__sub_82D4EA58) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e3c
	ctx.lr = 0x82D4EA60;
	__savegprlr_17(ctx, base);
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82e28ee0
	ctx.lr = 0x82D4EA68;
	__savefpr_14(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d4ec64
	if (!ctx.cr6.gt) goto loc_82D4EC64;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// rlwinm r18,r11,2,0,29
	ctx.r18.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// rlwinm r17,r11,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f19,-1812(r20)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -1812);
	ctx.f19.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f20,-6140(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -6140);
	ctx.f20.f64 = double(temp.f32);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f21,-1816(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -1816);
	ctx.f21.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f22,-6144(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -6144);
	ctx.f22.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f27,-1820(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -1820);
	ctx.f27.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f28,-6160(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -6160);
	ctx.f28.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f29,-6156(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -6156);
	ctx.f29.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f30,-1824(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -1824);
	ctx.f30.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f23,-1828(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -1828);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,-5076(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -5076);
	ctx.f24.f64 = double(temp.f32);
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lfs f25,-1832(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -1832);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,-5080(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -5080);
	ctx.f26.f64 = double(temp.f32);
	// lfs f13,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-28552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
loc_82D4EAF8:
	// mulli r11,r7,12
	ctx.r11.s64 = ctx.r7.s64 * 12;
	// lfs f12,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f7,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f10,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// fadds f3,f10,f12
	ctx.f3.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// lfsx f9,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// rlwinm r30,r7,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r29,r9,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r28,r8,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r27,r8,4,0,27
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f8,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// lfsx f11,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f2,f8,f11
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f11.f64));
	// lfsx f4,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f5,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f1,f4,f9
	ctx.f1.f64 = double(float(ctx.f4.f64 - ctx.f9.f64));
	// lfsx f6,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// fadds f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f8.f64));
	// fadds f8,f9,f4
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f4.f64));
	// fmadds f10,f3,f0,f5
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f5.f64));
	// fsubs f4,f5,f3
	ctx.f4.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fmuls f18,f12,f25
	ctx.f18.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// fmuls f17,f12,f23
	ctx.f17.f64 = double(float(ctx.f12.f64 * ctx.f23.f64));
	// fsubs f31,f6,f2
	ctx.f31.f64 = double(float(ctx.f6.f64 - ctx.f2.f64));
	// fmadds f9,f2,f0,f6
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f6.f64));
	// fsubs f5,f7,f1
	ctx.f5.f64 = double(float(ctx.f7.f64 - ctx.f1.f64));
	// fmadds f7,f1,f0,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f7.f64));
	// fmuls f3,f10,f29
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// rlwinm r31,r9,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f2,f10,f28
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// rlwinm r30,r8,3,0,28
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f16,f11,f19
	ctx.f16.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// add r3,r18,r3
	ctx.r3.u64 = ctx.r18.u64 + ctx.r3.u64;
	// fmuls f15,f11,f21
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f21.f64));
	// add r4,r18,r4
	ctx.r4.u64 = ctx.r18.u64 + ctx.r4.u64;
	// fmuls f14,f11,f27
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f27.f64));
	// fsubs f1,f4,f31
	ctx.f1.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// fadds f6,f4,f31
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f31.f64));
	// fmuls f31,f9,f29
	ctx.f31.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// fmsubs f4,f12,f30,f3
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 - ctx.f3.f64));
	// fmadds f12,f12,f27,f2
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f27.f64 + ctx.f2.f64));
	// fmadds f2,f9,f20,f16
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f20.f64 + ctx.f16.f64));
	// fmuls f3,f1,f13
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// stfsx f3,r29,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fmsubs f1,f9,f22,f15
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f22.f64 - ctx.f15.f64));
	// fmadds f3,f10,f26,f18
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f26.f64 + ctx.f18.f64));
	// fmsubs f11,f11,f30,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64 - ctx.f31.f64));
	// fmsubs f10,f10,f24,f17
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f24.f64 - ctx.f17.f64));
	// fmadds f9,f9,f28,f14
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64 + ctx.f14.f64));
	// fadds f31,f6,f5
	ctx.f31.f64 = double(float(ctx.f6.f64 + ctx.f5.f64));
	// fnmsubs f6,f6,f0,f5
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f5.f64)));
	// stfsx f6,r28,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fsubs f6,f4,f2
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// stfsx f31,r27,r5
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fadds f5,f12,f1
	ctx.f5.f64 = double(float(ctx.f12.f64 + ctx.f1.f64));
	// fsubs f12,f1,f12
	ctx.f12.f64 = double(float(ctx.f1.f64 - ctx.f12.f64));
	// fsubs f1,f10,f11
	ctx.f1.f64 = double(float(ctx.f10.f64 - ctx.f11.f64));
	// fadds f2,f9,f3
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// fsubs f9,f3,f9
	ctx.f9.f64 = double(float(ctx.f3.f64 - ctx.f9.f64));
	// fadds f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// fnmsubs f31,f8,f13,f6
	ctx.f31.f64 = double(float(-(ctx.f8.f64 * ctx.f13.f64 - ctx.f6.f64)));
	// stfs f31,0(r6)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmadds f4,f4,f13,f7
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f7.f64));
	// fadds f10,f5,f7
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// stfs f10,0(r5)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// fmuls f3,f1,f0
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fsubs f8,f8,f2
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f2.f64));
	// fmadds f9,f9,f0,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 + ctx.f7.f64));
	// fmsubs f12,f12,f13,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 - ctx.f6.f64));
	// stfsx f12,r11,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f12,f5,f0,f4
	ctx.f12.f64 = double(float(-(ctx.f5.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// stfsx f12,r10,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fmadds f12,f8,f13,f3
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 + ctx.f3.f64));
	// stfsx f12,r31,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fmadds f12,f11,f13,f9
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f9.f64));
	// stfsx f12,r30,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 3532);
	// add r6,r17,r6
	ctx.r6.u64 = ctx.r17.u64 + ctx.r6.u64;
	// add r5,r17,r5
	ctx.r5.u64 = ctx.r17.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d4eaf8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D4EAF8;
loc_82D4EC64:
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82e28f2c
	ctx.lr = 0x82D4EC6C;
	__restfpr_14(ctx, base);
	// b 0x82e28e8c
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4EC70"))) PPC_WEAK_FUNC(sub_82D4EC70);
PPC_FUNC_IMPL(__imp__sub_82D4EC70) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1880
	ctx.r5.s64 = ctx.r11.s64 + -1880;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-5544
	ctx.r4.s64 = ctx.r11.s64 + -5544;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4EC88"))) PPC_WEAK_FUNC(sub_82D4EC88);
PPC_FUNC_IMPL(__imp__sub_82D4EC88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e50
	ctx.lr = 0x82D4EC90;
	__savegprlr_22(ctx, base);
	// stfd f29,-112(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -112, ctx.f29.u64);
	// stfd f30,-104(r1)
	PPC_STORE_U64(ctx.r1.u32 + -104, ctx.f30.u64);
	// stfd f31,-96(r1)
	PPC_STORE_U64(ctx.r1.u32 + -96, ctx.f31.u64);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d4edd0
	if (!ctx.cr6.gt) goto loc_82D4EDD0;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r31,-32236
	ctx.r31.s64 = -2112618496;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r29,r11,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f13,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-8016(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8016);
	ctx.f0.f64 = double(temp.f32);
	// lfs f2,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f2.f64 = double(temp.f32);
loc_82D4ECD4:
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f12,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mulli r31,r7,12
	ctx.r31.s64 = ctx.r7.s64 * 12;
	// fmuls f4,f12,f13
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f9,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f6,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fadds f1,f8,f9
	ctx.f1.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f31,f6,f13
	ctx.f31.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fsubs f30,f9,f8
	ctx.f30.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// lfsx f7,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f29,f6,f0
	ctx.f29.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// mulli r27,r8,12
	ctx.r27.s64 = ctx.r8.s64 * 12;
	// lfsx f10,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f10,f13
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfsx f5,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f10,f10,f0,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fmuls f9,f1,f2
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// mulli r26,r9,12
	ctx.r26.s64 = ctx.r9.s64 * 12;
	// fmadds f8,f7,f0,f31
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 + ctx.f31.f64));
	// fmuls f6,f30,f2
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f2.f64));
	// fmsubs f7,f7,f13,f29
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 - ctx.f29.f64));
	// fmsubs f12,f12,f0,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 - ctx.f3.f64));
	// rlwinm r25,r8,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r24,r8,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f4,f9,f5
	ctx.f4.f64 = double(float(ctx.f9.f64 + ctx.f5.f64));
	// rlwinm r23,r9,3,0,28
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f9,f5,f9
	ctx.f9.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// rlwinm r22,r9,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f5,f8,f10
	ctx.f5.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// add r4,r30,r4
	ctx.r4.u64 = ctx.r30.u64 + ctx.r4.u64;
	// fadds f3,f6,f11
	ctx.f3.f64 = double(float(ctx.f6.f64 + ctx.f11.f64));
	// add r3,r30,r3
	ctx.r3.u64 = ctx.r30.u64 + ctx.r3.u64;
	// fsubs f11,f11,f6
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f6.f64));
	// fsubs f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// fadds f6,f7,f12
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fsubs f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 - ctx.f12.f64));
	// fadds f8,f4,f5
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f7,f4,f5
	ctx.f7.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// fsubs f5,f3,f6
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// stfsx f5,r27,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f6,f6,f3
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// stfs f6,0(r5)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f6,f11,f10
	ctx.f6.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fsubs f10,f12,f9
	ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// fadds f12,f9,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f12.f64));
	// fneg f9,f8
	ctx.f9.u64 = ctx.f8.u64 ^ 0x8000000000000000;
	// stfs f9,0(r6)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// stfsx f7,r26,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// stfsx f6,r25,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// stfsx f11,r24,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// add r5,r29,r5
	ctx.r5.u64 = ctx.r29.u64 + ctx.r5.u64;
	// stfsx f10,r23,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// stfsx f12,r22,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,3532(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3532);
	// add r6,r29,r6
	ctx.r6.u64 = ctx.r29.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d4ecd4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D4ECD4;
loc_82D4EDD0:
	// lfd f29,-112(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// lfd f30,-104(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x82e28ea0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4EDE0"))) PPC_WEAK_FUNC(sub_82D4EDE0);
PPC_FUNC_IMPL(__imp__sub_82D4EDE0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1808
	ctx.r5.s64 = ctx.r11.s64 + -1808;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-4984
	ctx.r4.s64 = ctx.r11.s64 + -4984;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4EDF8"))) PPC_WEAK_FUNC(sub_82D4EDF8);
PPC_FUNC_IMPL(__imp__sub_82D4EDF8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D4EE00;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f08
	ctx.lr = 0x82D4EE08;
	__savefpr_24(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d4ef4c
	if (!ctx.cr6.gt) goto loc_82D4EF4C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f2,-4940(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -4940);
	ctx.f2.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f3,-4944(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -4944);
	ctx.f3.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f4,-4948(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -4948);
	ctx.f4.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f5,-4960(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -4960);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,-4952(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4952);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,-4956(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4956);
	ctx.f7.f64 = double(temp.f32);
loc_82D4EE58:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f0,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// mulli r28,r7,12
	ctx.r28.s64 = ctx.r7.s64 * 12;
	// lfsx f11,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f8,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f12,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// fadds f9,f8,f11
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// fadds f10,f12,f13
	ctx.f10.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfsx f1,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfsx f31,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f12,f11,f8
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f8,f31,f1
	ctx.f8.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// rlwinm r27,r9,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f11,f1,f31
	ctx.f11.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// rlwinm r26,r8,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r25,r8,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r24,r8,12
	ctx.r24.s64 = ctx.r8.s64 * 12;
	// fmuls f27,f9,f6
	ctx.f27.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f1,f10,f7
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// fmuls f31,f13,f3
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fmuls f30,f10,f6
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// fmuls f29,f13,f2
	ctx.f29.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fmuls f26,f12,f3
	ctx.f26.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fmadds f25,f12,f2,f0
	ctx.f25.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 + ctx.f0.f64));
	// fmadds f24,f11,f3,f0
	ctx.f24.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f0.f64));
	// fmadds f28,f13,f4,f0
	ctx.f28.f64 = double(float(ctx.f13.f64 * ctx.f4.f64 + ctx.f0.f64));
	// fadds f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fmadds f27,f8,f7,f27
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 + ctx.f27.f64));
	// fmsubs f1,f8,f6,f1
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f6.f64 - ctx.f1.f64));
	// fmadds f31,f11,f4,f31
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f4.f64 + ctx.f31.f64));
	// fmsubs f30,f9,f7,f30
	ctx.f30.f64 = double(float(ctx.f9.f64 * ctx.f7.f64 - ctx.f30.f64));
	// fnmadds f29,f12,f4,f29
	ctx.f29.f64 = double(float(-(ctx.f12.f64 * ctx.f4.f64 + ctx.f29.f64)));
	// fnmadds f26,f11,f2,f26
	ctx.f26.f64 = double(float(-(ctx.f11.f64 * ctx.f2.f64 + ctx.f26.f64)));
	// fadds f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fnmadds f12,f10,f5,f27
	ctx.f12.f64 = double(float(-(ctx.f10.f64 * ctx.f5.f64 + ctx.f27.f64)));
	// stfs f12,0(r6)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fnmsubs f12,f9,f5,f1
	ctx.f12.f64 = double(float(-(ctx.f9.f64 * ctx.f5.f64 - ctx.f1.f64)));
	// stfsx f12,r28,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f12,f31,f25
	ctx.f12.f64 = double(float(ctx.f31.f64 + ctx.f25.f64));
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fnmsubs f12,f8,f5,f30
	ctx.f12.f64 = double(float(-(ctx.f8.f64 * ctx.f5.f64 - ctx.f30.f64)));
	// stfsx f12,r27,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fadds f12,f29,f24
	ctx.f12.f64 = double(float(ctx.f29.f64 + ctx.f24.f64));
	// stfsx f12,r26,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fadds f12,f26,f28
	ctx.f12.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// stfsx f12,r25,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfsx f0,r24,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3532);
	// add r6,r30,r6
	ctx.r6.u64 = ctx.r30.u64 + ctx.r6.u64;
	// add r5,r30,r5
	ctx.r5.u64 = ctx.r30.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d4ee58
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D4EE58;
loc_82D4EF4C:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f54
	ctx.lr = 0x82D4EF54;
	__restfpr_24(ctx, base);
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4EF58"))) PPC_WEAK_FUNC(sub_82D4EF58);
PPC_FUNC_IMPL(__imp__sub_82D4EF58) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1760
	ctx.r5.s64 = ctx.r11.s64 + -1760;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-4616
	ctx.r4.s64 = ctx.r11.s64 + -4616;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4EF70"))) PPC_WEAK_FUNC(sub_82D4EF70);
PPC_FUNC_IMPL(__imp__sub_82D4EF70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82D4EF78;
	__savegprlr_25(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d4f054
	if (!ctx.cr6.gt) goto loc_82D4F054;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f6,-28552(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28552);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,-7656(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -7656);
	ctx.f7.f64 = double(temp.f32);
loc_82D4EFA8:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r28,r8,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r27,r9,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r26,r8,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f10,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// rlwinm r25,r9,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f13,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f13.f64 = double(temp.f32);
	// fadds f8,f12,f10
	ctx.f8.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// lfsx f0,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// fsubs f5,f0,f13
	ctx.f5.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfsx f9,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f10,f13,f0
	ctx.f10.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fadds f4,f13,f11
	ctx.f4.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fmuls f13,f12,f7
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// fmadds f11,f5,f6,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f6.f64 + ctx.f11.f64));
	// fmuls f12,f10,f7
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// fsubs f10,f4,f0
	ctx.f10.f64 = double(float(ctx.f4.f64 - ctx.f0.f64));
	// fmadds f0,f8,f6,f9
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f6.f64 + ctx.f9.f64));
	// fsubs f5,f9,f8
	ctx.f5.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fsubs f9,f11,f13
	ctx.f9.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// stfs f9,0(r5)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// stfsx f13,r28,r5
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// stfsx f5,r27,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fadds f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
	// stfsx f10,r26,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fsubs f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// add r5,r30,r5
	ctx.r5.u64 = ctx.r30.u64 + ctx.r5.u64;
	// fneg f13,f13
	ctx.f13.u64 = ctx.f13.u64 ^ 0x8000000000000000;
	// stfs f13,0(r6)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// stfsx f0,r25,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,3532(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3532);
	// add r6,r30,r6
	ctx.r6.u64 = ctx.r30.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d4efa8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D4EFA8;
loc_82D4F054:
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4F058"))) PPC_WEAK_FUNC(sub_82D4F058);
PPC_FUNC_IMPL(__imp__sub_82D4F058) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1712
	ctx.r5.s64 = ctx.r11.s64 + -1712;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-4240
	ctx.r4.s64 = ctx.r11.s64 + -4240;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4F070"))) PPC_WEAK_FUNC(sub_82D4F070);
PPC_FUNC_IMPL(__imp__sub_82D4F070) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D4F078;
	__savegprlr_26(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d4f154
	if (!ctx.cr6.gt) goto loc_82D4F154;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r27,-32255
	ctx.r27.s64 = -2113863680;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f5,-12288(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -12288);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,-7592(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -7592);
	ctx.f6.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f7,-7584(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -7584);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,-7588(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -7588);
	ctx.f8.f64 = double(temp.f32);
loc_82D4F0B8:
	// rlwinm r29,r7,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r28,r8,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r27,r9,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r26,r8,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f12,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f10,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f9,f12,f0
	ctx.f9.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// lfsx f11,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// fadds f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
	// fsubs f12,f11,f10
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// fmuls f10,f0,f7
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fmuls f4,f0,f8
	ctx.f4.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// fadds f0,f9,f12
	ctx.f0.f64 = double(float(ctx.f9.f64 + ctx.f12.f64));
	// fsubs f12,f12,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// fmsubs f10,f11,f8,f10
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 - ctx.f10.f64));
	// fnmadds f11,f11,f7,f4
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f7.f64 + ctx.f4.f64)));
	// fadds f9,f0,f13
	ctx.f9.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// stfsx f9,r28,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fmuls f12,f12,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// stfsx f10,r27,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f0,f0,f5,f13
	ctx.f0.f64 = double(float(-(ctx.f0.f64 * ctx.f5.f64 - ctx.f13.f64)));
	// stfs f11,0(r6)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// add r6,r31,r6
	ctx.r6.u64 = ctx.r31.u64 + ctx.r6.u64;
	// fadds f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
	// stfs f13,0(r5)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// stfsx f0,r26,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// add r5,r31,r5
	ctx.r5.u64 = ctx.r31.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d4f0b8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D4F0B8;
loc_82D4F154:
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4F158"))) PPC_WEAK_FUNC(sub_82D4F158);
PPC_FUNC_IMPL(__imp__sub_82D4F158) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1664
	ctx.r5.s64 = ctx.r11.s64 + -1664;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-3984
	ctx.r4.s64 = ctx.r11.s64 + -3984;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4F170"))) PPC_WEAK_FUNC(sub_82D4F170);
PPC_FUNC_IMPL(__imp__sub_82D4F170) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D4F178;
	__savegprlr_28(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d4f214
	if (!ctx.cr6.gt) goto loc_82D4F214;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f10,140(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
loc_82D4F1A0:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r29,r8,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f12,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f12.f64 = double(temp.f32);
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// fadds f9,f12,f0
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// lfsx f11,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f12,f0,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fmuls f0,f9,f10
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// fmuls f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// fadds f9,f0,f11
	ctx.f9.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// fsubs f8,f13,f12
	ctx.f8.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// stfsx f8,r29,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fsubs f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// stfsx f0,r28,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f0,f12,f13
	ctx.f0.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// add r5,r31,r5
	ctx.r5.u64 = ctx.r31.u64 + ctx.r5.u64;
	// fneg f0,f9
	ctx.f0.u64 = ctx.f9.u64 ^ 0x8000000000000000;
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lwz r11,3532(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// add r6,r31,r6
	ctx.r6.u64 = ctx.r31.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d4f1a0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D4F1A0;
loc_82D4F214:
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4F218"))) PPC_WEAK_FUNC(sub_82D4F218);
PPC_FUNC_IMPL(__imp__sub_82D4F218) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1616
	ctx.r5.s64 = ctx.r11.s64 + -1616;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-3728
	ctx.r4.s64 = ctx.r11.s64 + -3728;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4F230"))) PPC_WEAK_FUNC(sub_82D4F230);
PPC_FUNC_IMPL(__imp__sub_82D4F230) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d4f2c0
	if (!ctx.cr6.gt) goto loc_82D4F2C0;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r30,-32255
	ctx.r30.s64 = -2113863680;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f9,-28552(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -28552);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-7656(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -7656);
	ctx.f10.f64 = double(temp.f32);
loc_82D4F268:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r30,r8,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lfsx f12,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fsubs f11,f0,f12
	ctx.f11.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fadds f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fsubs f12,f13,f11
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// stfsx f12,r30,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fmuls f0,f0,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// fneg f0,f0
	ctx.f0.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fmadds f0,f11,f9,f13
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f9.f64 + ctx.f13.f64));
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r11,3532(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 3532);
	// add r6,r9,r6
	ctx.r6.u64 = ctx.r9.u64 + ctx.r6.u64;
	// add r5,r9,r5
	ctx.r5.u64 = ctx.r9.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d4f268
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D4F268;
loc_82D4F2C0:
	// ld r30,-16(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D4F2D0"))) PPC_WEAK_FUNC(sub_82D4F2D0);
PPC_FUNC_IMPL(__imp__sub_82D4F2D0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1568
	ctx.r5.s64 = ctx.r11.s64 + -1568;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-3536
	ctx.r4.s64 = ctx.r11.s64 + -3536;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4F2E8"))) PPC_WEAK_FUNC(sub_82D4F2E8);
PPC_FUNC_IMPL(__imp__sub_82D4F2E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// blelr cr6
	if (!ctx.cr6.gt) return;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D4F304:
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// add r4,r11,r4
	ctx.r4.u64 = ctx.r11.u64 + ctx.r4.u64;
	// lfs f13,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fneg f0,f0
	ctx.f0.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// stfs f13,0(r5)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// add r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// add r5,r10,r5
	ctx.r5.u64 = ctx.r10.u64 + ctx.r5.u64;
	// add r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 + ctx.r6.u64;
	// bdnz 0x82d4f304
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D4F304;
	// blr 
	return;
}

